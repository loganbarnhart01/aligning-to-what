{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9997262523952917,
  "eval_steps": 500.0,
  "global_step": 16437,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00018249840313897252,
      "grad_norm": 1.1739975214004517,
      "learning_rate": 5.333333333333335e-07,
      "logits/chosen": -0.8579156398773193,
      "logits/rejected": -0.842444121837616,
      "logps/chosen": -143.12728881835938,
      "logps/rejected": -108.96340942382812,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.0018249840313897254,
      "grad_norm": 1.7223604917526245,
      "learning_rate": 4.800000000000001e-06,
      "logits/chosen": -0.9099692106246948,
      "logits/rejected": -0.9433425068855286,
      "logps/chosen": -122.76173400878906,
      "logps/rejected": -131.39303588867188,
      "loss": 0.6934,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -9.380446863360703e-05,
      "rewards/margins": -0.00044181611156091094,
      "rewards/rejected": 0.00034801167203113437,
      "step": 10
    },
    {
      "epoch": 0.003649968062779451,
      "grad_norm": 1.3494524955749512,
      "learning_rate": 1.0133333333333335e-05,
      "logits/chosen": -0.9213789105415344,
      "logits/rejected": -0.8858861923217773,
      "logps/chosen": -130.88314819335938,
      "logps/rejected": -122.84271240234375,
      "loss": 0.6928,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.00345954904332757,
      "rewards/margins": 0.0006675625336356461,
      "rewards/rejected": 0.0027919865678995848,
      "step": 20
    },
    {
      "epoch": 0.005474952094169176,
      "grad_norm": 1.8266887664794922,
      "learning_rate": 1.546666666666667e-05,
      "logits/chosen": -0.9900725483894348,
      "logits/rejected": -0.9339817762374878,
      "logps/chosen": -166.92764282226562,
      "logps/rejected": -139.60092163085938,
      "loss": 0.6932,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.011721925809979439,
      "rewards/margins": -0.00014285091310739517,
      "rewards/rejected": 0.011864776723086834,
      "step": 30
    },
    {
      "epoch": 0.007299936125558902,
      "grad_norm": 1.0533100366592407,
      "learning_rate": 2.08e-05,
      "logits/chosen": -0.9146875143051147,
      "logits/rejected": -0.9282172918319702,
      "logps/chosen": -143.02366638183594,
      "logps/rejected": -140.30990600585938,
      "loss": 0.6911,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.022545630112290382,
      "rewards/margins": 0.004126735031604767,
      "rewards/rejected": 0.018418895080685616,
      "step": 40
    },
    {
      "epoch": 0.009124920156948626,
      "grad_norm": NaN,
      "learning_rate": 2.5600000000000002e-05,
      "logits/chosen": -0.9592822790145874,
      "logits/rejected": -0.9217880368232727,
      "logps/chosen": -147.7567138671875,
      "logps/rejected": -119.9024658203125,
      "loss": 0.6932,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.046882398426532745,
      "rewards/margins": 0.00022670738690067083,
      "rewards/rejected": 0.046655695885419846,
      "step": 50
    },
    {
      "epoch": 0.010949904188338352,
      "grad_norm": 1.3863749504089355,
      "learning_rate": 3.093333333333334e-05,
      "logits/chosen": -0.9324530363082886,
      "logits/rejected": -0.879136860370636,
      "logps/chosen": -158.80258178710938,
      "logps/rejected": -123.15061950683594,
      "loss": 0.6906,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.05181484296917915,
      "rewards/margins": 0.005393867380917072,
      "rewards/rejected": 0.046420980244874954,
      "step": 60
    },
    {
      "epoch": 0.012774888219728078,
      "grad_norm": 1.3510128259658813,
      "learning_rate": 3.626666666666667e-05,
      "logits/chosen": -0.912787914276123,
      "logits/rejected": -0.8715840578079224,
      "logps/chosen": -142.7753143310547,
      "logps/rejected": -127.09721374511719,
      "loss": 0.6877,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.05714214965701103,
      "rewards/margins": 0.011530722491443157,
      "rewards/rejected": 0.045611422508955,
      "step": 70
    },
    {
      "epoch": 0.014599872251117803,
      "grad_norm": 1.4074546098709106,
      "learning_rate": 4.16e-05,
      "logits/chosen": -0.9587358236312866,
      "logits/rejected": -0.9309524297714233,
      "logps/chosen": -147.1240234375,
      "logps/rejected": -115.83321380615234,
      "loss": 0.6865,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.07926484942436218,
      "rewards/margins": 0.014393068850040436,
      "rewards/rejected": 0.06487178057432175,
      "step": 80
    },
    {
      "epoch": 0.01642485628250753,
      "grad_norm": 1.8684366941452026,
      "learning_rate": 4.693333333333334e-05,
      "logits/chosen": -0.9296540021896362,
      "logits/rejected": -0.8974363207817078,
      "logps/chosen": -149.52206420898438,
      "logps/rejected": -121.22786712646484,
      "loss": 0.6748,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.09010467678308487,
      "rewards/margins": 0.04043922573328018,
      "rewards/rejected": 0.04966544359922409,
      "step": 90
    },
    {
      "epoch": 0.018249840313897252,
      "grad_norm": 2.1698126792907715,
      "learning_rate": 5.226666666666667e-05,
      "logits/chosen": -0.8845146298408508,
      "logits/rejected": -0.853683352470398,
      "logps/chosen": -158.7959747314453,
      "logps/rejected": -135.03854370117188,
      "loss": 0.6632,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.13501590490341187,
      "rewards/margins": 0.06964494287967682,
      "rewards/rejected": 0.06537095457315445,
      "step": 100
    },
    {
      "epoch": 0.020074824345286978,
      "grad_norm": 2.5103232860565186,
      "learning_rate": 5.7600000000000004e-05,
      "logits/chosen": -0.9321249723434448,
      "logits/rejected": -0.8696069717407227,
      "logps/chosen": -169.82998657226562,
      "logps/rejected": -121.40095520019531,
      "loss": 0.6465,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.05006041377782822,
      "rewards/margins": 0.11047764867544174,
      "rewards/rejected": -0.06041722744703293,
      "step": 110
    },
    {
      "epoch": 0.021899808376676703,
      "grad_norm": 2.2140591144561768,
      "learning_rate": 6.293333333333334e-05,
      "logits/chosen": -0.9196816682815552,
      "logits/rejected": -0.8999847173690796,
      "logps/chosen": -140.66091918945312,
      "logps/rejected": -127.64927673339844,
      "loss": 0.6551,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.12057159096002579,
      "rewards/margins": 0.095227912068367,
      "rewards/rejected": -0.21579952538013458,
      "step": 120
    },
    {
      "epoch": 0.02372479240806643,
      "grad_norm": 1.8672019243240356,
      "learning_rate": 6.826666666666668e-05,
      "logits/chosen": -0.9109039306640625,
      "logits/rejected": -0.8842675089836121,
      "logps/chosen": -160.33094787597656,
      "logps/rejected": -143.3021697998047,
      "loss": 0.6441,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.027177993208169937,
      "rewards/margins": 0.14097367227077484,
      "rewards/rejected": -0.16815167665481567,
      "step": 130
    },
    {
      "epoch": 0.025549776439456155,
      "grad_norm": 3.1275253295898438,
      "learning_rate": 7.360000000000001e-05,
      "logits/chosen": -0.9303447604179382,
      "logits/rejected": -0.886880099773407,
      "logps/chosen": -152.20382690429688,
      "logps/rejected": -128.73504638671875,
      "loss": 0.6521,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.02036627009510994,
      "rewards/margins": 0.14128980040550232,
      "rewards/rejected": -0.16165606677532196,
      "step": 140
    },
    {
      "epoch": 0.02737476047084588,
      "grad_norm": 3.81528902053833,
      "learning_rate": 7.893333333333335e-05,
      "logits/chosen": -0.9508352279663086,
      "logits/rejected": -0.9380999803543091,
      "logps/chosen": -142.3009490966797,
      "logps/rejected": -133.51437377929688,
      "loss": 0.6383,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.19416742026805878,
      "rewards/margins": 0.20391210913658142,
      "rewards/rejected": -0.3980795443058014,
      "step": 150
    },
    {
      "epoch": 0.029199744502235607,
      "grad_norm": 3.7009241580963135,
      "learning_rate": 7.996070485663413e-05,
      "logits/chosen": -0.9645269513130188,
      "logits/rejected": -0.9294408559799194,
      "logps/chosen": -150.7361602783203,
      "logps/rejected": -124.0806884765625,
      "loss": 0.561,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.0718490332365036,
      "rewards/margins": 0.4067119061946869,
      "rewards/rejected": -0.33486291766166687,
      "step": 160
    },
    {
      "epoch": 0.03102472853362533,
      "grad_norm": 4.9690728187561035,
      "learning_rate": 7.991158592742679e-05,
      "logits/chosen": -0.8730254173278809,
      "logits/rejected": -0.8372138738632202,
      "logps/chosen": -157.50857543945312,
      "logps/rejected": -135.46530151367188,
      "loss": 0.6348,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.5744383335113525,
      "rewards/margins": 0.33327579498291016,
      "rewards/rejected": -0.9077141880989075,
      "step": 170
    },
    {
      "epoch": 0.03284971256501506,
      "grad_norm": 11.047629356384277,
      "learning_rate": 7.986246699821945e-05,
      "logits/chosen": -0.9482674598693848,
      "logits/rejected": -0.9161989092826843,
      "logps/chosen": -145.7418670654297,
      "logps/rejected": -142.94412231445312,
      "loss": 0.5839,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.450265884399414,
      "rewards/margins": 0.4122084677219391,
      "rewards/rejected": -1.8624740839004517,
      "step": 180
    },
    {
      "epoch": 0.034674696596404785,
      "grad_norm": 4.749417304992676,
      "learning_rate": 7.98133480690121e-05,
      "logits/chosen": -0.9429707527160645,
      "logits/rejected": -0.9177879095077515,
      "logps/chosen": -156.83819580078125,
      "logps/rejected": -146.45071411132812,
      "loss": 0.6412,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.479048728942871,
      "rewards/margins": 0.3146219253540039,
      "rewards/rejected": -2.793670654296875,
      "step": 190
    },
    {
      "epoch": 0.036499680627794504,
      "grad_norm": 6.721950054168701,
      "learning_rate": 7.976422913980476e-05,
      "logits/chosen": -0.9602111577987671,
      "logits/rejected": -0.9559811353683472,
      "logps/chosen": -155.7548370361328,
      "logps/rejected": -139.8035125732422,
      "loss": 0.662,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -1.6693589687347412,
      "rewards/margins": 0.23085251450538635,
      "rewards/rejected": -1.9002113342285156,
      "step": 200
    },
    {
      "epoch": 0.03832466465918423,
      "grad_norm": 6.0640153884887695,
      "learning_rate": 7.971511021059742e-05,
      "logits/chosen": -0.9399754405021667,
      "logits/rejected": -0.9203237295150757,
      "logps/chosen": -163.2810516357422,
      "logps/rejected": -152.39915466308594,
      "loss": 0.6772,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -1.906394600868225,
      "rewards/margins": 0.23889108002185822,
      "rewards/rejected": -2.1452853679656982,
      "step": 210
    },
    {
      "epoch": 0.040149648690573955,
      "grad_norm": 4.692460060119629,
      "learning_rate": 7.966599128139007e-05,
      "logits/chosen": -0.9615851640701294,
      "logits/rejected": -0.9186593294143677,
      "logps/chosen": -161.39393615722656,
      "logps/rejected": -141.03140258789062,
      "loss": 0.6239,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -1.3774330615997314,
      "rewards/margins": 0.3105335235595703,
      "rewards/rejected": -1.6879663467407227,
      "step": 220
    },
    {
      "epoch": 0.04197463272196368,
      "grad_norm": 5.455709934234619,
      "learning_rate": 7.961687235218272e-05,
      "logits/chosen": -0.8600401878356934,
      "logits/rejected": -0.8411459922790527,
      "logps/chosen": -160.39707946777344,
      "logps/rejected": -146.35086059570312,
      "loss": 0.7293,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -1.144080638885498,
      "rewards/margins": 0.1360943615436554,
      "rewards/rejected": -1.2801750898361206,
      "step": 230
    },
    {
      "epoch": 0.04379961675335341,
      "grad_norm": 2.436851978302002,
      "learning_rate": 7.95677534229754e-05,
      "logits/chosen": -0.9243465662002563,
      "logits/rejected": -0.8860034942626953,
      "logps/chosen": -146.3559112548828,
      "logps/rejected": -132.61318969726562,
      "loss": 0.6202,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.6327334642410278,
      "rewards/margins": 0.33967483043670654,
      "rewards/rejected": -0.9724082946777344,
      "step": 240
    },
    {
      "epoch": 0.04562460078474313,
      "grad_norm": 4.467226505279541,
      "learning_rate": 7.951863449376804e-05,
      "logits/chosen": -0.9489458203315735,
      "logits/rejected": -0.8994137644767761,
      "logps/chosen": -144.4513702392578,
      "logps/rejected": -133.4075164794922,
      "loss": 0.6355,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.24887362122535706,
      "rewards/margins": 0.32089394330978394,
      "rewards/rejected": -0.5697675943374634,
      "step": 250
    },
    {
      "epoch": 0.04744958481613286,
      "grad_norm": 6.278979301452637,
      "learning_rate": 7.94695155645607e-05,
      "logits/chosen": -0.9889273643493652,
      "logits/rejected": -0.956682026386261,
      "logps/chosen": -160.2544403076172,
      "logps/rejected": -146.70950317382812,
      "loss": 0.6517,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.47003546357154846,
      "rewards/margins": 0.26790276169776917,
      "rewards/rejected": -0.7379382848739624,
      "step": 260
    },
    {
      "epoch": 0.049274568847522585,
      "grad_norm": 4.664032936096191,
      "learning_rate": 7.942039663535335e-05,
      "logits/chosen": -0.9978491067886353,
      "logits/rejected": -0.9621903300285339,
      "logps/chosen": -173.31532287597656,
      "logps/rejected": -145.121337890625,
      "loss": 0.6733,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.6750885248184204,
      "rewards/margins": 0.15897607803344727,
      "rewards/rejected": -0.8340646624565125,
      "step": 270
    },
    {
      "epoch": 0.05109955287891231,
      "grad_norm": 4.681807041168213,
      "learning_rate": 7.937127770614601e-05,
      "logits/chosen": -0.9774074554443359,
      "logits/rejected": -0.9563146829605103,
      "logps/chosen": -145.18734741210938,
      "logps/rejected": -126.7834243774414,
      "loss": 0.6098,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.642044186592102,
      "rewards/margins": 0.3091551661491394,
      "rewards/rejected": -0.9511993527412415,
      "step": 280
    },
    {
      "epoch": 0.052924536910302036,
      "grad_norm": 5.485991954803467,
      "learning_rate": 7.932215877693867e-05,
      "logits/chosen": -0.9808764457702637,
      "logits/rejected": -0.9352054595947266,
      "logps/chosen": -159.77928161621094,
      "logps/rejected": -140.60572814941406,
      "loss": 0.5624,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.431133896112442,
      "rewards/margins": 0.4758010506629944,
      "rewards/rejected": -0.906934916973114,
      "step": 290
    },
    {
      "epoch": 0.05474952094169176,
      "grad_norm": 3.9867563247680664,
      "learning_rate": 7.927303984773133e-05,
      "logits/chosen": -0.9602251052856445,
      "logits/rejected": -0.932837963104248,
      "logps/chosen": -157.75570678710938,
      "logps/rejected": -148.04403686523438,
      "loss": 0.5939,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.576103150844574,
      "rewards/margins": 0.4556453227996826,
      "rewards/rejected": -1.0317485332489014,
      "step": 300
    },
    {
      "epoch": 0.05657450497308149,
      "grad_norm": 3.4539597034454346,
      "learning_rate": 7.922392091852399e-05,
      "logits/chosen": -0.9796693921089172,
      "logits/rejected": -0.9325091242790222,
      "logps/chosen": -170.61033630371094,
      "logps/rejected": -146.75762939453125,
      "loss": 0.6172,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.36515918374061584,
      "rewards/margins": 0.4512189030647278,
      "rewards/rejected": -0.816378116607666,
      "step": 310
    },
    {
      "epoch": 0.058399489004471214,
      "grad_norm": 3.9554951190948486,
      "learning_rate": 7.917480198931664e-05,
      "logits/chosen": -0.8925948143005371,
      "logits/rejected": -0.8593066334724426,
      "logps/chosen": -148.45936584472656,
      "logps/rejected": -132.9539794921875,
      "loss": 0.6686,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.8896192312240601,
      "rewards/margins": 0.27045565843582153,
      "rewards/rejected": -1.1600747108459473,
      "step": 320
    },
    {
      "epoch": 0.06022447303586093,
      "grad_norm": 3.1665894985198975,
      "learning_rate": 7.913059495303003e-05,
      "logits/chosen": -0.8992528915405273,
      "logits/rejected": -0.8392236828804016,
      "logps/chosen": -174.9293670654297,
      "logps/rejected": -150.96542358398438,
      "loss": 0.5398,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1545928716659546,
      "rewards/margins": 0.5927711725234985,
      "rewards/rejected": -1.747363805770874,
      "step": 330
    },
    {
      "epoch": 0.06204945706725066,
      "grad_norm": 8.182446479797363,
      "learning_rate": 7.908147602382269e-05,
      "logits/chosen": -0.9033522605895996,
      "logits/rejected": -0.8731626272201538,
      "logps/chosen": -157.84158325195312,
      "logps/rejected": -147.70217895507812,
      "loss": 0.5728,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.9314433932304382,
      "rewards/margins": 0.6005207300186157,
      "rewards/rejected": -1.5319641828536987,
      "step": 340
    },
    {
      "epoch": 0.06387444109864039,
      "grad_norm": 3.6002628803253174,
      "learning_rate": 7.903235709461534e-05,
      "logits/chosen": -0.9406194686889648,
      "logits/rejected": -0.9119185209274292,
      "logps/chosen": -155.5684051513672,
      "logps/rejected": -142.48391723632812,
      "loss": 0.6184,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.6284950375556946,
      "rewards/margins": 0.5423872470855713,
      "rewards/rejected": -1.170882225036621,
      "step": 350
    },
    {
      "epoch": 0.06569942513003012,
      "grad_norm": 4.237017631530762,
      "learning_rate": 7.898323816540801e-05,
      "logits/chosen": -0.923642635345459,
      "logits/rejected": -0.8971103429794312,
      "logps/chosen": -153.8644561767578,
      "logps/rejected": -148.774169921875,
      "loss": 0.6344,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.4897211194038391,
      "rewards/margins": 0.47076815366744995,
      "rewards/rejected": -0.9604892730712891,
      "step": 360
    },
    {
      "epoch": 0.06752440916141984,
      "grad_norm": 4.616262912750244,
      "learning_rate": 7.893411923620067e-05,
      "logits/chosen": -0.9686688184738159,
      "logits/rejected": -0.9076355695724487,
      "logps/chosen": -145.92233276367188,
      "logps/rejected": -127.07791900634766,
      "loss": 0.6252,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.3995591700077057,
      "rewards/margins": 0.40849629044532776,
      "rewards/rejected": -0.808055579662323,
      "step": 370
    },
    {
      "epoch": 0.06934939319280957,
      "grad_norm": 3.1655044555664062,
      "learning_rate": 7.888500030699331e-05,
      "logits/chosen": -0.9576835632324219,
      "logits/rejected": -0.9026141166687012,
      "logps/chosen": -152.0081024169922,
      "logps/rejected": -127.87809753417969,
      "loss": 0.5983,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.30014297366142273,
      "rewards/margins": 0.41703957319259644,
      "rewards/rejected": -0.7171826362609863,
      "step": 380
    },
    {
      "epoch": 0.0711743772241993,
      "grad_norm": 3.706674814224243,
      "learning_rate": 7.883588137778597e-05,
      "logits/chosen": -0.9211624264717102,
      "logits/rejected": -0.8926073908805847,
      "logps/chosen": -159.69357299804688,
      "logps/rejected": -141.51856994628906,
      "loss": 0.6278,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.18703597784042358,
      "rewards/margins": 0.37311118841171265,
      "rewards/rejected": -0.5601471662521362,
      "step": 390
    },
    {
      "epoch": 0.07299936125558901,
      "grad_norm": 2.4989354610443115,
      "learning_rate": 7.878676244857863e-05,
      "logits/chosen": -0.967938244342804,
      "logits/rejected": -0.9143651723861694,
      "logps/chosen": -147.8990020751953,
      "logps/rejected": -120.01835632324219,
      "loss": 0.6196,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.08857376873493195,
      "rewards/margins": 0.39379334449768066,
      "rewards/rejected": -0.4823671281337738,
      "step": 400
    },
    {
      "epoch": 0.07482434528697873,
      "grad_norm": 3.149991035461426,
      "learning_rate": 7.873764351937128e-05,
      "logits/chosen": -0.9665462374687195,
      "logits/rejected": -0.9381502866744995,
      "logps/chosen": -155.74148559570312,
      "logps/rejected": -144.4596405029297,
      "loss": 0.592,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.4155682623386383,
      "rewards/margins": 0.46264949440956116,
      "rewards/rejected": -0.8782178163528442,
      "step": 410
    },
    {
      "epoch": 0.07664932931836846,
      "grad_norm": 3.9101994037628174,
      "learning_rate": 7.868852459016394e-05,
      "logits/chosen": -0.9217314720153809,
      "logits/rejected": -0.8976801037788391,
      "logps/chosen": -150.9813995361328,
      "logps/rejected": -138.0497589111328,
      "loss": 0.6335,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.8179938197135925,
      "rewards/margins": 0.3811967968940735,
      "rewards/rejected": -1.1991908550262451,
      "step": 420
    },
    {
      "epoch": 0.07847431334975818,
      "grad_norm": 3.973724126815796,
      "learning_rate": 7.86394056609566e-05,
      "logits/chosen": -0.9095250368118286,
      "logits/rejected": -0.886221706867218,
      "logps/chosen": -150.0350799560547,
      "logps/rejected": -137.5963592529297,
      "loss": 0.6152,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.7465001344680786,
      "rewards/margins": 0.39183300733566284,
      "rewards/rejected": -1.1383330821990967,
      "step": 430
    },
    {
      "epoch": 0.08029929738114791,
      "grad_norm": 3.666827917098999,
      "learning_rate": 7.859028673174926e-05,
      "logits/chosen": -0.9110067486763,
      "logits/rejected": -0.8818814158439636,
      "logps/chosen": -151.01687622070312,
      "logps/rejected": -143.48324584960938,
      "loss": 0.564,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.5824309587478638,
      "rewards/margins": 0.5404235124588013,
      "rewards/rejected": -1.122854471206665,
      "step": 440
    },
    {
      "epoch": 0.08212428141253764,
      "grad_norm": 3.4785900115966797,
      "learning_rate": 7.854116780254191e-05,
      "logits/chosen": -0.9113259315490723,
      "logits/rejected": -0.9003841280937195,
      "logps/chosen": -151.18711853027344,
      "logps/rejected": -142.84640502929688,
      "loss": 0.6374,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.6621488332748413,
      "rewards/margins": 0.4333069920539856,
      "rewards/rejected": -1.0954558849334717,
      "step": 450
    },
    {
      "epoch": 0.08394926544392736,
      "grad_norm": 5.092621803283691,
      "learning_rate": 7.849204887333457e-05,
      "logits/chosen": -0.943567156791687,
      "logits/rejected": -0.8918803334236145,
      "logps/chosen": -157.77268981933594,
      "logps/rejected": -134.39810180664062,
      "loss": 0.5643,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6366904973983765,
      "rewards/margins": 0.5155426859855652,
      "rewards/rejected": -1.1522332429885864,
      "step": 460
    },
    {
      "epoch": 0.08577424947531709,
      "grad_norm": 6.088417053222656,
      "learning_rate": 7.844292994412723e-05,
      "logits/chosen": -0.9338051676750183,
      "logits/rejected": -0.9107629060745239,
      "logps/chosen": -142.694580078125,
      "logps/rejected": -138.36215209960938,
      "loss": 0.557,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.15009343624115,
      "rewards/margins": 0.6764439344406128,
      "rewards/rejected": -1.8265373706817627,
      "step": 470
    },
    {
      "epoch": 0.08759923350670681,
      "grad_norm": 4.704120635986328,
      "learning_rate": 7.839381101491989e-05,
      "logits/chosen": -0.9277065992355347,
      "logits/rejected": -0.9259611964225769,
      "logps/chosen": -154.5487060546875,
      "logps/rejected": -152.00186157226562,
      "loss": 0.729,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -1.6136928796768188,
      "rewards/margins": 0.2842175364494324,
      "rewards/rejected": -1.897910475730896,
      "step": 480
    },
    {
      "epoch": 0.08942421753809654,
      "grad_norm": 3.271743059158325,
      "learning_rate": 7.834469208571253e-05,
      "logits/chosen": -0.9776847958564758,
      "logits/rejected": -0.9236580729484558,
      "logps/chosen": -169.60118103027344,
      "logps/rejected": -139.52320861816406,
      "loss": 0.4972,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.025445580482483,
      "rewards/margins": 0.8168366551399231,
      "rewards/rejected": -1.8422822952270508,
      "step": 490
    },
    {
      "epoch": 0.09124920156948627,
      "grad_norm": 4.035861968994141,
      "learning_rate": 7.829557315650519e-05,
      "logits/chosen": -1.0323388576507568,
      "logits/rejected": -1.0214576721191406,
      "logps/chosen": -149.90672302246094,
      "logps/rejected": -146.2696075439453,
      "loss": 0.6193,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5016835331916809,
      "rewards/margins": 0.4878876805305481,
      "rewards/rejected": -0.9895712733268738,
      "step": 500
    },
    {
      "epoch": 0.09307418560087599,
      "grad_norm": 4.6830034255981445,
      "learning_rate": 7.824645422729786e-05,
      "logits/chosen": -1.009926438331604,
      "logits/rejected": -0.9975157976150513,
      "logps/chosen": -159.09036254882812,
      "logps/rejected": -160.45262145996094,
      "loss": 0.5846,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.3863198161125183,
      "rewards/margins": 0.5705528855323792,
      "rewards/rejected": -0.9568729400634766,
      "step": 510
    },
    {
      "epoch": 0.09489916963226572,
      "grad_norm": 4.898622512817383,
      "learning_rate": 7.81973352980905e-05,
      "logits/chosen": -1.0550479888916016,
      "logits/rejected": -1.0156619548797607,
      "logps/chosen": -151.3610382080078,
      "logps/rejected": -134.77490234375,
      "loss": 0.4782,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.17787447571754456,
      "rewards/margins": 0.7841469049453735,
      "rewards/rejected": -0.9620213508605957,
      "step": 520
    },
    {
      "epoch": 0.09672415366365544,
      "grad_norm": 5.30891752243042,
      "learning_rate": 7.814821636888316e-05,
      "logits/chosen": -1.030312418937683,
      "logits/rejected": -0.9917749166488647,
      "logps/chosen": -146.08201599121094,
      "logps/rejected": -121.4139404296875,
      "loss": 0.5834,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.09923435747623444,
      "rewards/margins": 0.6255996823310852,
      "rewards/rejected": -0.5263653993606567,
      "step": 530
    },
    {
      "epoch": 0.09854913769504517,
      "grad_norm": 5.38960599899292,
      "learning_rate": 7.809909743967582e-05,
      "logits/chosen": -1.0400527715682983,
      "logits/rejected": -1.0087685585021973,
      "logps/chosen": -144.73341369628906,
      "logps/rejected": -138.4625244140625,
      "loss": 0.6427,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.28130730986595154,
      "rewards/margins": 0.44801443815231323,
      "rewards/rejected": -0.7293218374252319,
      "step": 540
    },
    {
      "epoch": 0.1003741217264349,
      "grad_norm": 3.787102222442627,
      "learning_rate": 7.804997851046848e-05,
      "logits/chosen": -1.1105432510375977,
      "logits/rejected": -1.0653165578842163,
      "logps/chosen": -165.99588012695312,
      "logps/rejected": -146.96231079101562,
      "loss": 0.5412,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0490465871989727,
      "rewards/margins": 0.6196019649505615,
      "rewards/rejected": -0.6686484813690186,
      "step": 550
    },
    {
      "epoch": 0.10219910575782462,
      "grad_norm": 4.137238502502441,
      "learning_rate": 7.800085958126114e-05,
      "logits/chosen": -1.1300619840621948,
      "logits/rejected": -1.107203722000122,
      "logps/chosen": -147.0370330810547,
      "logps/rejected": -138.30442810058594,
      "loss": 0.6354,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.3050749599933624,
      "rewards/margins": 0.4102419912815094,
      "rewards/rejected": -0.715316891670227,
      "step": 560
    },
    {
      "epoch": 0.10402408978921435,
      "grad_norm": 4.402844429016113,
      "learning_rate": 7.79517406520538e-05,
      "logits/chosen": -1.1734776496887207,
      "logits/rejected": -1.1768466234207153,
      "logps/chosen": -136.56687927246094,
      "logps/rejected": -138.19589233398438,
      "loss": 0.6039,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.34041470289230347,
      "rewards/margins": 0.37634626030921936,
      "rewards/rejected": -0.7167608737945557,
      "step": 570
    },
    {
      "epoch": 0.10584907382060407,
      "grad_norm": 3.3070027828216553,
      "learning_rate": 7.790262172284645e-05,
      "logits/chosen": -1.2008394002914429,
      "logits/rejected": -1.1942052841186523,
      "logps/chosen": -152.8354034423828,
      "logps/rejected": -143.63604736328125,
      "loss": 0.5981,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.4182364344596863,
      "rewards/margins": 0.4744836688041687,
      "rewards/rejected": -0.892720103263855,
      "step": 580
    },
    {
      "epoch": 0.1076740578519938,
      "grad_norm": 7.230775356292725,
      "learning_rate": 7.785350279363911e-05,
      "logits/chosen": -1.2812963724136353,
      "logits/rejected": -1.238667607307434,
      "logps/chosen": -160.49058532714844,
      "logps/rejected": -119.9569091796875,
      "loss": 0.7284,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -0.9780982732772827,
      "rewards/margins": 0.2093656063079834,
      "rewards/rejected": -1.1874639987945557,
      "step": 590
    },
    {
      "epoch": 0.10949904188338352,
      "grad_norm": 5.122862339019775,
      "learning_rate": 7.780438386443177e-05,
      "logits/chosen": -1.237756371498108,
      "logits/rejected": -1.227932333946228,
      "logps/chosen": -165.52206420898438,
      "logps/rejected": -144.20838928222656,
      "loss": 0.6013,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.8217943906784058,
      "rewards/margins": 0.40154948830604553,
      "rewards/rejected": -1.2233439683914185,
      "step": 600
    },
    {
      "epoch": 0.11132402591477325,
      "grad_norm": 2.3439197540283203,
      "learning_rate": 7.775526493522441e-05,
      "logits/chosen": -1.1677284240722656,
      "logits/rejected": -1.1529772281646729,
      "logps/chosen": -154.13522338867188,
      "logps/rejected": -143.367431640625,
      "loss": 0.6123,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.43192631006240845,
      "rewards/margins": 0.4067762792110443,
      "rewards/rejected": -0.8387025594711304,
      "step": 610
    },
    {
      "epoch": 0.11314900994616298,
      "grad_norm": 3.763411521911621,
      "learning_rate": 7.770614600601708e-05,
      "logits/chosen": -1.0966906547546387,
      "logits/rejected": -1.0625059604644775,
      "logps/chosen": -133.19686889648438,
      "logps/rejected": -127.58866119384766,
      "loss": 0.587,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.14168019592761993,
      "rewards/margins": 0.4520566463470459,
      "rewards/rejected": -0.31037643551826477,
      "step": 620
    },
    {
      "epoch": 0.1149739939775527,
      "grad_norm": 3.7449839115142822,
      "learning_rate": 7.765702707680973e-05,
      "logits/chosen": -1.0491154193878174,
      "logits/rejected": -1.0046675205230713,
      "logps/chosen": -141.90069580078125,
      "logps/rejected": -117.39278411865234,
      "loss": 0.5817,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.5840998888015747,
      "rewards/margins": 0.48023223876953125,
      "rewards/rejected": 0.10386762768030167,
      "step": 630
    },
    {
      "epoch": 0.11679897800894243,
      "grad_norm": 3.3057005405426025,
      "learning_rate": 7.760790814760238e-05,
      "logits/chosen": -1.0154939889907837,
      "logits/rejected": -0.9487791061401367,
      "logps/chosen": -156.28639221191406,
      "logps/rejected": -129.51553344726562,
      "loss": 0.5454,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.48254209756851196,
      "rewards/margins": 0.6480913162231445,
      "rewards/rejected": -0.16554929316043854,
      "step": 640
    },
    {
      "epoch": 0.11862396204033215,
      "grad_norm": 4.3121137619018555,
      "learning_rate": 7.755878921839506e-05,
      "logits/chosen": -1.0217506885528564,
      "logits/rejected": -0.9556562304496765,
      "logps/chosen": -165.9781494140625,
      "logps/rejected": -138.66439819335938,
      "loss": 0.5369,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.2644176483154297,
      "rewards/margins": 0.7845640182495117,
      "rewards/rejected": -0.5201462507247925,
      "step": 650
    },
    {
      "epoch": 0.12044894607172187,
      "grad_norm": 2.8720903396606445,
      "learning_rate": 7.75096702891877e-05,
      "logits/chosen": -1.0254985094070435,
      "logits/rejected": -0.9340724945068359,
      "logps/chosen": -164.7762908935547,
      "logps/rejected": -130.68092346191406,
      "loss": 0.5444,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.08344878256320953,
      "rewards/margins": 0.7596184015274048,
      "rewards/rejected": -0.8430671691894531,
      "step": 660
    },
    {
      "epoch": 0.12227393010311159,
      "grad_norm": 4.740869045257568,
      "learning_rate": 7.746055135998036e-05,
      "logits/chosen": -1.035888671875,
      "logits/rejected": -0.9861686825752258,
      "logps/chosen": -154.1751708984375,
      "logps/rejected": -137.58212280273438,
      "loss": 0.643,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.10698948800563812,
      "rewards/margins": 0.5934867858886719,
      "rewards/rejected": -0.48649734258651733,
      "step": 670
    },
    {
      "epoch": 0.12409891413450132,
      "grad_norm": 4.048191070556641,
      "learning_rate": 7.741143243077301e-05,
      "logits/chosen": -0.9446334838867188,
      "logits/rejected": -0.898388683795929,
      "logps/chosen": -136.37741088867188,
      "logps/rejected": -123.44758605957031,
      "loss": 0.6227,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.2613537907600403,
      "rewards/margins": 0.6212270259857178,
      "rewards/rejected": -0.8825807571411133,
      "step": 680
    },
    {
      "epoch": 0.12592389816589106,
      "grad_norm": 4.936943531036377,
      "learning_rate": 7.736231350156567e-05,
      "logits/chosen": -1.0014947652816772,
      "logits/rejected": -0.9437594413757324,
      "logps/chosen": -154.0449676513672,
      "logps/rejected": -144.22445678710938,
      "loss": 0.5624,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.2994600832462311,
      "rewards/margins": 0.7151491045951843,
      "rewards/rejected": -0.41568899154663086,
      "step": 690
    },
    {
      "epoch": 0.12774888219728078,
      "grad_norm": 3.8173325061798096,
      "learning_rate": 7.731319457235833e-05,
      "logits/chosen": -1.0306133031845093,
      "logits/rejected": -0.9557355642318726,
      "logps/chosen": -169.9527130126953,
      "logps/rejected": -135.92330932617188,
      "loss": 0.5255,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.08911280333995819,
      "rewards/margins": 0.7367759943008423,
      "rewards/rejected": -0.6476632356643677,
      "step": 700
    },
    {
      "epoch": 0.1295738662286705,
      "grad_norm": 4.36376428604126,
      "learning_rate": 7.726407564315099e-05,
      "logits/chosen": -0.9909496307373047,
      "logits/rejected": -0.9580304026603699,
      "logps/chosen": -144.9103240966797,
      "logps/rejected": -123.099609375,
      "loss": 0.6281,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.22294080257415771,
      "rewards/margins": 0.5581868886947632,
      "rewards/rejected": -0.7811276316642761,
      "step": 710
    },
    {
      "epoch": 0.13139885026006023,
      "grad_norm": 2.5173137187957764,
      "learning_rate": 7.721495671394363e-05,
      "logits/chosen": -1.0080645084381104,
      "logits/rejected": -0.9632972478866577,
      "logps/chosen": -153.1226806640625,
      "logps/rejected": -135.73411560058594,
      "loss": 0.5979,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.5783562064170837,
      "rewards/margins": 0.533190131187439,
      "rewards/rejected": 0.045166052877902985,
      "step": 720
    },
    {
      "epoch": 0.13322383429144996,
      "grad_norm": 4.278646469116211,
      "learning_rate": 7.71658377847363e-05,
      "logits/chosen": -1.0286940336227417,
      "logits/rejected": -0.9830619692802429,
      "logps/chosen": -143.4391632080078,
      "logps/rejected": -128.4344940185547,
      "loss": 0.5967,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.4441434442996979,
      "rewards/margins": 0.5116699934005737,
      "rewards/rejected": -0.06752659380435944,
      "step": 730
    },
    {
      "epoch": 0.1350488183228397,
      "grad_norm": 3.986313581466675,
      "learning_rate": 7.711671885552896e-05,
      "logits/chosen": -1.0608577728271484,
      "logits/rejected": -1.0072686672210693,
      "logps/chosen": -136.3700714111328,
      "logps/rejected": -125.55525970458984,
      "loss": 0.5624,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.2386614978313446,
      "rewards/margins": 0.566186785697937,
      "rewards/rejected": -0.32752522826194763,
      "step": 740
    },
    {
      "epoch": 0.1368738023542294,
      "grad_norm": 5.106315612792969,
      "learning_rate": 7.70675999263216e-05,
      "logits/chosen": -1.0782978534698486,
      "logits/rejected": -1.0237789154052734,
      "logps/chosen": -143.31268310546875,
      "logps/rejected": -129.39935302734375,
      "loss": 0.483,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.07197501510381699,
      "rewards/margins": 0.9466096758842468,
      "rewards/rejected": -1.0185846090316772,
      "step": 750
    },
    {
      "epoch": 0.13869878638561914,
      "grad_norm": 3.618108034133911,
      "learning_rate": 7.701848099711428e-05,
      "logits/chosen": -1.0097590684890747,
      "logits/rejected": -0.937766432762146,
      "logps/chosen": -149.0207061767578,
      "logps/rejected": -133.55613708496094,
      "loss": 0.6196,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.2582938075065613,
      "rewards/margins": 0.6057348251342773,
      "rewards/rejected": -0.8640286326408386,
      "step": 760
    },
    {
      "epoch": 0.14052377041700886,
      "grad_norm": 2.958587646484375,
      "learning_rate": 7.696936206790692e-05,
      "logits/chosen": -1.019278645515442,
      "logits/rejected": -0.9559966325759888,
      "logps/chosen": -159.04617309570312,
      "logps/rejected": -124.07164001464844,
      "loss": 0.6039,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.14413967728614807,
      "rewards/margins": 0.6252979040145874,
      "rewards/rejected": -0.7694376111030579,
      "step": 770
    },
    {
      "epoch": 0.1423487544483986,
      "grad_norm": 7.1021223068237305,
      "learning_rate": 7.692024313869958e-05,
      "logits/chosen": -1.0156581401824951,
      "logits/rejected": -1.0360161066055298,
      "logps/chosen": -139.0221710205078,
      "logps/rejected": -150.73480224609375,
      "loss": 0.6801,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.08211933821439743,
      "rewards/margins": 0.4342641830444336,
      "rewards/rejected": -0.35214489698410034,
      "step": 780
    },
    {
      "epoch": 0.1441737384797883,
      "grad_norm": 2.4257700443267822,
      "learning_rate": 7.687112420949224e-05,
      "logits/chosen": -0.9819448590278625,
      "logits/rejected": -0.9611978530883789,
      "logps/chosen": -131.08665466308594,
      "logps/rejected": -119.92985534667969,
      "loss": 0.5686,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.7294297218322754,
      "rewards/margins": 0.5046456456184387,
      "rewards/rejected": 0.22478406131267548,
      "step": 790
    },
    {
      "epoch": 0.14599872251117801,
      "grad_norm": 4.235898971557617,
      "learning_rate": 7.68220052802849e-05,
      "logits/chosen": -0.997148334980011,
      "logits/rejected": -0.9467988014221191,
      "logps/chosen": -138.4717559814453,
      "logps/rejected": -120.89327239990234,
      "loss": 0.5746,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.6782376170158386,
      "rewards/margins": 0.5152837038040161,
      "rewards/rejected": 0.16295388340950012,
      "step": 800
    },
    {
      "epoch": 0.14782370654256774,
      "grad_norm": 3.248852252960205,
      "learning_rate": 7.677288635107755e-05,
      "logits/chosen": -1.0631217956542969,
      "logits/rejected": -1.0203206539154053,
      "logps/chosen": -142.78497314453125,
      "logps/rejected": -128.95913696289062,
      "loss": 0.5499,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.31586912274360657,
      "rewards/margins": 0.6322425007820129,
      "rewards/rejected": -0.3163732886314392,
      "step": 810
    },
    {
      "epoch": 0.14964869057395747,
      "grad_norm": 3.857518196105957,
      "learning_rate": 7.672376742187021e-05,
      "logits/chosen": -1.0765857696533203,
      "logits/rejected": -1.0248544216156006,
      "logps/chosen": -148.04641723632812,
      "logps/rejected": -133.8470916748047,
      "loss": 0.5935,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.0934329703450203,
      "rewards/margins": 0.5818504095077515,
      "rewards/rejected": -0.48841744661331177,
      "step": 820
    },
    {
      "epoch": 0.1514736746053472,
      "grad_norm": 4.679764270782471,
      "learning_rate": 7.667464849266287e-05,
      "logits/chosen": -1.0489296913146973,
      "logits/rejected": -1.0091230869293213,
      "logps/chosen": -150.26080322265625,
      "logps/rejected": -138.9738006591797,
      "loss": 0.6783,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.13148233294487,
      "rewards/margins": 0.37570706009864807,
      "rewards/rejected": -0.5071893930435181,
      "step": 830
    },
    {
      "epoch": 0.15329865863673692,
      "grad_norm": 3.270447254180908,
      "learning_rate": 7.662552956345552e-05,
      "logits/chosen": -1.0241872072219849,
      "logits/rejected": -0.9724764823913574,
      "logps/chosen": -145.14805603027344,
      "logps/rejected": -132.62527465820312,
      "loss": 0.4992,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 0.12632694840431213,
      "rewards/margins": 0.8065335154533386,
      "rewards/rejected": -0.6802066564559937,
      "step": 840
    },
    {
      "epoch": 0.15512364266812664,
      "grad_norm": 2.466923952102661,
      "learning_rate": 7.657641063424818e-05,
      "logits/chosen": -0.9416574239730835,
      "logits/rejected": -0.924629807472229,
      "logps/chosen": -141.71852111816406,
      "logps/rejected": -132.59329223632812,
      "loss": 0.5028,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.07744839042425156,
      "rewards/margins": 0.9214560389518738,
      "rewards/rejected": -0.8440076112747192,
      "step": 850
    },
    {
      "epoch": 0.15694862669951637,
      "grad_norm": 3.3668878078460693,
      "learning_rate": 7.652729170504084e-05,
      "logits/chosen": -0.9717941284179688,
      "logits/rejected": -0.939812183380127,
      "logps/chosen": -156.7182159423828,
      "logps/rejected": -144.52175903320312,
      "loss": 0.5732,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.07063144445419312,
      "rewards/margins": 0.715458869934082,
      "rewards/rejected": -0.7860901951789856,
      "step": 860
    },
    {
      "epoch": 0.1587736107309061,
      "grad_norm": 3.7364847660064697,
      "learning_rate": 7.64781727758335e-05,
      "logits/chosen": -1.0625709295272827,
      "logits/rejected": -1.000551462173462,
      "logps/chosen": -160.42587280273438,
      "logps/rejected": -144.43630981445312,
      "loss": 0.5455,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 0.1473122239112854,
      "rewards/margins": 0.9490699768066406,
      "rewards/rejected": -0.8017576932907104,
      "step": 870
    },
    {
      "epoch": 0.16059859476229582,
      "grad_norm": 4.944913387298584,
      "learning_rate": 7.642905384662616e-05,
      "logits/chosen": -1.1215450763702393,
      "logits/rejected": -1.077493667602539,
      "logps/chosen": -157.58624267578125,
      "logps/rejected": -154.05068969726562,
      "loss": 0.5393,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.2355790138244629,
      "rewards/margins": 0.7244505882263184,
      "rewards/rejected": -0.4888715147972107,
      "step": 880
    },
    {
      "epoch": 0.16242357879368555,
      "grad_norm": 4.780206680297852,
      "learning_rate": 7.63799349174188e-05,
      "logits/chosen": -1.0291917324066162,
      "logits/rejected": -0.9664598703384399,
      "logps/chosen": -166.57156372070312,
      "logps/rejected": -139.31588745117188,
      "loss": 0.6112,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.24905402958393097,
      "rewards/margins": 0.5576803088188171,
      "rewards/rejected": -0.30862629413604736,
      "step": 890
    },
    {
      "epoch": 0.16424856282507527,
      "grad_norm": 6.000335216522217,
      "learning_rate": 7.633081598821146e-05,
      "logits/chosen": -1.0373876094818115,
      "logits/rejected": -1.024753451347351,
      "logps/chosen": -132.31411743164062,
      "logps/rejected": -134.3974151611328,
      "loss": 0.6196,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.2960633635520935,
      "rewards/margins": 0.4672321677207947,
      "rewards/rejected": -0.17116887867450714,
      "step": 900
    },
    {
      "epoch": 0.166073546856465,
      "grad_norm": 4.743982791900635,
      "learning_rate": 7.628169705900413e-05,
      "logits/chosen": -0.982613742351532,
      "logits/rejected": -0.9486902356147766,
      "logps/chosen": -141.11041259765625,
      "logps/rejected": -137.03646850585938,
      "loss": 0.5889,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.23566775023937225,
      "rewards/margins": 0.5440528392791748,
      "rewards/rejected": -0.30838513374328613,
      "step": 910
    },
    {
      "epoch": 0.16789853088785472,
      "grad_norm": 3.33351469039917,
      "learning_rate": 7.623257812979677e-05,
      "logits/chosen": -0.9815008044242859,
      "logits/rejected": -0.9472193717956543,
      "logps/chosen": -146.31317138671875,
      "logps/rejected": -140.4872589111328,
      "loss": 0.5234,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.14923259615898132,
      "rewards/margins": 0.8585931658744812,
      "rewards/rejected": -0.7093605995178223,
      "step": 920
    },
    {
      "epoch": 0.16972351491924445,
      "grad_norm": 5.690113067626953,
      "learning_rate": 7.618345920058943e-05,
      "logits/chosen": -0.9820276498794556,
      "logits/rejected": -0.908595085144043,
      "logps/chosen": -156.4844207763672,
      "logps/rejected": -143.45921325683594,
      "loss": 0.6293,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.7935324311256409,
      "rewards/margins": 0.7138775587081909,
      "rewards/rejected": -1.5074098110198975,
      "step": 930
    },
    {
      "epoch": 0.17154849895063418,
      "grad_norm": 4.6912336349487305,
      "learning_rate": 7.613434027138209e-05,
      "logits/chosen": -0.9325078129768372,
      "logits/rejected": -0.8674777150154114,
      "logps/chosen": -156.2091522216797,
      "logps/rejected": -142.56430053710938,
      "loss": 0.588,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.5652412176132202,
      "rewards/margins": 0.5831462144851685,
      "rewards/rejected": -2.1483874320983887,
      "step": 940
    },
    {
      "epoch": 0.1733734829820239,
      "grad_norm": 7.336336135864258,
      "learning_rate": 7.608522134217475e-05,
      "logits/chosen": -0.9815851449966431,
      "logits/rejected": -0.8933397531509399,
      "logps/chosen": -158.35910034179688,
      "logps/rejected": -132.0614471435547,
      "loss": 0.5538,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8992081880569458,
      "rewards/margins": 0.6992679238319397,
      "rewards/rejected": -1.5984761714935303,
      "step": 950
    },
    {
      "epoch": 0.17519846701341363,
      "grad_norm": 2.6730682849884033,
      "learning_rate": 7.60361024129674e-05,
      "logits/chosen": -1.0154486894607544,
      "logits/rejected": -0.9447498321533203,
      "logps/chosen": -164.32936096191406,
      "logps/rejected": -146.20883178710938,
      "loss": 0.5478,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9470071792602539,
      "rewards/margins": 0.7727900743484497,
      "rewards/rejected": -1.7197973728179932,
      "step": 960
    },
    {
      "epoch": 0.17702345104480335,
      "grad_norm": 4.494349002838135,
      "learning_rate": 7.598698348376006e-05,
      "logits/chosen": -0.9414821863174438,
      "logits/rejected": -0.8910554647445679,
      "logps/chosen": -154.21627807617188,
      "logps/rejected": -151.15284729003906,
      "loss": 0.6031,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.080283284187317,
      "rewards/margins": 0.774793267250061,
      "rewards/rejected": -1.8550764322280884,
      "step": 970
    },
    {
      "epoch": 0.17884843507619308,
      "grad_norm": 4.573657512664795,
      "learning_rate": 7.593786455455272e-05,
      "logits/chosen": -0.959387481212616,
      "logits/rejected": -0.9199099540710449,
      "logps/chosen": -147.14141845703125,
      "logps/rejected": -143.7910919189453,
      "loss": 0.5948,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.9558793306350708,
      "rewards/margins": 0.5506053566932678,
      "rewards/rejected": -1.5064846277236938,
      "step": 980
    },
    {
      "epoch": 0.1806734191075828,
      "grad_norm": 4.3127031326293945,
      "learning_rate": 7.588874562534538e-05,
      "logits/chosen": -1.0158028602600098,
      "logits/rejected": -0.9342678785324097,
      "logps/chosen": -150.4903564453125,
      "logps/rejected": -129.8169708251953,
      "loss": 0.6456,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0355713367462158,
      "rewards/margins": 0.5210433006286621,
      "rewards/rejected": -1.5566147565841675,
      "step": 990
    },
    {
      "epoch": 0.18249840313897253,
      "grad_norm": 4.656304836273193,
      "learning_rate": 7.583962669613804e-05,
      "logits/chosen": -1.052912950515747,
      "logits/rejected": -0.9727853536605835,
      "logps/chosen": -166.73733520507812,
      "logps/rejected": -148.0121612548828,
      "loss": 0.4961,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.3413742184638977,
      "rewards/margins": 0.822385311126709,
      "rewards/rejected": -1.163759469985962,
      "step": 1000
    },
    {
      "epoch": 0.18432338717036226,
      "grad_norm": 3.8221616744995117,
      "learning_rate": 7.579050776693068e-05,
      "logits/chosen": -0.946986973285675,
      "logits/rejected": -0.8508330583572388,
      "logps/chosen": -156.68438720703125,
      "logps/rejected": -135.1925506591797,
      "loss": 0.5327,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.782468855381012,
      "rewards/margins": 0.8875924348831177,
      "rewards/rejected": -1.6700613498687744,
      "step": 1010
    },
    {
      "epoch": 0.18614837120175198,
      "grad_norm": 4.005212783813477,
      "learning_rate": 7.574138883772335e-05,
      "logits/chosen": -0.9321190118789673,
      "logits/rejected": -0.8910005688667297,
      "logps/chosen": -145.75787353515625,
      "logps/rejected": -146.3277587890625,
      "loss": 0.6779,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.6054643392562866,
      "rewards/margins": 0.529241681098938,
      "rewards/rejected": -1.134705901145935,
      "step": 1020
    },
    {
      "epoch": 0.1879733552331417,
      "grad_norm": 2.565230131149292,
      "learning_rate": 7.5692269908516e-05,
      "logits/chosen": -0.967184841632843,
      "logits/rejected": -0.9113150835037231,
      "logps/chosen": -141.81942749023438,
      "logps/rejected": -134.54165649414062,
      "loss": 0.4827,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.03951539844274521,
      "rewards/margins": 0.9154998660087585,
      "rewards/rejected": -0.9550153017044067,
      "step": 1030
    },
    {
      "epoch": 0.18979833926453143,
      "grad_norm": 2.9366016387939453,
      "learning_rate": 7.564315097930865e-05,
      "logits/chosen": -0.9862046241760254,
      "logits/rejected": -0.931632399559021,
      "logps/chosen": -157.88739013671875,
      "logps/rejected": -137.3368377685547,
      "loss": 0.6125,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.0781259685754776,
      "rewards/margins": 0.6459101438522339,
      "rewards/rejected": -0.7240360975265503,
      "step": 1040
    },
    {
      "epoch": 0.19162332329592116,
      "grad_norm": 2.8450381755828857,
      "learning_rate": 7.559403205010132e-05,
      "logits/chosen": -0.9846067428588867,
      "logits/rejected": -0.9253977537155151,
      "logps/chosen": -131.10494995117188,
      "logps/rejected": -126.1799545288086,
      "loss": 0.5303,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.18817856907844543,
      "rewards/margins": 0.7585352659225464,
      "rewards/rejected": -0.9467138051986694,
      "step": 1050
    },
    {
      "epoch": 0.1934483073273109,
      "grad_norm": 4.969995975494385,
      "learning_rate": 7.554491312089397e-05,
      "logits/chosen": -1.0089542865753174,
      "logits/rejected": -0.9758170247077942,
      "logps/chosen": -149.3008270263672,
      "logps/rejected": -145.06561279296875,
      "loss": 0.4775,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.35063862800598145,
      "rewards/margins": 0.970423698425293,
      "rewards/rejected": -1.321062445640564,
      "step": 1060
    },
    {
      "epoch": 0.1952732913587006,
      "grad_norm": 3.4896175861358643,
      "learning_rate": 7.549579419168663e-05,
      "logits/chosen": -1.0427186489105225,
      "logits/rejected": -0.9648454785346985,
      "logps/chosen": -182.15647888183594,
      "logps/rejected": -166.33026123046875,
      "loss": 0.5921,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.579369068145752,
      "rewards/margins": 0.9721757769584656,
      "rewards/rejected": -2.551544666290283,
      "step": 1070
    },
    {
      "epoch": 0.19709827539009034,
      "grad_norm": 4.625999927520752,
      "learning_rate": 7.544667526247928e-05,
      "logits/chosen": -1.108777403831482,
      "logits/rejected": -1.0620932579040527,
      "logps/chosen": -169.57162475585938,
      "logps/rejected": -175.612548828125,
      "loss": 0.5461,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.4378104209899902,
      "rewards/margins": 0.8717492818832397,
      "rewards/rejected": -3.3095593452453613,
      "step": 1080
    },
    {
      "epoch": 0.19892325942148006,
      "grad_norm": 4.009703159332275,
      "learning_rate": 7.539755633327194e-05,
      "logits/chosen": -0.9828560948371887,
      "logits/rejected": -0.895405650138855,
      "logps/chosen": -185.9591064453125,
      "logps/rejected": -164.42953491210938,
      "loss": 0.6834,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -2.570901870727539,
      "rewards/margins": 0.5353702306747437,
      "rewards/rejected": -3.1062722206115723,
      "step": 1090
    },
    {
      "epoch": 0.2007482434528698,
      "grad_norm": 3.92494797706604,
      "learning_rate": 7.53484374040646e-05,
      "logits/chosen": -0.9632099270820618,
      "logits/rejected": -0.9209324717521667,
      "logps/chosen": -155.98764038085938,
      "logps/rejected": -153.12533569335938,
      "loss": 0.5598,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9336055517196655,
      "rewards/margins": 0.8066486120223999,
      "rewards/rejected": -2.7402539253234863,
      "step": 1100
    },
    {
      "epoch": 0.20257322748425952,
      "grad_norm": 5.829402446746826,
      "learning_rate": 7.529931847485726e-05,
      "logits/chosen": -1.0010563135147095,
      "logits/rejected": -0.9984310865402222,
      "logps/chosen": -152.75057983398438,
      "logps/rejected": -164.3118438720703,
      "loss": 0.6091,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.2667778730392456,
      "rewards/margins": 0.6045188903808594,
      "rewards/rejected": -1.8712968826293945,
      "step": 1110
    },
    {
      "epoch": 0.20439821151564924,
      "grad_norm": 4.060335159301758,
      "learning_rate": 7.52501995456499e-05,
      "logits/chosen": -1.0391899347305298,
      "logits/rejected": -1.0057518482208252,
      "logps/chosen": -160.2957000732422,
      "logps/rejected": -144.9344940185547,
      "loss": 0.6912,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.288875699043274,
      "rewards/margins": 0.5883845686912537,
      "rewards/rejected": -1.8772602081298828,
      "step": 1120
    },
    {
      "epoch": 0.20622319554703897,
      "grad_norm": 2.7491142749786377,
      "learning_rate": 7.520108061644257e-05,
      "logits/chosen": -1.001349925994873,
      "logits/rejected": -0.8891257047653198,
      "logps/chosen": -143.95794677734375,
      "logps/rejected": -124.16468811035156,
      "loss": 0.5416,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.5871331095695496,
      "rewards/margins": 0.7976073026657104,
      "rewards/rejected": -1.3847405910491943,
      "step": 1130
    },
    {
      "epoch": 0.2080481795784287,
      "grad_norm": 4.876359939575195,
      "learning_rate": 7.515196168723523e-05,
      "logits/chosen": -1.021749496459961,
      "logits/rejected": -0.9650076031684875,
      "logps/chosen": -141.57656860351562,
      "logps/rejected": -144.38595581054688,
      "loss": 0.6103,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.71869957447052,
      "rewards/margins": 0.4955926835536957,
      "rewards/rejected": -1.214292287826538,
      "step": 1140
    },
    {
      "epoch": 0.20987316360981842,
      "grad_norm": 3.5752415657043457,
      "learning_rate": 7.510284275802787e-05,
      "logits/chosen": -0.9956296682357788,
      "logits/rejected": -0.9219934344291687,
      "logps/chosen": -152.6024169921875,
      "logps/rejected": -145.59339904785156,
      "loss": 0.4724,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9791603088378906,
      "rewards/margins": 0.8833326101303101,
      "rewards/rejected": -1.8624931573867798,
      "step": 1150
    },
    {
      "epoch": 0.21169814764120815,
      "grad_norm": 3.712165117263794,
      "learning_rate": 7.505372382882055e-05,
      "logits/chosen": -0.9475687146186829,
      "logits/rejected": -0.8885403871536255,
      "logps/chosen": -158.4574737548828,
      "logps/rejected": -154.07701110839844,
      "loss": 0.4678,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4030481576919556,
      "rewards/margins": 0.9874992370605469,
      "rewards/rejected": -2.390547275543213,
      "step": 1160
    },
    {
      "epoch": 0.21352313167259787,
      "grad_norm": 3.9337961673736572,
      "learning_rate": 7.500460489961319e-05,
      "logits/chosen": -0.9720999002456665,
      "logits/rejected": -0.897608757019043,
      "logps/chosen": -153.17236328125,
      "logps/rejected": -134.12904357910156,
      "loss": 0.5624,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.7465794086456299,
      "rewards/margins": 0.7839738130569458,
      "rewards/rejected": -2.530553102493286,
      "step": 1170
    },
    {
      "epoch": 0.2153481157039876,
      "grad_norm": 6.227589130401611,
      "learning_rate": 7.495548597040585e-05,
      "logits/chosen": -1.0423587560653687,
      "logits/rejected": -0.9622475504875183,
      "logps/chosen": -158.81263732910156,
      "logps/rejected": -148.5620574951172,
      "loss": 0.5572,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.4527807235717773,
      "rewards/margins": 0.8676964044570923,
      "rewards/rejected": -2.32047700881958,
      "step": 1180
    },
    {
      "epoch": 0.21717309973537732,
      "grad_norm": 4.710745811462402,
      "learning_rate": 7.49063670411985e-05,
      "logits/chosen": -0.9685847163200378,
      "logits/rejected": -0.914703369140625,
      "logps/chosen": -146.32540893554688,
      "logps/rejected": -139.56289672851562,
      "loss": 0.4876,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7694793939590454,
      "rewards/margins": 1.0404257774353027,
      "rewards/rejected": -1.8099052906036377,
      "step": 1190
    },
    {
      "epoch": 0.21899808376676705,
      "grad_norm": 3.1497151851654053,
      "learning_rate": 7.485724811199116e-05,
      "logits/chosen": -0.9475980997085571,
      "logits/rejected": -0.9196003675460815,
      "logps/chosen": -151.0613555908203,
      "logps/rejected": -146.6578826904297,
      "loss": 0.6262,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5019845962524414,
      "rewards/margins": 0.5692929029464722,
      "rewards/rejected": -1.0712774991989136,
      "step": 1200
    },
    {
      "epoch": 0.22082306779815677,
      "grad_norm": 5.999180316925049,
      "learning_rate": 7.480812918278382e-05,
      "logits/chosen": -1.0925657749176025,
      "logits/rejected": -1.03046452999115,
      "logps/chosen": -157.1761016845703,
      "logps/rejected": -138.5642547607422,
      "loss": 0.6005,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.18153750896453857,
      "rewards/margins": 0.7037414312362671,
      "rewards/rejected": -0.8852788209915161,
      "step": 1210
    },
    {
      "epoch": 0.2226480518295465,
      "grad_norm": 2.451052665710449,
      "learning_rate": 7.475901025357648e-05,
      "logits/chosen": -0.9395090937614441,
      "logits/rejected": -0.8739982843399048,
      "logps/chosen": -140.89407348632812,
      "logps/rejected": -128.0484161376953,
      "loss": 0.5427,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.45604485273361206,
      "rewards/margins": 0.6865028738975525,
      "rewards/rejected": -1.142547845840454,
      "step": 1220
    },
    {
      "epoch": 0.22447303586093623,
      "grad_norm": 2.9100077152252197,
      "learning_rate": 7.470989132436914e-05,
      "logits/chosen": -0.9329473376274109,
      "logits/rejected": -0.8707784414291382,
      "logps/chosen": -148.4555206298828,
      "logps/rejected": -143.87583923339844,
      "loss": 0.5393,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7195022702217102,
      "rewards/margins": 0.7979510426521301,
      "rewards/rejected": -1.5174534320831299,
      "step": 1230
    },
    {
      "epoch": 0.22629801989232595,
      "grad_norm": 3.8135015964508057,
      "learning_rate": 7.46607723951618e-05,
      "logits/chosen": -1.0714647769927979,
      "logits/rejected": -0.9812783002853394,
      "logps/chosen": -177.43545532226562,
      "logps/rejected": -146.6656036376953,
      "loss": 0.4771,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9518394470214844,
      "rewards/margins": 0.9135047793388367,
      "rewards/rejected": -1.8653442859649658,
      "step": 1240
    },
    {
      "epoch": 0.22812300392371568,
      "grad_norm": 5.265185356140137,
      "learning_rate": 7.461165346595445e-05,
      "logits/chosen": -0.9595267176628113,
      "logits/rejected": -0.9183530807495117,
      "logps/chosen": -161.0406494140625,
      "logps/rejected": -155.88442993164062,
      "loss": 0.5809,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.2638908624649048,
      "rewards/margins": 0.7848358154296875,
      "rewards/rejected": -2.0487265586853027,
      "step": 1250
    },
    {
      "epoch": 0.2299479879551054,
      "grad_norm": 3.808621644973755,
      "learning_rate": 7.45625345367471e-05,
      "logits/chosen": -0.9183673858642578,
      "logits/rejected": -0.8481429815292358,
      "logps/chosen": -159.57101440429688,
      "logps/rejected": -153.7645263671875,
      "loss": 0.5852,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0243144035339355,
      "rewards/margins": 0.774039626121521,
      "rewards/rejected": -1.798353910446167,
      "step": 1260
    },
    {
      "epoch": 0.23177297198649513,
      "grad_norm": 2.5833566188812256,
      "learning_rate": 7.451341560753977e-05,
      "logits/chosen": -1.0534191131591797,
      "logits/rejected": -0.9216310381889343,
      "logps/chosen": -175.6396026611328,
      "logps/rejected": -146.4729461669922,
      "loss": 0.5004,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7150915265083313,
      "rewards/margins": 0.8667871356010437,
      "rewards/rejected": -1.581878662109375,
      "step": 1270
    },
    {
      "epoch": 0.23359795601788486,
      "grad_norm": 4.96299409866333,
      "learning_rate": 7.446429667833242e-05,
      "logits/chosen": -0.9880653619766235,
      "logits/rejected": -0.9157002568244934,
      "logps/chosen": -157.0203399658203,
      "logps/rejected": -147.27891540527344,
      "loss": 0.4621,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6556947231292725,
      "rewards/margins": 0.968208909034729,
      "rewards/rejected": -1.6239036321640015,
      "step": 1280
    },
    {
      "epoch": 0.23542294004927458,
      "grad_norm": 4.867981910705566,
      "learning_rate": 7.441517774912507e-05,
      "logits/chosen": -0.9590508341789246,
      "logits/rejected": -0.8875167965888977,
      "logps/chosen": -142.02549743652344,
      "logps/rejected": -142.78993225097656,
      "loss": 0.5456,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.4592369496822357,
      "rewards/margins": 1.182273507118225,
      "rewards/rejected": -1.6415103673934937,
      "step": 1290
    },
    {
      "epoch": 0.2372479240806643,
      "grad_norm": 5.528153419494629,
      "learning_rate": 7.436605881991773e-05,
      "logits/chosen": -1.0099549293518066,
      "logits/rejected": -0.9558442831039429,
      "logps/chosen": -149.05923461914062,
      "logps/rejected": -142.29513549804688,
      "loss": 0.5252,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.37735989689826965,
      "rewards/margins": 0.9448353052139282,
      "rewards/rejected": -1.3221951723098755,
      "step": 1300
    },
    {
      "epoch": 0.23907290811205403,
      "grad_norm": 2.9700381755828857,
      "learning_rate": 7.43169398907104e-05,
      "logits/chosen": -1.026953101158142,
      "logits/rejected": -0.9779030084609985,
      "logps/chosen": -155.96844482421875,
      "logps/rejected": -144.80667114257812,
      "loss": 0.6159,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.7458294630050659,
      "rewards/margins": 0.8482211232185364,
      "rewards/rejected": -1.594050645828247,
      "step": 1310
    },
    {
      "epoch": 0.24089789214344373,
      "grad_norm": 2.7363903522491455,
      "learning_rate": 7.426782096150304e-05,
      "logits/chosen": -1.0143887996673584,
      "logits/rejected": -0.9428098797798157,
      "logps/chosen": -146.30348205566406,
      "logps/rejected": -131.16966247558594,
      "loss": 0.5612,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.5109910368919373,
      "rewards/margins": 0.7610172033309937,
      "rewards/rejected": -1.2720081806182861,
      "step": 1320
    },
    {
      "epoch": 0.24272287617483346,
      "grad_norm": 3.6459572315216064,
      "learning_rate": 7.42187020322957e-05,
      "logits/chosen": -0.9502007365226746,
      "logits/rejected": -0.8814314603805542,
      "logps/chosen": -156.16452026367188,
      "logps/rejected": -133.4778289794922,
      "loss": 0.5817,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.488756000995636,
      "rewards/margins": 0.5661279559135437,
      "rewards/rejected": -1.0548838376998901,
      "step": 1330
    },
    {
      "epoch": 0.24454786020622318,
      "grad_norm": 2.084679365158081,
      "learning_rate": 7.416958310308836e-05,
      "logits/chosen": -1.0712275505065918,
      "logits/rejected": -1.0442169904708862,
      "logps/chosen": -131.58399963378906,
      "logps/rejected": -140.6514892578125,
      "loss": 0.4662,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.31998270750045776,
      "rewards/margins": 0.933379054069519,
      "rewards/rejected": -1.2533619403839111,
      "step": 1340
    },
    {
      "epoch": 0.2463728442376129,
      "grad_norm": 3.4812698364257812,
      "learning_rate": 7.412046417388102e-05,
      "logits/chosen": -1.0100219249725342,
      "logits/rejected": -0.9712130427360535,
      "logps/chosen": -136.54588317871094,
      "logps/rejected": -155.40960693359375,
      "loss": 0.5659,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.6037824153900146,
      "rewards/margins": 0.923758327960968,
      "rewards/rejected": -1.5275408029556274,
      "step": 1350
    },
    {
      "epoch": 0.24819782826900263,
      "grad_norm": 4.4091033935546875,
      "learning_rate": 7.407134524467367e-05,
      "logits/chosen": -1.0456067323684692,
      "logits/rejected": -0.9720802307128906,
      "logps/chosen": -170.32455444335938,
      "logps/rejected": -155.3847198486328,
      "loss": 0.5083,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9015704989433289,
      "rewards/margins": 1.1606981754302979,
      "rewards/rejected": -2.0622687339782715,
      "step": 1360
    },
    {
      "epoch": 0.25002281230039236,
      "grad_norm": 2.2102818489074707,
      "learning_rate": 7.402222631546633e-05,
      "logits/chosen": -0.9693238139152527,
      "logits/rejected": -0.9527930021286011,
      "logps/chosen": -148.93260192871094,
      "logps/rejected": -153.5797119140625,
      "loss": 0.5214,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6464928388595581,
      "rewards/margins": 1.0607428550720215,
      "rewards/rejected": -1.70723557472229,
      "step": 1370
    },
    {
      "epoch": 0.2518477963317821,
      "grad_norm": 4.006618976593018,
      "learning_rate": 7.397310738625899e-05,
      "logits/chosen": -0.9995349645614624,
      "logits/rejected": -0.9471486210823059,
      "logps/chosen": -156.53298950195312,
      "logps/rejected": -155.65428161621094,
      "loss": 0.4888,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7110151052474976,
      "rewards/margins": 1.0174239873886108,
      "rewards/rejected": -1.7284390926361084,
      "step": 1380
    },
    {
      "epoch": 0.2536727803631718,
      "grad_norm": 5.74928092956543,
      "learning_rate": 7.392398845705165e-05,
      "logits/chosen": -1.0047990083694458,
      "logits/rejected": -0.9077043533325195,
      "logps/chosen": -171.10305786132812,
      "logps/rejected": -151.85842895507812,
      "loss": 0.5535,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2035285234451294,
      "rewards/margins": 1.125150203704834,
      "rewards/rejected": -2.328678607940674,
      "step": 1390
    },
    {
      "epoch": 0.25549776439456157,
      "grad_norm": 3.1437699794769287,
      "learning_rate": 7.38748695278443e-05,
      "logits/chosen": -0.9720107913017273,
      "logits/rejected": -0.890579342842102,
      "logps/chosen": -170.91812133789062,
      "logps/rejected": -144.05850219726562,
      "loss": 0.5314,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.631452202796936,
      "rewards/margins": 1.1139501333236694,
      "rewards/rejected": -1.7454025745391846,
      "step": 1400
    },
    {
      "epoch": 0.25732274842595126,
      "grad_norm": 3.406067371368408,
      "learning_rate": 7.382575059863695e-05,
      "logits/chosen": -0.9370986223220825,
      "logits/rejected": -0.8105446696281433,
      "logps/chosen": -176.5894012451172,
      "logps/rejected": -144.38803100585938,
      "loss": 0.574,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.43625134229660034,
      "rewards/margins": 1.0712368488311768,
      "rewards/rejected": -1.5074881315231323,
      "step": 1410
    },
    {
      "epoch": 0.259147732457341,
      "grad_norm": 6.309344291687012,
      "learning_rate": 7.377663166942962e-05,
      "logits/chosen": -0.9203450083732605,
      "logits/rejected": -0.8730676770210266,
      "logps/chosen": -147.7607879638672,
      "logps/rejected": -146.48306274414062,
      "loss": 0.5886,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6088085770606995,
      "rewards/margins": 1.0272773504257202,
      "rewards/rejected": -1.6360857486724854,
      "step": 1420
    },
    {
      "epoch": 0.2609727164887307,
      "grad_norm": 4.216403007507324,
      "learning_rate": 7.372751274022226e-05,
      "logits/chosen": -0.9168702960014343,
      "logits/rejected": -0.8749090433120728,
      "logps/chosen": -138.53944396972656,
      "logps/rejected": -129.04896545410156,
      "loss": 0.6476,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.35627439618110657,
      "rewards/margins": 0.6525472402572632,
      "rewards/rejected": -1.008821725845337,
      "step": 1430
    },
    {
      "epoch": 0.26279770052012047,
      "grad_norm": 3.122392177581787,
      "learning_rate": 7.367839381101492e-05,
      "logits/chosen": -0.9774830937385559,
      "logits/rejected": -0.8698344230651855,
      "logps/chosen": -156.0734405517578,
      "logps/rejected": -127.46537017822266,
      "loss": 0.5236,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.049598898738622665,
      "rewards/margins": 0.9389041662216187,
      "rewards/rejected": -0.988503098487854,
      "step": 1440
    },
    {
      "epoch": 0.26462268455151017,
      "grad_norm": 2.3677942752838135,
      "learning_rate": 7.362927488180759e-05,
      "logits/chosen": -0.9782136082649231,
      "logits/rejected": -0.954545795917511,
      "logps/chosen": -132.6616973876953,
      "logps/rejected": -136.07733154296875,
      "loss": 0.5752,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.19042515754699707,
      "rewards/margins": 0.6474202275276184,
      "rewards/rejected": -0.8378453254699707,
      "step": 1450
    },
    {
      "epoch": 0.2664476685828999,
      "grad_norm": 2.751110792160034,
      "learning_rate": 7.358015595260024e-05,
      "logits/chosen": -1.0809866189956665,
      "logits/rejected": -1.0049200057983398,
      "logps/chosen": -142.57595825195312,
      "logps/rejected": -127.50102233886719,
      "loss": 0.5045,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.05377551168203354,
      "rewards/margins": 0.9967589378356934,
      "rewards/rejected": -1.0505343675613403,
      "step": 1460
    },
    {
      "epoch": 0.2682726526142896,
      "grad_norm": 3.489830732345581,
      "learning_rate": 7.35310370233929e-05,
      "logits/chosen": -1.0480550527572632,
      "logits/rejected": -0.9951518774032593,
      "logps/chosen": -156.49838256835938,
      "logps/rejected": -142.6190643310547,
      "loss": 0.5644,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7107558250427246,
      "rewards/margins": 0.8219102025032043,
      "rewards/rejected": -1.5326659679412842,
      "step": 1470
    },
    {
      "epoch": 0.2700976366456794,
      "grad_norm": 3.377553939819336,
      "learning_rate": 7.348191809418555e-05,
      "logits/chosen": -1.0273395776748657,
      "logits/rejected": -0.9017569422721863,
      "logps/chosen": -168.3784942626953,
      "logps/rejected": -132.80221557617188,
      "loss": 0.5737,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.797493577003479,
      "rewards/margins": 0.6977585554122925,
      "rewards/rejected": -1.4952521324157715,
      "step": 1480
    },
    {
      "epoch": 0.27192262067706907,
      "grad_norm": 3.0015909671783447,
      "learning_rate": 7.343279916497821e-05,
      "logits/chosen": -0.9086810946464539,
      "logits/rejected": -0.8724550008773804,
      "logps/chosen": -146.33993530273438,
      "logps/rejected": -147.4788055419922,
      "loss": 0.7176,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.9353889226913452,
      "rewards/margins": 0.3920252025127411,
      "rewards/rejected": -1.3274140357971191,
      "step": 1490
    },
    {
      "epoch": 0.2737476047084588,
      "grad_norm": 4.379655361175537,
      "learning_rate": 7.338368023577087e-05,
      "logits/chosen": -0.8721430897712708,
      "logits/rejected": -0.8127548098564148,
      "logps/chosen": -143.6931915283203,
      "logps/rejected": -141.41165161132812,
      "loss": 0.5817,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.5795578956604004,
      "rewards/margins": 0.6947111487388611,
      "rewards/rejected": -1.2742691040039062,
      "step": 1500
    },
    {
      "epoch": 0.2755725887398485,
      "grad_norm": 3.485020875930786,
      "learning_rate": 7.333456130656353e-05,
      "logits/chosen": -0.9117871522903442,
      "logits/rejected": -0.8363133668899536,
      "logps/chosen": -147.9068603515625,
      "logps/rejected": -143.63198852539062,
      "loss": 0.4983,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.015339456498622894,
      "rewards/margins": 1.1065757274627686,
      "rewards/rejected": -1.1219151020050049,
      "step": 1510
    },
    {
      "epoch": 0.2773975727712383,
      "grad_norm": 2.711322069168091,
      "learning_rate": 7.328544237735618e-05,
      "logits/chosen": -0.8974266052246094,
      "logits/rejected": -0.8220111131668091,
      "logps/chosen": -145.6955108642578,
      "logps/rejected": -130.53036499023438,
      "loss": 0.6054,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.02680731937289238,
      "rewards/margins": 0.7107348442077637,
      "rewards/rejected": -0.7375421524047852,
      "step": 1520
    },
    {
      "epoch": 0.279222556802628,
      "grad_norm": 2.268646001815796,
      "learning_rate": 7.323632344814884e-05,
      "logits/chosen": -0.89495450258255,
      "logits/rejected": -0.7649110555648804,
      "logps/chosen": -158.09107971191406,
      "logps/rejected": -127.30218505859375,
      "loss": 0.5385,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.23412902653217316,
      "rewards/margins": 0.8627440333366394,
      "rewards/rejected": -0.6286150813102722,
      "step": 1530
    },
    {
      "epoch": 0.28104754083401773,
      "grad_norm": 2.248516321182251,
      "learning_rate": 7.31872045189415e-05,
      "logits/chosen": -0.793535053730011,
      "logits/rejected": -0.7553188800811768,
      "logps/chosen": -131.9468231201172,
      "logps/rejected": -128.1568145751953,
      "loss": 0.6343,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.07840514183044434,
      "rewards/margins": 0.573717474937439,
      "rewards/rejected": -0.6521225571632385,
      "step": 1540
    },
    {
      "epoch": 0.2828725248654074,
      "grad_norm": 2.644427537918091,
      "learning_rate": 7.313808558973414e-05,
      "logits/chosen": -0.8605899810791016,
      "logits/rejected": -0.7566507458686829,
      "logps/chosen": -165.56820678710938,
      "logps/rejected": -136.85101318359375,
      "loss": 0.4887,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.07494746148586273,
      "rewards/margins": 0.772369921207428,
      "rewards/rejected": -0.8473173975944519,
      "step": 1550
    },
    {
      "epoch": 0.2846975088967972,
      "grad_norm": 2.8839738368988037,
      "learning_rate": 7.308896666052681e-05,
      "logits/chosen": -0.7966479063034058,
      "logits/rejected": -0.7267588376998901,
      "logps/chosen": -157.8994903564453,
      "logps/rejected": -138.06069946289062,
      "loss": 0.4517,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.011238964274525642,
      "rewards/margins": 1.094380259513855,
      "rewards/rejected": -1.105619192123413,
      "step": 1560
    },
    {
      "epoch": 0.2865224929281869,
      "grad_norm": 3.125483751296997,
      "learning_rate": 7.303984773131946e-05,
      "logits/chosen": -0.8121921420097351,
      "logits/rejected": -0.7527056932449341,
      "logps/chosen": -158.92236328125,
      "logps/rejected": -147.75851440429688,
      "loss": 0.4909,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.04024192690849304,
      "rewards/margins": 1.029994249343872,
      "rewards/rejected": -1.070236086845398,
      "step": 1570
    },
    {
      "epoch": 0.2883474769595766,
      "grad_norm": 5.709223747253418,
      "learning_rate": 7.299072880211212e-05,
      "logits/chosen": -0.8145667314529419,
      "logits/rejected": -0.7991023063659668,
      "logps/chosen": -149.23223876953125,
      "logps/rejected": -149.9619903564453,
      "loss": 0.6127,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.33497148752212524,
      "rewards/margins": 0.7229384183883667,
      "rewards/rejected": -1.0579099655151367,
      "step": 1580
    },
    {
      "epoch": 0.29017246099096633,
      "grad_norm": 3.6728787422180176,
      "learning_rate": 7.294160987290477e-05,
      "logits/chosen": -0.8375333547592163,
      "logits/rejected": -0.8095258474349976,
      "logps/chosen": -148.55160522460938,
      "logps/rejected": -148.3024139404297,
      "loss": 0.5524,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.15548451244831085,
      "rewards/margins": 0.7951352000236511,
      "rewards/rejected": -0.9506198167800903,
      "step": 1590
    },
    {
      "epoch": 0.29199744502235603,
      "grad_norm": 3.7271056175231934,
      "learning_rate": 7.289249094369743e-05,
      "logits/chosen": -0.8262443542480469,
      "logits/rejected": -0.786669135093689,
      "logps/chosen": -145.33731079101562,
      "logps/rejected": -149.75634765625,
      "loss": 0.6348,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6440248489379883,
      "rewards/margins": 0.8444372415542603,
      "rewards/rejected": -1.488461971282959,
      "step": 1600
    },
    {
      "epoch": 0.2938224290537458,
      "grad_norm": 3.8505160808563232,
      "learning_rate": 7.284337201449009e-05,
      "logits/chosen": -0.8601218461990356,
      "logits/rejected": -0.7807595133781433,
      "logps/chosen": -153.0630340576172,
      "logps/rejected": -133.7376251220703,
      "loss": 0.6383,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.3878389000892639,
      "rewards/margins": 0.5422391891479492,
      "rewards/rejected": -0.9300781488418579,
      "step": 1610
    },
    {
      "epoch": 0.2956474130851355,
      "grad_norm": 1.4048528671264648,
      "learning_rate": 7.279425308528275e-05,
      "logits/chosen": -0.8138955235481262,
      "logits/rejected": -0.7388182282447815,
      "logps/chosen": -152.3164825439453,
      "logps/rejected": -138.04690551757812,
      "loss": 0.5287,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.5046795606613159,
      "rewards/margins": 0.7960022687911987,
      "rewards/rejected": -1.3006818294525146,
      "step": 1620
    },
    {
      "epoch": 0.29747239711652523,
      "grad_norm": 1.8901349306106567,
      "learning_rate": 7.27451341560754e-05,
      "logits/chosen": -0.8218029141426086,
      "logits/rejected": -0.7620278596878052,
      "logps/chosen": -143.0020294189453,
      "logps/rejected": -140.04335021972656,
      "loss": 0.5005,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.44987350702285767,
      "rewards/margins": 1.1063947677612305,
      "rewards/rejected": -1.5562684535980225,
      "step": 1630
    },
    {
      "epoch": 0.29929738114791493,
      "grad_norm": 5.472195148468018,
      "learning_rate": 7.269601522686806e-05,
      "logits/chosen": -0.7720165848731995,
      "logits/rejected": -0.7394530177116394,
      "logps/chosen": -148.8368682861328,
      "logps/rejected": -144.6156768798828,
      "loss": 0.5449,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1640743017196655,
      "rewards/margins": 1.008798599243164,
      "rewards/rejected": -2.17287278175354,
      "step": 1640
    },
    {
      "epoch": 0.3011223651793047,
      "grad_norm": 5.024754047393799,
      "learning_rate": 7.264689629766072e-05,
      "logits/chosen": -0.865282416343689,
      "logits/rejected": -0.7976030111312866,
      "logps/chosen": -154.64505004882812,
      "logps/rejected": -150.8828887939453,
      "loss": 0.7464,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -1.0606896877288818,
      "rewards/margins": 0.5712800621986389,
      "rewards/rejected": -1.6319698095321655,
      "step": 1650
    },
    {
      "epoch": 0.3029473492106944,
      "grad_norm": 3.731001377105713,
      "learning_rate": 7.259777736845336e-05,
      "logits/chosen": -0.847272515296936,
      "logits/rejected": -0.7958288788795471,
      "logps/chosen": -155.01296997070312,
      "logps/rejected": -152.15350341796875,
      "loss": 0.6039,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.949821949005127,
      "rewards/margins": 0.7613213062286377,
      "rewards/rejected": -1.7111432552337646,
      "step": 1660
    },
    {
      "epoch": 0.30477233324208414,
      "grad_norm": 2.6668598651885986,
      "learning_rate": 7.254865843924604e-05,
      "logits/chosen": -0.8997246623039246,
      "logits/rejected": -0.8494731783866882,
      "logps/chosen": -167.36990356445312,
      "logps/rejected": -151.07626342773438,
      "loss": 0.5964,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5042804479598999,
      "rewards/margins": 0.570527195930481,
      "rewards/rejected": -1.0748077630996704,
      "step": 1670
    },
    {
      "epoch": 0.30659731727347384,
      "grad_norm": 5.385797023773193,
      "learning_rate": 7.249953951003869e-05,
      "logits/chosen": -0.8397151827812195,
      "logits/rejected": -0.7984366416931152,
      "logps/chosen": -156.44471740722656,
      "logps/rejected": -146.2540283203125,
      "loss": 0.6233,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.34627291560173035,
      "rewards/margins": 0.7071025967597961,
      "rewards/rejected": -1.053375482559204,
      "step": 1680
    },
    {
      "epoch": 0.3084223013048636,
      "grad_norm": 3.6972146034240723,
      "learning_rate": 7.245042058083134e-05,
      "logits/chosen": -0.8111926913261414,
      "logits/rejected": -0.8614959716796875,
      "logps/chosen": -119.5791244506836,
      "logps/rejected": -167.00990295410156,
      "loss": 0.803,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -0.47727447748184204,
      "rewards/margins": 0.16027168929576874,
      "rewards/rejected": -0.637546181678772,
      "step": 1690
    },
    {
      "epoch": 0.3102472853362533,
      "grad_norm": 3.101271629333496,
      "learning_rate": 7.2401301651624e-05,
      "logits/chosen": -0.91468745470047,
      "logits/rejected": -0.9153806567192078,
      "logps/chosen": -137.3372802734375,
      "logps/rejected": -145.635498046875,
      "loss": 0.5207,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.02935861609876156,
      "rewards/margins": 0.7320305109024048,
      "rewards/rejected": -0.7613892555236816,
      "step": 1700
    },
    {
      "epoch": 0.31207226936764304,
      "grad_norm": 2.8302001953125,
      "learning_rate": 7.235218272241667e-05,
      "logits/chosen": -0.940198540687561,
      "logits/rejected": -0.8854724764823914,
      "logps/chosen": -145.68399047851562,
      "logps/rejected": -127.58000183105469,
      "loss": 0.473,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.14214152097702026,
      "rewards/margins": 0.7787189483642578,
      "rewards/rejected": -0.6365774869918823,
      "step": 1710
    },
    {
      "epoch": 0.31389725339903274,
      "grad_norm": 3.1873905658721924,
      "learning_rate": 7.230306379320931e-05,
      "logits/chosen": -0.9592396020889282,
      "logits/rejected": -0.9171306490898132,
      "logps/chosen": -143.58700561523438,
      "logps/rejected": -139.887451171875,
      "loss": 0.5626,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.28969207406044006,
      "rewards/margins": 0.6745069026947021,
      "rewards/rejected": -0.3848148286342621,
      "step": 1720
    },
    {
      "epoch": 0.3157222374304225,
      "grad_norm": 2.3113389015197754,
      "learning_rate": 7.225394486400197e-05,
      "logits/chosen": -0.9138428568840027,
      "logits/rejected": -0.8425998687744141,
      "logps/chosen": -152.28237915039062,
      "logps/rejected": -134.72836303710938,
      "loss": 0.5303,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.29811325669288635,
      "rewards/margins": 0.8726695775985718,
      "rewards/rejected": -0.5745563507080078,
      "step": 1730
    },
    {
      "epoch": 0.3175472214618122,
      "grad_norm": 3.3933889865875244,
      "learning_rate": 7.220482593479463e-05,
      "logits/chosen": -0.8706243634223938,
      "logits/rejected": -0.8572141528129578,
      "logps/chosen": -141.98023986816406,
      "logps/rejected": -136.6844024658203,
      "loss": 0.5261,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.12882758677005768,
      "rewards/margins": 0.7581915855407715,
      "rewards/rejected": -0.6293639540672302,
      "step": 1740
    },
    {
      "epoch": 0.31937220549320194,
      "grad_norm": 2.718505620956421,
      "learning_rate": 7.215570700558728e-05,
      "logits/chosen": -0.9060477018356323,
      "logits/rejected": -0.8527665138244629,
      "logps/chosen": -128.2312469482422,
      "logps/rejected": -123.63487243652344,
      "loss": 0.5394,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5062387585639954,
      "rewards/margins": 1.0053369998931885,
      "rewards/rejected": -1.5115759372711182,
      "step": 1750
    },
    {
      "epoch": 0.32119718952459164,
      "grad_norm": 4.3686299324035645,
      "learning_rate": 7.210658807637994e-05,
      "logits/chosen": -0.9362121820449829,
      "logits/rejected": -0.8934314846992493,
      "logps/chosen": -161.670166015625,
      "logps/rejected": -157.08294677734375,
      "loss": 0.6299,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6785959005355835,
      "rewards/margins": 0.8519619107246399,
      "rewards/rejected": -1.5305578708648682,
      "step": 1760
    },
    {
      "epoch": 0.3230221735559814,
      "grad_norm": 3.655397653579712,
      "learning_rate": 7.20574691471726e-05,
      "logits/chosen": -0.9498850703239441,
      "logits/rejected": -0.9130929112434387,
      "logps/chosen": -143.96725463867188,
      "logps/rejected": -148.5584716796875,
      "loss": 0.5988,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5473716855049133,
      "rewards/margins": 0.8955904841423035,
      "rewards/rejected": -1.4429620504379272,
      "step": 1770
    },
    {
      "epoch": 0.3248471575873711,
      "grad_norm": 3.5548081398010254,
      "learning_rate": 7.200835021796526e-05,
      "logits/chosen": -0.9275617599487305,
      "logits/rejected": -0.8823406100273132,
      "logps/chosen": -136.26718139648438,
      "logps/rejected": -124.47734069824219,
      "loss": 0.6662,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.2729088068008423,
      "rewards/margins": 0.573357343673706,
      "rewards/rejected": -0.8462661504745483,
      "step": 1780
    },
    {
      "epoch": 0.32667214161876085,
      "grad_norm": 2.935046911239624,
      "learning_rate": 7.195923128875791e-05,
      "logits/chosen": -0.937920093536377,
      "logits/rejected": -0.8414163589477539,
      "logps/chosen": -160.6533203125,
      "logps/rejected": -134.87303161621094,
      "loss": 0.4688,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.21693262457847595,
      "rewards/margins": 0.8791141510009766,
      "rewards/rejected": -1.0960466861724854,
      "step": 1790
    },
    {
      "epoch": 0.32849712565015055,
      "grad_norm": 3.233412981033325,
      "learning_rate": 7.191011235955057e-05,
      "logits/chosen": -0.8867090940475464,
      "logits/rejected": -0.8263331651687622,
      "logps/chosen": -149.1910858154297,
      "logps/rejected": -134.3521270751953,
      "loss": 0.4863,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.3229309916496277,
      "rewards/margins": 0.8113727569580078,
      "rewards/rejected": -1.1343038082122803,
      "step": 1800
    },
    {
      "epoch": 0.3303221096815403,
      "grad_norm": 4.562108516693115,
      "learning_rate": 7.186099343034323e-05,
      "logits/chosen": -0.7756372094154358,
      "logits/rejected": -0.6830428838729858,
      "logps/chosen": -153.54733276367188,
      "logps/rejected": -139.6850128173828,
      "loss": 0.5502,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.4321414530277252,
      "rewards/margins": 1.0483524799346924,
      "rewards/rejected": -1.4804939031600952,
      "step": 1810
    },
    {
      "epoch": 0.33214709371293,
      "grad_norm": 2.8864076137542725,
      "learning_rate": 7.181187450113589e-05,
      "logits/chosen": -0.7705010771751404,
      "logits/rejected": -0.6582857966423035,
      "logps/chosen": -153.40586853027344,
      "logps/rejected": -119.57757568359375,
      "loss": 0.5351,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.3009147346019745,
      "rewards/margins": 0.9531558156013489,
      "rewards/rejected": -1.254070520401001,
      "step": 1820
    },
    {
      "epoch": 0.33397207774431975,
      "grad_norm": 5.1807403564453125,
      "learning_rate": 7.176275557192853e-05,
      "logits/chosen": -0.7599266767501831,
      "logits/rejected": -0.6912835836410522,
      "logps/chosen": -168.7930145263672,
      "logps/rejected": -155.43881225585938,
      "loss": 0.5359,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.6884647607803345,
      "rewards/margins": 0.8682332038879395,
      "rewards/rejected": -1.5566980838775635,
      "step": 1830
    },
    {
      "epoch": 0.33579706177570945,
      "grad_norm": 3.2673470973968506,
      "learning_rate": 7.171363664272119e-05,
      "logits/chosen": -0.7878535985946655,
      "logits/rejected": -0.7290584444999695,
      "logps/chosen": -163.59622192382812,
      "logps/rejected": -156.50196838378906,
      "loss": 0.5604,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.1007992029190063,
      "rewards/margins": 0.9006446599960327,
      "rewards/rejected": -2.00144362449646,
      "step": 1840
    },
    {
      "epoch": 0.3376220458070992,
      "grad_norm": 4.806133270263672,
      "learning_rate": 7.166451771351386e-05,
      "logits/chosen": -0.7510755658149719,
      "logits/rejected": -0.6395837664604187,
      "logps/chosen": -171.10316467285156,
      "logps/rejected": -158.46099853515625,
      "loss": 0.5972,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.1935818195343018,
      "rewards/margins": 0.911524772644043,
      "rewards/rejected": -2.105106830596924,
      "step": 1850
    },
    {
      "epoch": 0.3394470298384889,
      "grad_norm": 3.0248777866363525,
      "learning_rate": 7.16153987843065e-05,
      "logits/chosen": -0.7089576721191406,
      "logits/rejected": -0.6423065066337585,
      "logps/chosen": -153.75894165039062,
      "logps/rejected": -139.51995849609375,
      "loss": 0.5866,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.2702014446258545,
      "rewards/margins": 0.6546197533607483,
      "rewards/rejected": -1.924821138381958,
      "step": 1860
    },
    {
      "epoch": 0.34127201386987865,
      "grad_norm": 1.8883031606674194,
      "learning_rate": 7.156627985509916e-05,
      "logits/chosen": -0.6713556051254272,
      "logits/rejected": -0.5722318887710571,
      "logps/chosen": -159.182373046875,
      "logps/rejected": -140.64060974121094,
      "loss": 0.5098,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8341328501701355,
      "rewards/margins": 1.1170063018798828,
      "rewards/rejected": -1.951139211654663,
      "step": 1870
    },
    {
      "epoch": 0.34309699790126835,
      "grad_norm": 3.7267751693725586,
      "learning_rate": 7.151716092589182e-05,
      "logits/chosen": -0.6504020094871521,
      "logits/rejected": -0.6227720379829407,
      "logps/chosen": -145.3643035888672,
      "logps/rejected": -141.17391967773438,
      "loss": 0.6518,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.8835703134536743,
      "rewards/margins": 0.49725475907325745,
      "rewards/rejected": -1.3808252811431885,
      "step": 1880
    },
    {
      "epoch": 0.3449219819326581,
      "grad_norm": 3.297712802886963,
      "learning_rate": 7.146804199668448e-05,
      "logits/chosen": -0.6729791760444641,
      "logits/rejected": -0.6406342387199402,
      "logps/chosen": -148.97080993652344,
      "logps/rejected": -151.2450408935547,
      "loss": 0.7439,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.720902144908905,
      "rewards/margins": 0.2860758304595947,
      "rewards/rejected": -1.0069780349731445,
      "step": 1890
    },
    {
      "epoch": 0.3467469659640478,
      "grad_norm": 2.528313636779785,
      "learning_rate": 7.141892306747714e-05,
      "logits/chosen": -0.7240595817565918,
      "logits/rejected": -0.6710534691810608,
      "logps/chosen": -144.09597778320312,
      "logps/rejected": -148.07176208496094,
      "loss": 0.5295,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.25189000368118286,
      "rewards/margins": 0.7388712763786316,
      "rewards/rejected": -0.9907611608505249,
      "step": 1900
    },
    {
      "epoch": 0.34857194999543756,
      "grad_norm": 4.9289069175720215,
      "learning_rate": 7.13698041382698e-05,
      "logits/chosen": -0.759449303150177,
      "logits/rejected": -0.6702256202697754,
      "logps/chosen": -160.0177764892578,
      "logps/rejected": -135.80410766601562,
      "loss": 0.6258,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.11754117161035538,
      "rewards/margins": 0.6747339963912964,
      "rewards/rejected": -0.7922751307487488,
      "step": 1910
    },
    {
      "epoch": 0.35039693402682726,
      "grad_norm": 3.47771954536438,
      "learning_rate": 7.132068520906245e-05,
      "logits/chosen": -0.7215430736541748,
      "logits/rejected": -0.6817451119422913,
      "logps/chosen": -144.62643432617188,
      "logps/rejected": -140.23861694335938,
      "loss": 0.6192,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.3614340126514435,
      "rewards/margins": 0.523774266242981,
      "rewards/rejected": -0.885208249092102,
      "step": 1920
    },
    {
      "epoch": 0.352221918058217,
      "grad_norm": 2.4685816764831543,
      "learning_rate": 7.127156627985511e-05,
      "logits/chosen": -0.75665682554245,
      "logits/rejected": -0.6473574042320251,
      "logps/chosen": -161.40638732910156,
      "logps/rejected": -129.11781311035156,
      "loss": 0.6127,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.3815534710884094,
      "rewards/margins": 0.6095924973487854,
      "rewards/rejected": -0.9911459684371948,
      "step": 1930
    },
    {
      "epoch": 0.3540469020896067,
      "grad_norm": 2.8141422271728516,
      "learning_rate": 7.122244735064777e-05,
      "logits/chosen": -0.767052948474884,
      "logits/rejected": -0.7422848343849182,
      "logps/chosen": -141.49014282226562,
      "logps/rejected": -135.5503387451172,
      "loss": 0.6119,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.5257826447486877,
      "rewards/margins": 0.4735988974571228,
      "rewards/rejected": -0.9993816614151001,
      "step": 1940
    },
    {
      "epoch": 0.35587188612099646,
      "grad_norm": 2.24340558052063,
      "learning_rate": 7.117332842144041e-05,
      "logits/chosen": -0.7820910811424255,
      "logits/rejected": -0.6935640573501587,
      "logps/chosen": -156.27786254882812,
      "logps/rejected": -136.4993133544922,
      "loss": 0.5139,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.2043699324131012,
      "rewards/margins": 0.8881333470344543,
      "rewards/rejected": -1.092503309249878,
      "step": 1950
    },
    {
      "epoch": 0.35769687015238616,
      "grad_norm": 2.7419466972351074,
      "learning_rate": 7.112420949223308e-05,
      "logits/chosen": -0.7479439377784729,
      "logits/rejected": -0.6556174755096436,
      "logps/chosen": -146.894287109375,
      "logps/rejected": -133.50254821777344,
      "loss": 0.5106,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.3663156032562256,
      "rewards/margins": 0.8445969820022583,
      "rewards/rejected": -1.2109124660491943,
      "step": 1960
    },
    {
      "epoch": 0.3595218541837759,
      "grad_norm": 2.41023850440979,
      "learning_rate": 7.107509056302573e-05,
      "logits/chosen": -0.7714954614639282,
      "logits/rejected": -0.7210264801979065,
      "logps/chosen": -139.63473510742188,
      "logps/rejected": -140.92474365234375,
      "loss": 0.6451,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.22234764695167542,
      "rewards/margins": 0.5345668792724609,
      "rewards/rejected": -0.7569146156311035,
      "step": 1970
    },
    {
      "epoch": 0.3613468382151656,
      "grad_norm": 3.193009376525879,
      "learning_rate": 7.102597163381838e-05,
      "logits/chosen": -0.7093038558959961,
      "logits/rejected": -0.6469809412956238,
      "logps/chosen": -149.1739959716797,
      "logps/rejected": -142.73098754882812,
      "loss": 0.6028,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.06708093732595444,
      "rewards/margins": 0.6533423066139221,
      "rewards/rejected": -0.5862613916397095,
      "step": 1980
    },
    {
      "epoch": 0.36317182224655536,
      "grad_norm": 1.7824918031692505,
      "learning_rate": 7.097685270461104e-05,
      "logits/chosen": -0.8176946640014648,
      "logits/rejected": -0.737708330154419,
      "logps/chosen": -143.33132934570312,
      "logps/rejected": -132.57089233398438,
      "loss": 0.4503,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.0839441642165184,
      "rewards/margins": 1.0319888591766357,
      "rewards/rejected": -0.9480447769165039,
      "step": 1990
    },
    {
      "epoch": 0.36499680627794506,
      "grad_norm": 4.90587043762207,
      "learning_rate": 7.09277337754037e-05,
      "logits/chosen": -0.6921242475509644,
      "logits/rejected": -0.5893919467926025,
      "logps/chosen": -176.64755249023438,
      "logps/rejected": -142.41517639160156,
      "loss": 0.5289,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.24644801020622253,
      "rewards/margins": 0.9522920846939087,
      "rewards/rejected": -1.1987402439117432,
      "step": 2000
    },
    {
      "epoch": 0.3668217903093348,
      "grad_norm": 2.5443830490112305,
      "learning_rate": 7.087861484619636e-05,
      "logits/chosen": -0.8184818029403687,
      "logits/rejected": -0.7091552019119263,
      "logps/chosen": -149.802734375,
      "logps/rejected": -129.22341918945312,
      "loss": 0.5975,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.6480981111526489,
      "rewards/margins": 0.7790594100952148,
      "rewards/rejected": -1.4271576404571533,
      "step": 2010
    },
    {
      "epoch": 0.3686467743407245,
      "grad_norm": 3.4333696365356445,
      "learning_rate": 7.082949591698902e-05,
      "logits/chosen": -0.722007155418396,
      "logits/rejected": -0.6722814440727234,
      "logps/chosen": -142.7584686279297,
      "logps/rejected": -137.99826049804688,
      "loss": 0.5777,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7795141935348511,
      "rewards/margins": 0.9630082249641418,
      "rewards/rejected": -1.7425224781036377,
      "step": 2020
    },
    {
      "epoch": 0.37047175837211427,
      "grad_norm": 2.817849636077881,
      "learning_rate": 7.078037698778167e-05,
      "logits/chosen": -0.6864879131317139,
      "logits/rejected": -0.6057740449905396,
      "logps/chosen": -141.62677001953125,
      "logps/rejected": -132.47579956054688,
      "loss": 0.6105,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.20295250415802,
      "rewards/margins": 0.6523193717002869,
      "rewards/rejected": -1.8552719354629517,
      "step": 2030
    },
    {
      "epoch": 0.37229674240350397,
      "grad_norm": 3.8928213119506836,
      "learning_rate": 7.073125805857433e-05,
      "logits/chosen": -0.7242826223373413,
      "logits/rejected": -0.6608587503433228,
      "logps/chosen": -168.11727905273438,
      "logps/rejected": -164.53892517089844,
      "loss": 0.551,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.1739842891693115,
      "rewards/margins": 0.7154643535614014,
      "rewards/rejected": -1.8894487619400024,
      "step": 2040
    },
    {
      "epoch": 0.3741217264348937,
      "grad_norm": 5.284481525421143,
      "learning_rate": 7.068213912936699e-05,
      "logits/chosen": -0.6723490953445435,
      "logits/rejected": -0.5847961902618408,
      "logps/chosen": -180.9969940185547,
      "logps/rejected": -155.24496459960938,
      "loss": 0.7051,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -1.6675670146942139,
      "rewards/margins": 0.5392873287200928,
      "rewards/rejected": -2.2068543434143066,
      "step": 2050
    },
    {
      "epoch": 0.3759467104662834,
      "grad_norm": 3.6881179809570312,
      "learning_rate": 7.063302020015963e-05,
      "logits/chosen": -0.7014471888542175,
      "logits/rejected": -0.65160071849823,
      "logps/chosen": -157.70468139648438,
      "logps/rejected": -165.3306884765625,
      "loss": 0.5854,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.1845496892929077,
      "rewards/margins": 0.5571741461753845,
      "rewards/rejected": -1.7417237758636475,
      "step": 2060
    },
    {
      "epoch": 0.37777169449767317,
      "grad_norm": 3.6823413372039795,
      "learning_rate": 7.05839012709523e-05,
      "logits/chosen": -0.7931016087532043,
      "logits/rejected": -0.7230827212333679,
      "logps/chosen": -147.40420532226562,
      "logps/rejected": -136.96530151367188,
      "loss": 0.5579,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7050580978393555,
      "rewards/margins": 0.7100076079368591,
      "rewards/rejected": -1.4150656461715698,
      "step": 2070
    },
    {
      "epoch": 0.37959667852906287,
      "grad_norm": 2.00065541267395,
      "learning_rate": 7.053478234174496e-05,
      "logits/chosen": -0.7753702402114868,
      "logits/rejected": -0.7199608087539673,
      "logps/chosen": -145.70077514648438,
      "logps/rejected": -137.27755737304688,
      "loss": 0.6066,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.735059916973114,
      "rewards/margins": 0.5590074062347412,
      "rewards/rejected": -1.2940672636032104,
      "step": 2080
    },
    {
      "epoch": 0.3814216625604526,
      "grad_norm": 4.550923824310303,
      "learning_rate": 7.04856634125376e-05,
      "logits/chosen": -0.744698703289032,
      "logits/rejected": -0.6635082364082336,
      "logps/chosen": -167.85586547851562,
      "logps/rejected": -160.07723999023438,
      "loss": 0.521,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.39243024587631226,
      "rewards/margins": 0.9102054834365845,
      "rewards/rejected": -1.302635669708252,
      "step": 2090
    },
    {
      "epoch": 0.3832466465918423,
      "grad_norm": 7.856445789337158,
      "learning_rate": 7.043654448333026e-05,
      "logits/chosen": -0.7652761936187744,
      "logits/rejected": -0.6814361810684204,
      "logps/chosen": -172.15939331054688,
      "logps/rejected": -151.66543579101562,
      "loss": 0.5493,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.5952145457267761,
      "rewards/margins": 0.8248348236083984,
      "rewards/rejected": -1.4200494289398193,
      "step": 2100
    },
    {
      "epoch": 0.385071630623232,
      "grad_norm": 2.337808132171631,
      "learning_rate": 7.038742555412292e-05,
      "logits/chosen": -0.7994405627250671,
      "logits/rejected": -0.7180124521255493,
      "logps/chosen": -163.83499145507812,
      "logps/rejected": -143.91725158691406,
      "loss": 0.6785,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0157465934753418,
      "rewards/margins": 0.5374088287353516,
      "rewards/rejected": -1.5531551837921143,
      "step": 2110
    },
    {
      "epoch": 0.3868966146546218,
      "grad_norm": 3.2280352115631104,
      "learning_rate": 7.033830662491558e-05,
      "logits/chosen": -0.7876879572868347,
      "logits/rejected": -0.7051234841346741,
      "logps/chosen": -168.25807189941406,
      "logps/rejected": -153.13980102539062,
      "loss": 0.5985,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6729778051376343,
      "rewards/margins": 0.7206509113311768,
      "rewards/rejected": -1.3936288356781006,
      "step": 2120
    },
    {
      "epoch": 0.38872159868601147,
      "grad_norm": 2.0721545219421387,
      "learning_rate": 7.028918769570824e-05,
      "logits/chosen": -0.8093026876449585,
      "logits/rejected": -0.7062524557113647,
      "logps/chosen": -161.68832397460938,
      "logps/rejected": -151.7109375,
      "loss": 0.5126,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.8291182518005371,
      "rewards/margins": 1.0224049091339111,
      "rewards/rejected": -1.8515231609344482,
      "step": 2130
    },
    {
      "epoch": 0.3905465827174012,
      "grad_norm": 3.6517579555511475,
      "learning_rate": 7.02400687665009e-05,
      "logits/chosen": -0.7642693519592285,
      "logits/rejected": -0.7372549772262573,
      "logps/chosen": -147.83717346191406,
      "logps/rejected": -150.85330200195312,
      "loss": 0.5139,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7892304062843323,
      "rewards/margins": 0.8221237063407898,
      "rewards/rejected": -1.611354112625122,
      "step": 2140
    },
    {
      "epoch": 0.3923715667487909,
      "grad_norm": 2.02695894241333,
      "learning_rate": 7.019094983729355e-05,
      "logits/chosen": -0.8351947665214539,
      "logits/rejected": -0.804604709148407,
      "logps/chosen": -156.36593627929688,
      "logps/rejected": -159.41848754882812,
      "loss": 0.6916,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.7209380865097046,
      "rewards/margins": 0.5160990357398987,
      "rewards/rejected": -1.2370370626449585,
      "step": 2150
    },
    {
      "epoch": 0.3941965507801807,
      "grad_norm": 4.791823387145996,
      "learning_rate": 7.014183090808621e-05,
      "logits/chosen": -0.8132866621017456,
      "logits/rejected": -0.7670331597328186,
      "logps/chosen": -145.5638427734375,
      "logps/rejected": -134.85162353515625,
      "loss": 0.6015,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.9471440315246582,
      "rewards/margins": 0.5910729169845581,
      "rewards/rejected": -1.5382169485092163,
      "step": 2160
    },
    {
      "epoch": 0.3960215348115704,
      "grad_norm": 3.775686264038086,
      "learning_rate": 7.009271197887887e-05,
      "logits/chosen": -0.8299952745437622,
      "logits/rejected": -0.7705085873603821,
      "logps/chosen": -147.81912231445312,
      "logps/rejected": -124.9219741821289,
      "loss": 0.6003,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.6077287793159485,
      "rewards/margins": 0.6115895509719849,
      "rewards/rejected": -1.219318151473999,
      "step": 2170
    },
    {
      "epoch": 0.39784651884296013,
      "grad_norm": 6.497370719909668,
      "learning_rate": 7.004359304967153e-05,
      "logits/chosen": -0.7973647713661194,
      "logits/rejected": -0.7494107484817505,
      "logps/chosen": -163.65602111816406,
      "logps/rejected": -148.5999298095703,
      "loss": 0.6529,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.9164319038391113,
      "rewards/margins": 0.6313183903694153,
      "rewards/rejected": -1.5477502346038818,
      "step": 2180
    },
    {
      "epoch": 0.3996715028743498,
      "grad_norm": 2.6424150466918945,
      "learning_rate": 6.999447412046418e-05,
      "logits/chosen": -0.8390886187553406,
      "logits/rejected": -0.7700897455215454,
      "logps/chosen": -154.0325927734375,
      "logps/rejected": -141.79754638671875,
      "loss": 0.5372,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8420655131340027,
      "rewards/margins": 1.0651096105575562,
      "rewards/rejected": -1.907175064086914,
      "step": 2190
    },
    {
      "epoch": 0.4014964869057396,
      "grad_norm": 3.8603456020355225,
      "learning_rate": 6.994535519125683e-05,
      "logits/chosen": -0.8766493797302246,
      "logits/rejected": -0.8395746350288391,
      "logps/chosen": -135.9195556640625,
      "logps/rejected": -142.24600219726562,
      "loss": 0.6006,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8750762939453125,
      "rewards/margins": 0.7489724159240723,
      "rewards/rejected": -1.6240485906600952,
      "step": 2200
    },
    {
      "epoch": 0.4033214709371293,
      "grad_norm": 3.3976409435272217,
      "learning_rate": 6.98962362620495e-05,
      "logits/chosen": -0.877802848815918,
      "logits/rejected": -0.7910192608833313,
      "logps/chosen": -173.26206970214844,
      "logps/rejected": -149.3911590576172,
      "loss": 0.5277,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8992220163345337,
      "rewards/margins": 0.8584119081497192,
      "rewards/rejected": -1.7576338052749634,
      "step": 2210
    },
    {
      "epoch": 0.40514645496851903,
      "grad_norm": 3.2803735733032227,
      "learning_rate": 6.984711733284216e-05,
      "logits/chosen": -0.8493674993515015,
      "logits/rejected": -0.7777959108352661,
      "logps/chosen": -163.21432495117188,
      "logps/rejected": -145.54859924316406,
      "loss": 0.5391,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0781461000442505,
      "rewards/margins": 1.0771350860595703,
      "rewards/rejected": -2.1552810668945312,
      "step": 2220
    },
    {
      "epoch": 0.40697143899990873,
      "grad_norm": 4.521782398223877,
      "learning_rate": 6.97979984036348e-05,
      "logits/chosen": -0.8250288963317871,
      "logits/rejected": -0.7280393242835999,
      "logps/chosen": -157.4234619140625,
      "logps/rejected": -141.69168090820312,
      "loss": 0.6144,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.9472888112068176,
      "rewards/margins": 0.7482895255088806,
      "rewards/rejected": -1.6955783367156982,
      "step": 2230
    },
    {
      "epoch": 0.4087964230312985,
      "grad_norm": 5.782075881958008,
      "learning_rate": 6.974887947442746e-05,
      "logits/chosen": -0.8588045239448547,
      "logits/rejected": -0.8198848962783813,
      "logps/chosen": -145.18362426757812,
      "logps/rejected": -137.3046875,
      "loss": 0.6061,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6781134605407715,
      "rewards/margins": 0.8293653726577759,
      "rewards/rejected": -1.5074787139892578,
      "step": 2240
    },
    {
      "epoch": 0.4106214070626882,
      "grad_norm": 3.5862669944763184,
      "learning_rate": 6.969976054522013e-05,
      "logits/chosen": -0.8527497053146362,
      "logits/rejected": -0.7463264465332031,
      "logps/chosen": -157.69570922851562,
      "logps/rejected": -134.9937744140625,
      "loss": 0.5709,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7610469460487366,
      "rewards/margins": 0.7924659848213196,
      "rewards/rejected": -1.5535129308700562,
      "step": 2250
    },
    {
      "epoch": 0.41244639109407794,
      "grad_norm": 4.372931957244873,
      "learning_rate": 6.965064161601277e-05,
      "logits/chosen": -0.8104871511459351,
      "logits/rejected": -0.7646421790122986,
      "logps/chosen": -156.64230346679688,
      "logps/rejected": -161.79840087890625,
      "loss": 0.527,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7980782389640808,
      "rewards/margins": 0.8566657304763794,
      "rewards/rejected": -1.6547439098358154,
      "step": 2260
    },
    {
      "epoch": 0.41427137512546763,
      "grad_norm": 3.324596881866455,
      "learning_rate": 6.960152268680543e-05,
      "logits/chosen": -0.8382048606872559,
      "logits/rejected": -0.7276251316070557,
      "logps/chosen": -155.77316284179688,
      "logps/rejected": -133.61094665527344,
      "loss": 0.5695,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.0940711498260498,
      "rewards/margins": 0.6468555331230164,
      "rewards/rejected": -1.740926742553711,
      "step": 2270
    },
    {
      "epoch": 0.4160963591568574,
      "grad_norm": 2.392153263092041,
      "learning_rate": 6.955240375759809e-05,
      "logits/chosen": -0.8448274731636047,
      "logits/rejected": -0.7846304178237915,
      "logps/chosen": -137.70877075195312,
      "logps/rejected": -127.33741760253906,
      "loss": 0.5305,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8513280749320984,
      "rewards/margins": 0.8584526777267456,
      "rewards/rejected": -1.7097809314727783,
      "step": 2280
    },
    {
      "epoch": 0.4179213431882471,
      "grad_norm": 3.8832056522369385,
      "learning_rate": 6.950328482839075e-05,
      "logits/chosen": -0.8640149831771851,
      "logits/rejected": -0.771858811378479,
      "logps/chosen": -166.9089813232422,
      "logps/rejected": -147.2809600830078,
      "loss": 0.5301,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.9787343144416809,
      "rewards/margins": 0.7992730140686035,
      "rewards/rejected": -1.7780075073242188,
      "step": 2290
    },
    {
      "epoch": 0.41974632721963684,
      "grad_norm": 2.9325084686279297,
      "learning_rate": 6.94541658991834e-05,
      "logits/chosen": -0.8513994216918945,
      "logits/rejected": -0.8141242861747742,
      "logps/chosen": -149.9945831298828,
      "logps/rejected": -149.70074462890625,
      "loss": 0.5544,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.0628560781478882,
      "rewards/margins": 0.6748560667037964,
      "rewards/rejected": -1.7377121448516846,
      "step": 2300
    },
    {
      "epoch": 0.42157131125102654,
      "grad_norm": 3.7165486812591553,
      "learning_rate": 6.940504696997606e-05,
      "logits/chosen": -0.8490416407585144,
      "logits/rejected": -0.8115205764770508,
      "logps/chosen": -152.98562622070312,
      "logps/rejected": -139.216064453125,
      "loss": 0.6307,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.9388151168823242,
      "rewards/margins": 0.7895864248275757,
      "rewards/rejected": -1.7284014225006104,
      "step": 2310
    },
    {
      "epoch": 0.4233962952824163,
      "grad_norm": 5.202849864959717,
      "learning_rate": 6.935592804076872e-05,
      "logits/chosen": -0.8763043284416199,
      "logits/rejected": -0.8278667330741882,
      "logps/chosen": -145.46609497070312,
      "logps/rejected": -139.19931030273438,
      "loss": 0.5676,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.724408745765686,
      "rewards/margins": 0.722481906414032,
      "rewards/rejected": -1.4468907117843628,
      "step": 2320
    },
    {
      "epoch": 0.425221279313806,
      "grad_norm": 3.256328582763672,
      "learning_rate": 6.930680911156138e-05,
      "logits/chosen": -0.8579343557357788,
      "logits/rejected": -0.8151785135269165,
      "logps/chosen": -149.21871948242188,
      "logps/rejected": -126.8486099243164,
      "loss": 0.6263,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.5523839592933655,
      "rewards/margins": 0.5281234383583069,
      "rewards/rejected": -1.080507516860962,
      "step": 2330
    },
    {
      "epoch": 0.42704626334519574,
      "grad_norm": 1.800583839416504,
      "learning_rate": 6.926260207527477e-05,
      "logits/chosen": -0.8325921893119812,
      "logits/rejected": -0.8049536943435669,
      "logps/chosen": -148.08944702148438,
      "logps/rejected": -153.837158203125,
      "loss": 0.5387,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.3253710865974426,
      "rewards/margins": 1.0078104734420776,
      "rewards/rejected": -1.333181619644165,
      "step": 2340
    },
    {
      "epoch": 0.42887124737658544,
      "grad_norm": 2.104466676712036,
      "learning_rate": 6.921348314606743e-05,
      "logits/chosen": -0.8242846727371216,
      "logits/rejected": -0.763846755027771,
      "logps/chosen": -152.1842041015625,
      "logps/rejected": -145.43399047851562,
      "loss": 0.526,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.297197163105011,
      "rewards/margins": 1.0456210374832153,
      "rewards/rejected": -1.342818260192871,
      "step": 2350
    },
    {
      "epoch": 0.4306962314079752,
      "grad_norm": 1.6332001686096191,
      "learning_rate": 6.916436421686007e-05,
      "logits/chosen": -0.8008174896240234,
      "logits/rejected": -0.7491092085838318,
      "logps/chosen": -141.65371704101562,
      "logps/rejected": -143.28585815429688,
      "loss": 0.5151,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.6502764821052551,
      "rewards/margins": 1.1024425029754639,
      "rewards/rejected": -1.7527191638946533,
      "step": 2360
    },
    {
      "epoch": 0.4325212154393649,
      "grad_norm": 3.712283134460449,
      "learning_rate": 6.911524528765274e-05,
      "logits/chosen": -0.800193190574646,
      "logits/rejected": -0.7159596681594849,
      "logps/chosen": -150.42974853515625,
      "logps/rejected": -131.04347229003906,
      "loss": 0.4302,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7729198336601257,
      "rewards/margins": 1.2637135982513428,
      "rewards/rejected": -2.036633014678955,
      "step": 2370
    },
    {
      "epoch": 0.43434619947075465,
      "grad_norm": 5.661199569702148,
      "learning_rate": 6.906612635844539e-05,
      "logits/chosen": -0.8326390981674194,
      "logits/rejected": -0.7386638522148132,
      "logps/chosen": -160.70748901367188,
      "logps/rejected": -140.42752075195312,
      "loss": 0.6232,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.2564303874969482,
      "rewards/margins": 0.7632420659065247,
      "rewards/rejected": -2.019672393798828,
      "step": 2380
    },
    {
      "epoch": 0.43617118350214434,
      "grad_norm": 3.3077073097229004,
      "learning_rate": 6.901700742923804e-05,
      "logits/chosen": -0.7938652038574219,
      "logits/rejected": -0.681537926197052,
      "logps/chosen": -180.6600799560547,
      "logps/rejected": -139.37318420410156,
      "loss": 0.5016,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.364089012145996,
      "rewards/margins": 1.1464879512786865,
      "rewards/rejected": -2.5105769634246826,
      "step": 2390
    },
    {
      "epoch": 0.4379961675335341,
      "grad_norm": 5.9094557762146,
      "learning_rate": 6.89678885000307e-05,
      "logits/chosen": -0.757411003112793,
      "logits/rejected": -0.7362629175186157,
      "logps/chosen": -152.25721740722656,
      "logps/rejected": -153.56094360351562,
      "loss": 0.5752,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.3585337400436401,
      "rewards/margins": 0.9567302465438843,
      "rewards/rejected": -2.3152642250061035,
      "step": 2400
    },
    {
      "epoch": 0.4398211515649238,
      "grad_norm": 2.7655298709869385,
      "learning_rate": 6.891876957082336e-05,
      "logits/chosen": -0.840779185295105,
      "logits/rejected": -0.7785676717758179,
      "logps/chosen": -157.7557373046875,
      "logps/rejected": -142.64541625976562,
      "loss": 0.5565,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.110968828201294,
      "rewards/margins": 0.8704075813293457,
      "rewards/rejected": -1.9813764095306396,
      "step": 2410
    },
    {
      "epoch": 0.44164613559631355,
      "grad_norm": 3.304550886154175,
      "learning_rate": 6.886965064161602e-05,
      "logits/chosen": -0.7549672722816467,
      "logits/rejected": -0.7051298022270203,
      "logps/chosen": -141.2522430419922,
      "logps/rejected": -139.53411865234375,
      "loss": 0.5305,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.08201003074646,
      "rewards/margins": 1.2212955951690674,
      "rewards/rejected": -2.3033058643341064,
      "step": 2420
    },
    {
      "epoch": 0.44347111962770325,
      "grad_norm": 2.145613670349121,
      "learning_rate": 6.882053171240868e-05,
      "logits/chosen": -0.8355041742324829,
      "logits/rejected": -0.8253381848335266,
      "logps/chosen": -155.2613983154297,
      "logps/rejected": -162.62550354003906,
      "loss": 0.4961,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7647595405578613,
      "rewards/margins": 1.0706205368041992,
      "rewards/rejected": -1.835379958152771,
      "step": 2430
    },
    {
      "epoch": 0.445296103659093,
      "grad_norm": 3.5612640380859375,
      "learning_rate": 6.877141278320133e-05,
      "logits/chosen": -0.8706525564193726,
      "logits/rejected": -0.8291398882865906,
      "logps/chosen": -150.66294860839844,
      "logps/rejected": -147.26901245117188,
      "loss": 0.5873,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6189543008804321,
      "rewards/margins": 0.8622884750366211,
      "rewards/rejected": -1.4812428951263428,
      "step": 2440
    },
    {
      "epoch": 0.4471210876904827,
      "grad_norm": 4.447732448577881,
      "learning_rate": 6.872229385399399e-05,
      "logits/chosen": -0.8978391885757446,
      "logits/rejected": -0.8729303479194641,
      "logps/chosen": -142.08799743652344,
      "logps/rejected": -142.14718627929688,
      "loss": 0.581,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6270361542701721,
      "rewards/margins": 0.8801787495613098,
      "rewards/rejected": -1.507214903831482,
      "step": 2450
    },
    {
      "epoch": 0.44894607172187245,
      "grad_norm": 4.550269603729248,
      "learning_rate": 6.867317492478665e-05,
      "logits/chosen": -0.9518579244613647,
      "logits/rejected": -0.8691199421882629,
      "logps/chosen": -168.66412353515625,
      "logps/rejected": -139.74282836914062,
      "loss": 0.6903,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.2870997488498688,
      "rewards/margins": 0.48428279161453247,
      "rewards/rejected": -0.7713824510574341,
      "step": 2460
    },
    {
      "epoch": 0.45077105575326215,
      "grad_norm": 2.5650792121887207,
      "learning_rate": 6.862405599557929e-05,
      "logits/chosen": -0.9041637182235718,
      "logits/rejected": -0.8320335149765015,
      "logps/chosen": -157.25440979003906,
      "logps/rejected": -131.0377655029297,
      "loss": 0.6073,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.012497354298830032,
      "rewards/margins": 0.6502869725227356,
      "rewards/rejected": -0.6627843379974365,
      "step": 2470
    },
    {
      "epoch": 0.4525960397846519,
      "grad_norm": 3.3693177700042725,
      "learning_rate": 6.857493706637196e-05,
      "logits/chosen": -0.910889744758606,
      "logits/rejected": -0.874665379524231,
      "logps/chosen": -147.54591369628906,
      "logps/rejected": -143.74415588378906,
      "loss": 0.5586,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.09480337053537369,
      "rewards/margins": 0.6528211832046509,
      "rewards/rejected": -0.7476245760917664,
      "step": 2480
    },
    {
      "epoch": 0.4544210238160416,
      "grad_norm": 3.116755247116089,
      "learning_rate": 6.852581813716462e-05,
      "logits/chosen": -0.8749306797981262,
      "logits/rejected": -0.8482123613357544,
      "logps/chosen": -142.66384887695312,
      "logps/rejected": -139.9083709716797,
      "loss": 0.5183,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.26146987080574036,
      "rewards/margins": 0.8935893774032593,
      "rewards/rejected": -1.1550593376159668,
      "step": 2490
    },
    {
      "epoch": 0.45624600784743136,
      "grad_norm": 2.921968698501587,
      "learning_rate": 6.847669920795727e-05,
      "logits/chosen": -0.9409860372543335,
      "logits/rejected": -0.878325343132019,
      "logps/chosen": -145.60153198242188,
      "logps/rejected": -121.7262954711914,
      "loss": 0.5001,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6236801147460938,
      "rewards/margins": 0.776584267616272,
      "rewards/rejected": -1.4002643823623657,
      "step": 2500
    },
    {
      "epoch": 0.45807099187882105,
      "grad_norm": 5.023683547973633,
      "learning_rate": 6.842758027874992e-05,
      "logits/chosen": -0.8661120533943176,
      "logits/rejected": -0.7650720477104187,
      "logps/chosen": -175.25270080566406,
      "logps/rejected": -141.76596069335938,
      "loss": 0.5664,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6806480884552002,
      "rewards/margins": 1.161165475845337,
      "rewards/rejected": -1.8418136835098267,
      "step": 2510
    },
    {
      "epoch": 0.4598959759102108,
      "grad_norm": 3.1650280952453613,
      "learning_rate": 6.83784613495426e-05,
      "logits/chosen": -0.8684929609298706,
      "logits/rejected": -0.7807878255844116,
      "logps/chosen": -173.96572875976562,
      "logps/rejected": -148.66552734375,
      "loss": 0.5503,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.39605194330215454,
      "rewards/margins": 0.9696230888366699,
      "rewards/rejected": -1.3656749725341797,
      "step": 2520
    },
    {
      "epoch": 0.4617209599416005,
      "grad_norm": 3.9429194927215576,
      "learning_rate": 6.832934242033524e-05,
      "logits/chosen": -0.8895424604415894,
      "logits/rejected": -0.8591077923774719,
      "logps/chosen": -157.38449096679688,
      "logps/rejected": -147.00112915039062,
      "loss": 0.6451,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.28732365369796753,
      "rewards/margins": 0.7989647388458252,
      "rewards/rejected": -1.086288332939148,
      "step": 2530
    },
    {
      "epoch": 0.46354594397299026,
      "grad_norm": 1.376444697380066,
      "learning_rate": 6.82802234911279e-05,
      "logits/chosen": -0.8807151913642883,
      "logits/rejected": -0.8223023414611816,
      "logps/chosen": -150.0554962158203,
      "logps/rejected": -137.3962860107422,
      "loss": 0.5844,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.22271642088890076,
      "rewards/margins": 0.8039361238479614,
      "rewards/rejected": -1.0266525745391846,
      "step": 2540
    },
    {
      "epoch": 0.46537092800437996,
      "grad_norm": 3.5461418628692627,
      "learning_rate": 6.823110456192056e-05,
      "logits/chosen": -0.9415262341499329,
      "logits/rejected": -0.8723637461662292,
      "logps/chosen": -132.78855895996094,
      "logps/rejected": -125.02349853515625,
      "loss": 0.5106,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.15154795348644257,
      "rewards/margins": 0.7942535877227783,
      "rewards/rejected": -0.9458014369010925,
      "step": 2550
    },
    {
      "epoch": 0.4671959120357697,
      "grad_norm": 4.567718029022217,
      "learning_rate": 6.818198563271321e-05,
      "logits/chosen": -0.8953167200088501,
      "logits/rejected": -0.825637698173523,
      "logps/chosen": -141.8394775390625,
      "logps/rejected": -126.2165756225586,
      "loss": 0.5759,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6143974661827087,
      "rewards/margins": 0.8752943873405457,
      "rewards/rejected": -1.4896918535232544,
      "step": 2560
    },
    {
      "epoch": 0.4690208960671594,
      "grad_norm": 2.179732084274292,
      "learning_rate": 6.813286670350587e-05,
      "logits/chosen": -0.8821830749511719,
      "logits/rejected": -0.8674200773239136,
      "logps/chosen": -145.43887329101562,
      "logps/rejected": -158.10574340820312,
      "loss": 0.746,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.6091033816337585,
      "rewards/margins": 0.6224735975265503,
      "rewards/rejected": -1.2315770387649536,
      "step": 2570
    },
    {
      "epoch": 0.47084588009854916,
      "grad_norm": 1.8813679218292236,
      "learning_rate": 6.808374777429853e-05,
      "logits/chosen": -0.9428645968437195,
      "logits/rejected": -0.8792430758476257,
      "logps/chosen": -141.4347381591797,
      "logps/rejected": -131.90243530273438,
      "loss": 0.5064,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.23773625493049622,
      "rewards/margins": 0.8966557383537292,
      "rewards/rejected": -1.1343920230865479,
      "step": 2580
    },
    {
      "epoch": 0.47267086412993886,
      "grad_norm": 2.0409560203552246,
      "learning_rate": 6.803462884509119e-05,
      "logits/chosen": -0.9400848150253296,
      "logits/rejected": -0.9010322690010071,
      "logps/chosen": -136.62869262695312,
      "logps/rejected": -126.34151458740234,
      "loss": 0.5479,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.13357599079608917,
      "rewards/margins": 0.6455353498458862,
      "rewards/rejected": -0.7791115045547485,
      "step": 2590
    },
    {
      "epoch": 0.4744958481613286,
      "grad_norm": 2.5400311946868896,
      "learning_rate": 6.798550991588384e-05,
      "logits/chosen": -0.9740096926689148,
      "logits/rejected": -0.9469231367111206,
      "logps/chosen": -141.73696899414062,
      "logps/rejected": -135.95095825195312,
      "loss": 0.5876,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.13355758786201477,
      "rewards/margins": 0.597264289855957,
      "rewards/rejected": -0.7308217883110046,
      "step": 2600
    },
    {
      "epoch": 0.4763208321927183,
      "grad_norm": 1.5530807971954346,
      "learning_rate": 6.79363909866765e-05,
      "logits/chosen": -1.033440351486206,
      "logits/rejected": -0.9691177606582642,
      "logps/chosen": -147.9246063232422,
      "logps/rejected": -141.10464477539062,
      "loss": 0.5125,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.12448718398809433,
      "rewards/margins": 0.9584700465202332,
      "rewards/rejected": -0.8339828252792358,
      "step": 2610
    },
    {
      "epoch": 0.47814581622410807,
      "grad_norm": 2.8742353916168213,
      "learning_rate": 6.788727205746915e-05,
      "logits/chosen": -0.9570051431655884,
      "logits/rejected": -0.8864345550537109,
      "logps/chosen": -158.6227264404297,
      "logps/rejected": -136.1418914794922,
      "loss": 0.5333,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.19500023126602173,
      "rewards/margins": 0.9562126398086548,
      "rewards/rejected": -1.1512128114700317,
      "step": 2620
    },
    {
      "epoch": 0.47997080025549776,
      "grad_norm": 3.6774723529815674,
      "learning_rate": 6.783815312826182e-05,
      "logits/chosen": -1.0035120248794556,
      "logits/rejected": -0.9639968872070312,
      "logps/chosen": -158.56700134277344,
      "logps/rejected": -149.53408813476562,
      "loss": 0.5967,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.6186968684196472,
      "rewards/margins": 0.8239544630050659,
      "rewards/rejected": -1.4426512718200684,
      "step": 2630
    },
    {
      "epoch": 0.48179578428688746,
      "grad_norm": 2.5342977046966553,
      "learning_rate": 6.778903419905446e-05,
      "logits/chosen": -1.0502026081085205,
      "logits/rejected": -0.9759372472763062,
      "logps/chosen": -165.4445343017578,
      "logps/rejected": -143.31198120117188,
      "loss": 0.5558,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.5110547542572021,
      "rewards/margins": 1.0200951099395752,
      "rewards/rejected": -1.5311496257781982,
      "step": 2640
    },
    {
      "epoch": 0.4836207683182772,
      "grad_norm": 2.810842752456665,
      "learning_rate": 6.773991526984712e-05,
      "logits/chosen": -1.0459671020507812,
      "logits/rejected": -0.9878195524215698,
      "logps/chosen": -170.5524444580078,
      "logps/rejected": -154.50845336914062,
      "loss": 0.5254,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.47565117478370667,
      "rewards/margins": 0.8918360471725464,
      "rewards/rejected": -1.3674873113632202,
      "step": 2650
    },
    {
      "epoch": 0.4854457523496669,
      "grad_norm": 4.64189338684082,
      "learning_rate": 6.769079634063979e-05,
      "logits/chosen": -1.0494482517242432,
      "logits/rejected": -1.028817892074585,
      "logps/chosen": -146.93698120117188,
      "logps/rejected": -151.885498046875,
      "loss": 0.5868,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6689031720161438,
      "rewards/margins": 0.7568904161453247,
      "rewards/rejected": -1.4257936477661133,
      "step": 2660
    },
    {
      "epoch": 0.48727073638105667,
      "grad_norm": 6.189083099365234,
      "learning_rate": 6.764167741143243e-05,
      "logits/chosen": -1.0415252447128296,
      "logits/rejected": -1.0279672145843506,
      "logps/chosen": -168.20162963867188,
      "logps/rejected": -166.73353576660156,
      "loss": 0.6,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.9023321270942688,
      "rewards/margins": 0.7977403402328491,
      "rewards/rejected": -1.7000725269317627,
      "step": 2670
    },
    {
      "epoch": 0.48909572041244637,
      "grad_norm": 4.032539367675781,
      "learning_rate": 6.759255848222509e-05,
      "logits/chosen": -1.002913236618042,
      "logits/rejected": -0.9360960721969604,
      "logps/chosen": -152.29542541503906,
      "logps/rejected": -130.00694274902344,
      "loss": 0.5266,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.8331254720687866,
      "rewards/margins": 0.8202918171882629,
      "rewards/rejected": -1.6534173488616943,
      "step": 2680
    },
    {
      "epoch": 0.4909207044438361,
      "grad_norm": 2.473212242126465,
      "learning_rate": 6.754343955301775e-05,
      "logits/chosen": -1.0034581422805786,
      "logits/rejected": -0.9196680784225464,
      "logps/chosen": -177.86016845703125,
      "logps/rejected": -150.07882690429688,
      "loss": 0.4491,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.7780932784080505,
      "rewards/margins": 1.134939432144165,
      "rewards/rejected": -1.9130327701568604,
      "step": 2690
    },
    {
      "epoch": 0.4927456884752258,
      "grad_norm": 3.9270145893096924,
      "learning_rate": 6.749432062381041e-05,
      "logits/chosen": -1.0029146671295166,
      "logits/rejected": -0.9322880506515503,
      "logps/chosen": -172.5470428466797,
      "logps/rejected": -153.72080993652344,
      "loss": 0.5817,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8282661437988281,
      "rewards/margins": 1.067096471786499,
      "rewards/rejected": -1.8953624963760376,
      "step": 2700
    },
    {
      "epoch": 0.49457067250661557,
      "grad_norm": 4.532373905181885,
      "learning_rate": 6.744520169460307e-05,
      "logits/chosen": -0.9014407396316528,
      "logits/rejected": -0.8929572105407715,
      "logps/chosen": -153.0520477294922,
      "logps/rejected": -161.4816436767578,
      "loss": 0.6299,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8393187522888184,
      "rewards/margins": 0.7882369756698608,
      "rewards/rejected": -1.6275558471679688,
      "step": 2710
    },
    {
      "epoch": 0.49639565653800527,
      "grad_norm": 4.735689640045166,
      "learning_rate": 6.739608276539572e-05,
      "logits/chosen": -0.9001275897026062,
      "logits/rejected": -0.8923546075820923,
      "logps/chosen": -161.94302368164062,
      "logps/rejected": -157.9463653564453,
      "loss": 0.6781,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.8570762872695923,
      "rewards/margins": 0.7152725458145142,
      "rewards/rejected": -1.5723488330841064,
      "step": 2720
    },
    {
      "epoch": 0.498220640569395,
      "grad_norm": 2.223247766494751,
      "learning_rate": 6.734696383618837e-05,
      "logits/chosen": -0.9395328760147095,
      "logits/rejected": -0.881432056427002,
      "logps/chosen": -135.54222106933594,
      "logps/rejected": -122.72792053222656,
      "loss": 0.4596,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.5965067744255066,
      "rewards/margins": 1.0853573083877563,
      "rewards/rejected": -1.6818640232086182,
      "step": 2730
    },
    {
      "epoch": 0.5000456246007847,
      "grad_norm": 2.8643898963928223,
      "learning_rate": 6.729784490698104e-05,
      "logits/chosen": -0.896510124206543,
      "logits/rejected": -0.8233087658882141,
      "logps/chosen": -176.44915771484375,
      "logps/rejected": -149.9179229736328,
      "loss": 0.5491,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.5176440477371216,
      "rewards/margins": 0.9484155774116516,
      "rewards/rejected": -1.466059684753418,
      "step": 2740
    },
    {
      "epoch": 0.5018706086321745,
      "grad_norm": 3.4421496391296387,
      "learning_rate": 6.72487259777737e-05,
      "logits/chosen": -0.8752549886703491,
      "logits/rejected": -0.8487205505371094,
      "logps/chosen": -151.2686767578125,
      "logps/rejected": -150.23907470703125,
      "loss": 0.6331,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.6276568174362183,
      "rewards/margins": 0.6931061148643494,
      "rewards/rejected": -1.3207629919052124,
      "step": 2750
    },
    {
      "epoch": 0.5036955926635642,
      "grad_norm": 2.526646852493286,
      "learning_rate": 6.719960704856634e-05,
      "logits/chosen": -0.9215842485427856,
      "logits/rejected": -0.9040610194206238,
      "logps/chosen": -156.01016235351562,
      "logps/rejected": -153.0679168701172,
      "loss": 0.6194,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.30435502529144287,
      "rewards/margins": 0.5523614883422852,
      "rewards/rejected": -0.856716513633728,
      "step": 2760
    },
    {
      "epoch": 0.5055205766949539,
      "grad_norm": 2.744198799133301,
      "learning_rate": 6.715048811935901e-05,
      "logits/chosen": -0.9686952829360962,
      "logits/rejected": -0.9395656585693359,
      "logps/chosen": -127.44734954833984,
      "logps/rejected": -139.11961364746094,
      "loss": 0.4037,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": 0.1143621951341629,
      "rewards/margins": 1.124981164932251,
      "rewards/rejected": -1.0106189250946045,
      "step": 2770
    },
    {
      "epoch": 0.5073455607263436,
      "grad_norm": 3.318638324737549,
      "learning_rate": 6.710136919015166e-05,
      "logits/chosen": -0.9634581804275513,
      "logits/rejected": -0.880643367767334,
      "logps/chosen": -160.99359130859375,
      "logps/rejected": -123.5257339477539,
      "loss": 0.5401,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.42832231521606445,
      "rewards/margins": 0.8781615495681763,
      "rewards/rejected": -1.3064839839935303,
      "step": 2780
    },
    {
      "epoch": 0.5091705447577334,
      "grad_norm": 3.2029881477355957,
      "learning_rate": 6.705225026094431e-05,
      "logits/chosen": -0.949539840221405,
      "logits/rejected": -0.9000434875488281,
      "logps/chosen": -162.0643310546875,
      "logps/rejected": -156.711669921875,
      "loss": 0.5833,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6421798467636108,
      "rewards/margins": 0.9490154385566711,
      "rewards/rejected": -1.5911952257156372,
      "step": 2790
    },
    {
      "epoch": 0.5109955287891231,
      "grad_norm": 4.850387096405029,
      "learning_rate": 6.700313133173697e-05,
      "logits/chosen": -0.9345097541809082,
      "logits/rejected": -0.8391826748847961,
      "logps/chosen": -158.85011291503906,
      "logps/rejected": -141.4380340576172,
      "loss": 0.4882,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2748032808303833,
      "rewards/margins": 1.0664188861846924,
      "rewards/rejected": -2.3412222862243652,
      "step": 2800
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 3.0521152019500732,
      "learning_rate": 6.695401240252963e-05,
      "logits/chosen": -1.0337927341461182,
      "logits/rejected": -0.9521730542182922,
      "logps/chosen": -161.88601684570312,
      "logps/rejected": -145.83663940429688,
      "loss": 0.5845,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.9586694240570068,
      "rewards/margins": 0.9049016833305359,
      "rewards/rejected": -2.8635714054107666,
      "step": 2810
    },
    {
      "epoch": 0.5146454968519025,
      "grad_norm": 2.500335216522217,
      "learning_rate": 6.690489347332229e-05,
      "logits/chosen": -1.0065202713012695,
      "logits/rejected": -0.9687114953994751,
      "logps/chosen": -162.39105224609375,
      "logps/rejected": -153.8097381591797,
      "loss": 0.5052,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.3801640272140503,
      "rewards/margins": 1.0105077028274536,
      "rewards/rejected": -2.390671730041504,
      "step": 2820
    },
    {
      "epoch": 0.5164704808832923,
      "grad_norm": 3.977242946624756,
      "learning_rate": 6.685577454411494e-05,
      "logits/chosen": -1.0537065267562866,
      "logits/rejected": -0.9985259771347046,
      "logps/chosen": -165.90736389160156,
      "logps/rejected": -152.77243041992188,
      "loss": 0.4991,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6835947036743164,
      "rewards/margins": 1.1982421875,
      "rewards/rejected": -2.8818368911743164,
      "step": 2830
    },
    {
      "epoch": 0.518295464914682,
      "grad_norm": 4.006844520568848,
      "learning_rate": 6.68066556149076e-05,
      "logits/chosen": -1.0605722665786743,
      "logits/rejected": -1.0406639575958252,
      "logps/chosen": -150.52450561523438,
      "logps/rejected": -160.03201293945312,
      "loss": 0.456,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.4539450407028198,
      "rewards/margins": 1.4590860605239868,
      "rewards/rejected": -2.9130311012268066,
      "step": 2840
    },
    {
      "epoch": 0.5201204489460717,
      "grad_norm": 2.44732403755188,
      "learning_rate": 6.675753668570026e-05,
      "logits/chosen": -1.0844614505767822,
      "logits/rejected": -1.0529818534851074,
      "logps/chosen": -161.42306518554688,
      "logps/rejected": -168.51193237304688,
      "loss": 0.4808,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5288511514663696,
      "rewards/margins": 1.3979549407958984,
      "rewards/rejected": -2.9268059730529785,
      "step": 2850
    },
    {
      "epoch": 0.5219454329774614,
      "grad_norm": 5.208555698394775,
      "learning_rate": 6.670841775649292e-05,
      "logits/chosen": -1.0734063386917114,
      "logits/rejected": -1.0360968112945557,
      "logps/chosen": -158.119140625,
      "logps/rejected": -154.9300537109375,
      "loss": 0.5114,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6147193908691406,
      "rewards/margins": 1.277867317199707,
      "rewards/rejected": -2.8925867080688477,
      "step": 2860
    },
    {
      "epoch": 0.5237704170088512,
      "grad_norm": 3.6288156509399414,
      "learning_rate": 6.665929882728556e-05,
      "logits/chosen": -1.0619803667068481,
      "logits/rejected": -1.01804518699646,
      "logps/chosen": -155.9197998046875,
      "logps/rejected": -143.08335876464844,
      "loss": 0.5271,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.0319863557815552,
      "rewards/margins": 1.2616510391235352,
      "rewards/rejected": -2.29363751411438,
      "step": 2870
    },
    {
      "epoch": 0.5255954010402409,
      "grad_norm": 2.246211051940918,
      "learning_rate": 6.661017989807823e-05,
      "logits/chosen": -1.040245771408081,
      "logits/rejected": -0.9272316098213196,
      "logps/chosen": -164.27162170410156,
      "logps/rejected": -139.8960418701172,
      "loss": 0.4811,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6209157109260559,
      "rewards/margins": 1.3248274326324463,
      "rewards/rejected": -1.945743203163147,
      "step": 2880
    },
    {
      "epoch": 0.5274203850716306,
      "grad_norm": 4.042184829711914,
      "learning_rate": 6.656106096887089e-05,
      "logits/chosen": -1.0288927555084229,
      "logits/rejected": -0.9516857862472534,
      "logps/chosen": -160.031982421875,
      "logps/rejected": -147.41708374023438,
      "loss": 0.4281,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5379127860069275,
      "rewards/margins": 1.525409460067749,
      "rewards/rejected": -2.0633223056793213,
      "step": 2890
    },
    {
      "epoch": 0.5292453691030203,
      "grad_norm": 3.539883852005005,
      "learning_rate": 6.651194203966353e-05,
      "logits/chosen": -1.0076406002044678,
      "logits/rejected": -0.9676336050033569,
      "logps/chosen": -137.71084594726562,
      "logps/rejected": -142.29891967773438,
      "loss": 0.5612,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.8415924906730652,
      "rewards/margins": 1.2342078685760498,
      "rewards/rejected": -2.0758004188537598,
      "step": 2900
    },
    {
      "epoch": 0.5310703531344101,
      "grad_norm": 3.3136253356933594,
      "learning_rate": 6.646282311045619e-05,
      "logits/chosen": -0.9641499519348145,
      "logits/rejected": -0.9335090517997742,
      "logps/chosen": -162.58209228515625,
      "logps/rejected": -151.49679565429688,
      "loss": 0.663,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -1.3428103923797607,
      "rewards/margins": 0.6230350136756897,
      "rewards/rejected": -1.9658454656600952,
      "step": 2910
    },
    {
      "epoch": 0.5328953371657998,
      "grad_norm": 3.4753031730651855,
      "learning_rate": 6.641370418124885e-05,
      "logits/chosen": -0.9764161109924316,
      "logits/rejected": -0.8530339002609253,
      "logps/chosen": -168.0338592529297,
      "logps/rejected": -134.72103881835938,
      "loss": 0.5083,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3442274332046509,
      "rewards/margins": 1.3702709674835205,
      "rewards/rejected": -2.7144980430603027,
      "step": 2920
    },
    {
      "epoch": 0.5347203211971895,
      "grad_norm": 4.210771560668945,
      "learning_rate": 6.636458525204151e-05,
      "logits/chosen": -0.9281541109085083,
      "logits/rejected": -0.8801987767219543,
      "logps/chosen": -147.688720703125,
      "logps/rejected": -143.92880249023438,
      "loss": 0.5533,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.114788293838501,
      "rewards/margins": 0.8779282569885254,
      "rewards/rejected": -2.9927163124084473,
      "step": 2930
    },
    {
      "epoch": 0.5365453052285792,
      "grad_norm": 2.2607879638671875,
      "learning_rate": 6.631546632283417e-05,
      "logits/chosen": -1.0131481885910034,
      "logits/rejected": -0.9388099908828735,
      "logps/chosen": -172.74502563476562,
      "logps/rejected": -159.58877563476562,
      "loss": 0.5454,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.7697875499725342,
      "rewards/margins": 1.0774791240692139,
      "rewards/rejected": -2.847266912460327,
      "step": 2940
    },
    {
      "epoch": 0.538370289259969,
      "grad_norm": 2.7131900787353516,
      "learning_rate": 6.626634739362682e-05,
      "logits/chosen": -0.9403101205825806,
      "logits/rejected": -0.9272802472114563,
      "logps/chosen": -144.4773712158203,
      "logps/rejected": -155.68975830078125,
      "loss": 0.69,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -2.10227632522583,
      "rewards/margins": 0.7666680216789246,
      "rewards/rejected": -2.8689446449279785,
      "step": 2950
    },
    {
      "epoch": 0.5401952732913587,
      "grad_norm": 5.628412246704102,
      "learning_rate": 6.621722846441948e-05,
      "logits/chosen": -1.0004783868789673,
      "logits/rejected": -0.909182071685791,
      "logps/chosen": -169.287353515625,
      "logps/rejected": -146.75485229492188,
      "loss": 0.5548,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4743856191635132,
      "rewards/margins": 0.8499471545219421,
      "rewards/rejected": -2.3243329524993896,
      "step": 2960
    },
    {
      "epoch": 0.5420202573227484,
      "grad_norm": 2.7427783012390137,
      "learning_rate": 6.616810953521214e-05,
      "logits/chosen": -0.983073353767395,
      "logits/rejected": -0.957947850227356,
      "logps/chosen": -159.41305541992188,
      "logps/rejected": -156.56309509277344,
      "loss": 0.5568,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.3951287269592285,
      "rewards/margins": 0.8231910467147827,
      "rewards/rejected": -2.21832013130188,
      "step": 2970
    },
    {
      "epoch": 0.5438452413541381,
      "grad_norm": 2.9800832271575928,
      "learning_rate": 6.61189906060048e-05,
      "logits/chosen": -0.9610675573348999,
      "logits/rejected": -0.9356303215026855,
      "logps/chosen": -158.67922973632812,
      "logps/rejected": -155.1516571044922,
      "loss": 0.6348,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.495518445968628,
      "rewards/margins": 0.7534143328666687,
      "rewards/rejected": -2.2489328384399414,
      "step": 2980
    },
    {
      "epoch": 0.5456702253855279,
      "grad_norm": 2.0500545501708984,
      "learning_rate": 6.606987167679745e-05,
      "logits/chosen": -0.9396625757217407,
      "logits/rejected": -0.8738691210746765,
      "logps/chosen": -162.23521423339844,
      "logps/rejected": -143.90773010253906,
      "loss": 0.5077,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.2459027767181396,
      "rewards/margins": 0.8749746084213257,
      "rewards/rejected": -2.120877265930176,
      "step": 2990
    },
    {
      "epoch": 0.5474952094169176,
      "grad_norm": 2.2016239166259766,
      "learning_rate": 6.602075274759011e-05,
      "logits/chosen": -0.9798990488052368,
      "logits/rejected": -0.899720311164856,
      "logps/chosen": -149.92288208007812,
      "logps/rejected": -136.2421875,
      "loss": 0.5274,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9529591798782349,
      "rewards/margins": 0.9927967190742493,
      "rewards/rejected": -1.9457557201385498,
      "step": 3000
    },
    {
      "epoch": 0.5493201934483073,
      "grad_norm": 2.527315139770508,
      "learning_rate": 6.597163381838276e-05,
      "logits/chosen": -0.9024220705032349,
      "logits/rejected": -0.8450939059257507,
      "logps/chosen": -150.00668334960938,
      "logps/rejected": -140.94424438476562,
      "loss": 0.5804,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0404460430145264,
      "rewards/margins": 0.9680267572402954,
      "rewards/rejected": -2.0084729194641113,
      "step": 3010
    },
    {
      "epoch": 0.551145177479697,
      "grad_norm": 1.257598638534546,
      "learning_rate": 6.592251488917541e-05,
      "logits/chosen": -0.9816892743110657,
      "logits/rejected": -0.9295517206192017,
      "logps/chosen": -163.79722595214844,
      "logps/rejected": -153.88829040527344,
      "loss": 0.5626,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.0466773509979248,
      "rewards/margins": 0.9006966352462769,
      "rewards/rejected": -1.9473739862442017,
      "step": 3020
    },
    {
      "epoch": 0.5529701615110868,
      "grad_norm": 5.205791473388672,
      "learning_rate": 6.587339595996809e-05,
      "logits/chosen": -0.9673035740852356,
      "logits/rejected": -0.9039067029953003,
      "logps/chosen": -162.99151611328125,
      "logps/rejected": -149.5025177001953,
      "loss": 0.5092,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0976614952087402,
      "rewards/margins": 0.9718262553215027,
      "rewards/rejected": -2.0694878101348877,
      "step": 3030
    },
    {
      "epoch": 0.5547951455424766,
      "grad_norm": 5.144285202026367,
      "learning_rate": 6.582427703076073e-05,
      "logits/chosen": -1.0377724170684814,
      "logits/rejected": -0.9994093179702759,
      "logps/chosen": -145.2480010986328,
      "logps/rejected": -146.9214630126953,
      "loss": 0.5695,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.2177845239639282,
      "rewards/margins": 0.8094684481620789,
      "rewards/rejected": -2.027252674102783,
      "step": 3040
    },
    {
      "epoch": 0.5566201295738662,
      "grad_norm": 2.462144613265991,
      "learning_rate": 6.577515810155339e-05,
      "logits/chosen": -0.9023411870002747,
      "logits/rejected": -0.8792657852172852,
      "logps/chosen": -127.85164642333984,
      "logps/rejected": -132.96324157714844,
      "loss": 0.6456,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.6492197513580322,
      "rewards/margins": 0.8463695645332336,
      "rewards/rejected": -2.495589017868042,
      "step": 3050
    },
    {
      "epoch": 0.558445113605256,
      "grad_norm": 3.321260690689087,
      "learning_rate": 6.572603917234606e-05,
      "logits/chosen": -0.9305143356323242,
      "logits/rejected": -0.8629268407821655,
      "logps/chosen": -164.89889526367188,
      "logps/rejected": -159.59640502929688,
      "loss": 0.5185,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.9881570935249329,
      "rewards/margins": 1.1705446243286133,
      "rewards/rejected": -2.1587016582489014,
      "step": 3060
    },
    {
      "epoch": 0.5602700976366457,
      "grad_norm": 2.0874338150024414,
      "learning_rate": 6.56769202431387e-05,
      "logits/chosen": -0.9234800338745117,
      "logits/rejected": -0.9061277508735657,
      "logps/chosen": -145.08416748046875,
      "logps/rejected": -157.3889923095703,
      "loss": 0.5537,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.9062959551811218,
      "rewards/margins": 1.0492587089538574,
      "rewards/rejected": -1.955554723739624,
      "step": 3070
    },
    {
      "epoch": 0.5620950816680355,
      "grad_norm": 2.0018908977508545,
      "learning_rate": 6.562780131393136e-05,
      "logits/chosen": -0.9094402194023132,
      "logits/rejected": -0.8613354563713074,
      "logps/chosen": -147.37393188476562,
      "logps/rejected": -146.13076782226562,
      "loss": 0.6425,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.7928115725517273,
      "rewards/margins": 0.8942667841911316,
      "rewards/rejected": -1.6870782375335693,
      "step": 3080
    },
    {
      "epoch": 0.5639200656994251,
      "grad_norm": 2.2928450107574463,
      "learning_rate": 6.557868238472402e-05,
      "logits/chosen": -0.945324718952179,
      "logits/rejected": -0.8798022270202637,
      "logps/chosen": -156.7432403564453,
      "logps/rejected": -139.29124450683594,
      "loss": 0.5672,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5284658670425415,
      "rewards/margins": 0.8382536172866821,
      "rewards/rejected": -1.366719365119934,
      "step": 3090
    },
    {
      "epoch": 0.5657450497308149,
      "grad_norm": 3.59892201423645,
      "learning_rate": 6.552956345551668e-05,
      "logits/chosen": -0.9698330163955688,
      "logits/rejected": -0.946246325969696,
      "logps/chosen": -137.0754852294922,
      "logps/rejected": -154.76663208007812,
      "loss": 0.507,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.38322195410728455,
      "rewards/margins": 1.3747673034667969,
      "rewards/rejected": -1.7579891681671143,
      "step": 3100
    },
    {
      "epoch": 0.5675700337622046,
      "grad_norm": 2.9015491008758545,
      "learning_rate": 6.548044452630933e-05,
      "logits/chosen": -0.9133638143539429,
      "logits/rejected": -0.8554162979125977,
      "logps/chosen": -165.84527587890625,
      "logps/rejected": -150.0415496826172,
      "loss": 0.5639,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6741272807121277,
      "rewards/margins": 0.986476719379425,
      "rewards/rejected": -1.6606041193008423,
      "step": 3110
    },
    {
      "epoch": 0.5693950177935944,
      "grad_norm": 5.90934944152832,
      "learning_rate": 6.543132559710199e-05,
      "logits/chosen": -0.8967539668083191,
      "logits/rejected": -0.838006317615509,
      "logps/chosen": -163.369873046875,
      "logps/rejected": -167.68243408203125,
      "loss": 0.5888,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.8924956321716309,
      "rewards/margins": 1.0761483907699585,
      "rewards/rejected": -1.9686439037322998,
      "step": 3120
    },
    {
      "epoch": 0.571220001824984,
      "grad_norm": 2.921320915222168,
      "learning_rate": 6.538220666789464e-05,
      "logits/chosen": -0.9951741099357605,
      "logits/rejected": -0.8830709457397461,
      "logps/chosen": -151.2429656982422,
      "logps/rejected": -134.28819274902344,
      "loss": 0.4591,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.7599117159843445,
      "rewards/margins": 1.340915322303772,
      "rewards/rejected": -2.100827217102051,
      "step": 3130
    },
    {
      "epoch": 0.5730449858563738,
      "grad_norm": 5.2912678718566895,
      "learning_rate": 6.533308773868731e-05,
      "logits/chosen": -0.9695380330085754,
      "logits/rejected": -0.9474233388900757,
      "logps/chosen": -164.6947479248047,
      "logps/rejected": -175.32513427734375,
      "loss": 0.5547,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2293701171875,
      "rewards/margins": 0.8922888040542603,
      "rewards/rejected": -2.12165904045105,
      "step": 3140
    },
    {
      "epoch": 0.5748699698877635,
      "grad_norm": 3.9239120483398438,
      "learning_rate": 6.528396880947996e-05,
      "logits/chosen": -0.9407238960266113,
      "logits/rejected": -0.8853246569633484,
      "logps/chosen": -150.05810546875,
      "logps/rejected": -141.24337768554688,
      "loss": 0.6287,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.4359753131866455,
      "rewards/margins": 0.7859206199645996,
      "rewards/rejected": -2.221895933151245,
      "step": 3150
    },
    {
      "epoch": 0.5766949539191532,
      "grad_norm": 3.2703545093536377,
      "learning_rate": 6.523484988027261e-05,
      "logits/chosen": -0.9419244527816772,
      "logits/rejected": -0.8596335649490356,
      "logps/chosen": -148.76199340820312,
      "logps/rejected": -135.67642211914062,
      "loss": 0.4695,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.884869396686554,
      "rewards/margins": 1.246739149093628,
      "rewards/rejected": -2.131608486175537,
      "step": 3160
    },
    {
      "epoch": 0.5785199379505429,
      "grad_norm": 3.0280325412750244,
      "learning_rate": 6.518573095106528e-05,
      "logits/chosen": -0.9198942184448242,
      "logits/rejected": -0.8265244364738464,
      "logps/chosen": -151.9824676513672,
      "logps/rejected": -135.1732177734375,
      "loss": 0.5673,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8765897750854492,
      "rewards/margins": 0.8392173051834106,
      "rewards/rejected": -1.7158069610595703,
      "step": 3170
    },
    {
      "epoch": 0.5803449219819327,
      "grad_norm": 3.5507571697235107,
      "learning_rate": 6.513661202185792e-05,
      "logits/chosen": -0.9174346923828125,
      "logits/rejected": -0.8682080507278442,
      "logps/chosen": -156.00082397460938,
      "logps/rejected": -150.8856964111328,
      "loss": 0.6762,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.7752925753593445,
      "rewards/margins": 0.6362646222114563,
      "rewards/rejected": -1.4115573167800903,
      "step": 3180
    },
    {
      "epoch": 0.5821699060133224,
      "grad_norm": 2.5491151809692383,
      "learning_rate": 6.508749309265058e-05,
      "logits/chosen": -0.9003507494926453,
      "logits/rejected": -0.8308731913566589,
      "logps/chosen": -153.697509765625,
      "logps/rejected": -138.9378662109375,
      "loss": 0.5194,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.9861291646957397,
      "rewards/margins": 0.9322702288627625,
      "rewards/rejected": -1.918399453163147,
      "step": 3190
    },
    {
      "epoch": 0.5839948900447121,
      "grad_norm": 4.635639667510986,
      "learning_rate": 6.503837416344324e-05,
      "logits/chosen": -0.8736914396286011,
      "logits/rejected": -0.7856305837631226,
      "logps/chosen": -158.82662963867188,
      "logps/rejected": -148.35324096679688,
      "loss": 0.5076,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3571604490280151,
      "rewards/margins": 1.0439984798431396,
      "rewards/rejected": -2.4011588096618652,
      "step": 3200
    },
    {
      "epoch": 0.5858198740761018,
      "grad_norm": 1.5242289304733276,
      "learning_rate": 6.49892552342359e-05,
      "logits/chosen": -0.9286017417907715,
      "logits/rejected": -0.8309226036071777,
      "logps/chosen": -174.68521118164062,
      "logps/rejected": -148.86074829101562,
      "loss": 0.4701,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0464997291564941,
      "rewards/margins": 1.244226336479187,
      "rewards/rejected": -2.2907261848449707,
      "step": 3210
    },
    {
      "epoch": 0.5876448581074916,
      "grad_norm": 3.8683059215545654,
      "learning_rate": 6.494013630502856e-05,
      "logits/chosen": -0.8692591786384583,
      "logits/rejected": -0.8010637164115906,
      "logps/chosen": -168.98626708984375,
      "logps/rejected": -158.06747436523438,
      "loss": 0.6473,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.3520201444625854,
      "rewards/margins": 0.8902171850204468,
      "rewards/rejected": -2.2422375679016113,
      "step": 3220
    },
    {
      "epoch": 0.5894698421388813,
      "grad_norm": 4.068167209625244,
      "learning_rate": 6.489101737582121e-05,
      "logits/chosen": -0.8399534225463867,
      "logits/rejected": -0.7912592887878418,
      "logps/chosen": -154.43753051757812,
      "logps/rejected": -151.2237548828125,
      "loss": 0.5457,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.9438279867172241,
      "rewards/margins": 1.0546162128448486,
      "rewards/rejected": -1.9984439611434937,
      "step": 3230
    },
    {
      "epoch": 0.591294826170271,
      "grad_norm": 3.2768335342407227,
      "learning_rate": 6.484189844661387e-05,
      "logits/chosen": -0.8227755427360535,
      "logits/rejected": -0.725086510181427,
      "logps/chosen": -153.3395233154297,
      "logps/rejected": -145.3878631591797,
      "loss": 0.4504,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8601640462875366,
      "rewards/margins": 1.2393195629119873,
      "rewards/rejected": -2.0994834899902344,
      "step": 3240
    },
    {
      "epoch": 0.5931198102016607,
      "grad_norm": 2.3875508308410645,
      "learning_rate": 6.479277951740653e-05,
      "logits/chosen": -0.8130831718444824,
      "logits/rejected": -0.7441232800483704,
      "logps/chosen": -152.91355895996094,
      "logps/rejected": -142.3863525390625,
      "loss": 0.5054,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7807539105415344,
      "rewards/margins": 1.1363780498504639,
      "rewards/rejected": -1.917131781578064,
      "step": 3250
    },
    {
      "epoch": 0.5949447942330505,
      "grad_norm": 3.1346373558044434,
      "learning_rate": 6.474366058819919e-05,
      "logits/chosen": -0.8727719187736511,
      "logits/rejected": -0.8143901824951172,
      "logps/chosen": -162.09706115722656,
      "logps/rejected": -152.16970825195312,
      "loss": 0.4613,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.4929439127445221,
      "rewards/margins": 1.0673667192459106,
      "rewards/rejected": -1.5603106021881104,
      "step": 3260
    },
    {
      "epoch": 0.5967697782644402,
      "grad_norm": 5.515223026275635,
      "learning_rate": 6.469454165899183e-05,
      "logits/chosen": -0.8278180956840515,
      "logits/rejected": -0.8063909411430359,
      "logps/chosen": -139.9004364013672,
      "logps/rejected": -148.05996704101562,
      "loss": 0.5482,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6112762689590454,
      "rewards/margins": 0.9314813613891602,
      "rewards/rejected": -1.542757511138916,
      "step": 3270
    },
    {
      "epoch": 0.5985947622958299,
      "grad_norm": 2.8755946159362793,
      "learning_rate": 6.46454227297845e-05,
      "logits/chosen": -0.9341683387756348,
      "logits/rejected": -0.8435384631156921,
      "logps/chosen": -151.1466064453125,
      "logps/rejected": -137.82699584960938,
      "loss": 0.4624,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.13676266372203827,
      "rewards/margins": 1.2802960872650146,
      "rewards/rejected": -1.4170588254928589,
      "step": 3280
    },
    {
      "epoch": 0.6004197463272196,
      "grad_norm": 2.8615434169769287,
      "learning_rate": 6.459630380057716e-05,
      "logits/chosen": -0.8530377149581909,
      "logits/rejected": -0.8214067220687866,
      "logps/chosen": -151.97354125976562,
      "logps/rejected": -146.3968963623047,
      "loss": 0.5465,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5396210551261902,
      "rewards/margins": 0.8879708051681519,
      "rewards/rejected": -1.4275919198989868,
      "step": 3290
    },
    {
      "epoch": 0.6022447303586094,
      "grad_norm": 2.5194525718688965,
      "learning_rate": 6.45471848713698e-05,
      "logits/chosen": -0.9924348592758179,
      "logits/rejected": -0.9004683494567871,
      "logps/chosen": -152.8968963623047,
      "logps/rejected": -139.34141540527344,
      "loss": 0.4921,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.3586363196372986,
      "rewards/margins": 1.0085150003433228,
      "rewards/rejected": -1.3671512603759766,
      "step": 3300
    },
    {
      "epoch": 0.6040697143899991,
      "grad_norm": 3.7310099601745605,
      "learning_rate": 6.449806594216246e-05,
      "logits/chosen": -0.9554988741874695,
      "logits/rejected": -0.8603036999702454,
      "logps/chosen": -171.27310180664062,
      "logps/rejected": -146.103271484375,
      "loss": 0.5428,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.8360994458198547,
      "rewards/margins": 0.8931577801704407,
      "rewards/rejected": -1.7292572259902954,
      "step": 3310
    },
    {
      "epoch": 0.6058946984213888,
      "grad_norm": 4.723041534423828,
      "learning_rate": 6.444894701295512e-05,
      "logits/chosen": -0.920046329498291,
      "logits/rejected": -0.8723934292793274,
      "logps/chosen": -149.40396118164062,
      "logps/rejected": -153.3712921142578,
      "loss": 0.5852,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8984647989273071,
      "rewards/margins": 0.9730517268180847,
      "rewards/rejected": -1.8715165853500366,
      "step": 3320
    },
    {
      "epoch": 0.6077196824527785,
      "grad_norm": 4.944437026977539,
      "learning_rate": 6.439982808374778e-05,
      "logits/chosen": -0.9576333165168762,
      "logits/rejected": -0.9039270281791687,
      "logps/chosen": -141.0662078857422,
      "logps/rejected": -135.84332275390625,
      "loss": 0.5811,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.28840044140815735,
      "rewards/margins": 0.8576028943061829,
      "rewards/rejected": -1.1460034847259521,
      "step": 3330
    },
    {
      "epoch": 0.6095446664841683,
      "grad_norm": 2.6604151725769043,
      "learning_rate": 6.435070915454043e-05,
      "logits/chosen": -0.9734150171279907,
      "logits/rejected": -0.8679890632629395,
      "logps/chosen": -170.98072814941406,
      "logps/rejected": -136.5498809814453,
      "loss": 0.5515,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.09082017093896866,
      "rewards/margins": 0.922653079032898,
      "rewards/rejected": -0.831833004951477,
      "step": 3340
    },
    {
      "epoch": 0.611369650515558,
      "grad_norm": 3.3704638481140137,
      "learning_rate": 6.430159022533309e-05,
      "logits/chosen": -0.9293466806411743,
      "logits/rejected": -0.9032293558120728,
      "logps/chosen": -155.35911560058594,
      "logps/rejected": -159.41854858398438,
      "loss": 0.5563,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.2997759282588959,
      "rewards/margins": 0.9427134394645691,
      "rewards/rejected": -1.2424893379211426,
      "step": 3350
    },
    {
      "epoch": 0.6131946345469477,
      "grad_norm": 3.6139748096466064,
      "learning_rate": 6.425247129612575e-05,
      "logits/chosen": -0.8941985964775085,
      "logits/rejected": -0.8639755249023438,
      "logps/chosen": -152.68939208984375,
      "logps/rejected": -157.13453674316406,
      "loss": 0.5008,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.5555276870727539,
      "rewards/margins": 1.063352108001709,
      "rewards/rejected": -1.6188796758651733,
      "step": 3360
    },
    {
      "epoch": 0.6150196185783374,
      "grad_norm": 4.640195369720459,
      "learning_rate": 6.420335236691841e-05,
      "logits/chosen": -0.929783821105957,
      "logits/rejected": -0.8838241696357727,
      "logps/chosen": -154.5071258544922,
      "logps/rejected": -151.30575561523438,
      "loss": 0.6101,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.5100979208946228,
      "rewards/margins": 1.0365928411483765,
      "rewards/rejected": -1.546690821647644,
      "step": 3370
    },
    {
      "epoch": 0.6168446026097272,
      "grad_norm": 2.459213972091675,
      "learning_rate": 6.415423343771107e-05,
      "logits/chosen": -1.0343762636184692,
      "logits/rejected": -0.9764465093612671,
      "logps/chosen": -146.322265625,
      "logps/rejected": -136.1980438232422,
      "loss": 0.5783,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.4846421778202057,
      "rewards/margins": 0.884861171245575,
      "rewards/rejected": -1.369503378868103,
      "step": 3380
    },
    {
      "epoch": 0.6186695866411169,
      "grad_norm": 2.357511520385742,
      "learning_rate": 6.410511450850372e-05,
      "logits/chosen": -1.023533582687378,
      "logits/rejected": -0.9944494962692261,
      "logps/chosen": -138.46615600585938,
      "logps/rejected": -143.88638305664062,
      "loss": 0.4927,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.1903122365474701,
      "rewards/margins": 1.0530716180801392,
      "rewards/rejected": -1.243383765220642,
      "step": 3390
    },
    {
      "epoch": 0.6204945706725066,
      "grad_norm": 2.5225486755371094,
      "learning_rate": 6.405599557929638e-05,
      "logits/chosen": -1.0038150548934937,
      "logits/rejected": -0.9803193807601929,
      "logps/chosen": -152.53121948242188,
      "logps/rejected": -148.82986450195312,
      "loss": 0.5555,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.419312059879303,
      "rewards/margins": 0.9033353924751282,
      "rewards/rejected": -1.3226473331451416,
      "step": 3400
    },
    {
      "epoch": 0.6223195547038963,
      "grad_norm": 5.28898811340332,
      "learning_rate": 6.400687665008903e-05,
      "logits/chosen": -1.0061264038085938,
      "logits/rejected": -0.9600912928581238,
      "logps/chosen": -154.3745880126953,
      "logps/rejected": -143.89852905273438,
      "loss": 0.5454,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.49333420395851135,
      "rewards/margins": 0.932353675365448,
      "rewards/rejected": -1.4256877899169922,
      "step": 3410
    },
    {
      "epoch": 0.6241445387352861,
      "grad_norm": 2.042141914367676,
      "learning_rate": 6.395775772088168e-05,
      "logits/chosen": -0.9879181981086731,
      "logits/rejected": -0.9295880198478699,
      "logps/chosen": -171.64744567871094,
      "logps/rejected": -148.9947967529297,
      "loss": 0.6176,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6234298944473267,
      "rewards/margins": 0.972811222076416,
      "rewards/rejected": -1.5962409973144531,
      "step": 3420
    },
    {
      "epoch": 0.6259695227666758,
      "grad_norm": 2.4645426273345947,
      "learning_rate": 6.390863879167435e-05,
      "logits/chosen": -0.989536464214325,
      "logits/rejected": -0.9145137667655945,
      "logps/chosen": -159.78573608398438,
      "logps/rejected": -142.7601318359375,
      "loss": 0.5086,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.4076225757598877,
      "rewards/margins": 0.9224914312362671,
      "rewards/rejected": -1.3301140069961548,
      "step": 3430
    },
    {
      "epoch": 0.6277945067980655,
      "grad_norm": 2.2807247638702393,
      "learning_rate": 6.3859519862467e-05,
      "logits/chosen": -0.9714581370353699,
      "logits/rejected": -0.8968209028244019,
      "logps/chosen": -145.14585876464844,
      "logps/rejected": -130.14218139648438,
      "loss": 0.625,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.685836672782898,
      "rewards/margins": 0.7277568578720093,
      "rewards/rejected": -1.4135935306549072,
      "step": 3440
    },
    {
      "epoch": 0.6296194908294552,
      "grad_norm": 3.830198287963867,
      "learning_rate": 6.381040093325966e-05,
      "logits/chosen": -1.0058258771896362,
      "logits/rejected": -0.9672950506210327,
      "logps/chosen": -145.6759490966797,
      "logps/rejected": -145.29632568359375,
      "loss": 0.5451,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.9583592414855957,
      "rewards/margins": 0.9238678812980652,
      "rewards/rejected": -1.8822271823883057,
      "step": 3450
    },
    {
      "epoch": 0.631444474860845,
      "grad_norm": 2.712451457977295,
      "learning_rate": 6.376128200405233e-05,
      "logits/chosen": -0.9817660450935364,
      "logits/rejected": -0.9510971903800964,
      "logps/chosen": -156.5042724609375,
      "logps/rejected": -155.70443725585938,
      "loss": 0.5476,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7555824518203735,
      "rewards/margins": 1.011644959449768,
      "rewards/rejected": -1.7672275304794312,
      "step": 3460
    },
    {
      "epoch": 0.6332694588922347,
      "grad_norm": 2.7171757221221924,
      "learning_rate": 6.371216307484497e-05,
      "logits/chosen": -0.9821246862411499,
      "logits/rejected": -0.9424349069595337,
      "logps/chosen": -152.56591796875,
      "logps/rejected": -143.80313110351562,
      "loss": 0.5991,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.7343088388442993,
      "rewards/margins": 0.7989034056663513,
      "rewards/rejected": -1.5332120656967163,
      "step": 3470
    },
    {
      "epoch": 0.6350944429236244,
      "grad_norm": 4.302587509155273,
      "learning_rate": 6.366304414563763e-05,
      "logits/chosen": -1.0167261362075806,
      "logits/rejected": -0.9733769297599792,
      "logps/chosen": -165.9320831298828,
      "logps/rejected": -138.03836059570312,
      "loss": 0.6338,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.037278413772583,
      "rewards/margins": 0.670471727848053,
      "rewards/rejected": -1.7077503204345703,
      "step": 3480
    },
    {
      "epoch": 0.6369194269550141,
      "grad_norm": 4.558305740356445,
      "learning_rate": 6.361392521643029e-05,
      "logits/chosen": -0.9542568325996399,
      "logits/rejected": -0.8835773468017578,
      "logps/chosen": -163.46925354003906,
      "logps/rejected": -141.4253692626953,
      "loss": 0.5789,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.1259958744049072,
      "rewards/margins": 0.9780306816101074,
      "rewards/rejected": -2.1040265560150146,
      "step": 3490
    },
    {
      "epoch": 0.6387444109864039,
      "grad_norm": 2.7852983474731445,
      "learning_rate": 6.356480628722294e-05,
      "logits/chosen": -0.9770762324333191,
      "logits/rejected": -0.9056812524795532,
      "logps/chosen": -165.72731018066406,
      "logps/rejected": -148.53964233398438,
      "loss": 0.446,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.2185369729995728,
      "rewards/margins": 1.106241226196289,
      "rewards/rejected": -2.3247780799865723,
      "step": 3500
    },
    {
      "epoch": 0.6405693950177936,
      "grad_norm": 1.9991121292114258,
      "learning_rate": 6.35156873580156e-05,
      "logits/chosen": -1.018064260482788,
      "logits/rejected": -0.9827175140380859,
      "logps/chosen": -142.27296447753906,
      "logps/rejected": -143.9046173095703,
      "loss": 0.5668,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.2024916410446167,
      "rewards/margins": 1.0469189882278442,
      "rewards/rejected": -2.24941086769104,
      "step": 3510
    },
    {
      "epoch": 0.6423943790491833,
      "grad_norm": 2.0813755989074707,
      "learning_rate": 6.346656842880826e-05,
      "logits/chosen": -1.013519525527954,
      "logits/rejected": -0.9984679222106934,
      "logps/chosen": -144.87646484375,
      "logps/rejected": -143.94979858398438,
      "loss": 0.4872,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.304748296737671,
      "rewards/margins": 1.0312855243682861,
      "rewards/rejected": -2.336033582687378,
      "step": 3520
    },
    {
      "epoch": 0.644219363080573,
      "grad_norm": 3.6738290786743164,
      "learning_rate": 6.341744949960092e-05,
      "logits/chosen": -1.0413668155670166,
      "logits/rejected": -1.0012027025222778,
      "logps/chosen": -169.39462280273438,
      "logps/rejected": -156.53607177734375,
      "loss": 0.6216,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.535040020942688,
      "rewards/margins": 0.8142379522323608,
      "rewards/rejected": -2.349277973175049,
      "step": 3530
    },
    {
      "epoch": 0.6460443471119628,
      "grad_norm": 3.2224535942077637,
      "learning_rate": 6.336833057039358e-05,
      "logits/chosen": -1.0228185653686523,
      "logits/rejected": -0.9768832325935364,
      "logps/chosen": -173.77584838867188,
      "logps/rejected": -148.7918701171875,
      "loss": 0.5081,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.6553823947906494,
      "rewards/margins": 1.1862318515777588,
      "rewards/rejected": -2.841614246368408,
      "step": 3540
    },
    {
      "epoch": 0.6478693311433525,
      "grad_norm": 3.4528377056121826,
      "learning_rate": 6.331921164118623e-05,
      "logits/chosen": -1.03192937374115,
      "logits/rejected": -1.0309146642684937,
      "logps/chosen": -144.49354553222656,
      "logps/rejected": -160.84642028808594,
      "loss": 0.7331,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -2.0104551315307617,
      "rewards/margins": 0.5797818899154663,
      "rewards/rejected": -2.5902369022369385,
      "step": 3550
    },
    {
      "epoch": 0.6496943151747422,
      "grad_norm": 4.153512001037598,
      "learning_rate": 6.327009271197888e-05,
      "logits/chosen": -1.0569578409194946,
      "logits/rejected": -1.0033061504364014,
      "logps/chosen": -177.99136352539062,
      "logps/rejected": -157.98342895507812,
      "loss": 0.5813,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.8681278228759766,
      "rewards/margins": 0.7913891077041626,
      "rewards/rejected": -2.6595170497894287,
      "step": 3560
    },
    {
      "epoch": 0.6515192992061319,
      "grad_norm": 2.2972793579101562,
      "learning_rate": 6.322097378277155e-05,
      "logits/chosen": -1.0418415069580078,
      "logits/rejected": -0.9840838313102722,
      "logps/chosen": -165.65206909179688,
      "logps/rejected": -153.18307495117188,
      "loss": 0.5435,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.702079176902771,
      "rewards/margins": 1.1264545917510986,
      "rewards/rejected": -2.82853364944458,
      "step": 3570
    },
    {
      "epoch": 0.6533442832375217,
      "grad_norm": 3.492870330810547,
      "learning_rate": 6.317185485356419e-05,
      "logits/chosen": -1.011708378791809,
      "logits/rejected": -0.9601232409477234,
      "logps/chosen": -166.7415771484375,
      "logps/rejected": -155.1140594482422,
      "loss": 0.4664,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.296324372291565,
      "rewards/margins": 1.1370171308517456,
      "rewards/rejected": -2.4333415031433105,
      "step": 3580
    },
    {
      "epoch": 0.6551692672689114,
      "grad_norm": 3.7475359439849854,
      "learning_rate": 6.312273592435685e-05,
      "logits/chosen": -1.002490758895874,
      "logits/rejected": -0.9707025289535522,
      "logps/chosen": -138.61341857910156,
      "logps/rejected": -137.99398803710938,
      "loss": 0.6125,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.4468146562576294,
      "rewards/margins": 0.6225347518920898,
      "rewards/rejected": -2.0693492889404297,
      "step": 3590
    },
    {
      "epoch": 0.6569942513003011,
      "grad_norm": 3.138416290283203,
      "learning_rate": 6.307361699514951e-05,
      "logits/chosen": -1.0178231000900269,
      "logits/rejected": -0.9727498888969421,
      "logps/chosen": -142.21505737304688,
      "logps/rejected": -141.8998260498047,
      "loss": 0.4817,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.9383267164230347,
      "rewards/margins": 1.01397705078125,
      "rewards/rejected": -1.9523036479949951,
      "step": 3600
    },
    {
      "epoch": 0.6588192353316908,
      "grad_norm": 2.081451416015625,
      "learning_rate": 6.302449806594217e-05,
      "logits/chosen": -1.0269917249679565,
      "logits/rejected": -1.0111154317855835,
      "logps/chosen": -140.90646362304688,
      "logps/rejected": -143.83599853515625,
      "loss": 0.594,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.8729060888290405,
      "rewards/margins": 0.6858372688293457,
      "rewards/rejected": -1.5587433576583862,
      "step": 3610
    },
    {
      "epoch": 0.6606442193630806,
      "grad_norm": 2.132828712463379,
      "learning_rate": 6.297537913673482e-05,
      "logits/chosen": -1.0005183219909668,
      "logits/rejected": -0.9425386190414429,
      "logps/chosen": -157.89944458007812,
      "logps/rejected": -141.19090270996094,
      "loss": 0.5362,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7610951662063599,
      "rewards/margins": 1.069126844406128,
      "rewards/rejected": -1.8302218914031982,
      "step": 3620
    },
    {
      "epoch": 0.6624692033944704,
      "grad_norm": 2.574054718017578,
      "learning_rate": 6.292626020752748e-05,
      "logits/chosen": -1.046142339706421,
      "logits/rejected": -0.9926878213882446,
      "logps/chosen": -162.4786834716797,
      "logps/rejected": -162.34312438964844,
      "loss": 0.5292,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5227241516113281,
      "rewards/margins": 0.8396968841552734,
      "rewards/rejected": -1.3624210357666016,
      "step": 3630
    },
    {
      "epoch": 0.66429418742586,
      "grad_norm": 3.493104934692383,
      "learning_rate": 6.287714127832014e-05,
      "logits/chosen": -1.0165191888809204,
      "logits/rejected": -0.9701012372970581,
      "logps/chosen": -147.11610412597656,
      "logps/rejected": -133.53268432617188,
      "loss": 0.5206,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7740301489830017,
      "rewards/margins": 1.0705690383911133,
      "rewards/rejected": -1.8445991277694702,
      "step": 3640
    },
    {
      "epoch": 0.6661191714572497,
      "grad_norm": 1.9836509227752686,
      "learning_rate": 6.28280223491128e-05,
      "logits/chosen": -1.043845772743225,
      "logits/rejected": -1.0057296752929688,
      "logps/chosen": -153.72328186035156,
      "logps/rejected": -148.0681610107422,
      "loss": 0.5274,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.943230926990509,
      "rewards/margins": 0.8888106346130371,
      "rewards/rejected": -1.8320415019989014,
      "step": 3650
    },
    {
      "epoch": 0.6679441554886395,
      "grad_norm": 2.986945152282715,
      "learning_rate": 6.277890341990545e-05,
      "logits/chosen": -0.9758898615837097,
      "logits/rejected": -0.9408220052719116,
      "logps/chosen": -156.21774291992188,
      "logps/rejected": -144.45863342285156,
      "loss": 0.555,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0051064491271973,
      "rewards/margins": 0.9555299878120422,
      "rewards/rejected": -1.9606364965438843,
      "step": 3660
    },
    {
      "epoch": 0.6697691395200293,
      "grad_norm": 3.795564889907837,
      "learning_rate": 6.27297844906981e-05,
      "logits/chosen": -1.0392597913742065,
      "logits/rejected": -1.0266071557998657,
      "logps/chosen": -156.2618865966797,
      "logps/rejected": -157.8015899658203,
      "loss": 0.5451,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.3219369649887085,
      "rewards/margins": 0.9331372380256653,
      "rewards/rejected": -2.2550740242004395,
      "step": 3670
    },
    {
      "epoch": 0.6715941235514189,
      "grad_norm": 4.199346542358398,
      "learning_rate": 6.268066556149077e-05,
      "logits/chosen": -1.0860557556152344,
      "logits/rejected": -1.0278584957122803,
      "logps/chosen": -156.6220245361328,
      "logps/rejected": -129.80990600585938,
      "loss": 0.6006,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.1918829679489136,
      "rewards/margins": 0.7490382790565491,
      "rewards/rejected": -1.9409215450286865,
      "step": 3680
    },
    {
      "epoch": 0.6734191075828087,
      "grad_norm": 3.4128870964050293,
      "learning_rate": 6.263154663228343e-05,
      "logits/chosen": -1.103823184967041,
      "logits/rejected": -1.0742157697677612,
      "logps/chosen": -152.9717254638672,
      "logps/rejected": -135.82376098632812,
      "loss": 0.5792,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.4066274166107178,
      "rewards/margins": 0.9482443928718567,
      "rewards/rejected": -2.354871988296509,
      "step": 3690
    },
    {
      "epoch": 0.6752440916141984,
      "grad_norm": 1.7328062057495117,
      "learning_rate": 6.258242770307607e-05,
      "logits/chosen": -1.0338040590286255,
      "logits/rejected": -1.0069584846496582,
      "logps/chosen": -152.99539184570312,
      "logps/rejected": -155.2034149169922,
      "loss": 0.484,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.3681108951568604,
      "rewards/margins": 1.1339279413223267,
      "rewards/rejected": -2.5020387172698975,
      "step": 3700
    },
    {
      "epoch": 0.677069075645588,
      "grad_norm": 3.377528429031372,
      "learning_rate": 6.253330877386873e-05,
      "logits/chosen": -1.0241034030914307,
      "logits/rejected": -1.0238077640533447,
      "logps/chosen": -152.57550048828125,
      "logps/rejected": -167.37342834472656,
      "loss": 0.6066,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.6417230367660522,
      "rewards/margins": 0.9022067189216614,
      "rewards/rejected": -2.5439298152923584,
      "step": 3710
    },
    {
      "epoch": 0.6788940596769778,
      "grad_norm": 2.75907564163208,
      "learning_rate": 6.248418984466139e-05,
      "logits/chosen": -0.986549973487854,
      "logits/rejected": -0.923580527305603,
      "logps/chosen": -164.5599822998047,
      "logps/rejected": -154.01101684570312,
      "loss": 0.6376,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.8028733730316162,
      "rewards/margins": 0.7744987607002258,
      "rewards/rejected": -2.5773720741271973,
      "step": 3720
    },
    {
      "epoch": 0.6807190437083676,
      "grad_norm": 3.0434701442718506,
      "learning_rate": 6.243507091545405e-05,
      "logits/chosen": -0.9846347570419312,
      "logits/rejected": -0.9343163371086121,
      "logps/chosen": -159.63348388671875,
      "logps/rejected": -148.83883666992188,
      "loss": 0.5366,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7843427658081055,
      "rewards/margins": 0.8025520443916321,
      "rewards/rejected": -2.586894989013672,
      "step": 3730
    },
    {
      "epoch": 0.6825440277397573,
      "grad_norm": 3.5217456817626953,
      "learning_rate": 6.23859519862467e-05,
      "logits/chosen": -1.0071148872375488,
      "logits/rejected": -0.9055584073066711,
      "logps/chosen": -167.24539184570312,
      "logps/rejected": -132.49880981445312,
      "loss": 0.4488,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6341899633407593,
      "rewards/margins": 1.2102301120758057,
      "rewards/rejected": -2.8444199562072754,
      "step": 3740
    },
    {
      "epoch": 0.684369011771147,
      "grad_norm": 2.9583165645599365,
      "learning_rate": 6.233683305703936e-05,
      "logits/chosen": -1.0099756717681885,
      "logits/rejected": -0.9586284756660461,
      "logps/chosen": -165.0270538330078,
      "logps/rejected": -165.68392944335938,
      "loss": 0.5363,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.3657290935516357,
      "rewards/margins": 0.9604728817939758,
      "rewards/rejected": -2.326201915740967,
      "step": 3750
    },
    {
      "epoch": 0.6861939958025367,
      "grad_norm": 4.306751728057861,
      "learning_rate": 6.228771412783202e-05,
      "logits/chosen": -1.0048216581344604,
      "logits/rejected": -0.9663947820663452,
      "logps/chosen": -165.34584045410156,
      "logps/rejected": -170.02490234375,
      "loss": 0.5672,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.2920066118240356,
      "rewards/margins": 0.9974113702774048,
      "rewards/rejected": -2.2894179821014404,
      "step": 3760
    },
    {
      "epoch": 0.6880189798339265,
      "grad_norm": 3.4280056953430176,
      "learning_rate": 6.223859519862468e-05,
      "logits/chosen": -0.9393723607063293,
      "logits/rejected": -0.8798574209213257,
      "logps/chosen": -167.90695190429688,
      "logps/rejected": -144.93858337402344,
      "loss": 0.5426,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9217666387557983,
      "rewards/margins": 1.2002699375152588,
      "rewards/rejected": -2.1220364570617676,
      "step": 3770
    },
    {
      "epoch": 0.6898439638653162,
      "grad_norm": 2.6564199924468994,
      "learning_rate": 6.218947626941733e-05,
      "logits/chosen": -0.9493012428283691,
      "logits/rejected": -0.864256739616394,
      "logps/chosen": -162.75637817382812,
      "logps/rejected": -137.26901245117188,
      "loss": 0.5302,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.3498002886772156,
      "rewards/margins": 0.9943386912345886,
      "rewards/rejected": -1.3441390991210938,
      "step": 3780
    },
    {
      "epoch": 0.6916689478967059,
      "grad_norm": 1.284216284751892,
      "learning_rate": 6.214035734020999e-05,
      "logits/chosen": -1.0040361881256104,
      "logits/rejected": -0.9283227920532227,
      "logps/chosen": -152.0721435546875,
      "logps/rejected": -136.38404846191406,
      "loss": 0.6202,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8733943104743958,
      "rewards/margins": 0.7447233200073242,
      "rewards/rejected": -1.6181176900863647,
      "step": 3790
    },
    {
      "epoch": 0.6934939319280956,
      "grad_norm": 3.0490260124206543,
      "learning_rate": 6.209123841100265e-05,
      "logits/chosen": -0.8866279721260071,
      "logits/rejected": -0.8668498992919922,
      "logps/chosen": -151.03384399414062,
      "logps/rejected": -148.09861755371094,
      "loss": 0.6401,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.0749915838241577,
      "rewards/margins": 0.7031000852584839,
      "rewards/rejected": -1.7780917882919312,
      "step": 3800
    },
    {
      "epoch": 0.6953189159594854,
      "grad_norm": 2.2188620567321777,
      "learning_rate": 6.20421194817953e-05,
      "logits/chosen": -0.8521248698234558,
      "logits/rejected": -0.8092705011367798,
      "logps/chosen": -150.83999633789062,
      "logps/rejected": -139.84005737304688,
      "loss": 0.4916,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7987419366836548,
      "rewards/margins": 0.9085008502006531,
      "rewards/rejected": -1.707242727279663,
      "step": 3810
    },
    {
      "epoch": 0.6971438999908751,
      "grad_norm": 3.2888846397399902,
      "learning_rate": 6.199300055258796e-05,
      "logits/chosen": -0.9789867401123047,
      "logits/rejected": -0.8993194699287415,
      "logps/chosen": -159.69691467285156,
      "logps/rejected": -142.08700561523438,
      "loss": 0.5084,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6793191432952881,
      "rewards/margins": 1.0384972095489502,
      "rewards/rejected": -1.7178161144256592,
      "step": 3820
    },
    {
      "epoch": 0.6989688840222648,
      "grad_norm": 2.477376699447632,
      "learning_rate": 6.194388162338062e-05,
      "logits/chosen": -0.9256167411804199,
      "logits/rejected": -0.8316413760185242,
      "logps/chosen": -177.78306579589844,
      "logps/rejected": -139.3839874267578,
      "loss": 0.4426,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.16196608543396,
      "rewards/margins": 1.1216427087783813,
      "rewards/rejected": -2.28360915184021,
      "step": 3830
    },
    {
      "epoch": 0.7007938680536545,
      "grad_norm": 4.020753383636475,
      "learning_rate": 6.189476269417327e-05,
      "logits/chosen": -0.9502694010734558,
      "logits/rejected": -0.8642050623893738,
      "logps/chosen": -160.79312133789062,
      "logps/rejected": -144.28759765625,
      "loss": 0.6178,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.285583734512329,
      "rewards/margins": 0.9194760322570801,
      "rewards/rejected": -2.205059766769409,
      "step": 3840
    },
    {
      "epoch": 0.7026188520850443,
      "grad_norm": 5.119575023651123,
      "learning_rate": 6.184564376496592e-05,
      "logits/chosen": -0.9417505264282227,
      "logits/rejected": -0.9233713150024414,
      "logps/chosen": -155.45278930664062,
      "logps/rejected": -154.06661987304688,
      "loss": 0.5333,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.7255529165267944,
      "rewards/margins": 0.9252796173095703,
      "rewards/rejected": -2.650832414627075,
      "step": 3850
    },
    {
      "epoch": 0.704443836116434,
      "grad_norm": 2.5510730743408203,
      "learning_rate": 6.179652483575858e-05,
      "logits/chosen": -0.9936709403991699,
      "logits/rejected": -0.9069366455078125,
      "logps/chosen": -171.71131896972656,
      "logps/rejected": -152.40969848632812,
      "loss": 0.5299,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.230360746383667,
      "rewards/margins": 1.248028039932251,
      "rewards/rejected": -2.478388547897339,
      "step": 3860
    },
    {
      "epoch": 0.7062688201478237,
      "grad_norm": 3.6930642127990723,
      "learning_rate": 6.174740590655124e-05,
      "logits/chosen": -0.9815925359725952,
      "logits/rejected": -0.9409247636795044,
      "logps/chosen": -150.87673950195312,
      "logps/rejected": -150.85638427734375,
      "loss": 0.4896,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.2830135822296143,
      "rewards/margins": 0.9887054562568665,
      "rewards/rejected": -2.271718740463257,
      "step": 3870
    },
    {
      "epoch": 0.7080938041792134,
      "grad_norm": 3.7216057777404785,
      "learning_rate": 6.16982869773439e-05,
      "logits/chosen": -1.0016758441925049,
      "logits/rejected": -0.9712932705879211,
      "logps/chosen": -164.23971557617188,
      "logps/rejected": -157.846923828125,
      "loss": 0.627,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.1011772155761719,
      "rewards/margins": 0.7525127530097961,
      "rewards/rejected": -1.8536899089813232,
      "step": 3880
    },
    {
      "epoch": 0.7099187882106032,
      "grad_norm": 4.169564723968506,
      "learning_rate": 6.164916804813656e-05,
      "logits/chosen": -1.0177152156829834,
      "logits/rejected": -1.0208004713058472,
      "logps/chosen": -156.4800262451172,
      "logps/rejected": -157.62994384765625,
      "loss": 0.7042,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.039299488067627,
      "rewards/margins": 0.5454182028770447,
      "rewards/rejected": -1.5847175121307373,
      "step": 3890
    },
    {
      "epoch": 0.7117437722419929,
      "grad_norm": 2.293703317642212,
      "learning_rate": 6.160004911892921e-05,
      "logits/chosen": -1.0589748620986938,
      "logits/rejected": -1.0163739919662476,
      "logps/chosen": -160.50881958007812,
      "logps/rejected": -152.1576385498047,
      "loss": 0.6376,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.9001106023788452,
      "rewards/margins": 0.6420888900756836,
      "rewards/rejected": -1.5421994924545288,
      "step": 3900
    },
    {
      "epoch": 0.7135687562733826,
      "grad_norm": 2.1218717098236084,
      "learning_rate": 6.155093018972187e-05,
      "logits/chosen": -0.949549674987793,
      "logits/rejected": -0.9194360971450806,
      "logps/chosen": -153.4720458984375,
      "logps/rejected": -146.96957397460938,
      "loss": 0.5388,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0300092697143555,
      "rewards/margins": 0.6446266174316406,
      "rewards/rejected": -1.674635887145996,
      "step": 3910
    },
    {
      "epoch": 0.7153937403047723,
      "grad_norm": 2.9821536540985107,
      "learning_rate": 6.150181126051453e-05,
      "logits/chosen": -0.9576695561408997,
      "logits/rejected": -0.896777331829071,
      "logps/chosen": -165.6584930419922,
      "logps/rejected": -148.12814331054688,
      "loss": 0.5753,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0241906642913818,
      "rewards/margins": 0.693987250328064,
      "rewards/rejected": -1.7181780338287354,
      "step": 3920
    },
    {
      "epoch": 0.7172187243361621,
      "grad_norm": 2.5952649116516113,
      "learning_rate": 6.145269233130719e-05,
      "logits/chosen": -0.967799186706543,
      "logits/rejected": -0.9297107458114624,
      "logps/chosen": -143.68807983398438,
      "logps/rejected": -152.3903350830078,
      "loss": 0.6083,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0542409420013428,
      "rewards/margins": 0.7709645628929138,
      "rewards/rejected": -1.8252055644989014,
      "step": 3930
    },
    {
      "epoch": 0.7190437083675518,
      "grad_norm": 2.5038139820098877,
      "learning_rate": 6.140357340209984e-05,
      "logits/chosen": -1.0027878284454346,
      "logits/rejected": -0.9778119921684265,
      "logps/chosen": -137.515625,
      "logps/rejected": -140.13150024414062,
      "loss": 0.5794,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.033294916152954,
      "rewards/margins": 0.6266264915466309,
      "rewards/rejected": -1.6599212884902954,
      "step": 3940
    },
    {
      "epoch": 0.7208686923989415,
      "grad_norm": 1.5695843696594238,
      "learning_rate": 6.13544544728925e-05,
      "logits/chosen": -0.990215003490448,
      "logits/rejected": -0.9075043797492981,
      "logps/chosen": -173.13897705078125,
      "logps/rejected": -149.01853942871094,
      "loss": 0.4424,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.069602608680725,
      "rewards/margins": 0.9775508642196655,
      "rewards/rejected": -2.0471534729003906,
      "step": 3950
    },
    {
      "epoch": 0.7226936764303312,
      "grad_norm": 4.096615791320801,
      "learning_rate": 6.130533554368515e-05,
      "logits/chosen": -0.9591127634048462,
      "logits/rejected": -0.9369780421257019,
      "logps/chosen": -161.92994689941406,
      "logps/rejected": -154.10720825195312,
      "loss": 0.5632,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0949363708496094,
      "rewards/margins": 0.7695716619491577,
      "rewards/rejected": -1.864508032798767,
      "step": 3960
    },
    {
      "epoch": 0.724518660461721,
      "grad_norm": 1.9153668880462646,
      "learning_rate": 6.125621661447782e-05,
      "logits/chosen": -0.9262069463729858,
      "logits/rejected": -0.8886105418205261,
      "logps/chosen": -143.2192840576172,
      "logps/rejected": -144.62808227539062,
      "loss": 0.5298,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.06766676902771,
      "rewards/margins": 1.060031533241272,
      "rewards/rejected": -2.1276981830596924,
      "step": 3970
    },
    {
      "epoch": 0.7263436444931107,
      "grad_norm": 1.842652678489685,
      "learning_rate": 6.120709768527046e-05,
      "logits/chosen": -0.9665287137031555,
      "logits/rejected": -0.8832970857620239,
      "logps/chosen": -156.509765625,
      "logps/rejected": -137.5894012451172,
      "loss": 0.5069,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1248308420181274,
      "rewards/margins": 1.1481233835220337,
      "rewards/rejected": -2.272953987121582,
      "step": 3980
    },
    {
      "epoch": 0.7281686285245004,
      "grad_norm": 2.425903558731079,
      "learning_rate": 6.115797875606312e-05,
      "logits/chosen": -1.0275981426239014,
      "logits/rejected": -0.9206088185310364,
      "logps/chosen": -180.73622131347656,
      "logps/rejected": -152.50479125976562,
      "loss": 0.4998,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.0197240114212036,
      "rewards/margins": 1.2914034128189087,
      "rewards/rejected": -2.3111276626586914,
      "step": 3990
    },
    {
      "epoch": 0.7299936125558901,
      "grad_norm": 3.2217421531677246,
      "learning_rate": 6.110885982685578e-05,
      "logits/chosen": -1.006898045539856,
      "logits/rejected": -0.9381998777389526,
      "logps/chosen": -162.582275390625,
      "logps/rejected": -147.90689086914062,
      "loss": 0.5853,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2568676471710205,
      "rewards/margins": 0.9928649067878723,
      "rewards/rejected": -2.249732494354248,
      "step": 4000
    },
    {
      "epoch": 0.7318185965872799,
      "grad_norm": 3.0287582874298096,
      "learning_rate": 6.105974089764843e-05,
      "logits/chosen": -0.9926563501358032,
      "logits/rejected": -0.9304376840591431,
      "logps/chosen": -152.2515411376953,
      "logps/rejected": -136.03067016601562,
      "loss": 0.561,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1491806507110596,
      "rewards/margins": 1.0114840269088745,
      "rewards/rejected": -2.1606645584106445,
      "step": 4010
    },
    {
      "epoch": 0.7336435806186696,
      "grad_norm": 1.7590866088867188,
      "learning_rate": 6.101062196844109e-05,
      "logits/chosen": -0.9808505773544312,
      "logits/rejected": -0.8966771960258484,
      "logps/chosen": -159.62399291992188,
      "logps/rejected": -150.38197326660156,
      "loss": 0.4377,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4672116041183472,
      "rewards/margins": 1.2315012216567993,
      "rewards/rejected": -2.6987133026123047,
      "step": 4020
    },
    {
      "epoch": 0.7354685646500593,
      "grad_norm": 1.678882122039795,
      "learning_rate": 6.096150303923375e-05,
      "logits/chosen": -0.9630414247512817,
      "logits/rejected": -0.8977004289627075,
      "logps/chosen": -162.89208984375,
      "logps/rejected": -162.30007934570312,
      "loss": 0.4689,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9505430459976196,
      "rewards/margins": 1.3178589344024658,
      "rewards/rejected": -2.268401622772217,
      "step": 4030
    },
    {
      "epoch": 0.737293548681449,
      "grad_norm": 2.41355037689209,
      "learning_rate": 6.091238411002641e-05,
      "logits/chosen": -1.0104801654815674,
      "logits/rejected": -0.8688886761665344,
      "logps/chosen": -180.27651977539062,
      "logps/rejected": -140.19100952148438,
      "loss": 0.3503,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.012826681137085,
      "rewards/margins": 1.6845834255218506,
      "rewards/rejected": -2.6974103450775146,
      "step": 4040
    },
    {
      "epoch": 0.7391185327128388,
      "grad_norm": 4.785682201385498,
      "learning_rate": 6.0863265180819066e-05,
      "logits/chosen": -0.9081970453262329,
      "logits/rejected": -0.82274329662323,
      "logps/chosen": -159.85108947753906,
      "logps/rejected": -145.0712890625,
      "loss": 0.5903,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.118152379989624,
      "rewards/margins": 1.4236104488372803,
      "rewards/rejected": -2.5417628288269043,
      "step": 4050
    },
    {
      "epoch": 0.7409435167442285,
      "grad_norm": 4.424059867858887,
      "learning_rate": 6.0814146251611717e-05,
      "logits/chosen": -0.9471176266670227,
      "logits/rejected": -0.9132665395736694,
      "logps/chosen": -151.60317993164062,
      "logps/rejected": -153.47203063964844,
      "loss": 0.6609,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8146387338638306,
      "rewards/margins": 0.9661059379577637,
      "rewards/rejected": -1.7807445526123047,
      "step": 4060
    },
    {
      "epoch": 0.7427685007756182,
      "grad_norm": 1.8263617753982544,
      "learning_rate": 6.0765027322404374e-05,
      "logits/chosen": -0.9069005250930786,
      "logits/rejected": -0.8499140739440918,
      "logps/chosen": -148.63278198242188,
      "logps/rejected": -145.7271728515625,
      "loss": 0.6361,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.5885508060455322,
      "rewards/margins": 0.9754274487495422,
      "rewards/rejected": -1.5639780759811401,
      "step": 4070
    },
    {
      "epoch": 0.7445934848070079,
      "grad_norm": 3.323284864425659,
      "learning_rate": 6.071590839319704e-05,
      "logits/chosen": -0.9291952252388,
      "logits/rejected": -0.8560894727706909,
      "logps/chosen": -156.5521240234375,
      "logps/rejected": -145.0399932861328,
      "loss": 0.4999,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6239787936210632,
      "rewards/margins": 1.0881397724151611,
      "rewards/rejected": -1.7121185064315796,
      "step": 4080
    },
    {
      "epoch": 0.7464184688383977,
      "grad_norm": 3.4985737800598145,
      "learning_rate": 6.066678946398969e-05,
      "logits/chosen": -0.8752597570419312,
      "logits/rejected": -0.8455106616020203,
      "logps/chosen": -161.55514526367188,
      "logps/rejected": -160.49453735351562,
      "loss": 0.6536,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.2304680347442627,
      "rewards/margins": 0.5734566450119019,
      "rewards/rejected": -1.803924560546875,
      "step": 4090
    },
    {
      "epoch": 0.7482434528697874,
      "grad_norm": 2.204221248626709,
      "learning_rate": 6.061767053478235e-05,
      "logits/chosen": -0.9362679719924927,
      "logits/rejected": -0.8851253390312195,
      "logps/chosen": -154.7608184814453,
      "logps/rejected": -147.1708526611328,
      "loss": 0.5932,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0991456508636475,
      "rewards/margins": 0.8293946981430054,
      "rewards/rejected": -1.9285404682159424,
      "step": 4100
    },
    {
      "epoch": 0.7500684369011771,
      "grad_norm": 3.1056950092315674,
      "learning_rate": 6.0568551605575005e-05,
      "logits/chosen": -0.8983865976333618,
      "logits/rejected": -0.8765426874160767,
      "logps/chosen": -140.48556518554688,
      "logps/rejected": -143.51138305664062,
      "loss": 0.6141,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.2108579874038696,
      "rewards/margins": 0.5656418800354004,
      "rewards/rejected": -1.7764999866485596,
      "step": 4110
    },
    {
      "epoch": 0.7518934209325668,
      "grad_norm": 2.7026453018188477,
      "learning_rate": 6.051943267636766e-05,
      "logits/chosen": -0.9283899068832397,
      "logits/rejected": -0.8180937767028809,
      "logps/chosen": -175.3411407470703,
      "logps/rejected": -145.901123046875,
      "loss": 0.4654,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.9650579690933228,
      "rewards/margins": 1.0756226778030396,
      "rewards/rejected": -2.040680408477783,
      "step": 4120
    },
    {
      "epoch": 0.7537184049639566,
      "grad_norm": 3.4445786476135254,
      "learning_rate": 6.0470313747160314e-05,
      "logits/chosen": -0.892591655254364,
      "logits/rejected": -0.8504917025566101,
      "logps/chosen": -161.96902465820312,
      "logps/rejected": -157.01416015625,
      "loss": 0.6593,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.8206362724304199,
      "rewards/margins": 0.7249047160148621,
      "rewards/rejected": -1.5455410480499268,
      "step": 4130
    },
    {
      "epoch": 0.7555433889953463,
      "grad_norm": 2.1152572631835938,
      "learning_rate": 6.042119481795297e-05,
      "logits/chosen": -0.8142873644828796,
      "logits/rejected": -0.7463887333869934,
      "logps/chosen": -168.92098999023438,
      "logps/rejected": -138.272216796875,
      "loss": 0.5918,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.165950894355774,
      "rewards/margins": 0.8532156944274902,
      "rewards/rejected": -2.0191664695739746,
      "step": 4140
    },
    {
      "epoch": 0.757368373026736,
      "grad_norm": 2.418738842010498,
      "learning_rate": 6.0372075888745636e-05,
      "logits/chosen": -0.87725430727005,
      "logits/rejected": -0.852221667766571,
      "logps/chosen": -141.7292022705078,
      "logps/rejected": -139.36038208007812,
      "loss": 0.5527,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.0140063762664795,
      "rewards/margins": 0.6340230703353882,
      "rewards/rejected": -1.6480295658111572,
      "step": 4150
    },
    {
      "epoch": 0.7591933570581257,
      "grad_norm": 3.412874937057495,
      "learning_rate": 6.032295695953829e-05,
      "logits/chosen": -0.90626460313797,
      "logits/rejected": -0.8764744997024536,
      "logps/chosen": -153.41549682617188,
      "logps/rejected": -156.0861358642578,
      "loss": 0.5852,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8525703549385071,
      "rewards/margins": 0.8950702548027039,
      "rewards/rejected": -1.7476403713226318,
      "step": 4160
    },
    {
      "epoch": 0.7610183410895155,
      "grad_norm": 2.46697735786438,
      "learning_rate": 6.0273838030330945e-05,
      "logits/chosen": -0.9737333059310913,
      "logits/rejected": -0.9155046343803406,
      "logps/chosen": -164.6267547607422,
      "logps/rejected": -143.0704345703125,
      "loss": 0.6048,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5686266422271729,
      "rewards/margins": 0.7926653027534485,
      "rewards/rejected": -1.3612918853759766,
      "step": 4170
    },
    {
      "epoch": 0.7628433251209052,
      "grad_norm": 2.714245557785034,
      "learning_rate": 6.0224719101123596e-05,
      "logits/chosen": -0.9933279752731323,
      "logits/rejected": -0.9603748321533203,
      "logps/chosen": -151.9747314453125,
      "logps/rejected": -146.53250122070312,
      "loss": 0.513,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.518363356590271,
      "rewards/margins": 0.8894457817077637,
      "rewards/rejected": -1.4078090190887451,
      "step": 4180
    },
    {
      "epoch": 0.7646683091522949,
      "grad_norm": 1.926641583442688,
      "learning_rate": 6.017560017191626e-05,
      "logits/chosen": -0.9243524670600891,
      "logits/rejected": -0.8950763940811157,
      "logps/chosen": -155.41256713867188,
      "logps/rejected": -154.6746368408203,
      "loss": 0.6445,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.7478889226913452,
      "rewards/margins": 0.5272976160049438,
      "rewards/rejected": -1.275186538696289,
      "step": 4190
    },
    {
      "epoch": 0.7664932931836846,
      "grad_norm": 9.326643943786621,
      "learning_rate": 6.012648124270891e-05,
      "logits/chosen": -0.9351406097412109,
      "logits/rejected": -0.8842889070510864,
      "logps/chosen": -150.21334838867188,
      "logps/rejected": -145.1216278076172,
      "loss": 0.5329,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.1910138875246048,
      "rewards/margins": 1.00713312625885,
      "rewards/rejected": -1.198146939277649,
      "step": 4200
    },
    {
      "epoch": 0.7683182772150744,
      "grad_norm": 3.4477486610412598,
      "learning_rate": 6.007736231350157e-05,
      "logits/chosen": -0.8909740447998047,
      "logits/rejected": -0.8503479957580566,
      "logps/chosen": -143.9760284423828,
      "logps/rejected": -133.82546997070312,
      "loss": 0.5749,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.6299739480018616,
      "rewards/margins": 0.7455636858940125,
      "rewards/rejected": -1.3755377531051636,
      "step": 4210
    },
    {
      "epoch": 0.770143261246464,
      "grad_norm": 2.860316753387451,
      "learning_rate": 6.0028243384294233e-05,
      "logits/chosen": -1.0197210311889648,
      "logits/rejected": -0.9209823608398438,
      "logps/chosen": -159.70523071289062,
      "logps/rejected": -137.04293823242188,
      "loss": 0.5147,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7975758910179138,
      "rewards/margins": 1.0152089595794678,
      "rewards/rejected": -1.8127849102020264,
      "step": 4220
    },
    {
      "epoch": 0.7719682452778538,
      "grad_norm": 2.0720341205596924,
      "learning_rate": 5.9979124455086884e-05,
      "logits/chosen": -0.9994536638259888,
      "logits/rejected": -0.9420525431632996,
      "logps/chosen": -149.6705322265625,
      "logps/rejected": -147.62435913085938,
      "loss": 0.489,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0944498777389526,
      "rewards/margins": 0.9762037396430969,
      "rewards/rejected": -2.0706534385681152,
      "step": 4230
    },
    {
      "epoch": 0.7737932293092435,
      "grad_norm": 5.338988304138184,
      "learning_rate": 5.993000552587954e-05,
      "logits/chosen": -0.9309932589530945,
      "logits/rejected": -0.8563265800476074,
      "logps/chosen": -167.95323181152344,
      "logps/rejected": -154.8676300048828,
      "loss": 0.5621,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4220112562179565,
      "rewards/margins": 0.9325252771377563,
      "rewards/rejected": -2.354536771774292,
      "step": 4240
    },
    {
      "epoch": 0.7756182133406333,
      "grad_norm": 2.740114212036133,
      "learning_rate": 5.988088659667219e-05,
      "logits/chosen": -0.9167868494987488,
      "logits/rejected": -0.8648088574409485,
      "logps/chosen": -158.44216918945312,
      "logps/rejected": -155.27938842773438,
      "loss": 0.5105,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.429931402206421,
      "rewards/margins": 1.1910799741744995,
      "rewards/rejected": -2.621011734008789,
      "step": 4250
    },
    {
      "epoch": 0.7774431973720229,
      "grad_norm": 3.233290672302246,
      "learning_rate": 5.983176766746486e-05,
      "logits/chosen": -0.9203929901123047,
      "logits/rejected": -0.879921555519104,
      "logps/chosen": -153.05255126953125,
      "logps/rejected": -158.1848907470703,
      "loss": 0.511,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.457005262374878,
      "rewards/margins": 1.1943949460983276,
      "rewards/rejected": -2.651400327682495,
      "step": 4260
    },
    {
      "epoch": 0.7792681814034127,
      "grad_norm": 2.750704288482666,
      "learning_rate": 5.978264873825751e-05,
      "logits/chosen": -0.9439778327941895,
      "logits/rejected": -0.9035431146621704,
      "logps/chosen": -165.73562622070312,
      "logps/rejected": -158.91421508789062,
      "loss": 0.5588,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.522352933883667,
      "rewards/margins": 0.8734229207038879,
      "rewards/rejected": -2.3957760334014893,
      "step": 4270
    },
    {
      "epoch": 0.7810931654348024,
      "grad_norm": 3.313737630844116,
      "learning_rate": 5.9733529809050166e-05,
      "logits/chosen": -0.8814813494682312,
      "logits/rejected": -0.8196302652359009,
      "logps/chosen": -152.34786987304688,
      "logps/rejected": -148.89151000976562,
      "loss": 0.5837,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.8753032684326172,
      "rewards/margins": 0.8872653245925903,
      "rewards/rejected": -2.7625679969787598,
      "step": 4280
    },
    {
      "epoch": 0.7829181494661922,
      "grad_norm": 3.9583232402801514,
      "learning_rate": 5.968441087984282e-05,
      "logits/chosen": -0.891797661781311,
      "logits/rejected": -0.8361543416976929,
      "logps/chosen": -168.9193572998047,
      "logps/rejected": -155.76675415039062,
      "loss": 0.6082,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.5275660753250122,
      "rewards/margins": 0.8088191151618958,
      "rewards/rejected": -2.3363852500915527,
      "step": 4290
    },
    {
      "epoch": 0.7847431334975818,
      "grad_norm": 2.33396053314209,
      "learning_rate": 5.963529195063548e-05,
      "logits/chosen": -0.8929265141487122,
      "logits/rejected": -0.8324570655822754,
      "logps/chosen": -157.3278350830078,
      "logps/rejected": -148.7550506591797,
      "loss": 0.5761,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.7727245092391968,
      "rewards/margins": 0.9252457618713379,
      "rewards/rejected": -2.697970151901245,
      "step": 4300
    },
    {
      "epoch": 0.7865681175289716,
      "grad_norm": 2.710165500640869,
      "learning_rate": 5.958617302142814e-05,
      "logits/chosen": -0.8981930613517761,
      "logits/rejected": -0.799906849861145,
      "logps/chosen": -158.75927734375,
      "logps/rejected": -152.9349365234375,
      "loss": 0.4115,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4963338375091553,
      "rewards/margins": 1.3111255168914795,
      "rewards/rejected": -2.8074593544006348,
      "step": 4310
    },
    {
      "epoch": 0.7883931015603614,
      "grad_norm": 2.7265424728393555,
      "learning_rate": 5.953705409222079e-05,
      "logits/chosen": -0.8226256370544434,
      "logits/rejected": -0.734388530254364,
      "logps/chosen": -176.98239135742188,
      "logps/rejected": -154.54290771484375,
      "loss": 0.4559,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.784733772277832,
      "rewards/margins": 1.119943618774414,
      "rewards/rejected": -2.904677391052246,
      "step": 4320
    },
    {
      "epoch": 0.7902180855917511,
      "grad_norm": 2.920877456665039,
      "learning_rate": 5.9487935163013455e-05,
      "logits/chosen": -0.8537628054618835,
      "logits/rejected": -0.8128606677055359,
      "logps/chosen": -161.42904663085938,
      "logps/rejected": -150.89259338378906,
      "loss": 0.5524,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.099216938018799,
      "rewards/margins": 0.8892378807067871,
      "rewards/rejected": -2.988455057144165,
      "step": 4330
    },
    {
      "epoch": 0.7920430696231407,
      "grad_norm": 3.08870530128479,
      "learning_rate": 5.9438816233806106e-05,
      "logits/chosen": -0.9274349212646484,
      "logits/rejected": -0.832233726978302,
      "logps/chosen": -164.25083923339844,
      "logps/rejected": -148.26368713378906,
      "loss": 0.5152,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.103604793548584,
      "rewards/margins": 1.0658994913101196,
      "rewards/rejected": -3.169504404067993,
      "step": 4340
    },
    {
      "epoch": 0.7938680536545305,
      "grad_norm": 2.3482518196105957,
      "learning_rate": 5.9389697304598764e-05,
      "logits/chosen": -0.9543951153755188,
      "logits/rejected": -0.795493483543396,
      "logps/chosen": -195.68203735351562,
      "logps/rejected": -153.64598083496094,
      "loss": 0.5029,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7279554605484009,
      "rewards/margins": 1.045624017715454,
      "rewards/rejected": -2.7735795974731445,
      "step": 4350
    },
    {
      "epoch": 0.7956930376859203,
      "grad_norm": 3.7228565216064453,
      "learning_rate": 5.9340578375391415e-05,
      "logits/chosen": -0.978564441204071,
      "logits/rejected": -0.8769963383674622,
      "logps/chosen": -184.82461547851562,
      "logps/rejected": -170.39784240722656,
      "loss": 0.4939,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.3958938121795654,
      "rewards/margins": 1.1732228994369507,
      "rewards/rejected": -2.5691170692443848,
      "step": 4360
    },
    {
      "epoch": 0.79751802171731,
      "grad_norm": 3.4291820526123047,
      "learning_rate": 5.929145944618408e-05,
      "logits/chosen": -0.9926192164421082,
      "logits/rejected": -0.8760460615158081,
      "logps/chosen": -168.53964233398438,
      "logps/rejected": -140.42587280273438,
      "loss": 0.468,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3827701807022095,
      "rewards/margins": 1.2972242832183838,
      "rewards/rejected": -2.679994583129883,
      "step": 4370
    },
    {
      "epoch": 0.7993430057486997,
      "grad_norm": 2.0555360317230225,
      "learning_rate": 5.924234051697674e-05,
      "logits/chosen": -0.9771251678466797,
      "logits/rejected": -0.8364455103874207,
      "logps/chosen": -172.3146209716797,
      "logps/rejected": -143.7196502685547,
      "loss": 0.4237,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.562770128250122,
      "rewards/margins": 1.5471967458724976,
      "rewards/rejected": -3.109966993331909,
      "step": 4380
    },
    {
      "epoch": 0.8011679897800894,
      "grad_norm": 2.136920213699341,
      "learning_rate": 5.919322158776939e-05,
      "logits/chosen": -1.0647311210632324,
      "logits/rejected": -0.9941169619560242,
      "logps/chosen": -162.76528930664062,
      "logps/rejected": -156.7453155517578,
      "loss": 0.6361,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.7188072204589844,
      "rewards/margins": 1.0868103504180908,
      "rewards/rejected": -2.8056178092956543,
      "step": 4390
    },
    {
      "epoch": 0.8029929738114792,
      "grad_norm": 3.127504348754883,
      "learning_rate": 5.914410265856205e-05,
      "logits/chosen": -1.0448135137557983,
      "logits/rejected": -0.9609793424606323,
      "logps/chosen": -167.6468963623047,
      "logps/rejected": -158.00045776367188,
      "loss": 0.4599,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2961183786392212,
      "rewards/margins": 1.4789855480194092,
      "rewards/rejected": -2.775103807449341,
      "step": 4400
    },
    {
      "epoch": 0.8048179578428689,
      "grad_norm": 1.5815482139587402,
      "learning_rate": 5.909498372935471e-05,
      "logits/chosen": -1.07137930393219,
      "logits/rejected": -0.9898843765258789,
      "logps/chosen": -167.1034393310547,
      "logps/rejected": -155.545654296875,
      "loss": 0.6722,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.154664397239685,
      "rewards/margins": 0.9815394282341003,
      "rewards/rejected": -2.1362040042877197,
      "step": 4410
    },
    {
      "epoch": 0.8066429418742586,
      "grad_norm": 2.407804489135742,
      "learning_rate": 5.904586480014736e-05,
      "logits/chosen": -0.9649271965026855,
      "logits/rejected": -0.9228092432022095,
      "logps/chosen": -143.5159454345703,
      "logps/rejected": -144.7267608642578,
      "loss": 0.5231,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.772365391254425,
      "rewards/margins": 1.1829222440719604,
      "rewards/rejected": -1.9552875757217407,
      "step": 4420
    },
    {
      "epoch": 0.8084679259056483,
      "grad_norm": 3.630671501159668,
      "learning_rate": 5.899674587094002e-05,
      "logits/chosen": -0.9520279169082642,
      "logits/rejected": -0.8994013071060181,
      "logps/chosen": -167.3197479248047,
      "logps/rejected": -158.45350646972656,
      "loss": 0.5007,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9422688484191895,
      "rewards/margins": 1.3282625675201416,
      "rewards/rejected": -2.27053165435791,
      "step": 4430
    },
    {
      "epoch": 0.8102929099370381,
      "grad_norm": 3.3705663681030273,
      "learning_rate": 5.8947626941732676e-05,
      "logits/chosen": -0.9501277804374695,
      "logits/rejected": -0.8899652361869812,
      "logps/chosen": -163.33828735351562,
      "logps/rejected": -155.48646545410156,
      "loss": 0.4202,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.0758894681930542,
      "rewards/margins": 1.2405351400375366,
      "rewards/rejected": -2.316424608230591,
      "step": 4440
    },
    {
      "epoch": 0.8121178939684278,
      "grad_norm": 2.6185989379882812,
      "learning_rate": 5.8898508012525334e-05,
      "logits/chosen": -0.9699400663375854,
      "logits/rejected": -0.8747140765190125,
      "logps/chosen": -168.50526428222656,
      "logps/rejected": -160.33297729492188,
      "loss": 0.5711,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.048724889755249,
      "rewards/margins": 1.2545045614242554,
      "rewards/rejected": -2.303229808807373,
      "step": 4450
    },
    {
      "epoch": 0.8139428779998175,
      "grad_norm": 2.653792381286621,
      "learning_rate": 5.8849389083317985e-05,
      "logits/chosen": -0.9279354810714722,
      "logits/rejected": -0.9061506390571594,
      "logps/chosen": -154.77261352539062,
      "logps/rejected": -173.21450805664062,
      "loss": 0.5642,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.106207013130188,
      "rewards/margins": 0.9816583395004272,
      "rewards/rejected": -2.0878653526306152,
      "step": 4460
    },
    {
      "epoch": 0.8157678620312072,
      "grad_norm": 4.099514007568359,
      "learning_rate": 5.880027015411064e-05,
      "logits/chosen": -0.8510887026786804,
      "logits/rejected": -0.8044174313545227,
      "logps/chosen": -155.17367553710938,
      "logps/rejected": -146.2913055419922,
      "loss": 0.5932,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.9494574666023254,
      "rewards/margins": 0.8723627328872681,
      "rewards/rejected": -1.8218200206756592,
      "step": 4470
    },
    {
      "epoch": 0.817592846062597,
      "grad_norm": 2.2188687324523926,
      "learning_rate": 5.875115122490331e-05,
      "logits/chosen": -0.8965705037117004,
      "logits/rejected": -0.855582058429718,
      "logps/chosen": -145.00341796875,
      "logps/rejected": -152.5525665283203,
      "loss": 0.557,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.652914822101593,
      "rewards/margins": 0.9998526573181152,
      "rewards/rejected": -1.6527674198150635,
      "step": 4480
    },
    {
      "epoch": 0.8194178300939867,
      "grad_norm": 3.8631770610809326,
      "learning_rate": 5.870203229569596e-05,
      "logits/chosen": -0.8817821741104126,
      "logits/rejected": -0.8100302815437317,
      "logps/chosen": -140.6031951904297,
      "logps/rejected": -138.64553833007812,
      "loss": 0.4704,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.38554590940475464,
      "rewards/margins": 1.1234920024871826,
      "rewards/rejected": -1.5090378522872925,
      "step": 4490
    },
    {
      "epoch": 0.8212428141253764,
      "grad_norm": 2.966867685317993,
      "learning_rate": 5.8652913366488616e-05,
      "logits/chosen": -0.9818375706672668,
      "logits/rejected": -0.8817569613456726,
      "logps/chosen": -170.30502319335938,
      "logps/rejected": -154.44464111328125,
      "loss": 0.449,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7271925210952759,
      "rewards/margins": 1.4512577056884766,
      "rewards/rejected": -2.178450107574463,
      "step": 4500
    },
    {
      "epoch": 0.8230677981567661,
      "grad_norm": 3.1054985523223877,
      "learning_rate": 5.8603794437281274e-05,
      "logits/chosen": -0.9569937586784363,
      "logits/rejected": -0.9529527425765991,
      "logps/chosen": -145.02621459960938,
      "logps/rejected": -152.6805877685547,
      "loss": 0.5351,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.4263145327568054,
      "rewards/margins": 1.0006617307662964,
      "rewards/rejected": -1.426976203918457,
      "step": 4510
    },
    {
      "epoch": 0.8248927821881559,
      "grad_norm": 2.0403573513031006,
      "learning_rate": 5.855467550807393e-05,
      "logits/chosen": -0.9722638130187988,
      "logits/rejected": -0.9155367016792297,
      "logps/chosen": -141.40206909179688,
      "logps/rejected": -133.13360595703125,
      "loss": 0.3967,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 0.03117787465453148,
      "rewards/margins": 1.568854570388794,
      "rewards/rejected": -1.5376765727996826,
      "step": 4520
    },
    {
      "epoch": 0.8267177662195456,
      "grad_norm": 3.648918628692627,
      "learning_rate": 5.850555657886658e-05,
      "logits/chosen": -0.8837990760803223,
      "logits/rejected": -0.8821280598640442,
      "logps/chosen": -137.7579803466797,
      "logps/rejected": -156.7877655029297,
      "loss": 0.5762,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.45296090841293335,
      "rewards/margins": 1.0017281770706177,
      "rewards/rejected": -1.4546892642974854,
      "step": 4530
    },
    {
      "epoch": 0.8285427502509353,
      "grad_norm": 4.044806957244873,
      "learning_rate": 5.845643764965924e-05,
      "logits/chosen": -0.9292801022529602,
      "logits/rejected": -0.8820875883102417,
      "logps/chosen": -135.79981994628906,
      "logps/rejected": -130.9659881591797,
      "loss": 0.568,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.5896047949790955,
      "rewards/margins": 0.7755955457687378,
      "rewards/rejected": -1.3652002811431885,
      "step": 4540
    },
    {
      "epoch": 0.830367734282325,
      "grad_norm": 1.5913692712783813,
      "learning_rate": 5.8407318720451905e-05,
      "logits/chosen": -0.9315887689590454,
      "logits/rejected": -0.8644964098930359,
      "logps/chosen": -136.66549682617188,
      "logps/rejected": -123.67816162109375,
      "loss": 0.4482,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.4904368817806244,
      "rewards/margins": 1.4712450504302979,
      "rewards/rejected": -1.961681604385376,
      "step": 4550
    },
    {
      "epoch": 0.8321927183137148,
      "grad_norm": 3.1425282955169678,
      "learning_rate": 5.8358199791244556e-05,
      "logits/chosen": -0.9696540832519531,
      "logits/rejected": -0.8712732195854187,
      "logps/chosen": -163.9534912109375,
      "logps/rejected": -138.12353515625,
      "loss": 0.4172,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5384826064109802,
      "rewards/margins": 1.2962779998779297,
      "rewards/rejected": -1.8347604274749756,
      "step": 4560
    },
    {
      "epoch": 0.8340177023451045,
      "grad_norm": 2.947171688079834,
      "learning_rate": 5.8309080862037213e-05,
      "logits/chosen": -0.9899964332580566,
      "logits/rejected": -0.8932679891586304,
      "logps/chosen": -158.59938049316406,
      "logps/rejected": -147.79495239257812,
      "loss": 0.4802,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7754064798355103,
      "rewards/margins": 1.3643652200698853,
      "rewards/rejected": -2.1397716999053955,
      "step": 4570
    },
    {
      "epoch": 0.8358426863764942,
      "grad_norm": 1.4632856845855713,
      "learning_rate": 5.8259961932829864e-05,
      "logits/chosen": -0.9906834363937378,
      "logits/rejected": -0.9338502883911133,
      "logps/chosen": -168.62454223632812,
      "logps/rejected": -157.3106231689453,
      "loss": 0.5287,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7691339254379272,
      "rewards/margins": 1.0221807956695557,
      "rewards/rejected": -1.791314721107483,
      "step": 4580
    },
    {
      "epoch": 0.8376676704078839,
      "grad_norm": 3.817404270172119,
      "learning_rate": 5.821084300362253e-05,
      "logits/chosen": -0.9511874914169312,
      "logits/rejected": -0.9266868829727173,
      "logps/chosen": -144.6981201171875,
      "logps/rejected": -148.91249084472656,
      "loss": 0.6671,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.2251698970794678,
      "rewards/margins": 0.915848433971405,
      "rewards/rejected": -2.1410183906555176,
      "step": 4590
    },
    {
      "epoch": 0.8394926544392737,
      "grad_norm": 3.2505977153778076,
      "learning_rate": 5.816172407441518e-05,
      "logits/chosen": -1.0199429988861084,
      "logits/rejected": -0.9525006413459778,
      "logps/chosen": -157.71261596679688,
      "logps/rejected": -148.52711486816406,
      "loss": 0.4583,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0079591274261475,
      "rewards/margins": 1.2655525207519531,
      "rewards/rejected": -2.2735114097595215,
      "step": 4600
    },
    {
      "epoch": 0.8413176384706634,
      "grad_norm": 3.7594757080078125,
      "learning_rate": 5.811260514520784e-05,
      "logits/chosen": -1.0198206901550293,
      "logits/rejected": -0.9332114458084106,
      "logps/chosen": -167.09671020507812,
      "logps/rejected": -129.87692260742188,
      "loss": 0.5868,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2967150211334229,
      "rewards/margins": 1.0184153318405151,
      "rewards/rejected": -2.3151304721832275,
      "step": 4610
    },
    {
      "epoch": 0.8431426225020531,
      "grad_norm": 2.6073193550109863,
      "learning_rate": 5.80634862160005e-05,
      "logits/chosen": -0.9612151384353638,
      "logits/rejected": -0.9180964231491089,
      "logps/chosen": -142.3863525390625,
      "logps/rejected": -133.6705780029297,
      "loss": 0.4772,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.367849349975586,
      "rewards/margins": 1.172874093055725,
      "rewards/rejected": -2.5407233238220215,
      "step": 4620
    },
    {
      "epoch": 0.8449676065334428,
      "grad_norm": 1.2041130065917969,
      "learning_rate": 5.801436728679315e-05,
      "logits/chosen": -0.9952105283737183,
      "logits/rejected": -0.9548454284667969,
      "logps/chosen": -145.38870239257812,
      "logps/rejected": -142.541259765625,
      "loss": 0.493,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9283871650695801,
      "rewards/margins": 1.4297140836715698,
      "rewards/rejected": -2.3581013679504395,
      "step": 4630
    },
    {
      "epoch": 0.8467925905648326,
      "grad_norm": 3.6429049968719482,
      "learning_rate": 5.796524835758581e-05,
      "logits/chosen": -0.9947498440742493,
      "logits/rejected": -0.959227442741394,
      "logps/chosen": -153.47756958007812,
      "logps/rejected": -154.09405517578125,
      "loss": 0.5345,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9227115511894226,
      "rewards/margins": 1.1983524560928345,
      "rewards/rejected": -2.1210639476776123,
      "step": 4640
    },
    {
      "epoch": 0.8486175745962223,
      "grad_norm": 3.648871898651123,
      "learning_rate": 5.791612942837846e-05,
      "logits/chosen": -0.9818496704101562,
      "logits/rejected": -0.9328432083129883,
      "logps/chosen": -164.5284881591797,
      "logps/rejected": -158.37466430664062,
      "loss": 0.5156,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5721994638442993,
      "rewards/margins": 1.272998571395874,
      "rewards/rejected": -1.8451976776123047,
      "step": 4650
    },
    {
      "epoch": 0.850442558627612,
      "grad_norm": 2.013655424118042,
      "learning_rate": 5.7867010499171126e-05,
      "logits/chosen": -0.9200257062911987,
      "logits/rejected": -0.9022841453552246,
      "logps/chosen": -164.0541534423828,
      "logps/rejected": -166.19265747070312,
      "loss": 0.5093,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.5180753469467163,
      "rewards/margins": 1.0936180353164673,
      "rewards/rejected": -1.6116933822631836,
      "step": 4660
    },
    {
      "epoch": 0.8522675426590017,
      "grad_norm": 4.8782453536987305,
      "learning_rate": 5.781789156996378e-05,
      "logits/chosen": -0.9319046139717102,
      "logits/rejected": -0.8741620779037476,
      "logps/chosen": -141.31808471679688,
      "logps/rejected": -141.91864013671875,
      "loss": 0.4065,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9413517117500305,
      "rewards/margins": 1.634924292564392,
      "rewards/rejected": -2.5762758255004883,
      "step": 4670
    },
    {
      "epoch": 0.8540925266903915,
      "grad_norm": 3.618112325668335,
      "learning_rate": 5.7768772640756435e-05,
      "logits/chosen": -0.8691446185112,
      "logits/rejected": -0.8403630256652832,
      "logps/chosen": -146.63262939453125,
      "logps/rejected": -161.38299560546875,
      "loss": 0.7354,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -1.3696008920669556,
      "rewards/margins": 0.8452728390693665,
      "rewards/rejected": -2.2148735523223877,
      "step": 4680
    },
    {
      "epoch": 0.8559175107217812,
      "grad_norm": 3.9235239028930664,
      "learning_rate": 5.77196537115491e-05,
      "logits/chosen": -0.9007610082626343,
      "logits/rejected": -0.8869879841804504,
      "logps/chosen": -148.36434936523438,
      "logps/rejected": -161.5950164794922,
      "loss": 0.5549,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.1203045845031738,
      "rewards/margins": 0.9897739291191101,
      "rewards/rejected": -2.1100783348083496,
      "step": 4690
    },
    {
      "epoch": 0.8577424947531709,
      "grad_norm": 2.1958227157592773,
      "learning_rate": 5.767053478234175e-05,
      "logits/chosen": -0.8793098330497742,
      "logits/rejected": -0.8398863673210144,
      "logps/chosen": -149.33934020996094,
      "logps/rejected": -141.87142944335938,
      "loss": 0.4596,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7847651243209839,
      "rewards/margins": 1.413576602935791,
      "rewards/rejected": -2.1983418464660645,
      "step": 4700
    },
    {
      "epoch": 0.8595674787845606,
      "grad_norm": 2.508225202560425,
      "learning_rate": 5.762141585313441e-05,
      "logits/chosen": -0.8663309216499329,
      "logits/rejected": -0.7970897555351257,
      "logps/chosen": -143.91128540039062,
      "logps/rejected": -134.97555541992188,
      "loss": 0.515,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9454259872436523,
      "rewards/margins": 1.1402616500854492,
      "rewards/rejected": -2.0856876373291016,
      "step": 4710
    },
    {
      "epoch": 0.8613924628159504,
      "grad_norm": 5.221670150756836,
      "learning_rate": 5.757229692392706e-05,
      "logits/chosen": -0.8899906277656555,
      "logits/rejected": -0.8221204876899719,
      "logps/chosen": -145.82530212402344,
      "logps/rejected": -135.40969848632812,
      "loss": 0.4829,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0149600505828857,
      "rewards/margins": 1.236770749092102,
      "rewards/rejected": -2.2517306804656982,
      "step": 4720
    },
    {
      "epoch": 0.86321744684734,
      "grad_norm": 1.9088116884231567,
      "learning_rate": 5.7523177994719724e-05,
      "logits/chosen": -0.8721631765365601,
      "logits/rejected": -0.8337481617927551,
      "logps/chosen": -137.28451538085938,
      "logps/rejected": -142.5337371826172,
      "loss": 0.5979,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.144695520401001,
      "rewards/margins": 0.8203058242797852,
      "rewards/rejected": -1.9650017023086548,
      "step": 4730
    },
    {
      "epoch": 0.8650424308787298,
      "grad_norm": 4.108124256134033,
      "learning_rate": 5.7474059065512375e-05,
      "logits/chosen": -0.9756788015365601,
      "logits/rejected": -0.863198459148407,
      "logps/chosen": -187.16819763183594,
      "logps/rejected": -150.20809936523438,
      "loss": 0.5736,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.8257268071174622,
      "rewards/margins": 1.0187488794326782,
      "rewards/rejected": -1.844475507736206,
      "step": 4740
    },
    {
      "epoch": 0.8668674149101195,
      "grad_norm": 2.5041756629943848,
      "learning_rate": 5.742494013630503e-05,
      "logits/chosen": -0.9743682742118835,
      "logits/rejected": -0.9304082989692688,
      "logps/chosen": -153.63262939453125,
      "logps/rejected": -162.0976104736328,
      "loss": 0.5978,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.3284485340118408,
      "rewards/margins": 1.065510630607605,
      "rewards/rejected": -2.3939590454101562,
      "step": 4750
    },
    {
      "epoch": 0.8686923989415093,
      "grad_norm": 2.0184316635131836,
      "learning_rate": 5.737582120709768e-05,
      "logits/chosen": -0.9600530862808228,
      "logits/rejected": -0.9686717987060547,
      "logps/chosen": -140.58236694335938,
      "logps/rejected": -180.5942840576172,
      "loss": 0.5143,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.5646671056747437,
      "rewards/margins": 1.1421486139297485,
      "rewards/rejected": -2.706815719604492,
      "step": 4760
    },
    {
      "epoch": 0.8705173829728989,
      "grad_norm": 4.2040181159973145,
      "learning_rate": 5.732670227789035e-05,
      "logits/chosen": -0.9954889416694641,
      "logits/rejected": -0.9476739168167114,
      "logps/chosen": -151.58470153808594,
      "logps/rejected": -154.8973388671875,
      "loss": 0.4752,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3392183780670166,
      "rewards/margins": 1.2391836643218994,
      "rewards/rejected": -2.578401803970337,
      "step": 4770
    },
    {
      "epoch": 0.8723423670042887,
      "grad_norm": 2.8926851749420166,
      "learning_rate": 5.7277583348683005e-05,
      "logits/chosen": -0.9958928227424622,
      "logits/rejected": -0.9964374303817749,
      "logps/chosen": -167.73536682128906,
      "logps/rejected": -167.41012573242188,
      "loss": 0.5636,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.2367775440216064,
      "rewards/margins": 0.9988404512405396,
      "rewards/rejected": -2.2356181144714355,
      "step": 4780
    },
    {
      "epoch": 0.8741673510356784,
      "grad_norm": 3.1224870681762695,
      "learning_rate": 5.7228464419475656e-05,
      "logits/chosen": -1.0235477685928345,
      "logits/rejected": -0.9765291213989258,
      "logps/chosen": -144.57290649414062,
      "logps/rejected": -136.88165283203125,
      "loss": 0.4249,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9719170331954956,
      "rewards/margins": 1.3410948514938354,
      "rewards/rejected": -2.313011884689331,
      "step": 4790
    },
    {
      "epoch": 0.8759923350670682,
      "grad_norm": 3.5783910751342773,
      "learning_rate": 5.717934549026832e-05,
      "logits/chosen": -1.0015575885772705,
      "logits/rejected": -0.9680362939834595,
      "logps/chosen": -154.35494995117188,
      "logps/rejected": -162.1076202392578,
      "loss": 0.5517,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2291481494903564,
      "rewards/margins": 1.1048325300216675,
      "rewards/rejected": -2.3339807987213135,
      "step": 4800
    },
    {
      "epoch": 0.8778173190984578,
      "grad_norm": 3.7563469409942627,
      "learning_rate": 5.713022656106097e-05,
      "logits/chosen": -0.9942220449447632,
      "logits/rejected": -0.9555584788322449,
      "logps/chosen": -152.8428192138672,
      "logps/rejected": -153.6700897216797,
      "loss": 0.4768,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2877395153045654,
      "rewards/margins": 1.0929423570632935,
      "rewards/rejected": -2.3806817531585693,
      "step": 4810
    },
    {
      "epoch": 0.8796423031298476,
      "grad_norm": 3.2283401489257812,
      "learning_rate": 5.708110763185363e-05,
      "logits/chosen": -1.0022032260894775,
      "logits/rejected": -0.9869782328605652,
      "logps/chosen": -156.33148193359375,
      "logps/rejected": -156.2192840576172,
      "loss": 0.497,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.026256799697876,
      "rewards/margins": 1.112194538116455,
      "rewards/rejected": -2.138451099395752,
      "step": 4820
    },
    {
      "epoch": 0.8814672871612373,
      "grad_norm": 3.2001733779907227,
      "learning_rate": 5.703198870264628e-05,
      "logits/chosen": -0.9292517900466919,
      "logits/rejected": -0.8661554455757141,
      "logps/chosen": -175.45896911621094,
      "logps/rejected": -152.75796508789062,
      "loss": 0.5446,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.997602105140686,
      "rewards/margins": 1.1463972330093384,
      "rewards/rejected": -2.1439995765686035,
      "step": 4830
    },
    {
      "epoch": 0.8832922711926271,
      "grad_norm": 2.449540853500366,
      "learning_rate": 5.6982869773438945e-05,
      "logits/chosen": -0.9229236841201782,
      "logits/rejected": -0.8649252653121948,
      "logps/chosen": -158.87890625,
      "logps/rejected": -137.0255126953125,
      "loss": 0.5582,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.3758906126022339,
      "rewards/margins": 0.9613458514213562,
      "rewards/rejected": -2.337236166000366,
      "step": 4840
    },
    {
      "epoch": 0.8851172552240167,
      "grad_norm": 3.5189404487609863,
      "learning_rate": 5.69337508442316e-05,
      "logits/chosen": -0.8974277377128601,
      "logits/rejected": -0.8931120038032532,
      "logps/chosen": -175.4156951904297,
      "logps/rejected": -169.77626037597656,
      "loss": 0.6187,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.3287862539291382,
      "rewards/margins": 0.819000244140625,
      "rewards/rejected": -2.1477866172790527,
      "step": 4850
    },
    {
      "epoch": 0.8869422392554065,
      "grad_norm": 1.9285632371902466,
      "learning_rate": 5.6884631915024254e-05,
      "logits/chosen": -0.9693215489387512,
      "logits/rejected": -0.8742671012878418,
      "logps/chosen": -171.34793090820312,
      "logps/rejected": -131.69747924804688,
      "loss": 0.4887,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.192697525024414,
      "rewards/margins": 0.9774014353752136,
      "rewards/rejected": -2.1700987815856934,
      "step": 4860
    },
    {
      "epoch": 0.8887672232867962,
      "grad_norm": 3.448131799697876,
      "learning_rate": 5.683551298581691e-05,
      "logits/chosen": -0.946469783782959,
      "logits/rejected": -0.9317376017570496,
      "logps/chosen": -146.89540100097656,
      "logps/rejected": -143.79031372070312,
      "loss": 0.5341,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.2238471508026123,
      "rewards/margins": 0.7840330600738525,
      "rewards/rejected": -2.007880449295044,
      "step": 4870
    },
    {
      "epoch": 0.890592207318186,
      "grad_norm": 3.9236223697662354,
      "learning_rate": 5.6786394056609576e-05,
      "logits/chosen": -0.9834324717521667,
      "logits/rejected": -0.9393531680107117,
      "logps/chosen": -158.9580535888672,
      "logps/rejected": -151.6687469482422,
      "loss": 0.5614,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.3390452861785889,
      "rewards/margins": 0.7003528475761414,
      "rewards/rejected": -2.039397954940796,
      "step": 4880
    },
    {
      "epoch": 0.8924171913495756,
      "grad_norm": 3.83284068107605,
      "learning_rate": 5.673727512740223e-05,
      "logits/chosen": -0.9255791902542114,
      "logits/rejected": -0.8987798690795898,
      "logps/chosen": -142.65631103515625,
      "logps/rejected": -151.04739379882812,
      "loss": 0.5107,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8410459756851196,
      "rewards/margins": 1.0055166482925415,
      "rewards/rejected": -2.846562385559082,
      "step": 4890
    },
    {
      "epoch": 0.8942421753809654,
      "grad_norm": 2.0702760219573975,
      "learning_rate": 5.6688156198194885e-05,
      "logits/chosen": -1.0234867334365845,
      "logits/rejected": -0.9890626668930054,
      "logps/chosen": -169.57005310058594,
      "logps/rejected": -186.9932098388672,
      "loss": 0.5749,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.8111743927001953,
      "rewards/margins": 1.034491777420044,
      "rewards/rejected": -2.84566593170166,
      "step": 4900
    },
    {
      "epoch": 0.8960671594123552,
      "grad_norm": 2.487431764602661,
      "learning_rate": 5.663903726898754e-05,
      "logits/chosen": -0.9820578694343567,
      "logits/rejected": -0.9123603105545044,
      "logps/chosen": -152.47048950195312,
      "logps/rejected": -140.45738220214844,
      "loss": 0.4706,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4152729511260986,
      "rewards/margins": 1.1569125652313232,
      "rewards/rejected": -2.572185754776001,
      "step": 4910
    },
    {
      "epoch": 0.8978921434437449,
      "grad_norm": 2.5795083045959473,
      "learning_rate": 5.65899183397802e-05,
      "logits/chosen": -0.999698281288147,
      "logits/rejected": -0.9580238461494446,
      "logps/chosen": -169.61074829101562,
      "logps/rejected": -154.0577392578125,
      "loss": 0.5311,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.3249033689498901,
      "rewards/margins": 1.0165199041366577,
      "rewards/rejected": -2.341423511505127,
      "step": 4920
    },
    {
      "epoch": 0.8997171274751345,
      "grad_norm": 2.680183172225952,
      "learning_rate": 5.654079941057285e-05,
      "logits/chosen": -0.9759994745254517,
      "logits/rejected": -0.9462920427322388,
      "logps/chosen": -163.1144561767578,
      "logps/rejected": -155.0791778564453,
      "loss": 0.5354,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7858415842056274,
      "rewards/margins": 0.9632555246353149,
      "rewards/rejected": -1.7490971088409424,
      "step": 4930
    },
    {
      "epoch": 0.9015421115065243,
      "grad_norm": 2.7303225994110107,
      "learning_rate": 5.649168048136551e-05,
      "logits/chosen": -0.9433277249336243,
      "logits/rejected": -0.9056752920150757,
      "logps/chosen": -145.85630798339844,
      "logps/rejected": -134.94003295898438,
      "loss": 0.4879,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7985872030258179,
      "rewards/margins": 1.0880380868911743,
      "rewards/rejected": -1.8866252899169922,
      "step": 4940
    },
    {
      "epoch": 0.903367095537914,
      "grad_norm": 2.8365678787231445,
      "learning_rate": 5.644256155215817e-05,
      "logits/chosen": -0.914319634437561,
      "logits/rejected": -0.8941766023635864,
      "logps/chosen": -133.2110137939453,
      "logps/rejected": -139.09274291992188,
      "loss": 0.5394,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.2101961374282837,
      "rewards/margins": 0.8707672953605652,
      "rewards/rejected": -2.080963611602783,
      "step": 4950
    },
    {
      "epoch": 0.9051920795693038,
      "grad_norm": 1.362886905670166,
      "learning_rate": 5.6393442622950824e-05,
      "logits/chosen": -0.9442266225814819,
      "logits/rejected": -0.8545129895210266,
      "logps/chosen": -167.71072387695312,
      "logps/rejected": -145.43865966796875,
      "loss": 0.5167,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.5022056102752686,
      "rewards/margins": 1.2800824642181396,
      "rewards/rejected": -2.782288074493408,
      "step": 4960
    },
    {
      "epoch": 0.9070170636006935,
      "grad_norm": 2.5608296394348145,
      "learning_rate": 5.634432369374348e-05,
      "logits/chosen": -0.886497974395752,
      "logits/rejected": -0.8401258587837219,
      "logps/chosen": -169.22689819335938,
      "logps/rejected": -173.35166931152344,
      "loss": 0.4233,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7863690853118896,
      "rewards/margins": 1.2020046710968018,
      "rewards/rejected": -2.9883739948272705,
      "step": 4970
    },
    {
      "epoch": 0.9088420476320832,
      "grad_norm": 2.189356803894043,
      "learning_rate": 5.629520476453614e-05,
      "logits/chosen": -0.8949947357177734,
      "logits/rejected": -0.8539274334907532,
      "logps/chosen": -158.00125122070312,
      "logps/rejected": -154.32333374023438,
      "loss": 0.6094,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.04781436920166,
      "rewards/margins": 0.9132145643234253,
      "rewards/rejected": -2.961028814315796,
      "step": 4980
    },
    {
      "epoch": 0.910667031663473,
      "grad_norm": 3.055387020111084,
      "learning_rate": 5.62460858353288e-05,
      "logits/chosen": -0.9211316108703613,
      "logits/rejected": -0.7630594372749329,
      "logps/chosen": -181.26438903808594,
      "logps/rejected": -154.56723022460938,
      "loss": 0.5223,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9240570068359375,
      "rewards/margins": 1.282745599746704,
      "rewards/rejected": -3.2068028450012207,
      "step": 4990
    },
    {
      "epoch": 0.9124920156948627,
      "grad_norm": 3.437537431716919,
      "learning_rate": 5.619696690612145e-05,
      "logits/chosen": -0.9061638712882996,
      "logits/rejected": -0.8009651303291321,
      "logps/chosen": -167.76698303222656,
      "logps/rejected": -156.36424255371094,
      "loss": 0.5019,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.525154709815979,
      "rewards/margins": 1.3990310430526733,
      "rewards/rejected": -2.9241855144500732,
      "step": 5000
    },
    {
      "epoch": 0.9143169997262524,
      "grad_norm": 3.0563535690307617,
      "learning_rate": 5.6147847976914106e-05,
      "logits/chosen": -0.8802483677864075,
      "logits/rejected": -0.7739294767379761,
      "logps/chosen": -180.97682189941406,
      "logps/rejected": -154.05776977539062,
      "loss": 0.4554,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5855796337127686,
      "rewards/margins": 1.505378007888794,
      "rewards/rejected": -3.0909578800201416,
      "step": 5010
    },
    {
      "epoch": 0.9161419837576421,
      "grad_norm": 3.8764913082122803,
      "learning_rate": 5.609872904770677e-05,
      "logits/chosen": -0.9290964007377625,
      "logits/rejected": -0.8563119769096375,
      "logps/chosen": -150.9596710205078,
      "logps/rejected": -147.4914093017578,
      "loss": 0.6014,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.0110924243927,
      "rewards/margins": 1.1621900796890259,
      "rewards/rejected": -3.1732826232910156,
      "step": 5020
    },
    {
      "epoch": 0.9179669677890319,
      "grad_norm": 4.447327136993408,
      "learning_rate": 5.604961011849942e-05,
      "logits/chosen": -0.8421076536178589,
      "logits/rejected": -0.78780198097229,
      "logps/chosen": -171.9931640625,
      "logps/rejected": -168.56915283203125,
      "loss": 0.5971,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.4310334920883179,
      "rewards/margins": 1.0688400268554688,
      "rewards/rejected": -2.499873638153076,
      "step": 5030
    },
    {
      "epoch": 0.9197919518204216,
      "grad_norm": 4.3785786628723145,
      "learning_rate": 5.600049118929208e-05,
      "logits/chosen": -0.8476846814155579,
      "logits/rejected": -0.7780251502990723,
      "logps/chosen": -173.1840057373047,
      "logps/rejected": -157.84567260742188,
      "loss": 0.6061,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.418338418006897,
      "rewards/margins": 0.9187296032905579,
      "rewards/rejected": -2.3370680809020996,
      "step": 5040
    },
    {
      "epoch": 0.9216169358518113,
      "grad_norm": 3.5992143154144287,
      "learning_rate": 5.595137226008473e-05,
      "logits/chosen": -0.8097249269485474,
      "logits/rejected": -0.7391613721847534,
      "logps/chosen": -144.59536743164062,
      "logps/rejected": -146.50985717773438,
      "loss": 0.4726,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3567030429840088,
      "rewards/margins": 1.2338345050811768,
      "rewards/rejected": -2.5905375480651855,
      "step": 5050
    },
    {
      "epoch": 0.923441919883201,
      "grad_norm": 7.339751243591309,
      "learning_rate": 5.5902253330877395e-05,
      "logits/chosen": -0.8030380010604858,
      "logits/rejected": -0.6627127528190613,
      "logps/chosen": -175.5900421142578,
      "logps/rejected": -136.6033935546875,
      "loss": 0.5432,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.5593030452728271,
      "rewards/margins": 1.0852227210998535,
      "rewards/rejected": -2.6445260047912598,
      "step": 5060
    },
    {
      "epoch": 0.9252669039145908,
      "grad_norm": 1.636196494102478,
      "learning_rate": 5.5853134401670046e-05,
      "logits/chosen": -0.9509574770927429,
      "logits/rejected": -0.8951690793037415,
      "logps/chosen": -156.22718811035156,
      "logps/rejected": -163.0718994140625,
      "loss": 0.4929,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.5280548334121704,
      "rewards/margins": 1.070317268371582,
      "rewards/rejected": -2.598371982574463,
      "step": 5070
    },
    {
      "epoch": 0.9270918879459805,
      "grad_norm": 2.0251972675323486,
      "learning_rate": 5.5804015472462704e-05,
      "logits/chosen": -0.893011212348938,
      "logits/rejected": -0.842315673828125,
      "logps/chosen": -148.57028198242188,
      "logps/rejected": -151.4440460205078,
      "loss": 0.5326,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.3496109247207642,
      "rewards/margins": 1.218681812286377,
      "rewards/rejected": -2.5682926177978516,
      "step": 5080
    },
    {
      "epoch": 0.9289168719773702,
      "grad_norm": 5.524646759033203,
      "learning_rate": 5.575489654325537e-05,
      "logits/chosen": -0.8377851247787476,
      "logits/rejected": -0.7791811227798462,
      "logps/chosen": -143.81533813476562,
      "logps/rejected": -153.13388061523438,
      "loss": 0.6343,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5937192440032959,
      "rewards/margins": 1.060829520225525,
      "rewards/rejected": -1.6545488834381104,
      "step": 5090
    },
    {
      "epoch": 0.9307418560087599,
      "grad_norm": 3.436258554458618,
      "learning_rate": 5.570577761404802e-05,
      "logits/chosen": -0.9153493046760559,
      "logits/rejected": -0.8724624514579773,
      "logps/chosen": -154.39785766601562,
      "logps/rejected": -149.9460906982422,
      "loss": 0.6278,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.3168228268623352,
      "rewards/margins": 0.7411000728607178,
      "rewards/rejected": -1.0579228401184082,
      "step": 5100
    },
    {
      "epoch": 0.9325668400401497,
      "grad_norm": 2.1778533458709717,
      "learning_rate": 5.565665868484068e-05,
      "logits/chosen": -0.9640033841133118,
      "logits/rejected": -0.865564227104187,
      "logps/chosen": -148.33042907714844,
      "logps/rejected": -120.18959045410156,
      "loss": 0.5298,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.11946149170398712,
      "rewards/margins": 0.9622553586959839,
      "rewards/rejected": -0.8427940607070923,
      "step": 5110
    },
    {
      "epoch": 0.9343918240715394,
      "grad_norm": 1.9887837171554565,
      "learning_rate": 5.560753975563333e-05,
      "logits/chosen": -0.963851809501648,
      "logits/rejected": -0.911206841468811,
      "logps/chosen": -134.13381958007812,
      "logps/rejected": -124.27156829833984,
      "loss": 0.5616,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.4201127588748932,
      "rewards/margins": 0.763771116733551,
      "rewards/rejected": -1.183883786201477,
      "step": 5120
    },
    {
      "epoch": 0.9362168081029291,
      "grad_norm": 2.9211649894714355,
      "learning_rate": 5.555842082642599e-05,
      "logits/chosen": -0.8904457092285156,
      "logits/rejected": -0.8355773091316223,
      "logps/chosen": -165.5841827392578,
      "logps/rejected": -142.5945281982422,
      "loss": 0.5354,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.2257157266139984,
      "rewards/margins": 0.8429734110832214,
      "rewards/rejected": -1.0686891078948975,
      "step": 5130
    },
    {
      "epoch": 0.9380417921343188,
      "grad_norm": 3.110114097595215,
      "learning_rate": 5.550930189721864e-05,
      "logits/chosen": -0.9033911824226379,
      "logits/rejected": -0.844884991645813,
      "logps/chosen": -152.4806365966797,
      "logps/rejected": -137.30654907226562,
      "loss": 0.5348,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.3237079679965973,
      "rewards/margins": 0.8946894407272339,
      "rewards/rejected": -1.2183973789215088,
      "step": 5140
    },
    {
      "epoch": 0.9398667761657086,
      "grad_norm": 3.9952454566955566,
      "learning_rate": 5.54601829680113e-05,
      "logits/chosen": -0.9368531107902527,
      "logits/rejected": -0.8758044242858887,
      "logps/chosen": -152.3852081298828,
      "logps/rejected": -134.4749298095703,
      "loss": 0.621,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5904935002326965,
      "rewards/margins": 0.8590914011001587,
      "rewards/rejected": -1.4495848417282104,
      "step": 5150
    },
    {
      "epoch": 0.9416917601970983,
      "grad_norm": 2.8494668006896973,
      "learning_rate": 5.541106403880395e-05,
      "logits/chosen": -0.8721655607223511,
      "logits/rejected": -0.861846923828125,
      "logps/chosen": -150.81112670898438,
      "logps/rejected": -155.55453491210938,
      "loss": 0.5785,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.7986222505569458,
      "rewards/margins": 0.6534041166305542,
      "rewards/rejected": -1.4520263671875,
      "step": 5160
    },
    {
      "epoch": 0.943516744228488,
      "grad_norm": 2.36415696144104,
      "learning_rate": 5.5361945109596616e-05,
      "logits/chosen": -0.9755304455757141,
      "logits/rejected": -0.8882872462272644,
      "logps/chosen": -148.32479858398438,
      "logps/rejected": -127.84175109863281,
      "loss": 0.517,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.5797015428543091,
      "rewards/margins": 0.8829822540283203,
      "rewards/rejected": -1.4626837968826294,
      "step": 5170
    },
    {
      "epoch": 0.9453417282598777,
      "grad_norm": 2.622652292251587,
      "learning_rate": 5.5312826180389274e-05,
      "logits/chosen": -0.9495790600776672,
      "logits/rejected": -0.8695961833000183,
      "logps/chosen": -160.21270751953125,
      "logps/rejected": -133.03968811035156,
      "loss": 0.4893,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7279400825500488,
      "rewards/margins": 0.9206510782241821,
      "rewards/rejected": -1.6485910415649414,
      "step": 5180
    },
    {
      "epoch": 0.9471667122912675,
      "grad_norm": 3.4970829486846924,
      "learning_rate": 5.5263707251181925e-05,
      "logits/chosen": -0.9120295643806458,
      "logits/rejected": -0.8742464184761047,
      "logps/chosen": -154.62295532226562,
      "logps/rejected": -153.64279174804688,
      "loss": 0.4924,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8245176076889038,
      "rewards/margins": 1.1270554065704346,
      "rewards/rejected": -1.9515727758407593,
      "step": 5190
    },
    {
      "epoch": 0.9489916963226572,
      "grad_norm": 3.286081314086914,
      "learning_rate": 5.521458832197459e-05,
      "logits/chosen": -0.9981118440628052,
      "logits/rejected": -0.9392720460891724,
      "logps/chosen": -158.57135009765625,
      "logps/rejected": -143.02664184570312,
      "loss": 0.5133,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.40135377645492554,
      "rewards/margins": 1.2549015283584595,
      "rewards/rejected": -1.6562553644180298,
      "step": 5200
    },
    {
      "epoch": 0.9508166803540469,
      "grad_norm": 1.7877017259597778,
      "learning_rate": 5.516546939276724e-05,
      "logits/chosen": -0.9267854690551758,
      "logits/rejected": -0.8747143745422363,
      "logps/chosen": -158.41470336914062,
      "logps/rejected": -142.1088409423828,
      "loss": 0.6951,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1104676723480225,
      "rewards/margins": 0.7635545134544373,
      "rewards/rejected": -1.8740222454071045,
      "step": 5210
    },
    {
      "epoch": 0.9526416643854366,
      "grad_norm": 2.2170214653015137,
      "learning_rate": 5.51163504635599e-05,
      "logits/chosen": -0.9467276334762573,
      "logits/rejected": -0.8714570999145508,
      "logps/chosen": -149.29518127441406,
      "logps/rejected": -144.24847412109375,
      "loss": 0.5232,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.8529016375541687,
      "rewards/margins": 1.1272047758102417,
      "rewards/rejected": -1.9801063537597656,
      "step": 5220
    },
    {
      "epoch": 0.9544666484168264,
      "grad_norm": 2.514681577682495,
      "learning_rate": 5.506723153435255e-05,
      "logits/chosen": -0.9663516283035278,
      "logits/rejected": -0.8818504214286804,
      "logps/chosen": -169.31527709960938,
      "logps/rejected": -139.86923217773438,
      "loss": 0.4786,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.699543833732605,
      "rewards/margins": 1.192535638809204,
      "rewards/rejected": -1.8920793533325195,
      "step": 5230
    },
    {
      "epoch": 0.9562916324482161,
      "grad_norm": 2.7689085006713867,
      "learning_rate": 5.5018112605145214e-05,
      "logits/chosen": -0.9781524538993835,
      "logits/rejected": -0.9359070658683777,
      "logps/chosen": -156.63818359375,
      "logps/rejected": -149.560546875,
      "loss": 0.6029,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.1078747510910034,
      "rewards/margins": 0.7512434124946594,
      "rewards/rejected": -1.8591182231903076,
      "step": 5240
    },
    {
      "epoch": 0.9581166164796058,
      "grad_norm": 3.5438146591186523,
      "learning_rate": 5.496899367593787e-05,
      "logits/chosen": -0.9547300338745117,
      "logits/rejected": -0.9176832437515259,
      "logps/chosen": -151.3429412841797,
      "logps/rejected": -165.16024780273438,
      "loss": 0.547,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9689302444458008,
      "rewards/margins": 0.889243483543396,
      "rewards/rejected": -1.8581737279891968,
      "step": 5250
    },
    {
      "epoch": 0.9599416005109955,
      "grad_norm": 2.2765800952911377,
      "learning_rate": 5.491987474673052e-05,
      "logits/chosen": -0.9663678407669067,
      "logits/rejected": -0.9113389253616333,
      "logps/chosen": -148.06044006347656,
      "logps/rejected": -140.4081268310547,
      "loss": 0.5537,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8428314328193665,
      "rewards/margins": 0.8770569562911987,
      "rewards/rejected": -1.71988844871521,
      "step": 5260
    },
    {
      "epoch": 0.9617665845423853,
      "grad_norm": 3.718412399291992,
      "learning_rate": 5.487075581752319e-05,
      "logits/chosen": -1.0147565603256226,
      "logits/rejected": -0.9814642071723938,
      "logps/chosen": -148.25759887695312,
      "logps/rejected": -142.7653045654297,
      "loss": 0.5724,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5829733610153198,
      "rewards/margins": 0.869886040687561,
      "rewards/rejected": -1.4528594017028809,
      "step": 5270
    },
    {
      "epoch": 0.9635915685737749,
      "grad_norm": 3.5584018230438232,
      "learning_rate": 5.482163688831584e-05,
      "logits/chosen": -1.0304007530212402,
      "logits/rejected": -0.9980942010879517,
      "logps/chosen": -150.0431671142578,
      "logps/rejected": -145.27113342285156,
      "loss": 0.5384,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7725211977958679,
      "rewards/margins": 1.3321611881256104,
      "rewards/rejected": -2.104682445526123,
      "step": 5280
    },
    {
      "epoch": 0.9654165526051647,
      "grad_norm": 2.2451772689819336,
      "learning_rate": 5.4772517959108496e-05,
      "logits/chosen": -1.0100829601287842,
      "logits/rejected": -0.9606643915176392,
      "logps/chosen": -162.2757568359375,
      "logps/rejected": -153.6744842529297,
      "loss": 0.6004,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9861611127853394,
      "rewards/margins": 0.8301204442977905,
      "rewards/rejected": -1.8162816762924194,
      "step": 5290
    },
    {
      "epoch": 0.9672415366365544,
      "grad_norm": 2.4331319332122803,
      "learning_rate": 5.4723399029901146e-05,
      "logits/chosen": -0.947681725025177,
      "logits/rejected": -0.8867208361625671,
      "logps/chosen": -167.52044677734375,
      "logps/rejected": -134.3115692138672,
      "loss": 0.6047,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.9347570538520813,
      "rewards/margins": 0.769052267074585,
      "rewards/rejected": -1.703809142112732,
      "step": 5300
    },
    {
      "epoch": 0.9690665206679442,
      "grad_norm": 3.283522129058838,
      "learning_rate": 5.467428010069381e-05,
      "logits/chosen": -0.9511027336120605,
      "logits/rejected": -0.9097881317138672,
      "logps/chosen": -158.5376739501953,
      "logps/rejected": -159.76422119140625,
      "loss": 0.7245,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -1.2999345064163208,
      "rewards/margins": 0.48439303040504456,
      "rewards/rejected": -1.784327507019043,
      "step": 5310
    },
    {
      "epoch": 0.9708915046993338,
      "grad_norm": 2.599306344985962,
      "learning_rate": 5.462516117148647e-05,
      "logits/chosen": -1.0078682899475098,
      "logits/rejected": -0.9297558069229126,
      "logps/chosen": -163.6932373046875,
      "logps/rejected": -136.52105712890625,
      "loss": 0.4783,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8183916211128235,
      "rewards/margins": 1.0826950073242188,
      "rewards/rejected": -1.9010865688323975,
      "step": 5320
    },
    {
      "epoch": 0.9727164887307236,
      "grad_norm": 1.9990975856781006,
      "learning_rate": 5.457604224227912e-05,
      "logits/chosen": -0.9577956199645996,
      "logits/rejected": -0.9298194646835327,
      "logps/chosen": -159.681396484375,
      "logps/rejected": -150.09036254882812,
      "loss": 0.5108,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8436883091926575,
      "rewards/margins": 0.8907858729362488,
      "rewards/rejected": -1.7344741821289062,
      "step": 5330
    },
    {
      "epoch": 0.9745414727621133,
      "grad_norm": 3.041311264038086,
      "learning_rate": 5.452692331307178e-05,
      "logits/chosen": -0.9016615748405457,
      "logits/rejected": -0.8852357864379883,
      "logps/chosen": -149.95668029785156,
      "logps/rejected": -144.55792236328125,
      "loss": 0.5753,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.06672203540802,
      "rewards/margins": 0.7982252836227417,
      "rewards/rejected": -1.8649475574493408,
      "step": 5340
    },
    {
      "epoch": 0.9763664567935031,
      "grad_norm": 4.6694135665893555,
      "learning_rate": 5.447780438386444e-05,
      "logits/chosen": -0.9531057476997375,
      "logits/rejected": -0.9316855669021606,
      "logps/chosen": -172.3681182861328,
      "logps/rejected": -157.5668182373047,
      "loss": 0.6757,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.7346633672714233,
      "rewards/margins": 0.4723913073539734,
      "rewards/rejected": -2.207054615020752,
      "step": 5350
    },
    {
      "epoch": 0.9781914408248927,
      "grad_norm": 3.405015468597412,
      "learning_rate": 5.442868545465709e-05,
      "logits/chosen": -0.9122816324234009,
      "logits/rejected": -0.8933967351913452,
      "logps/chosen": -162.40469360351562,
      "logps/rejected": -149.02487182617188,
      "loss": 0.6811,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.6037242412567139,
      "rewards/margins": 0.4430278241634369,
      "rewards/rejected": -2.0467519760131836,
      "step": 5360
    },
    {
      "epoch": 0.9800164248562825,
      "grad_norm": 3.468944787979126,
      "learning_rate": 5.437956652544975e-05,
      "logits/chosen": -0.942886233329773,
      "logits/rejected": -0.8848236203193665,
      "logps/chosen": -157.5469207763672,
      "logps/rejected": -151.82107543945312,
      "loss": 0.4887,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5216211080551147,
      "rewards/margins": 0.8091181516647339,
      "rewards/rejected": -2.3307392597198486,
      "step": 5370
    },
    {
      "epoch": 0.9818414088876722,
      "grad_norm": 2.2935943603515625,
      "learning_rate": 5.433044759624241e-05,
      "logits/chosen": -0.9124851226806641,
      "logits/rejected": -0.8927708864212036,
      "logps/chosen": -146.4929962158203,
      "logps/rejected": -145.223388671875,
      "loss": 0.5431,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.4575371742248535,
      "rewards/margins": 0.7503552436828613,
      "rewards/rejected": -2.2078921794891357,
      "step": 5380
    },
    {
      "epoch": 0.983666392919062,
      "grad_norm": 2.0940749645233154,
      "learning_rate": 5.4281328667035066e-05,
      "logits/chosen": -0.887803852558136,
      "logits/rejected": -0.8845891952514648,
      "logps/chosen": -138.8806915283203,
      "logps/rejected": -152.48074340820312,
      "loss": 0.5629,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.5887737274169922,
      "rewards/margins": 0.723179042339325,
      "rewards/rejected": -2.311952590942383,
      "step": 5390
    },
    {
      "epoch": 0.9854913769504516,
      "grad_norm": 4.696174144744873,
      "learning_rate": 5.423220973782772e-05,
      "logits/chosen": -0.9169797897338867,
      "logits/rejected": -0.8552265167236328,
      "logps/chosen": -170.1734619140625,
      "logps/rejected": -161.32687377929688,
      "loss": 0.5343,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4565750360488892,
      "rewards/margins": 0.9388223886489868,
      "rewards/rejected": -2.395397186279297,
      "step": 5400
    },
    {
      "epoch": 0.9873163609818414,
      "grad_norm": 3.0598227977752686,
      "learning_rate": 5.4183090808620375e-05,
      "logits/chosen": -0.923041045665741,
      "logits/rejected": -0.9157430529594421,
      "logps/chosen": -145.14376831054688,
      "logps/rejected": -156.67825317382812,
      "loss": 0.4571,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3890632390975952,
      "rewards/margins": 1.1088061332702637,
      "rewards/rejected": -2.4978697299957275,
      "step": 5410
    },
    {
      "epoch": 0.9891413450132311,
      "grad_norm": 1.9686992168426514,
      "learning_rate": 5.413397187941304e-05,
      "logits/chosen": -0.9205954670906067,
      "logits/rejected": -0.8412264585494995,
      "logps/chosen": -172.8739776611328,
      "logps/rejected": -155.88961791992188,
      "loss": 0.5011,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0124845504760742,
      "rewards/margins": 1.0213555097579956,
      "rewards/rejected": -2.0338399410247803,
      "step": 5420
    },
    {
      "epoch": 0.9909663290446209,
      "grad_norm": 3.4892072677612305,
      "learning_rate": 5.408485295020569e-05,
      "logits/chosen": -0.9244461059570312,
      "logits/rejected": -0.8910409808158875,
      "logps/chosen": -164.85543823242188,
      "logps/rejected": -170.06961059570312,
      "loss": 0.4071,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.021497130393982,
      "rewards/margins": 1.341064214706421,
      "rewards/rejected": -2.3625612258911133,
      "step": 5430
    },
    {
      "epoch": 0.9927913130760105,
      "grad_norm": 1.4145116806030273,
      "learning_rate": 5.403573402099835e-05,
      "logits/chosen": -0.9037691354751587,
      "logits/rejected": -0.8371695280075073,
      "logps/chosen": -171.0498809814453,
      "logps/rejected": -142.14785766601562,
      "loss": 0.5104,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.8768380880355835,
      "rewards/margins": 1.230862021446228,
      "rewards/rejected": -2.1077001094818115,
      "step": 5440
    },
    {
      "epoch": 0.9946162971074003,
      "grad_norm": 3.655836582183838,
      "learning_rate": 5.3986615091791e-05,
      "logits/chosen": -0.8900591135025024,
      "logits/rejected": -0.8125215768814087,
      "logps/chosen": -144.76478576660156,
      "logps/rejected": -153.05032348632812,
      "loss": 0.4012,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.0062434673309326,
      "rewards/margins": 1.5984374284744263,
      "rewards/rejected": -2.6046810150146484,
      "step": 5450
    },
    {
      "epoch": 0.99644128113879,
      "grad_norm": 2.090338945388794,
      "learning_rate": 5.3937496162583663e-05,
      "logits/chosen": -0.8519835472106934,
      "logits/rejected": -0.8012548685073853,
      "logps/chosen": -154.05126953125,
      "logps/rejected": -157.78958129882812,
      "loss": 0.5551,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.142427682876587,
      "rewards/margins": 1.1734422445297241,
      "rewards/rejected": -2.3158698081970215,
      "step": 5460
    },
    {
      "epoch": 0.9982662651701798,
      "grad_norm": 1.8774296045303345,
      "learning_rate": 5.3888377233376314e-05,
      "logits/chosen": -0.8803544044494629,
      "logits/rejected": -0.8241370916366577,
      "logps/chosen": -170.83767700195312,
      "logps/rejected": -162.6258544921875,
      "loss": 0.5717,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.6361262798309326,
      "rewards/margins": 1.323150873184204,
      "rewards/rejected": -2.959277391433716,
      "step": 5470
    },
    {
      "epoch": 1.0000912492015694,
      "grad_norm": 6.013887405395508,
      "learning_rate": 5.383925830416897e-05,
      "logits/chosen": -0.8260696530342102,
      "logits/rejected": -0.7980653047561646,
      "logps/chosen": -135.55796813964844,
      "logps/rejected": -148.8482666015625,
      "loss": 0.5366,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.2428137063980103,
      "rewards/margins": 1.174222707748413,
      "rewards/rejected": -2.417036294937134,
      "step": 5480
    },
    {
      "epoch": 1.0019162332329592,
      "grad_norm": 3.8799357414245605,
      "learning_rate": 5.3790139374961637e-05,
      "logits/chosen": -0.8723638653755188,
      "logits/rejected": -0.7925244569778442,
      "logps/chosen": -165.80349731445312,
      "logps/rejected": -138.0897674560547,
      "loss": 0.5579,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8614917993545532,
      "rewards/margins": 1.2339669466018677,
      "rewards/rejected": -2.095458745956421,
      "step": 5490
    },
    {
      "epoch": 1.003741217264349,
      "grad_norm": 2.4141759872436523,
      "learning_rate": 5.374102044575429e-05,
      "logits/chosen": -0.9163602590560913,
      "logits/rejected": -0.8430624008178711,
      "logps/chosen": -154.97396850585938,
      "logps/rejected": -134.33168029785156,
      "loss": 0.4018,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.7516459226608276,
      "rewards/margins": 1.3677716255187988,
      "rewards/rejected": -2.119417667388916,
      "step": 5500
    },
    {
      "epoch": 1.0055662012957387,
      "grad_norm": 1.5944370031356812,
      "learning_rate": 5.3691901516546945e-05,
      "logits/chosen": -0.8542355298995972,
      "logits/rejected": -0.7510067820549011,
      "logps/chosen": -171.37319946289062,
      "logps/rejected": -147.7929229736328,
      "loss": 0.384,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.361470103263855,
      "rewards/margins": 1.7301117181777954,
      "rewards/rejected": -2.0915818214416504,
      "step": 5510
    },
    {
      "epoch": 1.0073911853271285,
      "grad_norm": 1.5526841878890991,
      "learning_rate": 5.3642782587339596e-05,
      "logits/chosen": -0.8306044340133667,
      "logits/rejected": -0.7813157439231873,
      "logps/chosen": -132.3009490966797,
      "logps/rejected": -149.5854949951172,
      "loss": 0.4571,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.8302627801895142,
      "rewards/margins": 1.305919885635376,
      "rewards/rejected": -2.1361827850341797,
      "step": 5520
    },
    {
      "epoch": 1.0092161693585182,
      "grad_norm": 1.4616310596466064,
      "learning_rate": 5.359366365813226e-05,
      "logits/chosen": -0.8772088289260864,
      "logits/rejected": -0.7759926319122314,
      "logps/chosen": -167.21005249023438,
      "logps/rejected": -150.9323272705078,
      "loss": 0.3917,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.5766626596450806,
      "rewards/margins": 1.598846197128296,
      "rewards/rejected": -2.175508499145508,
      "step": 5530
    },
    {
      "epoch": 1.0110411533899077,
      "grad_norm": 1.5740714073181152,
      "learning_rate": 5.354454472892491e-05,
      "logits/chosen": -0.8660343289375305,
      "logits/rejected": -0.811114490032196,
      "logps/chosen": -158.87326049804688,
      "logps/rejected": -149.24429321289062,
      "loss": 0.4134,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.1040289402008057,
      "rewards/margins": 1.4844701290130615,
      "rewards/rejected": -2.5884993076324463,
      "step": 5540
    },
    {
      "epoch": 1.0128661374212975,
      "grad_norm": 4.295504570007324,
      "learning_rate": 5.349542579971757e-05,
      "logits/chosen": -0.8821789026260376,
      "logits/rejected": -0.7987993359565735,
      "logps/chosen": -172.73019409179688,
      "logps/rejected": -165.87982177734375,
      "loss": 0.4852,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6393789052963257,
      "rewards/margins": 1.519036054611206,
      "rewards/rejected": -3.158414840698242,
      "step": 5550
    },
    {
      "epoch": 1.0146911214526873,
      "grad_norm": 4.8928608894348145,
      "learning_rate": 5.344630687051022e-05,
      "logits/chosen": -0.8821693658828735,
      "logits/rejected": -0.7918351888656616,
      "logps/chosen": -177.62039184570312,
      "logps/rejected": -160.06527709960938,
      "loss": 0.4198,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.510326623916626,
      "rewards/margins": 1.61972975730896,
      "rewards/rejected": -3.130056381225586,
      "step": 5560
    },
    {
      "epoch": 1.016516105484077,
      "grad_norm": 3.214992046356201,
      "learning_rate": 5.3397187941302885e-05,
      "logits/chosen": -0.8118414878845215,
      "logits/rejected": -0.7273040413856506,
      "logps/chosen": -163.36935424804688,
      "logps/rejected": -163.0678253173828,
      "loss": 0.4174,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6515657901763916,
      "rewards/margins": 1.595404863357544,
      "rewards/rejected": -3.2469704151153564,
      "step": 5570
    },
    {
      "epoch": 1.0183410895154668,
      "grad_norm": 3.4956109523773193,
      "learning_rate": 5.334806901209554e-05,
      "logits/chosen": -0.8515617251396179,
      "logits/rejected": -0.7964388132095337,
      "logps/chosen": -163.90017700195312,
      "logps/rejected": -152.77536010742188,
      "loss": 0.5386,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.6960397958755493,
      "rewards/margins": 1.1364637613296509,
      "rewards/rejected": -2.8325035572052,
      "step": 5580
    },
    {
      "epoch": 1.0201660735468565,
      "grad_norm": 2.8899455070495605,
      "learning_rate": 5.3298950082888194e-05,
      "logits/chosen": -0.7630747556686401,
      "logits/rejected": -0.6442748308181763,
      "logps/chosen": -182.5646209716797,
      "logps/rejected": -156.07144165039062,
      "loss": 0.4753,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7631454467773438,
      "rewards/margins": 1.4535717964172363,
      "rewards/rejected": -3.216716766357422,
      "step": 5590
    },
    {
      "epoch": 1.0219910575782463,
      "grad_norm": 2.960508108139038,
      "learning_rate": 5.324983115368086e-05,
      "logits/chosen": -0.7690085172653198,
      "logits/rejected": -0.6778869032859802,
      "logps/chosen": -159.7283172607422,
      "logps/rejected": -157.6903839111328,
      "loss": 0.3903,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6171541213989258,
      "rewards/margins": 1.5494195222854614,
      "rewards/rejected": -3.1665737628936768,
      "step": 5600
    },
    {
      "epoch": 1.023816041609636,
      "grad_norm": 4.232241153717041,
      "learning_rate": 5.320071222447351e-05,
      "logits/chosen": -0.7556315660476685,
      "logits/rejected": -0.7431021928787231,
      "logps/chosen": -159.19384765625,
      "logps/rejected": -183.97799682617188,
      "loss": 0.4089,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9618877172470093,
      "rewards/margins": 1.651087999343872,
      "rewards/rejected": -3.612975597381592,
      "step": 5610
    },
    {
      "epoch": 1.0256410256410255,
      "grad_norm": 1.915358543395996,
      "learning_rate": 5.315159329526617e-05,
      "logits/chosen": -0.7640984058380127,
      "logits/rejected": -0.6895990371704102,
      "logps/chosen": -164.53359985351562,
      "logps/rejected": -161.47088623046875,
      "loss": 0.4933,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7471485137939453,
      "rewards/margins": 1.1399204730987549,
      "rewards/rejected": -2.887068748474121,
      "step": 5620
    },
    {
      "epoch": 1.0274660096724153,
      "grad_norm": 4.771135330200195,
      "learning_rate": 5.310247436605882e-05,
      "logits/chosen": -0.765946626663208,
      "logits/rejected": -0.6841670870780945,
      "logps/chosen": -174.43472290039062,
      "logps/rejected": -170.24514770507812,
      "loss": 0.4003,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9284603595733643,
      "rewards/margins": 1.6654752492904663,
      "rewards/rejected": -3.59393572807312,
      "step": 5630
    },
    {
      "epoch": 1.029290993703805,
      "grad_norm": 2.2461445331573486,
      "learning_rate": 5.305335543685148e-05,
      "logits/chosen": -0.7287615537643433,
      "logits/rejected": -0.6544976234436035,
      "logps/chosen": -169.0659637451172,
      "logps/rejected": -158.03887939453125,
      "loss": 0.484,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9732940196990967,
      "rewards/margins": 1.1941094398498535,
      "rewards/rejected": -3.1674036979675293,
      "step": 5640
    },
    {
      "epoch": 1.0311159777351948,
      "grad_norm": 4.2981767654418945,
      "learning_rate": 5.300423650764414e-05,
      "logits/chosen": -0.7969347834587097,
      "logits/rejected": -0.6880826950073242,
      "logps/chosen": -196.7852783203125,
      "logps/rejected": -193.5804901123047,
      "loss": 0.4338,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6928339004516602,
      "rewards/margins": 1.5738780498504639,
      "rewards/rejected": -3.266712188720703,
      "step": 5650
    },
    {
      "epoch": 1.0329409617665846,
      "grad_norm": 4.410745143890381,
      "learning_rate": 5.295511757843679e-05,
      "logits/chosen": -0.7447053790092468,
      "logits/rejected": -0.7076901197433472,
      "logps/chosen": -158.057861328125,
      "logps/rejected": -170.7926788330078,
      "loss": 0.5246,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.039717197418213,
      "rewards/margins": 1.062224268913269,
      "rewards/rejected": -3.1019415855407715,
      "step": 5660
    },
    {
      "epoch": 1.0347659457979743,
      "grad_norm": 1.939109444618225,
      "learning_rate": 5.2905998649229455e-05,
      "logits/chosen": -0.7632039785385132,
      "logits/rejected": -0.6326652765274048,
      "logps/chosen": -168.20660400390625,
      "logps/rejected": -139.22341918945312,
      "loss": 0.4678,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8310056924819946,
      "rewards/margins": 1.478636384010315,
      "rewards/rejected": -3.3096420764923096,
      "step": 5670
    },
    {
      "epoch": 1.036590929829364,
      "grad_norm": 2.184363603591919,
      "learning_rate": 5.2856879720022106e-05,
      "logits/chosen": -0.7465483546257019,
      "logits/rejected": -0.6644368767738342,
      "logps/chosen": -167.77493286132812,
      "logps/rejected": -161.71311950683594,
      "loss": 0.4055,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.3614044189453125,
      "rewards/margins": 1.4912023544311523,
      "rewards/rejected": -2.852606773376465,
      "step": 5680
    },
    {
      "epoch": 1.0384159138607538,
      "grad_norm": 3.0918402671813965,
      "learning_rate": 5.2807760790814764e-05,
      "logits/chosen": -0.7681682109832764,
      "logits/rejected": -0.699256420135498,
      "logps/chosen": -154.53314208984375,
      "logps/rejected": -141.60743713378906,
      "loss": 0.4585,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1443055868148804,
      "rewards/margins": 1.344476342201233,
      "rewards/rejected": -2.4887819290161133,
      "step": 5690
    },
    {
      "epoch": 1.0402408978921434,
      "grad_norm": 3.152940034866333,
      "learning_rate": 5.2758641861607415e-05,
      "logits/chosen": -0.7509151697158813,
      "logits/rejected": -0.6848720908164978,
      "logps/chosen": -163.62020874023438,
      "logps/rejected": -153.27175903320312,
      "loss": 0.4488,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6962467432022095,
      "rewards/margins": 1.4086750745773315,
      "rewards/rejected": -3.104921817779541,
      "step": 5700
    },
    {
      "epoch": 1.042065881923533,
      "grad_norm": 2.428070306777954,
      "learning_rate": 5.270952293240008e-05,
      "logits/chosen": -0.8313136100769043,
      "logits/rejected": -0.7703760266304016,
      "logps/chosen": -161.97073364257812,
      "logps/rejected": -167.7264862060547,
      "loss": 0.4025,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.1367485523223877,
      "rewards/margins": 1.563367247581482,
      "rewards/rejected": -2.70011568069458,
      "step": 5710
    },
    {
      "epoch": 1.0438908659549229,
      "grad_norm": 2.46928334236145,
      "learning_rate": 5.266040400319274e-05,
      "logits/chosen": -0.825441837310791,
      "logits/rejected": -0.8315154910087585,
      "logps/chosen": -158.0281524658203,
      "logps/rejected": -183.2200927734375,
      "loss": 0.4755,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2655391693115234,
      "rewards/margins": 1.3704149723052979,
      "rewards/rejected": -2.6359541416168213,
      "step": 5720
    },
    {
      "epoch": 1.0457158499863126,
      "grad_norm": 3.8551878929138184,
      "learning_rate": 5.261128507398539e-05,
      "logits/chosen": -0.7631117105484009,
      "logits/rejected": -0.6754318475723267,
      "logps/chosen": -169.19613647460938,
      "logps/rejected": -163.34164428710938,
      "loss": 0.5521,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.944838285446167,
      "rewards/margins": 1.0467880964279175,
      "rewards/rejected": -2.991626501083374,
      "step": 5730
    },
    {
      "epoch": 1.0475408340177024,
      "grad_norm": 3.299955368041992,
      "learning_rate": 5.2562166144778046e-05,
      "logits/chosen": -0.7340545058250427,
      "logits/rejected": -0.646137535572052,
      "logps/chosen": -160.00038146972656,
      "logps/rejected": -170.44898986816406,
      "loss": 0.4205,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5943855047225952,
      "rewards/margins": 1.4358388185501099,
      "rewards/rejected": -3.030224323272705,
      "step": 5740
    },
    {
      "epoch": 1.0493658180490921,
      "grad_norm": 1.8936058282852173,
      "learning_rate": 5.251304721557071e-05,
      "logits/chosen": -0.7528953552246094,
      "logits/rejected": -0.6520558595657349,
      "logps/chosen": -184.22674560546875,
      "logps/rejected": -174.45892333984375,
      "loss": 0.4582,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6517162322998047,
      "rewards/margins": 1.1639115810394287,
      "rewards/rejected": -2.8156280517578125,
      "step": 5750
    },
    {
      "epoch": 1.0511908020804819,
      "grad_norm": 3.750216245651245,
      "learning_rate": 5.246392828636336e-05,
      "logits/chosen": -0.7121769189834595,
      "logits/rejected": -0.567733645439148,
      "logps/chosen": -187.16770935058594,
      "logps/rejected": -163.12973022460938,
      "loss": 0.395,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1074562072753906,
      "rewards/margins": 1.4904656410217285,
      "rewards/rejected": -3.5979220867156982,
      "step": 5760
    },
    {
      "epoch": 1.0530157861118714,
      "grad_norm": 4.714409828186035,
      "learning_rate": 5.241480935715601e-05,
      "logits/chosen": -0.7646780610084534,
      "logits/rejected": -0.6388739943504333,
      "logps/chosen": -163.45205688476562,
      "logps/rejected": -164.62771606445312,
      "loss": 0.4172,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.9558522701263428,
      "rewards/margins": 1.4464528560638428,
      "rewards/rejected": -3.4023048877716064,
      "step": 5770
    },
    {
      "epoch": 1.0548407701432612,
      "grad_norm": 2.5691781044006348,
      "learning_rate": 5.236569042794868e-05,
      "logits/chosen": -0.7401130795478821,
      "logits/rejected": -0.6243287324905396,
      "logps/chosen": -161.41209411621094,
      "logps/rejected": -151.5563507080078,
      "loss": 0.4857,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.2075486183166504,
      "rewards/margins": 1.4495214223861694,
      "rewards/rejected": -3.657069683074951,
      "step": 5780
    },
    {
      "epoch": 1.056665754174651,
      "grad_norm": 3.8184359073638916,
      "learning_rate": 5.2316571498741335e-05,
      "logits/chosen": -0.8040350675582886,
      "logits/rejected": -0.6692895889282227,
      "logps/chosen": -187.8504638671875,
      "logps/rejected": -162.92333984375,
      "loss": 0.433,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9486744403839111,
      "rewards/margins": 1.504314661026001,
      "rewards/rejected": -3.452989101409912,
      "step": 5790
    },
    {
      "epoch": 1.0584907382060407,
      "grad_norm": 2.6055243015289307,
      "learning_rate": 5.2267452569533986e-05,
      "logits/chosen": -0.8458563089370728,
      "logits/rejected": -0.7648115158081055,
      "logps/chosen": -160.25006103515625,
      "logps/rejected": -154.95449829101562,
      "loss": 0.5854,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.110970973968506,
      "rewards/margins": 1.0803115367889404,
      "rewards/rejected": -3.1912827491760254,
      "step": 5800
    },
    {
      "epoch": 1.0603157222374304,
      "grad_norm": 2.0080981254577637,
      "learning_rate": 5.221833364032664e-05,
      "logits/chosen": -0.8047692179679871,
      "logits/rejected": -0.6795476078987122,
      "logps/chosen": -176.49301147460938,
      "logps/rejected": -163.4567413330078,
      "loss": 0.4151,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3720930814743042,
      "rewards/margins": 1.3565802574157715,
      "rewards/rejected": -2.7286734580993652,
      "step": 5810
    },
    {
      "epoch": 1.0621407062688202,
      "grad_norm": 2.931767702102661,
      "learning_rate": 5.216921471111931e-05,
      "logits/chosen": -0.8027175068855286,
      "logits/rejected": -0.6792935132980347,
      "logps/chosen": -165.2667694091797,
      "logps/rejected": -144.85731506347656,
      "loss": 0.3666,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.5360454320907593,
      "rewards/margins": 1.4810314178466797,
      "rewards/rejected": -3.0170767307281494,
      "step": 5820
    },
    {
      "epoch": 1.06396569030021,
      "grad_norm": 2.6827621459960938,
      "learning_rate": 5.212009578191196e-05,
      "logits/chosen": -0.7764445543289185,
      "logits/rejected": -0.6486717462539673,
      "logps/chosen": -170.1448974609375,
      "logps/rejected": -165.2312469482422,
      "loss": 0.3615,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.856964111328125,
      "rewards/margins": 1.8924000263214111,
      "rewards/rejected": -3.7493643760681152,
      "step": 5830
    },
    {
      "epoch": 1.0657906743315997,
      "grad_norm": 4.756613254547119,
      "learning_rate": 5.2070976852704617e-05,
      "logits/chosen": -0.740932047367096,
      "logits/rejected": -0.707680344581604,
      "logps/chosen": -167.4774627685547,
      "logps/rejected": -172.34909057617188,
      "loss": 0.4131,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.3885529041290283,
      "rewards/margins": 1.5381476879119873,
      "rewards/rejected": -3.9267005920410156,
      "step": 5840
    },
    {
      "epoch": 1.0676156583629894,
      "grad_norm": 4.077399730682373,
      "learning_rate": 5.202185792349727e-05,
      "logits/chosen": -0.8356192708015442,
      "logits/rejected": -0.6902444958686829,
      "logps/chosen": -186.4398193359375,
      "logps/rejected": -173.48202514648438,
      "loss": 0.3928,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4660916328430176,
      "rewards/margins": 1.84097158908844,
      "rewards/rejected": -4.307063102722168,
      "step": 5850
    },
    {
      "epoch": 1.069440642394379,
      "grad_norm": 5.712342262268066,
      "learning_rate": 5.197273899428993e-05,
      "logits/chosen": -0.7716540098190308,
      "logits/rejected": -0.7309051752090454,
      "logps/chosen": -159.67483520507812,
      "logps/rejected": -161.01487731933594,
      "loss": 0.5074,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.5233798027038574,
      "rewards/margins": 1.2727714776992798,
      "rewards/rejected": -3.7961509227752686,
      "step": 5860
    },
    {
      "epoch": 1.0712656264257687,
      "grad_norm": 3.5018787384033203,
      "learning_rate": 5.192362006508258e-05,
      "logits/chosen": -0.8626450300216675,
      "logits/rejected": -0.7578922510147095,
      "logps/chosen": -178.04226684570312,
      "logps/rejected": -171.75152587890625,
      "loss": 0.5006,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.5289483070373535,
      "rewards/margins": 1.2783715724945068,
      "rewards/rejected": -3.8073201179504395,
      "step": 5870
    },
    {
      "epoch": 1.0730906104571585,
      "grad_norm": 2.2883565425872803,
      "learning_rate": 5.187450113587524e-05,
      "logits/chosen": -0.8372616767883301,
      "logits/rejected": -0.6737920045852661,
      "logps/chosen": -191.73110961914062,
      "logps/rejected": -174.3020782470703,
      "loss": 0.4483,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.625669479370117,
      "rewards/margins": 1.4232490062713623,
      "rewards/rejected": -4.048918724060059,
      "step": 5880
    },
    {
      "epoch": 1.0749155944885482,
      "grad_norm": 6.461526870727539,
      "learning_rate": 5.1825382206667905e-05,
      "logits/chosen": -0.8198935389518738,
      "logits/rejected": -0.700914204120636,
      "logps/chosen": -174.84608459472656,
      "logps/rejected": -159.76412963867188,
      "loss": 0.4575,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.609017848968506,
      "rewards/margins": 1.4387850761413574,
      "rewards/rejected": -4.047802925109863,
      "step": 5890
    },
    {
      "epoch": 1.076740578519938,
      "grad_norm": 3.5642523765563965,
      "learning_rate": 5.1776263277460556e-05,
      "logits/chosen": -0.814750075340271,
      "logits/rejected": -0.6996031999588013,
      "logps/chosen": -172.37738037109375,
      "logps/rejected": -156.41683959960938,
      "loss": 0.4091,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.627319097518921,
      "rewards/margins": 1.5054872035980225,
      "rewards/rejected": -3.1328063011169434,
      "step": 5900
    },
    {
      "epoch": 1.0785655625513277,
      "grad_norm": 1.7770428657531738,
      "learning_rate": 5.1727144348253214e-05,
      "logits/chosen": -0.843540370464325,
      "logits/rejected": -0.7579034566879272,
      "logps/chosen": -163.05706787109375,
      "logps/rejected": -162.11483764648438,
      "loss": 0.5334,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9232162237167358,
      "rewards/margins": 1.2429380416870117,
      "rewards/rejected": -3.166154384613037,
      "step": 5910
    },
    {
      "epoch": 1.0803905465827175,
      "grad_norm": 3.7862699031829834,
      "learning_rate": 5.1678025419045865e-05,
      "logits/chosen": -0.8784966468811035,
      "logits/rejected": -0.7586208581924438,
      "logps/chosen": -167.2407684326172,
      "logps/rejected": -174.99472045898438,
      "loss": 0.3099,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4011523723602295,
      "rewards/margins": 2.32110333442688,
      "rewards/rejected": -3.7222557067871094,
      "step": 5920
    },
    {
      "epoch": 1.082215530614107,
      "grad_norm": 6.028719425201416,
      "learning_rate": 5.162890648983853e-05,
      "logits/chosen": -0.8752764463424683,
      "logits/rejected": -0.8184839487075806,
      "logps/chosen": -166.0567169189453,
      "logps/rejected": -179.52899169921875,
      "loss": 0.5378,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.8987009525299072,
      "rewards/margins": 1.520782232284546,
      "rewards/rejected": -3.419483184814453,
      "step": 5930
    },
    {
      "epoch": 1.0840405146454968,
      "grad_norm": 4.477479934692383,
      "learning_rate": 5.157978756063118e-05,
      "logits/chosen": -0.936309814453125,
      "logits/rejected": -0.8508947491645813,
      "logps/chosen": -155.48306274414062,
      "logps/rejected": -141.2109375,
      "loss": 0.5362,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.9708452224731445,
      "rewards/margins": 1.127960205078125,
      "rewards/rejected": -3.0988054275512695,
      "step": 5940
    },
    {
      "epoch": 1.0858654986768865,
      "grad_norm": 4.514008522033691,
      "learning_rate": 5.153066863142384e-05,
      "logits/chosen": -0.929566502571106,
      "logits/rejected": -0.8763696551322937,
      "logps/chosen": -160.34637451171875,
      "logps/rejected": -159.7168426513672,
      "loss": 0.3904,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.2645090818405151,
      "rewards/margins": 1.4340215921401978,
      "rewards/rejected": -2.698530673980713,
      "step": 5950
    },
    {
      "epoch": 1.0876904827082763,
      "grad_norm": 2.998192310333252,
      "learning_rate": 5.14815497022165e-05,
      "logits/chosen": -0.9268292188644409,
      "logits/rejected": -0.8389177322387695,
      "logps/chosen": -153.0872039794922,
      "logps/rejected": -148.4363250732422,
      "loss": 0.417,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5878912210464478,
      "rewards/margins": 1.494045615196228,
      "rewards/rejected": -3.081936836242676,
      "step": 5960
    },
    {
      "epoch": 1.089515466739666,
      "grad_norm": 1.5380500555038452,
      "learning_rate": 5.1432430773009153e-05,
      "logits/chosen": -0.8882037401199341,
      "logits/rejected": -0.7739347219467163,
      "logps/chosen": -165.08201599121094,
      "logps/rejected": -160.6977081298828,
      "loss": 0.4271,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.5764981508255005,
      "rewards/margins": 1.7826963663101196,
      "rewards/rejected": -3.359194278717041,
      "step": 5970
    },
    {
      "epoch": 1.0913404507710558,
      "grad_norm": 2.8671536445617676,
      "learning_rate": 5.138331184380181e-05,
      "logits/chosen": -0.8645592927932739,
      "logits/rejected": -0.7988097071647644,
      "logps/chosen": -155.2630615234375,
      "logps/rejected": -161.13853454589844,
      "loss": 0.461,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.7534844875335693,
      "rewards/margins": 1.6892211437225342,
      "rewards/rejected": -3.4427058696746826,
      "step": 5980
    },
    {
      "epoch": 1.0931654348024455,
      "grad_norm": 3.5058209896087646,
      "learning_rate": 5.133419291459446e-05,
      "logits/chosen": -0.8021785020828247,
      "logits/rejected": -0.688446044921875,
      "logps/chosen": -150.5363006591797,
      "logps/rejected": -151.03021240234375,
      "loss": 0.3802,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.57381272315979,
      "rewards/margins": 1.8658316135406494,
      "rewards/rejected": -3.4396445751190186,
      "step": 5990
    },
    {
      "epoch": 1.0949904188338353,
      "grad_norm": 4.3751726150512695,
      "learning_rate": 5.128507398538713e-05,
      "logits/chosen": -0.8947369456291199,
      "logits/rejected": -0.7381600737571716,
      "logps/chosen": -172.2406463623047,
      "logps/rejected": -136.6438751220703,
      "loss": 0.442,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.1402795314788818,
      "rewards/margins": 1.492203712463379,
      "rewards/rejected": -2.6324830055236816,
      "step": 6000
    },
    {
      "epoch": 1.0968154028652248,
      "grad_norm": 3.58542799949646,
      "learning_rate": 5.123595505617978e-05,
      "logits/chosen": -0.8994989395141602,
      "logits/rejected": -0.8435007333755493,
      "logps/chosen": -174.04013061523438,
      "logps/rejected": -176.51052856445312,
      "loss": 0.4146,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0305887460708618,
      "rewards/margins": 1.5147745609283447,
      "rewards/rejected": -2.545362949371338,
      "step": 6010
    },
    {
      "epoch": 1.0986403868966146,
      "grad_norm": 4.1488938331604,
      "learning_rate": 5.1186836126972435e-05,
      "logits/chosen": -0.8961805105209351,
      "logits/rejected": -0.7690985798835754,
      "logps/chosen": -163.3479461669922,
      "logps/rejected": -155.46737670898438,
      "loss": 0.4561,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1842012405395508,
      "rewards/margins": 1.8140487670898438,
      "rewards/rejected": -2.9982502460479736,
      "step": 6020
    },
    {
      "epoch": 1.1004653709280043,
      "grad_norm": 4.771762847900391,
      "learning_rate": 5.1137717197765086e-05,
      "logits/chosen": -0.9069662094116211,
      "logits/rejected": -0.8302423357963562,
      "logps/chosen": -154.45492553710938,
      "logps/rejected": -149.1107635498047,
      "loss": 0.4316,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.1907107830047607,
      "rewards/margins": 1.4852797985076904,
      "rewards/rejected": -2.6759908199310303,
      "step": 6030
    },
    {
      "epoch": 1.102290354959394,
      "grad_norm": 3.4922118186950684,
      "learning_rate": 5.108859826855775e-05,
      "logits/chosen": -0.9257389903068542,
      "logits/rejected": -0.8510499000549316,
      "logps/chosen": -163.54647827148438,
      "logps/rejected": -168.58984375,
      "loss": 0.3707,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9095020294189453,
      "rewards/margins": 1.8195937871932983,
      "rewards/rejected": -2.729095935821533,
      "step": 6040
    },
    {
      "epoch": 1.1041153389907838,
      "grad_norm": 4.366860866546631,
      "learning_rate": 5.103947933935041e-05,
      "logits/chosen": -0.938938319683075,
      "logits/rejected": -0.923913836479187,
      "logps/chosen": -151.82534790039062,
      "logps/rejected": -169.087646484375,
      "loss": 0.4968,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.2567455768585205,
      "rewards/margins": 1.487120270729065,
      "rewards/rejected": -2.743865966796875,
      "step": 6050
    },
    {
      "epoch": 1.1059403230221736,
      "grad_norm": 2.3980069160461426,
      "learning_rate": 5.099036041014306e-05,
      "logits/chosen": -0.9411311149597168,
      "logits/rejected": -0.8627972602844238,
      "logps/chosen": -155.7003631591797,
      "logps/rejected": -160.7047882080078,
      "loss": 0.3441,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.1554210186004639,
      "rewards/margins": 1.8342616558074951,
      "rewards/rejected": -2.989682674407959,
      "step": 6060
    },
    {
      "epoch": 1.1077653070535634,
      "grad_norm": 3.487178087234497,
      "learning_rate": 5.0941241480935724e-05,
      "logits/chosen": -0.9811693429946899,
      "logits/rejected": -0.8530799746513367,
      "logps/chosen": -152.3434600830078,
      "logps/rejected": -154.20919799804688,
      "loss": 0.4872,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.3176171779632568,
      "rewards/margins": 1.4877679347991943,
      "rewards/rejected": -2.805385112762451,
      "step": 6070
    },
    {
      "epoch": 1.109590291084953,
      "grad_norm": 5.790815353393555,
      "learning_rate": 5.0892122551728375e-05,
      "logits/chosen": -0.9622241854667664,
      "logits/rejected": -0.9559497833251953,
      "logps/chosen": -135.97084045410156,
      "logps/rejected": -150.06753540039062,
      "loss": 0.5049,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7266737222671509,
      "rewards/margins": 1.458875060081482,
      "rewards/rejected": -3.1855485439300537,
      "step": 6080
    },
    {
      "epoch": 1.1114152751163426,
      "grad_norm": 3.417794942855835,
      "learning_rate": 5.084300362252103e-05,
      "logits/chosen": -0.985772430896759,
      "logits/rejected": -0.9093493223190308,
      "logps/chosen": -165.11724853515625,
      "logps/rejected": -154.08033752441406,
      "loss": 0.5048,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3039791584014893,
      "rewards/margins": 1.155863881111145,
      "rewards/rejected": -2.4598429203033447,
      "step": 6090
    },
    {
      "epoch": 1.1132402591477324,
      "grad_norm": 2.0090315341949463,
      "learning_rate": 5.0793884693313684e-05,
      "logits/chosen": -0.9717106819152832,
      "logits/rejected": -0.9100033640861511,
      "logps/chosen": -155.1402587890625,
      "logps/rejected": -165.22244262695312,
      "loss": 0.4987,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3873971700668335,
      "rewards/margins": 1.3059155941009521,
      "rewards/rejected": -2.6933131217956543,
      "step": 6100
    },
    {
      "epoch": 1.1150652431791221,
      "grad_norm": 3.7538933753967285,
      "learning_rate": 5.074476576410635e-05,
      "logits/chosen": -0.8877753019332886,
      "logits/rejected": -0.8452205657958984,
      "logps/chosen": -167.05516052246094,
      "logps/rejected": -185.08668518066406,
      "loss": 0.472,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5661119222640991,
      "rewards/margins": 1.5133781433105469,
      "rewards/rejected": -3.0794901847839355,
      "step": 6110
    },
    {
      "epoch": 1.116890227210512,
      "grad_norm": 4.290159702301025,
      "learning_rate": 5.0695646834899006e-05,
      "logits/chosen": -0.8681821823120117,
      "logits/rejected": -0.8158273696899414,
      "logps/chosen": -142.0042724609375,
      "logps/rejected": -151.6539764404297,
      "loss": 0.439,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5364731550216675,
      "rewards/margins": 1.4745266437530518,
      "rewards/rejected": -3.011000156402588,
      "step": 6120
    },
    {
      "epoch": 1.1187152112419017,
      "grad_norm": 3.690399169921875,
      "learning_rate": 5.064652790569166e-05,
      "logits/chosen": -0.8675176501274109,
      "logits/rejected": -0.7982384562492371,
      "logps/chosen": -157.68746948242188,
      "logps/rejected": -163.55783081054688,
      "loss": 0.4726,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7129234075546265,
      "rewards/margins": 1.2748606204986572,
      "rewards/rejected": -2.987783670425415,
      "step": 6130
    },
    {
      "epoch": 1.1205401952732914,
      "grad_norm": 2.525803565979004,
      "learning_rate": 5.0597408976484315e-05,
      "logits/chosen": -0.8754032850265503,
      "logits/rejected": -0.7513755559921265,
      "logps/chosen": -156.42872619628906,
      "logps/rejected": -145.5062713623047,
      "loss": 0.3671,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5080276727676392,
      "rewards/margins": 1.6884148120880127,
      "rewards/rejected": -3.1964423656463623,
      "step": 6140
    },
    {
      "epoch": 1.1223651793046812,
      "grad_norm": 3.4539361000061035,
      "learning_rate": 5.054829004727697e-05,
      "logits/chosen": -0.9357150793075562,
      "logits/rejected": -0.867988109588623,
      "logps/chosen": -148.99371337890625,
      "logps/rejected": -154.7859649658203,
      "loss": 0.3952,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3561742305755615,
      "rewards/margins": 1.5090521574020386,
      "rewards/rejected": -2.8652265071868896,
      "step": 6150
    },
    {
      "epoch": 1.124190163336071,
      "grad_norm": 1.5509235858917236,
      "learning_rate": 5.049917111806963e-05,
      "logits/chosen": -0.9458425641059875,
      "logits/rejected": -0.8979905843734741,
      "logps/chosen": -144.33401489257812,
      "logps/rejected": -155.4916229248047,
      "loss": 0.3933,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.8713207244873047,
      "rewards/margins": 1.5139583349227905,
      "rewards/rejected": -3.3852791786193848,
      "step": 6160
    },
    {
      "epoch": 1.1260151473674604,
      "grad_norm": 2.648479461669922,
      "learning_rate": 5.045005218886228e-05,
      "logits/chosen": -0.8607200384140015,
      "logits/rejected": -0.8021465539932251,
      "logps/chosen": -153.5263214111328,
      "logps/rejected": -155.63331604003906,
      "loss": 0.5888,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.1611595153808594,
      "rewards/margins": 1.0520856380462646,
      "rewards/rejected": -3.213244915008545,
      "step": 6170
    },
    {
      "epoch": 1.1278401313988502,
      "grad_norm": 1.5892624855041504,
      "learning_rate": 5.0400933259654946e-05,
      "logits/chosen": -0.9946991801261902,
      "logits/rejected": -0.8745372891426086,
      "logps/chosen": -167.50210571289062,
      "logps/rejected": -164.0665283203125,
      "loss": 0.352,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.383355736732483,
      "rewards/margins": 1.7809686660766602,
      "rewards/rejected": -3.1643245220184326,
      "step": 6180
    },
    {
      "epoch": 1.12966511543024,
      "grad_norm": 1.1315245628356934,
      "learning_rate": 5.03518143304476e-05,
      "logits/chosen": -0.9404464960098267,
      "logits/rejected": -0.8016952276229858,
      "logps/chosen": -169.33035278320312,
      "logps/rejected": -168.06289672851562,
      "loss": 0.362,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.763506293296814,
      "rewards/margins": 1.8376939296722412,
      "rewards/rejected": -3.601200580596924,
      "step": 6190
    },
    {
      "epoch": 1.1314900994616297,
      "grad_norm": 2.3634700775146484,
      "learning_rate": 5.0302695401240254e-05,
      "logits/chosen": -0.9842575788497925,
      "logits/rejected": -0.9016423225402832,
      "logps/chosen": -158.41653442382812,
      "logps/rejected": -170.33926391601562,
      "loss": 0.4055,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.6593701839447021,
      "rewards/margins": 1.8851187229156494,
      "rewards/rejected": -3.5444893836975098,
      "step": 6200
    },
    {
      "epoch": 1.1333150834930195,
      "grad_norm": 3.486041784286499,
      "learning_rate": 5.025357647203291e-05,
      "logits/chosen": -0.9729382395744324,
      "logits/rejected": -0.8589879274368286,
      "logps/chosen": -175.28860473632812,
      "logps/rejected": -163.0943603515625,
      "loss": 0.4459,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9590650796890259,
      "rewards/margins": 1.8159366846084595,
      "rewards/rejected": -3.7750015258789062,
      "step": 6210
    },
    {
      "epoch": 1.1351400675244092,
      "grad_norm": 3.6608636379241943,
      "learning_rate": 5.0204457542825576e-05,
      "logits/chosen": -0.9236478805541992,
      "logits/rejected": -0.8223229646682739,
      "logps/chosen": -179.19761657714844,
      "logps/rejected": -157.95379638671875,
      "loss": 0.5299,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.701923131942749,
      "rewards/margins": 1.3397791385650635,
      "rewards/rejected": -3.0417027473449707,
      "step": 6220
    },
    {
      "epoch": 1.136965051555799,
      "grad_norm": 2.9215831756591797,
      "learning_rate": 5.015533861361823e-05,
      "logits/chosen": -0.9250292778015137,
      "logits/rejected": -0.7642145156860352,
      "logps/chosen": -158.40664672851562,
      "logps/rejected": -161.71359252929688,
      "loss": 0.3699,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.197580099105835,
      "rewards/margins": 1.915408730506897,
      "rewards/rejected": -3.112988233566284,
      "step": 6230
    },
    {
      "epoch": 1.1387900355871885,
      "grad_norm": 3.313508987426758,
      "learning_rate": 5.010621968441088e-05,
      "logits/chosen": -0.9254528880119324,
      "logits/rejected": -0.8300827145576477,
      "logps/chosen": -164.1946563720703,
      "logps/rejected": -156.61083984375,
      "loss": 0.4226,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.592297911643982,
      "rewards/margins": 1.542656421661377,
      "rewards/rejected": -3.1349542140960693,
      "step": 6240
    },
    {
      "epoch": 1.1406150196185783,
      "grad_norm": 4.857037544250488,
      "learning_rate": 5.005710075520354e-05,
      "logits/chosen": -0.9139000177383423,
      "logits/rejected": -0.8025229573249817,
      "logps/chosen": -153.11851501464844,
      "logps/rejected": -155.56639099121094,
      "loss": 0.5391,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.236063003540039,
      "rewards/margins": 1.9320167303085327,
      "rewards/rejected": -3.1680798530578613,
      "step": 6250
    },
    {
      "epoch": 1.142440003649968,
      "grad_norm": 3.3067002296447754,
      "learning_rate": 5.00079818259962e-05,
      "logits/chosen": -0.8790063858032227,
      "logits/rejected": -0.7784789800643921,
      "logps/chosen": -170.7285614013672,
      "logps/rejected": -156.15682983398438,
      "loss": 0.5106,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1568257808685303,
      "rewards/margins": 1.4067580699920654,
      "rewards/rejected": -2.5635838508605957,
      "step": 6260
    },
    {
      "epoch": 1.1442649876813578,
      "grad_norm": 2.660836935043335,
      "learning_rate": 4.995886289678885e-05,
      "logits/chosen": -1.0649943351745605,
      "logits/rejected": -0.9287082552909851,
      "logps/chosen": -168.92526245117188,
      "logps/rejected": -141.15867614746094,
      "loss": 0.3547,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.6268729567527771,
      "rewards/margins": 1.649332046508789,
      "rewards/rejected": -2.27620530128479,
      "step": 6270
    },
    {
      "epoch": 1.1460899717127475,
      "grad_norm": 2.420254945755005,
      "learning_rate": 4.990974396758151e-05,
      "logits/chosen": -1.0332508087158203,
      "logits/rejected": -0.9692102670669556,
      "logps/chosen": -162.5969696044922,
      "logps/rejected": -156.91842651367188,
      "loss": 0.4228,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.746081531047821,
      "rewards/margins": 1.3298430442810059,
      "rewards/rejected": -2.0759246349334717,
      "step": 6280
    },
    {
      "epoch": 1.1479149557441373,
      "grad_norm": 1.496109962463379,
      "learning_rate": 4.9860625038374174e-05,
      "logits/chosen": -1.0401129722595215,
      "logits/rejected": -1.0230122804641724,
      "logps/chosen": -140.98434448242188,
      "logps/rejected": -164.49472045898438,
      "loss": 0.4235,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.887022852897644,
      "rewards/margins": 1.4454834461212158,
      "rewards/rejected": -2.3325066566467285,
      "step": 6290
    },
    {
      "epoch": 1.149739939775527,
      "grad_norm": 4.0181097984313965,
      "learning_rate": 4.9811506109166825e-05,
      "logits/chosen": -1.1060248613357544,
      "logits/rejected": -0.9992334246635437,
      "logps/chosen": -154.50479125976562,
      "logps/rejected": -159.47537231445312,
      "loss": 0.4691,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6208544969558716,
      "rewards/margins": 1.612415075302124,
      "rewards/rejected": -2.2332699298858643,
      "step": 6300
    },
    {
      "epoch": 1.1515649238069168,
      "grad_norm": 3.034156322479248,
      "learning_rate": 4.976238717995948e-05,
      "logits/chosen": -1.1645931005477905,
      "logits/rejected": -1.0744231939315796,
      "logps/chosen": -156.6449432373047,
      "logps/rejected": -154.95684814453125,
      "loss": 0.5166,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7200207710266113,
      "rewards/margins": 1.524543046951294,
      "rewards/rejected": -2.244563579559326,
      "step": 6310
    },
    {
      "epoch": 1.1533899078383065,
      "grad_norm": 5.560070037841797,
      "learning_rate": 4.9713268250752133e-05,
      "logits/chosen": -1.106865644454956,
      "logits/rejected": -0.9919238090515137,
      "logps/chosen": -162.89010620117188,
      "logps/rejected": -145.04110717773438,
      "loss": 0.4117,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6887056827545166,
      "rewards/margins": 2.0080978870391846,
      "rewards/rejected": -2.696803569793701,
      "step": 6320
    },
    {
      "epoch": 1.155214891869696,
      "grad_norm": 4.323660373687744,
      "learning_rate": 4.96641493215448e-05,
      "logits/chosen": -1.0878812074661255,
      "logits/rejected": -1.0250589847564697,
      "logps/chosen": -156.58607482910156,
      "logps/rejected": -155.79856872558594,
      "loss": 0.5289,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8987129926681519,
      "rewards/margins": 1.497585654258728,
      "rewards/rejected": -2.396298885345459,
      "step": 6330
    },
    {
      "epoch": 1.1570398759010858,
      "grad_norm": 4.1143903732299805,
      "learning_rate": 4.961503039233745e-05,
      "logits/chosen": -1.074610948562622,
      "logits/rejected": -1.031961441040039,
      "logps/chosen": -152.36361694335938,
      "logps/rejected": -155.23471069335938,
      "loss": 0.4656,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.22205683588981628,
      "rewards/margins": 1.1087688207626343,
      "rewards/rejected": -1.3308255672454834,
      "step": 6340
    },
    {
      "epoch": 1.1588648599324756,
      "grad_norm": 1.4501856565475464,
      "learning_rate": 4.956591146313011e-05,
      "logits/chosen": -1.0253416299819946,
      "logits/rejected": -0.9725162386894226,
      "logps/chosen": -147.2967987060547,
      "logps/rejected": -139.05404663085938,
      "loss": 0.4992,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.31688445806503296,
      "rewards/margins": 1.1745731830596924,
      "rewards/rejected": -1.4914575815200806,
      "step": 6350
    },
    {
      "epoch": 1.1606898439638653,
      "grad_norm": 3.1706645488739014,
      "learning_rate": 4.951679253392277e-05,
      "logits/chosen": -1.1483234167099,
      "logits/rejected": -1.0555843114852905,
      "logps/chosen": -146.66839599609375,
      "logps/rejected": -142.4355926513672,
      "loss": 0.3247,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.3763737678527832,
      "rewards/margins": 1.6593067646026611,
      "rewards/rejected": -2.0356802940368652,
      "step": 6360
    },
    {
      "epoch": 1.162514827995255,
      "grad_norm": 6.125502586364746,
      "learning_rate": 4.946767360471542e-05,
      "logits/chosen": -1.0863173007965088,
      "logits/rejected": -1.0326745510101318,
      "logps/chosen": -166.66021728515625,
      "logps/rejected": -162.3112030029297,
      "loss": 0.5231,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9620872735977173,
      "rewards/margins": 1.3027899265289307,
      "rewards/rejected": -2.2648770809173584,
      "step": 6370
    },
    {
      "epoch": 1.1643398120266448,
      "grad_norm": 4.702324390411377,
      "learning_rate": 4.9423466568428814e-05,
      "logits/chosen": -1.1143155097961426,
      "logits/rejected": -0.994110107421875,
      "logps/chosen": -159.69168090820312,
      "logps/rejected": -149.14437866210938,
      "loss": 0.4559,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.0796890258789062,
      "rewards/margins": 1.516350269317627,
      "rewards/rejected": -2.596039295196533,
      "step": 6380
    },
    {
      "epoch": 1.1661647960580346,
      "grad_norm": 4.218980312347412,
      "learning_rate": 4.937434763922147e-05,
      "logits/chosen": -1.0865243673324585,
      "logits/rejected": -1.073543906211853,
      "logps/chosen": -142.63877868652344,
      "logps/rejected": -161.14479064941406,
      "loss": 0.4567,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1357696056365967,
      "rewards/margins": 1.2000597715377808,
      "rewards/rejected": -2.335829496383667,
      "step": 6390
    },
    {
      "epoch": 1.1679897800894241,
      "grad_norm": 1.626111626625061,
      "learning_rate": 4.932522871001412e-05,
      "logits/chosen": -1.0971843004226685,
      "logits/rejected": -1.0124965906143188,
      "logps/chosen": -152.50726318359375,
      "logps/rejected": -141.30108642578125,
      "loss": 0.4745,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.6030359864234924,
      "rewards/margins": 1.3582807779312134,
      "rewards/rejected": -1.961316704750061,
      "step": 6400
    },
    {
      "epoch": 1.1698147641208139,
      "grad_norm": 2.5281078815460205,
      "learning_rate": 4.927610978080679e-05,
      "logits/chosen": -1.1846832036972046,
      "logits/rejected": -1.0867359638214111,
      "logps/chosen": -156.1529998779297,
      "logps/rejected": -157.46286010742188,
      "loss": 0.3537,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.3268243670463562,
      "rewards/margins": 1.6638429164886475,
      "rewards/rejected": -1.9906675815582275,
      "step": 6410
    },
    {
      "epoch": 1.1716397481522036,
      "grad_norm": 3.8227591514587402,
      "learning_rate": 4.922699085159944e-05,
      "logits/chosen": -1.1017500162124634,
      "logits/rejected": -1.0086488723754883,
      "logps/chosen": -160.3598175048828,
      "logps/rejected": -147.24459838867188,
      "loss": 0.3913,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.7818161249160767,
      "rewards/margins": 1.5401369333267212,
      "rewards/rejected": -2.321953058242798,
      "step": 6420
    },
    {
      "epoch": 1.1734647321835934,
      "grad_norm": 6.01370096206665,
      "learning_rate": 4.9177871922392096e-05,
      "logits/chosen": -1.0690348148345947,
      "logits/rejected": -0.9100334048271179,
      "logps/chosen": -172.01638793945312,
      "logps/rejected": -153.54498291015625,
      "loss": 0.5006,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0819876194000244,
      "rewards/margins": 1.5157701969146729,
      "rewards/rejected": -2.5977580547332764,
      "step": 6430
    },
    {
      "epoch": 1.1752897162149831,
      "grad_norm": 3.5891759395599365,
      "learning_rate": 4.912875299318475e-05,
      "logits/chosen": -0.9478389024734497,
      "logits/rejected": -0.8905534744262695,
      "logps/chosen": -151.42486572265625,
      "logps/rejected": -168.00608825683594,
      "loss": 0.4308,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.2516467571258545,
      "rewards/margins": 1.6857929229736328,
      "rewards/rejected": -2.9374396800994873,
      "step": 6440
    },
    {
      "epoch": 1.1771147002463729,
      "grad_norm": 3.9054481983184814,
      "learning_rate": 4.907963406397741e-05,
      "logits/chosen": -0.9525570869445801,
      "logits/rejected": -0.8459417223930359,
      "logps/chosen": -155.83700561523438,
      "logps/rejected": -140.01815795898438,
      "loss": 0.5741,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.4731364250183105,
      "rewards/margins": 0.8864349126815796,
      "rewards/rejected": -2.3595714569091797,
      "step": 6450
    },
    {
      "epoch": 1.1789396842777626,
      "grad_norm": 3.674354076385498,
      "learning_rate": 4.903051513477007e-05,
      "logits/chosen": -0.9731115102767944,
      "logits/rejected": -0.8771002888679504,
      "logps/chosen": -153.0273895263672,
      "logps/rejected": -141.34690856933594,
      "loss": 0.4317,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.447960615158081,
      "rewards/margins": 1.4298486709594727,
      "rewards/rejected": -2.8778092861175537,
      "step": 6460
    },
    {
      "epoch": 1.1807646683091524,
      "grad_norm": 3.481616973876953,
      "learning_rate": 4.898139620556272e-05,
      "logits/chosen": -0.997724711894989,
      "logits/rejected": -0.8674277067184448,
      "logps/chosen": -162.1016845703125,
      "logps/rejected": -149.49942016601562,
      "loss": 0.492,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.2072464227676392,
      "rewards/margins": 1.3692166805267334,
      "rewards/rejected": -2.576463222503662,
      "step": 6470
    },
    {
      "epoch": 1.1825896523405421,
      "grad_norm": 6.050545692443848,
      "learning_rate": 4.893227727635538e-05,
      "logits/chosen": -0.9321510195732117,
      "logits/rejected": -0.8557055592536926,
      "logps/chosen": -163.61253356933594,
      "logps/rejected": -149.99844360351562,
      "loss": 0.5442,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.2097705602645874,
      "rewards/margins": 1.31668221950531,
      "rewards/rejected": -2.5264530181884766,
      "step": 6480
    },
    {
      "epoch": 1.1844146363719317,
      "grad_norm": 2.9419853687286377,
      "learning_rate": 4.8883158347148036e-05,
      "logits/chosen": -0.9828888773918152,
      "logits/rejected": -0.9549759030342102,
      "logps/chosen": -145.48648071289062,
      "logps/rejected": -160.55467224121094,
      "loss": 0.3961,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9928164482116699,
      "rewards/margins": 1.5926669836044312,
      "rewards/rejected": -2.5854830741882324,
      "step": 6490
    },
    {
      "epoch": 1.1862396204033214,
      "grad_norm": 5.674384593963623,
      "learning_rate": 4.883403941794069e-05,
      "logits/chosen": -1.0905424356460571,
      "logits/rejected": -1.0758484601974487,
      "logps/chosen": -154.306640625,
      "logps/rejected": -154.8630828857422,
      "loss": 0.5478,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.404748558998108,
      "rewards/margins": 1.1336472034454346,
      "rewards/rejected": -2.538395881652832,
      "step": 6500
    },
    {
      "epoch": 1.1880646044347112,
      "grad_norm": 4.994589328765869,
      "learning_rate": 4.8784920488733344e-05,
      "logits/chosen": -1.0282225608825684,
      "logits/rejected": -0.984642505645752,
      "logps/chosen": -145.29205322265625,
      "logps/rejected": -156.7547607421875,
      "loss": 0.4488,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9678613543510437,
      "rewards/margins": 1.4945604801177979,
      "rewards/rejected": -2.4624218940734863,
      "step": 6510
    },
    {
      "epoch": 1.189889588466101,
      "grad_norm": 4.374828815460205,
      "learning_rate": 4.873580155952601e-05,
      "logits/chosen": -1.115956425666809,
      "logits/rejected": -1.0657991170883179,
      "logps/chosen": -159.18411254882812,
      "logps/rejected": -156.0140380859375,
      "loss": 0.3914,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.6781777143478394,
      "rewards/margins": 1.4601991176605225,
      "rewards/rejected": -2.1383767127990723,
      "step": 6520
    },
    {
      "epoch": 1.1917145724974907,
      "grad_norm": 2.9307985305786133,
      "learning_rate": 4.8686682630318666e-05,
      "logits/chosen": -1.1017727851867676,
      "logits/rejected": -1.0239028930664062,
      "logps/chosen": -147.96923828125,
      "logps/rejected": -130.26156616210938,
      "loss": 0.4015,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.8111535310745239,
      "rewards/margins": 1.43733549118042,
      "rewards/rejected": -2.2484891414642334,
      "step": 6530
    },
    {
      "epoch": 1.1935395565288804,
      "grad_norm": 3.5781660079956055,
      "learning_rate": 4.863756370111132e-05,
      "logits/chosen": -1.108804702758789,
      "logits/rejected": -1.0306463241577148,
      "logps/chosen": -164.77232360839844,
      "logps/rejected": -159.30557250976562,
      "loss": 0.3704,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.0848242044448853,
      "rewards/margins": 1.7064998149871826,
      "rewards/rejected": -2.7913243770599365,
      "step": 6540
    },
    {
      "epoch": 1.1953645405602702,
      "grad_norm": 2.09551739692688,
      "learning_rate": 4.8588444771903975e-05,
      "logits/chosen": -1.118260145187378,
      "logits/rejected": -1.010622262954712,
      "logps/chosen": -156.87747192382812,
      "logps/rejected": -151.57765197753906,
      "loss": 0.3323,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.0525063276290894,
      "rewards/margins": 2.106832981109619,
      "rewards/rejected": -3.159339189529419,
      "step": 6550
    },
    {
      "epoch": 1.1971895245916597,
      "grad_norm": 2.058546304702759,
      "learning_rate": 4.853932584269664e-05,
      "logits/chosen": -1.123457431793213,
      "logits/rejected": -1.03374183177948,
      "logps/chosen": -167.82070922851562,
      "logps/rejected": -165.2954559326172,
      "loss": 0.3281,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.510457992553711,
      "rewards/margins": 2.1361465454101562,
      "rewards/rejected": -3.646604537963867,
      "step": 6560
    },
    {
      "epoch": 1.1990145086230495,
      "grad_norm": 3.7209012508392334,
      "learning_rate": 4.849020691348929e-05,
      "logits/chosen": -1.073890209197998,
      "logits/rejected": -1.046847939491272,
      "logps/chosen": -170.2884979248047,
      "logps/rejected": -174.7657928466797,
      "loss": 0.6309,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8117434978485107,
      "rewards/margins": 1.1810526847839355,
      "rewards/rejected": -2.9927961826324463,
      "step": 6570
    },
    {
      "epoch": 1.2008394926544392,
      "grad_norm": 9.755582809448242,
      "learning_rate": 4.844108798428194e-05,
      "logits/chosen": -1.0446536540985107,
      "logits/rejected": -0.9623051881790161,
      "logps/chosen": -155.9683837890625,
      "logps/rejected": -158.37164306640625,
      "loss": 0.5689,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6131031513214111,
      "rewards/margins": 1.4999834299087524,
      "rewards/rejected": -3.113086700439453,
      "step": 6580
    },
    {
      "epoch": 1.202664476685829,
      "grad_norm": 4.449942111968994,
      "learning_rate": 4.83919690550746e-05,
      "logits/chosen": -1.0231598615646362,
      "logits/rejected": -0.9255572557449341,
      "logps/chosen": -155.7394561767578,
      "logps/rejected": -147.58584594726562,
      "loss": 0.4373,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2585299015045166,
      "rewards/margins": 1.6893573999404907,
      "rewards/rejected": -2.9478871822357178,
      "step": 6590
    },
    {
      "epoch": 1.2044894607172187,
      "grad_norm": 16.34280776977539,
      "learning_rate": 4.8342850125867264e-05,
      "logits/chosen": -1.0048073530197144,
      "logits/rejected": -0.9377759695053101,
      "logps/chosen": -169.0399932861328,
      "logps/rejected": -167.63604736328125,
      "loss": 0.7257,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4868193864822388,
      "rewards/margins": 1.149292230606079,
      "rewards/rejected": -2.6361117362976074,
      "step": 6600
    },
    {
      "epoch": 1.2063144447486085,
      "grad_norm": 2.89186429977417,
      "learning_rate": 4.8293731196659915e-05,
      "logits/chosen": -1.046700358390808,
      "logits/rejected": -0.9504580497741699,
      "logps/chosen": -166.955810546875,
      "logps/rejected": -162.19564819335938,
      "loss": 0.5083,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3204978704452515,
      "rewards/margins": 1.4023377895355225,
      "rewards/rejected": -2.7228357791900635,
      "step": 6610
    },
    {
      "epoch": 1.2081394287799982,
      "grad_norm": 2.559565305709839,
      "learning_rate": 4.824461226745257e-05,
      "logits/chosen": -0.9991031885147095,
      "logits/rejected": -0.9492321014404297,
      "logps/chosen": -156.67752075195312,
      "logps/rejected": -148.85165405273438,
      "loss": 0.491,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0720629692077637,
      "rewards/margins": 1.2301452159881592,
      "rewards/rejected": -2.302208423614502,
      "step": 6620
    },
    {
      "epoch": 1.209964412811388,
      "grad_norm": 3.1080965995788574,
      "learning_rate": 4.819549333824524e-05,
      "logits/chosen": -1.071657419204712,
      "logits/rejected": -0.9523725509643555,
      "logps/chosen": -162.57643127441406,
      "logps/rejected": -138.9618377685547,
      "loss": 0.4303,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.4182572364807129,
      "rewards/margins": 1.2174131870269775,
      "rewards/rejected": -1.6356704235076904,
      "step": 6630
    },
    {
      "epoch": 1.2117893968427775,
      "grad_norm": 3.443040609359741,
      "learning_rate": 4.814637440903789e-05,
      "logits/chosen": -1.0426563024520874,
      "logits/rejected": -0.964318573474884,
      "logps/chosen": -147.12205505371094,
      "logps/rejected": -144.08456420898438,
      "loss": 0.4217,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.5819010734558105,
      "rewards/margins": 1.2475653886795044,
      "rewards/rejected": -1.829466462135315,
      "step": 6640
    },
    {
      "epoch": 1.2136143808741673,
      "grad_norm": 3.2546000480651855,
      "learning_rate": 4.8097255479830546e-05,
      "logits/chosen": -1.1174522638320923,
      "logits/rejected": -1.0256977081298828,
      "logps/chosen": -168.46975708007812,
      "logps/rejected": -150.69882202148438,
      "loss": 0.4411,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.5947664976119995,
      "rewards/margins": 1.3902498483657837,
      "rewards/rejected": -1.9850164651870728,
      "step": 6650
    },
    {
      "epoch": 1.215439364905557,
      "grad_norm": 1.1184345483779907,
      "learning_rate": 4.80481365506232e-05,
      "logits/chosen": -1.0615084171295166,
      "logits/rejected": -0.9353638887405396,
      "logps/chosen": -173.034912109375,
      "logps/rejected": -141.11410522460938,
      "loss": 0.5048,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0316789150238037,
      "rewards/margins": 1.2827380895614624,
      "rewards/rejected": -2.3144168853759766,
      "step": 6660
    },
    {
      "epoch": 1.2172643489369468,
      "grad_norm": 4.117552280426025,
      "learning_rate": 4.799901762141586e-05,
      "logits/chosen": -0.9958245158195496,
      "logits/rejected": -0.9379482269287109,
      "logps/chosen": -168.29312133789062,
      "logps/rejected": -167.964111328125,
      "loss": 0.4663,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.2226365804672241,
      "rewards/margins": 1.2764124870300293,
      "rewards/rejected": -2.4990487098693848,
      "step": 6670
    },
    {
      "epoch": 1.2190893329683365,
      "grad_norm": 5.2219719886779785,
      "learning_rate": 4.794989869220851e-05,
      "logits/chosen": -0.9940166473388672,
      "logits/rejected": -0.9599226713180542,
      "logps/chosen": -154.01113891601562,
      "logps/rejected": -165.03526306152344,
      "loss": 0.5354,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1539281606674194,
      "rewards/margins": 1.2620254755020142,
      "rewards/rejected": -2.4159538745880127,
      "step": 6680
    },
    {
      "epoch": 1.2209143169997263,
      "grad_norm": 3.2557060718536377,
      "learning_rate": 4.790077976300117e-05,
      "logits/chosen": -1.024954915046692,
      "logits/rejected": -0.9437308311462402,
      "logps/chosen": -167.46722412109375,
      "logps/rejected": -166.33505249023438,
      "loss": 0.3548,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.1808762550354004,
      "rewards/margins": 1.6835085153579712,
      "rewards/rejected": -2.864384651184082,
      "step": 6690
    },
    {
      "epoch": 1.222739301031116,
      "grad_norm": 5.0401740074157715,
      "learning_rate": 4.7851660833793834e-05,
      "logits/chosen": -1.0670734643936157,
      "logits/rejected": -0.9591273069381714,
      "logps/chosen": -156.663330078125,
      "logps/rejected": -156.49993896484375,
      "loss": 0.5083,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.177320957183838,
      "rewards/margins": 1.4946558475494385,
      "rewards/rejected": -2.6719765663146973,
      "step": 6700
    },
    {
      "epoch": 1.2245642850625056,
      "grad_norm": 2.5640392303466797,
      "learning_rate": 4.7802541904586485e-05,
      "logits/chosen": -1.0919368267059326,
      "logits/rejected": -1.0383861064910889,
      "logps/chosen": -148.99169921875,
      "logps/rejected": -146.09982299804688,
      "loss": 0.4675,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.00723135471344,
      "rewards/margins": 1.454057216644287,
      "rewards/rejected": -2.4612886905670166,
      "step": 6710
    },
    {
      "epoch": 1.2263892690938953,
      "grad_norm": 2.5302820205688477,
      "learning_rate": 4.775833486829988e-05,
      "logits/chosen": -1.1084187030792236,
      "logits/rejected": -1.0224077701568604,
      "logps/chosen": -174.31314086914062,
      "logps/rejected": -165.96273803710938,
      "loss": 0.4785,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.6046009063720703,
      "rewards/margins": 1.527776837348938,
      "rewards/rejected": -2.1323776245117188,
      "step": 6720
    },
    {
      "epoch": 1.228214253125285,
      "grad_norm": 5.1846537590026855,
      "learning_rate": 4.7709215939092535e-05,
      "logits/chosen": -1.070937156677246,
      "logits/rejected": -1.0063774585723877,
      "logps/chosen": -177.37608337402344,
      "logps/rejected": -156.3374786376953,
      "loss": 0.4913,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.057124137878418,
      "rewards/margins": 1.22069251537323,
      "rewards/rejected": -2.2778165340423584,
      "step": 6730
    },
    {
      "epoch": 1.2300392371566748,
      "grad_norm": 1.7686372995376587,
      "learning_rate": 4.7660097009885186e-05,
      "logits/chosen": -1.0926940441131592,
      "logits/rejected": -1.0143930912017822,
      "logps/chosen": -165.72914123535156,
      "logps/rejected": -151.7373504638672,
      "loss": 0.4466,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.4655113220214844,
      "rewards/margins": 1.2937098741531372,
      "rewards/rejected": -1.7592213153839111,
      "step": 6740
    },
    {
      "epoch": 1.2318642211880646,
      "grad_norm": 2.461927890777588,
      "learning_rate": 4.7610978080677844e-05,
      "logits/chosen": -1.0713865756988525,
      "logits/rejected": -0.9914385676383972,
      "logps/chosen": -151.66944885253906,
      "logps/rejected": -136.537841796875,
      "loss": 0.4477,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.4505682587623596,
      "rewards/margins": 1.4552116394042969,
      "rewards/rejected": -1.9057798385620117,
      "step": 6750
    },
    {
      "epoch": 1.2336892052194544,
      "grad_norm": 3.5677988529205322,
      "learning_rate": 4.75618591514705e-05,
      "logits/chosen": -1.086334466934204,
      "logits/rejected": -0.9722682237625122,
      "logps/chosen": -156.09768676757812,
      "logps/rejected": -144.61434936523438,
      "loss": 0.3996,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.23749856650829315,
      "rewards/margins": 1.4928258657455444,
      "rewards/rejected": -1.730324387550354,
      "step": 6760
    },
    {
      "epoch": 1.235514189250844,
      "grad_norm": 2.004093885421753,
      "learning_rate": 4.751274022226316e-05,
      "logits/chosen": -1.0765483379364014,
      "logits/rejected": -1.0329629182815552,
      "logps/chosen": -156.3801727294922,
      "logps/rejected": -158.02926635742188,
      "loss": 0.4536,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.3147485852241516,
      "rewards/margins": 1.2013580799102783,
      "rewards/rejected": -1.5161068439483643,
      "step": 6770
    },
    {
      "epoch": 1.2373391732822339,
      "grad_norm": 3.4948179721832275,
      "learning_rate": 4.746362129305581e-05,
      "logits/chosen": -1.1400352716445923,
      "logits/rejected": -1.0749456882476807,
      "logps/chosen": -158.5546417236328,
      "logps/rejected": -145.79159545898438,
      "loss": 0.4757,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.4113228917121887,
      "rewards/margins": 1.320940613746643,
      "rewards/rejected": -1.7322635650634766,
      "step": 6780
    },
    {
      "epoch": 1.2391641573136236,
      "grad_norm": 2.824431896209717,
      "learning_rate": 4.7414502363848475e-05,
      "logits/chosen": -1.1996989250183105,
      "logits/rejected": -1.1282427310943604,
      "logps/chosen": -159.53756713867188,
      "logps/rejected": -146.0956573486328,
      "loss": 0.4013,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.14966663718223572,
      "rewards/margins": 1.3953720331192017,
      "rewards/rejected": -1.5450387001037598,
      "step": 6790
    },
    {
      "epoch": 1.2409891413450131,
      "grad_norm": 5.333436489105225,
      "learning_rate": 4.736538343464113e-05,
      "logits/chosen": -1.1525905132293701,
      "logits/rejected": -1.071334958076477,
      "logps/chosen": -135.89743041992188,
      "logps/rejected": -138.0789031982422,
      "loss": 0.3748,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.08679374307394028,
      "rewards/margins": 1.6247434616088867,
      "rewards/rejected": -1.7115373611450195,
      "step": 6800
    },
    {
      "epoch": 1.242814125376403,
      "grad_norm": 3.4964001178741455,
      "learning_rate": 4.731626450543378e-05,
      "logits/chosen": -1.1602929830551147,
      "logits/rejected": -1.0917531251907349,
      "logps/chosen": -154.07931518554688,
      "logps/rejected": -144.63845825195312,
      "loss": 0.4693,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.5107043981552124,
      "rewards/margins": 1.1509230136871338,
      "rewards/rejected": -1.6616274118423462,
      "step": 6810
    },
    {
      "epoch": 1.2446391094077927,
      "grad_norm": 2.4220831394195557,
      "learning_rate": 4.726714557622644e-05,
      "logits/chosen": -1.0963408946990967,
      "logits/rejected": -1.028156042098999,
      "logps/chosen": -146.38406372070312,
      "logps/rejected": -153.31581115722656,
      "loss": 0.4171,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.7779275178909302,
      "rewards/margins": 1.5803251266479492,
      "rewards/rejected": -2.358252763748169,
      "step": 6820
    },
    {
      "epoch": 1.2464640934391824,
      "grad_norm": 5.098874092102051,
      "learning_rate": 4.72180266470191e-05,
      "logits/chosen": -1.0583395957946777,
      "logits/rejected": -0.9756234288215637,
      "logps/chosen": -152.80751037597656,
      "logps/rejected": -148.55894470214844,
      "loss": 0.4411,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.0013706684112549,
      "rewards/margins": 1.504818320274353,
      "rewards/rejected": -2.5061891078948975,
      "step": 6830
    },
    {
      "epoch": 1.2482890774705722,
      "grad_norm": 3.4417600631713867,
      "learning_rate": 4.7168907717811756e-05,
      "logits/chosen": -1.0335403680801392,
      "logits/rejected": -1.0038676261901855,
      "logps/chosen": -144.10855102539062,
      "logps/rejected": -157.412353515625,
      "loss": 0.3525,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.236802101135254,
      "rewards/margins": 1.7298561334609985,
      "rewards/rejected": -2.966658115386963,
      "step": 6840
    },
    {
      "epoch": 1.250114061501962,
      "grad_norm": 2.1500258445739746,
      "learning_rate": 4.711978878860441e-05,
      "logits/chosen": -1.014850378036499,
      "logits/rejected": -0.9528493881225586,
      "logps/chosen": -156.7738037109375,
      "logps/rejected": -150.61361694335938,
      "loss": 0.5104,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6020174026489258,
      "rewards/margins": 1.329481601715088,
      "rewards/rejected": -2.9314990043640137,
      "step": 6850
    },
    {
      "epoch": 1.2519390455333514,
      "grad_norm": 3.262287139892578,
      "learning_rate": 4.7070669859397065e-05,
      "logits/chosen": -1.098473310470581,
      "logits/rejected": -1.0242570638656616,
      "logps/chosen": -164.92324829101562,
      "logps/rejected": -167.41812133789062,
      "loss": 0.465,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6362613439559937,
      "rewards/margins": 1.6860110759735107,
      "rewards/rejected": -3.322272539138794,
      "step": 6860
    },
    {
      "epoch": 1.2537640295647412,
      "grad_norm": 1.8972374200820923,
      "learning_rate": 4.702155093018973e-05,
      "logits/chosen": -1.072778344154358,
      "logits/rejected": -1.0306674242019653,
      "logps/chosen": -166.406982421875,
      "logps/rejected": -183.89566040039062,
      "loss": 0.405,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.559569239616394,
      "rewards/margins": 1.4639029502868652,
      "rewards/rejected": -3.023472309112549,
      "step": 6870
    },
    {
      "epoch": 1.255589013596131,
      "grad_norm": 3.941223382949829,
      "learning_rate": 4.697243200098238e-05,
      "logits/chosen": -1.0853521823883057,
      "logits/rejected": -1.0183405876159668,
      "logps/chosen": -155.47642517089844,
      "logps/rejected": -166.31570434570312,
      "loss": 0.4644,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7436597347259521,
      "rewards/margins": 1.6075060367584229,
      "rewards/rejected": -3.351166248321533,
      "step": 6880
    },
    {
      "epoch": 1.2574139976275207,
      "grad_norm": 5.392540454864502,
      "learning_rate": 4.692331307177504e-05,
      "logits/chosen": -1.0544970035552979,
      "logits/rejected": -1.0451563596725464,
      "logps/chosen": -153.24681091308594,
      "logps/rejected": -166.11767578125,
      "loss": 0.4134,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.5500481128692627,
      "rewards/margins": 1.6263103485107422,
      "rewards/rejected": -3.176358461380005,
      "step": 6890
    },
    {
      "epoch": 1.2592389816589105,
      "grad_norm": 2.716116428375244,
      "learning_rate": 4.6874194142567696e-05,
      "logits/chosen": -1.0938680171966553,
      "logits/rejected": -1.0408371686935425,
      "logps/chosen": -160.42645263671875,
      "logps/rejected": -169.1865997314453,
      "loss": 0.4469,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4564592838287354,
      "rewards/margins": 1.7542003393173218,
      "rewards/rejected": -3.2106595039367676,
      "step": 6900
    },
    {
      "epoch": 1.2610639656903002,
      "grad_norm": 5.068421363830566,
      "learning_rate": 4.6825075213360354e-05,
      "logits/chosen": -1.156716227531433,
      "logits/rejected": -1.06478750705719,
      "logps/chosen": -160.0915069580078,
      "logps/rejected": -148.22314453125,
      "loss": 0.5121,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4454541206359863,
      "rewards/margins": 1.4952799081802368,
      "rewards/rejected": -2.9407339096069336,
      "step": 6910
    },
    {
      "epoch": 1.26288894972169,
      "grad_norm": 4.932165145874023,
      "learning_rate": 4.6775956284153005e-05,
      "logits/chosen": -1.170323133468628,
      "logits/rejected": -1.0685902833938599,
      "logps/chosen": -156.1306915283203,
      "logps/rejected": -150.64334106445312,
      "loss": 0.4902,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.0501168966293335,
      "rewards/margins": 1.336805820465088,
      "rewards/rejected": -2.386922836303711,
      "step": 6920
    },
    {
      "epoch": 1.2647139337530797,
      "grad_norm": 5.272546291351318,
      "learning_rate": 4.672683735494566e-05,
      "logits/chosen": -1.1593811511993408,
      "logits/rejected": -1.0850125551223755,
      "logps/chosen": -153.26641845703125,
      "logps/rejected": -149.13861083984375,
      "loss": 0.4976,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.034568428993225,
      "rewards/margins": 1.583956241607666,
      "rewards/rejected": -2.6185247898101807,
      "step": 6930
    },
    {
      "epoch": 1.2665389177844695,
      "grad_norm": 6.104220867156982,
      "learning_rate": 4.667771842573833e-05,
      "logits/chosen": -1.0864081382751465,
      "logits/rejected": -1.0203521251678467,
      "logps/chosen": -146.84884643554688,
      "logps/rejected": -146.1344757080078,
      "loss": 0.3903,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1705260276794434,
      "rewards/margins": 1.604146957397461,
      "rewards/rejected": -2.7746729850769043,
      "step": 6940
    },
    {
      "epoch": 1.2683639018158592,
      "grad_norm": 2.1413748264312744,
      "learning_rate": 4.662859949653098e-05,
      "logits/chosen": -1.162741780281067,
      "logits/rejected": -1.1204657554626465,
      "logps/chosen": -160.99705505371094,
      "logps/rejected": -162.50856018066406,
      "loss": 0.3978,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.0636874437332153,
      "rewards/margins": 1.3911173343658447,
      "rewards/rejected": -2.4548048973083496,
      "step": 6950
    },
    {
      "epoch": 1.2701888858472488,
      "grad_norm": 3.9974327087402344,
      "learning_rate": 4.6579480567323636e-05,
      "logits/chosen": -1.137691617012024,
      "logits/rejected": -1.0926494598388672,
      "logps/chosen": -143.52444458007812,
      "logps/rejected": -152.91717529296875,
      "loss": 0.3871,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.405821442604065,
      "rewards/margins": 1.465811014175415,
      "rewards/rejected": -2.8716325759887695,
      "step": 6960
    },
    {
      "epoch": 1.2720138698786385,
      "grad_norm": 4.664605617523193,
      "learning_rate": 4.65303616381163e-05,
      "logits/chosen": -1.1313669681549072,
      "logits/rejected": -1.094087839126587,
      "logps/chosen": -149.11134338378906,
      "logps/rejected": -156.2549591064453,
      "loss": 0.6475,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.7215970754623413,
      "rewards/margins": 1.210009217262268,
      "rewards/rejected": -2.9316062927246094,
      "step": 6970
    },
    {
      "epoch": 1.2738388539100283,
      "grad_norm": 2.4132330417633057,
      "learning_rate": 4.648124270890895e-05,
      "logits/chosen": -1.1372663974761963,
      "logits/rejected": -1.0880401134490967,
      "logps/chosen": -143.90371704101562,
      "logps/rejected": -152.03707885742188,
      "loss": 0.4434,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.9437597990036011,
      "rewards/margins": 1.366468071937561,
      "rewards/rejected": -2.310227870941162,
      "step": 6980
    },
    {
      "epoch": 1.275663837941418,
      "grad_norm": 2.104768991470337,
      "learning_rate": 4.643212377970161e-05,
      "logits/chosen": -1.2005635499954224,
      "logits/rejected": -1.0988163948059082,
      "logps/chosen": -160.26071166992188,
      "logps/rejected": -143.30743408203125,
      "loss": 0.4365,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.582151472568512,
      "rewards/margins": 1.35477614402771,
      "rewards/rejected": -1.9369275569915771,
      "step": 6990
    },
    {
      "epoch": 1.2774888219728078,
      "grad_norm": 1.9745588302612305,
      "learning_rate": 4.638300485049426e-05,
      "logits/chosen": -1.1464372873306274,
      "logits/rejected": -1.096388816833496,
      "logps/chosen": -156.1121368408203,
      "logps/rejected": -149.58328247070312,
      "loss": 0.3562,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.7721748352050781,
      "rewards/margins": 1.3505884408950806,
      "rewards/rejected": -2.1227633953094482,
      "step": 7000
    },
    {
      "epoch": 1.2793138060041975,
      "grad_norm": 3.0270681381225586,
      "learning_rate": 4.6333885921286924e-05,
      "logits/chosen": -1.1367642879486084,
      "logits/rejected": -1.0851764678955078,
      "logps/chosen": -144.52688598632812,
      "logps/rejected": -171.89427185058594,
      "loss": 0.3694,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.7750899195671082,
      "rewards/margins": 1.8268883228302002,
      "rewards/rejected": -2.601978302001953,
      "step": 7010
    },
    {
      "epoch": 1.281138790035587,
      "grad_norm": 4.089949131011963,
      "learning_rate": 4.6284766992079575e-05,
      "logits/chosen": -1.156148910522461,
      "logits/rejected": -1.0848877429962158,
      "logps/chosen": -144.32754516601562,
      "logps/rejected": -153.93466186523438,
      "loss": 0.3298,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.7583673000335693,
      "rewards/margins": 1.9569118022918701,
      "rewards/rejected": -2.7152791023254395,
      "step": 7020
    },
    {
      "epoch": 1.2829637740669768,
      "grad_norm": 2.2611494064331055,
      "learning_rate": 4.623564806287223e-05,
      "logits/chosen": -1.2082730531692505,
      "logits/rejected": -1.1367528438568115,
      "logps/chosen": -168.9225311279297,
      "logps/rejected": -166.7891082763672,
      "loss": 0.3917,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.349268913269043,
      "rewards/margins": 1.9871746301651,
      "rewards/rejected": -3.3364434242248535,
      "step": 7030
    },
    {
      "epoch": 1.2847887580983666,
      "grad_norm": 5.569680213928223,
      "learning_rate": 4.6186529133664884e-05,
      "logits/chosen": -1.2544444799423218,
      "logits/rejected": -1.1638697385787964,
      "logps/chosen": -152.71348571777344,
      "logps/rejected": -151.03253173828125,
      "loss": 0.47,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.2253657579421997,
      "rewards/margins": 1.638106107711792,
      "rewards/rejected": -2.8634719848632812,
      "step": 7040
    },
    {
      "epoch": 1.2866137421297563,
      "grad_norm": 4.350203037261963,
      "learning_rate": 4.613741020445755e-05,
      "logits/chosen": -1.3017183542251587,
      "logits/rejected": -1.1740597486495972,
      "logps/chosen": -186.12942504882812,
      "logps/rejected": -158.7583770751953,
      "loss": 0.4326,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.135657548904419,
      "rewards/margins": 1.738680124282837,
      "rewards/rejected": -2.874337911605835,
      "step": 7050
    },
    {
      "epoch": 1.288438726161146,
      "grad_norm": 7.2509002685546875,
      "learning_rate": 4.6088291275250206e-05,
      "logits/chosen": -1.2508938312530518,
      "logits/rejected": -1.1964912414550781,
      "logps/chosen": -167.3972625732422,
      "logps/rejected": -157.28575134277344,
      "loss": 0.6185,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.9733072519302368,
      "rewards/margins": 0.950118899345398,
      "rewards/rejected": -2.9234261512756348,
      "step": 7060
    },
    {
      "epoch": 1.2902637101925358,
      "grad_norm": 3.8367702960968018,
      "learning_rate": 4.603917234604286e-05,
      "logits/chosen": -1.18330979347229,
      "logits/rejected": -1.1270755529403687,
      "logps/chosen": -159.3534698486328,
      "logps/rejected": -159.56927490234375,
      "loss": 0.4389,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.763292670249939,
      "rewards/margins": 1.3806560039520264,
      "rewards/rejected": -3.1439483165740967,
      "step": 7070
    },
    {
      "epoch": 1.2920886942239256,
      "grad_norm": 6.838681221008301,
      "learning_rate": 4.599005341683552e-05,
      "logits/chosen": -1.2295501232147217,
      "logits/rejected": -1.1378382444381714,
      "logps/chosen": -163.49615478515625,
      "logps/rejected": -149.27505493164062,
      "loss": 0.5077,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.075784206390381,
      "rewards/margins": 1.2553330659866333,
      "rewards/rejected": -3.3311169147491455,
      "step": 7080
    },
    {
      "epoch": 1.2939136782553153,
      "grad_norm": 2.7685418128967285,
      "learning_rate": 4.594093448762817e-05,
      "logits/chosen": -1.212195634841919,
      "logits/rejected": -1.1871988773345947,
      "logps/chosen": -152.16200256347656,
      "logps/rejected": -158.73959350585938,
      "loss": 0.4435,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.5193419456481934,
      "rewards/margins": 1.278702974319458,
      "rewards/rejected": -3.7980446815490723,
      "step": 7090
    },
    {
      "epoch": 1.295738662286705,
      "grad_norm": 3.484686851501465,
      "learning_rate": 4.589181555842083e-05,
      "logits/chosen": -1.2707164287567139,
      "logits/rejected": -1.1510285139083862,
      "logps/chosen": -182.18576049804688,
      "logps/rejected": -163.35020446777344,
      "loss": 0.3351,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.3981621265411377,
      "rewards/margins": 1.5942867994308472,
      "rewards/rejected": -3.9924488067626953,
      "step": 7100
    },
    {
      "epoch": 1.2975636463180948,
      "grad_norm": 2.3073694705963135,
      "learning_rate": 4.584269662921348e-05,
      "logits/chosen": -1.2861301898956299,
      "logits/rejected": -1.2030363082885742,
      "logps/chosen": -206.2432403564453,
      "logps/rejected": -180.70584106445312,
      "loss": 0.4376,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.329491138458252,
      "rewards/margins": 1.622070074081421,
      "rewards/rejected": -3.951561450958252,
      "step": 7110
    },
    {
      "epoch": 1.2993886303494844,
      "grad_norm": 1.7505109310150146,
      "learning_rate": 4.5793577700006146e-05,
      "logits/chosen": -1.2762523889541626,
      "logits/rejected": -1.2083313465118408,
      "logps/chosen": -179.74874877929688,
      "logps/rejected": -183.64846801757812,
      "loss": 0.4595,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9891624450683594,
      "rewards/margins": 1.3645159006118774,
      "rewards/rejected": -3.3536782264709473,
      "step": 7120
    },
    {
      "epoch": 1.3012136143808741,
      "grad_norm": 1.3725781440734863,
      "learning_rate": 4.5744458770798804e-05,
      "logits/chosen": -1.3117424249649048,
      "logits/rejected": -1.2021234035491943,
      "logps/chosen": -168.09115600585938,
      "logps/rejected": -164.10739135742188,
      "loss": 0.2561,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.7020072937011719,
      "rewards/margins": 2.267000675201416,
      "rewards/rejected": -3.969007968902588,
      "step": 7130
    },
    {
      "epoch": 1.3030385984122639,
      "grad_norm": 2.7408933639526367,
      "learning_rate": 4.5695339841591455e-05,
      "logits/chosen": -1.3463246822357178,
      "logits/rejected": -1.2896935939788818,
      "logps/chosen": -169.05795288085938,
      "logps/rejected": -165.98666381835938,
      "loss": 0.4799,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.032008409500122,
      "rewards/margins": 1.6266225576400757,
      "rewards/rejected": -3.6586315631866455,
      "step": 7140
    },
    {
      "epoch": 1.3048635824436536,
      "grad_norm": 4.8010993003845215,
      "learning_rate": 4.564622091238411e-05,
      "logits/chosen": -1.4056047201156616,
      "logits/rejected": -1.3419545888900757,
      "logps/chosen": -160.8086700439453,
      "logps/rejected": -155.1620635986328,
      "loss": 0.5108,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.28085458278656,
      "rewards/margins": 1.407804250717163,
      "rewards/rejected": -2.688659191131592,
      "step": 7150
    },
    {
      "epoch": 1.3066885664750434,
      "grad_norm": 6.384032249450684,
      "learning_rate": 4.559710198317677e-05,
      "logits/chosen": -1.3861587047576904,
      "logits/rejected": -1.3073114156723022,
      "logps/chosen": -161.877197265625,
      "logps/rejected": -172.37680053710938,
      "loss": 0.4231,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8954302668571472,
      "rewards/margins": 2.0796189308166504,
      "rewards/rejected": -2.9750490188598633,
      "step": 7160
    },
    {
      "epoch": 1.3085135505064331,
      "grad_norm": 4.961359977722168,
      "learning_rate": 4.554798305396943e-05,
      "logits/chosen": -1.4005497694015503,
      "logits/rejected": -1.3580245971679688,
      "logps/chosen": -153.27438354492188,
      "logps/rejected": -154.04959106445312,
      "loss": 0.4816,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9109929203987122,
      "rewards/margins": 1.6633714437484741,
      "rewards/rejected": -2.574364423751831,
      "step": 7170
    },
    {
      "epoch": 1.3103385345378227,
      "grad_norm": 3.6274254322052,
      "learning_rate": 4.549886412476208e-05,
      "logits/chosen": -1.3823140859603882,
      "logits/rejected": -1.3514007329940796,
      "logps/chosen": -152.45770263671875,
      "logps/rejected": -164.57406616210938,
      "loss": 0.5049,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2260775566101074,
      "rewards/margins": 1.3666706085205078,
      "rewards/rejected": -2.592747926712036,
      "step": 7180
    },
    {
      "epoch": 1.3121635185692124,
      "grad_norm": 3.685990333557129,
      "learning_rate": 4.544974519555474e-05,
      "logits/chosen": -1.4043253660202026,
      "logits/rejected": -1.347150444984436,
      "logps/chosen": -148.51100158691406,
      "logps/rejected": -144.73912048339844,
      "loss": 0.4081,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9249215126037598,
      "rewards/margins": 1.5859483480453491,
      "rewards/rejected": -2.5108702182769775,
      "step": 7190
    },
    {
      "epoch": 1.3139885026006022,
      "grad_norm": 1.7878260612487793,
      "learning_rate": 4.54006262663474e-05,
      "logits/chosen": -1.3796827793121338,
      "logits/rejected": -1.301667332649231,
      "logps/chosen": -165.3581085205078,
      "logps/rejected": -153.66293334960938,
      "loss": 0.3581,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.7093715667724609,
      "rewards/margins": 1.8490171432495117,
      "rewards/rejected": -2.5583882331848145,
      "step": 7200
    },
    {
      "epoch": 1.315813486631992,
      "grad_norm": 4.693178653717041,
      "learning_rate": 4.535150733714005e-05,
      "logits/chosen": -1.3583500385284424,
      "logits/rejected": -1.3200716972351074,
      "logps/chosen": -164.02976989746094,
      "logps/rejected": -167.71292114257812,
      "loss": 0.3958,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.3755005598068237,
      "rewards/margins": 1.6197245121002197,
      "rewards/rejected": -2.995224714279175,
      "step": 7210
    },
    {
      "epoch": 1.3176384706633817,
      "grad_norm": 7.384282112121582,
      "learning_rate": 4.530238840793271e-05,
      "logits/chosen": -1.3810067176818848,
      "logits/rejected": -1.3103688955307007,
      "logps/chosen": -163.24058532714844,
      "logps/rejected": -169.557373046875,
      "loss": 0.4877,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.431311845779419,
      "rewards/margins": 1.781378149986267,
      "rewards/rejected": -3.2126898765563965,
      "step": 7220
    },
    {
      "epoch": 1.3194634546947714,
      "grad_norm": 1.946824073791504,
      "learning_rate": 4.525326947872537e-05,
      "logits/chosen": -1.3687913417816162,
      "logits/rejected": -1.3123199939727783,
      "logps/chosen": -163.12649536132812,
      "logps/rejected": -149.74545288085938,
      "loss": 0.4902,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.0971916913986206,
      "rewards/margins": 1.3707276582717896,
      "rewards/rejected": -2.46791934967041,
      "step": 7230
    },
    {
      "epoch": 1.3212884387261612,
      "grad_norm": 1.822755217552185,
      "learning_rate": 4.5204150549518025e-05,
      "logits/chosen": -1.3850055932998657,
      "logits/rejected": -1.3423805236816406,
      "logps/chosen": -151.72265625,
      "logps/rejected": -156.39700317382812,
      "loss": 0.3554,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8789035677909851,
      "rewards/margins": 1.7645689249038696,
      "rewards/rejected": -2.643472671508789,
      "step": 7240
    },
    {
      "epoch": 1.323113422757551,
      "grad_norm": 2.663214921951294,
      "learning_rate": 4.5155031620310676e-05,
      "logits/chosen": -1.371429681777954,
      "logits/rejected": -1.3273146152496338,
      "logps/chosen": -161.9831085205078,
      "logps/rejected": -158.744873046875,
      "loss": 0.5042,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.364432454109192,
      "rewards/margins": 1.2852189540863037,
      "rewards/rejected": -2.649651288986206,
      "step": 7250
    },
    {
      "epoch": 1.3249384067889407,
      "grad_norm": 1.5038554668426514,
      "learning_rate": 4.510591269110334e-05,
      "logits/chosen": -1.4212796688079834,
      "logits/rejected": -1.3612806797027588,
      "logps/chosen": -164.73171997070312,
      "logps/rejected": -152.7759246826172,
      "loss": 0.5667,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.3335175514221191,
      "rewards/margins": 1.142137885093689,
      "rewards/rejected": -2.4756555557250977,
      "step": 7260
    },
    {
      "epoch": 1.3267633908203305,
      "grad_norm": 2.7225301265716553,
      "learning_rate": 4.5056793761896e-05,
      "logits/chosen": -1.4110767841339111,
      "logits/rejected": -1.3512461185455322,
      "logps/chosen": -162.3787384033203,
      "logps/rejected": -157.17361450195312,
      "loss": 0.3491,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.6890175342559814,
      "rewards/margins": 1.543391466140747,
      "rewards/rejected": -2.2324090003967285,
      "step": 7270
    },
    {
      "epoch": 1.32858837485172,
      "grad_norm": 4.358626365661621,
      "learning_rate": 4.500767483268865e-05,
      "logits/chosen": -1.3840974569320679,
      "logits/rejected": -1.3307507038116455,
      "logps/chosen": -152.43096923828125,
      "logps/rejected": -139.1412811279297,
      "loss": 0.4735,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8489042520523071,
      "rewards/margins": 1.4315898418426514,
      "rewards/rejected": -2.280494213104248,
      "step": 7280
    },
    {
      "epoch": 1.3304133588831097,
      "grad_norm": 3.600324869155884,
      "learning_rate": 4.495855590348131e-05,
      "logits/chosen": -1.3852603435516357,
      "logits/rejected": -1.355454444885254,
      "logps/chosen": -162.37728881835938,
      "logps/rejected": -170.10824584960938,
      "loss": 0.533,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.0513336658477783,
      "rewards/margins": 1.4952019453048706,
      "rewards/rejected": -2.5465357303619385,
      "step": 7290
    },
    {
      "epoch": 1.3322383429144995,
      "grad_norm": 3.339045524597168,
      "learning_rate": 4.4909436974273965e-05,
      "logits/chosen": -1.401960849761963,
      "logits/rejected": -1.3432644605636597,
      "logps/chosen": -155.95741271972656,
      "logps/rejected": -141.826171875,
      "loss": 0.4219,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.8543709516525269,
      "rewards/margins": 1.5568777322769165,
      "rewards/rejected": -2.4112486839294434,
      "step": 7300
    },
    {
      "epoch": 1.3340633269458892,
      "grad_norm": 3.576664924621582,
      "learning_rate": 4.486031804506662e-05,
      "logits/chosen": -1.4026967287063599,
      "logits/rejected": -1.3623861074447632,
      "logps/chosen": -146.38922119140625,
      "logps/rejected": -150.31692504882812,
      "loss": 0.4175,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.48648181557655334,
      "rewards/margins": 1.595022439956665,
      "rewards/rejected": -2.0815043449401855,
      "step": 7310
    },
    {
      "epoch": 1.335888310977279,
      "grad_norm": 1.4836440086364746,
      "learning_rate": 4.481119911585927e-05,
      "logits/chosen": -1.3890717029571533,
      "logits/rejected": -1.3319480419158936,
      "logps/chosen": -146.07778930664062,
      "logps/rejected": -154.6152801513672,
      "loss": 0.4451,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9382575154304504,
      "rewards/margins": 1.6673452854156494,
      "rewards/rejected": -2.605602979660034,
      "step": 7320
    },
    {
      "epoch": 1.3377132950086688,
      "grad_norm": 4.172600269317627,
      "learning_rate": 4.476208018665193e-05,
      "logits/chosen": -1.4096686840057373,
      "logits/rejected": -1.355102300643921,
      "logps/chosen": -166.7737274169922,
      "logps/rejected": -155.8321990966797,
      "loss": 0.4687,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.6419650912284851,
      "rewards/margins": 1.7251453399658203,
      "rewards/rejected": -2.36711049079895,
      "step": 7330
    },
    {
      "epoch": 1.3395382790400583,
      "grad_norm": 3.0280075073242188,
      "learning_rate": 4.4712961257444596e-05,
      "logits/chosen": -1.3864465951919556,
      "logits/rejected": -1.3494889736175537,
      "logps/chosen": -145.30728149414062,
      "logps/rejected": -152.62106323242188,
      "loss": 0.4037,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.7324276566505432,
      "rewards/margins": 1.6067301034927368,
      "rewards/rejected": -2.339157819747925,
      "step": 7340
    },
    {
      "epoch": 1.341363263071448,
      "grad_norm": 5.023218154907227,
      "learning_rate": 4.4663842328237247e-05,
      "logits/chosen": -1.3759092092514038,
      "logits/rejected": -1.3068469762802124,
      "logps/chosen": -165.26123046875,
      "logps/rejected": -141.88427734375,
      "loss": 0.4221,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.4987776279449463,
      "rewards/margins": 1.4775272607803345,
      "rewards/rejected": -1.9763047695159912,
      "step": 7350
    },
    {
      "epoch": 1.3431882471028378,
      "grad_norm": 3.461193561553955,
      "learning_rate": 4.4614723399029904e-05,
      "logits/chosen": -1.378969430923462,
      "logits/rejected": -1.3144656419754028,
      "logps/chosen": -150.79263305664062,
      "logps/rejected": -147.01869201660156,
      "loss": 0.4055,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5677663683891296,
      "rewards/margins": 1.5265071392059326,
      "rewards/rejected": -2.094273328781128,
      "step": 7360
    },
    {
      "epoch": 1.3450132311342275,
      "grad_norm": 5.159322261810303,
      "learning_rate": 4.456560446982256e-05,
      "logits/chosen": -1.3931357860565186,
      "logits/rejected": -1.3474185466766357,
      "logps/chosen": -152.50750732421875,
      "logps/rejected": -145.5690460205078,
      "loss": 0.6066,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9768378138542175,
      "rewards/margins": 1.0184048414230347,
      "rewards/rejected": -1.995242714881897,
      "step": 7370
    },
    {
      "epoch": 1.3468382151656173,
      "grad_norm": 4.09559965133667,
      "learning_rate": 4.451648554061522e-05,
      "logits/chosen": -1.3274714946746826,
      "logits/rejected": -1.3058844804763794,
      "logps/chosen": -158.4474334716797,
      "logps/rejected": -167.0827178955078,
      "loss": 0.444,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6607402563095093,
      "rewards/margins": 1.4702202081680298,
      "rewards/rejected": -2.130960464477539,
      "step": 7380
    },
    {
      "epoch": 1.348663199197007,
      "grad_norm": 3.2190134525299072,
      "learning_rate": 4.446736661140787e-05,
      "logits/chosen": -1.3856486082077026,
      "logits/rejected": -1.3029934167861938,
      "logps/chosen": -140.16543579101562,
      "logps/rejected": -143.75772094726562,
      "loss": 0.4585,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5578156113624573,
      "rewards/margins": 1.4261963367462158,
      "rewards/rejected": -1.9840114116668701,
      "step": 7390
    },
    {
      "epoch": 1.3504881832283968,
      "grad_norm": 2.2570409774780273,
      "learning_rate": 4.441824768220053e-05,
      "logits/chosen": -1.343167781829834,
      "logits/rejected": -1.2790858745574951,
      "logps/chosen": -156.39645385742188,
      "logps/rejected": -144.01229858398438,
      "loss": 0.414,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.2891514003276825,
      "rewards/margins": 1.3791675567626953,
      "rewards/rejected": -1.6683189868927002,
      "step": 7400
    },
    {
      "epoch": 1.3523131672597866,
      "grad_norm": 3.6447904109954834,
      "learning_rate": 4.436912875299319e-05,
      "logits/chosen": -1.3512327671051025,
      "logits/rejected": -1.2965670824050903,
      "logps/chosen": -145.04864501953125,
      "logps/rejected": -143.1055145263672,
      "loss": 0.5271,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5292024612426758,
      "rewards/margins": 1.1694257259368896,
      "rewards/rejected": -1.6986281871795654,
      "step": 7410
    },
    {
      "epoch": 1.3541381512911763,
      "grad_norm": 3.0103611946105957,
      "learning_rate": 4.4320009823785844e-05,
      "logits/chosen": -1.3464734554290771,
      "logits/rejected": -1.2807320356369019,
      "logps/chosen": -144.3726043701172,
      "logps/rejected": -137.73764038085938,
      "loss": 0.4262,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.37738168239593506,
      "rewards/margins": 1.2546766996383667,
      "rewards/rejected": -1.6320585012435913,
      "step": 7420
    },
    {
      "epoch": 1.3559631353225658,
      "grad_norm": 4.527745723724365,
      "learning_rate": 4.42708908945785e-05,
      "logits/chosen": -1.3549538850784302,
      "logits/rejected": -1.2925444841384888,
      "logps/chosen": -161.56874084472656,
      "logps/rejected": -162.0340118408203,
      "loss": 0.5039,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7556971907615662,
      "rewards/margins": 1.2837241888046265,
      "rewards/rejected": -2.039421558380127,
      "step": 7430
    },
    {
      "epoch": 1.3577881193539556,
      "grad_norm": 3.6732659339904785,
      "learning_rate": 4.422177196537115e-05,
      "logits/chosen": -1.3341891765594482,
      "logits/rejected": -1.3039811849594116,
      "logps/chosen": -155.64236450195312,
      "logps/rejected": -147.96804809570312,
      "loss": 0.43,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.5351747870445251,
      "rewards/margins": 1.261025309562683,
      "rewards/rejected": -1.796200156211853,
      "step": 7440
    },
    {
      "epoch": 1.3596131033853454,
      "grad_norm": 5.101125240325928,
      "learning_rate": 4.417265303616382e-05,
      "logits/chosen": -1.3322983980178833,
      "logits/rejected": -1.262253999710083,
      "logps/chosen": -195.57374572753906,
      "logps/rejected": -163.78860473632812,
      "loss": 0.5595,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.42660242319107056,
      "rewards/margins": 0.9985078573226929,
      "rewards/rejected": -1.4251103401184082,
      "step": 7450
    },
    {
      "epoch": 1.361438087416735,
      "grad_norm": 2.850698471069336,
      "learning_rate": 4.4123534106956475e-05,
      "logits/chosen": -1.377885103225708,
      "logits/rejected": -1.301845669746399,
      "logps/chosen": -176.12513732910156,
      "logps/rejected": -129.9590606689453,
      "loss": 0.4862,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.4123624861240387,
      "rewards/margins": 1.085626482963562,
      "rewards/rejected": -1.4979889392852783,
      "step": 7460
    },
    {
      "epoch": 1.3632630714481249,
      "grad_norm": 2.3539059162139893,
      "learning_rate": 4.4074415177749126e-05,
      "logits/chosen": -1.2587850093841553,
      "logits/rejected": -1.2172316312789917,
      "logps/chosen": -155.00584411621094,
      "logps/rejected": -153.74331665039062,
      "loss": 0.3878,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.6208379864692688,
      "rewards/margins": 1.5524922609329224,
      "rewards/rejected": -2.173330307006836,
      "step": 7470
    },
    {
      "epoch": 1.3650880554795146,
      "grad_norm": 2.935598134994507,
      "learning_rate": 4.402529624854179e-05,
      "logits/chosen": -1.2349432706832886,
      "logits/rejected": -1.2208210229873657,
      "logps/chosen": -162.38333129882812,
      "logps/rejected": -172.12680053710938,
      "loss": 0.5069,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3295788764953613,
      "rewards/margins": 1.341139793395996,
      "rewards/rejected": -2.6707184314727783,
      "step": 7480
    },
    {
      "epoch": 1.3669130395109041,
      "grad_norm": 3.605659008026123,
      "learning_rate": 4.397617731933444e-05,
      "logits/chosen": -1.2804466485977173,
      "logits/rejected": -1.2416486740112305,
      "logps/chosen": -149.1936798095703,
      "logps/rejected": -157.53836059570312,
      "loss": 0.3599,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1853586435317993,
      "rewards/margins": 1.6280295848846436,
      "rewards/rejected": -2.8133883476257324,
      "step": 7490
    },
    {
      "epoch": 1.368738023542294,
      "grad_norm": 3.143723726272583,
      "learning_rate": 4.39270583901271e-05,
      "logits/chosen": -1.2997251749038696,
      "logits/rejected": -1.2461141347885132,
      "logps/chosen": -163.44447326660156,
      "logps/rejected": -160.89117431640625,
      "loss": 0.3703,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.166821837425232,
      "rewards/margins": 1.7963120937347412,
      "rewards/rejected": -2.963134288787842,
      "step": 7500
    },
    {
      "epoch": 1.3705630075736837,
      "grad_norm": 2.834437847137451,
      "learning_rate": 4.387793946091975e-05,
      "logits/chosen": -1.2808986902236938,
      "logits/rejected": -1.1989103555679321,
      "logps/chosen": -173.96531677246094,
      "logps/rejected": -153.01072692871094,
      "loss": 0.4978,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.683048963546753,
      "rewards/margins": 1.502482533454895,
      "rewards/rejected": -3.1855311393737793,
      "step": 7510
    },
    {
      "epoch": 1.3723879916050734,
      "grad_norm": 3.7060964107513428,
      "learning_rate": 4.3828820531712414e-05,
      "logits/chosen": -1.2832392454147339,
      "logits/rejected": -1.1918832063674927,
      "logps/chosen": -160.1608123779297,
      "logps/rejected": -134.489990234375,
      "loss": 0.3935,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.2601372003555298,
      "rewards/margins": 1.6314023733139038,
      "rewards/rejected": -2.8915393352508545,
      "step": 7520
    },
    {
      "epoch": 1.3742129756364632,
      "grad_norm": 3.032304286956787,
      "learning_rate": 4.377970160250507e-05,
      "logits/chosen": -1.268523097038269,
      "logits/rejected": -1.1780275106430054,
      "logps/chosen": -161.66357421875,
      "logps/rejected": -146.6003875732422,
      "loss": 0.5009,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1627352237701416,
      "rewards/margins": 1.425591230392456,
      "rewards/rejected": -2.5883266925811768,
      "step": 7530
    },
    {
      "epoch": 1.376037959667853,
      "grad_norm": 1.4137178659439087,
      "learning_rate": 4.373058267329772e-05,
      "logits/chosen": -1.3329532146453857,
      "logits/rejected": -1.2205218076705933,
      "logps/chosen": -164.90084838867188,
      "logps/rejected": -160.12661743164062,
      "loss": 0.3008,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.7034960985183716,
      "rewards/margins": 2.1311306953430176,
      "rewards/rejected": -2.8346266746520996,
      "step": 7540
    },
    {
      "epoch": 1.3778629436992427,
      "grad_norm": 3.181870460510254,
      "learning_rate": 4.368146374409039e-05,
      "logits/chosen": -1.3251398801803589,
      "logits/rejected": -1.2048717737197876,
      "logps/chosen": -178.05349731445312,
      "logps/rejected": -159.13165283203125,
      "loss": 0.4188,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4639028310775757,
      "rewards/margins": 1.7889763116836548,
      "rewards/rejected": -3.2528789043426514,
      "step": 7550
    },
    {
      "epoch": 1.3796879277306324,
      "grad_norm": 2.2487852573394775,
      "learning_rate": 4.363234481488304e-05,
      "logits/chosen": -1.2948744297027588,
      "logits/rejected": -1.2362192869186401,
      "logps/chosen": -161.416015625,
      "logps/rejected": -158.2966766357422,
      "loss": 0.3756,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.3642603158950806,
      "rewards/margins": 1.7075607776641846,
      "rewards/rejected": -3.0718209743499756,
      "step": 7560
    },
    {
      "epoch": 1.3815129117620222,
      "grad_norm": 4.433470726013184,
      "learning_rate": 4.3583225885675696e-05,
      "logits/chosen": -1.2652573585510254,
      "logits/rejected": -1.1993244886398315,
      "logps/chosen": -163.00717163085938,
      "logps/rejected": -158.3830108642578,
      "loss": 0.4375,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.880263328552246,
      "rewards/margins": 1.6911628246307373,
      "rewards/rejected": -3.5714263916015625,
      "step": 7570
    },
    {
      "epoch": 1.383337895793412,
      "grad_norm": 3.9346375465393066,
      "learning_rate": 4.353410695646835e-05,
      "logits/chosen": -1.3526893854141235,
      "logits/rejected": -1.292973518371582,
      "logps/chosen": -166.3011016845703,
      "logps/rejected": -159.79281616210938,
      "loss": 0.4062,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.1669658422470093,
      "rewards/margins": 1.8112571239471436,
      "rewards/rejected": -2.9782233238220215,
      "step": 7580
    },
    {
      "epoch": 1.3851628798248015,
      "grad_norm": 4.6903862953186035,
      "learning_rate": 4.348498802726101e-05,
      "logits/chosen": -1.277282953262329,
      "logits/rejected": -1.1940205097198486,
      "logps/chosen": -145.06277465820312,
      "logps/rejected": -147.3961181640625,
      "loss": 0.3644,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.069451093673706,
      "rewards/margins": 2.187156915664673,
      "rewards/rejected": -3.256608247756958,
      "step": 7590
    },
    {
      "epoch": 1.3869878638561912,
      "grad_norm": 3.7950754165649414,
      "learning_rate": 4.343586909805367e-05,
      "logits/chosen": -1.2600452899932861,
      "logits/rejected": -1.1982359886169434,
      "logps/chosen": -154.58200073242188,
      "logps/rejected": -157.20635986328125,
      "loss": 0.373,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.5005971193313599,
      "rewards/margins": 1.508873701095581,
      "rewards/rejected": -3.0094704627990723,
      "step": 7600
    },
    {
      "epoch": 1.388812847887581,
      "grad_norm": 6.313040733337402,
      "learning_rate": 4.338675016884632e-05,
      "logits/chosen": -1.3000813722610474,
      "logits/rejected": -1.2188104391098022,
      "logps/chosen": -170.1742706298828,
      "logps/rejected": -151.36160278320312,
      "loss": 0.4252,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9753811955451965,
      "rewards/margins": 1.6265039443969727,
      "rewards/rejected": -2.6018853187561035,
      "step": 7610
    },
    {
      "epoch": 1.3906378319189707,
      "grad_norm": 3.3322741985321045,
      "learning_rate": 4.333763123963898e-05,
      "logits/chosen": -1.2746105194091797,
      "logits/rejected": -1.2140014171600342,
      "logps/chosen": -163.75018310546875,
      "logps/rejected": -168.144775390625,
      "loss": 0.3911,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0088132619857788,
      "rewards/margins": 1.881110429763794,
      "rewards/rejected": -2.889923572540283,
      "step": 7620
    },
    {
      "epoch": 1.3924628159503605,
      "grad_norm": 2.6314384937286377,
      "learning_rate": 4.3288512310431636e-05,
      "logits/chosen": -1.2716588973999023,
      "logits/rejected": -1.1424508094787598,
      "logps/chosen": -175.59432983398438,
      "logps/rejected": -155.9623260498047,
      "loss": 0.3667,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9901100993156433,
      "rewards/margins": 2.0431084632873535,
      "rewards/rejected": -3.0332186222076416,
      "step": 7630
    },
    {
      "epoch": 1.3942877999817502,
      "grad_norm": 2.632749557495117,
      "learning_rate": 4.3239393381224294e-05,
      "logits/chosen": -1.2547494173049927,
      "logits/rejected": -1.2220220565795898,
      "logps/chosen": -162.13528442382812,
      "logps/rejected": -154.3505859375,
      "loss": 0.4715,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5044840574264526,
      "rewards/margins": 1.17815101146698,
      "rewards/rejected": -2.6826348304748535,
      "step": 7640
    },
    {
      "epoch": 1.3961127840131398,
      "grad_norm": 4.451566219329834,
      "learning_rate": 4.3190274452016945e-05,
      "logits/chosen": -1.2586867809295654,
      "logits/rejected": -1.1937516927719116,
      "logps/chosen": -157.66543579101562,
      "logps/rejected": -147.2900390625,
      "loss": 0.5058,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4728868007659912,
      "rewards/margins": 1.4038647413253784,
      "rewards/rejected": -2.876751661300659,
      "step": 7650
    },
    {
      "epoch": 1.3979377680445295,
      "grad_norm": 3.9031834602355957,
      "learning_rate": 4.314115552280961e-05,
      "logits/chosen": -1.333427906036377,
      "logits/rejected": -1.2944672107696533,
      "logps/chosen": -159.97219848632812,
      "logps/rejected": -165.32681274414062,
      "loss": 0.4518,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.1134138107299805,
      "rewards/margins": 1.676452398300171,
      "rewards/rejected": -2.7898662090301514,
      "step": 7660
    },
    {
      "epoch": 1.3997627520759193,
      "grad_norm": 6.411545276641846,
      "learning_rate": 4.309203659360227e-05,
      "logits/chosen": -1.3396307229995728,
      "logits/rejected": -1.2530454397201538,
      "logps/chosen": -143.44998168945312,
      "logps/rejected": -135.0241241455078,
      "loss": 0.4338,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9454314112663269,
      "rewards/margins": 1.4206020832061768,
      "rewards/rejected": -2.3660335540771484,
      "step": 7670
    },
    {
      "epoch": 1.401587736107309,
      "grad_norm": 3.1221182346343994,
      "learning_rate": 4.304291766439492e-05,
      "logits/chosen": -1.3065052032470703,
      "logits/rejected": -1.2176711559295654,
      "logps/chosen": -182.11355590820312,
      "logps/rejected": -169.65805053710938,
      "loss": 0.3256,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.9029677510261536,
      "rewards/margins": 2.060356378555298,
      "rewards/rejected": -2.9633238315582275,
      "step": 7680
    },
    {
      "epoch": 1.4034127201386988,
      "grad_norm": 5.443527698516846,
      "learning_rate": 4.2993798735187576e-05,
      "logits/chosen": -1.3100223541259766,
      "logits/rejected": -1.2752487659454346,
      "logps/chosen": -139.1311798095703,
      "logps/rejected": -153.14324951171875,
      "loss": 0.4087,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2829095125198364,
      "rewards/margins": 1.6650152206420898,
      "rewards/rejected": -2.947924852371216,
      "step": 7690
    },
    {
      "epoch": 1.4052377041700885,
      "grad_norm": 5.745696544647217,
      "learning_rate": 4.294467980598023e-05,
      "logits/chosen": -1.3219319581985474,
      "logits/rejected": -1.2689602375030518,
      "logps/chosen": -154.1855010986328,
      "logps/rejected": -147.47787475585938,
      "loss": 0.4385,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.6070772409439087,
      "rewards/margins": 1.4975305795669556,
      "rewards/rejected": -3.1046078205108643,
      "step": 7700
    },
    {
      "epoch": 1.4070626882014783,
      "grad_norm": 4.166339874267578,
      "learning_rate": 4.289556087677289e-05,
      "logits/chosen": -1.2989856004714966,
      "logits/rejected": -1.2620301246643066,
      "logps/chosen": -159.39498901367188,
      "logps/rejected": -183.6446075439453,
      "loss": 0.4418,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6209986209869385,
      "rewards/margins": 1.7900140285491943,
      "rewards/rejected": -3.411012649536133,
      "step": 7710
    },
    {
      "epoch": 1.408887672232868,
      "grad_norm": 6.201779842376709,
      "learning_rate": 4.284644194756554e-05,
      "logits/chosen": -1.3600120544433594,
      "logits/rejected": -1.3117190599441528,
      "logps/chosen": -161.33741760253906,
      "logps/rejected": -171.21009826660156,
      "loss": 0.4831,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7260792255401611,
      "rewards/margins": 1.6190344095230103,
      "rewards/rejected": -3.345113754272461,
      "step": 7720
    },
    {
      "epoch": 1.4107126562642578,
      "grad_norm": 5.68687105178833,
      "learning_rate": 4.27973230183582e-05,
      "logits/chosen": -1.3541680574417114,
      "logits/rejected": -1.2436866760253906,
      "logps/chosen": -176.14132690429688,
      "logps/rejected": -150.0504150390625,
      "loss": 0.4305,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.9960254430770874,
      "rewards/margins": 1.503844976425171,
      "rewards/rejected": -3.4998703002929688,
      "step": 7730
    },
    {
      "epoch": 1.4125376402956475,
      "grad_norm": 4.121723175048828,
      "learning_rate": 4.2748204089150864e-05,
      "logits/chosen": -1.3572518825531006,
      "logits/rejected": -1.2927826642990112,
      "logps/chosen": -165.40835571289062,
      "logps/rejected": -164.38229370117188,
      "loss": 0.4101,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7851498126983643,
      "rewards/margins": 1.6570920944213867,
      "rewards/rejected": -3.442242383956909,
      "step": 7740
    },
    {
      "epoch": 1.414362624327037,
      "grad_norm": 2.709617853164673,
      "learning_rate": 4.2699085159943515e-05,
      "logits/chosen": -1.3221718072891235,
      "logits/rejected": -1.2764170169830322,
      "logps/chosen": -153.6486358642578,
      "logps/rejected": -163.13580322265625,
      "loss": 0.3254,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8703502416610718,
      "rewards/margins": 1.7264957427978516,
      "rewards/rejected": -3.596846103668213,
      "step": 7750
    },
    {
      "epoch": 1.4161876083584268,
      "grad_norm": 4.418054580688477,
      "learning_rate": 4.264996623073617e-05,
      "logits/chosen": -1.2861506938934326,
      "logits/rejected": -1.1869885921478271,
      "logps/chosen": -161.66363525390625,
      "logps/rejected": -157.46302795410156,
      "loss": 0.4352,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.4381706714630127,
      "rewards/margins": 1.6200557947158813,
      "rewards/rejected": -4.058226585388184,
      "step": 7760
    },
    {
      "epoch": 1.4180125923898166,
      "grad_norm": 6.8925323486328125,
      "learning_rate": 4.260084730152883e-05,
      "logits/chosen": -1.2672429084777832,
      "logits/rejected": -1.1789815425872803,
      "logps/chosen": -167.6819305419922,
      "logps/rejected": -176.9065704345703,
      "loss": 0.4008,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.560906410217285,
      "rewards/margins": 2.1397910118103027,
      "rewards/rejected": -4.700697422027588,
      "step": 7770
    },
    {
      "epoch": 1.4198375764212063,
      "grad_norm": 3.253741502761841,
      "learning_rate": 4.255172837232149e-05,
      "logits/chosen": -1.2811882495880127,
      "logits/rejected": -1.2255679368972778,
      "logps/chosen": -163.66236877441406,
      "logps/rejected": -169.45553588867188,
      "loss": 0.4492,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.2740819454193115,
      "rewards/margins": 1.6145737171173096,
      "rewards/rejected": -3.8886559009552,
      "step": 7780
    },
    {
      "epoch": 1.421662560452596,
      "grad_norm": 6.422773838043213,
      "learning_rate": 4.250260944311414e-05,
      "logits/chosen": -1.2778713703155518,
      "logits/rejected": -1.2140969038009644,
      "logps/chosen": -167.43881225585938,
      "logps/rejected": -178.4099884033203,
      "loss": 0.5077,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.134381055831909,
      "rewards/margins": 1.4131511449813843,
      "rewards/rejected": -3.547531843185425,
      "step": 7790
    },
    {
      "epoch": 1.4234875444839858,
      "grad_norm": 5.723570823669434,
      "learning_rate": 4.24534905139068e-05,
      "logits/chosen": -1.3226748704910278,
      "logits/rejected": -1.2187154293060303,
      "logps/chosen": -184.25234985351562,
      "logps/rejected": -158.61715698242188,
      "loss": 0.4208,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5226085186004639,
      "rewards/margins": 1.9175491333007812,
      "rewards/rejected": -3.440157651901245,
      "step": 7800
    },
    {
      "epoch": 1.4253125285153754,
      "grad_norm": 3.830296277999878,
      "learning_rate": 4.240437158469946e-05,
      "logits/chosen": -1.3145166635513306,
      "logits/rejected": -1.2266314029693604,
      "logps/chosen": -175.53146362304688,
      "logps/rejected": -166.224853515625,
      "loss": 0.4657,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8864717483520508,
      "rewards/margins": 1.7461073398590088,
      "rewards/rejected": -3.6325793266296387,
      "step": 7810
    },
    {
      "epoch": 1.4271375125467651,
      "grad_norm": 3.762756109237671,
      "learning_rate": 4.235525265549211e-05,
      "logits/chosen": -1.2957412004470825,
      "logits/rejected": -1.1978367567062378,
      "logps/chosen": -183.67555236816406,
      "logps/rejected": -173.47079467773438,
      "loss": 0.3485,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.019711494445801,
      "rewards/margins": 1.8268944025039673,
      "rewards/rejected": -3.8466060161590576,
      "step": 7820
    },
    {
      "epoch": 1.4289624965781549,
      "grad_norm": 4.448051452636719,
      "learning_rate": 4.230613372628477e-05,
      "logits/chosen": -1.2827086448669434,
      "logits/rejected": -1.2134857177734375,
      "logps/chosen": -151.99574279785156,
      "logps/rejected": -156.72637939453125,
      "loss": 0.433,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9435374736785889,
      "rewards/margins": 1.6416594982147217,
      "rewards/rejected": -3.5851969718933105,
      "step": 7830
    },
    {
      "epoch": 1.4307874806095446,
      "grad_norm": 2.0154595375061035,
      "learning_rate": 4.2257014797077435e-05,
      "logits/chosen": -1.3299365043640137,
      "logits/rejected": -1.2707864046096802,
      "logps/chosen": -160.48886108398438,
      "logps/rejected": -171.5950469970703,
      "loss": 0.3989,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.9291505813598633,
      "rewards/margins": 1.6895160675048828,
      "rewards/rejected": -3.618666887283325,
      "step": 7840
    },
    {
      "epoch": 1.4326124646409344,
      "grad_norm": 6.262078762054443,
      "learning_rate": 4.2207895867870086e-05,
      "logits/chosen": -1.262615442276001,
      "logits/rejected": -1.2214405536651611,
      "logps/chosen": -150.49874877929688,
      "logps/rejected": -161.16912841796875,
      "loss": 0.5634,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.109616756439209,
      "rewards/margins": 1.2065802812576294,
      "rewards/rejected": -3.316196918487549,
      "step": 7850
    },
    {
      "epoch": 1.4344374486723241,
      "grad_norm": 6.162620544433594,
      "learning_rate": 4.215877693866274e-05,
      "logits/chosen": -1.2772605419158936,
      "logits/rejected": -1.1990360021591187,
      "logps/chosen": -162.24887084960938,
      "logps/rejected": -153.31539916992188,
      "loss": 0.433,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.8905935287475586,
      "rewards/margins": 1.6319891214370728,
      "rewards/rejected": -3.522582530975342,
      "step": 7860
    },
    {
      "epoch": 1.436262432703714,
      "grad_norm": 4.983808517456055,
      "learning_rate": 4.2109658009455394e-05,
      "logits/chosen": -1.2744221687316895,
      "logits/rejected": -1.2189706563949585,
      "logps/chosen": -175.19381713867188,
      "logps/rejected": -179.86798095703125,
      "loss": 0.5344,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.225262403488159,
      "rewards/margins": 1.5044453144073486,
      "rewards/rejected": -3.729708194732666,
      "step": 7870
    },
    {
      "epoch": 1.4380874167351037,
      "grad_norm": 2.591658115386963,
      "learning_rate": 4.206053908024806e-05,
      "logits/chosen": -1.2896817922592163,
      "logits/rejected": -1.2369247674942017,
      "logps/chosen": -160.86862182617188,
      "logps/rejected": -154.43692016601562,
      "loss": 0.4034,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.076657772064209,
      "rewards/margins": 1.6087939739227295,
      "rewards/rejected": -3.6854519844055176,
      "step": 7880
    },
    {
      "epoch": 1.4399124007664934,
      "grad_norm": 6.280391693115234,
      "learning_rate": 4.201142015104071e-05,
      "logits/chosen": -1.3186708688735962,
      "logits/rejected": -1.2651407718658447,
      "logps/chosen": -158.6949462890625,
      "logps/rejected": -169.4934539794922,
      "loss": 0.3515,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8438045978546143,
      "rewards/margins": 1.8198515176773071,
      "rewards/rejected": -3.663656234741211,
      "step": 7890
    },
    {
      "epoch": 1.441737384797883,
      "grad_norm": 3.6983635425567627,
      "learning_rate": 4.196230122183337e-05,
      "logits/chosen": -1.3794810771942139,
      "logits/rejected": -1.3122477531433105,
      "logps/chosen": -166.4611358642578,
      "logps/rejected": -156.3273162841797,
      "loss": 0.4424,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.0881528854370117,
      "rewards/margins": 1.530639886856079,
      "rewards/rejected": -3.61879301071167,
      "step": 7900
    },
    {
      "epoch": 1.4435623688292727,
      "grad_norm": 2.674180746078491,
      "learning_rate": 4.191318229262602e-05,
      "logits/chosen": -1.2936439514160156,
      "logits/rejected": -1.2130842208862305,
      "logps/chosen": -152.79678344726562,
      "logps/rejected": -155.48284912109375,
      "loss": 0.3573,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.848146677017212,
      "rewards/margins": 1.7326538562774658,
      "rewards/rejected": -3.5808005332946777,
      "step": 7910
    },
    {
      "epoch": 1.4453873528606624,
      "grad_norm": 1.8406672477722168,
      "learning_rate": 4.186406336341868e-05,
      "logits/chosen": -1.3394660949707031,
      "logits/rejected": -1.2789585590362549,
      "logps/chosen": -173.35784912109375,
      "logps/rejected": -161.02328491210938,
      "loss": 0.3986,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.1994410753250122,
      "rewards/margins": 1.6254791021347046,
      "rewards/rejected": -2.8249194622039795,
      "step": 7920
    },
    {
      "epoch": 1.4472123368920522,
      "grad_norm": 3.170398473739624,
      "learning_rate": 4.181494443421134e-05,
      "logits/chosen": -1.3351894617080688,
      "logits/rejected": -1.2641929388046265,
      "logps/chosen": -174.0556182861328,
      "logps/rejected": -143.20425415039062,
      "loss": 0.4828,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.7126662731170654,
      "rewards/margins": 1.1688059568405151,
      "rewards/rejected": -2.881472110748291,
      "step": 7930
    },
    {
      "epoch": 1.449037320923442,
      "grad_norm": 4.444561004638672,
      "learning_rate": 4.176582550500399e-05,
      "logits/chosen": -1.3114091157913208,
      "logits/rejected": -1.2972853183746338,
      "logps/chosen": -149.7397918701172,
      "logps/rejected": -172.1060333251953,
      "loss": 0.343,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.1439534425735474,
      "rewards/margins": 2.1435647010803223,
      "rewards/rejected": -3.28751802444458,
      "step": 7940
    },
    {
      "epoch": 1.4508623049548317,
      "grad_norm": 4.367986679077148,
      "learning_rate": 4.1716706575796656e-05,
      "logits/chosen": -1.3857717514038086,
      "logits/rejected": -1.3367578983306885,
      "logps/chosen": -178.37771606445312,
      "logps/rejected": -177.7492218017578,
      "loss": 0.5562,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2577322721481323,
      "rewards/margins": 1.5840009450912476,
      "rewards/rejected": -2.84173321723938,
      "step": 7950
    },
    {
      "epoch": 1.4526872889862212,
      "grad_norm": 5.428968906402588,
      "learning_rate": 4.166758764658931e-05,
      "logits/chosen": -1.4023051261901855,
      "logits/rejected": -1.3177157640457153,
      "logps/chosen": -154.9010772705078,
      "logps/rejected": -149.32205200195312,
      "loss": 0.4382,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.9883052706718445,
      "rewards/margins": 1.7899996042251587,
      "rewards/rejected": -2.7783048152923584,
      "step": 7960
    },
    {
      "epoch": 1.454512273017611,
      "grad_norm": 2.607750177383423,
      "learning_rate": 4.1618468717381965e-05,
      "logits/chosen": -1.3876299858093262,
      "logits/rejected": -1.3038785457611084,
      "logps/chosen": -169.06607055664062,
      "logps/rejected": -154.73837280273438,
      "loss": 0.4792,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.3588216304779053,
      "rewards/margins": 1.5273514986038208,
      "rewards/rejected": -2.8861732482910156,
      "step": 7970
    },
    {
      "epoch": 1.4563372570490007,
      "grad_norm": 4.801614284515381,
      "learning_rate": 4.1569349788174616e-05,
      "logits/chosen": -1.3377892971038818,
      "logits/rejected": -1.2944225072860718,
      "logps/chosen": -154.40829467773438,
      "logps/rejected": -163.97450256347656,
      "loss": 0.5019,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5668106079101562,
      "rewards/margins": 1.4128592014312744,
      "rewards/rejected": -2.9796700477600098,
      "step": 7980
    },
    {
      "epoch": 1.4581622410803905,
      "grad_norm": 3.6123876571655273,
      "learning_rate": 4.152023085896728e-05,
      "logits/chosen": -1.3507786989212036,
      "logits/rejected": -1.315996766090393,
      "logps/chosen": -146.24453735351562,
      "logps/rejected": -153.89022827148438,
      "loss": 0.4162,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.2106651067733765,
      "rewards/margins": 1.6781871318817139,
      "rewards/rejected": -2.88885235786438,
      "step": 7990
    },
    {
      "epoch": 1.4599872251117803,
      "grad_norm": 2.316248655319214,
      "learning_rate": 4.147111192975994e-05,
      "logits/chosen": -1.3072525262832642,
      "logits/rejected": -1.2653661966323853,
      "logps/chosen": -143.68008422851562,
      "logps/rejected": -169.99349975585938,
      "loss": 0.4289,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5728200674057007,
      "rewards/margins": 1.5811173915863037,
      "rewards/rejected": -3.153937339782715,
      "step": 8000
    },
    {
      "epoch": 1.46181220914317,
      "grad_norm": 4.103718280792236,
      "learning_rate": 4.142199300055259e-05,
      "logits/chosen": -1.3536514043807983,
      "logits/rejected": -1.2763926982879639,
      "logps/chosen": -159.66213989257812,
      "logps/rejected": -146.5570068359375,
      "loss": 0.4491,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6170225143432617,
      "rewards/margins": 1.6337597370147705,
      "rewards/rejected": -3.2507824897766113,
      "step": 8010
    },
    {
      "epoch": 1.4636371931745598,
      "grad_norm": 6.070542335510254,
      "learning_rate": 4.137287407134525e-05,
      "logits/chosen": -1.3449448347091675,
      "logits/rejected": -1.3019747734069824,
      "logps/chosen": -153.19566345214844,
      "logps/rejected": -152.75274658203125,
      "loss": 0.4379,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.132315754890442,
      "rewards/margins": 1.559570074081421,
      "rewards/rejected": -2.6918859481811523,
      "step": 8020
    },
    {
      "epoch": 1.4654621772059495,
      "grad_norm": 3.461925983428955,
      "learning_rate": 4.1323755142137905e-05,
      "logits/chosen": -1.3183952569961548,
      "logits/rejected": -1.2572449445724487,
      "logps/chosen": -161.39013671875,
      "logps/rejected": -155.322509765625,
      "loss": 0.4715,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.2766945362091064,
      "rewards/margins": 1.6266504526138306,
      "rewards/rejected": -2.9033451080322266,
      "step": 8030
    },
    {
      "epoch": 1.4672871612373393,
      "grad_norm": 4.678431510925293,
      "learning_rate": 4.127463621293056e-05,
      "logits/chosen": -1.2677996158599854,
      "logits/rejected": -1.2307249307632446,
      "logps/chosen": -140.93995666503906,
      "logps/rejected": -148.7353973388672,
      "loss": 0.5151,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1204009056091309,
      "rewards/margins": 1.3301700353622437,
      "rewards/rejected": -2.450571298599243,
      "step": 8040
    },
    {
      "epoch": 1.469112145268729,
      "grad_norm": 3.8301806449890137,
      "learning_rate": 4.122551728372321e-05,
      "logits/chosen": -1.227471947669983,
      "logits/rejected": -1.2263129949569702,
      "logps/chosen": -131.6222381591797,
      "logps/rejected": -164.68093872070312,
      "loss": 0.4925,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.2649219036102295,
      "rewards/margins": 1.191381573677063,
      "rewards/rejected": -2.456303596496582,
      "step": 8050
    },
    {
      "epoch": 1.4709371293001186,
      "grad_norm": 1.6472923755645752,
      "learning_rate": 4.117639835451588e-05,
      "logits/chosen": -1.2445451021194458,
      "logits/rejected": -1.1922006607055664,
      "logps/chosen": -151.71133422851562,
      "logps/rejected": -155.80465698242188,
      "loss": 0.478,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4672319889068604,
      "rewards/margins": 1.1352307796478271,
      "rewards/rejected": -2.6024627685546875,
      "step": 8060
    },
    {
      "epoch": 1.4727621133315083,
      "grad_norm": 2.72646427154541,
      "learning_rate": 4.1127279425308535e-05,
      "logits/chosen": -1.236473798751831,
      "logits/rejected": -1.16568922996521,
      "logps/chosen": -156.7179718017578,
      "logps/rejected": -145.91744995117188,
      "loss": 0.3568,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.7327606081962585,
      "rewards/margins": 1.5287833213806152,
      "rewards/rejected": -2.2615439891815186,
      "step": 8070
    },
    {
      "epoch": 1.474587097362898,
      "grad_norm": 2.5359535217285156,
      "learning_rate": 4.1078160496101186e-05,
      "logits/chosen": -1.271327257156372,
      "logits/rejected": -1.2397466897964478,
      "logps/chosen": -151.05897521972656,
      "logps/rejected": -161.27719116210938,
      "loss": 0.471,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.013543963432312,
      "rewards/margins": 1.3717299699783325,
      "rewards/rejected": -2.3852739334106445,
      "step": 8080
    },
    {
      "epoch": 1.4764120813942878,
      "grad_norm": 3.9465572834014893,
      "learning_rate": 4.1029041566893844e-05,
      "logits/chosen": -1.2703375816345215,
      "logits/rejected": -1.1989275217056274,
      "logps/chosen": -174.2078399658203,
      "logps/rejected": -149.36688232421875,
      "loss": 0.4245,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8451454043388367,
      "rewards/margins": 1.3410099744796753,
      "rewards/rejected": -2.186155319213867,
      "step": 8090
    },
    {
      "epoch": 1.4782370654256776,
      "grad_norm": 3.8895950317382812,
      "learning_rate": 4.09799226376865e-05,
      "logits/chosen": -1.2309706211090088,
      "logits/rejected": -1.1631138324737549,
      "logps/chosen": -141.3059844970703,
      "logps/rejected": -150.73361206054688,
      "loss": 0.4248,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8506677746772766,
      "rewards/margins": 1.4802640676498413,
      "rewards/rejected": -2.330932140350342,
      "step": 8100
    },
    {
      "epoch": 1.4800620494570673,
      "grad_norm": 4.3471550941467285,
      "learning_rate": 4.093080370847916e-05,
      "logits/chosen": -1.2861963510513306,
      "logits/rejected": -1.140053153038025,
      "logps/chosen": -176.41729736328125,
      "logps/rejected": -159.8927459716797,
      "loss": 0.333,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.0067135095596313,
      "rewards/margins": 1.811438798904419,
      "rewards/rejected": -2.8181521892547607,
      "step": 8110
    },
    {
      "epoch": 1.4818870334884569,
      "grad_norm": 3.2337284088134766,
      "learning_rate": 4.088168477927181e-05,
      "logits/chosen": -1.291553020477295,
      "logits/rejected": -1.2125135660171509,
      "logps/chosen": -160.25570678710938,
      "logps/rejected": -152.8597869873047,
      "loss": 0.4355,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5360108613967896,
      "rewards/margins": 1.440516710281372,
      "rewards/rejected": -2.976527214050293,
      "step": 8120
    },
    {
      "epoch": 1.4837120175198466,
      "grad_norm": 1.3759765625,
      "learning_rate": 4.0832565850064475e-05,
      "logits/chosen": -1.2487341165542603,
      "logits/rejected": -1.1817373037338257,
      "logps/chosen": -173.78675842285156,
      "logps/rejected": -173.29757690429688,
      "loss": 0.466,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9163419604301453,
      "rewards/margins": 1.7592613697052002,
      "rewards/rejected": -2.675603151321411,
      "step": 8130
    },
    {
      "epoch": 1.4855370015512364,
      "grad_norm": 5.098724842071533,
      "learning_rate": 4.078344692085713e-05,
      "logits/chosen": -1.2398141622543335,
      "logits/rejected": -1.1710259914398193,
      "logps/chosen": -163.27969360351562,
      "logps/rejected": -146.67494201660156,
      "loss": 0.5241,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.348691701889038,
      "rewards/margins": 1.4769260883331299,
      "rewards/rejected": -2.8256173133850098,
      "step": 8140
    },
    {
      "epoch": 1.4873619855826261,
      "grad_norm": 2.5648155212402344,
      "learning_rate": 4.0734327991649784e-05,
      "logits/chosen": -1.3107770681381226,
      "logits/rejected": -1.261642575263977,
      "logps/chosen": -145.59580993652344,
      "logps/rejected": -160.84243774414062,
      "loss": 0.4335,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7208451628684998,
      "rewards/margins": 1.6734027862548828,
      "rewards/rejected": -2.3942482471466064,
      "step": 8150
    },
    {
      "epoch": 1.4891869696140159,
      "grad_norm": 2.052464723587036,
      "learning_rate": 4.068520906244244e-05,
      "logits/chosen": -1.301194429397583,
      "logits/rejected": -1.2425134181976318,
      "logps/chosen": -165.58694458007812,
      "logps/rejected": -158.36672973632812,
      "loss": 0.3637,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.7553605437278748,
      "rewards/margins": 1.8095916509628296,
      "rewards/rejected": -2.5649521350860596,
      "step": 8160
    },
    {
      "epoch": 1.4910119536454056,
      "grad_norm": 2.8360347747802734,
      "learning_rate": 4.06360901332351e-05,
      "logits/chosen": -1.2144901752471924,
      "logits/rejected": -1.1544177532196045,
      "logps/chosen": -145.66888427734375,
      "logps/rejected": -145.01150512695312,
      "loss": 0.4758,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9855540990829468,
      "rewards/margins": 1.3204114437103271,
      "rewards/rejected": -2.3059659004211426,
      "step": 8170
    },
    {
      "epoch": 1.4928369376767954,
      "grad_norm": 5.023116111755371,
      "learning_rate": 4.058697120402776e-05,
      "logits/chosen": -1.236080288887024,
      "logits/rejected": -1.2009104490280151,
      "logps/chosen": -154.42105102539062,
      "logps/rejected": -163.1846160888672,
      "loss": 0.3968,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.814536452293396,
      "rewards/margins": 1.6617845296859741,
      "rewards/rejected": -2.4763214588165283,
      "step": 8180
    },
    {
      "epoch": 1.4946619217081851,
      "grad_norm": 4.454850673675537,
      "learning_rate": 4.053785227482041e-05,
      "logits/chosen": -1.220515489578247,
      "logits/rejected": -1.1519315242767334,
      "logps/chosen": -148.2377471923828,
      "logps/rejected": -140.1521453857422,
      "loss": 0.3728,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.5334151983261108,
      "rewards/margins": 1.631039023399353,
      "rewards/rejected": -2.1644539833068848,
      "step": 8190
    },
    {
      "epoch": 1.4964869057395749,
      "grad_norm": 2.1801745891571045,
      "learning_rate": 4.0488733345613066e-05,
      "logits/chosen": -1.263048768043518,
      "logits/rejected": -1.204641580581665,
      "logps/chosen": -151.4998016357422,
      "logps/rejected": -155.28146362304688,
      "loss": 0.3258,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.1806302070617676,
      "rewards/margins": 1.866305947303772,
      "rewards/rejected": -3.046936273574829,
      "step": 8200
    },
    {
      "epoch": 1.4983118897709646,
      "grad_norm": 3.0797743797302246,
      "learning_rate": 4.043961441640573e-05,
      "logits/chosen": -1.2616701126098633,
      "logits/rejected": -1.1801012754440308,
      "logps/chosen": -167.4807586669922,
      "logps/rejected": -139.2833709716797,
      "loss": 0.3867,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.1507694721221924,
      "rewards/margins": 1.8730182647705078,
      "rewards/rejected": -3.023787498474121,
      "step": 8210
    },
    {
      "epoch": 1.5001368738023544,
      "grad_norm": 3.182737350463867,
      "learning_rate": 4.039049548719838e-05,
      "logits/chosen": -1.3007384538650513,
      "logits/rejected": -1.221703290939331,
      "logps/chosen": -151.83250427246094,
      "logps/rejected": -160.58285522460938,
      "loss": 0.3292,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.407428503036499,
      "rewards/margins": 1.9525970220565796,
      "rewards/rejected": -3.360025405883789,
      "step": 8220
    },
    {
      "epoch": 1.501961857833744,
      "grad_norm": 4.043642044067383,
      "learning_rate": 4.034137655799104e-05,
      "logits/chosen": -1.3005285263061523,
      "logits/rejected": -1.2719969749450684,
      "logps/chosen": -142.73728942871094,
      "logps/rejected": -154.41226196289062,
      "loss": 0.4508,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4213520288467407,
      "rewards/margins": 1.3825438022613525,
      "rewards/rejected": -2.803895950317383,
      "step": 8230
    },
    {
      "epoch": 1.5037868418651337,
      "grad_norm": 6.101346969604492,
      "learning_rate": 4.0292257628783697e-05,
      "logits/chosen": -1.289420485496521,
      "logits/rejected": -1.2353274822235107,
      "logps/chosen": -155.1280517578125,
      "logps/rejected": -162.29891967773438,
      "loss": 0.5137,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.6245752573013306,
      "rewards/margins": 1.7359983921051025,
      "rewards/rejected": -3.3605735301971436,
      "step": 8240
    },
    {
      "epoch": 1.5056118258965234,
      "grad_norm": 3.1583757400512695,
      "learning_rate": 4.0243138699576354e-05,
      "logits/chosen": -1.2897899150848389,
      "logits/rejected": -1.2257301807403564,
      "logps/chosen": -155.86331176757812,
      "logps/rejected": -168.18894958496094,
      "loss": 0.3387,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.37855064868927,
      "rewards/margins": 2.1477041244506836,
      "rewards/rejected": -3.526254177093506,
      "step": 8250
    },
    {
      "epoch": 1.5074368099279132,
      "grad_norm": 5.265182018280029,
      "learning_rate": 4.0194019770369005e-05,
      "logits/chosen": -1.3176376819610596,
      "logits/rejected": -1.2539249658584595,
      "logps/chosen": -152.42849731445312,
      "logps/rejected": -165.70413208007812,
      "loss": 0.4143,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5122345685958862,
      "rewards/margins": 1.7954286336898804,
      "rewards/rejected": -3.3076629638671875,
      "step": 8260
    },
    {
      "epoch": 1.5092617939593027,
      "grad_norm": 4.642259120941162,
      "learning_rate": 4.014490084116166e-05,
      "logits/chosen": -1.3359639644622803,
      "logits/rejected": -1.3408544063568115,
      "logps/chosen": -178.722900390625,
      "logps/rejected": -192.62530517578125,
      "loss": 0.6616,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8867542743682861,
      "rewards/margins": 1.454994797706604,
      "rewards/rejected": -3.3417491912841797,
      "step": 8270
    },
    {
      "epoch": 1.5110867779906925,
      "grad_norm": 4.55567741394043,
      "learning_rate": 4.009578191195433e-05,
      "logits/chosen": -1.2305700778961182,
      "logits/rejected": -1.1990747451782227,
      "logps/chosen": -152.53030395507812,
      "logps/rejected": -166.4010009765625,
      "loss": 0.6253,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.7272449731826782,
      "rewards/margins": 1.2164949178695679,
      "rewards/rejected": -2.943739891052246,
      "step": 8280
    },
    {
      "epoch": 1.5129117620220822,
      "grad_norm": 3.9660966396331787,
      "learning_rate": 4.004666298274698e-05,
      "logits/chosen": -1.2209523916244507,
      "logits/rejected": -1.1206490993499756,
      "logps/chosen": -172.62014770507812,
      "logps/rejected": -166.64381408691406,
      "loss": 0.3646,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.662024736404419,
      "rewards/margins": 1.8262531757354736,
      "rewards/rejected": -3.4882779121398926,
      "step": 8290
    },
    {
      "epoch": 1.514736746053472,
      "grad_norm": 4.050127029418945,
      "learning_rate": 3.9997544053539636e-05,
      "logits/chosen": -1.2416126728057861,
      "logits/rejected": -1.194230079650879,
      "logps/chosen": -170.0797119140625,
      "logps/rejected": -167.66644287109375,
      "loss": 0.4705,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8037166595458984,
      "rewards/margins": 1.380818247795105,
      "rewards/rejected": -3.184534788131714,
      "step": 8300
    },
    {
      "epoch": 1.5165617300848617,
      "grad_norm": 5.69596529006958,
      "learning_rate": 3.9948425124332294e-05,
      "logits/chosen": -1.2462334632873535,
      "logits/rejected": -1.1484880447387695,
      "logps/chosen": -176.88751220703125,
      "logps/rejected": -160.00619506835938,
      "loss": 0.5158,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.715752363204956,
      "rewards/margins": 1.4241430759429932,
      "rewards/rejected": -3.139895439147949,
      "step": 8310
    },
    {
      "epoch": 1.5183867141162515,
      "grad_norm": 6.078123092651367,
      "learning_rate": 3.989930619512495e-05,
      "logits/chosen": -1.2605451345443726,
      "logits/rejected": -1.208655595779419,
      "logps/chosen": -163.99557495117188,
      "logps/rejected": -169.29071044921875,
      "loss": 0.4404,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.089495897293091,
      "rewards/margins": 1.4801006317138672,
      "rewards/rejected": -3.569596529006958,
      "step": 8320
    },
    {
      "epoch": 1.5202116981476412,
      "grad_norm": 6.422389507293701,
      "learning_rate": 3.98501872659176e-05,
      "logits/chosen": -1.2654023170471191,
      "logits/rejected": -1.1433753967285156,
      "logps/chosen": -162.3369903564453,
      "logps/rejected": -148.4608917236328,
      "loss": 0.3847,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.8488086462020874,
      "rewards/margins": 1.67255437374115,
      "rewards/rejected": -3.521362781524658,
      "step": 8330
    },
    {
      "epoch": 1.522036682179031,
      "grad_norm": 6.062182426452637,
      "learning_rate": 3.980106833671027e-05,
      "logits/chosen": -1.2522623538970947,
      "logits/rejected": -1.1918880939483643,
      "logps/chosen": -158.05294799804688,
      "logps/rejected": -165.95652770996094,
      "loss": 0.4095,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7065826654434204,
      "rewards/margins": 1.7712856531143188,
      "rewards/rejected": -3.4778683185577393,
      "step": 8340
    },
    {
      "epoch": 1.5238616662104207,
      "grad_norm": 4.66538143157959,
      "learning_rate": 3.975194940750292e-05,
      "logits/chosen": -1.281860589981079,
      "logits/rejected": -1.255477786064148,
      "logps/chosen": -161.30836486816406,
      "logps/rejected": -160.0831298828125,
      "loss": 0.5017,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.5261361598968506,
      "rewards/margins": 1.5860519409179688,
      "rewards/rejected": -3.1121881008148193,
      "step": 8350
    },
    {
      "epoch": 1.5256866502418105,
      "grad_norm": 5.049202919006348,
      "learning_rate": 3.9702830478295576e-05,
      "logits/chosen": -1.321028709411621,
      "logits/rejected": -1.2579700946807861,
      "logps/chosen": -159.43673706054688,
      "logps/rejected": -169.29563903808594,
      "loss": 0.3824,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2687654495239258,
      "rewards/margins": 1.8156907558441162,
      "rewards/rejected": -3.084456205368042,
      "step": 8360
    },
    {
      "epoch": 1.5275116342732002,
      "grad_norm": 3.6319692134857178,
      "learning_rate": 3.9653711549088234e-05,
      "logits/chosen": -1.2551145553588867,
      "logits/rejected": -1.213118314743042,
      "logps/chosen": -159.93643188476562,
      "logps/rejected": -156.98220825195312,
      "loss": 0.3914,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.1316386461257935,
      "rewards/margins": 1.573279619216919,
      "rewards/rejected": -2.7049179077148438,
      "step": 8370
    },
    {
      "epoch": 1.52933661830459,
      "grad_norm": 3.1173617839813232,
      "learning_rate": 3.960459261988089e-05,
      "logits/chosen": -1.241249442100525,
      "logits/rejected": -1.2060282230377197,
      "logps/chosen": -149.68130493164062,
      "logps/rejected": -164.69998168945312,
      "loss": 0.494,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1652525663375854,
      "rewards/margins": 1.4592831134796143,
      "rewards/rejected": -2.6245360374450684,
      "step": 8380
    },
    {
      "epoch": 1.5311616023359795,
      "grad_norm": 4.440927505493164,
      "learning_rate": 3.955547369067354e-05,
      "logits/chosen": -1.320375680923462,
      "logits/rejected": -1.2666807174682617,
      "logps/chosen": -168.9352264404297,
      "logps/rejected": -158.18179321289062,
      "loss": 0.432,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1105115413665771,
      "rewards/margins": 1.493411898612976,
      "rewards/rejected": -2.6039235591888428,
      "step": 8390
    },
    {
      "epoch": 1.5329865863673693,
      "grad_norm": 5.510258674621582,
      "learning_rate": 3.950635476146621e-05,
      "logits/chosen": -1.2680127620697021,
      "logits/rejected": -1.2633353471755981,
      "logps/chosen": -150.32373046875,
      "logps/rejected": -164.491455078125,
      "loss": 0.4744,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.5943458080291748,
      "rewards/margins": 1.303053617477417,
      "rewards/rejected": -2.897399425506592,
      "step": 8400
    },
    {
      "epoch": 1.534811570398759,
      "grad_norm": 3.5677895545959473,
      "learning_rate": 3.945723583225886e-05,
      "logits/chosen": -1.2706655263900757,
      "logits/rejected": -1.1669673919677734,
      "logps/chosen": -170.65609741210938,
      "logps/rejected": -139.217041015625,
      "loss": 0.4062,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9491264224052429,
      "rewards/margins": 1.5790705680847168,
      "rewards/rejected": -2.5281968116760254,
      "step": 8410
    },
    {
      "epoch": 1.5366365544301486,
      "grad_norm": 2.8600032329559326,
      "learning_rate": 3.9408116903051515e-05,
      "logits/chosen": -1.2190403938293457,
      "logits/rejected": -1.1724402904510498,
      "logps/chosen": -147.88192749023438,
      "logps/rejected": -150.92828369140625,
      "loss": 0.4099,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2606568336486816,
      "rewards/margins": 1.590355634689331,
      "rewards/rejected": -2.8510124683380127,
      "step": 8420
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 3.330458641052246,
      "learning_rate": 3.935899797384417e-05,
      "logits/chosen": -1.209148645401001,
      "logits/rejected": -1.1738758087158203,
      "logps/chosen": -171.90530395507812,
      "logps/rejected": -178.85440063476562,
      "loss": 0.4613,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.19590163230896,
      "rewards/margins": 1.6494134664535522,
      "rewards/rejected": -2.8453152179718018,
      "step": 8430
    },
    {
      "epoch": 1.540286522492928,
      "grad_norm": 5.5724310874938965,
      "learning_rate": 3.930987904463683e-05,
      "logits/chosen": -1.302241325378418,
      "logits/rejected": -1.1999620199203491,
      "logps/chosen": -173.71701049804688,
      "logps/rejected": -151.64962768554688,
      "loss": 0.4635,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0479393005371094,
      "rewards/margins": 1.309173345565796,
      "rewards/rejected": -2.3571126461029053,
      "step": 8440
    },
    {
      "epoch": 1.5421115065243178,
      "grad_norm": 3.3543357849121094,
      "learning_rate": 3.926076011542949e-05,
      "logits/chosen": -1.192591905593872,
      "logits/rejected": -1.0914908647537231,
      "logps/chosen": -168.46041870117188,
      "logps/rejected": -146.20887756347656,
      "loss": 0.4837,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1973581314086914,
      "rewards/margins": 1.522196650505066,
      "rewards/rejected": -2.7195544242858887,
      "step": 8450
    },
    {
      "epoch": 1.5439364905557076,
      "grad_norm": 3.4233036041259766,
      "learning_rate": 3.921164118622214e-05,
      "logits/chosen": -1.1892170906066895,
      "logits/rejected": -1.0762670040130615,
      "logps/chosen": -175.5933380126953,
      "logps/rejected": -146.82357788085938,
      "loss": 0.4678,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2128140926361084,
      "rewards/margins": 1.573289155960083,
      "rewards/rejected": -2.7861034870147705,
      "step": 8460
    },
    {
      "epoch": 1.5457614745870973,
      "grad_norm": 3.6923725605010986,
      "learning_rate": 3.9162522257014804e-05,
      "logits/chosen": -1.1420546770095825,
      "logits/rejected": -1.047833800315857,
      "logps/chosen": -145.0943603515625,
      "logps/rejected": -146.94851684570312,
      "loss": 0.3681,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.2268575429916382,
      "rewards/margins": 1.5008341073989868,
      "rewards/rejected": -2.727691888809204,
      "step": 8470
    },
    {
      "epoch": 1.547586458618487,
      "grad_norm": 3.156916379928589,
      "learning_rate": 3.9113403327807455e-05,
      "logits/chosen": -1.166227102279663,
      "logits/rejected": -1.0684577226638794,
      "logps/chosen": -165.62779235839844,
      "logps/rejected": -147.92251586914062,
      "loss": 0.4188,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9890192747116089,
      "rewards/margins": 1.6910041570663452,
      "rewards/rejected": -2.680023670196533,
      "step": 8480
    },
    {
      "epoch": 1.5494114426498768,
      "grad_norm": 3.0856523513793945,
      "learning_rate": 3.906428439860011e-05,
      "logits/chosen": -1.1363437175750732,
      "logits/rejected": -1.0576624870300293,
      "logps/chosen": -153.59503173828125,
      "logps/rejected": -143.73080444335938,
      "loss": 0.492,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.319629430770874,
      "rewards/margins": 1.3426105976104736,
      "rewards/rejected": -2.6622397899627686,
      "step": 8490
    },
    {
      "epoch": 1.5512364266812666,
      "grad_norm": 2.431638479232788,
      "learning_rate": 3.901516546939277e-05,
      "logits/chosen": -1.1669566631317139,
      "logits/rejected": -1.0836094617843628,
      "logps/chosen": -164.6142120361328,
      "logps/rejected": -151.53599548339844,
      "loss": 0.576,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.764916181564331,
      "rewards/margins": 1.0502495765686035,
      "rewards/rejected": -2.8151657581329346,
      "step": 8500
    },
    {
      "epoch": 1.5530614107126564,
      "grad_norm": 3.2419304847717285,
      "learning_rate": 3.896604654018543e-05,
      "logits/chosen": -1.1328303813934326,
      "logits/rejected": -1.0751737356185913,
      "logps/chosen": -153.40237426757812,
      "logps/rejected": -162.4169464111328,
      "loss": 0.3909,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5879366397857666,
      "rewards/margins": 1.508941411972046,
      "rewards/rejected": -3.0968780517578125,
      "step": 8510
    },
    {
      "epoch": 1.554886394744046,
      "grad_norm": 2.1971709728240967,
      "learning_rate": 3.8916927610978086e-05,
      "logits/chosen": -1.1872901916503906,
      "logits/rejected": -1.1069953441619873,
      "logps/chosen": -166.18521118164062,
      "logps/rejected": -152.10733032226562,
      "loss": 0.5054,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2221407890319824,
      "rewards/margins": 1.2893149852752686,
      "rewards/rejected": -2.511455774307251,
      "step": 8520
    },
    {
      "epoch": 1.5567113787754359,
      "grad_norm": 2.7914390563964844,
      "learning_rate": 3.886780868177074e-05,
      "logits/chosen": -1.1262884140014648,
      "logits/rejected": -1.0927174091339111,
      "logps/chosen": -158.52500915527344,
      "logps/rejected": -181.8959197998047,
      "loss": 0.4223,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.444036841392517,
      "rewards/margins": 1.6182947158813477,
      "rewards/rejected": -3.0623316764831543,
      "step": 8530
    },
    {
      "epoch": 1.5585363628068254,
      "grad_norm": 1.752349615097046,
      "learning_rate": 3.88186897525634e-05,
      "logits/chosen": -1.1566615104675293,
      "logits/rejected": -1.0768868923187256,
      "logps/chosen": -159.05130004882812,
      "logps/rejected": -149.0680694580078,
      "loss": 0.3502,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.1505659818649292,
      "rewards/margins": 1.7579400539398193,
      "rewards/rejected": -2.9085066318511963,
      "step": 8540
    },
    {
      "epoch": 1.5603613468382151,
      "grad_norm": 3.836099147796631,
      "learning_rate": 3.876957082335605e-05,
      "logits/chosen": -1.1279995441436768,
      "logits/rejected": -1.0085231065750122,
      "logps/chosen": -170.69712829589844,
      "logps/rejected": -155.8118896484375,
      "loss": 0.4925,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.2303391695022583,
      "rewards/margins": 1.361756443977356,
      "rewards/rejected": -2.5920956134796143,
      "step": 8550
    },
    {
      "epoch": 1.562186330869605,
      "grad_norm": 5.6070475578308105,
      "learning_rate": 3.872045189414871e-05,
      "logits/chosen": -1.1134566068649292,
      "logits/rejected": -1.0308871269226074,
      "logps/chosen": -161.03585815429688,
      "logps/rejected": -150.33193969726562,
      "loss": 0.4484,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3583228588104248,
      "rewards/margins": 1.3607767820358276,
      "rewards/rejected": -2.719099760055542,
      "step": 8560
    },
    {
      "epoch": 1.5640113149009947,
      "grad_norm": 3.88443660736084,
      "learning_rate": 3.867133296494137e-05,
      "logits/chosen": -1.0904170274734497,
      "logits/rejected": -1.0344455242156982,
      "logps/chosen": -161.44134521484375,
      "logps/rejected": -164.71371459960938,
      "loss": 0.4225,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0059306621551514,
      "rewards/margins": 1.7613718509674072,
      "rewards/rejected": -2.7673027515411377,
      "step": 8570
    },
    {
      "epoch": 1.5658362989323842,
      "grad_norm": 4.00194787979126,
      "learning_rate": 3.8622214035734026e-05,
      "logits/chosen": -1.1460130214691162,
      "logits/rejected": -1.0851953029632568,
      "logps/chosen": -144.69259643554688,
      "logps/rejected": -153.72828674316406,
      "loss": 0.4172,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.0734840631484985,
      "rewards/margins": 1.4826453924179077,
      "rewards/rejected": -2.556129217147827,
      "step": 8580
    },
    {
      "epoch": 1.567661282963774,
      "grad_norm": 5.210468769073486,
      "learning_rate": 3.8573095106526676e-05,
      "logits/chosen": -1.2174594402313232,
      "logits/rejected": -1.1253145933151245,
      "logps/chosen": -160.13388061523438,
      "logps/rejected": -146.69717407226562,
      "loss": 0.4878,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.486737608909607,
      "rewards/margins": 1.4677151441574097,
      "rewards/rejected": -2.9544529914855957,
      "step": 8590
    },
    {
      "epoch": 1.5694862669951637,
      "grad_norm": 3.598881721496582,
      "learning_rate": 3.852397617731934e-05,
      "logits/chosen": -1.1335536241531372,
      "logits/rejected": -1.1078516244888306,
      "logps/chosen": -135.33035278320312,
      "logps/rejected": -139.19154357910156,
      "loss": 0.561,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.2336609363555908,
      "rewards/margins": 1.1748065948486328,
      "rewards/rejected": -2.4084675312042236,
      "step": 8600
    },
    {
      "epoch": 1.5713112510265534,
      "grad_norm": 2.7771382331848145,
      "learning_rate": 3.8474857248112e-05,
      "logits/chosen": -1.1334812641143799,
      "logits/rejected": -1.092637300491333,
      "logps/chosen": -153.9382781982422,
      "logps/rejected": -164.1085205078125,
      "loss": 0.454,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7760186195373535,
      "rewards/margins": 1.5780234336853027,
      "rewards/rejected": -2.3540420532226562,
      "step": 8610
    },
    {
      "epoch": 1.5731362350579432,
      "grad_norm": 2.892692804336548,
      "learning_rate": 3.842573831890465e-05,
      "logits/chosen": -1.1278672218322754,
      "logits/rejected": -1.0632860660552979,
      "logps/chosen": -149.93606567382812,
      "logps/rejected": -152.5409393310547,
      "loss": 0.4495,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.119920253753662,
      "rewards/margins": 1.400670051574707,
      "rewards/rejected": -2.520590305328369,
      "step": 8620
    },
    {
      "epoch": 1.574961219089333,
      "grad_norm": 3.315544605255127,
      "learning_rate": 3.837661938969731e-05,
      "logits/chosen": -1.1539500951766968,
      "logits/rejected": -1.096024751663208,
      "logps/chosen": -145.97015380859375,
      "logps/rejected": -152.8821563720703,
      "loss": 0.3513,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.117236614227295,
      "rewards/margins": 1.5802298784255981,
      "rewards/rejected": -2.6974666118621826,
      "step": 8630
    },
    {
      "epoch": 1.5767862031207227,
      "grad_norm": 5.061515808105469,
      "learning_rate": 3.8327500460489965e-05,
      "logits/chosen": -1.163431167602539,
      "logits/rejected": -1.0876907110214233,
      "logps/chosen": -161.02525329589844,
      "logps/rejected": -162.0957794189453,
      "loss": 0.4825,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.633387804031372,
      "rewards/margins": 1.5439794063568115,
      "rewards/rejected": -3.1773674488067627,
      "step": 8640
    },
    {
      "epoch": 1.5786111871521125,
      "grad_norm": 1.6933211088180542,
      "learning_rate": 3.827838153128262e-05,
      "logits/chosen": -1.1231577396392822,
      "logits/rejected": -1.0445873737335205,
      "logps/chosen": -134.1993865966797,
      "logps/rejected": -141.89248657226562,
      "loss": 0.3708,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.196450114250183,
      "rewards/margins": 1.5935404300689697,
      "rewards/rejected": -2.7899904251098633,
      "step": 8650
    },
    {
      "epoch": 1.5804361711835022,
      "grad_norm": 3.762679100036621,
      "learning_rate": 3.8229262602075274e-05,
      "logits/chosen": -1.1758286952972412,
      "logits/rejected": -1.094582438468933,
      "logps/chosen": -150.44659423828125,
      "logps/rejected": -136.55911254882812,
      "loss": 0.4873,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1935851573944092,
      "rewards/margins": 1.2617909908294678,
      "rewards/rejected": -2.455376148223877,
      "step": 8660
    },
    {
      "epoch": 1.582261155214892,
      "grad_norm": 2.828376293182373,
      "learning_rate": 3.818014367286794e-05,
      "logits/chosen": -1.1325172185897827,
      "logits/rejected": -1.0544553995132446,
      "logps/chosen": -148.24078369140625,
      "logps/rejected": -151.9928741455078,
      "loss": 0.3836,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.9549332857131958,
      "rewards/margins": 1.9024989604949951,
      "rewards/rejected": -2.8574323654174805,
      "step": 8670
    },
    {
      "epoch": 1.5840861392462817,
      "grad_norm": 3.301950216293335,
      "learning_rate": 3.813102474366059e-05,
      "logits/chosen": -1.1780428886413574,
      "logits/rejected": -1.1224868297576904,
      "logps/chosen": -144.2035369873047,
      "logps/rejected": -146.0174102783203,
      "loss": 0.4317,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.4684767723083496,
      "rewards/margins": 1.859163522720337,
      "rewards/rejected": -2.3276400566101074,
      "step": 8680
    },
    {
      "epoch": 1.5859111232776715,
      "grad_norm": 1.8437081575393677,
      "learning_rate": 3.808190581445325e-05,
      "logits/chosen": -1.1682662963867188,
      "logits/rejected": -1.1261351108551025,
      "logps/chosen": -166.68643188476562,
      "logps/rejected": -159.19424438476562,
      "loss": 0.376,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.7724083662033081,
      "rewards/margins": 1.58583664894104,
      "rewards/rejected": -2.3582451343536377,
      "step": 8690
    },
    {
      "epoch": 1.587736107309061,
      "grad_norm": 3.836817979812622,
      "learning_rate": 3.8032786885245905e-05,
      "logits/chosen": -1.1578781604766846,
      "logits/rejected": -1.0496525764465332,
      "logps/chosen": -150.43594360351562,
      "logps/rejected": -148.18783569335938,
      "loss": 0.4379,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6263846755027771,
      "rewards/margins": 1.6781896352767944,
      "rewards/rejected": -2.304574489593506,
      "step": 8700
    },
    {
      "epoch": 1.5895610913404508,
      "grad_norm": 3.710942268371582,
      "learning_rate": 3.798366795603856e-05,
      "logits/chosen": -1.17428719997406,
      "logits/rejected": -1.108935832977295,
      "logps/chosen": -152.53765869140625,
      "logps/rejected": -153.08883666992188,
      "loss": 0.5077,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.5233524441719055,
      "rewards/margins": 1.075927495956421,
      "rewards/rejected": -1.599279761314392,
      "step": 8710
    },
    {
      "epoch": 1.5913860753718405,
      "grad_norm": 2.200514078140259,
      "learning_rate": 3.793454902683122e-05,
      "logits/chosen": -1.0836752653121948,
      "logits/rejected": -1.0550248622894287,
      "logps/chosen": -145.0179443359375,
      "logps/rejected": -149.05056762695312,
      "loss": 0.4017,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.8067118525505066,
      "rewards/margins": 1.447909951210022,
      "rewards/rejected": -2.254621982574463,
      "step": 8720
    },
    {
      "epoch": 1.5932110594032303,
      "grad_norm": 6.375762462615967,
      "learning_rate": 3.788543009762387e-05,
      "logits/chosen": -1.157484769821167,
      "logits/rejected": -1.0809026956558228,
      "logps/chosen": -158.9003448486328,
      "logps/rejected": -154.05215454101562,
      "loss": 0.3922,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.5434511303901672,
      "rewards/margins": 1.6336673498153687,
      "rewards/rejected": -2.1771185398101807,
      "step": 8730
    },
    {
      "epoch": 1.5950360434346198,
      "grad_norm": 4.82424783706665,
      "learning_rate": 3.7836311168416536e-05,
      "logits/chosen": -1.1106563806533813,
      "logits/rejected": -1.0483540296554565,
      "logps/chosen": -158.8831024169922,
      "logps/rejected": -156.61085510253906,
      "loss": 0.5164,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.3290473222732544,
      "rewards/margins": 1.5334380865097046,
      "rewards/rejected": -2.86248517036438,
      "step": 8740
    },
    {
      "epoch": 1.5968610274660096,
      "grad_norm": 4.056059837341309,
      "learning_rate": 3.778719223920919e-05,
      "logits/chosen": -1.1114192008972168,
      "logits/rejected": -0.9650107622146606,
      "logps/chosen": -183.66482543945312,
      "logps/rejected": -163.28811645507812,
      "loss": 0.3901,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0099769830703735,
      "rewards/margins": 1.7294842004776,
      "rewards/rejected": -2.7394614219665527,
      "step": 8750
    },
    {
      "epoch": 1.5986860114973993,
      "grad_norm": 6.084535121917725,
      "learning_rate": 3.7738073310001844e-05,
      "logits/chosen": -1.0118337869644165,
      "logits/rejected": -1.0020431280136108,
      "logps/chosen": -149.87350463867188,
      "logps/rejected": -165.6302947998047,
      "loss": 0.4927,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4188356399536133,
      "rewards/margins": 1.3077104091644287,
      "rewards/rejected": -2.726546049118042,
      "step": 8760
    },
    {
      "epoch": 1.600510995528789,
      "grad_norm": 3.318453550338745,
      "learning_rate": 3.76889543807945e-05,
      "logits/chosen": -1.0227066278457642,
      "logits/rejected": -0.9334843754768372,
      "logps/chosen": -162.51199340820312,
      "logps/rejected": -157.2792205810547,
      "loss": 0.4099,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.2868545055389404,
      "rewards/margins": 1.4543896913528442,
      "rewards/rejected": -2.741244316101074,
      "step": 8770
    },
    {
      "epoch": 1.6023359795601788,
      "grad_norm": 3.719761371612549,
      "learning_rate": 3.763983545158716e-05,
      "logits/chosen": -1.052541971206665,
      "logits/rejected": -1.013447880744934,
      "logps/chosen": -148.3590087890625,
      "logps/rejected": -168.05831909179688,
      "loss": 0.4375,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.123319149017334,
      "rewards/margins": 1.767615556716919,
      "rewards/rejected": -2.890934705734253,
      "step": 8780
    },
    {
      "epoch": 1.6041609635915686,
      "grad_norm": 5.011646270751953,
      "learning_rate": 3.759071652237981e-05,
      "logits/chosen": -1.0783755779266357,
      "logits/rejected": -1.0025732517242432,
      "logps/chosen": -140.73013305664062,
      "logps/rejected": -136.81961059570312,
      "loss": 0.4273,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4694410562515259,
      "rewards/margins": 1.4539340734481812,
      "rewards/rejected": -2.923375129699707,
      "step": 8790
    },
    {
      "epoch": 1.6059859476229583,
      "grad_norm": 3.259834051132202,
      "learning_rate": 3.754159759317247e-05,
      "logits/chosen": -1.112851858139038,
      "logits/rejected": -1.0655593872070312,
      "logps/chosen": -158.67662048339844,
      "logps/rejected": -163.1862030029297,
      "loss": 0.3735,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4106638431549072,
      "rewards/margins": 1.6462064981460571,
      "rewards/rejected": -3.0568699836730957,
      "step": 8800
    },
    {
      "epoch": 1.607810931654348,
      "grad_norm": 2.4142143726348877,
      "learning_rate": 3.749247866396513e-05,
      "logits/chosen": -1.144912600517273,
      "logits/rejected": -1.0517088174819946,
      "logps/chosen": -165.5239715576172,
      "logps/rejected": -162.13307189941406,
      "loss": 0.4288,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1980419158935547,
      "rewards/margins": 1.7661428451538086,
      "rewards/rejected": -2.9641849994659424,
      "step": 8810
    },
    {
      "epoch": 1.6096359156857378,
      "grad_norm": 5.532523155212402,
      "learning_rate": 3.7443359734757784e-05,
      "logits/chosen": -1.1204065084457397,
      "logits/rejected": -1.0247671604156494,
      "logps/chosen": -149.21420288085938,
      "logps/rejected": -145.79861450195312,
      "loss": 0.5225,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6624457836151123,
      "rewards/margins": 1.487762212753296,
      "rewards/rejected": -3.150207996368408,
      "step": 8820
    },
    {
      "epoch": 1.6114608997171276,
      "grad_norm": 2.442269802093506,
      "learning_rate": 3.739424080555044e-05,
      "logits/chosen": -1.0681102275848389,
      "logits/rejected": -0.9623526334762573,
      "logps/chosen": -151.68106079101562,
      "logps/rejected": -140.02700805664062,
      "loss": 0.4026,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5334663391113281,
      "rewards/margins": 1.740451455116272,
      "rewards/rejected": -3.2739181518554688,
      "step": 8830
    },
    {
      "epoch": 1.6132858837485173,
      "grad_norm": 3.0766568183898926,
      "learning_rate": 3.73451218763431e-05,
      "logits/chosen": -1.1295480728149414,
      "logits/rejected": -1.0094727277755737,
      "logps/chosen": -166.2406768798828,
      "logps/rejected": -159.94847106933594,
      "loss": 0.2771,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.1251567602157593,
      "rewards/margins": 2.3012642860412598,
      "rewards/rejected": -3.4264214038848877,
      "step": 8840
    },
    {
      "epoch": 1.615110867779907,
      "grad_norm": 4.495499610900879,
      "learning_rate": 3.729600294713576e-05,
      "logits/chosen": -1.0888720750808716,
      "logits/rejected": -1.0137861967086792,
      "logps/chosen": -146.90927124023438,
      "logps/rejected": -166.74339294433594,
      "loss": 0.4357,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.638763189315796,
      "rewards/margins": 2.176365375518799,
      "rewards/rejected": -3.815128803253174,
      "step": 8850
    },
    {
      "epoch": 1.6169358518112966,
      "grad_norm": 5.930356025695801,
      "learning_rate": 3.724688401792841e-05,
      "logits/chosen": -1.0943034887313843,
      "logits/rejected": -0.9637060165405273,
      "logps/chosen": -161.3850860595703,
      "logps/rejected": -153.80380249023438,
      "loss": 0.3889,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.55312979221344,
      "rewards/margins": 2.099936008453369,
      "rewards/rejected": -3.6530659198760986,
      "step": 8860
    },
    {
      "epoch": 1.6187608358426864,
      "grad_norm": 6.179111003875732,
      "learning_rate": 3.719776508872107e-05,
      "logits/chosen": -1.045135259628296,
      "logits/rejected": -0.99922114610672,
      "logps/chosen": -160.03890991210938,
      "logps/rejected": -177.01919555664062,
      "loss": 0.4366,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3331215381622314,
      "rewards/margins": 1.4977418184280396,
      "rewards/rejected": -2.8308634757995605,
      "step": 8870
    },
    {
      "epoch": 1.6205858198740761,
      "grad_norm": 3.352391004562378,
      "learning_rate": 3.7148646159513724e-05,
      "logits/chosen": -1.0793839693069458,
      "logits/rejected": -0.98974609375,
      "logps/chosen": -174.98660278320312,
      "logps/rejected": -169.7759246826172,
      "loss": 0.2971,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.5528380870819092,
      "rewards/margins": 1.9577643871307373,
      "rewards/rejected": -3.5106024742126465,
      "step": 8880
    },
    {
      "epoch": 1.6224108039054659,
      "grad_norm": 2.348512887954712,
      "learning_rate": 3.709952723030638e-05,
      "logits/chosen": -1.0899558067321777,
      "logits/rejected": -0.9761991500854492,
      "logps/chosen": -158.80836486816406,
      "logps/rejected": -153.97976684570312,
      "loss": 0.2858,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5260462760925293,
      "rewards/margins": 2.075911283493042,
      "rewards/rejected": -3.601957321166992,
      "step": 8890
    },
    {
      "epoch": 1.6242357879368554,
      "grad_norm": 6.340356826782227,
      "learning_rate": 3.705040830109904e-05,
      "logits/chosen": -1.0875473022460938,
      "logits/rejected": -1.033510684967041,
      "logps/chosen": -161.53976440429688,
      "logps/rejected": -175.4987335205078,
      "loss": 0.505,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7500200271606445,
      "rewards/margins": 2.0158050060272217,
      "rewards/rejected": -3.7658252716064453,
      "step": 8900
    },
    {
      "epoch": 1.6260607719682452,
      "grad_norm": 3.8114960193634033,
      "learning_rate": 3.70012893718917e-05,
      "logits/chosen": -1.110097885131836,
      "logits/rejected": -1.0007648468017578,
      "logps/chosen": -163.0088653564453,
      "logps/rejected": -162.09317016601562,
      "loss": 0.2801,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5655744075775146,
      "rewards/margins": 2.4016146659851074,
      "rewards/rejected": -3.967189073562622,
      "step": 8910
    },
    {
      "epoch": 1.627885755999635,
      "grad_norm": 3.092482089996338,
      "learning_rate": 3.6952170442684355e-05,
      "logits/chosen": -1.172066330909729,
      "logits/rejected": -1.1056177616119385,
      "logps/chosen": -145.54922485351562,
      "logps/rejected": -152.4295196533203,
      "loss": 0.4632,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.3403055667877197,
      "rewards/margins": 1.747955322265625,
      "rewards/rejected": -3.0882608890533447,
      "step": 8920
    },
    {
      "epoch": 1.6297107400310247,
      "grad_norm": 5.047232151031494,
      "learning_rate": 3.6903051513477005e-05,
      "logits/chosen": -1.1289571523666382,
      "logits/rejected": -1.0052770376205444,
      "logps/chosen": -170.05775451660156,
      "logps/rejected": -162.5406036376953,
      "loss": 0.4044,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.0840166807174683,
      "rewards/margins": 1.9634654521942139,
      "rewards/rejected": -3.0474822521209717,
      "step": 8930
    },
    {
      "epoch": 1.6315357240624144,
      "grad_norm": 3.1961936950683594,
      "learning_rate": 3.685393258426967e-05,
      "logits/chosen": -1.1547353267669678,
      "logits/rejected": -1.0121256113052368,
      "logps/chosen": -159.3123779296875,
      "logps/rejected": -146.8838653564453,
      "loss": 0.3318,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.1083717346191406,
      "rewards/margins": 1.9001127481460571,
      "rewards/rejected": -3.008484363555908,
      "step": 8940
    },
    {
      "epoch": 1.6333607080938042,
      "grad_norm": 2.7742831707000732,
      "learning_rate": 3.680481365506232e-05,
      "logits/chosen": -1.092719316482544,
      "logits/rejected": -1.0087093114852905,
      "logps/chosen": -148.7035369873047,
      "logps/rejected": -156.78176879882812,
      "loss": 0.4587,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0775684118270874,
      "rewards/margins": 1.770037055015564,
      "rewards/rejected": -2.8476057052612305,
      "step": 8950
    },
    {
      "epoch": 1.635185692125194,
      "grad_norm": 2.401860237121582,
      "learning_rate": 3.675569472585498e-05,
      "logits/chosen": -1.0708461999893188,
      "logits/rejected": -0.9777511358261108,
      "logps/chosen": -169.66348266601562,
      "logps/rejected": -160.8187713623047,
      "loss": 0.3672,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3685088157653809,
      "rewards/margins": 1.9400571584701538,
      "rewards/rejected": -3.3085663318634033,
      "step": 8960
    },
    {
      "epoch": 1.6370106761565837,
      "grad_norm": 8.216575622558594,
      "learning_rate": 3.6706575796647636e-05,
      "logits/chosen": -1.0565153360366821,
      "logits/rejected": -0.9934894442558289,
      "logps/chosen": -165.33860778808594,
      "logps/rejected": -168.36599731445312,
      "loss": 0.4593,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4966812133789062,
      "rewards/margins": 1.6426277160644531,
      "rewards/rejected": -3.1393089294433594,
      "step": 8970
    },
    {
      "epoch": 1.6388356601879734,
      "grad_norm": 2.389235258102417,
      "learning_rate": 3.6657456867440294e-05,
      "logits/chosen": -1.1114696264266968,
      "logits/rejected": -0.9871156811714172,
      "logps/chosen": -165.40069580078125,
      "logps/rejected": -175.0648651123047,
      "loss": 0.4155,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.2659722566604614,
      "rewards/margins": 1.9633222818374634,
      "rewards/rejected": -3.2292943000793457,
      "step": 8980
    },
    {
      "epoch": 1.6406606442193632,
      "grad_norm": 2.182647228240967,
      "learning_rate": 3.6608337938232945e-05,
      "logits/chosen": -1.0600411891937256,
      "logits/rejected": -0.988943874835968,
      "logps/chosen": -138.67245483398438,
      "logps/rejected": -142.55743408203125,
      "loss": 0.5044,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.30451238155365,
      "rewards/margins": 1.701782464981079,
      "rewards/rejected": -3.0062949657440186,
      "step": 8990
    },
    {
      "epoch": 1.642485628250753,
      "grad_norm": 6.428018569946289,
      "learning_rate": 3.65592190090256e-05,
      "logits/chosen": -1.1497786045074463,
      "logits/rejected": -1.099604606628418,
      "logps/chosen": -157.2197723388672,
      "logps/rejected": -163.2703399658203,
      "loss": 0.4808,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.3593666553497314,
      "rewards/margins": 1.5986249446868896,
      "rewards/rejected": -2.957991600036621,
      "step": 9000
    },
    {
      "epoch": 1.6443106122821425,
      "grad_norm": 3.6060361862182617,
      "learning_rate": 3.651010007981827e-05,
      "logits/chosen": -1.1271759271621704,
      "logits/rejected": -1.0160940885543823,
      "logps/chosen": -177.67013549804688,
      "logps/rejected": -152.13096618652344,
      "loss": 0.3823,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.1222602128982544,
      "rewards/margins": 1.7657970190048218,
      "rewards/rejected": -2.888057231903076,
      "step": 9010
    },
    {
      "epoch": 1.6461355963135322,
      "grad_norm": 2.8741164207458496,
      "learning_rate": 3.646098115061092e-05,
      "logits/chosen": -1.1754628419876099,
      "logits/rejected": -1.1007224321365356,
      "logps/chosen": -165.63436889648438,
      "logps/rejected": -153.99481201171875,
      "loss": 0.5351,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.6276041269302368,
      "rewards/margins": 1.099561333656311,
      "rewards/rejected": -1.7271654605865479,
      "step": 9020
    },
    {
      "epoch": 1.647960580344922,
      "grad_norm": 4.4589924812316895,
      "learning_rate": 3.6411862221403576e-05,
      "logits/chosen": -1.1700570583343506,
      "logits/rejected": -1.0941401720046997,
      "logps/chosen": -155.6227569580078,
      "logps/rejected": -148.57595825195312,
      "loss": 0.4004,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.3554108738899231,
      "rewards/margins": 1.6129783391952515,
      "rewards/rejected": -1.9683891534805298,
      "step": 9030
    },
    {
      "epoch": 1.6497855643763117,
      "grad_norm": 4.880678176879883,
      "learning_rate": 3.6362743292196234e-05,
      "logits/chosen": -1.1194130182266235,
      "logits/rejected": -1.0396848917007446,
      "logps/chosen": -164.88189697265625,
      "logps/rejected": -155.13946533203125,
      "loss": 0.5092,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.49591177701950073,
      "rewards/margins": 1.4603363275527954,
      "rewards/rejected": -1.9562480449676514,
      "step": 9040
    },
    {
      "epoch": 1.6516105484077013,
      "grad_norm": 5.901828765869141,
      "learning_rate": 3.631362436298889e-05,
      "logits/chosen": -1.1273632049560547,
      "logits/rejected": -1.0308289527893066,
      "logps/chosen": -155.04953002929688,
      "logps/rejected": -138.6595001220703,
      "loss": 0.4314,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.513351321220398,
      "rewards/margins": 1.5409904718399048,
      "rewards/rejected": -2.0543417930603027,
      "step": 9050
    },
    {
      "epoch": 1.653435532439091,
      "grad_norm": 5.536700248718262,
      "learning_rate": 3.626450543378154e-05,
      "logits/chosen": -1.0674383640289307,
      "logits/rejected": -0.9778997302055359,
      "logps/chosen": -149.69863891601562,
      "logps/rejected": -138.27566528320312,
      "loss": 0.4463,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8623284101486206,
      "rewards/margins": 1.6092040538787842,
      "rewards/rejected": -2.4715325832366943,
      "step": 9060
    },
    {
      "epoch": 1.6552605164704808,
      "grad_norm": 2.4203732013702393,
      "learning_rate": 3.621538650457421e-05,
      "logits/chosen": -1.1400245428085327,
      "logits/rejected": -0.9744580984115601,
      "logps/chosen": -174.2813720703125,
      "logps/rejected": -153.65298461914062,
      "loss": 0.4167,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9591131210327148,
      "rewards/margins": 1.7406114339828491,
      "rewards/rejected": -2.6997246742248535,
      "step": 9070
    },
    {
      "epoch": 1.6570855005018705,
      "grad_norm": 2.7766876220703125,
      "learning_rate": 3.616626757536686e-05,
      "logits/chosen": -1.0585989952087402,
      "logits/rejected": -0.9641584157943726,
      "logps/chosen": -156.28408813476562,
      "logps/rejected": -168.29388427734375,
      "loss": 0.3447,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.3075388669967651,
      "rewards/margins": 2.0246732234954834,
      "rewards/rejected": -3.332212448120117,
      "step": 9080
    },
    {
      "epoch": 1.6589104845332603,
      "grad_norm": 4.703739166259766,
      "learning_rate": 3.6117148646159516e-05,
      "logits/chosen": -1.0609149932861328,
      "logits/rejected": -0.9812155961990356,
      "logps/chosen": -166.70660400390625,
      "logps/rejected": -159.94068908691406,
      "loss": 0.5079,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.3573403358459473,
      "rewards/margins": 1.5041908025741577,
      "rewards/rejected": -2.8615312576293945,
      "step": 9090
    },
    {
      "epoch": 1.66073546856465,
      "grad_norm": 4.150598049163818,
      "learning_rate": 3.606802971695217e-05,
      "logits/chosen": -1.028483510017395,
      "logits/rejected": -0.9490413665771484,
      "logps/chosen": -142.39306640625,
      "logps/rejected": -143.7904815673828,
      "loss": 0.346,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.1673752069473267,
      "rewards/margins": 1.790065050125122,
      "rewards/rejected": -2.9574403762817383,
      "step": 9100
    },
    {
      "epoch": 1.6625604525960398,
      "grad_norm": 3.022249221801758,
      "learning_rate": 3.601891078774483e-05,
      "logits/chosen": -1.0850017070770264,
      "logits/rejected": -1.025730848312378,
      "logps/chosen": -149.82798767089844,
      "logps/rejected": -159.6288604736328,
      "loss": 0.3742,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.0079280138015747,
      "rewards/margins": 1.8947557210922241,
      "rewards/rejected": -2.902683734893799,
      "step": 9110
    },
    {
      "epoch": 1.6643854366274295,
      "grad_norm": 3.173585891723633,
      "learning_rate": 3.596979185853749e-05,
      "logits/chosen": -1.0872266292572021,
      "logits/rejected": -0.9945874214172363,
      "logps/chosen": -153.34579467773438,
      "logps/rejected": -160.9937286376953,
      "loss": 0.3834,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.093388319015503,
      "rewards/margins": 2.075183868408203,
      "rewards/rejected": -3.168572187423706,
      "step": 9120
    },
    {
      "epoch": 1.6662104206588193,
      "grad_norm": 5.399106979370117,
      "learning_rate": 3.592067292933014e-05,
      "logits/chosen": -1.1390966176986694,
      "logits/rejected": -1.0618321895599365,
      "logps/chosen": -162.5413055419922,
      "logps/rejected": -161.0989227294922,
      "loss": 0.448,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2341665029525757,
      "rewards/margins": 1.7008476257324219,
      "rewards/rejected": -2.935014247894287,
      "step": 9130
    },
    {
      "epoch": 1.668035404690209,
      "grad_norm": 2.852191925048828,
      "learning_rate": 3.5871554000122804e-05,
      "logits/chosen": -1.0657590627670288,
      "logits/rejected": -1.0001049041748047,
      "logps/chosen": -155.10296630859375,
      "logps/rejected": -161.70181274414062,
      "loss": 0.4245,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.678640365600586,
      "rewards/margins": 1.751814842224121,
      "rewards/rejected": -3.430455446243286,
      "step": 9140
    },
    {
      "epoch": 1.6698603887215988,
      "grad_norm": 6.724295616149902,
      "learning_rate": 3.5822435070915455e-05,
      "logits/chosen": -1.0703723430633545,
      "logits/rejected": -1.0080235004425049,
      "logps/chosen": -170.69802856445312,
      "logps/rejected": -171.0294189453125,
      "loss": 0.6087,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8369276523590088,
      "rewards/margins": 1.3466989994049072,
      "rewards/rejected": -3.183626890182495,
      "step": 9150
    },
    {
      "epoch": 1.6716853727529886,
      "grad_norm": 4.449195384979248,
      "learning_rate": 3.577331614170811e-05,
      "logits/chosen": -1.0979191064834595,
      "logits/rejected": -0.9808675050735474,
      "logps/chosen": -173.73898315429688,
      "logps/rejected": -152.74716186523438,
      "loss": 0.4107,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7959139347076416,
      "rewards/margins": 1.5167101621627808,
      "rewards/rejected": -3.312623977661133,
      "step": 9160
    },
    {
      "epoch": 1.673510356784378,
      "grad_norm": 4.816799640655518,
      "learning_rate": 3.572419721250077e-05,
      "logits/chosen": -1.035172939300537,
      "logits/rejected": -0.8803361058235168,
      "logps/chosen": -181.1878662109375,
      "logps/rejected": -156.41452026367188,
      "loss": 0.3732,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7328636646270752,
      "rewards/margins": 1.5594193935394287,
      "rewards/rejected": -3.292283296585083,
      "step": 9170
    },
    {
      "epoch": 1.6753353408157678,
      "grad_norm": 6.053293228149414,
      "learning_rate": 3.567507828329343e-05,
      "logits/chosen": -1.058847427368164,
      "logits/rejected": -0.9225835800170898,
      "logps/chosen": -190.588623046875,
      "logps/rejected": -170.9243621826172,
      "loss": 0.3873,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0479016304016113,
      "rewards/margins": 1.7025172710418701,
      "rewards/rejected": -3.7504189014434814,
      "step": 9180
    },
    {
      "epoch": 1.6771603248471576,
      "grad_norm": 3.7555553913116455,
      "learning_rate": 3.5625959354086086e-05,
      "logits/chosen": -0.8918637037277222,
      "logits/rejected": -0.8310931324958801,
      "logps/chosen": -146.743408203125,
      "logps/rejected": -154.81687927246094,
      "loss": 0.4153,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.500643014907837,
      "rewards/margins": 1.823667287826538,
      "rewards/rejected": -3.324310302734375,
      "step": 9190
    },
    {
      "epoch": 1.6789853088785474,
      "grad_norm": 5.967940330505371,
      "learning_rate": 3.557684042487874e-05,
      "logits/chosen": -0.9043431282043457,
      "logits/rejected": -0.767363429069519,
      "logps/chosen": -148.80307006835938,
      "logps/rejected": -140.83694458007812,
      "loss": 0.3281,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.824090600013733,
      "rewards/margins": 1.7222187519073486,
      "rewards/rejected": -3.546309232711792,
      "step": 9200
    },
    {
      "epoch": 1.6808102929099369,
      "grad_norm": 7.101417541503906,
      "learning_rate": 3.55277214956714e-05,
      "logits/chosen": -0.947348415851593,
      "logits/rejected": -0.8888101577758789,
      "logps/chosen": -143.89913940429688,
      "logps/rejected": -166.10037231445312,
      "loss": 0.434,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.816380500793457,
      "rewards/margins": 1.9843448400497437,
      "rewards/rejected": -3.800725221633911,
      "step": 9210
    },
    {
      "epoch": 1.6826352769413266,
      "grad_norm": 4.311479568481445,
      "learning_rate": 3.547860256646405e-05,
      "logits/chosen": -0.9277859926223755,
      "logits/rejected": -0.8513065576553345,
      "logps/chosen": -155.8479766845703,
      "logps/rejected": -172.9590606689453,
      "loss": 0.452,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.1135754585266113,
      "rewards/margins": 1.7590796947479248,
      "rewards/rejected": -3.872655153274536,
      "step": 9220
    },
    {
      "epoch": 1.6844602609727164,
      "grad_norm": 1.9601824283599854,
      "learning_rate": 3.542948363725671e-05,
      "logits/chosen": -0.9179071187973022,
      "logits/rejected": -0.8494462966918945,
      "logps/chosen": -153.3507537841797,
      "logps/rejected": -165.6363067626953,
      "loss": 0.354,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.4365203380584717,
      "rewards/margins": 1.9688999652862549,
      "rewards/rejected": -3.4054207801818848,
      "step": 9230
    },
    {
      "epoch": 1.6862852450041061,
      "grad_norm": 5.60889196395874,
      "learning_rate": 3.538036470804937e-05,
      "logits/chosen": -0.9205824732780457,
      "logits/rejected": -0.8602570295333862,
      "logps/chosen": -155.70533752441406,
      "logps/rejected": -175.54708862304688,
      "loss": 0.4652,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.713436484336853,
      "rewards/margins": 1.9040660858154297,
      "rewards/rejected": -3.6175029277801514,
      "step": 9240
    },
    {
      "epoch": 1.688110229035496,
      "grad_norm": 5.6852803230285645,
      "learning_rate": 3.5331245778842026e-05,
      "logits/chosen": -1.0072205066680908,
      "logits/rejected": -0.8909463882446289,
      "logps/chosen": -171.51747131347656,
      "logps/rejected": -168.2860870361328,
      "loss": 0.3621,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.767822265625,
      "rewards/margins": 1.797965407371521,
      "rewards/rejected": -3.5657875537872314,
      "step": 9250
    },
    {
      "epoch": 1.6899352130668857,
      "grad_norm": 2.9243757724761963,
      "learning_rate": 3.528212684963468e-05,
      "logits/chosen": -0.9365887641906738,
      "logits/rejected": -0.8646224737167358,
      "logps/chosen": -167.3384552001953,
      "logps/rejected": -163.65769958496094,
      "loss": 0.5254,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.128343105316162,
      "rewards/margins": 1.3228405714035034,
      "rewards/rejected": -3.451183795928955,
      "step": 9260
    },
    {
      "epoch": 1.6917601970982754,
      "grad_norm": 4.34527587890625,
      "learning_rate": 3.523300792042734e-05,
      "logits/chosen": -0.9395984411239624,
      "logits/rejected": -0.8849002122879028,
      "logps/chosen": -157.4862518310547,
      "logps/rejected": -173.93466186523438,
      "loss": 0.4134,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0557074546813965,
      "rewards/margins": 1.8623077869415283,
      "rewards/rejected": -3.918015241622925,
      "step": 9270
    },
    {
      "epoch": 1.6935851811296652,
      "grad_norm": 4.257716178894043,
      "learning_rate": 3.518388899121999e-05,
      "logits/chosen": -0.910300076007843,
      "logits/rejected": -0.8187152147293091,
      "logps/chosen": -155.3328399658203,
      "logps/rejected": -158.05758666992188,
      "loss": 0.3836,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.1717798709869385,
      "rewards/margins": 1.704646348953247,
      "rewards/rejected": -3.8764259815216064,
      "step": 9280
    },
    {
      "epoch": 1.695410165161055,
      "grad_norm": 6.519165992736816,
      "learning_rate": 3.513477006201265e-05,
      "logits/chosen": -0.9043475985527039,
      "logits/rejected": -0.7759668827056885,
      "logps/chosen": -170.75926208496094,
      "logps/rejected": -166.9020233154297,
      "loss": 0.3629,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.281083106994629,
      "rewards/margins": 1.7794325351715088,
      "rewards/rejected": -4.060515403747559,
      "step": 9290
    },
    {
      "epoch": 1.6972351491924447,
      "grad_norm": 4.550633907318115,
      "learning_rate": 3.508565113280531e-05,
      "logits/chosen": -0.9689450263977051,
      "logits/rejected": -0.9103794097900391,
      "logps/chosen": -155.54736328125,
      "logps/rejected": -161.28077697753906,
      "loss": 0.4481,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.036491870880127,
      "rewards/margins": 1.4517462253570557,
      "rewards/rejected": -3.4882380962371826,
      "step": 9300
    },
    {
      "epoch": 1.6990601332238344,
      "grad_norm": 2.808603048324585,
      "learning_rate": 3.5036532203597965e-05,
      "logits/chosen": -0.9167836904525757,
      "logits/rejected": -0.9089013934135437,
      "logps/chosen": -166.28858947753906,
      "logps/rejected": -184.2261962890625,
      "loss": 0.2805,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5049718618392944,
      "rewards/margins": 2.0447168350219727,
      "rewards/rejected": -3.5496883392333984,
      "step": 9310
    },
    {
      "epoch": 1.7008851172552242,
      "grad_norm": 4.363058090209961,
      "learning_rate": 3.498741327439062e-05,
      "logits/chosen": -1.061976671218872,
      "logits/rejected": -0.9079689979553223,
      "logps/chosen": -170.64596557617188,
      "logps/rejected": -156.82681274414062,
      "loss": 0.3438,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6672801971435547,
      "rewards/margins": 2.1652777194976807,
      "rewards/rejected": -3.8325581550598145,
      "step": 9320
    },
    {
      "epoch": 1.7027101012866137,
      "grad_norm": 4.707680702209473,
      "learning_rate": 3.4938294345183274e-05,
      "logits/chosen": -1.0772076845169067,
      "logits/rejected": -0.9367473721504211,
      "logps/chosen": -164.5189208984375,
      "logps/rejected": -153.7248077392578,
      "loss": 0.4598,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.494077205657959,
      "rewards/margins": 1.8476755619049072,
      "rewards/rejected": -3.341752290725708,
      "step": 9330
    },
    {
      "epoch": 1.7045350853180035,
      "grad_norm": 4.147579193115234,
      "learning_rate": 3.488917541597594e-05,
      "logits/chosen": -1.0216422080993652,
      "logits/rejected": -0.9668118357658386,
      "logps/chosen": -163.90443420410156,
      "logps/rejected": -154.0954132080078,
      "loss": 0.5456,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.0877249240875244,
      "rewards/margins": 1.187139868736267,
      "rewards/rejected": -3.274864912033081,
      "step": 9340
    },
    {
      "epoch": 1.7063600693493932,
      "grad_norm": 7.474943161010742,
      "learning_rate": 3.484005648676859e-05,
      "logits/chosen": -1.099269151687622,
      "logits/rejected": -1.0422613620758057,
      "logps/chosen": -156.26502990722656,
      "logps/rejected": -164.7880401611328,
      "loss": 0.5001,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.6686995029449463,
      "rewards/margins": 1.4381693601608276,
      "rewards/rejected": -3.1068687438964844,
      "step": 9350
    },
    {
      "epoch": 1.708185053380783,
      "grad_norm": 3.0510904788970947,
      "learning_rate": 3.479093755756125e-05,
      "logits/chosen": -1.094144582748413,
      "logits/rejected": -0.9510099291801453,
      "logps/chosen": -181.27085876464844,
      "logps/rejected": -169.6477508544922,
      "loss": 0.5098,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7190042734146118,
      "rewards/margins": 1.2476894855499268,
      "rewards/rejected": -2.966693878173828,
      "step": 9360
    },
    {
      "epoch": 1.7100100374121725,
      "grad_norm": 4.7601318359375,
      "learning_rate": 3.4741818628353905e-05,
      "logits/chosen": -1.0503075122833252,
      "logits/rejected": -0.9313374757766724,
      "logps/chosen": -159.66880798339844,
      "logps/rejected": -152.64645385742188,
      "loss": 0.3912,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.2912342548370361,
      "rewards/margins": 1.6954615116119385,
      "rewards/rejected": -2.9866957664489746,
      "step": 9370
    },
    {
      "epoch": 1.7118350214435623,
      "grad_norm": 4.833506107330322,
      "learning_rate": 3.469269969914656e-05,
      "logits/chosen": -1.0334805250167847,
      "logits/rejected": -0.9266504049301147,
      "logps/chosen": -152.8125,
      "logps/rejected": -154.13262939453125,
      "loss": 0.4621,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.696862816810608,
      "rewards/margins": 1.6278259754180908,
      "rewards/rejected": -3.3246891498565674,
      "step": 9380
    },
    {
      "epoch": 1.713660005474952,
      "grad_norm": 5.564366817474365,
      "learning_rate": 3.464358076993922e-05,
      "logits/chosen": -1.0466909408569336,
      "logits/rejected": -0.9190706014633179,
      "logps/chosen": -171.90036010742188,
      "logps/rejected": -153.6731414794922,
      "loss": 0.4412,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4432069063186646,
      "rewards/margins": 1.5542125701904297,
      "rewards/rejected": -2.9974193572998047,
      "step": 9390
    },
    {
      "epoch": 1.7154849895063418,
      "grad_norm": 4.041109561920166,
      "learning_rate": 3.459446184073187e-05,
      "logits/chosen": -1.0829308032989502,
      "logits/rejected": -1.034821629524231,
      "logps/chosen": -155.16038513183594,
      "logps/rejected": -163.87081909179688,
      "loss": 0.4824,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.304473876953125,
      "rewards/margins": 1.535064458847046,
      "rewards/rejected": -2.839538335800171,
      "step": 9400
    },
    {
      "epoch": 1.7173099735377315,
      "grad_norm": 2.632580518722534,
      "learning_rate": 3.4545342911524536e-05,
      "logits/chosen": -1.0151455402374268,
      "logits/rejected": -0.9150257110595703,
      "logps/chosen": -152.56344604492188,
      "logps/rejected": -141.02029418945312,
      "loss": 0.4658,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.434649109840393,
      "rewards/margins": 1.4785000085830688,
      "rewards/rejected": -2.913149356842041,
      "step": 9410
    },
    {
      "epoch": 1.7191349575691213,
      "grad_norm": 3.9190917015075684,
      "learning_rate": 3.449622398231719e-05,
      "logits/chosen": -1.0601106882095337,
      "logits/rejected": -0.9891935586929321,
      "logps/chosen": -167.6368408203125,
      "logps/rejected": -155.10121154785156,
      "loss": 0.4526,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3235363960266113,
      "rewards/margins": 1.4651734828948975,
      "rewards/rejected": -2.7887096405029297,
      "step": 9420
    },
    {
      "epoch": 1.720959941600511,
      "grad_norm": 4.602712154388428,
      "learning_rate": 3.4447105053109845e-05,
      "logits/chosen": -1.016194462776184,
      "logits/rejected": -0.9578466415405273,
      "logps/chosen": -150.07313537597656,
      "logps/rejected": -161.01943969726562,
      "loss": 0.4139,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.7703964710235596,
      "rewards/margins": 1.5061818361282349,
      "rewards/rejected": -3.276578187942505,
      "step": 9430
    },
    {
      "epoch": 1.7227849256319008,
      "grad_norm": 2.2908012866973877,
      "learning_rate": 3.43979861239025e-05,
      "logits/chosen": -1.0486385822296143,
      "logits/rejected": -0.9526376724243164,
      "logps/chosen": -153.27511596679688,
      "logps/rejected": -165.02499389648438,
      "loss": 0.4974,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5418567657470703,
      "rewards/margins": 1.627994179725647,
      "rewards/rejected": -3.1698508262634277,
      "step": 9440
    },
    {
      "epoch": 1.7246099096632905,
      "grad_norm": 2.8487401008605957,
      "learning_rate": 3.434886719469516e-05,
      "logits/chosen": -1.030872106552124,
      "logits/rejected": -0.9609950184822083,
      "logps/chosen": -158.8653564453125,
      "logps/rejected": -155.41995239257812,
      "loss": 0.4158,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1265017986297607,
      "rewards/margins": 1.3155776262283325,
      "rewards/rejected": -2.4420793056488037,
      "step": 9450
    },
    {
      "epoch": 1.7264348936946803,
      "grad_norm": 4.682835578918457,
      "learning_rate": 3.429974826548781e-05,
      "logits/chosen": -1.0469666719436646,
      "logits/rejected": -0.9576665759086609,
      "logps/chosen": -146.9369659423828,
      "logps/rejected": -156.31024169921875,
      "loss": 0.4148,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9865278005599976,
      "rewards/margins": 1.5199676752090454,
      "rewards/rejected": -2.506495475769043,
      "step": 9460
    },
    {
      "epoch": 1.72825987772607,
      "grad_norm": 5.891817569732666,
      "learning_rate": 3.425062933628047e-05,
      "logits/chosen": -1.1044541597366333,
      "logits/rejected": -1.045894980430603,
      "logps/chosen": -139.77194213867188,
      "logps/rejected": -148.7848663330078,
      "loss": 0.3726,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0243232250213623,
      "rewards/margins": 1.6062161922454834,
      "rewards/rejected": -2.630539655685425,
      "step": 9470
    },
    {
      "epoch": 1.7300848617574596,
      "grad_norm": 3.9781901836395264,
      "learning_rate": 3.420151040707313e-05,
      "logits/chosen": -1.0762370824813843,
      "logits/rejected": -0.9778674840927124,
      "logps/chosen": -153.84898376464844,
      "logps/rejected": -153.91055297851562,
      "loss": 0.3532,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.3437893390655518,
      "rewards/margins": 1.8028161525726318,
      "rewards/rejected": -3.1466052532196045,
      "step": 9480
    },
    {
      "epoch": 1.7319098457888493,
      "grad_norm": 3.578181028366089,
      "learning_rate": 3.4152391477865784e-05,
      "logits/chosen": -1.0508582592010498,
      "logits/rejected": -0.9213060140609741,
      "logps/chosen": -150.18081665039062,
      "logps/rejected": -141.31637573242188,
      "loss": 0.3952,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2844641208648682,
      "rewards/margins": 1.7636102437973022,
      "rewards/rejected": -3.04807448387146,
      "step": 9490
    },
    {
      "epoch": 1.733734829820239,
      "grad_norm": 2.493380069732666,
      "learning_rate": 3.410327254865844e-05,
      "logits/chosen": -1.0471898317337036,
      "logits/rejected": -1.000882863998413,
      "logps/chosen": -158.40042114257812,
      "logps/rejected": -167.47317504882812,
      "loss": 0.3706,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.1498264074325562,
      "rewards/margins": 1.7328885793685913,
      "rewards/rejected": -2.8827147483825684,
      "step": 9500
    },
    {
      "epoch": 1.7355598138516288,
      "grad_norm": 4.456913948059082,
      "learning_rate": 3.40541536194511e-05,
      "logits/chosen": -1.0619256496429443,
      "logits/rejected": -0.9587308764457703,
      "logps/chosen": -184.6564178466797,
      "logps/rejected": -168.0484619140625,
      "loss": 0.4133,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.476440668106079,
      "rewards/margins": 1.753307580947876,
      "rewards/rejected": -3.229748249053955,
      "step": 9510
    },
    {
      "epoch": 1.7373847978830184,
      "grad_norm": 5.881031036376953,
      "learning_rate": 3.400503469024376e-05,
      "logits/chosen": -1.0893669128417969,
      "logits/rejected": -1.0081465244293213,
      "logps/chosen": -160.33753967285156,
      "logps/rejected": -157.66995239257812,
      "loss": 0.47,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2989990711212158,
      "rewards/margins": 1.5744349956512451,
      "rewards/rejected": -2.873434066772461,
      "step": 9520
    },
    {
      "epoch": 1.7392097819144081,
      "grad_norm": 3.5189900398254395,
      "learning_rate": 3.395591576103641e-05,
      "logits/chosen": -1.1233642101287842,
      "logits/rejected": -1.0528948307037354,
      "logps/chosen": -178.34384155273438,
      "logps/rejected": -169.86434936523438,
      "loss": 0.5191,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.5259063243865967,
      "rewards/margins": 1.5129724740982056,
      "rewards/rejected": -3.0388786792755127,
      "step": 9530
    },
    {
      "epoch": 1.7410347659457979,
      "grad_norm": 4.608268737792969,
      "learning_rate": 3.390679683182907e-05,
      "logits/chosen": -1.091115951538086,
      "logits/rejected": -0.9772307276725769,
      "logps/chosen": -153.61322021484375,
      "logps/rejected": -152.32785034179688,
      "loss": 0.4619,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5374605655670166,
      "rewards/margins": 1.4915250539779663,
      "rewards/rejected": -3.0289855003356934,
      "step": 9540
    },
    {
      "epoch": 1.7428597499771876,
      "grad_norm": 6.478460788726807,
      "learning_rate": 3.3857677902621724e-05,
      "logits/chosen": -1.039705514907837,
      "logits/rejected": -0.9863790273666382,
      "logps/chosen": -147.7708282470703,
      "logps/rejected": -162.4139404296875,
      "loss": 0.5094,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7853740453720093,
      "rewards/margins": 1.4511339664459229,
      "rewards/rejected": -2.2365078926086426,
      "step": 9550
    },
    {
      "epoch": 1.7446847340085774,
      "grad_norm": 3.1402587890625,
      "learning_rate": 3.380855897341438e-05,
      "logits/chosen": -1.1197706460952759,
      "logits/rejected": -1.0070689916610718,
      "logps/chosen": -152.81143188476562,
      "logps/rejected": -139.1672821044922,
      "loss": 0.3973,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.2406842708587646,
      "rewards/margins": 1.7343213558197021,
      "rewards/rejected": -2.975005626678467,
      "step": 9560
    },
    {
      "epoch": 1.7465097180399671,
      "grad_norm": 3.0775387287139893,
      "learning_rate": 3.375944004420704e-05,
      "logits/chosen": -1.088289499282837,
      "logits/rejected": -0.9708496928215027,
      "logps/chosen": -170.43702697753906,
      "logps/rejected": -146.59754943847656,
      "loss": 0.4972,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.1246049404144287,
      "rewards/margins": 1.4088090658187866,
      "rewards/rejected": -2.533414363861084,
      "step": 9570
    },
    {
      "epoch": 1.7483347020713569,
      "grad_norm": 4.089452743530273,
      "learning_rate": 3.37103211149997e-05,
      "logits/chosen": -1.0901286602020264,
      "logits/rejected": -0.9624189138412476,
      "logps/chosen": -157.97390747070312,
      "logps/rejected": -142.8560028076172,
      "loss": 0.3876,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.8664683103561401,
      "rewards/margins": 1.7356961965560913,
      "rewards/rejected": -2.6021645069122314,
      "step": 9580
    },
    {
      "epoch": 1.7501596861027466,
      "grad_norm": 5.071392059326172,
      "learning_rate": 3.3661202185792355e-05,
      "logits/chosen": -1.0786972045898438,
      "logits/rejected": -0.9372517466545105,
      "logps/chosen": -165.28182983398438,
      "logps/rejected": -144.00283813476562,
      "loss": 0.4024,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.046262502670288,
      "rewards/margins": 1.9124424457550049,
      "rewards/rejected": -2.958704948425293,
      "step": 9590
    },
    {
      "epoch": 1.7519846701341364,
      "grad_norm": 3.519887685775757,
      "learning_rate": 3.3612083256585006e-05,
      "logits/chosen": -1.1402106285095215,
      "logits/rejected": -1.0381886959075928,
      "logps/chosen": -148.30697631835938,
      "logps/rejected": -145.31964111328125,
      "loss": 0.4712,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9338197708129883,
      "rewards/margins": 1.52400803565979,
      "rewards/rejected": -2.4578278064727783,
      "step": 9600
    },
    {
      "epoch": 1.7538096541655261,
      "grad_norm": 4.334935188293457,
      "learning_rate": 3.356296432737767e-05,
      "logits/chosen": -1.117558479309082,
      "logits/rejected": -1.046949028968811,
      "logps/chosen": -154.15628051757812,
      "logps/rejected": -151.95474243164062,
      "loss": 0.4229,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.0047273635864258,
      "rewards/margins": 1.3405815362930298,
      "rewards/rejected": -2.345308542251587,
      "step": 9610
    },
    {
      "epoch": 1.755634638196916,
      "grad_norm": 2.4757444858551025,
      "learning_rate": 3.351384539817032e-05,
      "logits/chosen": -1.0398443937301636,
      "logits/rejected": -0.9938567280769348,
      "logps/chosen": -160.606689453125,
      "logps/rejected": -165.5428466796875,
      "loss": 0.4686,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2296786308288574,
      "rewards/margins": 1.485929250717163,
      "rewards/rejected": -2.7156076431274414,
      "step": 9620
    },
    {
      "epoch": 1.7574596222283057,
      "grad_norm": 5.078697204589844,
      "learning_rate": 3.346472646896298e-05,
      "logits/chosen": -1.0503590106964111,
      "logits/rejected": -0.9747398495674133,
      "logps/chosen": -155.58824157714844,
      "logps/rejected": -169.45169067382812,
      "loss": 0.4665,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7702430486679077,
      "rewards/margins": 1.4319634437561035,
      "rewards/rejected": -3.20220685005188,
      "step": 9630
    },
    {
      "epoch": 1.7592846062596952,
      "grad_norm": 4.574155807495117,
      "learning_rate": 3.341560753975564e-05,
      "logits/chosen": -1.1559770107269287,
      "logits/rejected": -1.0765300989151,
      "logps/chosen": -163.118408203125,
      "logps/rejected": -160.68533325195312,
      "loss": 0.3575,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.3305423259735107,
      "rewards/margins": 1.7814152240753174,
      "rewards/rejected": -3.1119580268859863,
      "step": 9640
    },
    {
      "epoch": 1.761109590291085,
      "grad_norm": 3.4115068912506104,
      "learning_rate": 3.3366488610548294e-05,
      "logits/chosen": -1.0578258037567139,
      "logits/rejected": -0.9808723330497742,
      "logps/chosen": -149.43997192382812,
      "logps/rejected": -162.04287719726562,
      "loss": 0.4941,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.612073540687561,
      "rewards/margins": 1.6195743083953857,
      "rewards/rejected": -3.231647491455078,
      "step": 9650
    },
    {
      "epoch": 1.7629345743224747,
      "grad_norm": 5.256811141967773,
      "learning_rate": 3.3317369681340945e-05,
      "logits/chosen": -1.059398889541626,
      "logits/rejected": -0.9322636723518372,
      "logps/chosen": -170.6243896484375,
      "logps/rejected": -173.32122802734375,
      "loss": 0.4524,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.641740083694458,
      "rewards/margins": 1.7119534015655518,
      "rewards/rejected": -3.3536934852600098,
      "step": 9660
    },
    {
      "epoch": 1.7647595583538644,
      "grad_norm": 4.736235618591309,
      "learning_rate": 3.32682507521336e-05,
      "logits/chosen": -1.020607352256775,
      "logits/rejected": -0.9211544990539551,
      "logps/chosen": -158.86180114746094,
      "logps/rejected": -163.3187255859375,
      "loss": 0.4405,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4317305088043213,
      "rewards/margins": 1.4405014514923096,
      "rewards/rejected": -2.872231960296631,
      "step": 9670
    },
    {
      "epoch": 1.766584542385254,
      "grad_norm": 3.638056516647339,
      "learning_rate": 3.321913182292627e-05,
      "logits/chosen": -1.0657212734222412,
      "logits/rejected": -0.947590172290802,
      "logps/chosen": -148.8752899169922,
      "logps/rejected": -155.5466766357422,
      "loss": 0.413,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.428588628768921,
      "rewards/margins": 1.679019570350647,
      "rewards/rejected": -3.1076083183288574,
      "step": 9680
    },
    {
      "epoch": 1.7684095264166437,
      "grad_norm": 6.8739914894104,
      "learning_rate": 3.317001289371892e-05,
      "logits/chosen": -1.0081303119659424,
      "logits/rejected": -0.9322269558906555,
      "logps/chosen": -158.2216033935547,
      "logps/rejected": -155.73304748535156,
      "loss": 0.5295,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.6556657552719116,
      "rewards/margins": 1.4666327238082886,
      "rewards/rejected": -3.1222987174987793,
      "step": 9690
    },
    {
      "epoch": 1.7702345104480335,
      "grad_norm": 3.525570869445801,
      "learning_rate": 3.3120893964511576e-05,
      "logits/chosen": -1.0357921123504639,
      "logits/rejected": -0.8821075558662415,
      "logps/chosen": -165.468994140625,
      "logps/rejected": -144.30311584472656,
      "loss": 0.4625,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8341118097305298,
      "rewards/margins": 1.3259607553482056,
      "rewards/rejected": -3.1600723266601562,
      "step": 9700
    },
    {
      "epoch": 1.7720594944794232,
      "grad_norm": 4.977239608764648,
      "learning_rate": 3.3071775035304234e-05,
      "logits/chosen": -1.022844672203064,
      "logits/rejected": -0.9762349128723145,
      "logps/chosen": -171.41929626464844,
      "logps/rejected": -169.55233764648438,
      "loss": 0.4581,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.071624279022217,
      "rewards/margins": 1.333146572113037,
      "rewards/rejected": -3.404770612716675,
      "step": 9710
    },
    {
      "epoch": 1.773884478510813,
      "grad_norm": 2.237063407897949,
      "learning_rate": 3.302265610609689e-05,
      "logits/chosen": -1.1369234323501587,
      "logits/rejected": -1.0502086877822876,
      "logps/chosen": -163.73724365234375,
      "logps/rejected": -172.59616088867188,
      "loss": 0.4421,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5490293502807617,
      "rewards/margins": 1.6471372842788696,
      "rewards/rejected": -3.196166515350342,
      "step": 9720
    },
    {
      "epoch": 1.7757094625422027,
      "grad_norm": 1.5939843654632568,
      "learning_rate": 3.297353717688954e-05,
      "logits/chosen": -1.0438776016235352,
      "logits/rejected": -0.9880115389823914,
      "logps/chosen": -157.16140747070312,
      "logps/rejected": -170.45669555664062,
      "loss": 0.5232,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.0622589588165283,
      "rewards/margins": 1.3626105785369873,
      "rewards/rejected": -3.4248690605163574,
      "step": 9730
    },
    {
      "epoch": 1.7775344465735925,
      "grad_norm": 7.464351177215576,
      "learning_rate": 3.292441824768221e-05,
      "logits/chosen": -1.0475934743881226,
      "logits/rejected": -0.9409141540527344,
      "logps/chosen": -162.16848754882812,
      "logps/rejected": -170.9925537109375,
      "loss": 0.4792,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9274307489395142,
      "rewards/margins": 1.5295146703720093,
      "rewards/rejected": -3.4569454193115234,
      "step": 9740
    },
    {
      "epoch": 1.7793594306049823,
      "grad_norm": 3.787379503250122,
      "learning_rate": 3.287529931847486e-05,
      "logits/chosen": -1.0396279096603394,
      "logits/rejected": -0.9457577466964722,
      "logps/chosen": -168.03468322753906,
      "logps/rejected": -155.32754516601562,
      "loss": 0.4633,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.441650629043579,
      "rewards/margins": 1.3313319683074951,
      "rewards/rejected": -3.7729828357696533,
      "step": 9750
    },
    {
      "epoch": 1.781184414636372,
      "grad_norm": 5.851569652557373,
      "learning_rate": 3.2826180389267516e-05,
      "logits/chosen": -1.1554944515228271,
      "logits/rejected": -0.9742088317871094,
      "logps/chosen": -175.1822967529297,
      "logps/rejected": -163.03109741210938,
      "loss": 0.3804,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.1707324981689453,
      "rewards/margins": 1.6729463338851929,
      "rewards/rejected": -3.8436789512634277,
      "step": 9760
    },
    {
      "epoch": 1.7830093986677618,
      "grad_norm": 4.72773551940918,
      "learning_rate": 3.2777061460060174e-05,
      "logits/chosen": -1.0458176136016846,
      "logits/rejected": -0.9174546003341675,
      "logps/chosen": -174.25086975097656,
      "logps/rejected": -156.9633026123047,
      "loss": 0.4069,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.662384510040283,
      "rewards/margins": 1.4822826385498047,
      "rewards/rejected": -4.14466667175293,
      "step": 9770
    },
    {
      "epoch": 1.7848343826991515,
      "grad_norm": 4.779432773590088,
      "learning_rate": 3.272794253085283e-05,
      "logits/chosen": -1.1257855892181396,
      "logits/rejected": -1.0291153192520142,
      "logps/chosen": -179.60972595214844,
      "logps/rejected": -164.3541717529297,
      "loss": 0.5011,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.4735257625579834,
      "rewards/margins": 1.5109684467315674,
      "rewards/rejected": -3.98449444770813,
      "step": 9780
    },
    {
      "epoch": 1.7866593667305413,
      "grad_norm": 4.458256721496582,
      "learning_rate": 3.267882360164549e-05,
      "logits/chosen": -1.0142276287078857,
      "logits/rejected": -0.9235814213752747,
      "logps/chosen": -156.78561401367188,
      "logps/rejected": -164.47520446777344,
      "loss": 0.4381,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.199455738067627,
      "rewards/margins": 1.6553035974502563,
      "rewards/rejected": -3.854759931564331,
      "step": 9790
    },
    {
      "epoch": 1.7884843507619308,
      "grad_norm": 3.9753665924072266,
      "learning_rate": 3.262970467243814e-05,
      "logits/chosen": -1.05440092086792,
      "logits/rejected": -0.9470330476760864,
      "logps/chosen": -161.50424194335938,
      "logps/rejected": -154.0733184814453,
      "loss": 0.4955,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.0625462532043457,
      "rewards/margins": 1.4880774021148682,
      "rewards/rejected": -3.550624132156372,
      "step": 9800
    },
    {
      "epoch": 1.7903093347933206,
      "grad_norm": 4.796015739440918,
      "learning_rate": 3.2580585743230804e-05,
      "logits/chosen": -1.0024795532226562,
      "logits/rejected": -0.945804238319397,
      "logps/chosen": -159.8993377685547,
      "logps/rejected": -171.22470092773438,
      "loss": 0.5349,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.212951183319092,
      "rewards/margins": 1.2688384056091309,
      "rewards/rejected": -3.4817898273468018,
      "step": 9810
    },
    {
      "epoch": 1.7921343188247103,
      "grad_norm": 5.462059020996094,
      "learning_rate": 3.2531466814023455e-05,
      "logits/chosen": -1.020566463470459,
      "logits/rejected": -0.9405986070632935,
      "logps/chosen": -151.4466552734375,
      "logps/rejected": -152.97360229492188,
      "loss": 0.4686,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.941175103187561,
      "rewards/margins": 1.403093934059143,
      "rewards/rejected": -3.344269275665283,
      "step": 9820
    },
    {
      "epoch": 1.7939593028561,
      "grad_norm": 3.330930233001709,
      "learning_rate": 3.248234788481611e-05,
      "logits/chosen": -1.0551706552505493,
      "logits/rejected": -0.9509899020195007,
      "logps/chosen": -162.95120239257812,
      "logps/rejected": -160.4300537109375,
      "loss": 0.4334,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.0952811241149902,
      "rewards/margins": 1.5797936916351318,
      "rewards/rejected": -3.675074815750122,
      "step": 9830
    },
    {
      "epoch": 1.7957842868874896,
      "grad_norm": 3.83130145072937,
      "learning_rate": 3.243322895560877e-05,
      "logits/chosen": -1.113887071609497,
      "logits/rejected": -0.9916974902153015,
      "logps/chosen": -164.8136444091797,
      "logps/rejected": -146.75869750976562,
      "loss": 0.4252,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6702978610992432,
      "rewards/margins": 1.6553055047988892,
      "rewards/rejected": -3.325603485107422,
      "step": 9840
    },
    {
      "epoch": 1.7976092709188793,
      "grad_norm": 6.061430931091309,
      "learning_rate": 3.238411002640143e-05,
      "logits/chosen": -1.0646789073944092,
      "logits/rejected": -0.9846227765083313,
      "logps/chosen": -157.7501983642578,
      "logps/rejected": -163.02952575683594,
      "loss": 0.4771,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9173219203948975,
      "rewards/margins": 1.5329368114471436,
      "rewards/rejected": -3.45025897026062,
      "step": 9850
    },
    {
      "epoch": 1.799434254950269,
      "grad_norm": 3.4500882625579834,
      "learning_rate": 3.233499109719408e-05,
      "logits/chosen": -1.1215324401855469,
      "logits/rejected": -1.0010994672775269,
      "logps/chosen": -155.7028045654297,
      "logps/rejected": -160.22731018066406,
      "loss": 0.3549,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.3521651029586792,
      "rewards/margins": 2.0115511417388916,
      "rewards/rejected": -3.3637161254882812,
      "step": 9860
    },
    {
      "epoch": 1.8012592389816589,
      "grad_norm": 4.5726637840271,
      "learning_rate": 3.228587216798674e-05,
      "logits/chosen": -1.0932825803756714,
      "logits/rejected": -0.9498313665390015,
      "logps/chosen": -163.95535278320312,
      "logps/rejected": -149.35061645507812,
      "loss": 0.3369,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.7820112705230713,
      "rewards/margins": 1.9155384302139282,
      "rewards/rejected": -3.697549343109131,
      "step": 9870
    },
    {
      "epoch": 1.8030842230130486,
      "grad_norm": 2.7707953453063965,
      "learning_rate": 3.22367532387794e-05,
      "logits/chosen": -1.0376514196395874,
      "logits/rejected": -0.9637683629989624,
      "logps/chosen": -153.5608673095703,
      "logps/rejected": -152.5787811279297,
      "loss": 0.5168,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8166062831878662,
      "rewards/margins": 1.5539419651031494,
      "rewards/rejected": -3.3705482482910156,
      "step": 9880
    },
    {
      "epoch": 1.8049092070444384,
      "grad_norm": 6.486782550811768,
      "learning_rate": 3.218763430957205e-05,
      "logits/chosen": -1.0858345031738281,
      "logits/rejected": -0.9970353245735168,
      "logps/chosen": -153.51522827148438,
      "logps/rejected": -152.6228485107422,
      "loss": 0.43,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6682980060577393,
      "rewards/margins": 1.744397521018982,
      "rewards/rejected": -3.4126956462860107,
      "step": 9890
    },
    {
      "epoch": 1.806734191075828,
      "grad_norm": 4.1641106605529785,
      "learning_rate": 3.213851538036471e-05,
      "logits/chosen": -1.0778300762176514,
      "logits/rejected": -0.9604193568229675,
      "logps/chosen": -168.3807830810547,
      "logps/rejected": -150.36233520507812,
      "loss": 0.3355,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8232570886611938,
      "rewards/margins": 1.7056324481964111,
      "rewards/rejected": -3.5288894176483154,
      "step": 9900
    },
    {
      "epoch": 1.8085591751072179,
      "grad_norm": 2.5922160148620605,
      "learning_rate": 3.208939645115737e-05,
      "logits/chosen": -1.0575153827667236,
      "logits/rejected": -0.9882858991622925,
      "logps/chosen": -155.72767639160156,
      "logps/rejected": -151.42967224121094,
      "loss": 0.3816,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6862573623657227,
      "rewards/margins": 1.8230206966400146,
      "rewards/rejected": -3.509277820587158,
      "step": 9910
    },
    {
      "epoch": 1.8103841591386076,
      "grad_norm": 7.409385681152344,
      "learning_rate": 3.2040277521950026e-05,
      "logits/chosen": -1.1236073970794678,
      "logits/rejected": -1.0316282510757446,
      "logps/chosen": -181.82122802734375,
      "logps/rejected": -168.46975708007812,
      "loss": 0.3924,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.8293135166168213,
      "rewards/margins": 1.7894794940948486,
      "rewards/rejected": -3.61879301071167,
      "step": 9920
    },
    {
      "epoch": 1.8122091431699974,
      "grad_norm": 5.69950532913208,
      "learning_rate": 3.199115859274268e-05,
      "logits/chosen": -1.0273851156234741,
      "logits/rejected": -1.0183104276657104,
      "logps/chosen": -168.51156616210938,
      "logps/rejected": -184.24717712402344,
      "loss": 0.4516,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.924053430557251,
      "rewards/margins": 1.8637406826019287,
      "rewards/rejected": -3.787794589996338,
      "step": 9930
    },
    {
      "epoch": 1.8140341272013871,
      "grad_norm": 2.929065704345703,
      "learning_rate": 3.1942039663535335e-05,
      "logits/chosen": -1.0334498882293701,
      "logits/rejected": -0.9897672533988953,
      "logps/chosen": -157.61502075195312,
      "logps/rejected": -169.3026580810547,
      "loss": 0.5478,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.154940366744995,
      "rewards/margins": 1.5550451278686523,
      "rewards/rejected": -3.7099857330322266,
      "step": 9940
    },
    {
      "epoch": 1.8158591112327769,
      "grad_norm": 4.38686466217041,
      "learning_rate": 3.189292073432799e-05,
      "logits/chosen": -1.0516990423202515,
      "logits/rejected": -0.9252934455871582,
      "logps/chosen": -180.43862915039062,
      "logps/rejected": -171.80740356445312,
      "loss": 0.3851,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0592691898345947,
      "rewards/margins": 2.0345921516418457,
      "rewards/rejected": -4.0938615798950195,
      "step": 9950
    },
    {
      "epoch": 1.8176840952641664,
      "grad_norm": 2.4895474910736084,
      "learning_rate": 3.184380180512065e-05,
      "logits/chosen": -1.0451363325119019,
      "logits/rejected": -0.8811492919921875,
      "logps/chosen": -178.04061889648438,
      "logps/rejected": -165.49954223632812,
      "loss": 0.4134,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.111605167388916,
      "rewards/margins": 1.7972631454467773,
      "rewards/rejected": -3.9088687896728516,
      "step": 9960
    },
    {
      "epoch": 1.8195090792955562,
      "grad_norm": 2.9404497146606445,
      "learning_rate": 3.179468287591331e-05,
      "logits/chosen": -0.985917866230011,
      "logits/rejected": -0.8687885999679565,
      "logps/chosen": -178.7474365234375,
      "logps/rejected": -165.7720489501953,
      "loss": 0.4329,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.9444828033447266,
      "rewards/margins": 1.8426463603973389,
      "rewards/rejected": -3.7871291637420654,
      "step": 9970
    },
    {
      "epoch": 1.821334063326946,
      "grad_norm": 3.258946657180786,
      "learning_rate": 3.1745563946705966e-05,
      "logits/chosen": -1.0176174640655518,
      "logits/rejected": -0.9125056266784668,
      "logps/chosen": -164.85540771484375,
      "logps/rejected": -163.97132873535156,
      "loss": 0.4805,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.190666437149048,
      "rewards/margins": 1.4621573686599731,
      "rewards/rejected": -3.6528232097625732,
      "step": 9980
    },
    {
      "epoch": 1.8231590473583354,
      "grad_norm": 4.602431297302246,
      "learning_rate": 3.169644501749862e-05,
      "logits/chosen": -1.0291587114334106,
      "logits/rejected": -0.8810439109802246,
      "logps/chosen": -175.4075469970703,
      "logps/rejected": -163.53451538085938,
      "loss": 0.5074,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.1986498832702637,
      "rewards/margins": 1.5326142311096191,
      "rewards/rejected": -3.731264591217041,
      "step": 9990
    },
    {
      "epoch": 1.8249840313897252,
      "grad_norm": 2.4512791633605957,
      "learning_rate": 3.1647326088291274e-05,
      "logits/chosen": -0.966736912727356,
      "logits/rejected": -0.8382415771484375,
      "logps/chosen": -163.64859008789062,
      "logps/rejected": -160.43113708496094,
      "loss": 0.4854,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.194614887237549,
      "rewards/margins": 1.4445195198059082,
      "rewards/rejected": -3.639134645462036,
      "step": 10000
    },
    {
      "epoch": 1.826809015421115,
      "grad_norm": 3.554913282394409,
      "learning_rate": 3.159820715908394e-05,
      "logits/chosen": -0.92512446641922,
      "logits/rejected": -0.8299306631088257,
      "logps/chosen": -163.79080200195312,
      "logps/rejected": -158.7323455810547,
      "loss": 0.4119,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.1037676334381104,
      "rewards/margins": 1.5217736959457397,
      "rewards/rejected": -3.6255416870117188,
      "step": 10010
    },
    {
      "epoch": 1.8286339994525047,
      "grad_norm": 4.481624126434326,
      "learning_rate": 3.154908822987659e-05,
      "logits/chosen": -0.9434011578559875,
      "logits/rejected": -0.823813259601593,
      "logps/chosen": -174.4214630126953,
      "logps/rejected": -163.54103088378906,
      "loss": 0.5608,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.384803056716919,
      "rewards/margins": 1.2148213386535645,
      "rewards/rejected": -3.5996241569519043,
      "step": 10020
    },
    {
      "epoch": 1.8304589834838945,
      "grad_norm": 2.487269878387451,
      "learning_rate": 3.149996930066925e-05,
      "logits/chosen": -1.0017077922821045,
      "logits/rejected": -0.8490346670150757,
      "logps/chosen": -162.95887756347656,
      "logps/rejected": -151.55224609375,
      "loss": 0.4707,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.2502598762512207,
      "rewards/margins": 1.419083833694458,
      "rewards/rejected": -3.669343948364258,
      "step": 10030
    },
    {
      "epoch": 1.8322839675152842,
      "grad_norm": 2.803102731704712,
      "learning_rate": 3.1450850371461905e-05,
      "logits/chosen": -0.9865477681159973,
      "logits/rejected": -0.8796346783638,
      "logps/chosen": -170.003662109375,
      "logps/rejected": -167.33633422851562,
      "loss": 0.3698,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.9998195171356201,
      "rewards/margins": 1.6897693872451782,
      "rewards/rejected": -3.689589023590088,
      "step": 10040
    },
    {
      "epoch": 1.834108951546674,
      "grad_norm": 6.19590950012207,
      "learning_rate": 3.140173144225456e-05,
      "logits/chosen": -1.0264251232147217,
      "logits/rejected": -0.8754254579544067,
      "logps/chosen": -166.3838348388672,
      "logps/rejected": -152.33082580566406,
      "loss": 0.4465,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.215740919113159,
      "rewards/margins": 1.5882227420806885,
      "rewards/rejected": -3.8039634227752686,
      "step": 10050
    },
    {
      "epoch": 1.8359339355780637,
      "grad_norm": 3.5370163917541504,
      "learning_rate": 3.135261251304722e-05,
      "logits/chosen": -0.9573103785514832,
      "logits/rejected": -0.8085542917251587,
      "logps/chosen": -182.6915283203125,
      "logps/rejected": -173.47177124023438,
      "loss": 0.3557,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.3148558139801025,
      "rewards/margins": 1.745321273803711,
      "rewards/rejected": -4.060176849365234,
      "step": 10060
    },
    {
      "epoch": 1.8377589196094535,
      "grad_norm": 3.7204599380493164,
      "learning_rate": 3.130349358383987e-05,
      "logits/chosen": -0.9387289881706238,
      "logits/rejected": -0.8464703559875488,
      "logps/chosen": -153.5307159423828,
      "logps/rejected": -157.07432556152344,
      "loss": 0.3464,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.058155059814453,
      "rewards/margins": 1.8470741510391235,
      "rewards/rejected": -3.905229091644287,
      "step": 10070
    },
    {
      "epoch": 1.8395839036408432,
      "grad_norm": 3.872347831726074,
      "learning_rate": 3.1254374654632536e-05,
      "logits/chosen": -1.0815738439559937,
      "logits/rejected": -0.9918716549873352,
      "logps/chosen": -175.9064483642578,
      "logps/rejected": -166.30189514160156,
      "loss": 0.5088,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.2573962211608887,
      "rewards/margins": 1.3121347427368164,
      "rewards/rejected": -3.569530963897705,
      "step": 10080
    },
    {
      "epoch": 1.841408887672233,
      "grad_norm": 5.369403839111328,
      "learning_rate": 3.120525572542519e-05,
      "logits/chosen": -0.9968241453170776,
      "logits/rejected": -0.904351532459259,
      "logps/chosen": -183.40904235839844,
      "logps/rejected": -184.49916076660156,
      "loss": 0.4091,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.3636136054992676,
      "rewards/margins": 1.6209033727645874,
      "rewards/rejected": -3.9845168590545654,
      "step": 10090
    },
    {
      "epoch": 1.8432338717036227,
      "grad_norm": 4.0556488037109375,
      "learning_rate": 3.1156136796217845e-05,
      "logits/chosen": -1.01511549949646,
      "logits/rejected": -0.8904393315315247,
      "logps/chosen": -173.13768005371094,
      "logps/rejected": -174.87533569335938,
      "loss": 0.366,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.104395627975464,
      "rewards/margins": 1.7546005249023438,
      "rewards/rejected": -3.8589961528778076,
      "step": 10100
    },
    {
      "epoch": 1.8450588557350123,
      "grad_norm": 2.175558090209961,
      "learning_rate": 3.11070178670105e-05,
      "logits/chosen": -1.0976678133010864,
      "logits/rejected": -0.9451636075973511,
      "logps/chosen": -189.46243286132812,
      "logps/rejected": -166.2245635986328,
      "loss": 0.4791,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.2843117713928223,
      "rewards/margins": 1.4444773197174072,
      "rewards/rejected": -3.7287890911102295,
      "step": 10110
    },
    {
      "epoch": 1.846883839766402,
      "grad_norm": 6.052621364593506,
      "learning_rate": 3.105789893780316e-05,
      "logits/chosen": -0.9096792340278625,
      "logits/rejected": -0.8206381797790527,
      "logps/chosen": -180.237060546875,
      "logps/rejected": -174.84912109375,
      "loss": 0.4163,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4395809173583984,
      "rewards/margins": 1.626394510269165,
      "rewards/rejected": -4.065975666046143,
      "step": 10120
    },
    {
      "epoch": 1.8487088237977918,
      "grad_norm": 2.1147141456604004,
      "learning_rate": 3.100878000859581e-05,
      "logits/chosen": -0.9812666177749634,
      "logits/rejected": -0.8795967102050781,
      "logps/chosen": -167.1481170654297,
      "logps/rejected": -169.67576599121094,
      "loss": 0.5009,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.411299228668213,
      "rewards/margins": 1.4264048337936401,
      "rewards/rejected": -3.8377044200897217,
      "step": 10130
    },
    {
      "epoch": 1.8505338078291815,
      "grad_norm": 5.775922775268555,
      "learning_rate": 3.095966107938847e-05,
      "logits/chosen": -0.9061118364334106,
      "logits/rejected": -0.8832801580429077,
      "logps/chosen": -159.25335693359375,
      "logps/rejected": -173.4047088623047,
      "loss": 0.5529,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.6416354179382324,
      "rewards/margins": 1.2842200994491577,
      "rewards/rejected": -3.9258556365966797,
      "step": 10140
    },
    {
      "epoch": 1.852358791860571,
      "grad_norm": 5.862342357635498,
      "learning_rate": 3.091054215018113e-05,
      "logits/chosen": -0.9859983325004578,
      "logits/rejected": -0.8890277743339539,
      "logps/chosen": -171.62596130371094,
      "logps/rejected": -171.35865783691406,
      "loss": 0.426,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.2835030555725098,
      "rewards/margins": 1.7113549709320068,
      "rewards/rejected": -3.9948582649230957,
      "step": 10150
    },
    {
      "epoch": 1.8541837758919608,
      "grad_norm": 2.3980836868286133,
      "learning_rate": 3.0861423220973784e-05,
      "logits/chosen": -0.9105957746505737,
      "logits/rejected": -0.8303127288818359,
      "logps/chosen": -159.10476684570312,
      "logps/rejected": -176.689453125,
      "loss": 0.412,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.2951557636260986,
      "rewards/margins": 1.6897211074829102,
      "rewards/rejected": -3.9848766326904297,
      "step": 10160
    },
    {
      "epoch": 1.8560087599233506,
      "grad_norm": 4.404553413391113,
      "learning_rate": 3.081230429176644e-05,
      "logits/chosen": -0.9762589335441589,
      "logits/rejected": -0.8843460083007812,
      "logps/chosen": -180.46035766601562,
      "logps/rejected": -171.90884399414062,
      "loss": 0.4538,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.330277919769287,
      "rewards/margins": 1.462202787399292,
      "rewards/rejected": -3.792480945587158,
      "step": 10170
    },
    {
      "epoch": 1.8578337439547403,
      "grad_norm": 3.2570960521698,
      "learning_rate": 3.07631853625591e-05,
      "logits/chosen": -0.9037808179855347,
      "logits/rejected": -0.7346172332763672,
      "logps/chosen": -179.9760284423828,
      "logps/rejected": -160.7206573486328,
      "loss": 0.3634,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9934955835342407,
      "rewards/margins": 1.5883525609970093,
      "rewards/rejected": -3.581847667694092,
      "step": 10180
    },
    {
      "epoch": 1.85965872798613,
      "grad_norm": 4.290694713592529,
      "learning_rate": 3.071406643335176e-05,
      "logits/chosen": -0.9650041460990906,
      "logits/rejected": -0.8530999422073364,
      "logps/chosen": -178.8109893798828,
      "logps/rejected": -171.49188232421875,
      "loss": 0.4504,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.9392414093017578,
      "rewards/margins": 1.6449401378631592,
      "rewards/rejected": -3.584182024002075,
      "step": 10190
    },
    {
      "epoch": 1.8614837120175198,
      "grad_norm": 5.154546737670898,
      "learning_rate": 3.066494750414441e-05,
      "logits/chosen": -1.0251374244689941,
      "logits/rejected": -0.9656673669815063,
      "logps/chosen": -157.20712280273438,
      "logps/rejected": -159.4274139404297,
      "loss": 0.4621,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6457617282867432,
      "rewards/margins": 1.5894114971160889,
      "rewards/rejected": -3.235172986984253,
      "step": 10200
    },
    {
      "epoch": 1.8633086960489096,
      "grad_norm": 3.5569064617156982,
      "learning_rate": 3.061582857493707e-05,
      "logits/chosen": -1.0391945838928223,
      "logits/rejected": -0.9915176630020142,
      "logps/chosen": -171.62371826171875,
      "logps/rejected": -174.63186645507812,
      "loss": 0.446,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5385935306549072,
      "rewards/margins": 1.6537444591522217,
      "rewards/rejected": -3.192338228225708,
      "step": 10210
    },
    {
      "epoch": 1.8651336800802993,
      "grad_norm": 3.4723169803619385,
      "learning_rate": 3.0566709645729724e-05,
      "logits/chosen": -0.9842104911804199,
      "logits/rejected": -0.8573715090751648,
      "logps/chosen": -145.69041442871094,
      "logps/rejected": -142.39297485351562,
      "loss": 0.4975,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.6558910608291626,
      "rewards/margins": 1.2440377473831177,
      "rewards/rejected": -2.8999288082122803,
      "step": 10220
    },
    {
      "epoch": 1.866958664111689,
      "grad_norm": 3.410425901412964,
      "learning_rate": 3.051759071652238e-05,
      "logits/chosen": -1.0492981672286987,
      "logits/rejected": -0.8951917886734009,
      "logps/chosen": -174.20419311523438,
      "logps/rejected": -159.5723876953125,
      "loss": 0.3824,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2926995754241943,
      "rewards/margins": 1.5607481002807617,
      "rewards/rejected": -2.853447675704956,
      "step": 10230
    },
    {
      "epoch": 1.8687836481430788,
      "grad_norm": 4.950095176696777,
      "learning_rate": 3.0468471787315036e-05,
      "logits/chosen": -1.0410144329071045,
      "logits/rejected": -0.9362348318099976,
      "logps/chosen": -179.80618286132812,
      "logps/rejected": -169.8165740966797,
      "loss": 0.416,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6369807720184326,
      "rewards/margins": 1.4344485998153687,
      "rewards/rejected": -3.071429491043091,
      "step": 10240
    },
    {
      "epoch": 1.8706086321744686,
      "grad_norm": 3.390948534011841,
      "learning_rate": 3.0419352858107697e-05,
      "logits/chosen": -0.9503394365310669,
      "logits/rejected": -0.9385825395584106,
      "logps/chosen": -139.5512237548828,
      "logps/rejected": -164.26171875,
      "loss": 0.5141,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8221423625946045,
      "rewards/margins": 1.3009014129638672,
      "rewards/rejected": -3.1230437755584717,
      "step": 10250
    },
    {
      "epoch": 1.8724336162058584,
      "grad_norm": 5.9983344078063965,
      "learning_rate": 3.0370233928900355e-05,
      "logits/chosen": -0.9220333099365234,
      "logits/rejected": -0.8812492489814758,
      "logps/chosen": -161.56187438964844,
      "logps/rejected": -163.3734893798828,
      "loss": 0.4563,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5655444860458374,
      "rewards/margins": 1.1970971822738647,
      "rewards/rejected": -2.762641668319702,
      "step": 10260
    },
    {
      "epoch": 1.8742586002372479,
      "grad_norm": 1.6734068393707275,
      "learning_rate": 3.032111499969301e-05,
      "logits/chosen": -0.9402836561203003,
      "logits/rejected": -0.8452216386795044,
      "logps/chosen": -169.90760803222656,
      "logps/rejected": -155.75270080566406,
      "loss": 0.4722,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7181217670440674,
      "rewards/margins": 1.295718789100647,
      "rewards/rejected": -3.013840436935425,
      "step": 10270
    },
    {
      "epoch": 1.8760835842686376,
      "grad_norm": 3.1602277755737305,
      "learning_rate": 3.0271996070485667e-05,
      "logits/chosen": -0.9525521397590637,
      "logits/rejected": -0.8203868865966797,
      "logps/chosen": -173.76083374023438,
      "logps/rejected": -146.78189086914062,
      "loss": 0.4315,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4185478687286377,
      "rewards/margins": 1.5329688787460327,
      "rewards/rejected": -2.951516628265381,
      "step": 10280
    },
    {
      "epoch": 1.8779085683000274,
      "grad_norm": 2.5857269763946533,
      "learning_rate": 3.022287714127832e-05,
      "logits/chosen": -1.0337841510772705,
      "logits/rejected": -0.9187923669815063,
      "logps/chosen": -165.21578979492188,
      "logps/rejected": -163.79391479492188,
      "loss": 0.3887,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5194861888885498,
      "rewards/margins": 1.7352174520492554,
      "rewards/rejected": -3.2547035217285156,
      "step": 10290
    },
    {
      "epoch": 1.8797335523314171,
      "grad_norm": 1.7463818788528442,
      "learning_rate": 3.017375821207098e-05,
      "logits/chosen": -0.9857553243637085,
      "logits/rejected": -0.9072197675704956,
      "logps/chosen": -178.9180908203125,
      "logps/rejected": -177.63223266601562,
      "loss": 0.4564,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.6850080490112305,
      "rewards/margins": 1.436262845993042,
      "rewards/rejected": -3.1212706565856934,
      "step": 10300
    },
    {
      "epoch": 1.8815585363628067,
      "grad_norm": 3.444087028503418,
      "learning_rate": 3.0124639282863633e-05,
      "logits/chosen": -0.9911999702453613,
      "logits/rejected": -0.8912056088447571,
      "logps/chosen": -165.99301147460938,
      "logps/rejected": -160.00318908691406,
      "loss": 0.4337,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6940807104110718,
      "rewards/margins": 1.4005110263824463,
      "rewards/rejected": -3.0945913791656494,
      "step": 10310
    },
    {
      "epoch": 1.8833835203941964,
      "grad_norm": 5.132241725921631,
      "learning_rate": 3.0075520353656295e-05,
      "logits/chosen": -1.0431469678878784,
      "logits/rejected": -0.9325723648071289,
      "logps/chosen": -162.40261840820312,
      "logps/rejected": -164.0950927734375,
      "loss": 0.4882,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7542979717254639,
      "rewards/margins": 1.2300387620925903,
      "rewards/rejected": -2.9843366146087646,
      "step": 10320
    },
    {
      "epoch": 1.8852085044255862,
      "grad_norm": 3.486271381378174,
      "learning_rate": 3.002640142444895e-05,
      "logits/chosen": -0.9979550242424011,
      "logits/rejected": -0.890764057636261,
      "logps/chosen": -151.29660034179688,
      "logps/rejected": -141.27615356445312,
      "loss": 0.4258,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5193754434585571,
      "rewards/margins": 1.3591562509536743,
      "rewards/rejected": -2.8785316944122314,
      "step": 10330
    },
    {
      "epoch": 1.887033488456976,
      "grad_norm": 3.6263184547424316,
      "learning_rate": 2.9977282495241607e-05,
      "logits/chosen": -0.9028352499008179,
      "logits/rejected": -0.8442302942276001,
      "logps/chosen": -157.58102416992188,
      "logps/rejected": -161.80337524414062,
      "loss": 0.4506,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.751262903213501,
      "rewards/margins": 1.3081793785095215,
      "rewards/rejected": -3.0594425201416016,
      "step": 10340
    },
    {
      "epoch": 1.8888584724883657,
      "grad_norm": 6.435869216918945,
      "learning_rate": 2.9928163566034264e-05,
      "logits/chosen": -1.0273706912994385,
      "logits/rejected": -0.8887462615966797,
      "logps/chosen": -167.60317993164062,
      "logps/rejected": -149.08616638183594,
      "loss": 0.5344,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.6104987859725952,
      "rewards/margins": 1.3417085409164429,
      "rewards/rejected": -2.952207326889038,
      "step": 10350
    },
    {
      "epoch": 1.8906834565197554,
      "grad_norm": 3.1632542610168457,
      "learning_rate": 2.987904463682692e-05,
      "logits/chosen": -1.0080105066299438,
      "logits/rejected": -0.8524641990661621,
      "logps/chosen": -145.78079223632812,
      "logps/rejected": -141.8154754638672,
      "loss": 0.3681,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.302053689956665,
      "rewards/margins": 1.7760556936264038,
      "rewards/rejected": -3.0781095027923584,
      "step": 10360
    },
    {
      "epoch": 1.8925084405511452,
      "grad_norm": 1.60398530960083,
      "learning_rate": 2.9829925707619576e-05,
      "logits/chosen": -0.9859446287155151,
      "logits/rejected": -0.8591440916061401,
      "logps/chosen": -159.3880157470703,
      "logps/rejected": -143.86659240722656,
      "loss": 0.3531,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.3793946504592896,
      "rewards/margins": 1.6479434967041016,
      "rewards/rejected": -3.0273380279541016,
      "step": 10370
    },
    {
      "epoch": 1.894333424582535,
      "grad_norm": 3.574915885925293,
      "learning_rate": 2.978080677841223e-05,
      "logits/chosen": -0.9693155288696289,
      "logits/rejected": -0.8925204277038574,
      "logps/chosen": -159.31845092773438,
      "logps/rejected": -156.54971313476562,
      "loss": 0.5015,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.6073691844940186,
      "rewards/margins": 1.2984682321548462,
      "rewards/rejected": -2.905837297439575,
      "step": 10380
    },
    {
      "epoch": 1.8961584086139247,
      "grad_norm": 4.033246994018555,
      "learning_rate": 2.9731687849204892e-05,
      "logits/chosen": -1.004244089126587,
      "logits/rejected": -0.8523042798042297,
      "logps/chosen": -156.16238403320312,
      "logps/rejected": -137.2505340576172,
      "loss": 0.4578,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3225102424621582,
      "rewards/margins": 1.454833984375,
      "rewards/rejected": -2.777343988418579,
      "step": 10390
    },
    {
      "epoch": 1.8979833926453145,
      "grad_norm": 8.241311073303223,
      "learning_rate": 2.9682568919997546e-05,
      "logits/chosen": -0.9560474157333374,
      "logits/rejected": -0.8761455416679382,
      "logps/chosen": -161.24520874023438,
      "logps/rejected": -148.8537139892578,
      "loss": 0.4785,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2422212362289429,
      "rewards/margins": 1.676153540611267,
      "rewards/rejected": -2.918375015258789,
      "step": 10400
    },
    {
      "epoch": 1.8998083766767042,
      "grad_norm": 5.719363212585449,
      "learning_rate": 2.9633449990790204e-05,
      "logits/chosen": -0.9860087633132935,
      "logits/rejected": -0.9131931066513062,
      "logps/chosen": -156.4375762939453,
      "logps/rejected": -158.00450134277344,
      "loss": 0.4448,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1982502937316895,
      "rewards/margins": 1.4712371826171875,
      "rewards/rejected": -2.669487237930298,
      "step": 10410
    },
    {
      "epoch": 1.901633360708094,
      "grad_norm": 3.582134485244751,
      "learning_rate": 2.958433106158286e-05,
      "logits/chosen": -1.0004053115844727,
      "logits/rejected": -0.8908282518386841,
      "logps/chosen": -162.62100219726562,
      "logps/rejected": -156.7346649169922,
      "loss": 0.4586,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4178307056427002,
      "rewards/margins": 1.6503543853759766,
      "rewards/rejected": -3.068185329437256,
      "step": 10420
    },
    {
      "epoch": 1.9034583447394835,
      "grad_norm": 3.2058491706848145,
      "learning_rate": 2.9535212132375516e-05,
      "logits/chosen": -1.0322967767715454,
      "logits/rejected": -0.9305083155632019,
      "logps/chosen": -156.6470184326172,
      "logps/rejected": -148.11544799804688,
      "loss": 0.3693,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.2451058626174927,
      "rewards/margins": 1.5699399709701538,
      "rewards/rejected": -2.8150455951690674,
      "step": 10430
    },
    {
      "epoch": 1.9052833287708733,
      "grad_norm": 3.912240505218506,
      "learning_rate": 2.948609320316817e-05,
      "logits/chosen": -0.9904362559318542,
      "logits/rejected": -0.9247580766677856,
      "logps/chosen": -176.390869140625,
      "logps/rejected": -188.33761596679688,
      "loss": 0.2887,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.688476800918579,
      "rewards/margins": 1.8755165338516235,
      "rewards/rejected": -3.563992977142334,
      "step": 10440
    },
    {
      "epoch": 1.907108312802263,
      "grad_norm": 2.8144052028656006,
      "learning_rate": 2.943697427396083e-05,
      "logits/chosen": -1.028590202331543,
      "logits/rejected": -0.9050949811935425,
      "logps/chosen": -180.34429931640625,
      "logps/rejected": -174.4483642578125,
      "loss": 0.374,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1993815898895264,
      "rewards/margins": 1.8558540344238281,
      "rewards/rejected": -3.0552353858947754,
      "step": 10450
    },
    {
      "epoch": 1.9089332968336528,
      "grad_norm": 4.910129070281982,
      "learning_rate": 2.938785534475349e-05,
      "logits/chosen": -1.020878553390503,
      "logits/rejected": -0.9831023216247559,
      "logps/chosen": -145.99676513671875,
      "logps/rejected": -153.1581573486328,
      "loss": 0.4241,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8262087106704712,
      "rewards/margins": 1.3411529064178467,
      "rewards/rejected": -3.1673617362976074,
      "step": 10460
    },
    {
      "epoch": 1.9107582808650423,
      "grad_norm": 4.662676811218262,
      "learning_rate": 2.9338736415546144e-05,
      "logits/chosen": -1.0369877815246582,
      "logits/rejected": -0.9507689476013184,
      "logps/chosen": -149.24002075195312,
      "logps/rejected": -159.6662139892578,
      "loss": 0.4431,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6571102142333984,
      "rewards/margins": 1.47602117061615,
      "rewards/rejected": -3.133131742477417,
      "step": 10470
    },
    {
      "epoch": 1.912583264896432,
      "grad_norm": 6.024290084838867,
      "learning_rate": 2.92896174863388e-05,
      "logits/chosen": -1.0470612049102783,
      "logits/rejected": -0.9425233602523804,
      "logps/chosen": -177.6607666015625,
      "logps/rejected": -162.15036010742188,
      "loss": 0.3914,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5807048082351685,
      "rewards/margins": 1.7326641082763672,
      "rewards/rejected": -3.313369035720825,
      "step": 10480
    },
    {
      "epoch": 1.9144082489278218,
      "grad_norm": 4.466083526611328,
      "learning_rate": 2.9240498557131456e-05,
      "logits/chosen": -1.1268590688705444,
      "logits/rejected": -0.9956393241882324,
      "logps/chosen": -156.15621948242188,
      "logps/rejected": -157.11166381835938,
      "loss": 0.3357,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6508004665374756,
      "rewards/margins": 1.9270050525665283,
      "rewards/rejected": -3.577805280685425,
      "step": 10490
    },
    {
      "epoch": 1.9162332329592116,
      "grad_norm": 1.312108039855957,
      "learning_rate": 2.9191379627924113e-05,
      "logits/chosen": -1.0609341859817505,
      "logits/rejected": -0.9766421318054199,
      "logps/chosen": -166.2554473876953,
      "logps/rejected": -164.35162353515625,
      "loss": 0.4451,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.561488151550293,
      "rewards/margins": 1.6978098154067993,
      "rewards/rejected": -3.2592978477478027,
      "step": 10500
    },
    {
      "epoch": 1.9180582169906013,
      "grad_norm": 5.105528354644775,
      "learning_rate": 2.9142260698716768e-05,
      "logits/chosen": -1.1158729791641235,
      "logits/rejected": -1.051423192024231,
      "logps/chosen": -166.57498168945312,
      "logps/rejected": -168.1243438720703,
      "loss": 0.4519,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.6355146169662476,
      "rewards/margins": 1.5027673244476318,
      "rewards/rejected": -3.138282060623169,
      "step": 10510
    },
    {
      "epoch": 1.919883201021991,
      "grad_norm": 5.3694071769714355,
      "learning_rate": 2.909314176950943e-05,
      "logits/chosen": -1.0980806350708008,
      "logits/rejected": -1.0056164264678955,
      "logps/chosen": -157.57211303710938,
      "logps/rejected": -157.9866485595703,
      "loss": 0.3692,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8862403631210327,
      "rewards/margins": 1.6525713205337524,
      "rewards/rejected": -3.5388119220733643,
      "step": 10520
    },
    {
      "epoch": 1.9217081850533808,
      "grad_norm": 3.052231788635254,
      "learning_rate": 2.9044022840302083e-05,
      "logits/chosen": -1.0531446933746338,
      "logits/rejected": -0.9244615435600281,
      "logps/chosen": -174.92738342285156,
      "logps/rejected": -152.47567749023438,
      "loss": 0.44,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9806629419326782,
      "rewards/margins": 1.7661755084991455,
      "rewards/rejected": -3.746838331222534,
      "step": 10530
    },
    {
      "epoch": 1.9235331690847706,
      "grad_norm": 5.030280590057373,
      "learning_rate": 2.899490391109474e-05,
      "logits/chosen": -1.0837485790252686,
      "logits/rejected": -0.959204375743866,
      "logps/chosen": -169.3572998046875,
      "logps/rejected": -163.72979736328125,
      "loss": 0.4317,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7270803451538086,
      "rewards/margins": 2.0730371475219727,
      "rewards/rejected": -3.8001174926757812,
      "step": 10540
    },
    {
      "epoch": 1.9253581531161603,
      "grad_norm": 5.381191730499268,
      "learning_rate": 2.89457849818874e-05,
      "logits/chosen": -1.1100680828094482,
      "logits/rejected": -1.0439741611480713,
      "logps/chosen": -152.7800750732422,
      "logps/rejected": -156.88372802734375,
      "loss": 0.4639,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.671815276145935,
      "rewards/margins": 1.7572462558746338,
      "rewards/rejected": -3.4290614128112793,
      "step": 10550
    },
    {
      "epoch": 1.92718313714755,
      "grad_norm": 3.2057597637176514,
      "learning_rate": 2.8896666052680053e-05,
      "logits/chosen": -1.1679847240447998,
      "logits/rejected": -1.0446865558624268,
      "logps/chosen": -174.87567138671875,
      "logps/rejected": -158.75314331054688,
      "loss": 0.4745,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.425982117652893,
      "rewards/margins": 1.562427043914795,
      "rewards/rejected": -2.9884088039398193,
      "step": 10560
    },
    {
      "epoch": 1.9290081211789398,
      "grad_norm": 6.180756568908691,
      "learning_rate": 2.884754712347271e-05,
      "logits/chosen": -1.1394920349121094,
      "logits/rejected": -1.0690710544586182,
      "logps/chosen": -172.01083374023438,
      "logps/rejected": -165.3982391357422,
      "loss": 0.5106,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6502538919448853,
      "rewards/margins": 1.4011203050613403,
      "rewards/rejected": -3.0513744354248047,
      "step": 10570
    },
    {
      "epoch": 1.9308331052103294,
      "grad_norm": 9.152959823608398,
      "learning_rate": 2.8798428194265365e-05,
      "logits/chosen": -1.1630996465682983,
      "logits/rejected": -1.0633865594863892,
      "logps/chosen": -156.4094696044922,
      "logps/rejected": -148.97166442871094,
      "loss": 0.4315,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.819409728050232,
      "rewards/margins": 1.8755264282226562,
      "rewards/rejected": -3.6949360370635986,
      "step": 10580
    },
    {
      "epoch": 1.9326580892417191,
      "grad_norm": 3.9822299480438232,
      "learning_rate": 2.8749309265058026e-05,
      "logits/chosen": -1.1799299716949463,
      "logits/rejected": -1.0918408632278442,
      "logps/chosen": -164.27810668945312,
      "logps/rejected": -152.5262451171875,
      "loss": 0.4999,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.1297078132629395,
      "rewards/margins": 1.4572861194610596,
      "rewards/rejected": -3.586994171142578,
      "step": 10590
    },
    {
      "epoch": 1.9344830732731089,
      "grad_norm": 2.967956304550171,
      "learning_rate": 2.870019033585068e-05,
      "logits/chosen": -1.2062106132507324,
      "logits/rejected": -1.1406595706939697,
      "logps/chosen": -163.8481903076172,
      "logps/rejected": -171.6882781982422,
      "loss": 0.3363,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5710490942001343,
      "rewards/margins": 1.9412950277328491,
      "rewards/rejected": -3.5123443603515625,
      "step": 10600
    },
    {
      "epoch": 1.9363080573044986,
      "grad_norm": 4.306974411010742,
      "learning_rate": 2.8651071406643338e-05,
      "logits/chosen": -1.2332502603530884,
      "logits/rejected": -1.1568739414215088,
      "logps/chosen": -180.76499938964844,
      "logps/rejected": -159.58993530273438,
      "loss": 0.4647,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.769995093345642,
      "rewards/margins": 1.5556844472885132,
      "rewards/rejected": -3.3256797790527344,
      "step": 10610
    },
    {
      "epoch": 1.9381330413358882,
      "grad_norm": 3.870232582092285,
      "learning_rate": 2.8601952477435993e-05,
      "logits/chosen": -1.209161400794983,
      "logits/rejected": -1.1084816455841064,
      "logps/chosen": -188.6205291748047,
      "logps/rejected": -172.23037719726562,
      "loss": 0.3208,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.5659685134887695,
      "rewards/margins": 1.95150887966156,
      "rewards/rejected": -3.517477512359619,
      "step": 10620
    },
    {
      "epoch": 1.939958025367278,
      "grad_norm": 4.334657192230225,
      "learning_rate": 2.855283354822865e-05,
      "logits/chosen": -1.2164554595947266,
      "logits/rejected": -1.118661642074585,
      "logps/chosen": -172.451904296875,
      "logps/rejected": -158.52394104003906,
      "loss": 0.4827,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6794662475585938,
      "rewards/margins": 1.6751235723495483,
      "rewards/rejected": -3.3545899391174316,
      "step": 10630
    },
    {
      "epoch": 1.9417830093986677,
      "grad_norm": 7.526022434234619,
      "learning_rate": 2.850371461902131e-05,
      "logits/chosen": -1.1668858528137207,
      "logits/rejected": -1.1227505207061768,
      "logps/chosen": -172.25216674804688,
      "logps/rejected": -169.43490600585938,
      "loss": 0.4416,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9438447952270508,
      "rewards/margins": 1.4521307945251465,
      "rewards/rejected": -3.3959758281707764,
      "step": 10640
    },
    {
      "epoch": 1.9436079934300574,
      "grad_norm": 3.081301212310791,
      "learning_rate": 2.8454595689813966e-05,
      "logits/chosen": -1.158142328262329,
      "logits/rejected": -1.0909634828567505,
      "logps/chosen": -156.79196166992188,
      "logps/rejected": -163.2347869873047,
      "loss": 0.5046,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.9409252405166626,
      "rewards/margins": 1.3809194564819336,
      "rewards/rejected": -3.3218448162078857,
      "step": 10650
    },
    {
      "epoch": 1.9454329774614472,
      "grad_norm": 2.263916015625,
      "learning_rate": 2.8405476760606624e-05,
      "logits/chosen": -1.238617181777954,
      "logits/rejected": -1.0863772630691528,
      "logps/chosen": -170.5881805419922,
      "logps/rejected": -139.53402709960938,
      "loss": 0.4232,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.7016284465789795,
      "rewards/margins": 1.5946166515350342,
      "rewards/rejected": -3.296245574951172,
      "step": 10660
    },
    {
      "epoch": 1.947257961492837,
      "grad_norm": 5.383068084716797,
      "learning_rate": 2.8356357831399278e-05,
      "logits/chosen": -1.1351017951965332,
      "logits/rejected": -1.042361855506897,
      "logps/chosen": -154.2306365966797,
      "logps/rejected": -154.25326538085938,
      "loss": 0.4037,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8996086120605469,
      "rewards/margins": 1.6824264526367188,
      "rewards/rejected": -3.582035541534424,
      "step": 10670
    },
    {
      "epoch": 1.9490829455242267,
      "grad_norm": 5.7114739418029785,
      "learning_rate": 2.8307238902191936e-05,
      "logits/chosen": -1.1526463031768799,
      "logits/rejected": -1.0913240909576416,
      "logps/chosen": -162.32215881347656,
      "logps/rejected": -161.4419708251953,
      "loss": 0.5641,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.004260301589966,
      "rewards/margins": 1.1422532796859741,
      "rewards/rejected": -3.1465134620666504,
      "step": 10680
    },
    {
      "epoch": 1.9509079295556164,
      "grad_norm": 4.262447357177734,
      "learning_rate": 2.825811997298459e-05,
      "logits/chosen": -1.1338756084442139,
      "logits/rejected": -1.0334575176239014,
      "logps/chosen": -168.56051635742188,
      "logps/rejected": -159.92283630371094,
      "loss": 0.3915,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.647815465927124,
      "rewards/margins": 1.5637075901031494,
      "rewards/rejected": -3.2115230560302734,
      "step": 10690
    },
    {
      "epoch": 1.9527329135870062,
      "grad_norm": 3.305189609527588,
      "learning_rate": 2.8209001043777248e-05,
      "logits/chosen": -1.1575461626052856,
      "logits/rejected": -1.024019718170166,
      "logps/chosen": -158.14047241210938,
      "logps/rejected": -146.85215759277344,
      "loss": 0.3501,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.1124485731124878,
      "rewards/margins": 1.8102277517318726,
      "rewards/rejected": -2.9226763248443604,
      "step": 10700
    },
    {
      "epoch": 1.954557897618396,
      "grad_norm": 2.5214176177978516,
      "learning_rate": 2.8159882114569902e-05,
      "logits/chosen": -1.1311336755752563,
      "logits/rejected": -1.0350427627563477,
      "logps/chosen": -155.7384033203125,
      "logps/rejected": -152.63490295410156,
      "loss": 0.439,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.492287039756775,
      "rewards/margins": 1.5535521507263184,
      "rewards/rejected": -3.0458388328552246,
      "step": 10710
    },
    {
      "epoch": 1.9563828816497857,
      "grad_norm": 5.64851713180542,
      "learning_rate": 2.8110763185362563e-05,
      "logits/chosen": -1.1350958347320557,
      "logits/rejected": -1.0422006845474243,
      "logps/chosen": -174.2869110107422,
      "logps/rejected": -177.0789337158203,
      "loss": 0.4048,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4070537090301514,
      "rewards/margins": 1.8678863048553467,
      "rewards/rejected": -3.2749404907226562,
      "step": 10720
    },
    {
      "epoch": 1.9582078656811754,
      "grad_norm": 4.123480319976807,
      "learning_rate": 2.8061644256155218e-05,
      "logits/chosen": -1.1206605434417725,
      "logits/rejected": -0.9670001268386841,
      "logps/chosen": -164.1774139404297,
      "logps/rejected": -149.77706909179688,
      "loss": 0.3999,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4222980737686157,
      "rewards/margins": 1.9555833339691162,
      "rewards/rejected": -3.3778815269470215,
      "step": 10730
    },
    {
      "epoch": 1.960032849712565,
      "grad_norm": 4.424673080444336,
      "learning_rate": 2.8012525326947875e-05,
      "logits/chosen": -1.1662049293518066,
      "logits/rejected": -1.0694925785064697,
      "logps/chosen": -154.05499267578125,
      "logps/rejected": -137.70489501953125,
      "loss": 0.4363,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6267770528793335,
      "rewards/margins": 1.296714425086975,
      "rewards/rejected": -2.9234914779663086,
      "step": 10740
    },
    {
      "epoch": 1.9618578337439547,
      "grad_norm": 3.199784994125366,
      "learning_rate": 2.7963406397740533e-05,
      "logits/chosen": -1.189652681350708,
      "logits/rejected": -1.1277492046356201,
      "logps/chosen": -154.2909393310547,
      "logps/rejected": -153.9263916015625,
      "loss": 0.4464,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6692874431610107,
      "rewards/margins": 1.4060301780700684,
      "rewards/rejected": -3.0753180980682373,
      "step": 10750
    },
    {
      "epoch": 1.9636828177753445,
      "grad_norm": 4.69984245300293,
      "learning_rate": 2.7914287468533187e-05,
      "logits/chosen": -1.1595746278762817,
      "logits/rejected": -1.0824774503707886,
      "logps/chosen": -168.9136962890625,
      "logps/rejected": -167.4809112548828,
      "loss": 0.4368,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3297280073165894,
      "rewards/margins": 1.667320966720581,
      "rewards/rejected": -2.997048854827881,
      "step": 10760
    },
    {
      "epoch": 1.9655078018067342,
      "grad_norm": 4.598105430603027,
      "learning_rate": 2.7865168539325845e-05,
      "logits/chosen": -1.1728289127349854,
      "logits/rejected": -1.0934007167816162,
      "logps/chosen": -144.80258178710938,
      "logps/rejected": -149.3062744140625,
      "loss": 0.3461,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.252382516860962,
      "rewards/margins": 2.070559501647949,
      "rewards/rejected": -3.3229422569274902,
      "step": 10770
    },
    {
      "epoch": 1.9673327858381238,
      "grad_norm": 2.6928367614746094,
      "learning_rate": 2.78160496101185e-05,
      "logits/chosen": -1.2304754257202148,
      "logits/rejected": -1.1392322778701782,
      "logps/chosen": -171.28517150878906,
      "logps/rejected": -157.0466766357422,
      "loss": 0.3925,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.256483554840088,
      "rewards/margins": 1.68271005153656,
      "rewards/rejected": -2.9391937255859375,
      "step": 10780
    },
    {
      "epoch": 1.9691577698695135,
      "grad_norm": 2.7684414386749268,
      "learning_rate": 2.776693068091116e-05,
      "logits/chosen": -1.1960127353668213,
      "logits/rejected": -1.1832926273345947,
      "logps/chosen": -155.4440460205078,
      "logps/rejected": -154.4400634765625,
      "loss": 0.4989,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4326986074447632,
      "rewards/margins": 1.3587380647659302,
      "rewards/rejected": -2.7914364337921143,
      "step": 10790
    },
    {
      "epoch": 1.9709827539009033,
      "grad_norm": 3.309378147125244,
      "learning_rate": 2.7717811751703815e-05,
      "logits/chosen": -1.243096947669983,
      "logits/rejected": -1.1859283447265625,
      "logps/chosen": -155.15798950195312,
      "logps/rejected": -150.92115783691406,
      "loss": 0.5126,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.0221480131149292,
      "rewards/margins": 1.5165773630142212,
      "rewards/rejected": -2.5387253761291504,
      "step": 10800
    },
    {
      "epoch": 1.972807737932293,
      "grad_norm": 2.4297499656677246,
      "learning_rate": 2.7673604715417207e-05,
      "logits/chosen": -1.1793944835662842,
      "logits/rejected": -1.1123411655426025,
      "logps/chosen": -148.26321411132812,
      "logps/rejected": -157.38868713378906,
      "loss": 0.3694,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.1393544673919678,
      "rewards/margins": 1.5572302341461182,
      "rewards/rejected": -2.696584463119507,
      "step": 10810
    },
    {
      "epoch": 1.9746327219636828,
      "grad_norm": 5.451929092407227,
      "learning_rate": 2.7624485786209865e-05,
      "logits/chosen": -1.247647762298584,
      "logits/rejected": -1.1307803392410278,
      "logps/chosen": -157.44918823242188,
      "logps/rejected": -151.66175842285156,
      "loss": 0.3377,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.1471935510635376,
      "rewards/margins": 1.952580451965332,
      "rewards/rejected": -3.0997743606567383,
      "step": 10820
    },
    {
      "epoch": 1.9764577059950725,
      "grad_norm": 6.804377555847168,
      "learning_rate": 2.757536685700252e-05,
      "logits/chosen": -1.2556025981903076,
      "logits/rejected": -1.2051721811294556,
      "logps/chosen": -176.583251953125,
      "logps/rejected": -170.63925170898438,
      "loss": 0.6004,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.9543864130973816,
      "rewards/margins": 1.4691431522369385,
      "rewards/rejected": -2.4235293865203857,
      "step": 10830
    },
    {
      "epoch": 1.9782826900264623,
      "grad_norm": 2.8184256553649902,
      "learning_rate": 2.7526247927795177e-05,
      "logits/chosen": -1.1961053609848022,
      "logits/rejected": -1.0676863193511963,
      "logps/chosen": -161.47439575195312,
      "logps/rejected": -156.73655700683594,
      "loss": 0.3712,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.2613776922225952,
      "rewards/margins": 2.0393121242523193,
      "rewards/rejected": -3.300689697265625,
      "step": 10840
    },
    {
      "epoch": 1.980107674057852,
      "grad_norm": 3.1828408241271973,
      "learning_rate": 2.747712899858783e-05,
      "logits/chosen": -1.245819330215454,
      "logits/rejected": -1.1575249433517456,
      "logps/chosen": -153.4703826904297,
      "logps/rejected": -150.55517578125,
      "loss": 0.3825,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0187684297561646,
      "rewards/margins": 1.6131536960601807,
      "rewards/rejected": -2.6319217681884766,
      "step": 10850
    },
    {
      "epoch": 1.9819326580892418,
      "grad_norm": 4.35684061050415,
      "learning_rate": 2.7428010069380492e-05,
      "logits/chosen": -1.244818925857544,
      "logits/rejected": -1.199367642402649,
      "logps/chosen": -143.23362731933594,
      "logps/rejected": -160.17274475097656,
      "loss": 0.3529,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.0343873500823975,
      "rewards/margins": 1.864492416381836,
      "rewards/rejected": -2.8988795280456543,
      "step": 10860
    },
    {
      "epoch": 1.9837576421206315,
      "grad_norm": 4.076859951019287,
      "learning_rate": 2.7378891140173146e-05,
      "logits/chosen": -1.2451461553573608,
      "logits/rejected": -1.2101390361785889,
      "logps/chosen": -149.13848876953125,
      "logps/rejected": -160.56411743164062,
      "loss": 0.5593,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4498951435089111,
      "rewards/margins": 1.331043004989624,
      "rewards/rejected": -2.7809383869171143,
      "step": 10870
    },
    {
      "epoch": 1.9855826261520213,
      "grad_norm": 3.1624391078948975,
      "learning_rate": 2.7329772210965804e-05,
      "logits/chosen": -1.272332787513733,
      "logits/rejected": -1.1811387538909912,
      "logps/chosen": -181.5081329345703,
      "logps/rejected": -157.92507934570312,
      "loss": 0.4491,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.3690240383148193,
      "rewards/margins": 1.4004487991333008,
      "rewards/rejected": -2.76947283744812,
      "step": 10880
    },
    {
      "epoch": 1.987407610183411,
      "grad_norm": 2.5257747173309326,
      "learning_rate": 2.728065328175846e-05,
      "logits/chosen": -1.2075904607772827,
      "logits/rejected": -1.0924428701400757,
      "logps/chosen": -169.7988739013672,
      "logps/rejected": -169.6096649169922,
      "loss": 0.4266,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7439002990722656,
      "rewards/margins": 1.4912608861923218,
      "rewards/rejected": -3.2351608276367188,
      "step": 10890
    },
    {
      "epoch": 1.9892325942148006,
      "grad_norm": 1.6828320026397705,
      "learning_rate": 2.7231534352551116e-05,
      "logits/chosen": -1.2316488027572632,
      "logits/rejected": -1.146370530128479,
      "logps/chosen": -155.41165161132812,
      "logps/rejected": -145.7879180908203,
      "loss": 0.3579,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6086804866790771,
      "rewards/margins": 1.7400953769683838,
      "rewards/rejected": -3.348775863647461,
      "step": 10900
    },
    {
      "epoch": 1.9910575782461903,
      "grad_norm": 4.6578450202941895,
      "learning_rate": 2.7182415423343774e-05,
      "logits/chosen": -1.266365647315979,
      "logits/rejected": -1.1843197345733643,
      "logps/chosen": -183.85513305664062,
      "logps/rejected": -172.04550170898438,
      "loss": 0.4092,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4278947114944458,
      "rewards/margins": 1.807914137840271,
      "rewards/rejected": -3.235808849334717,
      "step": 10910
    },
    {
      "epoch": 1.99288256227758,
      "grad_norm": 4.535842418670654,
      "learning_rate": 2.713329649413643e-05,
      "logits/chosen": -1.2545490264892578,
      "logits/rejected": -1.1982429027557373,
      "logps/chosen": -161.98072814941406,
      "logps/rejected": -157.74954223632812,
      "loss": 0.4669,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.4876601696014404,
      "rewards/margins": 1.3062039613723755,
      "rewards/rejected": -2.7938644886016846,
      "step": 10920
    },
    {
      "epoch": 1.9947075463089698,
      "grad_norm": 5.415318012237549,
      "learning_rate": 2.708417756492909e-05,
      "logits/chosen": -1.2448101043701172,
      "logits/rejected": -1.1826889514923096,
      "logps/chosen": -161.40341186523438,
      "logps/rejected": -156.9521026611328,
      "loss": 0.4464,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8434772491455078,
      "rewards/margins": 1.7813571691513062,
      "rewards/rejected": -3.6248345375061035,
      "step": 10930
    },
    {
      "epoch": 1.9965325303403594,
      "grad_norm": 3.557264804840088,
      "learning_rate": 2.7035058635721744e-05,
      "logits/chosen": -1.1998192071914673,
      "logits/rejected": -1.13047194480896,
      "logps/chosen": -157.9198760986328,
      "logps/rejected": -153.171875,
      "loss": 0.3861,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.7156339883804321,
      "rewards/margins": 1.8877376317977905,
      "rewards/rejected": -3.6033718585968018,
      "step": 10940
    },
    {
      "epoch": 1.9983575143717491,
      "grad_norm": 3.80291485786438,
      "learning_rate": 2.69859397065144e-05,
      "logits/chosen": -1.2847837209701538,
      "logits/rejected": -1.242734670639038,
      "logps/chosen": -169.33267211914062,
      "logps/rejected": -163.64100646972656,
      "loss": 0.4032,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.803458571434021,
      "rewards/margins": 1.553750991821289,
      "rewards/rejected": -3.3572094440460205,
      "step": 10950
    },
    {
      "epoch": 2.000182498403139,
      "grad_norm": 4.235325813293457,
      "learning_rate": 2.6936820777307056e-05,
      "logits/chosen": -1.231305718421936,
      "logits/rejected": -1.1622294187545776,
      "logps/chosen": -156.99813842773438,
      "logps/rejected": -148.8280029296875,
      "loss": 0.4596,
      "rewards/accuracies": 0.8041666746139526,
      "rewards/chosen": -1.6768566370010376,
      "rewards/margins": 1.538242220878601,
      "rewards/rejected": -3.2150986194610596,
      "step": 10960
    },
    {
      "epoch": 2.0020074824345286,
      "grad_norm": 4.351225852966309,
      "learning_rate": 2.6887701848099714e-05,
      "logits/chosen": -1.2695618867874146,
      "logits/rejected": -1.1939380168914795,
      "logps/chosen": -181.88027954101562,
      "logps/rejected": -181.10679626464844,
      "loss": 0.2445,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.4283428192138672,
      "rewards/margins": 2.564967393875122,
      "rewards/rejected": -3.9933102130889893,
      "step": 10970
    },
    {
      "epoch": 2.0038324664659184,
      "grad_norm": 4.10683536529541,
      "learning_rate": 2.6838582918892368e-05,
      "logits/chosen": -1.2227851152420044,
      "logits/rejected": -1.1611812114715576,
      "logps/chosen": -163.59228515625,
      "logps/rejected": -160.90512084960938,
      "loss": 0.4409,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8290694952011108,
      "rewards/margins": 1.2966314554214478,
      "rewards/rejected": -3.1257009506225586,
      "step": 10980
    },
    {
      "epoch": 2.005657450497308,
      "grad_norm": 1.8583500385284424,
      "learning_rate": 2.6789463989685026e-05,
      "logits/chosen": -1.1820448637008667,
      "logits/rejected": -1.1078243255615234,
      "logps/chosen": -174.7219696044922,
      "logps/rejected": -166.35507202148438,
      "loss": 0.3428,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.930659294128418,
      "rewards/margins": 1.8413093090057373,
      "rewards/rejected": -3.771968364715576,
      "step": 10990
    },
    {
      "epoch": 2.007482434528698,
      "grad_norm": 2.499462604522705,
      "learning_rate": 2.6740345060477687e-05,
      "logits/chosen": -1.2180988788604736,
      "logits/rejected": -1.1327763795852661,
      "logps/chosen": -154.51950073242188,
      "logps/rejected": -153.66078186035156,
      "loss": 0.3338,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6991899013519287,
      "rewards/margins": 1.9317657947540283,
      "rewards/rejected": -3.630955457687378,
      "step": 11000
    },
    {
      "epoch": 2.0093074185600877,
      "grad_norm": 2.84779953956604,
      "learning_rate": 2.669122613127034e-05,
      "logits/chosen": -1.2133033275604248,
      "logits/rejected": -1.1060500144958496,
      "logps/chosen": -163.1727294921875,
      "logps/rejected": -166.51136779785156,
      "loss": 0.1937,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.3603003025054932,
      "rewards/margins": 2.4445927143096924,
      "rewards/rejected": -3.8048934936523438,
      "step": 11010
    },
    {
      "epoch": 2.0111324025914774,
      "grad_norm": 1.6885663270950317,
      "learning_rate": 2.6642107202063e-05,
      "logits/chosen": -1.2411010265350342,
      "logits/rejected": -1.1706830263137817,
      "logps/chosen": -171.9897918701172,
      "logps/rejected": -174.89248657226562,
      "loss": 0.3013,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.9559049606323242,
      "rewards/margins": 1.968918800354004,
      "rewards/rejected": -3.924823760986328,
      "step": 11020
    },
    {
      "epoch": 2.012957386622867,
      "grad_norm": 3.4144811630249023,
      "learning_rate": 2.6592988272855653e-05,
      "logits/chosen": -1.2311294078826904,
      "logits/rejected": -1.1735519170761108,
      "logps/chosen": -161.84353637695312,
      "logps/rejected": -168.45895385742188,
      "loss": 0.298,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.3202881813049316,
      "rewards/margins": 2.0077130794525146,
      "rewards/rejected": -4.328001499176025,
      "step": 11030
    },
    {
      "epoch": 2.014782370654257,
      "grad_norm": 3.6944315433502197,
      "learning_rate": 2.654386934364831e-05,
      "logits/chosen": -1.274850606918335,
      "logits/rejected": -1.1894781589508057,
      "logps/chosen": -155.7216796875,
      "logps/rejected": -168.28570556640625,
      "loss": 0.2598,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.0832085609436035,
      "rewards/margins": 2.5965867042541504,
      "rewards/rejected": -4.679795742034912,
      "step": 11040
    },
    {
      "epoch": 2.0166073546856467,
      "grad_norm": 3.8173882961273193,
      "learning_rate": 2.6494750414440965e-05,
      "logits/chosen": -1.2334312200546265,
      "logits/rejected": -1.1404919624328613,
      "logps/chosen": -181.4027557373047,
      "logps/rejected": -188.17160034179688,
      "loss": 0.3706,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.2373557090759277,
      "rewards/margins": 2.2185585498809814,
      "rewards/rejected": -4.455914497375488,
      "step": 11050
    },
    {
      "epoch": 2.0184323387170364,
      "grad_norm": 3.7705578804016113,
      "learning_rate": 2.6445631485233626e-05,
      "logits/chosen": -1.22835373878479,
      "logits/rejected": -1.1266529560089111,
      "logps/chosen": -176.60406494140625,
      "logps/rejected": -166.5605010986328,
      "loss": 0.3467,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.373643398284912,
      "rewards/margins": 2.1195783615112305,
      "rewards/rejected": -4.493222236633301,
      "step": 11060
    },
    {
      "epoch": 2.0202573227484257,
      "grad_norm": 4.771888732910156,
      "learning_rate": 2.639651255602628e-05,
      "logits/chosen": -1.1877731084823608,
      "logits/rejected": -1.107973337173462,
      "logps/chosen": -175.95999145507812,
      "logps/rejected": -183.1896209716797,
      "loss": 0.334,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.375195264816284,
      "rewards/margins": 2.2822482585906982,
      "rewards/rejected": -4.657444000244141,
      "step": 11070
    },
    {
      "epoch": 2.0220823067798155,
      "grad_norm": 2.07354736328125,
      "learning_rate": 2.634739362681894e-05,
      "logits/chosen": -1.2878329753875732,
      "logits/rejected": -1.1126139163970947,
      "logps/chosen": -182.49432373046875,
      "logps/rejected": -174.9519805908203,
      "loss": 0.1798,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4157110452651978,
      "rewards/margins": 2.9471707344055176,
      "rewards/rejected": -4.362881660461426,
      "step": 11080
    },
    {
      "epoch": 2.0239072908112052,
      "grad_norm": 5.745946884155273,
      "learning_rate": 2.6298274697611593e-05,
      "logits/chosen": -1.140579104423523,
      "logits/rejected": -1.1024501323699951,
      "logps/chosen": -158.68515014648438,
      "logps/rejected": -183.5109405517578,
      "loss": 0.3604,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.407038688659668,
      "rewards/margins": 2.1119778156280518,
      "rewards/rejected": -4.519016742706299,
      "step": 11090
    },
    {
      "epoch": 2.025732274842595,
      "grad_norm": 2.6498923301696777,
      "learning_rate": 2.624915576840425e-05,
      "logits/chosen": -1.2278389930725098,
      "logits/rejected": -1.1768690347671509,
      "logps/chosen": -172.66305541992188,
      "logps/rejected": -190.64016723632812,
      "loss": 0.2648,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.6234979629516602,
      "rewards/margins": 2.4708797931671143,
      "rewards/rejected": -4.094377517700195,
      "step": 11100
    },
    {
      "epoch": 2.0275572588739847,
      "grad_norm": 3.7378456592559814,
      "learning_rate": 2.6200036839196908e-05,
      "logits/chosen": -1.2590405941009521,
      "logits/rejected": -1.1509196758270264,
      "logps/chosen": -166.35617065429688,
      "logps/rejected": -176.24789428710938,
      "loss": 0.1848,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.642727255821228,
      "rewards/margins": 3.0479843616485596,
      "rewards/rejected": -4.690711975097656,
      "step": 11110
    },
    {
      "epoch": 2.0293822429053745,
      "grad_norm": 5.556655406951904,
      "learning_rate": 2.6150917909989563e-05,
      "logits/chosen": -1.2494618892669678,
      "logits/rejected": -1.1353633403778076,
      "logps/chosen": -176.87130737304688,
      "logps/rejected": -185.44320678710938,
      "loss": 0.2607,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.2358193397521973,
      "rewards/margins": 2.6803460121154785,
      "rewards/rejected": -4.916165351867676,
      "step": 11120
    },
    {
      "epoch": 2.0312072269367643,
      "grad_norm": 5.341851711273193,
      "learning_rate": 2.6101798980782224e-05,
      "logits/chosen": -1.2673097848892212,
      "logits/rejected": -1.1810705661773682,
      "logps/chosen": -176.4634246826172,
      "logps/rejected": -175.03395080566406,
      "loss": 0.3654,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.24735689163208,
      "rewards/margins": 2.2410950660705566,
      "rewards/rejected": -4.488451957702637,
      "step": 11130
    },
    {
      "epoch": 2.033032210968154,
      "grad_norm": 1.2085946798324585,
      "learning_rate": 2.6052680051574878e-05,
      "logits/chosen": -1.2278492450714111,
      "logits/rejected": -1.1649014949798584,
      "logps/chosen": -180.32608032226562,
      "logps/rejected": -189.3284454345703,
      "loss": 0.2424,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.814213514328003,
      "rewards/margins": 2.719954013824463,
      "rewards/rejected": -4.534167766571045,
      "step": 11140
    },
    {
      "epoch": 2.0348571949995438,
      "grad_norm": 1.5298943519592285,
      "learning_rate": 2.6003561122367536e-05,
      "logits/chosen": -1.2599530220031738,
      "logits/rejected": -1.194612741470337,
      "logps/chosen": -171.37216186523438,
      "logps/rejected": -176.60308837890625,
      "loss": 0.2765,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.8755226135253906,
      "rewards/margins": 2.563671827316284,
      "rewards/rejected": -4.439194202423096,
      "step": 11150
    },
    {
      "epoch": 2.0366821790309335,
      "grad_norm": 2.9099156856536865,
      "learning_rate": 2.595444219316019e-05,
      "logits/chosen": -1.2501429319381714,
      "logits/rejected": -1.203521728515625,
      "logps/chosen": -163.05044555664062,
      "logps/rejected": -176.42210388183594,
      "loss": 0.3202,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.548276901245117,
      "rewards/margins": 2.0328192710876465,
      "rewards/rejected": -4.581096172332764,
      "step": 11160
    },
    {
      "epoch": 2.0385071630623233,
      "grad_norm": 4.785392761230469,
      "learning_rate": 2.5905323263952848e-05,
      "logits/chosen": -1.2420405149459839,
      "logits/rejected": -1.1496845483779907,
      "logps/chosen": -169.9503173828125,
      "logps/rejected": -165.38442993164062,
      "loss": 0.3296,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.3541598320007324,
      "rewards/margins": 2.1504197120666504,
      "rewards/rejected": -4.504579544067383,
      "step": 11170
    },
    {
      "epoch": 2.040332147093713,
      "grad_norm": 2.120327949523926,
      "learning_rate": 2.5856204334745502e-05,
      "logits/chosen": -1.2555620670318604,
      "logits/rejected": -1.181463599205017,
      "logps/chosen": -161.08242797851562,
      "logps/rejected": -175.33351135253906,
      "loss": 0.2778,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.7626405954360962,
      "rewards/margins": 2.4673960208892822,
      "rewards/rejected": -4.230036735534668,
      "step": 11180
    },
    {
      "epoch": 2.0421571311251028,
      "grad_norm": 1.711470365524292,
      "learning_rate": 2.580708540553816e-05,
      "logits/chosen": -1.2568261623382568,
      "logits/rejected": -1.1800878047943115,
      "logps/chosen": -170.4670867919922,
      "logps/rejected": -175.88572692871094,
      "loss": 0.1976,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.9432913064956665,
      "rewards/margins": 2.869019031524658,
      "rewards/rejected": -4.812310218811035,
      "step": 11190
    },
    {
      "epoch": 2.0439821151564925,
      "grad_norm": 4.297910213470459,
      "learning_rate": 2.575796647633082e-05,
      "logits/chosen": -1.2319263219833374,
      "logits/rejected": -1.0888378620147705,
      "logps/chosen": -149.20042419433594,
      "logps/rejected": -152.52618408203125,
      "loss": 0.1934,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.8485348224639893,
      "rewards/margins": 2.9826512336730957,
      "rewards/rejected": -4.831185817718506,
      "step": 11200
    },
    {
      "epoch": 2.0458070991878823,
      "grad_norm": 7.053758144378662,
      "learning_rate": 2.5708847547123475e-05,
      "logits/chosen": -1.2375319004058838,
      "logits/rejected": -1.1517850160598755,
      "logps/chosen": -158.32339477539062,
      "logps/rejected": -161.31570434570312,
      "loss": 0.4309,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.33473801612854,
      "rewards/margins": 2.0320866107940674,
      "rewards/rejected": -3.3668251037597656,
      "step": 11210
    },
    {
      "epoch": 2.047632083219272,
      "grad_norm": 4.275997638702393,
      "learning_rate": 2.5659728617916133e-05,
      "logits/chosen": -1.1623104810714722,
      "logits/rejected": -1.0518074035644531,
      "logps/chosen": -153.54177856445312,
      "logps/rejected": -154.05320739746094,
      "loss": 0.2492,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.1928586959838867,
      "rewards/margins": 2.292145252227783,
      "rewards/rejected": -4.485003471374512,
      "step": 11220
    },
    {
      "epoch": 2.0494570672506613,
      "grad_norm": 2.628612518310547,
      "learning_rate": 2.5610609688708787e-05,
      "logits/chosen": -1.3100779056549072,
      "logits/rejected": -1.1757911443710327,
      "logps/chosen": -172.42478942871094,
      "logps/rejected": -167.80853271484375,
      "loss": 0.242,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.278376817703247,
      "rewards/margins": 3.0760741233825684,
      "rewards/rejected": -4.3544511795043945,
      "step": 11230
    },
    {
      "epoch": 2.051282051282051,
      "grad_norm": 3.1152515411376953,
      "learning_rate": 2.5561490759501445e-05,
      "logits/chosen": -1.2110321521759033,
      "logits/rejected": -1.1757392883300781,
      "logps/chosen": -145.9450225830078,
      "logps/rejected": -163.2710418701172,
      "loss": 0.4966,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.2588305473327637,
      "rewards/margins": 1.7063268423080444,
      "rewards/rejected": -3.9651572704315186,
      "step": 11240
    },
    {
      "epoch": 2.053107035313441,
      "grad_norm": 2.6841673851013184,
      "learning_rate": 2.55123718302941e-05,
      "logits/chosen": -1.246832251548767,
      "logits/rejected": -1.132288932800293,
      "logps/chosen": -179.75140380859375,
      "logps/rejected": -185.07618713378906,
      "loss": 0.326,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7554471492767334,
      "rewards/margins": 2.557783603668213,
      "rewards/rejected": -4.313231468200684,
      "step": 11250
    },
    {
      "epoch": 2.0549320193448306,
      "grad_norm": 3.0672035217285156,
      "learning_rate": 2.546325290108676e-05,
      "logits/chosen": -1.264409065246582,
      "logits/rejected": -1.1799161434173584,
      "logps/chosen": -166.38302612304688,
      "logps/rejected": -166.43212890625,
      "loss": 0.2229,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.790440559387207,
      "rewards/margins": 2.5867724418640137,
      "rewards/rejected": -4.3772125244140625,
      "step": 11260
    },
    {
      "epoch": 2.0567570033762204,
      "grad_norm": 10.609604835510254,
      "learning_rate": 2.5414133971879415e-05,
      "logits/chosen": -1.2841449975967407,
      "logits/rejected": -1.230523705482483,
      "logps/chosen": -163.1524200439453,
      "logps/rejected": -179.86349487304688,
      "loss": 0.4443,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6307729482650757,
      "rewards/margins": 2.070061445236206,
      "rewards/rejected": -3.7008347511291504,
      "step": 11270
    },
    {
      "epoch": 2.05858198740761,
      "grad_norm": 4.287619113922119,
      "learning_rate": 2.5365015042672073e-05,
      "logits/chosen": -1.2744790315628052,
      "logits/rejected": -1.1828290224075317,
      "logps/chosen": -162.1321563720703,
      "logps/rejected": -169.27890014648438,
      "loss": 0.4583,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.987250566482544,
      "rewards/margins": 2.1578118801116943,
      "rewards/rejected": -4.145062446594238,
      "step": 11280
    },
    {
      "epoch": 2.060406971439,
      "grad_norm": 4.967191696166992,
      "learning_rate": 2.531589611346473e-05,
      "logits/chosen": -1.2250616550445557,
      "logits/rejected": -1.1691898107528687,
      "logps/chosen": -162.64158630371094,
      "logps/rejected": -172.88455200195312,
      "loss": 0.4938,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.183414936065674,
      "rewards/margins": 1.7845646142959595,
      "rewards/rejected": -3.9679789543151855,
      "step": 11290
    },
    {
      "epoch": 2.0622319554703896,
      "grad_norm": 2.001699447631836,
      "learning_rate": 2.5266777184257385e-05,
      "logits/chosen": -1.2466386556625366,
      "logits/rejected": -1.1004012823104858,
      "logps/chosen": -175.72080993652344,
      "logps/rejected": -161.00038146972656,
      "loss": 0.1963,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.7893508672714233,
      "rewards/margins": 2.6547296047210693,
      "rewards/rejected": -4.444080829620361,
      "step": 11300
    },
    {
      "epoch": 2.0640569395017794,
      "grad_norm": 3.2605323791503906,
      "learning_rate": 2.5217658255050043e-05,
      "logits/chosen": -1.186692237854004,
      "logits/rejected": -1.1311854124069214,
      "logps/chosen": -151.3538818359375,
      "logps/rejected": -170.05386352539062,
      "loss": 0.2908,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.0578324794769287,
      "rewards/margins": 2.4722607135772705,
      "rewards/rejected": -4.530093193054199,
      "step": 11310
    },
    {
      "epoch": 2.065881923533169,
      "grad_norm": 2.383222818374634,
      "learning_rate": 2.5168539325842697e-05,
      "logits/chosen": -1.1846923828125,
      "logits/rejected": -1.0779781341552734,
      "logps/chosen": -158.51998901367188,
      "logps/rejected": -151.7130584716797,
      "loss": 0.3596,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5174974203109741,
      "rewards/margins": 2.1516261100769043,
      "rewards/rejected": -3.669123411178589,
      "step": 11320
    },
    {
      "epoch": 2.067706907564559,
      "grad_norm": 6.480315685272217,
      "learning_rate": 2.5119420396635358e-05,
      "logits/chosen": -1.2200160026550293,
      "logits/rejected": -1.150217890739441,
      "logps/chosen": -176.0706024169922,
      "logps/rejected": -167.206787109375,
      "loss": 0.3494,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.7417104244232178,
      "rewards/margins": 1.936394453048706,
      "rewards/rejected": -3.678104877471924,
      "step": 11330
    },
    {
      "epoch": 2.0695318915959486,
      "grad_norm": 2.9431021213531494,
      "learning_rate": 2.5070301467428012e-05,
      "logits/chosen": -1.2089259624481201,
      "logits/rejected": -1.109795331954956,
      "logps/chosen": -166.35281372070312,
      "logps/rejected": -168.13519287109375,
      "loss": 0.241,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.7574306726455688,
      "rewards/margins": 2.493037700653076,
      "rewards/rejected": -4.2504682540893555,
      "step": 11340
    },
    {
      "epoch": 2.0713568756273384,
      "grad_norm": 5.956135272979736,
      "learning_rate": 2.502118253822067e-05,
      "logits/chosen": -1.2154157161712646,
      "logits/rejected": -1.0915963649749756,
      "logps/chosen": -175.42369079589844,
      "logps/rejected": -164.56417846679688,
      "loss": 0.3057,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.847533941268921,
      "rewards/margins": 2.1072795391082764,
      "rewards/rejected": -3.9548137187957764,
      "step": 11350
    },
    {
      "epoch": 2.073181859658728,
      "grad_norm": 4.700872898101807,
      "learning_rate": 2.4972063609013324e-05,
      "logits/chosen": -1.1734453439712524,
      "logits/rejected": -1.1055498123168945,
      "logps/chosen": -171.60472106933594,
      "logps/rejected": -171.63540649414062,
      "loss": 0.3154,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.1455483436584473,
      "rewards/margins": 2.183108329772949,
      "rewards/rejected": -4.3286566734313965,
      "step": 11360
    },
    {
      "epoch": 2.075006843690118,
      "grad_norm": 5.131352424621582,
      "learning_rate": 2.4922944679805982e-05,
      "logits/chosen": -1.1554412841796875,
      "logits/rejected": -1.0898274183273315,
      "logps/chosen": -158.49041748046875,
      "logps/rejected": -168.93255615234375,
      "loss": 0.3326,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.3519062995910645,
      "rewards/margins": 2.5941853523254395,
      "rewards/rejected": -4.946091651916504,
      "step": 11370
    },
    {
      "epoch": 2.0768318277215077,
      "grad_norm": 4.37022066116333,
      "learning_rate": 2.4873825750598637e-05,
      "logits/chosen": -1.1884405612945557,
      "logits/rejected": -1.106744408607483,
      "logps/chosen": -170.19456481933594,
      "logps/rejected": -175.54849243164062,
      "loss": 0.2485,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.1912758350372314,
      "rewards/margins": 2.530205488204956,
      "rewards/rejected": -4.721480846405029,
      "step": 11380
    },
    {
      "epoch": 2.078656811752897,
      "grad_norm": 4.075567722320557,
      "learning_rate": 2.4824706821391294e-05,
      "logits/chosen": -1.1922816038131714,
      "logits/rejected": -1.135796308517456,
      "logps/chosen": -168.89736938476562,
      "logps/rejected": -194.56785583496094,
      "loss": 0.3002,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.3401355743408203,
      "rewards/margins": 2.6220192909240723,
      "rewards/rejected": -4.962154865264893,
      "step": 11390
    },
    {
      "epoch": 2.0804817957842867,
      "grad_norm": 7.837939262390137,
      "learning_rate": 2.4775587892183955e-05,
      "logits/chosen": -1.2115776538848877,
      "logits/rejected": -1.0838252305984497,
      "logps/chosen": -169.58401489257812,
      "logps/rejected": -184.14715576171875,
      "loss": 0.3544,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.3707733154296875,
      "rewards/margins": 2.8090758323669434,
      "rewards/rejected": -5.179848670959473,
      "step": 11400
    },
    {
      "epoch": 2.0823067798156765,
      "grad_norm": 1.8097045421600342,
      "learning_rate": 2.472646896297661e-05,
      "logits/chosen": -1.2616509199142456,
      "logits/rejected": -1.176468849182129,
      "logps/chosen": -184.99313354492188,
      "logps/rejected": -181.43174743652344,
      "loss": 0.2586,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0490238666534424,
      "rewards/margins": 2.5555367469787598,
      "rewards/rejected": -4.604560852050781,
      "step": 11410
    },
    {
      "epoch": 2.084131763847066,
      "grad_norm": 5.411459445953369,
      "learning_rate": 2.4677350033769267e-05,
      "logits/chosen": -1.192551612854004,
      "logits/rejected": -1.1017699241638184,
      "logps/chosen": -174.2569122314453,
      "logps/rejected": -165.97743225097656,
      "loss": 0.3305,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.456251859664917,
      "rewards/margins": 2.2214324474334717,
      "rewards/rejected": -4.677684307098389,
      "step": 11420
    },
    {
      "epoch": 2.085956747878456,
      "grad_norm": 4.494857311248779,
      "learning_rate": 2.4628231104561922e-05,
      "logits/chosen": -1.271417260169983,
      "logits/rejected": -1.2399227619171143,
      "logps/chosen": -174.86036682128906,
      "logps/rejected": -179.6681671142578,
      "loss": 0.4617,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0467288494110107,
      "rewards/margins": 1.838179588317871,
      "rewards/rejected": -3.884908676147461,
      "step": 11430
    },
    {
      "epoch": 2.0877817319098457,
      "grad_norm": 6.914574146270752,
      "learning_rate": 2.457911217535458e-05,
      "logits/chosen": -1.2119325399398804,
      "logits/rejected": -1.124624490737915,
      "logps/chosen": -165.5232391357422,
      "logps/rejected": -165.5179443359375,
      "loss": 0.3421,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8190147876739502,
      "rewards/margins": 2.1884734630584717,
      "rewards/rejected": -4.007488250732422,
      "step": 11440
    },
    {
      "epoch": 2.0896067159412355,
      "grad_norm": 4.448939323425293,
      "learning_rate": 2.4529993246147234e-05,
      "logits/chosen": -1.2184315919876099,
      "logits/rejected": -1.1292505264282227,
      "logps/chosen": -144.38206481933594,
      "logps/rejected": -151.14964294433594,
      "loss": 0.3541,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.7470111846923828,
      "rewards/margins": 2.178457021713257,
      "rewards/rejected": -3.9254677295684814,
      "step": 11450
    },
    {
      "epoch": 2.0914316999726252,
      "grad_norm": 7.3028950691223145,
      "learning_rate": 2.448087431693989e-05,
      "logits/chosen": -1.2298052310943604,
      "logits/rejected": -1.2099814414978027,
      "logps/chosen": -160.74574279785156,
      "logps/rejected": -188.5852813720703,
      "loss": 0.3493,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.6158974170684814,
      "rewards/margins": 2.0910565853118896,
      "rewards/rejected": -3.70695424079895,
      "step": 11460
    },
    {
      "epoch": 2.093256684004015,
      "grad_norm": 7.340243339538574,
      "learning_rate": 2.4431755387732546e-05,
      "logits/chosen": -1.2102206945419312,
      "logits/rejected": -1.1322036981582642,
      "logps/chosen": -153.53396606445312,
      "logps/rejected": -167.28509521484375,
      "loss": 0.3815,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.1841323375701904,
      "rewards/margins": 2.1356444358825684,
      "rewards/rejected": -4.319777488708496,
      "step": 11470
    },
    {
      "epoch": 2.0950816680354047,
      "grad_norm": 1.194730520248413,
      "learning_rate": 2.4382636458525207e-05,
      "logits/chosen": -1.2920396327972412,
      "logits/rejected": -1.1110680103302002,
      "logps/chosen": -185.931884765625,
      "logps/rejected": -162.5642547607422,
      "loss": 0.2604,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.5610872507095337,
      "rewards/margins": 2.4888386726379395,
      "rewards/rejected": -4.049925804138184,
      "step": 11480
    },
    {
      "epoch": 2.0969066520667945,
      "grad_norm": 4.891061782836914,
      "learning_rate": 2.4333517529317865e-05,
      "logits/chosen": -1.2196476459503174,
      "logits/rejected": -1.118920087814331,
      "logps/chosen": -157.8726348876953,
      "logps/rejected": -160.34878540039062,
      "loss": 0.2289,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.4362645149230957,
      "rewards/margins": 2.272414207458496,
      "rewards/rejected": -4.708678245544434,
      "step": 11490
    },
    {
      "epoch": 2.0987316360981843,
      "grad_norm": 4.212214469909668,
      "learning_rate": 2.428439860011052e-05,
      "logits/chosen": -1.2339882850646973,
      "logits/rejected": -1.2116777896881104,
      "logps/chosen": -164.5915069580078,
      "logps/rejected": -189.39004516601562,
      "loss": 0.2781,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.273834466934204,
      "rewards/margins": 2.1483397483825684,
      "rewards/rejected": -4.422173976898193,
      "step": 11500
    },
    {
      "epoch": 2.100556620129574,
      "grad_norm": 8.740239143371582,
      "learning_rate": 2.4235279670903177e-05,
      "logits/chosen": -1.225770354270935,
      "logits/rejected": -1.1255981922149658,
      "logps/chosen": -164.23760986328125,
      "logps/rejected": -183.17526245117188,
      "loss": 0.3169,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.358119249343872,
      "rewards/margins": 2.616420030593872,
      "rewards/rejected": -4.974539279937744,
      "step": 11510
    },
    {
      "epoch": 2.1023816041609638,
      "grad_norm": 6.013388156890869,
      "learning_rate": 2.418616074169583e-05,
      "logits/chosen": -1.2980852127075195,
      "logits/rejected": -1.194107174873352,
      "logps/chosen": -204.8367462158203,
      "logps/rejected": -183.0615692138672,
      "loss": 0.2892,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.6208856105804443,
      "rewards/margins": 2.2541911602020264,
      "rewards/rejected": -4.875076770782471,
      "step": 11520
    },
    {
      "epoch": 2.1042065881923535,
      "grad_norm": 3.9747018814086914,
      "learning_rate": 2.4137041812488492e-05,
      "logits/chosen": -1.2217646837234497,
      "logits/rejected": -1.169862985610962,
      "logps/chosen": -169.49754333496094,
      "logps/rejected": -194.9890899658203,
      "loss": 0.293,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.773510217666626,
      "rewards/margins": 3.0118584632873535,
      "rewards/rejected": -5.785368919372559,
      "step": 11530
    },
    {
      "epoch": 2.106031572223743,
      "grad_norm": 2.792853355407715,
      "learning_rate": 2.4087922883281147e-05,
      "logits/chosen": -1.246253252029419,
      "logits/rejected": -1.152134895324707,
      "logps/chosen": -168.18911743164062,
      "logps/rejected": -170.4141845703125,
      "loss": 0.2676,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.4618046283721924,
      "rewards/margins": 2.5209715366363525,
      "rewards/rejected": -4.982775688171387,
      "step": 11540
    },
    {
      "epoch": 2.1078565562551326,
      "grad_norm": 6.778815269470215,
      "learning_rate": 2.4038803954073804e-05,
      "logits/chosen": -1.2019927501678467,
      "logits/rejected": -1.0930612087249756,
      "logps/chosen": -182.00442504882812,
      "logps/rejected": -179.6391143798828,
      "loss": 0.2151,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.8188514709472656,
      "rewards/margins": 2.6362497806549072,
      "rewards/rejected": -5.455101013183594,
      "step": 11550
    },
    {
      "epoch": 2.1096815402865223,
      "grad_norm": 3.034881591796875,
      "learning_rate": 2.398968502486646e-05,
      "logits/chosen": -1.2739524841308594,
      "logits/rejected": -1.1119706630706787,
      "logps/chosen": -190.2325439453125,
      "logps/rejected": -189.31192016601562,
      "loss": 0.2133,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.7348480224609375,
      "rewards/margins": 3.2331225872039795,
      "rewards/rejected": -5.967970848083496,
      "step": 11560
    },
    {
      "epoch": 2.111506524317912,
      "grad_norm": 1.7558608055114746,
      "learning_rate": 2.3940566095659116e-05,
      "logits/chosen": -1.2373127937316895,
      "logits/rejected": -1.1038100719451904,
      "logps/chosen": -178.2256317138672,
      "logps/rejected": -178.27403259277344,
      "loss": 0.2513,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.2514941692352295,
      "rewards/margins": 2.944952964782715,
      "rewards/rejected": -5.196447372436523,
      "step": 11570
    },
    {
      "epoch": 2.113331508349302,
      "grad_norm": 5.182109355926514,
      "learning_rate": 2.389144716645177e-05,
      "logits/chosen": -1.2507179975509644,
      "logits/rejected": -1.1298892498016357,
      "logps/chosen": -184.5920867919922,
      "logps/rejected": -183.67237854003906,
      "loss": 0.298,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.441603183746338,
      "rewards/margins": 2.893683433532715,
      "rewards/rejected": -5.3352861404418945,
      "step": 11580
    },
    {
      "epoch": 2.1151564923806916,
      "grad_norm": 5.690244674682617,
      "learning_rate": 2.384232823724443e-05,
      "logits/chosen": -1.2712278366088867,
      "logits/rejected": -1.1433348655700684,
      "logps/chosen": -180.54446411132812,
      "logps/rejected": -169.3202667236328,
      "loss": 0.2944,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.163719892501831,
      "rewards/margins": 2.7230169773101807,
      "rewards/rejected": -4.886736869812012,
      "step": 11590
    },
    {
      "epoch": 2.1169814764120813,
      "grad_norm": 3.0530810356140137,
      "learning_rate": 2.379320930803709e-05,
      "logits/chosen": -1.254238247871399,
      "logits/rejected": -1.1414411067962646,
      "logps/chosen": -181.0348358154297,
      "logps/rejected": -180.34967041015625,
      "loss": 0.4077,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.6908769607543945,
      "rewards/margins": 2.510910749435425,
      "rewards/rejected": -5.20178747177124,
      "step": 11600
    },
    {
      "epoch": 2.118806460443471,
      "grad_norm": 3.8000950813293457,
      "learning_rate": 2.3744090378829744e-05,
      "logits/chosen": -1.2036292552947998,
      "logits/rejected": -1.1078177690505981,
      "logps/chosen": -168.82723999023438,
      "logps/rejected": -181.7908935546875,
      "loss": 0.2591,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1761717796325684,
      "rewards/margins": 2.747833490371704,
      "rewards/rejected": -4.924004554748535,
      "step": 11610
    },
    {
      "epoch": 2.120631444474861,
      "grad_norm": 7.652174949645996,
      "learning_rate": 2.3694971449622402e-05,
      "logits/chosen": -1.195530652999878,
      "logits/rejected": -1.148537039756775,
      "logps/chosen": -180.4358673095703,
      "logps/rejected": -191.3414306640625,
      "loss": 0.3442,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.565173625946045,
      "rewards/margins": 2.67232346534729,
      "rewards/rejected": -5.237497329711914,
      "step": 11620
    },
    {
      "epoch": 2.1224564285062506,
      "grad_norm": 4.346029758453369,
      "learning_rate": 2.3645852520415056e-05,
      "logits/chosen": -1.1583406925201416,
      "logits/rejected": -1.1297154426574707,
      "logps/chosen": -150.4487762451172,
      "logps/rejected": -173.6381378173828,
      "loss": 0.4155,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.4497597217559814,
      "rewards/margins": 1.8547531366348267,
      "rewards/rejected": -4.304512977600098,
      "step": 11630
    },
    {
      "epoch": 2.1242814125376404,
      "grad_norm": 2.0186266899108887,
      "learning_rate": 2.3596733591207714e-05,
      "logits/chosen": -1.2721158266067505,
      "logits/rejected": -1.1232311725616455,
      "logps/chosen": -166.56236267089844,
      "logps/rejected": -148.88917541503906,
      "loss": 0.3338,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.952760100364685,
      "rewards/margins": 2.0080654621124268,
      "rewards/rejected": -3.9608254432678223,
      "step": 11640
    },
    {
      "epoch": 2.12610639656903,
      "grad_norm": 4.06038236618042,
      "learning_rate": 2.3547614662000368e-05,
      "logits/chosen": -1.137033462524414,
      "logits/rejected": -1.121436357498169,
      "logps/chosen": -168.47030639648438,
      "logps/rejected": -198.01162719726562,
      "loss": 0.2913,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.092303514480591,
      "rewards/margins": 2.5572075843811035,
      "rewards/rejected": -4.649510860443115,
      "step": 11650
    },
    {
      "epoch": 2.12793138060042,
      "grad_norm": 5.410973072052002,
      "learning_rate": 2.350340762571376e-05,
      "logits/chosen": -1.1994026899337769,
      "logits/rejected": -1.0983250141143799,
      "logps/chosen": -173.9102020263672,
      "logps/rejected": -171.22044372558594,
      "loss": 0.4181,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.5528178215026855,
      "rewards/margins": 2.2483086585998535,
      "rewards/rejected": -4.801126956939697,
      "step": 11660
    },
    {
      "epoch": 2.1297563646318096,
      "grad_norm": 4.134652137756348,
      "learning_rate": 2.345428869650642e-05,
      "logits/chosen": -1.154605746269226,
      "logits/rejected": -1.0888383388519287,
      "logps/chosen": -169.2804412841797,
      "logps/rejected": -181.23538208007812,
      "loss": 0.1959,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -2.068817138671875,
      "rewards/margins": 2.5199828147888184,
      "rewards/rejected": -4.588799476623535,
      "step": 11670
    },
    {
      "epoch": 2.1315813486631994,
      "grad_norm": 3.044332981109619,
      "learning_rate": 2.3405169767299076e-05,
      "logits/chosen": -1.2225019931793213,
      "logits/rejected": -1.1011650562286377,
      "logps/chosen": -167.15440368652344,
      "logps/rejected": -187.05921936035156,
      "loss": 0.3242,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4491019248962402,
      "rewards/margins": 2.555710792541504,
      "rewards/rejected": -5.004812717437744,
      "step": 11680
    },
    {
      "epoch": 2.133406332694589,
      "grad_norm": 7.389141082763672,
      "learning_rate": 2.3356050838091733e-05,
      "logits/chosen": -1.1951870918273926,
      "logits/rejected": -1.1121056079864502,
      "logps/chosen": -174.1280517578125,
      "logps/rejected": -174.32406616210938,
      "loss": 0.4132,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.6843066215515137,
      "rewards/margins": 1.9911407232284546,
      "rewards/rejected": -4.6754469871521,
      "step": 11690
    },
    {
      "epoch": 2.135231316725979,
      "grad_norm": 3.862515687942505,
      "learning_rate": 2.3306931908884388e-05,
      "logits/chosen": -1.155526876449585,
      "logits/rejected": -1.092370867729187,
      "logps/chosen": -159.2167205810547,
      "logps/rejected": -170.00320434570312,
      "loss": 0.2402,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1682915687561035,
      "rewards/margins": 2.833585023880005,
      "rewards/rejected": -5.001877307891846,
      "step": 11700
    },
    {
      "epoch": 2.137056300757368,
      "grad_norm": 1.597720742225647,
      "learning_rate": 2.3257812979677045e-05,
      "logits/chosen": -1.1520965099334717,
      "logits/rejected": -1.060023307800293,
      "logps/chosen": -163.94552612304688,
      "logps/rejected": -176.0166473388672,
      "loss": 0.244,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.111274242401123,
      "rewards/margins": 2.7120869159698486,
      "rewards/rejected": -4.823361396789551,
      "step": 11710
    },
    {
      "epoch": 2.138881284788758,
      "grad_norm": 1.6933705806732178,
      "learning_rate": 2.32086940504697e-05,
      "logits/chosen": -1.2002209424972534,
      "logits/rejected": -1.0770204067230225,
      "logps/chosen": -178.73953247070312,
      "logps/rejected": -174.19778442382812,
      "loss": 0.2328,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.990869164466858,
      "rewards/margins": 2.803340196609497,
      "rewards/rejected": -4.794209003448486,
      "step": 11720
    },
    {
      "epoch": 2.1407062688201477,
      "grad_norm": 4.43551778793335,
      "learning_rate": 2.3159575121262357e-05,
      "logits/chosen": -1.2550781965255737,
      "logits/rejected": -1.1101853847503662,
      "logps/chosen": -186.67440795898438,
      "logps/rejected": -187.67160034179688,
      "loss": 0.3127,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.361558198928833,
      "rewards/margins": 2.7761645317077637,
      "rewards/rejected": -5.137722969055176,
      "step": 11730
    },
    {
      "epoch": 2.1425312528515374,
      "grad_norm": 7.0151519775390625,
      "learning_rate": 2.3110456192055012e-05,
      "logits/chosen": -1.1782416105270386,
      "logits/rejected": -1.1130167245864868,
      "logps/chosen": -155.9579620361328,
      "logps/rejected": -180.75965881347656,
      "loss": 0.4079,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.434551239013672,
      "rewards/margins": 2.4036974906921387,
      "rewards/rejected": -4.838249206542969,
      "step": 11740
    },
    {
      "epoch": 2.144356236882927,
      "grad_norm": 4.862312316894531,
      "learning_rate": 2.3061337262847673e-05,
      "logits/chosen": -1.21017587184906,
      "logits/rejected": -1.206594467163086,
      "logps/chosen": -163.97119140625,
      "logps/rejected": -202.97006225585938,
      "loss": 0.2078,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.1622109413146973,
      "rewards/margins": 2.494912624359131,
      "rewards/rejected": -4.657124042510986,
      "step": 11750
    },
    {
      "epoch": 2.146181220914317,
      "grad_norm": 4.869190216064453,
      "learning_rate": 2.301221833364033e-05,
      "logits/chosen": -1.2298400402069092,
      "logits/rejected": -1.1592543125152588,
      "logps/chosen": -169.88046264648438,
      "logps/rejected": -192.31192016601562,
      "loss": 0.3152,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.49385666847229,
      "rewards/margins": 2.8330166339874268,
      "rewards/rejected": -5.326872825622559,
      "step": 11760
    },
    {
      "epoch": 2.1480062049457067,
      "grad_norm": 2.5245790481567383,
      "learning_rate": 2.2963099404432985e-05,
      "logits/chosen": -1.2328118085861206,
      "logits/rejected": -1.1427665948867798,
      "logps/chosen": -172.06431579589844,
      "logps/rejected": -185.12704467773438,
      "loss": 0.2663,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.716669797897339,
      "rewards/margins": 2.5203135013580322,
      "rewards/rejected": -5.236983299255371,
      "step": 11770
    },
    {
      "epoch": 2.1498311889770965,
      "grad_norm": 1.7370271682739258,
      "learning_rate": 2.2913980475225643e-05,
      "logits/chosen": -1.2369019985198975,
      "logits/rejected": -1.1279242038726807,
      "logps/chosen": -168.10467529296875,
      "logps/rejected": -181.79501342773438,
      "loss": 0.2655,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.545288562774658,
      "rewards/margins": 2.913693904876709,
      "rewards/rejected": -5.458982944488525,
      "step": 11780
    },
    {
      "epoch": 2.151656173008486,
      "grad_norm": 4.481453895568848,
      "learning_rate": 2.2864861546018297e-05,
      "logits/chosen": -1.2523729801177979,
      "logits/rejected": -1.1291016340255737,
      "logps/chosen": -182.3856964111328,
      "logps/rejected": -193.30259704589844,
      "loss": 0.2541,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1732287406921387,
      "rewards/margins": 3.142693042755127,
      "rewards/rejected": -5.315921783447266,
      "step": 11790
    },
    {
      "epoch": 2.153481157039876,
      "grad_norm": 2.6076548099517822,
      "learning_rate": 2.2815742616810955e-05,
      "logits/chosen": -1.2297793626785278,
      "logits/rejected": -1.128424882888794,
      "logps/chosen": -173.2235870361328,
      "logps/rejected": -185.4983673095703,
      "loss": 0.2774,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.575652837753296,
      "rewards/margins": 2.7331440448760986,
      "rewards/rejected": -5.3087968826293945,
      "step": 11800
    },
    {
      "epoch": 2.1553061410712657,
      "grad_norm": 12.663747787475586,
      "learning_rate": 2.276662368760361e-05,
      "logits/chosen": -1.1908471584320068,
      "logits/rejected": -1.1100746393203735,
      "logps/chosen": -177.93649291992188,
      "logps/rejected": -191.8406219482422,
      "loss": 0.3905,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.8010191917419434,
      "rewards/margins": 2.421412229537964,
      "rewards/rejected": -5.22243070602417,
      "step": 11810
    },
    {
      "epoch": 2.1571311251026555,
      "grad_norm": 1.034537434577942,
      "learning_rate": 2.271750475839627e-05,
      "logits/chosen": -1.2280089855194092,
      "logits/rejected": -1.1419483423233032,
      "logps/chosen": -169.42263793945312,
      "logps/rejected": -179.23316955566406,
      "loss": 0.2501,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1966605186462402,
      "rewards/margins": 2.722167491912842,
      "rewards/rejected": -4.918828010559082,
      "step": 11820
    },
    {
      "epoch": 2.1589561091340452,
      "grad_norm": 4.634347438812256,
      "learning_rate": 2.2668385829188925e-05,
      "logits/chosen": -1.2773797512054443,
      "logits/rejected": -1.1690332889556885,
      "logps/chosen": -178.46926879882812,
      "logps/rejected": -177.37496948242188,
      "loss": 0.2453,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.464005947113037,
      "rewards/margins": 2.5419416427612305,
      "rewards/rejected": -5.005948066711426,
      "step": 11830
    },
    {
      "epoch": 2.160781093165435,
      "grad_norm": 11.062111854553223,
      "learning_rate": 2.2619266899981582e-05,
      "logits/chosen": -1.1713584661483765,
      "logits/rejected": -1.1334916353225708,
      "logps/chosen": -167.64805603027344,
      "logps/rejected": -193.10037231445312,
      "loss": 0.2542,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.8226373195648193,
      "rewards/margins": 2.8835957050323486,
      "rewards/rejected": -5.706233024597168,
      "step": 11840
    },
    {
      "epoch": 2.1626060771968243,
      "grad_norm": 8.489309310913086,
      "learning_rate": 2.2575059863694974e-05,
      "logits/chosen": -1.2373167276382446,
      "logits/rejected": -1.1318992376327515,
      "logps/chosen": -170.73719787597656,
      "logps/rejected": -180.1676483154297,
      "loss": 0.3764,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.8028976917266846,
      "rewards/margins": 2.260329484939575,
      "rewards/rejected": -5.06322717666626,
      "step": 11850
    },
    {
      "epoch": 2.164431061228214,
      "grad_norm": 5.9433913230896,
      "learning_rate": 2.252594093448763e-05,
      "logits/chosen": -1.186642050743103,
      "logits/rejected": -1.084688425064087,
      "logps/chosen": -181.98667907714844,
      "logps/rejected": -178.13992309570312,
      "loss": 0.2608,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.330986261367798,
      "rewards/margins": 3.25896954536438,
      "rewards/rejected": -5.5899553298950195,
      "step": 11860
    },
    {
      "epoch": 2.166256045259604,
      "grad_norm": 3.731926918029785,
      "learning_rate": 2.2476822005280286e-05,
      "logits/chosen": -1.1790566444396973,
      "logits/rejected": -1.1109817028045654,
      "logps/chosen": -157.49246215820312,
      "logps/rejected": -168.00506591796875,
      "loss": 0.2811,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.8651933670043945,
      "rewards/margins": 2.1600372791290283,
      "rewards/rejected": -5.025230884552002,
      "step": 11870
    },
    {
      "epoch": 2.1680810292909936,
      "grad_norm": 7.806288242340088,
      "learning_rate": 2.242770307607294e-05,
      "logits/chosen": -1.1485097408294678,
      "logits/rejected": -1.1189610958099365,
      "logps/chosen": -164.669921875,
      "logps/rejected": -199.863525390625,
      "loss": 0.4023,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.9493775367736816,
      "rewards/margins": 3.168705701828003,
      "rewards/rejected": -6.118082523345947,
      "step": 11880
    },
    {
      "epoch": 2.1699060133223833,
      "grad_norm": 4.359768867492676,
      "learning_rate": 2.2378584146865602e-05,
      "logits/chosen": -1.2097398042678833,
      "logits/rejected": -1.1137181520462036,
      "logps/chosen": -173.79409790039062,
      "logps/rejected": -192.406005859375,
      "loss": 0.3728,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.854681968688965,
      "rewards/margins": 2.7674694061279297,
      "rewards/rejected": -5.6221513748168945,
      "step": 11890
    },
    {
      "epoch": 2.171730997353773,
      "grad_norm": 6.320169925689697,
      "learning_rate": 2.2329465217658256e-05,
      "logits/chosen": -1.188458800315857,
      "logits/rejected": -1.1988990306854248,
      "logps/chosen": -169.5057373046875,
      "logps/rejected": -217.9756622314453,
      "loss": 0.3694,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.690147638320923,
      "rewards/margins": 3.012577533721924,
      "rewards/rejected": -5.702724933624268,
      "step": 11900
    },
    {
      "epoch": 2.173555981385163,
      "grad_norm": 10.241744041442871,
      "learning_rate": 2.2280346288450914e-05,
      "logits/chosen": -1.2433747053146362,
      "logits/rejected": -1.1466368436813354,
      "logps/chosen": -171.6771240234375,
      "logps/rejected": -175.31820678710938,
      "loss": 0.2342,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.2951619625091553,
      "rewards/margins": 2.7120308876037598,
      "rewards/rejected": -5.007193088531494,
      "step": 11910
    },
    {
      "epoch": 2.1753809654165526,
      "grad_norm": 4.752476215362549,
      "learning_rate": 2.223122735924357e-05,
      "logits/chosen": -1.253525972366333,
      "logits/rejected": -1.1409494876861572,
      "logps/chosen": -178.58334350585938,
      "logps/rejected": -190.63076782226562,
      "loss": 0.2328,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1673340797424316,
      "rewards/margins": 2.834291458129883,
      "rewards/rejected": -5.001625061035156,
      "step": 11920
    },
    {
      "epoch": 2.1772059494479423,
      "grad_norm": 6.577836036682129,
      "learning_rate": 2.2182108430036226e-05,
      "logits/chosen": -1.2597860097885132,
      "logits/rejected": -1.1481307744979858,
      "logps/chosen": -181.95199584960938,
      "logps/rejected": -173.4697723388672,
      "loss": 0.3805,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.4262123107910156,
      "rewards/margins": 2.7371978759765625,
      "rewards/rejected": -5.163410663604736,
      "step": 11930
    },
    {
      "epoch": 2.179030933479332,
      "grad_norm": 1.3222262859344482,
      "learning_rate": 2.2132989500828884e-05,
      "logits/chosen": -1.2591960430145264,
      "logits/rejected": -1.1629101037979126,
      "logps/chosen": -171.67962646484375,
      "logps/rejected": -181.32810974121094,
      "loss": 0.3078,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.025430917739868,
      "rewards/margins": 2.99434757232666,
      "rewards/rejected": -5.019778251647949,
      "step": 11940
    },
    {
      "epoch": 2.180855917510722,
      "grad_norm": 1.9168742895126343,
      "learning_rate": 2.2083870571621538e-05,
      "logits/chosen": -1.21807861328125,
      "logits/rejected": -1.1112251281738281,
      "logps/chosen": -159.68832397460938,
      "logps/rejected": -161.7839813232422,
      "loss": 0.3573,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.249345302581787,
      "rewards/margins": 2.608405590057373,
      "rewards/rejected": -4.85775089263916,
      "step": 11950
    },
    {
      "epoch": 2.1826809015421116,
      "grad_norm": 10.74804973602295,
      "learning_rate": 2.20347516424142e-05,
      "logits/chosen": -1.2423843145370483,
      "logits/rejected": -1.1363441944122314,
      "logps/chosen": -180.73973083496094,
      "logps/rejected": -179.04835510253906,
      "loss": 0.324,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4875214099884033,
      "rewards/margins": 2.384122371673584,
      "rewards/rejected": -4.871644020080566,
      "step": 11960
    },
    {
      "epoch": 2.1845058855735013,
      "grad_norm": 7.08191442489624,
      "learning_rate": 2.1985632713206854e-05,
      "logits/chosen": -1.2233307361602783,
      "logits/rejected": -1.0901405811309814,
      "logps/chosen": -164.8277587890625,
      "logps/rejected": -173.89859008789062,
      "loss": 0.3069,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.479099750518799,
      "rewards/margins": 2.9114391803741455,
      "rewards/rejected": -5.390538215637207,
      "step": 11970
    },
    {
      "epoch": 2.186330869604891,
      "grad_norm": 10.726205825805664,
      "learning_rate": 2.193651378399951e-05,
      "logits/chosen": -1.1752729415893555,
      "logits/rejected": -1.1231380701065063,
      "logps/chosen": -176.93966674804688,
      "logps/rejected": -197.87815856933594,
      "loss": 0.3649,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.690981388092041,
      "rewards/margins": 2.8985044956207275,
      "rewards/rejected": -5.589486122131348,
      "step": 11980
    },
    {
      "epoch": 2.188155853636281,
      "grad_norm": 3.093743085861206,
      "learning_rate": 2.1887394854792166e-05,
      "logits/chosen": -1.173377275466919,
      "logits/rejected": -1.1376018524169922,
      "logps/chosen": -161.1842041015625,
      "logps/rejected": -192.339599609375,
      "loss": 0.2645,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.7212560176849365,
      "rewards/margins": 2.8997817039489746,
      "rewards/rejected": -5.621037483215332,
      "step": 11990
    },
    {
      "epoch": 2.1899808376676706,
      "grad_norm": 3.9189200401306152,
      "learning_rate": 2.1838275925584823e-05,
      "logits/chosen": -1.2081875801086426,
      "logits/rejected": -1.1209303140640259,
      "logps/chosen": -168.29086303710938,
      "logps/rejected": -181.46231079101562,
      "loss": 0.2539,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.3219494819641113,
      "rewards/margins": 2.9104554653167725,
      "rewards/rejected": -5.232405662536621,
      "step": 12000
    },
    {
      "epoch": 2.1918058216990604,
      "grad_norm": 6.043946266174316,
      "learning_rate": 2.1789156996377484e-05,
      "logits/chosen": -1.167874813079834,
      "logits/rejected": -1.0687410831451416,
      "logps/chosen": -165.71791076660156,
      "logps/rejected": -179.04873657226562,
      "loss": 0.2498,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.295576333999634,
      "rewards/margins": 2.708982467651367,
      "rewards/rejected": -5.00455904006958,
      "step": 12010
    },
    {
      "epoch": 2.1936308057304497,
      "grad_norm": 6.672468662261963,
      "learning_rate": 2.174003806717014e-05,
      "logits/chosen": -1.1755120754241943,
      "logits/rejected": -1.1302392482757568,
      "logps/chosen": -162.66152954101562,
      "logps/rejected": -185.24893188476562,
      "loss": 0.3811,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.9054250717163086,
      "rewards/margins": 2.283651828765869,
      "rewards/rejected": -5.1890764236450195,
      "step": 12020
    },
    {
      "epoch": 2.1954557897618394,
      "grad_norm": 5.543096542358398,
      "learning_rate": 2.1690919137962797e-05,
      "logits/chosen": -1.2370398044586182,
      "logits/rejected": -1.1590803861618042,
      "logps/chosen": -178.46287536621094,
      "logps/rejected": -185.00790405273438,
      "loss": 0.3328,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.9138883352279663,
      "rewards/margins": 2.4398279190063477,
      "rewards/rejected": -4.353716850280762,
      "step": 12030
    },
    {
      "epoch": 2.197280773793229,
      "grad_norm": 7.685979843139648,
      "learning_rate": 2.164180020875545e-05,
      "logits/chosen": -1.2553519010543823,
      "logits/rejected": -1.1657040119171143,
      "logps/chosen": -174.890380859375,
      "logps/rejected": -183.55014038085938,
      "loss": 0.339,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.6991878747940063,
      "rewards/margins": 2.5011329650878906,
      "rewards/rejected": -4.200321197509766,
      "step": 12040
    },
    {
      "epoch": 2.199105757824619,
      "grad_norm": 5.138479709625244,
      "learning_rate": 2.159268127954811e-05,
      "logits/chosen": -1.1694456338882446,
      "logits/rejected": -1.1394314765930176,
      "logps/chosen": -146.8055877685547,
      "logps/rejected": -160.36666870117188,
      "loss": 0.2986,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.6170660257339478,
      "rewards/margins": 2.450573444366455,
      "rewards/rejected": -4.067639350891113,
      "step": 12050
    },
    {
      "epoch": 2.2009307418560087,
      "grad_norm": 5.504341125488281,
      "learning_rate": 2.1543562350340763e-05,
      "logits/chosen": -1.23264479637146,
      "logits/rejected": -1.1314948797225952,
      "logps/chosen": -166.03610229492188,
      "logps/rejected": -178.69717407226562,
      "loss": 0.1973,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.9829704761505127,
      "rewards/margins": 2.6040453910827637,
      "rewards/rejected": -4.5870161056518555,
      "step": 12060
    },
    {
      "epoch": 2.2027557258873984,
      "grad_norm": 7.253330707550049,
      "learning_rate": 2.149444342113342e-05,
      "logits/chosen": -1.247113823890686,
      "logits/rejected": -1.1631534099578857,
      "logps/chosen": -162.42599487304688,
      "logps/rejected": -171.1633758544922,
      "loss": 0.2511,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -1.7614784240722656,
      "rewards/margins": 2.338632822036743,
      "rewards/rejected": -4.100111484527588,
      "step": 12070
    },
    {
      "epoch": 2.204580709918788,
      "grad_norm": 3.8374438285827637,
      "learning_rate": 2.1445324491926075e-05,
      "logits/chosen": -1.2316055297851562,
      "logits/rejected": -1.107580304145813,
      "logps/chosen": -170.61444091796875,
      "logps/rejected": -165.62521362304688,
      "loss": 0.3092,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8243465423583984,
      "rewards/margins": 2.4195780754089355,
      "rewards/rejected": -4.243924617767334,
      "step": 12080
    },
    {
      "epoch": 2.206405693950178,
      "grad_norm": 2.321857213973999,
      "learning_rate": 2.1396205562718736e-05,
      "logits/chosen": -1.2533562183380127,
      "logits/rejected": -1.1826545000076294,
      "logps/chosen": -161.62733459472656,
      "logps/rejected": -179.50088500976562,
      "loss": 0.2942,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.3458526134490967,
      "rewards/margins": 2.5709831714630127,
      "rewards/rejected": -3.9168357849121094,
      "step": 12090
    },
    {
      "epoch": 2.2082306779815677,
      "grad_norm": 5.516061782836914,
      "learning_rate": 2.134708663351139e-05,
      "logits/chosen": -1.2259082794189453,
      "logits/rejected": -1.1703054904937744,
      "logps/chosen": -160.17489624023438,
      "logps/rejected": -172.95973205566406,
      "loss": 0.3678,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9225603342056274,
      "rewards/margins": 2.0330700874328613,
      "rewards/rejected": -3.9556307792663574,
      "step": 12100
    },
    {
      "epoch": 2.2100556620129574,
      "grad_norm": 1.2064465284347534,
      "learning_rate": 2.1297967704304048e-05,
      "logits/chosen": -1.2719618082046509,
      "logits/rejected": -1.1905945539474487,
      "logps/chosen": -149.7342071533203,
      "logps/rejected": -156.09422302246094,
      "loss": 0.2699,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.311086893081665,
      "rewards/margins": 2.5532965660095215,
      "rewards/rejected": -3.8643829822540283,
      "step": 12110
    },
    {
      "epoch": 2.211880646044347,
      "grad_norm": 1.990143895149231,
      "learning_rate": 2.1248848775096706e-05,
      "logits/chosen": -1.2482725381851196,
      "logits/rejected": -1.12125825881958,
      "logps/chosen": -166.9085693359375,
      "logps/rejected": -165.03953552246094,
      "loss": 0.2766,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.6547797918319702,
      "rewards/margins": 2.663161277770996,
      "rewards/rejected": -4.317941188812256,
      "step": 12120
    },
    {
      "epoch": 2.213705630075737,
      "grad_norm": 6.993413925170898,
      "learning_rate": 2.119972984588936e-05,
      "logits/chosen": -1.1877361536026,
      "logits/rejected": -1.084824800491333,
      "logps/chosen": -187.57546997070312,
      "logps/rejected": -165.67047119140625,
      "loss": 0.393,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8950574398040771,
      "rewards/margins": 2.3642685413360596,
      "rewards/rejected": -4.2593255043029785,
      "step": 12130
    },
    {
      "epoch": 2.2155306141071267,
      "grad_norm": 2.728483200073242,
      "learning_rate": 2.1150610916682018e-05,
      "logits/chosen": -1.2272440195083618,
      "logits/rejected": -1.113680124282837,
      "logps/chosen": -168.40237426757812,
      "logps/rejected": -168.71011352539062,
      "loss": 0.2623,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.558687448501587,
      "rewards/margins": 2.9635934829711914,
      "rewards/rejected": -4.522280216217041,
      "step": 12140
    },
    {
      "epoch": 2.2173555981385165,
      "grad_norm": 7.0639777183532715,
      "learning_rate": 2.1101491987474672e-05,
      "logits/chosen": -1.2105538845062256,
      "logits/rejected": -1.0977529287338257,
      "logps/chosen": -151.5782012939453,
      "logps/rejected": -161.17880249023438,
      "loss": 0.3563,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.927476167678833,
      "rewards/margins": 2.823061466217041,
      "rewards/rejected": -4.750537395477295,
      "step": 12150
    },
    {
      "epoch": 2.219180582169906,
      "grad_norm": 6.898081302642822,
      "learning_rate": 2.1052373058267333e-05,
      "logits/chosen": -1.2189180850982666,
      "logits/rejected": -1.1068156957626343,
      "logps/chosen": -163.87741088867188,
      "logps/rejected": -166.93826293945312,
      "loss": 0.3492,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6158746480941772,
      "rewards/margins": 2.4696836471557617,
      "rewards/rejected": -4.085558891296387,
      "step": 12160
    },
    {
      "epoch": 2.2210055662012955,
      "grad_norm": 7.27208948135376,
      "learning_rate": 2.1003254129059988e-05,
      "logits/chosen": -1.1912306547164917,
      "logits/rejected": -1.0909923315048218,
      "logps/chosen": -178.37258911132812,
      "logps/rejected": -168.29885864257812,
      "loss": 0.4353,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4036126136779785,
      "rewards/margins": 2.2115681171417236,
      "rewards/rejected": -4.615180492401123,
      "step": 12170
    },
    {
      "epoch": 2.2228305502326853,
      "grad_norm": 7.047006130218506,
      "learning_rate": 2.0954135199852646e-05,
      "logits/chosen": -1.1829884052276611,
      "logits/rejected": -1.0051854848861694,
      "logps/chosen": -181.2399139404297,
      "logps/rejected": -170.24002075195312,
      "loss": 0.4054,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7689940929412842,
      "rewards/margins": 2.5238699913024902,
      "rewards/rejected": -4.292863368988037,
      "step": 12180
    },
    {
      "epoch": 2.224655534264075,
      "grad_norm": 5.651066780090332,
      "learning_rate": 2.09050162706453e-05,
      "logits/chosen": -1.206843376159668,
      "logits/rejected": -1.1419382095336914,
      "logps/chosen": -165.50827026367188,
      "logps/rejected": -164.4939727783203,
      "loss": 0.4025,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6183449029922485,
      "rewards/margins": 2.3173210620880127,
      "rewards/rejected": -3.9356656074523926,
      "step": 12190
    },
    {
      "epoch": 2.226480518295465,
      "grad_norm": 5.256011009216309,
      "learning_rate": 2.0855897341437958e-05,
      "logits/chosen": -1.1981127262115479,
      "logits/rejected": -1.1369463205337524,
      "logps/chosen": -165.70254516601562,
      "logps/rejected": -180.46456909179688,
      "loss": 0.3153,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.6008832454681396,
      "rewards/margins": 2.408163070678711,
      "rewards/rejected": -4.0090460777282715,
      "step": 12200
    },
    {
      "epoch": 2.2283055023268545,
      "grad_norm": 3.034971237182617,
      "learning_rate": 2.080677841223062e-05,
      "logits/chosen": -1.18312406539917,
      "logits/rejected": -1.0848877429962158,
      "logps/chosen": -158.20359802246094,
      "logps/rejected": -170.87234497070312,
      "loss": 0.2313,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.488341212272644,
      "rewards/margins": 2.6312460899353027,
      "rewards/rejected": -4.1195878982543945,
      "step": 12210
    },
    {
      "epoch": 2.2301304863582443,
      "grad_norm": 9.891973495483398,
      "learning_rate": 2.0757659483023273e-05,
      "logits/chosen": -1.2363603115081787,
      "logits/rejected": -1.1357866525650024,
      "logps/chosen": -170.501953125,
      "logps/rejected": -155.74032592773438,
      "loss": 0.3552,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.617236852645874,
      "rewards/margins": 2.1789722442626953,
      "rewards/rejected": -3.7962088584899902,
      "step": 12220
    },
    {
      "epoch": 2.231955470389634,
      "grad_norm": 7.292543888092041,
      "learning_rate": 2.070854055381593e-05,
      "logits/chosen": -1.1474971771240234,
      "logits/rejected": -1.0470898151397705,
      "logps/chosen": -150.40786743164062,
      "logps/rejected": -154.49688720703125,
      "loss": 0.3506,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.948857069015503,
      "rewards/margins": 2.258772373199463,
      "rewards/rejected": -4.207629203796387,
      "step": 12230
    },
    {
      "epoch": 2.233780454421024,
      "grad_norm": 1.219487190246582,
      "learning_rate": 2.0659421624608585e-05,
      "logits/chosen": -1.175767183303833,
      "logits/rejected": -1.0993797779083252,
      "logps/chosen": -161.92636108398438,
      "logps/rejected": -172.6398468017578,
      "loss": 0.2456,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6372016668319702,
      "rewards/margins": 2.6237056255340576,
      "rewards/rejected": -4.260907173156738,
      "step": 12240
    },
    {
      "epoch": 2.2356054384524136,
      "grad_norm": 4.232352256774902,
      "learning_rate": 2.0610302695401243e-05,
      "logits/chosen": -1.189728021621704,
      "logits/rejected": -1.0969693660736084,
      "logps/chosen": -168.9537811279297,
      "logps/rejected": -174.38954162597656,
      "loss": 0.3061,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.270620822906494,
      "rewards/margins": 2.493088722229004,
      "rewards/rejected": -4.763709545135498,
      "step": 12250
    },
    {
      "epoch": 2.2374304224838033,
      "grad_norm": 5.800410270690918,
      "learning_rate": 2.0561183766193897e-05,
      "logits/chosen": -1.1689083576202393,
      "logits/rejected": -1.0973507165908813,
      "logps/chosen": -161.576904296875,
      "logps/rejected": -164.5210418701172,
      "loss": 0.3775,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.6962151527404785,
      "rewards/margins": 1.9608185291290283,
      "rewards/rejected": -4.657033443450928,
      "step": 12260
    },
    {
      "epoch": 2.239255406515193,
      "grad_norm": 5.465753078460693,
      "learning_rate": 2.0512064836986555e-05,
      "logits/chosen": -1.193927526473999,
      "logits/rejected": -1.0919954776763916,
      "logps/chosen": -177.06088256835938,
      "logps/rejected": -182.30795288085938,
      "loss": 0.2661,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9098888635635376,
      "rewards/margins": 2.673269748687744,
      "rewards/rejected": -4.583158016204834,
      "step": 12270
    },
    {
      "epoch": 2.241080390546583,
      "grad_norm": 6.06342077255249,
      "learning_rate": 2.046294590777921e-05,
      "logits/chosen": -1.211307406425476,
      "logits/rejected": -1.0733190774917603,
      "logps/chosen": -164.3798828125,
      "logps/rejected": -163.2694549560547,
      "loss": 0.2286,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.081860065460205,
      "rewards/margins": 2.4278900623321533,
      "rewards/rejected": -4.509749889373779,
      "step": 12280
    },
    {
      "epoch": 2.2429053745779726,
      "grad_norm": 1.4694862365722656,
      "learning_rate": 2.041382697857187e-05,
      "logits/chosen": -1.1077587604522705,
      "logits/rejected": -1.0634167194366455,
      "logps/chosen": -167.551513671875,
      "logps/rejected": -180.90701293945312,
      "loss": 0.4588,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.3474907875061035,
      "rewards/margins": 2.053830623626709,
      "rewards/rejected": -4.401322364807129,
      "step": 12290
    },
    {
      "epoch": 2.2447303586093623,
      "grad_norm": 2.354551076889038,
      "learning_rate": 2.0364708049364528e-05,
      "logits/chosen": -1.1658676862716675,
      "logits/rejected": -0.9849861860275269,
      "logps/chosen": -175.09048461914062,
      "logps/rejected": -173.60415649414062,
      "loss": 0.3022,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.006122589111328,
      "rewards/margins": 2.6519858837127686,
      "rewards/rejected": -4.658108234405518,
      "step": 12300
    },
    {
      "epoch": 2.246555342640752,
      "grad_norm": 8.200908660888672,
      "learning_rate": 2.0315589120157182e-05,
      "logits/chosen": -1.1219841241836548,
      "logits/rejected": -0.9852805137634277,
      "logps/chosen": -163.85707092285156,
      "logps/rejected": -158.5120086669922,
      "loss": 0.3315,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2041571140289307,
      "rewards/margins": 2.738103151321411,
      "rewards/rejected": -4.942259788513184,
      "step": 12310
    },
    {
      "epoch": 2.248380326672142,
      "grad_norm": 8.266512870788574,
      "learning_rate": 2.026647019094984e-05,
      "logits/chosen": -1.164738416671753,
      "logits/rejected": -1.0979812145233154,
      "logps/chosen": -152.01303100585938,
      "logps/rejected": -171.38299560546875,
      "loss": 0.3383,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.8840936422348022,
      "rewards/margins": 2.4909586906433105,
      "rewards/rejected": -4.375052452087402,
      "step": 12320
    },
    {
      "epoch": 2.2502053107035316,
      "grad_norm": 1.5224500894546509,
      "learning_rate": 2.0217351261742495e-05,
      "logits/chosen": -1.0877232551574707,
      "logits/rejected": -0.9354714155197144,
      "logps/chosen": -172.794189453125,
      "logps/rejected": -156.3855438232422,
      "loss": 0.3307,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.283329486846924,
      "rewards/margins": 2.379838705062866,
      "rewards/rejected": -4.663167953491211,
      "step": 12330
    },
    {
      "epoch": 2.252030294734921,
      "grad_norm": 3.030294179916382,
      "learning_rate": 2.0168232332535152e-05,
      "logits/chosen": -1.171035885810852,
      "logits/rejected": -0.9999289512634277,
      "logps/chosen": -185.52792358398438,
      "logps/rejected": -168.76083374023438,
      "loss": 0.3231,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.519031047821045,
      "rewards/margins": 2.1574549674987793,
      "rewards/rejected": -4.676486015319824,
      "step": 12340
    },
    {
      "epoch": 2.2538552787663106,
      "grad_norm": 3.970026969909668,
      "learning_rate": 2.0119113403327807e-05,
      "logits/chosen": -1.0878976583480835,
      "logits/rejected": -0.9639400243759155,
      "logps/chosen": -188.66635131835938,
      "logps/rejected": -177.82247924804688,
      "loss": 0.2653,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.5587873458862305,
      "rewards/margins": 2.311046600341797,
      "rewards/rejected": -4.869833469390869,
      "step": 12350
    },
    {
      "epoch": 2.2556802627977004,
      "grad_norm": 9.267284393310547,
      "learning_rate": 2.0069994474120468e-05,
      "logits/chosen": -1.151606798171997,
      "logits/rejected": -1.073227882385254,
      "logps/chosen": -160.23696899414062,
      "logps/rejected": -159.68429565429688,
      "loss": 0.4171,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4802544116973877,
      "rewards/margins": 1.8957369327545166,
      "rewards/rejected": -4.375991344451904,
      "step": 12360
    },
    {
      "epoch": 2.25750524682909,
      "grad_norm": 4.433953285217285,
      "learning_rate": 2.0020875544913122e-05,
      "logits/chosen": -1.179551362991333,
      "logits/rejected": -1.0752769708633423,
      "logps/chosen": -196.037841796875,
      "logps/rejected": -182.04969787597656,
      "loss": 0.3247,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4466769695281982,
      "rewards/margins": 1.973697304725647,
      "rewards/rejected": -4.420373916625977,
      "step": 12370
    },
    {
      "epoch": 2.25933023086048,
      "grad_norm": 2.6317856311798096,
      "learning_rate": 1.997175661570578e-05,
      "logits/chosen": -1.2069716453552246,
      "logits/rejected": -1.0902478694915771,
      "logps/chosen": -171.63714599609375,
      "logps/rejected": -180.75772094726562,
      "loss": 0.3202,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.4436116218566895,
      "rewards/margins": 2.3319225311279297,
      "rewards/rejected": -4.775534152984619,
      "step": 12380
    },
    {
      "epoch": 2.2611552148918697,
      "grad_norm": 4.937145233154297,
      "learning_rate": 1.9922637686498438e-05,
      "logits/chosen": -1.1830772161483765,
      "logits/rejected": -1.060516595840454,
      "logps/chosen": -168.43350219726562,
      "logps/rejected": -168.64163208007812,
      "loss": 0.2352,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.2321548461914062,
      "rewards/margins": 2.5682268142700195,
      "rewards/rejected": -4.800381660461426,
      "step": 12390
    },
    {
      "epoch": 2.2629801989232594,
      "grad_norm": 4.0799479484558105,
      "learning_rate": 1.9873518757291092e-05,
      "logits/chosen": -1.1515942811965942,
      "logits/rejected": -1.05850088596344,
      "logps/chosen": -155.54287719726562,
      "logps/rejected": -161.6086883544922,
      "loss": 0.2169,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -2.0522820949554443,
      "rewards/margins": 2.53666090965271,
      "rewards/rejected": -4.588942527770996,
      "step": 12400
    },
    {
      "epoch": 2.264805182954649,
      "grad_norm": 4.850975036621094,
      "learning_rate": 1.982439982808375e-05,
      "logits/chosen": -1.113676905632019,
      "logits/rejected": -1.0369806289672852,
      "logps/chosen": -173.10914611816406,
      "logps/rejected": -187.85800170898438,
      "loss": 0.2465,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.5335302352905273,
      "rewards/margins": 2.482405424118042,
      "rewards/rejected": -5.01593542098999,
      "step": 12410
    },
    {
      "epoch": 2.266630166986039,
      "grad_norm": 3.2842628955841064,
      "learning_rate": 1.9775280898876404e-05,
      "logits/chosen": -1.1349802017211914,
      "logits/rejected": -1.0083482265472412,
      "logps/chosen": -163.15232849121094,
      "logps/rejected": -169.28121948242188,
      "loss": 0.2715,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.8731991052627563,
      "rewards/margins": 2.9219510555267334,
      "rewards/rejected": -4.795150279998779,
      "step": 12420
    },
    {
      "epoch": 2.2684551510174287,
      "grad_norm": 7.399759769439697,
      "learning_rate": 1.9726161969669062e-05,
      "logits/chosen": -1.121644377708435,
      "logits/rejected": -1.0014045238494873,
      "logps/chosen": -175.8664093017578,
      "logps/rejected": -161.34341430664062,
      "loss": 0.4096,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.5033669471740723,
      "rewards/margins": 2.034949541091919,
      "rewards/rejected": -4.538316249847412,
      "step": 12430
    },
    {
      "epoch": 2.2702801350488184,
      "grad_norm": 11.396936416625977,
      "learning_rate": 1.967704304046172e-05,
      "logits/chosen": -1.1826822757720947,
      "logits/rejected": -1.0803946256637573,
      "logps/chosen": -166.08367919921875,
      "logps/rejected": -181.29507446289062,
      "loss": 0.2893,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.129694700241089,
      "rewards/margins": 2.922206401824951,
      "rewards/rejected": -5.051901340484619,
      "step": 12440
    },
    {
      "epoch": 2.272105119080208,
      "grad_norm": 4.0889811515808105,
      "learning_rate": 1.9627924111254377e-05,
      "logits/chosen": -1.1854248046875,
      "logits/rejected": -1.0949633121490479,
      "logps/chosen": -161.42498779296875,
      "logps/rejected": -168.72103881835938,
      "loss": 0.2601,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0351738929748535,
      "rewards/margins": 2.3000214099884033,
      "rewards/rejected": -4.335195064544678,
      "step": 12450
    },
    {
      "epoch": 2.273930103111598,
      "grad_norm": 9.28154182434082,
      "learning_rate": 1.9578805182047035e-05,
      "logits/chosen": -1.1518703699111938,
      "logits/rejected": -1.081953525543213,
      "logps/chosen": -178.82382202148438,
      "logps/rejected": -185.10658264160156,
      "loss": 0.3213,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.7373855113983154,
      "rewards/margins": 2.4227333068847656,
      "rewards/rejected": -5.16011905670166,
      "step": 12460
    },
    {
      "epoch": 2.2757550871429877,
      "grad_norm": 6.2084808349609375,
      "learning_rate": 1.952968625283969e-05,
      "logits/chosen": -1.1416399478912354,
      "logits/rejected": -1.0086132287979126,
      "logps/chosen": -183.47073364257812,
      "logps/rejected": -163.4202880859375,
      "loss": 0.3344,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.3355135917663574,
      "rewards/margins": 2.423973321914673,
      "rewards/rejected": -4.759486675262451,
      "step": 12470
    },
    {
      "epoch": 2.277580071174377,
      "grad_norm": 4.83036994934082,
      "learning_rate": 1.9480567323632347e-05,
      "logits/chosen": -1.1486713886260986,
      "logits/rejected": -1.097954511642456,
      "logps/chosen": -156.89230346679688,
      "logps/rejected": -176.06044006347656,
      "loss": 0.2555,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2139344215393066,
      "rewards/margins": 2.853789806365967,
      "rewards/rejected": -5.067724227905273,
      "step": 12480
    },
    {
      "epoch": 2.2794050552057668,
      "grad_norm": 6.219986915588379,
      "learning_rate": 1.9431448394425005e-05,
      "logits/chosen": -1.1189377307891846,
      "logits/rejected": -1.0382215976715088,
      "logps/chosen": -156.5175323486328,
      "logps/rejected": -169.27883911132812,
      "loss": 0.4669,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.0587716102600098,
      "rewards/margins": 1.9038203954696655,
      "rewards/rejected": -4.962592124938965,
      "step": 12490
    },
    {
      "epoch": 2.2812300392371565,
      "grad_norm": 5.206238269805908,
      "learning_rate": 1.938232946521766e-05,
      "logits/chosen": -1.1326323747634888,
      "logits/rejected": -1.0276614427566528,
      "logps/chosen": -152.54124450683594,
      "logps/rejected": -176.6019287109375,
      "loss": 0.2582,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.006998062133789,
      "rewards/margins": 2.7425413131713867,
      "rewards/rejected": -4.749539852142334,
      "step": 12500
    },
    {
      "epoch": 2.2830550232685463,
      "grad_norm": 14.345232009887695,
      "learning_rate": 1.9333210536010317e-05,
      "logits/chosen": -1.0820293426513672,
      "logits/rejected": -1.0791516304016113,
      "logps/chosen": -155.62106323242188,
      "logps/rejected": -192.95932006835938,
      "loss": 0.3921,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2949609756469727,
      "rewards/margins": 2.4986326694488525,
      "rewards/rejected": -4.793593883514404,
      "step": 12510
    },
    {
      "epoch": 2.284880007299936,
      "grad_norm": 6.365169525146484,
      "learning_rate": 1.928409160680297e-05,
      "logits/chosen": -1.0669214725494385,
      "logits/rejected": -0.9658821225166321,
      "logps/chosen": -152.62673950195312,
      "logps/rejected": -174.73377990722656,
      "loss": 0.3378,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.131103992462158,
      "rewards/margins": 2.5909583568573,
      "rewards/rejected": -4.722062110900879,
      "step": 12520
    },
    {
      "epoch": 2.2867049913313258,
      "grad_norm": 3.183778762817383,
      "learning_rate": 1.923497267759563e-05,
      "logits/chosen": -1.135589361190796,
      "logits/rejected": -1.0363690853118896,
      "logps/chosen": -159.77542114257812,
      "logps/rejected": -177.9129180908203,
      "loss": 0.2847,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.3021559715270996,
      "rewards/margins": 2.4219276905059814,
      "rewards/rejected": -4.72408390045166,
      "step": 12530
    },
    {
      "epoch": 2.2885299753627155,
      "grad_norm": 1.1450806856155396,
      "learning_rate": 1.9185853748388287e-05,
      "logits/chosen": -1.1647417545318604,
      "logits/rejected": -0.9901954531669617,
      "logps/chosen": -178.49221801757812,
      "logps/rejected": -167.598876953125,
      "loss": 0.2616,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.5255866050720215,
      "rewards/margins": 2.5686774253845215,
      "rewards/rejected": -5.094263553619385,
      "step": 12540
    },
    {
      "epoch": 2.2903549593941053,
      "grad_norm": 9.919225692749023,
      "learning_rate": 1.9136734819180944e-05,
      "logits/chosen": -1.117226481437683,
      "logits/rejected": -1.0627812147140503,
      "logps/chosen": -179.86155700683594,
      "logps/rejected": -179.6800994873047,
      "loss": 0.4515,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.9963659048080444,
      "rewards/margins": 2.560835838317871,
      "rewards/rejected": -4.557202339172363,
      "step": 12550
    },
    {
      "epoch": 2.292179943425495,
      "grad_norm": 5.296165943145752,
      "learning_rate": 1.9087615889973602e-05,
      "logits/chosen": -1.1270229816436768,
      "logits/rejected": -1.0295253992080688,
      "logps/chosen": -173.6373748779297,
      "logps/rejected": -178.77511596679688,
      "loss": 0.3273,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7892472743988037,
      "rewards/margins": 2.3610308170318604,
      "rewards/rejected": -4.150278568267822,
      "step": 12560
    },
    {
      "epoch": 2.294004927456885,
      "grad_norm": 5.986490249633789,
      "learning_rate": 1.9038496960766256e-05,
      "logits/chosen": -1.200386643409729,
      "logits/rejected": -1.1227247714996338,
      "logps/chosen": -165.767822265625,
      "logps/rejected": -190.33596801757812,
      "loss": 0.2729,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.579550862312317,
      "rewards/margins": 2.9180049896240234,
      "rewards/rejected": -4.497555732727051,
      "step": 12570
    },
    {
      "epoch": 2.2958299114882745,
      "grad_norm": 8.531659126281738,
      "learning_rate": 1.8989378031558914e-05,
      "logits/chosen": -1.1611478328704834,
      "logits/rejected": -1.0705116987228394,
      "logps/chosen": -146.39964294433594,
      "logps/rejected": -152.9020233154297,
      "loss": 0.5011,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7912616729736328,
      "rewards/margins": 1.855385422706604,
      "rewards/rejected": -3.646646499633789,
      "step": 12580
    },
    {
      "epoch": 2.2976548955196643,
      "grad_norm": 5.6985764503479,
      "learning_rate": 1.8940259102351572e-05,
      "logits/chosen": -1.1384366750717163,
      "logits/rejected": -1.0173625946044922,
      "logps/chosen": -175.241943359375,
      "logps/rejected": -172.48802185058594,
      "loss": 0.2743,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.9782345294952393,
      "rewards/margins": 2.7286930084228516,
      "rewards/rejected": -4.706927299499512,
      "step": 12590
    },
    {
      "epoch": 2.299479879551054,
      "grad_norm": 8.809282302856445,
      "learning_rate": 1.8891140173144226e-05,
      "logits/chosen": -1.2029529809951782,
      "logits/rejected": -1.125566005706787,
      "logps/chosen": -160.50115966796875,
      "logps/rejected": -179.6661376953125,
      "loss": 0.2722,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8884645700454712,
      "rewards/margins": 2.657287120819092,
      "rewards/rejected": -4.545751571655273,
      "step": 12600
    },
    {
      "epoch": 2.301304863582444,
      "grad_norm": 5.090100288391113,
      "learning_rate": 1.8842021243936884e-05,
      "logits/chosen": -1.1600053310394287,
      "logits/rejected": -1.1381412744522095,
      "logps/chosen": -168.04147338867188,
      "logps/rejected": -197.71673583984375,
      "loss": 0.2421,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.3147530555725098,
      "rewards/margins": 2.448479652404785,
      "rewards/rejected": -4.763232231140137,
      "step": 12610
    },
    {
      "epoch": 2.3031298476138335,
      "grad_norm": 9.139482498168945,
      "learning_rate": 1.8792902314729538e-05,
      "logits/chosen": -1.2055271863937378,
      "logits/rejected": -1.0407583713531494,
      "logps/chosen": -197.5128173828125,
      "logps/rejected": -191.6261749267578,
      "loss": 0.2516,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.424926996231079,
      "rewards/margins": 2.5287559032440186,
      "rewards/rejected": -4.953682899475098,
      "step": 12620
    },
    {
      "epoch": 2.3049548316452233,
      "grad_norm": 6.269044399261475,
      "learning_rate": 1.8743783385522196e-05,
      "logits/chosen": -1.1213595867156982,
      "logits/rejected": -0.9582794308662415,
      "logps/chosen": -165.07412719726562,
      "logps/rejected": -165.12734985351562,
      "loss": 0.3157,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.3180127143859863,
      "rewards/margins": 2.633676528930664,
      "rewards/rejected": -4.95168924331665,
      "step": 12630
    },
    {
      "epoch": 2.306779815676613,
      "grad_norm": 4.693414211273193,
      "learning_rate": 1.8694664456314854e-05,
      "logits/chosen": -1.119380235671997,
      "logits/rejected": -0.9728276133537292,
      "logps/chosen": -168.20335388183594,
      "logps/rejected": -175.2665252685547,
      "loss": 0.2477,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.4541163444519043,
      "rewards/margins": 2.6954469680786133,
      "rewards/rejected": -5.149563312530518,
      "step": 12640
    },
    {
      "epoch": 2.3086047997080024,
      "grad_norm": 5.642784595489502,
      "learning_rate": 1.864554552710751e-05,
      "logits/chosen": -1.151138424873352,
      "logits/rejected": -1.0763747692108154,
      "logps/chosen": -171.5879669189453,
      "logps/rejected": -181.0371551513672,
      "loss": 0.2355,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.080066442489624,
      "rewards/margins": 2.7714295387268066,
      "rewards/rejected": -4.85149621963501,
      "step": 12650
    },
    {
      "epoch": 2.310429783739392,
      "grad_norm": 3.336841106414795,
      "learning_rate": 1.859642659790017e-05,
      "logits/chosen": -1.1577199697494507,
      "logits/rejected": -1.0093640089035034,
      "logps/chosen": -172.1714324951172,
      "logps/rejected": -165.57034301757812,
      "loss": 0.1796,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.572631359100342,
      "rewards/margins": 3.1363000869750977,
      "rewards/rejected": -5.7089314460754395,
      "step": 12660
    },
    {
      "epoch": 2.312254767770782,
      "grad_norm": 8.65130615234375,
      "learning_rate": 1.8547307668692824e-05,
      "logits/chosen": -1.1432195901870728,
      "logits/rejected": -1.0263111591339111,
      "logps/chosen": -155.2836456298828,
      "logps/rejected": -168.322265625,
      "loss": 0.2723,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.4969229698181152,
      "rewards/margins": 2.8575592041015625,
      "rewards/rejected": -5.3544816970825195,
      "step": 12670
    },
    {
      "epoch": 2.3140797518021716,
      "grad_norm": 6.526309967041016,
      "learning_rate": 1.849818873948548e-05,
      "logits/chosen": -1.1739263534545898,
      "logits/rejected": -1.0885006189346313,
      "logps/chosen": -180.14688110351562,
      "logps/rejected": -176.2458953857422,
      "loss": 0.3168,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.266310214996338,
      "rewards/margins": 2.5501770973205566,
      "rewards/rejected": -4.816486835479736,
      "step": 12680
    },
    {
      "epoch": 2.3159047358335614,
      "grad_norm": 6.830277919769287,
      "learning_rate": 1.844906981027814e-05,
      "logits/chosen": -1.111981749534607,
      "logits/rejected": -1.0506072044372559,
      "logps/chosen": -155.04965209960938,
      "logps/rejected": -171.80613708496094,
      "loss": 0.4101,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.727419376373291,
      "rewards/margins": 1.9538129568099976,
      "rewards/rejected": -4.681232452392578,
      "step": 12690
    },
    {
      "epoch": 2.317729719864951,
      "grad_norm": 5.2726874351501465,
      "learning_rate": 1.8399950881070793e-05,
      "logits/chosen": -1.0994343757629395,
      "logits/rejected": -1.0095148086547852,
      "logps/chosen": -165.42233276367188,
      "logps/rejected": -169.73947143554688,
      "loss": 0.2821,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.248990058898926,
      "rewards/margins": 2.7524619102478027,
      "rewards/rejected": -5.0014519691467285,
      "step": 12700
    },
    {
      "epoch": 2.319554703896341,
      "grad_norm": 6.763250350952148,
      "learning_rate": 1.835083195186345e-05,
      "logits/chosen": -1.2580335140228271,
      "logits/rejected": -1.112668752670288,
      "logps/chosen": -184.65811157226562,
      "logps/rejected": -191.49717712402344,
      "loss": 0.2021,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.7171399593353271,
      "rewards/margins": 3.044063091278076,
      "rewards/rejected": -4.761202812194824,
      "step": 12710
    },
    {
      "epoch": 2.3213796879277306,
      "grad_norm": 4.432205677032471,
      "learning_rate": 1.8301713022656105e-05,
      "logits/chosen": -1.2033131122589111,
      "logits/rejected": -1.0530484914779663,
      "logps/chosen": -177.0950164794922,
      "logps/rejected": -183.5176239013672,
      "loss": 0.2999,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2513959407806396,
      "rewards/margins": 2.988262414932251,
      "rewards/rejected": -5.239657878875732,
      "step": 12720
    },
    {
      "epoch": 2.3232046719591204,
      "grad_norm": 4.115102291107178,
      "learning_rate": 1.8252594093448763e-05,
      "logits/chosen": -1.2072656154632568,
      "logits/rejected": -1.1379971504211426,
      "logps/chosen": -156.14743041992188,
      "logps/rejected": -175.64065551757812,
      "loss": 0.3315,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.141599655151367,
      "rewards/margins": 2.5356152057647705,
      "rewards/rejected": -4.677214622497559,
      "step": 12730
    },
    {
      "epoch": 2.32502965599051,
      "grad_norm": 6.271791934967041,
      "learning_rate": 1.820347516424142e-05,
      "logits/chosen": -1.2398344278335571,
      "logits/rejected": -1.1435972452163696,
      "logps/chosen": -172.0243377685547,
      "logps/rejected": -178.9558563232422,
      "loss": 0.2564,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.7420974969863892,
      "rewards/margins": 2.711240291595459,
      "rewards/rejected": -4.453337669372559,
      "step": 12740
    },
    {
      "epoch": 2.3268546400219,
      "grad_norm": 6.006252288818359,
      "learning_rate": 1.815435623503408e-05,
      "logits/chosen": -1.2149509191513062,
      "logits/rejected": -1.169202446937561,
      "logps/chosen": -153.28292846679688,
      "logps/rejected": -164.00192260742188,
      "loss": 0.3704,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.1268038749694824,
      "rewards/margins": 2.2007415294647217,
      "rewards/rejected": -4.327545166015625,
      "step": 12750
    },
    {
      "epoch": 2.3286796240532897,
      "grad_norm": 3.097357988357544,
      "learning_rate": 1.8105237305826736e-05,
      "logits/chosen": -1.1692936420440674,
      "logits/rejected": -1.1075749397277832,
      "logps/chosen": -166.3237762451172,
      "logps/rejected": -178.66798400878906,
      "loss": 0.275,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.2212040424346924,
      "rewards/margins": 2.8778719902038574,
      "rewards/rejected": -5.099076271057129,
      "step": 12760
    },
    {
      "epoch": 2.3305046080846794,
      "grad_norm": 5.216574668884277,
      "learning_rate": 1.805611837661939e-05,
      "logits/chosen": -1.2552878856658936,
      "logits/rejected": -1.1538740396499634,
      "logps/chosen": -162.53390502929688,
      "logps/rejected": -162.89987182617188,
      "loss": 0.2727,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.0908126831054688,
      "rewards/margins": 2.477968454360962,
      "rewards/rejected": -4.568780899047852,
      "step": 12770
    },
    {
      "epoch": 2.332329592116069,
      "grad_norm": 5.058341979980469,
      "learning_rate": 1.800699944741205e-05,
      "logits/chosen": -1.280705213546753,
      "logits/rejected": -1.1655986309051514,
      "logps/chosen": -179.1494140625,
      "logps/rejected": -176.429931640625,
      "loss": 0.3093,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8157737255096436,
      "rewards/margins": 2.5139310359954834,
      "rewards/rejected": -4.329704761505127,
      "step": 12780
    },
    {
      "epoch": 2.3341545761474585,
      "grad_norm": 2.391395092010498,
      "learning_rate": 1.7957880518204703e-05,
      "logits/chosen": -1.2410436868667603,
      "logits/rejected": -1.1530908346176147,
      "logps/chosen": -175.55044555664062,
      "logps/rejected": -168.1590118408203,
      "loss": 0.3,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.7610194683074951,
      "rewards/margins": 2.4192159175872803,
      "rewards/rejected": -4.180235862731934,
      "step": 12790
    },
    {
      "epoch": 2.3359795601788482,
      "grad_norm": 2.3593578338623047,
      "learning_rate": 1.790876158899736e-05,
      "logits/chosen": -1.2253574132919312,
      "logits/rejected": -1.1500680446624756,
      "logps/chosen": -173.72836303710938,
      "logps/rejected": -184.51231384277344,
      "loss": 0.2245,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.2823567390441895,
      "rewards/margins": 2.889836549758911,
      "rewards/rejected": -5.1721930503845215,
      "step": 12800
    },
    {
      "epoch": 2.337804544210238,
      "grad_norm": 5.140960216522217,
      "learning_rate": 1.7859642659790018e-05,
      "logits/chosen": -1.2190935611724854,
      "logits/rejected": -1.1280715465545654,
      "logps/chosen": -174.1482391357422,
      "logps/rejected": -178.9856719970703,
      "loss": 0.3359,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.4461112022399902,
      "rewards/margins": 2.499234676361084,
      "rewards/rejected": -4.945345878601074,
      "step": 12810
    },
    {
      "epoch": 2.3396295282416277,
      "grad_norm": 4.400536060333252,
      "learning_rate": 1.7810523730582673e-05,
      "logits/chosen": -1.2073354721069336,
      "logits/rejected": -1.0962178707122803,
      "logps/chosen": -177.79739379882812,
      "logps/rejected": -170.0701904296875,
      "loss": 0.3284,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.273486614227295,
      "rewards/margins": 2.3314754962921143,
      "rewards/rejected": -4.604962348937988,
      "step": 12820
    },
    {
      "epoch": 2.3414545122730175,
      "grad_norm": 3.048628330230713,
      "learning_rate": 1.776140480137533e-05,
      "logits/chosen": -1.2929675579071045,
      "logits/rejected": -1.1404774188995361,
      "logps/chosen": -184.52752685546875,
      "logps/rejected": -157.7456817626953,
      "loss": 0.238,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.0047249794006348,
      "rewards/margins": 2.43405818939209,
      "rewards/rejected": -4.438783168792725,
      "step": 12830
    },
    {
      "epoch": 2.3432794963044072,
      "grad_norm": 7.242510795593262,
      "learning_rate": 1.7712285872167988e-05,
      "logits/chosen": -1.2248587608337402,
      "logits/rejected": -1.1102169752120972,
      "logps/chosen": -162.68763732910156,
      "logps/rejected": -157.27255249023438,
      "loss": 0.4117,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4645605087280273,
      "rewards/margins": 2.1639387607574463,
      "rewards/rejected": -4.6284990310668945,
      "step": 12840
    },
    {
      "epoch": 2.345104480335797,
      "grad_norm": 3.5125551223754883,
      "learning_rate": 1.7663166942960646e-05,
      "logits/chosen": -1.2232351303100586,
      "logits/rejected": -1.1751930713653564,
      "logps/chosen": -164.93978881835938,
      "logps/rejected": -185.77578735351562,
      "loss": 0.3271,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.232097864151001,
      "rewards/margins": 2.3339030742645264,
      "rewards/rejected": -4.566000938415527,
      "step": 12850
    },
    {
      "epoch": 2.3469294643671867,
      "grad_norm": 7.617238998413086,
      "learning_rate": 1.7614048013753303e-05,
      "logits/chosen": -1.2134284973144531,
      "logits/rejected": -1.111092448234558,
      "logps/chosen": -166.0120086669922,
      "logps/rejected": -174.6453094482422,
      "loss": 0.334,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.2195804119110107,
      "rewards/margins": 2.718811511993408,
      "rewards/rejected": -4.938392639160156,
      "step": 12860
    },
    {
      "epoch": 2.3487544483985765,
      "grad_norm": 1.243577480316162,
      "learning_rate": 1.7564929084545958e-05,
      "logits/chosen": -1.1732184886932373,
      "logits/rejected": -1.0866987705230713,
      "logps/chosen": -169.5425262451172,
      "logps/rejected": -177.194091796875,
      "loss": 0.239,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.311803102493286,
      "rewards/margins": 2.861751079559326,
      "rewards/rejected": -5.173554420471191,
      "step": 12870
    },
    {
      "epoch": 2.3505794324299663,
      "grad_norm": 5.709921360015869,
      "learning_rate": 1.7515810155338616e-05,
      "logits/chosen": -1.2031676769256592,
      "logits/rejected": -1.161142110824585,
      "logps/chosen": -168.0147247314453,
      "logps/rejected": -196.71914672851562,
      "loss": 0.2885,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.686159133911133,
      "rewards/margins": 2.6679141521453857,
      "rewards/rejected": -5.354073524475098,
      "step": 12880
    },
    {
      "epoch": 2.352404416461356,
      "grad_norm": 9.820395469665527,
      "learning_rate": 1.746669122613127e-05,
      "logits/chosen": -1.2124245166778564,
      "logits/rejected": -1.1110966205596924,
      "logps/chosen": -167.70559692382812,
      "logps/rejected": -168.9227294921875,
      "loss": 0.4337,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.34865140914917,
      "rewards/margins": 2.435485363006592,
      "rewards/rejected": -4.784136772155762,
      "step": 12890
    },
    {
      "epoch": 2.3542294004927458,
      "grad_norm": 5.643028736114502,
      "learning_rate": 1.7417572296923928e-05,
      "logits/chosen": -1.1802682876586914,
      "logits/rejected": -1.1804554462432861,
      "logps/chosen": -162.5410614013672,
      "logps/rejected": -197.72796630859375,
      "loss": 0.4359,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.325529098510742,
      "rewards/margins": 2.177924394607544,
      "rewards/rejected": -4.503453254699707,
      "step": 12900
    },
    {
      "epoch": 2.3560543845241355,
      "grad_norm": 3.2549490928649902,
      "learning_rate": 1.7368453367716585e-05,
      "logits/chosen": -1.261771321296692,
      "logits/rejected": -1.173257827758789,
      "logps/chosen": -176.27078247070312,
      "logps/rejected": -174.4787139892578,
      "loss": 0.3574,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9793040752410889,
      "rewards/margins": 2.448331356048584,
      "rewards/rejected": -4.427635192871094,
      "step": 12910
    },
    {
      "epoch": 2.3578793685555253,
      "grad_norm": 6.381857395172119,
      "learning_rate": 1.731933443850924e-05,
      "logits/chosen": -1.1695764064788818,
      "logits/rejected": -1.1024020910263062,
      "logps/chosen": -157.9130401611328,
      "logps/rejected": -168.98133850097656,
      "loss": 0.2976,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.458545207977295,
      "rewards/margins": 2.497231960296631,
      "rewards/rejected": -4.955777168273926,
      "step": 12920
    },
    {
      "epoch": 2.359704352586915,
      "grad_norm": 3.6724090576171875,
      "learning_rate": 1.72702155093019e-05,
      "logits/chosen": -1.1937892436981201,
      "logits/rejected": -1.1763653755187988,
      "logps/chosen": -162.66720581054688,
      "logps/rejected": -183.70663452148438,
      "loss": 0.2755,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.07890248298645,
      "rewards/margins": 2.2610411643981934,
      "rewards/rejected": -4.339943885803223,
      "step": 12930
    },
    {
      "epoch": 2.3615293366183048,
      "grad_norm": 6.747291088104248,
      "learning_rate": 1.7221096580094555e-05,
      "logits/chosen": -1.2452281713485718,
      "logits/rejected": -1.1413285732269287,
      "logps/chosen": -180.3032684326172,
      "logps/rejected": -162.1716766357422,
      "loss": 0.3578,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.2738590240478516,
      "rewards/margins": 2.212268352508545,
      "rewards/rejected": -4.486126899719238,
      "step": 12940
    },
    {
      "epoch": 2.3633543206496945,
      "grad_norm": 5.647839546203613,
      "learning_rate": 1.7171977650887213e-05,
      "logits/chosen": -1.2151089906692505,
      "logits/rejected": -1.1073545217514038,
      "logps/chosen": -169.88116455078125,
      "logps/rejected": -158.87281799316406,
      "loss": 0.3625,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.9890639781951904,
      "rewards/margins": 2.0806565284729004,
      "rewards/rejected": -4.069720268249512,
      "step": 12950
    },
    {
      "epoch": 2.3651793046810843,
      "grad_norm": 4.193496227264404,
      "learning_rate": 1.712285872167987e-05,
      "logits/chosen": -1.2647624015808105,
      "logits/rejected": -1.175823450088501,
      "logps/chosen": -171.82308959960938,
      "logps/rejected": -173.881103515625,
      "loss": 0.3668,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.9607067108154297,
      "rewards/margins": 2.198439836502075,
      "rewards/rejected": -4.159146308898926,
      "step": 12960
    },
    {
      "epoch": 2.3670042887124736,
      "grad_norm": 6.812664031982422,
      "learning_rate": 1.7073739792472525e-05,
      "logits/chosen": -1.2227929830551147,
      "logits/rejected": -1.143672227859497,
      "logps/chosen": -157.5856170654297,
      "logps/rejected": -169.22930908203125,
      "loss": 0.3018,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.898550033569336,
      "rewards/margins": 2.388378620147705,
      "rewards/rejected": -4.286928176879883,
      "step": 12970
    },
    {
      "epoch": 2.3688292727438633,
      "grad_norm": 5.2844719886779785,
      "learning_rate": 1.7024620863265183e-05,
      "logits/chosen": -1.2044975757598877,
      "logits/rejected": -1.0957763195037842,
      "logps/chosen": -167.84027099609375,
      "logps/rejected": -166.40640258789062,
      "loss": 0.3417,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.0011961460113525,
      "rewards/margins": 2.3038077354431152,
      "rewards/rejected": -4.305004119873047,
      "step": 12980
    },
    {
      "epoch": 2.370654256775253,
      "grad_norm": 3.4496920108795166,
      "learning_rate": 1.6975501934057837e-05,
      "logits/chosen": -1.201174259185791,
      "logits/rejected": -1.1399247646331787,
      "logps/chosen": -165.74258422851562,
      "logps/rejected": -172.28738403320312,
      "loss": 0.3856,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2918813228607178,
      "rewards/margins": 2.1592328548431396,
      "rewards/rejected": -4.451114654541016,
      "step": 12990
    },
    {
      "epoch": 2.372479240806643,
      "grad_norm": 9.010873794555664,
      "learning_rate": 1.6926383004850495e-05,
      "logits/chosen": -1.207733392715454,
      "logits/rejected": -1.1364635229110718,
      "logps/chosen": -154.82244873046875,
      "logps/rejected": -164.52328491210938,
      "loss": 0.3874,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8851654529571533,
      "rewards/margins": 2.313624858856201,
      "rewards/rejected": -4.198790550231934,
      "step": 13000
    },
    {
      "epoch": 2.3743042248380326,
      "grad_norm": 6.494350433349609,
      "learning_rate": 1.6877264075643153e-05,
      "logits/chosen": -1.1739755868911743,
      "logits/rejected": -1.1113145351409912,
      "logps/chosen": -164.1674346923828,
      "logps/rejected": -157.59622192382812,
      "loss": 0.4247,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.2596983909606934,
      "rewards/margins": 1.7411912679672241,
      "rewards/rejected": -4.000889778137207,
      "step": 13010
    },
    {
      "epoch": 2.3761292088694224,
      "grad_norm": 9.688758850097656,
      "learning_rate": 1.6828145146435807e-05,
      "logits/chosen": -1.214176893234253,
      "logits/rejected": -1.0999858379364014,
      "logps/chosen": -186.59454345703125,
      "logps/rejected": -177.0327911376953,
      "loss": 0.3116,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.6756477355957031,
      "rewards/margins": 2.013068914413452,
      "rewards/rejected": -3.688716173171997,
      "step": 13020
    },
    {
      "epoch": 2.377954192900812,
      "grad_norm": 2.6747732162475586,
      "learning_rate": 1.6779026217228468e-05,
      "logits/chosen": -1.2487854957580566,
      "logits/rejected": -1.1762301921844482,
      "logps/chosen": -165.6699981689453,
      "logps/rejected": -182.4335174560547,
      "loss": 0.2552,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.789634346961975,
      "rewards/margins": 2.5801548957824707,
      "rewards/rejected": -4.3697896003723145,
      "step": 13030
    },
    {
      "epoch": 2.379779176932202,
      "grad_norm": 7.37484884262085,
      "learning_rate": 1.6729907288021122e-05,
      "logits/chosen": -1.2525527477264404,
      "logits/rejected": -1.102642297744751,
      "logps/chosen": -169.87640380859375,
      "logps/rejected": -153.48629760742188,
      "loss": 0.3088,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.6775106191635132,
      "rewards/margins": 2.368972063064575,
      "rewards/rejected": -4.046483039855957,
      "step": 13040
    },
    {
      "epoch": 2.3816041609635916,
      "grad_norm": 6.193380355834961,
      "learning_rate": 1.668078835881378e-05,
      "logits/chosen": -1.1811151504516602,
      "logits/rejected": -1.1195471286773682,
      "logps/chosen": -152.47445678710938,
      "logps/rejected": -162.94210815429688,
      "loss": 0.3311,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.9989429712295532,
      "rewards/margins": 1.929905652999878,
      "rewards/rejected": -3.9288487434387207,
      "step": 13050
    },
    {
      "epoch": 2.3834291449949814,
      "grad_norm": 4.4187726974487305,
      "learning_rate": 1.6631669429606438e-05,
      "logits/chosen": -1.173810601234436,
      "logits/rejected": -1.0572549104690552,
      "logps/chosen": -190.4254150390625,
      "logps/rejected": -176.89883422851562,
      "loss": 0.2449,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.638464331626892,
      "rewards/margins": 2.8337199687957764,
      "rewards/rejected": -4.472184181213379,
      "step": 13060
    },
    {
      "epoch": 2.385254129026371,
      "grad_norm": 4.659610748291016,
      "learning_rate": 1.6582550500399092e-05,
      "logits/chosen": -1.176292896270752,
      "logits/rejected": -1.147526741027832,
      "logps/chosen": -165.05105590820312,
      "logps/rejected": -163.52822875976562,
      "loss": 0.3245,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.266519069671631,
      "rewards/margins": 2.110347032546997,
      "rewards/rejected": -4.376865386962891,
      "step": 13070
    },
    {
      "epoch": 2.387079113057761,
      "grad_norm": 1.6505076885223389,
      "learning_rate": 1.653343157119175e-05,
      "logits/chosen": -1.2195273637771606,
      "logits/rejected": -1.1036384105682373,
      "logps/chosen": -176.550537109375,
      "logps/rejected": -170.9967803955078,
      "loss": 0.2256,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8059771060943604,
      "rewards/margins": 2.6490211486816406,
      "rewards/rejected": -4.45499849319458,
      "step": 13080
    },
    {
      "epoch": 2.3889040970891506,
      "grad_norm": 7.278872966766357,
      "learning_rate": 1.6484312641984404e-05,
      "logits/chosen": -1.1949183940887451,
      "logits/rejected": -1.1316994428634644,
      "logps/chosen": -161.0579376220703,
      "logps/rejected": -179.01516723632812,
      "loss": 0.3377,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2659411430358887,
      "rewards/margins": 2.3081932067871094,
      "rewards/rejected": -4.57413387298584,
      "step": 13090
    },
    {
      "epoch": 2.3907290811205404,
      "grad_norm": 9.453847885131836,
      "learning_rate": 1.6435193712777062e-05,
      "logits/chosen": -1.1620194911956787,
      "logits/rejected": -1.119248390197754,
      "logps/chosen": -170.56021118164062,
      "logps/rejected": -178.67037963867188,
      "loss": 0.4095,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.3864049911499023,
      "rewards/margins": 2.1699814796447754,
      "rewards/rejected": -4.5563859939575195,
      "step": 13100
    },
    {
      "epoch": 2.3925540651519297,
      "grad_norm": 5.848919868469238,
      "learning_rate": 1.638607478356972e-05,
      "logits/chosen": -1.2067394256591797,
      "logits/rejected": -1.055399775505066,
      "logps/chosen": -182.5048065185547,
      "logps/rejected": -167.82955932617188,
      "loss": 0.2713,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.246943950653076,
      "rewards/margins": 2.4002814292907715,
      "rewards/rejected": -4.6472249031066895,
      "step": 13110
    },
    {
      "epoch": 2.3943790491833195,
      "grad_norm": 6.448581218719482,
      "learning_rate": 1.6336955854362374e-05,
      "logits/chosen": -1.199344515800476,
      "logits/rejected": -1.0865055322647095,
      "logps/chosen": -175.00582885742188,
      "logps/rejected": -152.65969848632812,
      "loss": 0.3797,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.3015363216400146,
      "rewards/margins": 1.9263817071914673,
      "rewards/rejected": -4.22791862487793,
      "step": 13120
    },
    {
      "epoch": 2.396204033214709,
      "grad_norm": 3.886749505996704,
      "learning_rate": 1.6287836925155035e-05,
      "logits/chosen": -1.239550232887268,
      "logits/rejected": -1.106864094734192,
      "logps/chosen": -163.45779418945312,
      "logps/rejected": -165.68948364257812,
      "loss": 0.2018,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.8885942697525024,
      "rewards/margins": 2.970917224884033,
      "rewards/rejected": -4.859511375427246,
      "step": 13130
    },
    {
      "epoch": 2.398029017246099,
      "grad_norm": 10.931396484375,
      "learning_rate": 1.623871799594769e-05,
      "logits/chosen": -1.229518175125122,
      "logits/rejected": -1.1574039459228516,
      "logps/chosen": -166.7286834716797,
      "logps/rejected": -179.98690795898438,
      "loss": 0.3225,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.314271926879883,
      "rewards/margins": 2.40069580078125,
      "rewards/rejected": -4.714967727661133,
      "step": 13140
    },
    {
      "epoch": 2.3998540012774887,
      "grad_norm": 5.164738178253174,
      "learning_rate": 1.6189599066740347e-05,
      "logits/chosen": -1.2482774257659912,
      "logits/rejected": -1.1356351375579834,
      "logps/chosen": -183.33677673339844,
      "logps/rejected": -172.62753295898438,
      "loss": 0.3176,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.154500961303711,
      "rewards/margins": 2.274630069732666,
      "rewards/rejected": -4.429131031036377,
      "step": 13150
    },
    {
      "epoch": 2.4016789853088785,
      "grad_norm": 1.9553569555282593,
      "learning_rate": 1.6140480137533005e-05,
      "logits/chosen": -1.179726004600525,
      "logits/rejected": -1.1014654636383057,
      "logps/chosen": -162.24209594726562,
      "logps/rejected": -179.3372039794922,
      "loss": 0.2742,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9985936880111694,
      "rewards/margins": 2.6080405712127686,
      "rewards/rejected": -4.606634616851807,
      "step": 13160
    },
    {
      "epoch": 2.403503969340268,
      "grad_norm": 5.122426509857178,
      "learning_rate": 1.609136120832566e-05,
      "logits/chosen": -1.2236679792404175,
      "logits/rejected": -1.1022391319274902,
      "logps/chosen": -170.37841796875,
      "logps/rejected": -179.15869140625,
      "loss": 0.3637,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.1884400844573975,
      "rewards/margins": 2.3616435527801514,
      "rewards/rejected": -4.550084114074707,
      "step": 13170
    },
    {
      "epoch": 2.405328953371658,
      "grad_norm": 4.972711563110352,
      "learning_rate": 1.6042242279118317e-05,
      "logits/chosen": -1.2164572477340698,
      "logits/rejected": -1.1221518516540527,
      "logps/chosen": -176.54791259765625,
      "logps/rejected": -185.0335235595703,
      "loss": 0.33,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.4971706867218018,
      "rewards/margins": 2.4767847061157227,
      "rewards/rejected": -4.973954677581787,
      "step": 13180
    },
    {
      "epoch": 2.4071539374030477,
      "grad_norm": 4.846026420593262,
      "learning_rate": 1.599312334991097e-05,
      "logits/chosen": -1.1890811920166016,
      "logits/rejected": -1.1244158744812012,
      "logps/chosen": -166.09481811523438,
      "logps/rejected": -170.7634735107422,
      "loss": 0.2949,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.2185962200164795,
      "rewards/margins": 2.4309325218200684,
      "rewards/rejected": -4.649528503417969,
      "step": 13190
    },
    {
      "epoch": 2.4089789214344375,
      "grad_norm": 7.733334064483643,
      "learning_rate": 1.594400442070363e-05,
      "logits/chosen": -1.3003008365631104,
      "logits/rejected": -1.2044999599456787,
      "logps/chosen": -174.1477508544922,
      "logps/rejected": -173.66998291015625,
      "loss": 0.2196,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5373858213424683,
      "rewards/margins": 2.816990852355957,
      "rewards/rejected": -4.354377269744873,
      "step": 13200
    },
    {
      "epoch": 2.4108039054658272,
      "grad_norm": 9.965310096740723,
      "learning_rate": 1.5894885491496287e-05,
      "logits/chosen": -1.2435814142227173,
      "logits/rejected": -1.1310698986053467,
      "logps/chosen": -170.3748016357422,
      "logps/rejected": -181.02139282226562,
      "loss": 0.2879,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5605990886688232,
      "rewards/margins": 2.8239827156066895,
      "rewards/rejected": -4.384582042694092,
      "step": 13210
    },
    {
      "epoch": 2.412628889497217,
      "grad_norm": 9.767285346984863,
      "learning_rate": 1.5845766562288945e-05,
      "logits/chosen": -1.2292946577072144,
      "logits/rejected": -1.1441904306411743,
      "logps/chosen": -169.92532348632812,
      "logps/rejected": -188.51675415039062,
      "loss": 0.2231,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.4922752380371094,
      "rewards/margins": 2.6872615814208984,
      "rewards/rejected": -4.17953634262085,
      "step": 13220
    },
    {
      "epoch": 2.4144538735286067,
      "grad_norm": 5.645052909851074,
      "learning_rate": 1.5796647633081602e-05,
      "logits/chosen": -1.2429279088974,
      "logits/rejected": -1.0834174156188965,
      "logps/chosen": -185.69790649414062,
      "logps/rejected": -175.65431213378906,
      "loss": 0.23,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8249714374542236,
      "rewards/margins": 2.826209545135498,
      "rewards/rejected": -4.651181221008301,
      "step": 13230
    },
    {
      "epoch": 2.4162788575599965,
      "grad_norm": 8.719359397888184,
      "learning_rate": 1.5747528703874257e-05,
      "logits/chosen": -1.2078512907028198,
      "logits/rejected": -1.1511800289154053,
      "logps/chosen": -169.8243865966797,
      "logps/rejected": -197.91390991210938,
      "loss": 0.2216,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.565079927444458,
      "rewards/margins": 2.93656063079834,
      "rewards/rejected": -5.501641273498535,
      "step": 13240
    },
    {
      "epoch": 2.4181038415913862,
      "grad_norm": 3.933573007583618,
      "learning_rate": 1.5698409774666914e-05,
      "logits/chosen": -1.217071533203125,
      "logits/rejected": -1.1450284719467163,
      "logps/chosen": -167.34249877929688,
      "logps/rejected": -177.40304565429688,
      "loss": 0.3259,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4598708152770996,
      "rewards/margins": 2.3399949073791504,
      "rewards/rejected": -4.799866676330566,
      "step": 13250
    },
    {
      "epoch": 2.419928825622776,
      "grad_norm": 3.951479196548462,
      "learning_rate": 1.5649290845459572e-05,
      "logits/chosen": -1.1923775672912598,
      "logits/rejected": -1.12761390209198,
      "logps/chosen": -158.16439819335938,
      "logps/rejected": -168.04660034179688,
      "loss": 0.4463,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.515662670135498,
      "rewards/margins": 2.1777663230895996,
      "rewards/rejected": -4.693428993225098,
      "step": 13260
    },
    {
      "epoch": 2.4217538096541658,
      "grad_norm": 6.551303386688232,
      "learning_rate": 1.5600171916252226e-05,
      "logits/chosen": -1.2999800443649292,
      "logits/rejected": -1.2026541233062744,
      "logps/chosen": -181.0262451171875,
      "logps/rejected": -184.8577880859375,
      "loss": 0.2551,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6375850439071655,
      "rewards/margins": 3.076716899871826,
      "rewards/rejected": -4.714302062988281,
      "step": 13270
    },
    {
      "epoch": 2.423578793685555,
      "grad_norm": 5.428286552429199,
      "learning_rate": 1.5551052987044884e-05,
      "logits/chosen": -1.2316884994506836,
      "logits/rejected": -1.1265920400619507,
      "logps/chosen": -160.68252563476562,
      "logps/rejected": -165.6568603515625,
      "loss": 0.2803,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.9549286365509033,
      "rewards/margins": 2.7243168354034424,
      "rewards/rejected": -4.6792449951171875,
      "step": 13280
    },
    {
      "epoch": 2.425403777716945,
      "grad_norm": 5.209611892700195,
      "learning_rate": 1.550193405783754e-05,
      "logits/chosen": -1.2701308727264404,
      "logits/rejected": -1.1342525482177734,
      "logps/chosen": -185.43475341796875,
      "logps/rejected": -174.9764404296875,
      "loss": 0.2739,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.8255538940429688,
      "rewards/margins": 2.4599509239196777,
      "rewards/rejected": -4.2855048179626465,
      "step": 13290
    },
    {
      "epoch": 2.4272287617483346,
      "grad_norm": 7.02725887298584,
      "learning_rate": 1.5452815128630196e-05,
      "logits/chosen": -1.204885482788086,
      "logits/rejected": -1.0910975933074951,
      "logps/chosen": -181.55654907226562,
      "logps/rejected": -161.9702911376953,
      "loss": 0.2534,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.766156792640686,
      "rewards/margins": 2.6192173957824707,
      "rewards/rejected": -4.385374546051025,
      "step": 13300
    },
    {
      "epoch": 2.4290537457797243,
      "grad_norm": 3.5658586025238037,
      "learning_rate": 1.5403696199422854e-05,
      "logits/chosen": -1.2104321718215942,
      "logits/rejected": -1.0755975246429443,
      "logps/chosen": -165.0132293701172,
      "logps/rejected": -160.28860473632812,
      "loss": 0.2569,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.7199909687042236,
      "rewards/margins": 2.818021059036255,
      "rewards/rejected": -4.5380120277404785,
      "step": 13310
    },
    {
      "epoch": 2.430878729811114,
      "grad_norm": 1.6885907649993896,
      "learning_rate": 1.5354577270215512e-05,
      "logits/chosen": -1.2432125806808472,
      "logits/rejected": -1.140291690826416,
      "logps/chosen": -159.89501953125,
      "logps/rejected": -171.7819366455078,
      "loss": 0.2767,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.5758939981460571,
      "rewards/margins": 2.909741163253784,
      "rewards/rejected": -4.485634803771973,
      "step": 13320
    },
    {
      "epoch": 2.432703713842504,
      "grad_norm": 5.392780303955078,
      "learning_rate": 1.530545834100817e-05,
      "logits/chosen": -1.2554627656936646,
      "logits/rejected": -1.183293104171753,
      "logps/chosen": -166.63070678710938,
      "logps/rejected": -184.8553009033203,
      "loss": 0.2672,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.99807870388031,
      "rewards/margins": 2.738734006881714,
      "rewards/rejected": -4.736813068389893,
      "step": 13330
    },
    {
      "epoch": 2.4345286978738936,
      "grad_norm": 8.657015800476074,
      "learning_rate": 1.5256339411800824e-05,
      "logits/chosen": -1.2286608219146729,
      "logits/rejected": -1.1294962167739868,
      "logps/chosen": -167.82594299316406,
      "logps/rejected": -166.01226806640625,
      "loss": 0.2706,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.041774272918701,
      "rewards/margins": 2.712592840194702,
      "rewards/rejected": -4.754366874694824,
      "step": 13340
    },
    {
      "epoch": 2.4363536819052833,
      "grad_norm": 2.813392162322998,
      "learning_rate": 1.5207220482593482e-05,
      "logits/chosen": -1.2386802434921265,
      "logits/rejected": -1.1878225803375244,
      "logps/chosen": -157.582763671875,
      "logps/rejected": -179.3824005126953,
      "loss": 0.3151,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.6808913946151733,
      "rewards/margins": 2.8455355167388916,
      "rewards/rejected": -4.526426792144775,
      "step": 13350
    },
    {
      "epoch": 2.438178665936673,
      "grad_norm": 3.6035263538360596,
      "learning_rate": 1.5158101553386138e-05,
      "logits/chosen": -1.292562484741211,
      "logits/rejected": -1.2435271739959717,
      "logps/chosen": -164.14273071289062,
      "logps/rejected": -175.55459594726562,
      "loss": 0.3679,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9829928874969482,
      "rewards/margins": 2.2349750995635986,
      "rewards/rejected": -4.217967987060547,
      "step": 13360
    },
    {
      "epoch": 2.440003649968063,
      "grad_norm": 4.456255912780762,
      "learning_rate": 1.5108982624178794e-05,
      "logits/chosen": -1.2556061744689941,
      "logits/rejected": -1.177646279335022,
      "logps/chosen": -162.12396240234375,
      "logps/rejected": -181.28553771972656,
      "loss": 0.3015,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.09283709526062,
      "rewards/margins": 2.486035108566284,
      "rewards/rejected": -4.578871726989746,
      "step": 13370
    },
    {
      "epoch": 2.4418286339994526,
      "grad_norm": 6.5429511070251465,
      "learning_rate": 1.5059863694971451e-05,
      "logits/chosen": -1.3077431917190552,
      "logits/rejected": -1.229579210281372,
      "logps/chosen": -180.11972045898438,
      "logps/rejected": -189.45083618164062,
      "loss": 0.3553,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9339625835418701,
      "rewards/margins": 2.626499652862549,
      "rewards/rejected": -4.560462474822998,
      "step": 13380
    },
    {
      "epoch": 2.4436536180308424,
      "grad_norm": 7.833510398864746,
      "learning_rate": 1.5010744765764107e-05,
      "logits/chosen": -1.254398226737976,
      "logits/rejected": -1.1834338903427124,
      "logps/chosen": -157.29385375976562,
      "logps/rejected": -166.6812744140625,
      "loss": 0.3476,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8185802698135376,
      "rewards/margins": 2.458477735519409,
      "rewards/rejected": -4.277058124542236,
      "step": 13390
    },
    {
      "epoch": 2.445478602062232,
      "grad_norm": 4.549442291259766,
      "learning_rate": 1.4961625836556763e-05,
      "logits/chosen": -1.2305164337158203,
      "logits/rejected": -1.1637301445007324,
      "logps/chosen": -164.4509735107422,
      "logps/rejected": -170.44955444335938,
      "loss": 0.3286,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.177234649658203,
      "rewards/margins": 2.4862353801727295,
      "rewards/rejected": -4.663470268249512,
      "step": 13400
    },
    {
      "epoch": 2.447303586093622,
      "grad_norm": 8.228778839111328,
      "learning_rate": 1.491250690734942e-05,
      "logits/chosen": -1.2997934818267822,
      "logits/rejected": -1.1657354831695557,
      "logps/chosen": -178.65469360351562,
      "logps/rejected": -169.2774200439453,
      "loss": 0.2853,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.9312931299209595,
      "rewards/margins": 2.6999948024749756,
      "rewards/rejected": -4.631287574768066,
      "step": 13410
    },
    {
      "epoch": 2.449128570125011,
      "grad_norm": 3.34401798248291,
      "learning_rate": 1.4863387978142079e-05,
      "logits/chosen": -1.3169596195220947,
      "logits/rejected": -1.2157344818115234,
      "logps/chosen": -191.00491333007812,
      "logps/rejected": -190.3876953125,
      "loss": 0.2852,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.942571997642517,
      "rewards/margins": 2.886110305786133,
      "rewards/rejected": -4.8286824226379395,
      "step": 13420
    },
    {
      "epoch": 2.450953554156401,
      "grad_norm": 5.412566661834717,
      "learning_rate": 1.4814269048934735e-05,
      "logits/chosen": -1.2945340871810913,
      "logits/rejected": -1.214207410812378,
      "logps/chosen": -169.52401733398438,
      "logps/rejected": -172.7569122314453,
      "loss": 0.2077,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.6328423023223877,
      "rewards/margins": 2.841343641281128,
      "rewards/rejected": -4.474186420440674,
      "step": 13430
    },
    {
      "epoch": 2.4527785381877907,
      "grad_norm": 3.0333242416381836,
      "learning_rate": 1.4765150119727391e-05,
      "logits/chosen": -1.2721014022827148,
      "logits/rejected": -1.2157924175262451,
      "logps/chosen": -154.74417114257812,
      "logps/rejected": -187.22018432617188,
      "loss": 0.2818,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.0176076889038086,
      "rewards/margins": 2.6724045276641846,
      "rewards/rejected": -4.690012454986572,
      "step": 13440
    },
    {
      "epoch": 2.4546035222191804,
      "grad_norm": 2.2014639377593994,
      "learning_rate": 1.4716031190520049e-05,
      "logits/chosen": -1.238384485244751,
      "logits/rejected": -1.1420520544052124,
      "logps/chosen": -157.52651977539062,
      "logps/rejected": -152.82699584960938,
      "loss": 0.2057,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.212634563446045,
      "rewards/margins": 2.823244571685791,
      "rewards/rejected": -5.035878658294678,
      "step": 13450
    },
    {
      "epoch": 2.45642850625057,
      "grad_norm": 5.035083770751953,
      "learning_rate": 1.4666912261312705e-05,
      "logits/chosen": -1.2693895101547241,
      "logits/rejected": -1.1467314958572388,
      "logps/chosen": -171.9384307861328,
      "logps/rejected": -172.65090942382812,
      "loss": 0.3792,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.1248269081115723,
      "rewards/margins": 2.5292372703552246,
      "rewards/rejected": -4.654064178466797,
      "step": 13460
    },
    {
      "epoch": 2.45825349028196,
      "grad_norm": 8.34143352508545,
      "learning_rate": 1.461779333210536e-05,
      "logits/chosen": -1.2538583278656006,
      "logits/rejected": -1.2170463800430298,
      "logps/chosen": -149.35574340820312,
      "logps/rejected": -177.0049285888672,
      "loss": 0.2727,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4614293575286865,
      "rewards/margins": 2.82075834274292,
      "rewards/rejected": -4.282187461853027,
      "step": 13470
    },
    {
      "epoch": 2.4600784743133497,
      "grad_norm": 10.847533226013184,
      "learning_rate": 1.4568674402898017e-05,
      "logits/chosen": -1.2997459173202515,
      "logits/rejected": -1.2153122425079346,
      "logps/chosen": -175.55433654785156,
      "logps/rejected": -166.33895874023438,
      "loss": 0.3013,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.7302649021148682,
      "rewards/margins": 2.195420742034912,
      "rewards/rejected": -3.9256858825683594,
      "step": 13480
    },
    {
      "epoch": 2.4619034583447394,
      "grad_norm": 5.612955570220947,
      "learning_rate": 1.4519555473690674e-05,
      "logits/chosen": -1.3181331157684326,
      "logits/rejected": -1.2397929430007935,
      "logps/chosen": -173.15882873535156,
      "logps/rejected": -168.34547424316406,
      "loss": 0.2205,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8867419958114624,
      "rewards/margins": 2.508563280105591,
      "rewards/rejected": -4.395305633544922,
      "step": 13490
    },
    {
      "epoch": 2.463728442376129,
      "grad_norm": 8.711869239807129,
      "learning_rate": 1.447043654448333e-05,
      "logits/chosen": -1.2655893564224243,
      "logits/rejected": -1.2010176181793213,
      "logps/chosen": -155.3456268310547,
      "logps/rejected": -181.44790649414062,
      "loss": 0.4076,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.0488247871398926,
      "rewards/margins": 2.7080609798431396,
      "rewards/rejected": -4.756885528564453,
      "step": 13500
    },
    {
      "epoch": 2.465553426407519,
      "grad_norm": 1.9458175897598267,
      "learning_rate": 1.4421317615275987e-05,
      "logits/chosen": -1.2921922206878662,
      "logits/rejected": -1.2216819524765015,
      "logps/chosen": -158.3568115234375,
      "logps/rejected": -176.8949737548828,
      "loss": 0.2428,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.110457181930542,
      "rewards/margins": 2.770843029022217,
      "rewards/rejected": -4.881300449371338,
      "step": 13510
    },
    {
      "epoch": 2.4673784104389087,
      "grad_norm": 8.959543228149414,
      "learning_rate": 1.4372198686068646e-05,
      "logits/chosen": -1.2562711238861084,
      "logits/rejected": -1.195988416671753,
      "logps/chosen": -176.4073028564453,
      "logps/rejected": -179.55026245117188,
      "loss": 0.3145,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.226520538330078,
      "rewards/margins": 2.5507688522338867,
      "rewards/rejected": -4.777289390563965,
      "step": 13520
    },
    {
      "epoch": 2.4692033944702985,
      "grad_norm": 2.045822858810425,
      "learning_rate": 1.4323079756861302e-05,
      "logits/chosen": -1.2593574523925781,
      "logits/rejected": -1.1984407901763916,
      "logps/chosen": -154.36825561523438,
      "logps/rejected": -175.36436462402344,
      "loss": 0.3523,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.0706191062927246,
      "rewards/margins": 2.5233287811279297,
      "rewards/rejected": -4.593947410583496,
      "step": 13530
    },
    {
      "epoch": 2.471028378501688,
      "grad_norm": 11.454390525817871,
      "learning_rate": 1.4273960827653958e-05,
      "logits/chosen": -1.2847251892089844,
      "logits/rejected": -1.224225640296936,
      "logps/chosen": -178.3274688720703,
      "logps/rejected": -196.96279907226562,
      "loss": 0.2614,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.1244654655456543,
      "rewards/margins": 3.0697574615478516,
      "rewards/rejected": -5.194222927093506,
      "step": 13540
    },
    {
      "epoch": 2.472853362533078,
      "grad_norm": 3.862907648086548,
      "learning_rate": 1.4224841898446616e-05,
      "logits/chosen": -1.2866642475128174,
      "logits/rejected": -1.212348461151123,
      "logps/chosen": -169.03343200683594,
      "logps/rejected": -175.88900756835938,
      "loss": 0.4298,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.0376856327056885,
      "rewards/margins": 2.179330825805664,
      "rewards/rejected": -4.217016220092773,
      "step": 13550
    },
    {
      "epoch": 2.4746783465644677,
      "grad_norm": 2.9702649116516113,
      "learning_rate": 1.4175722969239272e-05,
      "logits/chosen": -1.2537888288497925,
      "logits/rejected": -1.2029132843017578,
      "logps/chosen": -165.28076171875,
      "logps/rejected": -168.91879272460938,
      "loss": 0.2297,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.1317131519317627,
      "rewards/margins": 2.4840617179870605,
      "rewards/rejected": -4.615775108337402,
      "step": 13560
    },
    {
      "epoch": 2.4765033305958575,
      "grad_norm": 3.595628499984741,
      "learning_rate": 1.4126604040031928e-05,
      "logits/chosen": -1.2304025888442993,
      "logits/rejected": -1.143348217010498,
      "logps/chosen": -165.6407470703125,
      "logps/rejected": -164.43966674804688,
      "loss": 0.3591,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.2321460247039795,
      "rewards/margins": 2.0930888652801514,
      "rewards/rejected": -4.325235366821289,
      "step": 13570
    },
    {
      "epoch": 2.4783283146272472,
      "grad_norm": 3.1248645782470703,
      "learning_rate": 1.4077485110824584e-05,
      "logits/chosen": -1.264235496520996,
      "logits/rejected": -1.1778334379196167,
      "logps/chosen": -172.09521484375,
      "logps/rejected": -164.5518798828125,
      "loss": 0.3561,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.1842398643493652,
      "rewards/margins": 2.1598639488220215,
      "rewards/rejected": -4.344103813171387,
      "step": 13580
    },
    {
      "epoch": 2.480153298658637,
      "grad_norm": 2.900702953338623,
      "learning_rate": 1.4028366181617242e-05,
      "logits/chosen": -1.2246935367584229,
      "logits/rejected": -1.1861484050750732,
      "logps/chosen": -149.41299438476562,
      "logps/rejected": -175.2244873046875,
      "loss": 0.2701,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.053518056869507,
      "rewards/margins": 2.6437175273895264,
      "rewards/rejected": -4.697236061096191,
      "step": 13590
    },
    {
      "epoch": 2.4819782826900263,
      "grad_norm": 8.945330619812012,
      "learning_rate": 1.3979247252409898e-05,
      "logits/chosen": -1.2744585275650024,
      "logits/rejected": -1.1995196342468262,
      "logps/chosen": -169.43531799316406,
      "logps/rejected": -191.4221649169922,
      "loss": 0.3031,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.069688320159912,
      "rewards/margins": 2.777808666229248,
      "rewards/rejected": -4.847497463226318,
      "step": 13600
    },
    {
      "epoch": 2.483803266721416,
      "grad_norm": 7.077671527862549,
      "learning_rate": 1.3930128323202557e-05,
      "logits/chosen": -1.2413671016693115,
      "logits/rejected": -1.1905152797698975,
      "logps/chosen": -173.10372924804688,
      "logps/rejected": -180.58070373535156,
      "loss": 0.3411,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.2083113193511963,
      "rewards/margins": 2.4721083641052246,
      "rewards/rejected": -4.680419921875,
      "step": 13610
    },
    {
      "epoch": 2.485628250752806,
      "grad_norm": 5.010124683380127,
      "learning_rate": 1.3881009393995213e-05,
      "logits/chosen": -1.3002941608428955,
      "logits/rejected": -1.213097333908081,
      "logps/chosen": -174.12582397460938,
      "logps/rejected": -170.22164916992188,
      "loss": 0.2757,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.3840150833129883,
      "rewards/margins": 2.7625274658203125,
      "rewards/rejected": -5.146542549133301,
      "step": 13620
    },
    {
      "epoch": 2.4874532347841956,
      "grad_norm": 7.781507968902588,
      "learning_rate": 1.383189046478787e-05,
      "logits/chosen": -1.3047771453857422,
      "logits/rejected": -1.2181923389434814,
      "logps/chosen": -167.92626953125,
      "logps/rejected": -174.73085021972656,
      "loss": 0.2921,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.7997410297393799,
      "rewards/margins": 2.5978972911834717,
      "rewards/rejected": -4.39763879776001,
      "step": 13630
    },
    {
      "epoch": 2.4892782188155853,
      "grad_norm": 10.414015769958496,
      "learning_rate": 1.3782771535580525e-05,
      "logits/chosen": -1.2179659605026245,
      "logits/rejected": -1.1505132913589478,
      "logps/chosen": -170.6058349609375,
      "logps/rejected": -174.52198791503906,
      "loss": 0.3108,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.6349751949310303,
      "rewards/margins": 2.842188596725464,
      "rewards/rejected": -5.477164268493652,
      "step": 13640
    },
    {
      "epoch": 2.491103202846975,
      "grad_norm": 6.521270751953125,
      "learning_rate": 1.3733652606373183e-05,
      "logits/chosen": -1.2021404504776,
      "logits/rejected": -1.1016714572906494,
      "logps/chosen": -158.61111450195312,
      "logps/rejected": -172.75498962402344,
      "loss": 0.2471,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.4829444885253906,
      "rewards/margins": 2.62451171875,
      "rewards/rejected": -5.107456207275391,
      "step": 13650
    },
    {
      "epoch": 2.492928186878365,
      "grad_norm": 4.057191371917725,
      "learning_rate": 1.3684533677165839e-05,
      "logits/chosen": -1.2438678741455078,
      "logits/rejected": -1.154261827468872,
      "logps/chosen": -181.57122802734375,
      "logps/rejected": -183.45152282714844,
      "loss": 0.3328,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.372804641723633,
      "rewards/margins": 2.749070405960083,
      "rewards/rejected": -5.121874809265137,
      "step": 13660
    },
    {
      "epoch": 2.4947531709097546,
      "grad_norm": 6.555685997009277,
      "learning_rate": 1.3635414747958495e-05,
      "logits/chosen": -1.272339105606079,
      "logits/rejected": -1.2092664241790771,
      "logps/chosen": -165.74996948242188,
      "logps/rejected": -178.74081420898438,
      "loss": 0.2556,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.252605676651001,
      "rewards/margins": 2.870448350906372,
      "rewards/rejected": -5.123053550720215,
      "step": 13670
    },
    {
      "epoch": 2.4965781549411443,
      "grad_norm": 10.414993286132812,
      "learning_rate": 1.3586295818751151e-05,
      "logits/chosen": -1.2664737701416016,
      "logits/rejected": -1.1680736541748047,
      "logps/chosen": -166.94747924804688,
      "logps/rejected": -173.8243408203125,
      "loss": 0.3598,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.9326311349868774,
      "rewards/margins": 2.769735097885132,
      "rewards/rejected": -4.702365875244141,
      "step": 13680
    },
    {
      "epoch": 2.498403138972534,
      "grad_norm": 5.300780296325684,
      "learning_rate": 1.3537176889543809e-05,
      "logits/chosen": -1.1958222389221191,
      "logits/rejected": -1.0949190855026245,
      "logps/chosen": -170.32540893554688,
      "logps/rejected": -172.4447021484375,
      "loss": 0.3598,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.711249589920044,
      "rewards/margins": 2.8835535049438477,
      "rewards/rejected": -5.594803333282471,
      "step": 13690
    },
    {
      "epoch": 2.500228123003924,
      "grad_norm": 3.3470981121063232,
      "learning_rate": 1.3488057960336465e-05,
      "logits/chosen": -1.2727115154266357,
      "logits/rejected": -1.177873969078064,
      "logps/chosen": -159.60433959960938,
      "logps/rejected": -169.68338012695312,
      "loss": 0.2561,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.289193630218506,
      "rewards/margins": 2.772076368331909,
      "rewards/rejected": -5.061270236968994,
      "step": 13700
    },
    {
      "epoch": 2.5020531070353136,
      "grad_norm": 3.848369598388672,
      "learning_rate": 1.3438939031129124e-05,
      "logits/chosen": -1.184202790260315,
      "logits/rejected": -1.047693133354187,
      "logps/chosen": -153.74514770507812,
      "logps/rejected": -158.0321502685547,
      "loss": 0.286,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2206130027770996,
      "rewards/margins": 2.895857334136963,
      "rewards/rejected": -5.116470813751221,
      "step": 13710
    },
    {
      "epoch": 2.503878091066703,
      "grad_norm": 6.405090808868408,
      "learning_rate": 1.338982010192178e-05,
      "logits/chosen": -1.1822454929351807,
      "logits/rejected": -1.0710251331329346,
      "logps/chosen": -179.42681884765625,
      "logps/rejected": -179.82830810546875,
      "loss": 0.3223,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.6848902702331543,
      "rewards/margins": 2.534482479095459,
      "rewards/rejected": -5.219372749328613,
      "step": 13720
    },
    {
      "epoch": 2.5057030750980926,
      "grad_norm": 5.302776336669922,
      "learning_rate": 1.3340701172714436e-05,
      "logits/chosen": -1.2664473056793213,
      "logits/rejected": -1.1935127973556519,
      "logps/chosen": -167.43055725097656,
      "logps/rejected": -182.7944793701172,
      "loss": 0.4189,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.428597927093506,
      "rewards/margins": 2.4828104972839355,
      "rewards/rejected": -4.9114089012146,
      "step": 13730
    },
    {
      "epoch": 2.5075280591294824,
      "grad_norm": 6.652426719665527,
      "learning_rate": 1.3291582243507092e-05,
      "logits/chosen": -1.2814744710922241,
      "logits/rejected": -1.1842385530471802,
      "logps/chosen": -182.4164276123047,
      "logps/rejected": -172.63717651367188,
      "loss": 0.3224,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.927761435508728,
      "rewards/margins": 2.393522024154663,
      "rewards/rejected": -4.32128381729126,
      "step": 13740
    },
    {
      "epoch": 2.509353043160872,
      "grad_norm": 5.62366247177124,
      "learning_rate": 1.324246331429975e-05,
      "logits/chosen": -1.2251079082489014,
      "logits/rejected": -1.168905258178711,
      "logps/chosen": -168.2310028076172,
      "logps/rejected": -175.34231567382812,
      "loss": 0.3536,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.3741822242736816,
      "rewards/margins": 2.567248582839966,
      "rewards/rejected": -4.941431045532227,
      "step": 13750
    },
    {
      "epoch": 2.511178027192262,
      "grad_norm": 7.776512622833252,
      "learning_rate": 1.3193344385092406e-05,
      "logits/chosen": -1.277602195739746,
      "logits/rejected": -1.1856684684753418,
      "logps/chosen": -173.2318878173828,
      "logps/rejected": -175.8969268798828,
      "loss": 0.4094,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.008096218109131,
      "rewards/margins": 2.4112799167633057,
      "rewards/rejected": -4.419376373291016,
      "step": 13760
    },
    {
      "epoch": 2.5130030112236517,
      "grad_norm": 4.6455183029174805,
      "learning_rate": 1.3144225455885062e-05,
      "logits/chosen": -1.2393443584442139,
      "logits/rejected": -1.1673238277435303,
      "logps/chosen": -165.93923950195312,
      "logps/rejected": -179.46859741210938,
      "loss": 0.2709,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.228005886077881,
      "rewards/margins": 2.7105212211608887,
      "rewards/rejected": -4.9385271072387695,
      "step": 13770
    },
    {
      "epoch": 2.5148279952550414,
      "grad_norm": 6.011319637298584,
      "learning_rate": 1.3095106526677718e-05,
      "logits/chosen": -1.2350283861160278,
      "logits/rejected": -1.1343042850494385,
      "logps/chosen": -170.1830291748047,
      "logps/rejected": -188.5008544921875,
      "loss": 0.2426,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.3218493461608887,
      "rewards/margins": 3.151925563812256,
      "rewards/rejected": -5.4737749099731445,
      "step": 13780
    },
    {
      "epoch": 2.516652979286431,
      "grad_norm": 8.554157257080078,
      "learning_rate": 1.3045987597470376e-05,
      "logits/chosen": -1.251644492149353,
      "logits/rejected": -1.1767853498458862,
      "logps/chosen": -165.13955688476562,
      "logps/rejected": -173.9519805908203,
      "loss": 0.3837,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.74381947517395,
      "rewards/margins": 2.286147117614746,
      "rewards/rejected": -5.029966354370117,
      "step": 13790
    },
    {
      "epoch": 2.518477963317821,
      "grad_norm": 7.363412380218506,
      "learning_rate": 1.2996868668263032e-05,
      "logits/chosen": -1.1666890382766724,
      "logits/rejected": -1.0896823406219482,
      "logps/chosen": -161.3302764892578,
      "logps/rejected": -169.25559997558594,
      "loss": 0.2888,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.6850740909576416,
      "rewards/margins": 2.5789754390716553,
      "rewards/rejected": -5.264050006866455,
      "step": 13800
    },
    {
      "epoch": 2.5203029473492107,
      "grad_norm": 7.523951530456543,
      "learning_rate": 1.294774973905569e-05,
      "logits/chosen": -1.2259137630462646,
      "logits/rejected": -1.1321827173233032,
      "logps/chosen": -174.40924072265625,
      "logps/rejected": -179.57577514648438,
      "loss": 0.2334,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.4453563690185547,
      "rewards/margins": 2.825270414352417,
      "rewards/rejected": -5.270627021789551,
      "step": 13810
    },
    {
      "epoch": 2.5221279313806004,
      "grad_norm": 7.316046714782715,
      "learning_rate": 1.2898630809848347e-05,
      "logits/chosen": -1.1839021444320679,
      "logits/rejected": -1.1032334566116333,
      "logps/chosen": -188.54318237304688,
      "logps/rejected": -194.90170288085938,
      "loss": 0.3411,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.740697145462036,
      "rewards/margins": 2.452033519744873,
      "rewards/rejected": -5.19273042678833,
      "step": 13820
    },
    {
      "epoch": 2.52395291541199,
      "grad_norm": 4.647592544555664,
      "learning_rate": 1.2849511880641003e-05,
      "logits/chosen": -1.2572294473648071,
      "logits/rejected": -1.2041971683502197,
      "logps/chosen": -169.4153289794922,
      "logps/rejected": -184.81265258789062,
      "loss": 0.2987,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.4859700202941895,
      "rewards/margins": 2.5350260734558105,
      "rewards/rejected": -5.020995616912842,
      "step": 13830
    },
    {
      "epoch": 2.52577789944338,
      "grad_norm": 6.6517863273620605,
      "learning_rate": 1.280039295143366e-05,
      "logits/chosen": -1.184909462928772,
      "logits/rejected": -1.1136400699615479,
      "logps/chosen": -159.39779663085938,
      "logps/rejected": -181.35780334472656,
      "loss": 0.2197,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.6513493061065674,
      "rewards/margins": 3.0103697776794434,
      "rewards/rejected": -5.661718845367432,
      "step": 13840
    },
    {
      "epoch": 2.5276028834747697,
      "grad_norm": 4.804884433746338,
      "learning_rate": 1.2751274022226317e-05,
      "logits/chosen": -1.1829851865768433,
      "logits/rejected": -1.1060973405838013,
      "logps/chosen": -177.3838653564453,
      "logps/rejected": -171.26133728027344,
      "loss": 0.2939,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.7376456260681152,
      "rewards/margins": 2.71407413482666,
      "rewards/rejected": -5.451719760894775,
      "step": 13850
    },
    {
      "epoch": 2.5294278675061594,
      "grad_norm": 7.820642948150635,
      "learning_rate": 1.2702155093018973e-05,
      "logits/chosen": -1.2488995790481567,
      "logits/rejected": -1.1290969848632812,
      "logps/chosen": -188.61038208007812,
      "logps/rejected": -193.15948486328125,
      "loss": 0.1958,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.6356260776519775,
      "rewards/margins": 2.990626573562622,
      "rewards/rejected": -5.626252174377441,
      "step": 13860
    },
    {
      "epoch": 2.531252851537549,
      "grad_norm": 6.3811211585998535,
      "learning_rate": 1.265303616381163e-05,
      "logits/chosen": -1.2480260133743286,
      "logits/rejected": -1.1664018630981445,
      "logps/chosen": -180.8354034423828,
      "logps/rejected": -181.24240112304688,
      "loss": 0.2643,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.240213632583618,
      "rewards/margins": 2.8626327514648438,
      "rewards/rejected": -5.102846145629883,
      "step": 13870
    },
    {
      "epoch": 2.533077835568939,
      "grad_norm": 6.395519256591797,
      "learning_rate": 1.2603917234604285e-05,
      "logits/chosen": -1.2145531177520752,
      "logits/rejected": -1.1569305658340454,
      "logps/chosen": -169.51304626464844,
      "logps/rejected": -178.0790557861328,
      "loss": 0.3865,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.8949930667877197,
      "rewards/margins": 2.364802360534668,
      "rewards/rejected": -5.259795188903809,
      "step": 13880
    },
    {
      "epoch": 2.5349028196003287,
      "grad_norm": 9.821684837341309,
      "learning_rate": 1.2554798305396943e-05,
      "logits/chosen": -1.3054442405700684,
      "logits/rejected": -1.165199875831604,
      "logps/chosen": -189.00132751464844,
      "logps/rejected": -180.35391235351562,
      "loss": 0.3012,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.9912035465240479,
      "rewards/margins": 2.951544761657715,
      "rewards/rejected": -4.942748069763184,
      "step": 13890
    },
    {
      "epoch": 2.5367278036317185,
      "grad_norm": 6.359692573547363,
      "learning_rate": 1.25056793761896e-05,
      "logits/chosen": -1.2172811031341553,
      "logits/rejected": -1.1638126373291016,
      "logps/chosen": -179.48147583007812,
      "logps/rejected": -178.1874237060547,
      "loss": 0.4283,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.6423864364624023,
      "rewards/margins": 1.9770538806915283,
      "rewards/rejected": -4.619440078735352,
      "step": 13900
    },
    {
      "epoch": 2.538552787663108,
      "grad_norm": 7.622020721435547,
      "learning_rate": 1.2456560446982257e-05,
      "logits/chosen": -1.2313110828399658,
      "logits/rejected": -1.1877917051315308,
      "logps/chosen": -173.34596252441406,
      "logps/rejected": -195.20010375976562,
      "loss": 0.3067,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.9677562713623047,
      "rewards/margins": 2.6260323524475098,
      "rewards/rejected": -4.5937886238098145,
      "step": 13910
    },
    {
      "epoch": 2.5403777716944975,
      "grad_norm": 9.096007347106934,
      "learning_rate": 1.2407441517774915e-05,
      "logits/chosen": -1.1960633993148804,
      "logits/rejected": -1.042130708694458,
      "logps/chosen": -178.37945556640625,
      "logps/rejected": -162.97323608398438,
      "loss": 0.3527,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.732517719268799,
      "rewards/margins": 2.298428773880005,
      "rewards/rejected": -5.030945777893066,
      "step": 13920
    },
    {
      "epoch": 2.5422027557258873,
      "grad_norm": 3.4965646266937256,
      "learning_rate": 1.235832258856757e-05,
      "logits/chosen": -1.1835860013961792,
      "logits/rejected": -1.1049343347549438,
      "logps/chosen": -171.24830627441406,
      "logps/rejected": -175.82119750976562,
      "loss": 0.2365,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.4191863536834717,
      "rewards/margins": 2.7507498264312744,
      "rewards/rejected": -5.169936180114746,
      "step": 13930
    },
    {
      "epoch": 2.544027739757277,
      "grad_norm": 3.0792510509490967,
      "learning_rate": 1.2309203659360227e-05,
      "logits/chosen": -1.2289223670959473,
      "logits/rejected": -1.1038769483566284,
      "logps/chosen": -159.80502319335938,
      "logps/rejected": -162.11837768554688,
      "loss": 0.1837,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.9736318588256836,
      "rewards/margins": 3.1217312812805176,
      "rewards/rejected": -5.095363140106201,
      "step": 13940
    },
    {
      "epoch": 2.545852723788667,
      "grad_norm": 10.475921630859375,
      "learning_rate": 1.2260084730152884e-05,
      "logits/chosen": -1.177616834640503,
      "logits/rejected": -1.0965015888214111,
      "logps/chosen": -177.4903564453125,
      "logps/rejected": -183.80531311035156,
      "loss": 0.387,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.509908437728882,
      "rewards/margins": 2.2773869037628174,
      "rewards/rejected": -4.787295341491699,
      "step": 13950
    },
    {
      "epoch": 2.5476777078200565,
      "grad_norm": 9.198330879211426,
      "learning_rate": 1.221096580094554e-05,
      "logits/chosen": -1.1160056591033936,
      "logits/rejected": -1.0208187103271484,
      "logps/chosen": -170.3900146484375,
      "logps/rejected": -184.20834350585938,
      "loss": 0.2719,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.8895766735076904,
      "rewards/margins": 2.971985101699829,
      "rewards/rejected": -5.8615617752075195,
      "step": 13960
    },
    {
      "epoch": 2.5495026918514463,
      "grad_norm": 5.961760520935059,
      "learning_rate": 1.2161846871738196e-05,
      "logits/chosen": -1.1527975797653198,
      "logits/rejected": -1.104546070098877,
      "logps/chosen": -157.25567626953125,
      "logps/rejected": -175.3394012451172,
      "loss": 0.2547,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.53033185005188,
      "rewards/margins": 2.747666597366333,
      "rewards/rejected": -5.277998447418213,
      "step": 13970
    },
    {
      "epoch": 2.551327675882836,
      "grad_norm": 9.681497573852539,
      "learning_rate": 1.2112727942530853e-05,
      "logits/chosen": -1.219743013381958,
      "logits/rejected": -1.100611686706543,
      "logps/chosen": -181.1809539794922,
      "logps/rejected": -175.70571899414062,
      "loss": 0.443,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.765324354171753,
      "rewards/margins": 2.4415435791015625,
      "rewards/rejected": -5.2068681716918945,
      "step": 13980
    },
    {
      "epoch": 2.553152659914226,
      "grad_norm": 11.243401527404785,
      "learning_rate": 1.206360901332351e-05,
      "logits/chosen": -1.2968480587005615,
      "logits/rejected": -1.2077099084854126,
      "logps/chosen": -178.82730102539062,
      "logps/rejected": -182.30471801757812,
      "loss": 0.4041,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.525214433670044,
      "rewards/margins": 2.4349188804626465,
      "rewards/rejected": -4.960132598876953,
      "step": 13990
    },
    {
      "epoch": 2.5549776439456156,
      "grad_norm": 2.138896942138672,
      "learning_rate": 1.2014490084116168e-05,
      "logits/chosen": -1.2862898111343384,
      "logits/rejected": -1.2049894332885742,
      "logps/chosen": -178.30996704101562,
      "logps/rejected": -191.0322723388672,
      "loss": 0.2432,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.550755023956299,
      "rewards/margins": 2.8604812622070312,
      "rewards/rejected": -5.41123628616333,
      "step": 14000
    },
    {
      "epoch": 2.5568026279770053,
      "grad_norm": 5.0904645919799805,
      "learning_rate": 1.1965371154908824e-05,
      "logits/chosen": -1.28874933719635,
      "logits/rejected": -1.1930944919586182,
      "logps/chosen": -171.78414916992188,
      "logps/rejected": -172.64962768554688,
      "loss": 0.2704,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.4419524669647217,
      "rewards/margins": 2.8439269065856934,
      "rewards/rejected": -5.285879611968994,
      "step": 14010
    },
    {
      "epoch": 2.558627612008395,
      "grad_norm": 2.8510217666625977,
      "learning_rate": 1.1916252225701482e-05,
      "logits/chosen": -1.3084644079208374,
      "logits/rejected": -1.2170242071151733,
      "logps/chosen": -177.9373321533203,
      "logps/rejected": -174.75344848632812,
      "loss": 0.2972,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.419550657272339,
      "rewards/margins": 2.5892999172210693,
      "rewards/rejected": -5.008850574493408,
      "step": 14020
    },
    {
      "epoch": 2.560452596039785,
      "grad_norm": 4.268742561340332,
      "learning_rate": 1.1867133296494138e-05,
      "logits/chosen": -1.281891942024231,
      "logits/rejected": -1.1783527135849,
      "logps/chosen": -167.69180297851562,
      "logps/rejected": -172.62088012695312,
      "loss": 0.2347,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.418801784515381,
      "rewards/margins": 3.0097243785858154,
      "rewards/rejected": -5.428525447845459,
      "step": 14030
    },
    {
      "epoch": 2.562277580071174,
      "grad_norm": 5.506784915924072,
      "learning_rate": 1.1818014367286794e-05,
      "logits/chosen": -1.284656286239624,
      "logits/rejected": -1.1826674938201904,
      "logps/chosen": -179.1913299560547,
      "logps/rejected": -184.6741943359375,
      "loss": 0.2456,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.1466524600982666,
      "rewards/margins": 2.8869919776916504,
      "rewards/rejected": -5.033644676208496,
      "step": 14040
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 7.787402153015137,
      "learning_rate": 1.176889543807945e-05,
      "logits/chosen": -1.2391090393066406,
      "logits/rejected": -1.1975853443145752,
      "logps/chosen": -154.2349090576172,
      "logps/rejected": -172.9600372314453,
      "loss": 0.3394,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.3951914310455322,
      "rewards/margins": 2.774751901626587,
      "rewards/rejected": -5.169943332672119,
      "step": 14050
    },
    {
      "epoch": 2.5659275481339536,
      "grad_norm": 4.803730487823486,
      "learning_rate": 1.1719776508872108e-05,
      "logits/chosen": -1.2838785648345947,
      "logits/rejected": -1.1782472133636475,
      "logps/chosen": -160.9095916748047,
      "logps/rejected": -170.3163604736328,
      "loss": 0.2928,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.538240671157837,
      "rewards/margins": 2.6939175128936768,
      "rewards/rejected": -5.232158660888672,
      "step": 14060
    },
    {
      "epoch": 2.5677525321653434,
      "grad_norm": 10.040363311767578,
      "learning_rate": 1.1670657579664764e-05,
      "logits/chosen": -1.271837830543518,
      "logits/rejected": -1.1900813579559326,
      "logps/chosen": -158.1842803955078,
      "logps/rejected": -170.7580108642578,
      "loss": 0.3216,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4700913429260254,
      "rewards/margins": 2.5200753211975098,
      "rewards/rejected": -4.990167140960693,
      "step": 14070
    },
    {
      "epoch": 2.569577516196733,
      "grad_norm": 3.5309386253356934,
      "learning_rate": 1.162153865045742e-05,
      "logits/chosen": -1.2654303312301636,
      "logits/rejected": -1.202767252922058,
      "logps/chosen": -151.16067504882812,
      "logps/rejected": -169.37220764160156,
      "loss": 0.2409,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.236724376678467,
      "rewards/margins": 2.8904781341552734,
      "rewards/rejected": -5.127202033996582,
      "step": 14080
    },
    {
      "epoch": 2.571402500228123,
      "grad_norm": 2.1310296058654785,
      "learning_rate": 1.1572419721250077e-05,
      "logits/chosen": -1.283016562461853,
      "logits/rejected": -1.1851403713226318,
      "logps/chosen": -176.70797729492188,
      "logps/rejected": -172.26431274414062,
      "loss": 0.234,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.2037243843078613,
      "rewards/margins": 2.8734984397888184,
      "rewards/rejected": -5.077223300933838,
      "step": 14090
    },
    {
      "epoch": 2.5732274842595126,
      "grad_norm": 7.0964884757995605,
      "learning_rate": 1.1523300792042735e-05,
      "logits/chosen": -1.2795335054397583,
      "logits/rejected": -1.180748701095581,
      "logps/chosen": -154.19003295898438,
      "logps/rejected": -166.70521545410156,
      "loss": 0.3127,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.5123696327209473,
      "rewards/margins": 2.913896322250366,
      "rewards/rejected": -5.426265716552734,
      "step": 14100
    },
    {
      "epoch": 2.5750524682909024,
      "grad_norm": 2.64559268951416,
      "learning_rate": 1.1474181862835391e-05,
      "logits/chosen": -1.2422523498535156,
      "logits/rejected": -1.2010952234268188,
      "logps/chosen": -158.05874633789062,
      "logps/rejected": -179.78721618652344,
      "loss": 0.3232,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.741189956665039,
      "rewards/margins": 2.2689356803894043,
      "rewards/rejected": -5.010125160217285,
      "step": 14110
    },
    {
      "epoch": 2.576877452322292,
      "grad_norm": 5.971365451812744,
      "learning_rate": 1.1425062933628049e-05,
      "logits/chosen": -1.3131202459335327,
      "logits/rejected": -1.2499052286148071,
      "logps/chosen": -169.60777282714844,
      "logps/rejected": -188.18939208984375,
      "loss": 0.2154,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.6411991119384766,
      "rewards/margins": 3.2502999305725098,
      "rewards/rejected": -4.891498565673828,
      "step": 14120
    },
    {
      "epoch": 2.578702436353682,
      "grad_norm": 13.52931022644043,
      "learning_rate": 1.1375944004420705e-05,
      "logits/chosen": -1.2272251844406128,
      "logits/rejected": -1.1815208196640015,
      "logps/chosen": -158.62550354003906,
      "logps/rejected": -182.53753662109375,
      "loss": 0.6274,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.8653502464294434,
      "rewards/margins": 2.0145821571350098,
      "rewards/rejected": -4.879932880401611,
      "step": 14130
    },
    {
      "epoch": 2.5805274203850717,
      "grad_norm": 6.9248480796813965,
      "learning_rate": 1.1326825075213361e-05,
      "logits/chosen": -1.2544258832931519,
      "logits/rejected": -1.1811621189117432,
      "logps/chosen": -175.6606903076172,
      "logps/rejected": -184.52322387695312,
      "loss": 0.2707,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.5047566890716553,
      "rewards/margins": 2.5748209953308105,
      "rewards/rejected": -5.079577445983887,
      "step": 14140
    },
    {
      "epoch": 2.5823524044164614,
      "grad_norm": 0.3735032379627228,
      "learning_rate": 1.1277706146006017e-05,
      "logits/chosen": -1.2446054220199585,
      "logits/rejected": -1.1777056455612183,
      "logps/chosen": -161.5193328857422,
      "logps/rejected": -169.48590087890625,
      "loss": 0.3357,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.212841510772705,
      "rewards/margins": 2.576140880584717,
      "rewards/rejected": -4.788981914520264,
      "step": 14150
    },
    {
      "epoch": 2.584177388447851,
      "grad_norm": 2.9883792400360107,
      "learning_rate": 1.1228587216798675e-05,
      "logits/chosen": -1.3072768449783325,
      "logits/rejected": -1.2343188524246216,
      "logps/chosen": -195.39688110351562,
      "logps/rejected": -188.59811401367188,
      "loss": 0.3229,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.2784743309020996,
      "rewards/margins": 2.6476712226867676,
      "rewards/rejected": -4.926145076751709,
      "step": 14160
    },
    {
      "epoch": 2.586002372479241,
      "grad_norm": 8.377846717834473,
      "learning_rate": 1.117946828759133e-05,
      "logits/chosen": -1.2591402530670166,
      "logits/rejected": -1.2058736085891724,
      "logps/chosen": -190.95779418945312,
      "logps/rejected": -210.6085968017578,
      "loss": 0.326,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.882020950317383,
      "rewards/margins": 2.6670494079589844,
      "rewards/rejected": -5.549069881439209,
      "step": 14170
    },
    {
      "epoch": 2.5878273565106307,
      "grad_norm": 14.553635597229004,
      "learning_rate": 1.1130349358383987e-05,
      "logits/chosen": -1.2847152948379517,
      "logits/rejected": -1.1700958013534546,
      "logps/chosen": -180.12107849121094,
      "logps/rejected": -186.2980499267578,
      "loss": 0.2603,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.830847978591919,
      "rewards/margins": 2.9728636741638184,
      "rewards/rejected": -4.803711891174316,
      "step": 14180
    },
    {
      "epoch": 2.5896523405420204,
      "grad_norm": 1.4125657081604004,
      "learning_rate": 1.1081230429176646e-05,
      "logits/chosen": -1.2637137174606323,
      "logits/rejected": -1.1975128650665283,
      "logps/chosen": -160.8477020263672,
      "logps/rejected": -181.3358612060547,
      "loss": 0.3349,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.2931225299835205,
      "rewards/margins": 2.947469711303711,
      "rewards/rejected": -5.2405924797058105,
      "step": 14190
    },
    {
      "epoch": 2.59147732457341,
      "grad_norm": 12.823892593383789,
      "learning_rate": 1.1032111499969302e-05,
      "logits/chosen": -1.2803704738616943,
      "logits/rejected": -1.2332128286361694,
      "logps/chosen": -165.24571228027344,
      "logps/rejected": -185.2123260498047,
      "loss": 0.2482,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.362712860107422,
      "rewards/margins": 2.625236988067627,
      "rewards/rejected": -4.987949848175049,
      "step": 14200
    },
    {
      "epoch": 2.5933023086048,
      "grad_norm": 2.599565029144287,
      "learning_rate": 1.0982992570761958e-05,
      "logits/chosen": -1.2057054042816162,
      "logits/rejected": -1.1041325330734253,
      "logps/chosen": -159.73416137695312,
      "logps/rejected": -171.6360626220703,
      "loss": 0.2373,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.4805006980895996,
      "rewards/margins": 2.975513219833374,
      "rewards/rejected": -5.4560136795043945,
      "step": 14210
    },
    {
      "epoch": 2.5951272926361897,
      "grad_norm": 4.234065532684326,
      "learning_rate": 1.0933873641554616e-05,
      "logits/chosen": -1.2583744525909424,
      "logits/rejected": -1.1778130531311035,
      "logps/chosen": -170.01380920410156,
      "logps/rejected": -174.4494171142578,
      "loss": 0.2632,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.826317548751831,
      "rewards/margins": 2.5542588233947754,
      "rewards/rejected": -5.380577087402344,
      "step": 14220
    },
    {
      "epoch": 2.596952276667579,
      "grad_norm": 6.884073257446289,
      "learning_rate": 1.0884754712347272e-05,
      "logits/chosen": -1.2461540699005127,
      "logits/rejected": -1.1651989221572876,
      "logps/chosen": -177.12734985351562,
      "logps/rejected": -161.23028564453125,
      "loss": 0.4518,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.6735453605651855,
      "rewards/margins": 2.4375545978546143,
      "rewards/rejected": -5.111100196838379,
      "step": 14230
    },
    {
      "epoch": 2.5987772606989687,
      "grad_norm": 9.347323417663574,
      "learning_rate": 1.0835635783139928e-05,
      "logits/chosen": -1.271302580833435,
      "logits/rejected": -1.2108440399169922,
      "logps/chosen": -163.102783203125,
      "logps/rejected": -183.26882934570312,
      "loss": 0.3886,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.555877447128296,
      "rewards/margins": 2.9710981845855713,
      "rewards/rejected": -5.526975631713867,
      "step": 14240
    },
    {
      "epoch": 2.6006022447303585,
      "grad_norm": 4.305772304534912,
      "learning_rate": 1.0786516853932584e-05,
      "logits/chosen": -1.2768018245697021,
      "logits/rejected": -1.1983747482299805,
      "logps/chosen": -169.23204040527344,
      "logps/rejected": -163.82363891601562,
      "loss": 0.2624,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.6308817863464355,
      "rewards/margins": 2.7759206295013428,
      "rewards/rejected": -5.406802654266357,
      "step": 14250
    },
    {
      "epoch": 2.6024272287617483,
      "grad_norm": 6.9256510734558105,
      "learning_rate": 1.0737397924725242e-05,
      "logits/chosen": -1.266208291053772,
      "logits/rejected": -1.2385612726211548,
      "logps/chosen": -156.9622344970703,
      "logps/rejected": -179.77383422851562,
      "loss": 0.3225,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.739258050918579,
      "rewards/margins": 2.5063843727111816,
      "rewards/rejected": -5.245642185211182,
      "step": 14260
    },
    {
      "epoch": 2.604252212793138,
      "grad_norm": 4.079762935638428,
      "learning_rate": 1.0688278995517898e-05,
      "logits/chosen": -1.2240080833435059,
      "logits/rejected": -1.209019660949707,
      "logps/chosen": -150.8599395751953,
      "logps/rejected": -187.07571411132812,
      "loss": 0.3127,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.8806538581848145,
      "rewards/margins": 2.97576642036438,
      "rewards/rejected": -5.856420993804932,
      "step": 14270
    },
    {
      "epoch": 2.6060771968245278,
      "grad_norm": 8.079026222229004,
      "learning_rate": 1.0639160066310554e-05,
      "logits/chosen": -1.3061304092407227,
      "logits/rejected": -1.2745882272720337,
      "logps/chosen": -161.50611877441406,
      "logps/rejected": -200.13027954101562,
      "loss": 0.245,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.974906325340271,
      "rewards/margins": 3.1671156883239746,
      "rewards/rejected": -5.142022132873535,
      "step": 14280
    },
    {
      "epoch": 2.6079021808559175,
      "grad_norm": 8.120743751525879,
      "learning_rate": 1.0590041137103213e-05,
      "logits/chosen": -1.295507550239563,
      "logits/rejected": -1.1837880611419678,
      "logps/chosen": -178.69728088378906,
      "logps/rejected": -183.39781188964844,
      "loss": 0.2683,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.814509868621826,
      "rewards/margins": 2.9618141651153564,
      "rewards/rejected": -5.776324272155762,
      "step": 14290
    },
    {
      "epoch": 2.6097271648873073,
      "grad_norm": 5.936429500579834,
      "learning_rate": 1.054092220789587e-05,
      "logits/chosen": -1.2583593130111694,
      "logits/rejected": -1.216279149055481,
      "logps/chosen": -167.29635620117188,
      "logps/rejected": -185.3357391357422,
      "loss": 0.4131,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.803689479827881,
      "rewards/margins": 2.2262539863586426,
      "rewards/rejected": -5.029942989349365,
      "step": 14300
    },
    {
      "epoch": 2.611552148918697,
      "grad_norm": 0.6189703941345215,
      "learning_rate": 1.0491803278688525e-05,
      "logits/chosen": -1.2715251445770264,
      "logits/rejected": -1.2295453548431396,
      "logps/chosen": -175.37838745117188,
      "logps/rejected": -186.42135620117188,
      "loss": 0.3646,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.4980597496032715,
      "rewards/margins": 2.431511640548706,
      "rewards/rejected": -4.929572105407715,
      "step": 14310
    },
    {
      "epoch": 2.613377132950087,
      "grad_norm": 13.53657054901123,
      "learning_rate": 1.0442684349481183e-05,
      "logits/chosen": -1.2819756269454956,
      "logits/rejected": -1.2319083213806152,
      "logps/chosen": -178.29653930664062,
      "logps/rejected": -183.1553192138672,
      "loss": 0.5037,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.671602249145508,
      "rewards/margins": 2.2022476196289062,
      "rewards/rejected": -4.873850345611572,
      "step": 14320
    },
    {
      "epoch": 2.6152021169814765,
      "grad_norm": 1.617166519165039,
      "learning_rate": 1.039356542027384e-05,
      "logits/chosen": -1.3049019575119019,
      "logits/rejected": -1.2032216787338257,
      "logps/chosen": -185.08523559570312,
      "logps/rejected": -178.8617401123047,
      "loss": 0.2617,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.291883945465088,
      "rewards/margins": 2.813632011413574,
      "rewards/rejected": -5.105515956878662,
      "step": 14330
    },
    {
      "epoch": 2.6170271010128663,
      "grad_norm": 8.676669120788574,
      "learning_rate": 1.0344446491066495e-05,
      "logits/chosen": -1.2493454217910767,
      "logits/rejected": -1.1876837015151978,
      "logps/chosen": -162.17239379882812,
      "logps/rejected": -185.27920532226562,
      "loss": 0.3057,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.339215040206909,
      "rewards/margins": 2.792052745819092,
      "rewards/rejected": -5.13126802444458,
      "step": 14340
    },
    {
      "epoch": 2.6188520850442556,
      "grad_norm": 3.5875256061553955,
      "learning_rate": 1.0295327561859151e-05,
      "logits/chosen": -1.2602870464324951,
      "logits/rejected": -1.1746277809143066,
      "logps/chosen": -164.40982055664062,
      "logps/rejected": -173.42507934570312,
      "loss": 0.2663,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.090010166168213,
      "rewards/margins": 2.629486560821533,
      "rewards/rejected": -4.719496250152588,
      "step": 14350
    },
    {
      "epoch": 2.6206770690756453,
      "grad_norm": 10.216156005859375,
      "learning_rate": 1.0246208632651809e-05,
      "logits/chosen": -1.2593085765838623,
      "logits/rejected": -1.1823294162750244,
      "logps/chosen": -175.71214294433594,
      "logps/rejected": -177.51571655273438,
      "loss": 0.3514,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.3409085273742676,
      "rewards/margins": 2.181522846221924,
      "rewards/rejected": -4.522431373596191,
      "step": 14360
    },
    {
      "epoch": 2.622502053107035,
      "grad_norm": 4.908595085144043,
      "learning_rate": 1.0197089703444465e-05,
      "logits/chosen": -1.315476417541504,
      "logits/rejected": -1.2162243127822876,
      "logps/chosen": -187.6102294921875,
      "logps/rejected": -174.85214233398438,
      "loss": 0.2639,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.838700294494629,
      "rewards/margins": 2.881094455718994,
      "rewards/rejected": -4.719795227050781,
      "step": 14370
    },
    {
      "epoch": 2.624327037138425,
      "grad_norm": 4.704700946807861,
      "learning_rate": 1.0147970774237121e-05,
      "logits/chosen": -1.2892849445343018,
      "logits/rejected": -1.214158296585083,
      "logps/chosen": -175.11758422851562,
      "logps/rejected": -173.70013427734375,
      "loss": 0.31,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.458416223526001,
      "rewards/margins": 2.5158801078796387,
      "rewards/rejected": -4.974296569824219,
      "step": 14380
    },
    {
      "epoch": 2.6261520211698146,
      "grad_norm": 4.149026870727539,
      "learning_rate": 1.009885184502978e-05,
      "logits/chosen": -1.313305377960205,
      "logits/rejected": -1.2641956806182861,
      "logps/chosen": -181.4778289794922,
      "logps/rejected": -188.25894165039062,
      "loss": 0.3477,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.6778252124786377,
      "rewards/margins": 2.3064186573028564,
      "rewards/rejected": -4.984243869781494,
      "step": 14390
    },
    {
      "epoch": 2.6279770052012044,
      "grad_norm": 1.5054090023040771,
      "learning_rate": 1.0049732915822437e-05,
      "logits/chosen": -1.2685010433197021,
      "logits/rejected": -1.231078863143921,
      "logps/chosen": -171.3340606689453,
      "logps/rejected": -171.3504180908203,
      "loss": 0.2427,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0932424068450928,
      "rewards/margins": 2.5287997722625732,
      "rewards/rejected": -4.622041702270508,
      "step": 14400
    },
    {
      "epoch": 2.629801989232594,
      "grad_norm": 5.152867794036865,
      "learning_rate": 1.0000613986615093e-05,
      "logits/chosen": -1.2757112979888916,
      "logits/rejected": -1.194352626800537,
      "logps/chosen": -172.34649658203125,
      "logps/rejected": -174.56504821777344,
      "loss": 0.3468,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.2747199535369873,
      "rewards/margins": 2.4320831298828125,
      "rewards/rejected": -4.706803321838379,
      "step": 14410
    },
    {
      "epoch": 2.631626973263984,
      "grad_norm": 6.06341028213501,
      "learning_rate": 9.95149505740775e-06,
      "logits/chosen": -1.3091051578521729,
      "logits/rejected": -1.1830809116363525,
      "logps/chosen": -197.96995544433594,
      "logps/rejected": -177.4554443359375,
      "loss": 0.3926,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.2389578819274902,
      "rewards/margins": 2.3129990100860596,
      "rewards/rejected": -4.551957130432129,
      "step": 14420
    },
    {
      "epoch": 2.6334519572953736,
      "grad_norm": 4.473085403442383,
      "learning_rate": 9.902376128200406e-06,
      "logits/chosen": -1.2500927448272705,
      "logits/rejected": -1.2023227214813232,
      "logps/chosen": -164.03138732910156,
      "logps/rejected": -177.4663543701172,
      "loss": 0.2865,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1353588104248047,
      "rewards/margins": 2.469160318374634,
      "rewards/rejected": -4.604518890380859,
      "step": 14430
    },
    {
      "epoch": 2.6352769413267634,
      "grad_norm": 8.0773344039917,
      "learning_rate": 9.853257198993062e-06,
      "logits/chosen": -1.2950462102890015,
      "logits/rejected": -1.1510673761367798,
      "logps/chosen": -183.3616943359375,
      "logps/rejected": -169.1626739501953,
      "loss": 0.2862,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.2684292793273926,
      "rewards/margins": 2.925004243850708,
      "rewards/rejected": -5.1934332847595215,
      "step": 14440
    },
    {
      "epoch": 2.637101925358153,
      "grad_norm": 4.9334211349487305,
      "learning_rate": 9.804138269785718e-06,
      "logits/chosen": -1.2580251693725586,
      "logits/rejected": -1.1785943508148193,
      "logps/chosen": -165.18951416015625,
      "logps/rejected": -179.81846618652344,
      "loss": 0.2042,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.0535531044006348,
      "rewards/margins": 2.858259677886963,
      "rewards/rejected": -4.911813259124756,
      "step": 14450
    },
    {
      "epoch": 2.638926909389543,
      "grad_norm": 5.279324531555176,
      "learning_rate": 9.755019340578376e-06,
      "logits/chosen": -1.2458288669586182,
      "logits/rejected": -1.1927918195724487,
      "logps/chosen": -173.66159057617188,
      "logps/rejected": -183.36978149414062,
      "loss": 0.3569,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.3113369941711426,
      "rewards/margins": 2.5050606727600098,
      "rewards/rejected": -4.816397666931152,
      "step": 14460
    },
    {
      "epoch": 2.6407518934209326,
      "grad_norm": 3.3879153728485107,
      "learning_rate": 9.705900411371034e-06,
      "logits/chosen": -1.3080204725265503,
      "logits/rejected": -1.217057704925537,
      "logps/chosen": -173.1272735595703,
      "logps/rejected": -179.4833221435547,
      "loss": 0.3425,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.280634641647339,
      "rewards/margins": 2.695378541946411,
      "rewards/rejected": -4.976014137268066,
      "step": 14470
    },
    {
      "epoch": 2.6425768774523224,
      "grad_norm": 4.596114158630371,
      "learning_rate": 9.65678148216369e-06,
      "logits/chosen": -1.2893282175064087,
      "logits/rejected": -1.2199970483779907,
      "logps/chosen": -165.7111053466797,
      "logps/rejected": -171.24720764160156,
      "loss": 0.2461,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.3514575958251953,
      "rewards/margins": 2.8174819946289062,
      "rewards/rejected": -5.168939590454102,
      "step": 14480
    },
    {
      "epoch": 2.644401861483712,
      "grad_norm": 2.7585906982421875,
      "learning_rate": 9.607662552956346e-06,
      "logits/chosen": -1.3000215291976929,
      "logits/rejected": -1.2033209800720215,
      "logps/chosen": -182.81600952148438,
      "logps/rejected": -175.20135498046875,
      "loss": 0.2555,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.236767292022705,
      "rewards/margins": 2.811800003051758,
      "rewards/rejected": -5.048567295074463,
      "step": 14490
    },
    {
      "epoch": 2.646226845515102,
      "grad_norm": 3.6169097423553467,
      "learning_rate": 9.558543623749002e-06,
      "logits/chosen": -1.2659579515457153,
      "logits/rejected": -1.1894758939743042,
      "logps/chosen": -168.6253204345703,
      "logps/rejected": -173.4620819091797,
      "loss": 0.2862,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.194516658782959,
      "rewards/margins": 2.351686477661133,
      "rewards/rejected": -4.546203136444092,
      "step": 14500
    },
    {
      "epoch": 2.6480518295464917,
      "grad_norm": 6.525815963745117,
      "learning_rate": 9.50942469454166e-06,
      "logits/chosen": -1.2879831790924072,
      "logits/rejected": -1.1919270753860474,
      "logps/chosen": -164.15122985839844,
      "logps/rejected": -169.03045654296875,
      "loss": 0.2725,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.156383991241455,
      "rewards/margins": 2.7805042266845703,
      "rewards/rejected": -4.936888217926025,
      "step": 14510
    },
    {
      "epoch": 2.6498768135778814,
      "grad_norm": 10.022170066833496,
      "learning_rate": 9.460305765334317e-06,
      "logits/chosen": -1.2670843601226807,
      "logits/rejected": -1.1880687475204468,
      "logps/chosen": -172.7438201904297,
      "logps/rejected": -176.40957641601562,
      "loss": 0.3385,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.3939476013183594,
      "rewards/margins": 2.1854071617126465,
      "rewards/rejected": -4.579354286193848,
      "step": 14520
    },
    {
      "epoch": 2.651701797609271,
      "grad_norm": 6.093805313110352,
      "learning_rate": 9.411186836126974e-06,
      "logits/chosen": -1.2165099382400513,
      "logits/rejected": -1.150123953819275,
      "logps/chosen": -177.39706420898438,
      "logps/rejected": -185.1889190673828,
      "loss": 0.3777,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.6097793579101562,
      "rewards/margins": 2.382434844970703,
      "rewards/rejected": -4.992214202880859,
      "step": 14530
    },
    {
      "epoch": 2.653526781640661,
      "grad_norm": 7.255829334259033,
      "learning_rate": 9.36206790691963e-06,
      "logits/chosen": -1.2518794536590576,
      "logits/rejected": -1.1805195808410645,
      "logps/chosen": -176.70877075195312,
      "logps/rejected": -172.30050659179688,
      "loss": 0.4312,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.5901176929473877,
      "rewards/margins": 2.1731247901916504,
      "rewards/rejected": -4.763242244720459,
      "step": 14540
    },
    {
      "epoch": 2.6553517656720502,
      "grad_norm": 4.961901664733887,
      "learning_rate": 9.312948977712286e-06,
      "logits/chosen": -1.232569694519043,
      "logits/rejected": -1.1863995790481567,
      "logps/chosen": -162.6219024658203,
      "logps/rejected": -174.07395935058594,
      "loss": 0.3588,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.5088648796081543,
      "rewards/margins": 1.9623057842254639,
      "rewards/rejected": -4.471170902252197,
      "step": 14550
    },
    {
      "epoch": 2.65717674970344,
      "grad_norm": 7.459990978240967,
      "learning_rate": 9.263830048504943e-06,
      "logits/chosen": -1.285488486289978,
      "logits/rejected": -1.2311244010925293,
      "logps/chosen": -160.56790161132812,
      "logps/rejected": -167.4311065673828,
      "loss": 0.2987,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4975831508636475,
      "rewards/margins": 2.322798013687134,
      "rewards/rejected": -4.820381164550781,
      "step": 14560
    },
    {
      "epoch": 2.6590017337348297,
      "grad_norm": 5.709052562713623,
      "learning_rate": 9.214711119297601e-06,
      "logits/chosen": -1.258138656616211,
      "logits/rejected": -1.21885347366333,
      "logps/chosen": -158.54647827148438,
      "logps/rejected": -166.5750274658203,
      "loss": 0.2687,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.0973715782165527,
      "rewards/margins": 2.5472729206085205,
      "rewards/rejected": -4.644644737243652,
      "step": 14570
    },
    {
      "epoch": 2.6608267177662195,
      "grad_norm": 9.506869316101074,
      "learning_rate": 9.165592190090257e-06,
      "logits/chosen": -1.2635847330093384,
      "logits/rejected": -1.1808421611785889,
      "logps/chosen": -177.95285034179688,
      "logps/rejected": -173.12576293945312,
      "loss": 0.3228,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.1938393115997314,
      "rewards/margins": 2.0870401859283447,
      "rewards/rejected": -4.280879020690918,
      "step": 14580
    },
    {
      "epoch": 2.6626517017976092,
      "grad_norm": 4.327035427093506,
      "learning_rate": 9.116473260882913e-06,
      "logits/chosen": -1.289724349975586,
      "logits/rejected": -1.1875836849212646,
      "logps/chosen": -172.46006774902344,
      "logps/rejected": -167.80113220214844,
      "loss": 0.3445,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.991140604019165,
      "rewards/margins": 2.2532503604888916,
      "rewards/rejected": -4.244390487670898,
      "step": 14590
    },
    {
      "epoch": 2.664476685828999,
      "grad_norm": 10.073908805847168,
      "learning_rate": 9.06735433167557e-06,
      "logits/chosen": -1.2688400745391846,
      "logits/rejected": -1.2199397087097168,
      "logps/chosen": -154.49725341796875,
      "logps/rejected": -166.36135864257812,
      "loss": 0.3038,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.2289624214172363,
      "rewards/margins": 2.2774577140808105,
      "rewards/rejected": -4.506420135498047,
      "step": 14600
    },
    {
      "epoch": 2.6663016698603887,
      "grad_norm": 4.562802314758301,
      "learning_rate": 9.018235402468227e-06,
      "logits/chosen": -1.3028953075408936,
      "logits/rejected": -1.1952252388000488,
      "logps/chosen": -174.55308532714844,
      "logps/rejected": -163.3724822998047,
      "loss": 0.2656,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.7430213689804077,
      "rewards/margins": 2.6580662727355957,
      "rewards/rejected": -4.401087760925293,
      "step": 14610
    },
    {
      "epoch": 2.6681266538917785,
      "grad_norm": 10.664130210876465,
      "learning_rate": 8.969116473260883e-06,
      "logits/chosen": -1.2405731678009033,
      "logits/rejected": -1.215909719467163,
      "logps/chosen": -172.5735321044922,
      "logps/rejected": -183.9452667236328,
      "loss": 0.3212,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.170405626296997,
      "rewards/margins": 2.4176013469696045,
      "rewards/rejected": -4.588006973266602,
      "step": 14620
    },
    {
      "epoch": 2.6699516379231683,
      "grad_norm": 2.583864212036133,
      "learning_rate": 8.91999754405354e-06,
      "logits/chosen": -1.2878369092941284,
      "logits/rejected": -1.2234165668487549,
      "logps/chosen": -177.9554901123047,
      "logps/rejected": -178.12704467773438,
      "loss": 0.2838,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.213930368423462,
      "rewards/margins": 2.7955362796783447,
      "rewards/rejected": -5.009466648101807,
      "step": 14630
    },
    {
      "epoch": 2.671776621954558,
      "grad_norm": 3.256989002227783,
      "learning_rate": 8.870878614846197e-06,
      "logits/chosen": -1.2555434703826904,
      "logits/rejected": -1.1672049760818481,
      "logps/chosen": -155.29507446289062,
      "logps/rejected": -169.2880401611328,
      "loss": 0.3226,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.0748233795166016,
      "rewards/margins": 2.460697889328003,
      "rewards/rejected": -4.535521507263184,
      "step": 14640
    },
    {
      "epoch": 2.6736016059859478,
      "grad_norm": 5.747845649719238,
      "learning_rate": 8.821759685638854e-06,
      "logits/chosen": -1.2938255071640015,
      "logits/rejected": -1.211864948272705,
      "logps/chosen": -172.80523681640625,
      "logps/rejected": -173.80148315429688,
      "loss": 0.3018,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1202006340026855,
      "rewards/margins": 2.5413460731506348,
      "rewards/rejected": -4.6615471839904785,
      "step": 14650
    },
    {
      "epoch": 2.6754265900173375,
      "grad_norm": 4.626123905181885,
      "learning_rate": 8.77264075643151e-06,
      "logits/chosen": -1.2788314819335938,
      "logits/rejected": -1.2508890628814697,
      "logps/chosen": -152.48960876464844,
      "logps/rejected": -172.791259765625,
      "loss": 0.2302,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.37959361076355,
      "rewards/margins": 2.6630759239196777,
      "rewards/rejected": -5.042669296264648,
      "step": 14660
    },
    {
      "epoch": 2.677251574048727,
      "grad_norm": 6.39400577545166,
      "learning_rate": 8.723521827224167e-06,
      "logits/chosen": -1.313080072402954,
      "logits/rejected": -1.2160314321517944,
      "logps/chosen": -179.60324096679688,
      "logps/rejected": -167.91241455078125,
      "loss": 0.435,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.6118288040161133,
      "rewards/margins": 2.2728219032287598,
      "rewards/rejected": -4.884650707244873,
      "step": 14670
    },
    {
      "epoch": 2.6790765580801166,
      "grad_norm": 6.020908355712891,
      "learning_rate": 8.674402898016824e-06,
      "logits/chosen": -1.2891026735305786,
      "logits/rejected": -1.2153252363204956,
      "logps/chosen": -169.8251495361328,
      "logps/rejected": -183.86846923828125,
      "loss": 0.2912,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.986973762512207,
      "rewards/margins": 2.709488868713379,
      "rewards/rejected": -4.696462631225586,
      "step": 14680
    },
    {
      "epoch": 2.6809015421115063,
      "grad_norm": 3.5511817932128906,
      "learning_rate": 8.62528396880948e-06,
      "logits/chosen": -1.275141954421997,
      "logits/rejected": -1.2000592947006226,
      "logps/chosen": -171.4028778076172,
      "logps/rejected": -174.7750701904297,
      "loss": 0.2549,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.386502504348755,
      "rewards/margins": 2.6055383682250977,
      "rewards/rejected": -4.992041110992432,
      "step": 14690
    },
    {
      "epoch": 2.682726526142896,
      "grad_norm": 5.577580451965332,
      "learning_rate": 8.576165039602138e-06,
      "logits/chosen": -1.292946457862854,
      "logits/rejected": -1.24392831325531,
      "logps/chosen": -157.17926025390625,
      "logps/rejected": -176.47303771972656,
      "loss": 0.2455,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.3575944900512695,
      "rewards/margins": 2.6850290298461914,
      "rewards/rejected": -5.042623519897461,
      "step": 14700
    },
    {
      "epoch": 2.684551510174286,
      "grad_norm": 2.4630579948425293,
      "learning_rate": 8.527046110394794e-06,
      "logits/chosen": -1.3523929119110107,
      "logits/rejected": -1.3089956045150757,
      "logps/chosen": -190.67190551757812,
      "logps/rejected": -199.12356567382812,
      "loss": 0.2802,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.037802219390869,
      "rewards/margins": 2.662513494491577,
      "rewards/rejected": -4.700315952301025,
      "step": 14710
    },
    {
      "epoch": 2.6863764942056756,
      "grad_norm": 4.384669780731201,
      "learning_rate": 8.47792718118745e-06,
      "logits/chosen": -1.277767539024353,
      "logits/rejected": -1.2372593879699707,
      "logps/chosen": -150.22146606445312,
      "logps/rejected": -164.1602020263672,
      "loss": 0.2762,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.3365213871002197,
      "rewards/margins": 2.3556275367736816,
      "rewards/rejected": -4.6921491622924805,
      "step": 14720
    },
    {
      "epoch": 2.6882014782370653,
      "grad_norm": 2.126842737197876,
      "learning_rate": 8.428808251980108e-06,
      "logits/chosen": -1.2835133075714111,
      "logits/rejected": -1.1900699138641357,
      "logps/chosen": -175.39837646484375,
      "logps/rejected": -170.9691925048828,
      "loss": 0.2308,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.248487949371338,
      "rewards/margins": 2.680389881134033,
      "rewards/rejected": -4.928878307342529,
      "step": 14730
    },
    {
      "epoch": 2.690026462268455,
      "grad_norm": 6.845944881439209,
      "learning_rate": 8.379689322772764e-06,
      "logits/chosen": -1.3338905572891235,
      "logits/rejected": -1.267608642578125,
      "logps/chosen": -164.8902130126953,
      "logps/rejected": -169.51412963867188,
      "loss": 0.2957,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1882216930389404,
      "rewards/margins": 2.247422933578491,
      "rewards/rejected": -4.435644626617432,
      "step": 14740
    },
    {
      "epoch": 2.691851446299845,
      "grad_norm": 3.392374038696289,
      "learning_rate": 8.330570393565422e-06,
      "logits/chosen": -1.3078835010528564,
      "logits/rejected": -1.2153071165084839,
      "logps/chosen": -157.50950622558594,
      "logps/rejected": -159.99801635742188,
      "loss": 0.415,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.676454544067383,
      "rewards/margins": 2.241755247116089,
      "rewards/rejected": -4.918210029602051,
      "step": 14750
    },
    {
      "epoch": 2.6936764303312346,
      "grad_norm": 4.27766752243042,
      "learning_rate": 8.281451464358078e-06,
      "logits/chosen": -1.3023027181625366,
      "logits/rejected": -1.230926752090454,
      "logps/chosen": -181.8966827392578,
      "logps/rejected": -177.8330841064453,
      "loss": 0.222,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.1623778343200684,
      "rewards/margins": 3.0502307415008545,
      "rewards/rejected": -5.212608337402344,
      "step": 14760
    },
    {
      "epoch": 2.6955014143626244,
      "grad_norm": 10.911274909973145,
      "learning_rate": 8.232332535150734e-06,
      "logits/chosen": -1.2657831907272339,
      "logits/rejected": -1.1943604946136475,
      "logps/chosen": -157.80999755859375,
      "logps/rejected": -165.75320434570312,
      "loss": 0.2918,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.2465615272521973,
      "rewards/margins": 2.406099796295166,
      "rewards/rejected": -4.652661323547363,
      "step": 14770
    },
    {
      "epoch": 2.697326398394014,
      "grad_norm": 6.481113433837891,
      "learning_rate": 8.183213605943391e-06,
      "logits/chosen": -1.2630836963653564,
      "logits/rejected": -1.197919249534607,
      "logps/chosen": -155.23358154296875,
      "logps/rejected": -172.11119079589844,
      "loss": 0.2882,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.524568796157837,
      "rewards/margins": 2.553522825241089,
      "rewards/rejected": -5.078091621398926,
      "step": 14780
    },
    {
      "epoch": 2.699151382425404,
      "grad_norm": 7.431016445159912,
      "learning_rate": 8.134094676736047e-06,
      "logits/chosen": -1.304292917251587,
      "logits/rejected": -1.2943390607833862,
      "logps/chosen": -155.45550537109375,
      "logps/rejected": -182.9160919189453,
      "loss": 0.3225,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9020029306411743,
      "rewards/margins": 2.3881561756134033,
      "rewards/rejected": -4.290159225463867,
      "step": 14790
    },
    {
      "epoch": 2.7009763664567936,
      "grad_norm": 2.6709697246551514,
      "learning_rate": 8.084975747528705e-06,
      "logits/chosen": -1.3217689990997314,
      "logits/rejected": -1.2296828031539917,
      "logps/chosen": -165.25131225585938,
      "logps/rejected": -183.97860717773438,
      "loss": 0.2562,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.4258081912994385,
      "rewards/margins": 2.990070104598999,
      "rewards/rejected": -5.415878772735596,
      "step": 14800
    },
    {
      "epoch": 2.7028013504881834,
      "grad_norm": 4.3857879638671875,
      "learning_rate": 8.035856818321361e-06,
      "logits/chosen": -1.2903718948364258,
      "logits/rejected": -1.2634515762329102,
      "logps/chosen": -159.92811584472656,
      "logps/rejected": -185.62994384765625,
      "loss": 0.1842,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.173740863800049,
      "rewards/margins": 3.024850845336914,
      "rewards/rejected": -5.198591709136963,
      "step": 14810
    },
    {
      "epoch": 2.704626334519573,
      "grad_norm": 2.6229283809661865,
      "learning_rate": 7.986737889114017e-06,
      "logits/chosen": -1.3620119094848633,
      "logits/rejected": -1.274023413658142,
      "logps/chosen": -165.64297485351562,
      "logps/rejected": -162.73081970214844,
      "loss": 0.326,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8574851751327515,
      "rewards/margins": 2.667314052581787,
      "rewards/rejected": -4.524799823760986,
      "step": 14820
    },
    {
      "epoch": 2.706451318550963,
      "grad_norm": 4.581229209899902,
      "learning_rate": 7.937618959906675e-06,
      "logits/chosen": -1.2993640899658203,
      "logits/rejected": -1.2570786476135254,
      "logps/chosen": -175.4341583251953,
      "logps/rejected": -185.85406494140625,
      "loss": 0.2886,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2472622394561768,
      "rewards/margins": 2.389662265777588,
      "rewards/rejected": -4.6369242668151855,
      "step": 14830
    },
    {
      "epoch": 2.7082763025823526,
      "grad_norm": 7.603174686431885,
      "learning_rate": 7.888500030699331e-06,
      "logits/chosen": -1.272562861442566,
      "logits/rejected": -1.236477255821228,
      "logps/chosen": -157.92921447753906,
      "logps/rejected": -173.4368133544922,
      "loss": 0.3289,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.3778645992279053,
      "rewards/margins": 2.375357151031494,
      "rewards/rejected": -4.7532219886779785,
      "step": 14840
    },
    {
      "epoch": 2.7101012866137424,
      "grad_norm": 6.728672504425049,
      "learning_rate": 7.839381101491989e-06,
      "logits/chosen": -1.3107630014419556,
      "logits/rejected": -1.2670838832855225,
      "logps/chosen": -168.0944061279297,
      "logps/rejected": -180.9440460205078,
      "loss": 0.2625,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.147024393081665,
      "rewards/margins": 2.8405697345733643,
      "rewards/rejected": -4.987593650817871,
      "step": 14850
    },
    {
      "epoch": 2.7119262706451317,
      "grad_norm": 7.380778789520264,
      "learning_rate": 7.790262172284645e-06,
      "logits/chosen": -1.289733648300171,
      "logits/rejected": -1.2665247917175293,
      "logps/chosen": -172.55113220214844,
      "logps/rejected": -199.18580627441406,
      "loss": 0.246,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.3668856620788574,
      "rewards/margins": 2.908165454864502,
      "rewards/rejected": -5.275051593780518,
      "step": 14860
    },
    {
      "epoch": 2.7137512546765215,
      "grad_norm": 1.3412189483642578,
      "learning_rate": 7.7411432430773e-06,
      "logits/chosen": -1.3350274562835693,
      "logits/rejected": -1.2769216299057007,
      "logps/chosen": -184.08995056152344,
      "logps/rejected": -192.6829071044922,
      "loss": 0.2639,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.014202117919922,
      "rewards/margins": 2.916714906692505,
      "rewards/rejected": -4.930917739868164,
      "step": 14870
    },
    {
      "epoch": 2.715576238707911,
      "grad_norm": 4.7320170402526855,
      "learning_rate": 7.692024313869959e-06,
      "logits/chosen": -1.2748931646347046,
      "logits/rejected": -1.2047581672668457,
      "logps/chosen": -168.12696838378906,
      "logps/rejected": -176.9161376953125,
      "loss": 0.2511,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.03320574760437,
      "rewards/margins": 2.647115707397461,
      "rewards/rejected": -4.680320739746094,
      "step": 14880
    },
    {
      "epoch": 2.717401222739301,
      "grad_norm": 9.354145050048828,
      "learning_rate": 7.642905384662615e-06,
      "logits/chosen": -1.3168573379516602,
      "logits/rejected": -1.19892418384552,
      "logps/chosen": -187.682373046875,
      "logps/rejected": -160.1121826171875,
      "loss": 0.4324,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.667739152908325,
      "rewards/margins": 1.9560234546661377,
      "rewards/rejected": -4.623763084411621,
      "step": 14890
    },
    {
      "epoch": 2.7192262067706907,
      "grad_norm": 10.180098533630371,
      "learning_rate": 7.593786455455272e-06,
      "logits/chosen": -1.3391449451446533,
      "logits/rejected": -1.2213472127914429,
      "logps/chosen": -182.0623321533203,
      "logps/rejected": -174.87045288085938,
      "loss": 0.2765,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.2263267040252686,
      "rewards/margins": 2.6455726623535156,
      "rewards/rejected": -4.871899604797363,
      "step": 14900
    },
    {
      "epoch": 2.7210511908020805,
      "grad_norm": 6.958741188049316,
      "learning_rate": 7.544667526247928e-06,
      "logits/chosen": -1.3279863595962524,
      "logits/rejected": -1.2509586811065674,
      "logps/chosen": -181.1529541015625,
      "logps/rejected": -189.10690307617188,
      "loss": 0.2728,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.288196086883545,
      "rewards/margins": 2.966355085372925,
      "rewards/rejected": -5.254550933837891,
      "step": 14910
    },
    {
      "epoch": 2.72287617483347,
      "grad_norm": 7.628934860229492,
      "learning_rate": 7.495548597040585e-06,
      "logits/chosen": -1.3536981344223022,
      "logits/rejected": -1.2640361785888672,
      "logps/chosen": -168.05857849121094,
      "logps/rejected": -171.32969665527344,
      "loss": 0.3799,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.066829204559326,
      "rewards/margins": 2.322373867034912,
      "rewards/rejected": -4.389203071594238,
      "step": 14920
    },
    {
      "epoch": 2.72470115886486,
      "grad_norm": 3.9696688652038574,
      "learning_rate": 7.446429667833241e-06,
      "logits/chosen": -1.283072829246521,
      "logits/rejected": -1.2714288234710693,
      "logps/chosen": -146.3038787841797,
      "logps/rejected": -169.59127807617188,
      "loss": 0.2924,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.096883773803711,
      "rewards/margins": 2.6601929664611816,
      "rewards/rejected": -4.757076263427734,
      "step": 14930
    },
    {
      "epoch": 2.7265261428962497,
      "grad_norm": 5.95141077041626,
      "learning_rate": 7.397310738625899e-06,
      "logits/chosen": -1.2918012142181396,
      "logits/rejected": -1.2392148971557617,
      "logps/chosen": -155.88754272460938,
      "logps/rejected": -182.98007202148438,
      "loss": 0.2259,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1179165840148926,
      "rewards/margins": 2.94398832321167,
      "rewards/rejected": -5.0619049072265625,
      "step": 14940
    },
    {
      "epoch": 2.7283511269276395,
      "grad_norm": 2.2937402725219727,
      "learning_rate": 7.348191809418556e-06,
      "logits/chosen": -1.3528692722320557,
      "logits/rejected": -1.2129137516021729,
      "logps/chosen": -180.22418212890625,
      "logps/rejected": -164.07960510253906,
      "loss": 0.2376,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.9350608587265015,
      "rewards/margins": 2.871994972229004,
      "rewards/rejected": -4.807055473327637,
      "step": 14950
    },
    {
      "epoch": 2.7301761109590292,
      "grad_norm": 4.926576137542725,
      "learning_rate": 7.299072880211212e-06,
      "logits/chosen": -1.3033390045166016,
      "logits/rejected": -1.2387773990631104,
      "logps/chosen": -164.83706665039062,
      "logps/rejected": -169.1400604248047,
      "loss": 0.2711,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.4171881675720215,
      "rewards/margins": 2.390453577041626,
      "rewards/rejected": -4.807641983032227,
      "step": 14960
    },
    {
      "epoch": 2.732001094990419,
      "grad_norm": 2.3366177082061768,
      "learning_rate": 7.249953951003869e-06,
      "logits/chosen": -1.2986036539077759,
      "logits/rejected": -1.2295589447021484,
      "logps/chosen": -161.2598114013672,
      "logps/rejected": -175.06051635742188,
      "loss": 0.2517,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8828729391098022,
      "rewards/margins": 2.8718669414520264,
      "rewards/rejected": -4.754740238189697,
      "step": 14970
    },
    {
      "epoch": 2.7338260790218083,
      "grad_norm": 2.360445022583008,
      "learning_rate": 7.200835021796525e-06,
      "logits/chosen": -1.2823022603988647,
      "logits/rejected": -1.2084630727767944,
      "logps/chosen": -181.2545928955078,
      "logps/rejected": -182.95730590820312,
      "loss": 0.2633,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.043332576751709,
      "rewards/margins": 2.655087471008301,
      "rewards/rejected": -4.69842004776001,
      "step": 14980
    },
    {
      "epoch": 2.735651063053198,
      "grad_norm": 5.7441277503967285,
      "learning_rate": 7.1517160925891826e-06,
      "logits/chosen": -1.208112120628357,
      "logits/rejected": -1.186425805091858,
      "logps/chosen": -159.1566619873047,
      "logps/rejected": -189.50848388671875,
      "loss": 0.2892,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.0006279945373535,
      "rewards/margins": 2.511335611343384,
      "rewards/rejected": -5.511963367462158,
      "step": 14990
    },
    {
      "epoch": 2.737476047084588,
      "grad_norm": 11.57068920135498,
      "learning_rate": 7.1025971633818394e-06,
      "logits/chosen": -1.3540102243423462,
      "logits/rejected": -1.2755556106567383,
      "logps/chosen": -185.34262084960938,
      "logps/rejected": -189.52159118652344,
      "loss": 0.3359,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.0766892433166504,
      "rewards/margins": 2.4822046756744385,
      "rewards/rejected": -4.558894157409668,
      "step": 15000
    },
    {
      "epoch": 2.7393010311159776,
      "grad_norm": 12.421673774719238,
      "learning_rate": 7.0534782341744955e-06,
      "logits/chosen": -1.3048049211502075,
      "logits/rejected": -1.1707172393798828,
      "logps/chosen": -178.05245971679688,
      "logps/rejected": -165.6903076171875,
      "loss": 0.3152,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.1982712745666504,
      "rewards/margins": 2.532054901123047,
      "rewards/rejected": -4.730325698852539,
      "step": 15010
    },
    {
      "epoch": 2.7411260151473673,
      "grad_norm": 6.301589012145996,
      "learning_rate": 7.004359304967152e-06,
      "logits/chosen": -1.3044836521148682,
      "logits/rejected": -1.2487800121307373,
      "logps/chosen": -155.00967407226562,
      "logps/rejected": -183.9751434326172,
      "loss": 0.2659,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.2190263271331787,
      "rewards/margins": 2.9205245971679688,
      "rewards/rejected": -5.139551639556885,
      "step": 15020
    },
    {
      "epoch": 2.742950999178757,
      "grad_norm": 8.45380973815918,
      "learning_rate": 6.955240375759808e-06,
      "logits/chosen": -1.2536489963531494,
      "logits/rejected": -1.1419330835342407,
      "logps/chosen": -165.8306121826172,
      "logps/rejected": -179.346435546875,
      "loss": 0.197,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -2.206132173538208,
      "rewards/margins": 3.1192710399627686,
      "rewards/rejected": -5.325402736663818,
      "step": 15030
    },
    {
      "epoch": 2.744775983210147,
      "grad_norm": 8.229822158813477,
      "learning_rate": 6.906121446552466e-06,
      "logits/chosen": -1.3192226886749268,
      "logits/rejected": -1.202887773513794,
      "logps/chosen": -174.89828491210938,
      "logps/rejected": -163.08363342285156,
      "loss": 0.2411,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.9158151149749756,
      "rewards/margins": 3.0940463542938232,
      "rewards/rejected": -5.009861469268799,
      "step": 15040
    },
    {
      "epoch": 2.7466009672415366,
      "grad_norm": 5.5774407386779785,
      "learning_rate": 6.857002517345123e-06,
      "logits/chosen": -1.2856117486953735,
      "logits/rejected": -1.2197036743164062,
      "logps/chosen": -172.35096740722656,
      "logps/rejected": -172.49928283691406,
      "loss": 0.2729,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.0267741680145264,
      "rewards/margins": 2.7996134757995605,
      "rewards/rejected": -4.826387405395508,
      "step": 15050
    },
    {
      "epoch": 2.7484259512729263,
      "grad_norm": 4.001475811004639,
      "learning_rate": 6.807883588137779e-06,
      "logits/chosen": -1.2741405963897705,
      "logits/rejected": -1.1894235610961914,
      "logps/chosen": -163.0493621826172,
      "logps/rejected": -165.18701171875,
      "loss": 0.281,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.122964859008789,
      "rewards/margins": 2.740905284881592,
      "rewards/rejected": -4.863870143890381,
      "step": 15060
    },
    {
      "epoch": 2.750250935304316,
      "grad_norm": 12.145127296447754,
      "learning_rate": 6.758764658930436e-06,
      "logits/chosen": -1.272605538368225,
      "logits/rejected": -1.222234845161438,
      "logps/chosen": -153.52854919433594,
      "logps/rejected": -178.7496337890625,
      "loss": 0.2481,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.9516007900238037,
      "rewards/margins": 3.00028395652771,
      "rewards/rejected": -4.951885223388672,
      "step": 15070
    },
    {
      "epoch": 2.752075919335706,
      "grad_norm": 10.942315101623535,
      "learning_rate": 6.709645729723092e-06,
      "logits/chosen": -1.316646695137024,
      "logits/rejected": -1.229612112045288,
      "logps/chosen": -169.96908569335938,
      "logps/rejected": -160.93394470214844,
      "loss": 0.2906,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.0458970069885254,
      "rewards/margins": 2.5908520221710205,
      "rewards/rejected": -4.636748313903809,
      "step": 15080
    },
    {
      "epoch": 2.7539009033670956,
      "grad_norm": 6.236338138580322,
      "learning_rate": 6.66052680051575e-06,
      "logits/chosen": -1.3100204467773438,
      "logits/rejected": -1.2324503660202026,
      "logps/chosen": -165.66769409179688,
      "logps/rejected": -179.11239624023438,
      "loss": 0.3001,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8725007772445679,
      "rewards/margins": 2.6025309562683105,
      "rewards/rejected": -4.475031852722168,
      "step": 15090
    },
    {
      "epoch": 2.7557258873984853,
      "grad_norm": 6.3803300857543945,
      "learning_rate": 6.611407871308407e-06,
      "logits/chosen": -1.2710808515548706,
      "logits/rejected": -1.2632746696472168,
      "logps/chosen": -144.81167602539062,
      "logps/rejected": -177.30589294433594,
      "loss": 0.321,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.0097384452819824,
      "rewards/margins": 2.5764377117156982,
      "rewards/rejected": -4.586175918579102,
      "step": 15100
    },
    {
      "epoch": 2.757550871429875,
      "grad_norm": 7.716960430145264,
      "learning_rate": 6.562288942101063e-06,
      "logits/chosen": -1.2848780155181885,
      "logits/rejected": -1.211874008178711,
      "logps/chosen": -168.156494140625,
      "logps/rejected": -176.65182495117188,
      "loss": 0.3031,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.3007235527038574,
      "rewards/margins": 2.521043300628662,
      "rewards/rejected": -4.8217668533325195,
      "step": 15110
    },
    {
      "epoch": 2.759375855461265,
      "grad_norm": 8.23707103729248,
      "learning_rate": 6.5131700128937195e-06,
      "logits/chosen": -1.2550873756408691,
      "logits/rejected": -1.2246001958847046,
      "logps/chosen": -154.22633361816406,
      "logps/rejected": -182.9718475341797,
      "loss": 0.3137,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.397614002227783,
      "rewards/margins": 2.9491710662841797,
      "rewards/rejected": -5.346785545349121,
      "step": 15120
    },
    {
      "epoch": 2.7612008394926546,
      "grad_norm": 3.2407119274139404,
      "learning_rate": 6.4640510836863756e-06,
      "logits/chosen": -1.2990864515304565,
      "logits/rejected": -1.2295558452606201,
      "logps/chosen": -182.2970733642578,
      "logps/rejected": -187.39596557617188,
      "loss": 0.2205,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.5300755500793457,
      "rewards/margins": 2.6310057640075684,
      "rewards/rejected": -5.161081790924072,
      "step": 15130
    },
    {
      "epoch": 2.7630258235240444,
      "grad_norm": 3.5891618728637695,
      "learning_rate": 6.414932154479033e-06,
      "logits/chosen": -1.308591365814209,
      "logits/rejected": -1.1789741516113281,
      "logps/chosen": -191.1769561767578,
      "logps/rejected": -176.1598663330078,
      "loss": 0.2943,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.732452869415283,
      "rewards/margins": 2.548686981201172,
      "rewards/rejected": -5.281139373779297,
      "step": 15140
    },
    {
      "epoch": 2.764850807555434,
      "grad_norm": 7.88864803314209,
      "learning_rate": 6.36581322527169e-06,
      "logits/chosen": -1.3343660831451416,
      "logits/rejected": -1.2428410053253174,
      "logps/chosen": -168.85337829589844,
      "logps/rejected": -171.1470184326172,
      "loss": 0.3083,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8423506021499634,
      "rewards/margins": 2.523460626602173,
      "rewards/rejected": -4.365810871124268,
      "step": 15150
    },
    {
      "epoch": 2.766675791586824,
      "grad_norm": 5.752494812011719,
      "learning_rate": 6.316694296064346e-06,
      "logits/chosen": -1.298140525817871,
      "logits/rejected": -1.238337755203247,
      "logps/chosen": -172.47779846191406,
      "logps/rejected": -185.12509155273438,
      "loss": 0.4001,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.204561710357666,
      "rewards/margins": 2.657410144805908,
      "rewards/rejected": -4.861971855163574,
      "step": 15160
    },
    {
      "epoch": 2.7685007756182136,
      "grad_norm": 7.272274494171143,
      "learning_rate": 6.267575366857003e-06,
      "logits/chosen": -1.2821499109268188,
      "logits/rejected": -1.2195857763290405,
      "logps/chosen": -185.5363311767578,
      "logps/rejected": -189.0556640625,
      "loss": 0.2745,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.3416099548339844,
      "rewards/margins": 2.807312250137329,
      "rewards/rejected": -5.148922443389893,
      "step": 15170
    },
    {
      "epoch": 2.770325759649603,
      "grad_norm": 6.117114067077637,
      "learning_rate": 6.218456437649659e-06,
      "logits/chosen": -1.3021647930145264,
      "logits/rejected": -1.1967532634735107,
      "logps/chosen": -172.74954223632812,
      "logps/rejected": -175.19081115722656,
      "loss": 0.2211,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.8042598962783813,
      "rewards/margins": 2.4614994525909424,
      "rewards/rejected": -4.265758991241455,
      "step": 15180
    },
    {
      "epoch": 2.7721507436809927,
      "grad_norm": 3.3156208992004395,
      "learning_rate": 6.169337508442317e-06,
      "logits/chosen": -1.327980875968933,
      "logits/rejected": -1.2355499267578125,
      "logps/chosen": -163.70570373535156,
      "logps/rejected": -174.1351318359375,
      "loss": 0.2315,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -1.989956259727478,
      "rewards/margins": 2.7438111305236816,
      "rewards/rejected": -4.733767509460449,
      "step": 15190
    },
    {
      "epoch": 2.7739757277123824,
      "grad_norm": 7.3526387214660645,
      "learning_rate": 6.120218579234973e-06,
      "logits/chosen": -1.3088576793670654,
      "logits/rejected": -1.207248330116272,
      "logps/chosen": -177.87393188476562,
      "logps/rejected": -176.2542724609375,
      "loss": 0.2846,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.8755581378936768,
      "rewards/margins": 2.8510544300079346,
      "rewards/rejected": -4.7266130447387695,
      "step": 15200
    },
    {
      "epoch": 2.775800711743772,
      "grad_norm": 5.84691858291626,
      "learning_rate": 6.07109965002763e-06,
      "logits/chosen": -1.3261499404907227,
      "logits/rejected": -1.235898733139038,
      "logps/chosen": -179.0557098388672,
      "logps/rejected": -180.36160278320312,
      "loss": 0.3838,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.3108763694763184,
      "rewards/margins": 2.929107189178467,
      "rewards/rejected": -5.239983558654785,
      "step": 15210
    },
    {
      "epoch": 2.777625695775162,
      "grad_norm": 3.825765371322632,
      "learning_rate": 6.021980720820287e-06,
      "logits/chosen": -1.2412879467010498,
      "logits/rejected": -1.1861729621887207,
      "logps/chosen": -144.0043182373047,
      "logps/rejected": -173.580810546875,
      "loss": 0.3639,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8062422275543213,
      "rewards/margins": 3.0298655033111572,
      "rewards/rejected": -4.8361077308654785,
      "step": 15220
    },
    {
      "epoch": 2.7794506798065517,
      "grad_norm": 3.8421342372894287,
      "learning_rate": 5.972861791612943e-06,
      "logits/chosen": -1.2718788385391235,
      "logits/rejected": -1.2151219844818115,
      "logps/chosen": -163.6502227783203,
      "logps/rejected": -176.9632568359375,
      "loss": 0.2275,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.2142248153686523,
      "rewards/margins": 2.895320177078247,
      "rewards/rejected": -5.109545707702637,
      "step": 15230
    },
    {
      "epoch": 2.7812756638379414,
      "grad_norm": 7.619726657867432,
      "learning_rate": 5.9237428624056004e-06,
      "logits/chosen": -1.2725093364715576,
      "logits/rejected": -1.2125585079193115,
      "logps/chosen": -147.37808227539062,
      "logps/rejected": -166.4723358154297,
      "loss": 0.3579,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1285250186920166,
      "rewards/margins": 2.7776031494140625,
      "rewards/rejected": -4.9061279296875,
      "step": 15240
    },
    {
      "epoch": 2.783100647869331,
      "grad_norm": 5.847338676452637,
      "learning_rate": 5.8746239331982565e-06,
      "logits/chosen": -1.3039571046829224,
      "logits/rejected": -1.243094801902771,
      "logps/chosen": -168.9871063232422,
      "logps/rejected": -191.134521484375,
      "loss": 0.2469,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.7245333194732666,
      "rewards/margins": 2.8980422019958496,
      "rewards/rejected": -4.622575283050537,
      "step": 15250
    },
    {
      "epoch": 2.784925631900721,
      "grad_norm": 9.071980476379395,
      "learning_rate": 5.825505003990913e-06,
      "logits/chosen": -1.2981032133102417,
      "logits/rejected": -1.2167270183563232,
      "logps/chosen": -190.4906463623047,
      "logps/rejected": -183.05616760253906,
      "loss": 0.4748,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.499246120452881,
      "rewards/margins": 1.9963184595108032,
      "rewards/rejected": -4.4955644607543945,
      "step": 15260
    },
    {
      "epoch": 2.7867506159321107,
      "grad_norm": 6.1922831535339355,
      "learning_rate": 5.77638607478357e-06,
      "logits/chosen": -1.3165357112884521,
      "logits/rejected": -1.2412585020065308,
      "logps/chosen": -172.15695190429688,
      "logps/rejected": -173.92691040039062,
      "loss": 0.5158,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.218289375305176,
      "rewards/margins": 2.076690912246704,
      "rewards/rejected": -4.294980525970459,
      "step": 15270
    },
    {
      "epoch": 2.7885755999635005,
      "grad_norm": 6.563896656036377,
      "learning_rate": 5.727267145576227e-06,
      "logits/chosen": -1.2875452041625977,
      "logits/rejected": -1.233806848526001,
      "logps/chosen": -157.53709411621094,
      "logps/rejected": -169.3411407470703,
      "loss": 0.3437,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.786317229270935,
      "rewards/margins": 2.4406509399414062,
      "rewards/rejected": -4.226967811584473,
      "step": 15280
    },
    {
      "epoch": 2.7904005839948898,
      "grad_norm": 3.6603524684906006,
      "learning_rate": 5.678148216368884e-06,
      "logits/chosen": -1.268768072128296,
      "logits/rejected": -1.1795036792755127,
      "logps/chosen": -162.5953369140625,
      "logps/rejected": -178.10595703125,
      "loss": 0.2053,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8472816944122314,
      "rewards/margins": 3.056802272796631,
      "rewards/rejected": -4.904084205627441,
      "step": 15290
    },
    {
      "epoch": 2.7922255680262795,
      "grad_norm": 2.1039326190948486,
      "learning_rate": 5.62902928716154e-06,
      "logits/chosen": -1.3061158657073975,
      "logits/rejected": -1.2261240482330322,
      "logps/chosen": -171.58200073242188,
      "logps/rejected": -180.4493865966797,
      "loss": 0.2096,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.864563226699829,
      "rewards/margins": 3.0359747409820557,
      "rewards/rejected": -4.900537967681885,
      "step": 15300
    },
    {
      "epoch": 2.7940505520576693,
      "grad_norm": 11.942286491394043,
      "learning_rate": 5.579910357954197e-06,
      "logits/chosen": -1.240802526473999,
      "logits/rejected": -1.1166123151779175,
      "logps/chosen": -174.3446044921875,
      "logps/rejected": -156.62142944335938,
      "loss": 0.3957,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.2552103996276855,
      "rewards/margins": 2.3652424812316895,
      "rewards/rejected": -4.620452880859375,
      "step": 15310
    },
    {
      "epoch": 2.795875536089059,
      "grad_norm": 1.8050329685211182,
      "learning_rate": 5.530791428746853e-06,
      "logits/chosen": -1.2635650634765625,
      "logits/rejected": -1.1654938459396362,
      "logps/chosen": -188.11563110351562,
      "logps/rejected": -175.66976928710938,
      "loss": 0.2853,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0871741771698,
      "rewards/margins": 2.6005871295928955,
      "rewards/rejected": -4.6877617835998535,
      "step": 15320
    },
    {
      "epoch": 2.797700520120449,
      "grad_norm": 2.4547030925750732,
      "learning_rate": 5.481672499539511e-06,
      "logits/chosen": -1.294734239578247,
      "logits/rejected": -1.1759881973266602,
      "logps/chosen": -165.73464965820312,
      "logps/rejected": -178.5666961669922,
      "loss": 0.2253,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.100019693374634,
      "rewards/margins": 2.9687063694000244,
      "rewards/rejected": -5.068726539611816,
      "step": 15330
    },
    {
      "epoch": 2.7995255041518385,
      "grad_norm": 3.983144521713257,
      "learning_rate": 5.432553570332168e-06,
      "logits/chosen": -1.3309681415557861,
      "logits/rejected": -1.2739841938018799,
      "logps/chosen": -180.30758666992188,
      "logps/rejected": -195.17636108398438,
      "loss": 0.2969,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.7807918787002563,
      "rewards/margins": 2.6264498233795166,
      "rewards/rejected": -4.407241344451904,
      "step": 15340
    },
    {
      "epoch": 2.8013504881832283,
      "grad_norm": 7.528571128845215,
      "learning_rate": 5.383434641124824e-06,
      "logits/chosen": -1.198322057723999,
      "logits/rejected": -1.179908037185669,
      "logps/chosen": -155.0124053955078,
      "logps/rejected": -186.6446075439453,
      "loss": 0.3805,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.4388153553009033,
      "rewards/margins": 2.1649746894836426,
      "rewards/rejected": -4.603790283203125,
      "step": 15350
    },
    {
      "epoch": 2.803175472214618,
      "grad_norm": 4.030930519104004,
      "learning_rate": 5.3343157119174805e-06,
      "logits/chosen": -1.281256079673767,
      "logits/rejected": -1.194871187210083,
      "logps/chosen": -161.12937927246094,
      "logps/rejected": -165.79092407226562,
      "loss": 0.1932,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.7191994190216064,
      "rewards/margins": 2.8838627338409424,
      "rewards/rejected": -4.603062629699707,
      "step": 15360
    },
    {
      "epoch": 2.805000456246008,
      "grad_norm": 7.928770542144775,
      "learning_rate": 5.2851967827101365e-06,
      "logits/chosen": -1.2537158727645874,
      "logits/rejected": -1.2059602737426758,
      "logps/chosen": -169.13026428222656,
      "logps/rejected": -166.56678771972656,
      "loss": 0.3957,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.211113929748535,
      "rewards/margins": 2.0365748405456543,
      "rewards/rejected": -4.2476887702941895,
      "step": 15370
    },
    {
      "epoch": 2.8068254402773976,
      "grad_norm": 2.4494051933288574,
      "learning_rate": 5.236077853502794e-06,
      "logits/chosen": -1.2782617807388306,
      "logits/rejected": -1.162139654159546,
      "logps/chosen": -161.15394592285156,
      "logps/rejected": -161.39102172851562,
      "loss": 0.3036,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.18756365776062,
      "rewards/margins": 2.599792718887329,
      "rewards/rejected": -4.787356376647949,
      "step": 15380
    },
    {
      "epoch": 2.8086504243087873,
      "grad_norm": 4.9185872077941895,
      "learning_rate": 5.186958924295451e-06,
      "logits/chosen": -1.232387900352478,
      "logits/rejected": -1.1813774108886719,
      "logps/chosen": -168.09341430664062,
      "logps/rejected": -174.11508178710938,
      "loss": 0.3702,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.4394867420196533,
      "rewards/margins": 2.306792974472046,
      "rewards/rejected": -4.746279239654541,
      "step": 15390
    },
    {
      "epoch": 2.810475408340177,
      "grad_norm": 3.8026509284973145,
      "learning_rate": 5.137839995088107e-06,
      "logits/chosen": -1.2170047760009766,
      "logits/rejected": -1.1563843488693237,
      "logps/chosen": -157.5721893310547,
      "logps/rejected": -186.50045776367188,
      "loss": 0.2029,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.266164541244507,
      "rewards/margins": 3.16251540184021,
      "rewards/rejected": -5.428679943084717,
      "step": 15400
    },
    {
      "epoch": 2.812300392371567,
      "grad_norm": 10.913809776306152,
      "learning_rate": 5.088721065880764e-06,
      "logits/chosen": -1.1781989336013794,
      "logits/rejected": -1.129482626914978,
      "logps/chosen": -156.28504943847656,
      "logps/rejected": -177.15028381347656,
      "loss": 0.225,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.0672528743743896,
      "rewards/margins": 2.752288818359375,
      "rewards/rejected": -4.8195414543151855,
      "step": 15410
    },
    {
      "epoch": 2.8141253764029566,
      "grad_norm": 6.093564510345459,
      "learning_rate": 5.03960213667342e-06,
      "logits/chosen": -1.2632442712783813,
      "logits/rejected": -1.1751039028167725,
      "logps/chosen": -159.36875915527344,
      "logps/rejected": -163.68984985351562,
      "loss": 0.2713,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.7868480682373047,
      "rewards/margins": 2.6634185314178467,
      "rewards/rejected": -4.4502668380737305,
      "step": 15420
    },
    {
      "epoch": 2.8159503604343463,
      "grad_norm": 3.049910306930542,
      "learning_rate": 4.990483207466078e-06,
      "logits/chosen": -1.2202060222625732,
      "logits/rejected": -1.1330616474151611,
      "logps/chosen": -166.12387084960938,
      "logps/rejected": -177.7387237548828,
      "loss": 0.342,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.195338249206543,
      "rewards/margins": 2.7085652351379395,
      "rewards/rejected": -4.903903007507324,
      "step": 15430
    },
    {
      "epoch": 2.817775344465736,
      "grad_norm": 3.7786877155303955,
      "learning_rate": 4.941364278258735e-06,
      "logits/chosen": -1.2844101190567017,
      "logits/rejected": -1.2141039371490479,
      "logps/chosen": -158.68173217773438,
      "logps/rejected": -179.9283447265625,
      "loss": 0.3636,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.120004177093506,
      "rewards/margins": 2.62261962890625,
      "rewards/rejected": -4.742623329162598,
      "step": 15440
    },
    {
      "epoch": 2.819600328497126,
      "grad_norm": 1.164092779159546,
      "learning_rate": 4.892245349051391e-06,
      "logits/chosen": -1.267350196838379,
      "logits/rejected": -1.1617162227630615,
      "logps/chosen": -184.4539337158203,
      "logps/rejected": -179.64273071289062,
      "loss": 0.2003,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.7920172214508057,
      "rewards/margins": 3.2391152381896973,
      "rewards/rejected": -5.031132698059082,
      "step": 15450
    },
    {
      "epoch": 2.8214253125285156,
      "grad_norm": 7.505958557128906,
      "learning_rate": 4.843126419844048e-06,
      "logits/chosen": -1.2257150411605835,
      "logits/rejected": -1.1316616535186768,
      "logps/chosen": -184.25558471679688,
      "logps/rejected": -178.9024200439453,
      "loss": 0.3526,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.572901487350464,
      "rewards/margins": 2.371324300765991,
      "rewards/rejected": -4.944226264953613,
      "step": 15460
    },
    {
      "epoch": 2.8232502965599053,
      "grad_norm": 8.281937599182129,
      "learning_rate": 4.7940074906367045e-06,
      "logits/chosen": -1.2460803985595703,
      "logits/rejected": -1.1149805784225464,
      "logps/chosen": -180.04469299316406,
      "logps/rejected": -178.20773315429688,
      "loss": 0.3256,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.097567081451416,
      "rewards/margins": 2.7941372394561768,
      "rewards/rejected": -4.891704082489014,
      "step": 15470
    },
    {
      "epoch": 2.825075280591295,
      "grad_norm": 11.005576133728027,
      "learning_rate": 4.744888561429361e-06,
      "logits/chosen": -1.2073081731796265,
      "logits/rejected": -1.1406078338623047,
      "logps/chosen": -158.29664611816406,
      "logps/rejected": -176.51913452148438,
      "loss": 0.2417,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.1254665851593018,
      "rewards/margins": 2.791769027709961,
      "rewards/rejected": -4.917235374450684,
      "step": 15480
    },
    {
      "epoch": 2.8269002646226844,
      "grad_norm": 7.091459274291992,
      "learning_rate": 4.695769632222018e-06,
      "logits/chosen": -1.251774549484253,
      "logits/rejected": -1.1445167064666748,
      "logps/chosen": -171.10726928710938,
      "logps/rejected": -190.48214721679688,
      "loss": 0.2512,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.0012121200561523,
      "rewards/margins": 2.8732805252075195,
      "rewards/rejected": -4.874492645263672,
      "step": 15490
    },
    {
      "epoch": 2.828725248654074,
      "grad_norm": 2.207113027572632,
      "learning_rate": 4.646650703014674e-06,
      "logits/chosen": -1.2381170988082886,
      "logits/rejected": -1.1552679538726807,
      "logps/chosen": -163.28274536132812,
      "logps/rejected": -173.19207763671875,
      "loss": 0.2104,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.480302095413208,
      "rewards/margins": 3.0787253379821777,
      "rewards/rejected": -5.559028148651123,
      "step": 15500
    },
    {
      "epoch": 2.830550232685464,
      "grad_norm": 10.210235595703125,
      "learning_rate": 4.597531773807331e-06,
      "logits/chosen": -1.183475136756897,
      "logits/rejected": -1.0919840335845947,
      "logps/chosen": -171.94464111328125,
      "logps/rejected": -173.65615844726562,
      "loss": 0.3156,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.591783046722412,
      "rewards/margins": 2.5923962593078613,
      "rewards/rejected": -5.184179782867432,
      "step": 15510
    },
    {
      "epoch": 2.8323752167168537,
      "grad_norm": 7.054238796234131,
      "learning_rate": 4.548412844599988e-06,
      "logits/chosen": -1.1917483806610107,
      "logits/rejected": -1.1161918640136719,
      "logps/chosen": -161.99984741210938,
      "logps/rejected": -161.29190063476562,
      "loss": 0.4053,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.1425931453704834,
      "rewards/margins": 2.3374805450439453,
      "rewards/rejected": -4.48007345199585,
      "step": 15520
    },
    {
      "epoch": 2.8342002007482434,
      "grad_norm": 5.777679920196533,
      "learning_rate": 4.499293915392645e-06,
      "logits/chosen": -1.173104166984558,
      "logits/rejected": -1.1434069871902466,
      "logps/chosen": -147.86404418945312,
      "logps/rejected": -172.0648193359375,
      "loss": 0.3537,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.5696494579315186,
      "rewards/margins": 2.71254301071167,
      "rewards/rejected": -5.282192230224609,
      "step": 15530
    },
    {
      "epoch": 2.836025184779633,
      "grad_norm": 4.391595840454102,
      "learning_rate": 4.450174986185302e-06,
      "logits/chosen": -1.2627248764038086,
      "logits/rejected": -1.1608664989471436,
      "logps/chosen": -167.75491333007812,
      "logps/rejected": -169.32745361328125,
      "loss": 0.2592,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.172778606414795,
      "rewards/margins": 2.6555399894714355,
      "rewards/rejected": -4.8283185958862305,
      "step": 15540
    },
    {
      "epoch": 2.837850168811023,
      "grad_norm": 1.5805341005325317,
      "learning_rate": 4.401056056977958e-06,
      "logits/chosen": -1.1963989734649658,
      "logits/rejected": -1.0741934776306152,
      "logps/chosen": -155.1390838623047,
      "logps/rejected": -163.11825561523438,
      "loss": 0.1864,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.9341135025024414,
      "rewards/margins": 3.1233835220336914,
      "rewards/rejected": -5.057497978210449,
      "step": 15550
    },
    {
      "epoch": 2.8396751528424127,
      "grad_norm": 3.295029640197754,
      "learning_rate": 4.351937127770615e-06,
      "logits/chosen": -1.2839118242263794,
      "logits/rejected": -1.121405839920044,
      "logps/chosen": -191.18984985351562,
      "logps/rejected": -173.59817504882812,
      "loss": 0.2771,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.0043420791625977,
      "rewards/margins": 2.8076000213623047,
      "rewards/rejected": -4.811942100524902,
      "step": 15560
    },
    {
      "epoch": 2.8415001368738024,
      "grad_norm": 5.233419895172119,
      "learning_rate": 4.302818198563272e-06,
      "logits/chosen": -1.2125012874603271,
      "logits/rejected": -1.130915641784668,
      "logps/chosen": -169.71099853515625,
      "logps/rejected": -188.47720336914062,
      "loss": 0.2218,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.371499538421631,
      "rewards/margins": 2.91849684715271,
      "rewards/rejected": -5.289996147155762,
      "step": 15570
    },
    {
      "epoch": 2.843325120905192,
      "grad_norm": 4.08651065826416,
      "learning_rate": 4.253699269355928e-06,
      "logits/chosen": -1.2240546941757202,
      "logits/rejected": -1.1649534702301025,
      "logps/chosen": -169.57945251464844,
      "logps/rejected": -193.74624633789062,
      "loss": 0.4026,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.2084200382232666,
      "rewards/margins": 2.7560486793518066,
      "rewards/rejected": -4.964468002319336,
      "step": 15580
    },
    {
      "epoch": 2.845150104936582,
      "grad_norm": 1.418458104133606,
      "learning_rate": 4.2045803401485855e-06,
      "logits/chosen": -1.2341837882995605,
      "logits/rejected": -1.1426249742507935,
      "logps/chosen": -178.36602783203125,
      "logps/rejected": -179.8610076904297,
      "loss": 0.3486,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.337998867034912,
      "rewards/margins": 3.001659631729126,
      "rewards/rejected": -5.339657783508301,
      "step": 15590
    },
    {
      "epoch": 2.8469750889679717,
      "grad_norm": 7.314812183380127,
      "learning_rate": 4.1554614109412415e-06,
      "logits/chosen": -1.2146438360214233,
      "logits/rejected": -1.0765539407730103,
      "logps/chosen": -177.74118041992188,
      "logps/rejected": -168.52554321289062,
      "loss": 0.4477,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.4711790084838867,
      "rewards/margins": 2.628701686859131,
      "rewards/rejected": -5.099880695343018,
      "step": 15600
    },
    {
      "epoch": 2.848800072999361,
      "grad_norm": 4.622859954833984,
      "learning_rate": 4.106342481733898e-06,
      "logits/chosen": -1.2479779720306396,
      "logits/rejected": -1.1701501607894897,
      "logps/chosen": -181.21865844726562,
      "logps/rejected": -200.164306640625,
      "loss": 0.3364,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.5099902153015137,
      "rewards/margins": 2.614417552947998,
      "rewards/rejected": -5.124407768249512,
      "step": 15610
    },
    {
      "epoch": 2.8506250570307508,
      "grad_norm": 9.0028715133667,
      "learning_rate": 4.057223552526555e-06,
      "logits/chosen": -1.1608555316925049,
      "logits/rejected": -1.1485586166381836,
      "logps/chosen": -155.83523559570312,
      "logps/rejected": -174.382568359375,
      "loss": 0.3546,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.595695972442627,
      "rewards/margins": 2.2953927516937256,
      "rewards/rejected": -4.891088962554932,
      "step": 15620
    },
    {
      "epoch": 2.8524500410621405,
      "grad_norm": 11.047014236450195,
      "learning_rate": 4.008104623319212e-06,
      "logits/chosen": -1.190941333770752,
      "logits/rejected": -1.1044762134552002,
      "logps/chosen": -178.1960906982422,
      "logps/rejected": -182.59829711914062,
      "loss": 0.2804,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.260857105255127,
      "rewards/margins": 2.841555118560791,
      "rewards/rejected": -5.102412223815918,
      "step": 15630
    },
    {
      "epoch": 2.8542750250935303,
      "grad_norm": 7.961071491241455,
      "learning_rate": 3.958985694111869e-06,
      "logits/chosen": -1.1699155569076538,
      "logits/rejected": -1.1147133111953735,
      "logps/chosen": -155.90908813476562,
      "logps/rejected": -164.38754272460938,
      "loss": 0.3496,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.3053667545318604,
      "rewards/margins": 2.3552021980285645,
      "rewards/rejected": -4.660568714141846,
      "step": 15640
    },
    {
      "epoch": 2.85610000912492,
      "grad_norm": 4.7927446365356445,
      "learning_rate": 3.909866764904525e-06,
      "logits/chosen": -1.2284033298492432,
      "logits/rejected": -1.1313703060150146,
      "logps/chosen": -167.46920776367188,
      "logps/rejected": -173.69407653808594,
      "loss": 0.1819,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.3755784034729004,
      "rewards/margins": 3.122408866882324,
      "rewards/rejected": -5.497986793518066,
      "step": 15650
    },
    {
      "epoch": 2.8579249931563098,
      "grad_norm": 3.635226249694824,
      "learning_rate": 3.860747835697182e-06,
      "logits/chosen": -1.2006601095199585,
      "logits/rejected": -1.1319698095321655,
      "logps/chosen": -164.77651977539062,
      "logps/rejected": -168.89755249023438,
      "loss": 0.3637,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.5716798305511475,
      "rewards/margins": 2.639371395111084,
      "rewards/rejected": -5.211050987243652,
      "step": 15660
    },
    {
      "epoch": 2.8597499771876995,
      "grad_norm": 3.7470755577087402,
      "learning_rate": 3.811628906489839e-06,
      "logits/chosen": -1.2284027338027954,
      "logits/rejected": -1.1289353370666504,
      "logps/chosen": -201.7112274169922,
      "logps/rejected": -193.9446258544922,
      "loss": 0.2995,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.748131275177002,
      "rewards/margins": 2.5941522121429443,
      "rewards/rejected": -5.342283248901367,
      "step": 15670
    },
    {
      "epoch": 2.8615749612190893,
      "grad_norm": 5.684726715087891,
      "learning_rate": 3.7625099772824957e-06,
      "logits/chosen": -1.179410696029663,
      "logits/rejected": -1.1312801837921143,
      "logps/chosen": -181.75625610351562,
      "logps/rejected": -186.3247833251953,
      "loss": 0.3275,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.1971354484558105,
      "rewards/margins": 2.4033355712890625,
      "rewards/rejected": -4.600470542907715,
      "step": 15680
    },
    {
      "epoch": 2.863399945250479,
      "grad_norm": 14.69771671295166,
      "learning_rate": 3.713391048075152e-06,
      "logits/chosen": -1.1879173517227173,
      "logits/rejected": -1.1763970851898193,
      "logps/chosen": -147.23483276367188,
      "logps/rejected": -182.2421875,
      "loss": 0.3715,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.0712921619415283,
      "rewards/margins": 2.597984552383423,
      "rewards/rejected": -4.669277191162109,
      "step": 15690
    },
    {
      "epoch": 2.865224929281869,
      "grad_norm": 6.7859578132629395,
      "learning_rate": 3.6642721188678086e-06,
      "logits/chosen": -1.2002451419830322,
      "logits/rejected": -1.173814058303833,
      "logps/chosen": -163.09564208984375,
      "logps/rejected": -182.21353149414062,
      "loss": 0.3581,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.165245532989502,
      "rewards/margins": 2.6175076961517334,
      "rewards/rejected": -4.7827534675598145,
      "step": 15700
    },
    {
      "epoch": 2.8670499133132585,
      "grad_norm": 7.765160083770752,
      "learning_rate": 3.615153189660466e-06,
      "logits/chosen": -1.2504589557647705,
      "logits/rejected": -1.1147245168685913,
      "logps/chosen": -174.52777099609375,
      "logps/rejected": -172.5205841064453,
      "loss": 0.2597,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9029567241668701,
      "rewards/margins": 2.734631061553955,
      "rewards/rejected": -4.637587547302246,
      "step": 15710
    },
    {
      "epoch": 2.8688748973446483,
      "grad_norm": 1.5218969583511353,
      "learning_rate": 3.5660342604531224e-06,
      "logits/chosen": -1.199105143547058,
      "logits/rejected": -1.143666386604309,
      "logps/chosen": -138.25601196289062,
      "logps/rejected": -172.50144958496094,
      "loss": 0.2346,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.1339526176452637,
      "rewards/margins": 3.0781683921813965,
      "rewards/rejected": -5.21212100982666,
      "step": 15720
    },
    {
      "epoch": 2.870699881376038,
      "grad_norm": 7.217804431915283,
      "learning_rate": 3.5169153312457793e-06,
      "logits/chosen": -1.2760920524597168,
      "logits/rejected": -1.1629266738891602,
      "logps/chosen": -163.29417419433594,
      "logps/rejected": -173.2860107421875,
      "loss": 0.4588,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.0008046627044678,
      "rewards/margins": 2.3730533123016357,
      "rewards/rejected": -4.373858451843262,
      "step": 15730
    },
    {
      "epoch": 2.872524865407428,
      "grad_norm": 7.664208889007568,
      "learning_rate": 3.4677964020384357e-06,
      "logits/chosen": -1.2191474437713623,
      "logits/rejected": -1.1481379270553589,
      "logps/chosen": -174.65744018554688,
      "logps/rejected": -174.0924072265625,
      "loss": 0.3772,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.184534788131714,
      "rewards/margins": 2.490710973739624,
      "rewards/rejected": -4.675245761871338,
      "step": 15740
    },
    {
      "epoch": 2.8743498494388176,
      "grad_norm": 7.108610153198242,
      "learning_rate": 3.418677472831092e-06,
      "logits/chosen": -1.2152974605560303,
      "logits/rejected": -1.1350117921829224,
      "logps/chosen": -178.41929626464844,
      "logps/rejected": -185.54373168945312,
      "loss": 0.2357,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.3701608180999756,
      "rewards/margins": 2.7939696311950684,
      "rewards/rejected": -5.164130687713623,
      "step": 15750
    },
    {
      "epoch": 2.8761748334702073,
      "grad_norm": 6.029624938964844,
      "learning_rate": 3.3695585436237495e-06,
      "logits/chosen": -1.2552955150604248,
      "logits/rejected": -1.1553146839141846,
      "logps/chosen": -192.81613159179688,
      "logps/rejected": -191.32049560546875,
      "loss": 0.2855,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.7221341133117676,
      "rewards/margins": 2.6129372119903564,
      "rewards/rejected": -5.335071086883545,
      "step": 15760
    },
    {
      "epoch": 2.877999817501597,
      "grad_norm": 3.462312698364258,
      "learning_rate": 3.320439614416406e-06,
      "logits/chosen": -1.1774415969848633,
      "logits/rejected": -1.1422059535980225,
      "logps/chosen": -159.6560821533203,
      "logps/rejected": -182.0154266357422,
      "loss": 0.3899,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.3683459758758545,
      "rewards/margins": 2.3201749324798584,
      "rewards/rejected": -4.688520908355713,
      "step": 15770
    },
    {
      "epoch": 2.879824801532987,
      "grad_norm": 6.078873157501221,
      "learning_rate": 3.271320685209063e-06,
      "logits/chosen": -1.2306678295135498,
      "logits/rejected": -1.1785354614257812,
      "logps/chosen": -164.30401611328125,
      "logps/rejected": -179.4267120361328,
      "loss": 0.2736,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.1699538230895996,
      "rewards/margins": 2.4031167030334473,
      "rewards/rejected": -4.573070526123047,
      "step": 15780
    },
    {
      "epoch": 2.8816497855643766,
      "grad_norm": 4.451816082000732,
      "learning_rate": 3.2222017560017193e-06,
      "logits/chosen": -1.2359156608581543,
      "logits/rejected": -1.0977904796600342,
      "logps/chosen": -178.86720275878906,
      "logps/rejected": -157.40835571289062,
      "loss": 0.3816,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.185515880584717,
      "rewards/margins": 2.4242842197418213,
      "rewards/rejected": -4.609800338745117,
      "step": 15790
    },
    {
      "epoch": 2.883474769595766,
      "grad_norm": 8.58523941040039,
      "learning_rate": 3.173082826794376e-06,
      "logits/chosen": -1.1778600215911865,
      "logits/rejected": -1.1239616870880127,
      "logps/chosen": -167.32337951660156,
      "logps/rejected": -178.71263122558594,
      "loss": 0.3172,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.339226245880127,
      "rewards/margins": 2.6915266513824463,
      "rewards/rejected": -5.030753135681152,
      "step": 15800
    },
    {
      "epoch": 2.8852997536271556,
      "grad_norm": 12.888277053833008,
      "learning_rate": 3.123963897587033e-06,
      "logits/chosen": -1.2043207883834839,
      "logits/rejected": -1.1242761611938477,
      "logps/chosen": -162.06597900390625,
      "logps/rejected": -170.8453826904297,
      "loss": 0.3562,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4780433177948,
      "rewards/margins": 2.01971435546875,
      "rewards/rejected": -4.497757911682129,
      "step": 15810
    },
    {
      "epoch": 2.8871247376585454,
      "grad_norm": 6.881036758422852,
      "learning_rate": 3.0748449683796896e-06,
      "logits/chosen": -1.163040280342102,
      "logits/rejected": -1.1126744747161865,
      "logps/chosen": -163.3054962158203,
      "logps/rejected": -190.76705932617188,
      "loss": 0.2218,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.720485210418701,
      "rewards/margins": 2.769198417663574,
      "rewards/rejected": -5.489683628082275,
      "step": 15820
    },
    {
      "epoch": 2.888949721689935,
      "grad_norm": 5.145195007324219,
      "learning_rate": 3.0257260391723464e-06,
      "logits/chosen": -1.2193090915679932,
      "logits/rejected": -1.1478272676467896,
      "logps/chosen": -186.40228271484375,
      "logps/rejected": -177.8883514404297,
      "loss": 0.2905,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.2826294898986816,
      "rewards/margins": 2.7599844932556152,
      "rewards/rejected": -5.042613983154297,
      "step": 15830
    },
    {
      "epoch": 2.890774705721325,
      "grad_norm": 5.737225532531738,
      "learning_rate": 2.976607109965003e-06,
      "logits/chosen": -1.2395007610321045,
      "logits/rejected": -1.1850056648254395,
      "logps/chosen": -162.99000549316406,
      "logps/rejected": -183.9017333984375,
      "loss": 0.2971,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.659546375274658,
      "rewards/margins": 2.498216390609741,
      "rewards/rejected": -5.1577630043029785,
      "step": 15840
    },
    {
      "epoch": 2.8925996897527146,
      "grad_norm": 6.145173072814941,
      "learning_rate": 2.9274881807576598e-06,
      "logits/chosen": -1.1878058910369873,
      "logits/rejected": -1.1056091785430908,
      "logps/chosen": -170.33419799804688,
      "logps/rejected": -180.28549194335938,
      "loss": 0.3021,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.525470018386841,
      "rewards/margins": 2.6598615646362305,
      "rewards/rejected": -5.185332298278809,
      "step": 15850
    },
    {
      "epoch": 2.8944246737841044,
      "grad_norm": 10.146979331970215,
      "learning_rate": 2.8783692515503162e-06,
      "logits/chosen": -1.1854631900787354,
      "logits/rejected": -1.1491270065307617,
      "logps/chosen": -146.93399047851562,
      "logps/rejected": -172.9346160888672,
      "loss": 0.2823,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.276621103286743,
      "rewards/margins": 2.619614839553833,
      "rewards/rejected": -4.896235466003418,
      "step": 15860
    },
    {
      "epoch": 2.896249657815494,
      "grad_norm": 3.574517250061035,
      "learning_rate": 2.829250322342973e-06,
      "logits/chosen": -1.1648913621902466,
      "logits/rejected": -1.0770303010940552,
      "logps/chosen": -176.2918243408203,
      "logps/rejected": -166.4762725830078,
      "loss": 0.2966,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.263355255126953,
      "rewards/margins": 2.548323631286621,
      "rewards/rejected": -4.811678409576416,
      "step": 15870
    },
    {
      "epoch": 2.898074641846884,
      "grad_norm": 7.523565292358398,
      "learning_rate": 2.78013139313563e-06,
      "logits/chosen": -1.197319746017456,
      "logits/rejected": -1.092483639717102,
      "logps/chosen": -184.42990112304688,
      "logps/rejected": -176.65780639648438,
      "loss": 0.2976,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.4621191024780273,
      "rewards/margins": 2.647709608078003,
      "rewards/rejected": -5.109828948974609,
      "step": 15880
    },
    {
      "epoch": 2.8998996258782737,
      "grad_norm": 6.562533855438232,
      "learning_rate": 2.7310124639282865e-06,
      "logits/chosen": -1.1627126932144165,
      "logits/rejected": -1.1543858051300049,
      "logps/chosen": -147.9539337158203,
      "logps/rejected": -181.18093872070312,
      "loss": 0.2891,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.645237445831299,
      "rewards/margins": 2.7371115684509277,
      "rewards/rejected": -5.382349014282227,
      "step": 15890
    },
    {
      "epoch": 2.9017246099096634,
      "grad_norm": 6.936804294586182,
      "learning_rate": 2.6818935347209434e-06,
      "logits/chosen": -1.2157233953475952,
      "logits/rejected": -1.1507999897003174,
      "logps/chosen": -171.41134643554688,
      "logps/rejected": -178.63516235351562,
      "loss": 0.2487,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.215928077697754,
      "rewards/margins": 2.549588441848755,
      "rewards/rejected": -4.7655158042907715,
      "step": 15900
    },
    {
      "epoch": 2.903549593941053,
      "grad_norm": 1.5815061330795288,
      "learning_rate": 2.6327746055136e-06,
      "logits/chosen": -1.2021644115447998,
      "logits/rejected": -1.1407365798950195,
      "logps/chosen": -175.74195861816406,
      "logps/rejected": -183.58041381835938,
      "loss": 0.2314,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.661484956741333,
      "rewards/margins": 2.7253315448760986,
      "rewards/rejected": -5.38681697845459,
      "step": 15910
    },
    {
      "epoch": 2.9053745779724425,
      "grad_norm": 6.286468505859375,
      "learning_rate": 2.5836556763062563e-06,
      "logits/chosen": -1.1719950437545776,
      "logits/rejected": -1.127049446105957,
      "logps/chosen": -167.66830444335938,
      "logps/rejected": -188.4927215576172,
      "loss": 0.2182,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.154554605484009,
      "rewards/margins": 2.897768974304199,
      "rewards/rejected": -5.052323818206787,
      "step": 15920
    },
    {
      "epoch": 2.9071995620038322,
      "grad_norm": 6.450213432312012,
      "learning_rate": 2.5345367470989136e-06,
      "logits/chosen": -1.2496824264526367,
      "logits/rejected": -1.1691343784332275,
      "logps/chosen": -184.4458465576172,
      "logps/rejected": -196.03567504882812,
      "loss": 0.3295,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.193988084793091,
      "rewards/margins": 2.8337931632995605,
      "rewards/rejected": -5.0277814865112305,
      "step": 15930
    },
    {
      "epoch": 2.909024546035222,
      "grad_norm": 8.683292388916016,
      "learning_rate": 2.4854178178915705e-06,
      "logits/chosen": -1.1902010440826416,
      "logits/rejected": -1.0901246070861816,
      "logps/chosen": -175.08843994140625,
      "logps/rejected": -181.25938415527344,
      "loss": 0.2813,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.6900410652160645,
      "rewards/margins": 2.796144962310791,
      "rewards/rejected": -5.4861860275268555,
      "step": 15940
    },
    {
      "epoch": 2.9108495300666117,
      "grad_norm": 6.646076202392578,
      "learning_rate": 2.436298888684227e-06,
      "logits/chosen": -1.2104467153549194,
      "logits/rejected": -1.0870280265808105,
      "logps/chosen": -193.38328552246094,
      "logps/rejected": -194.13156127929688,
      "loss": 0.2296,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.6825613975524902,
      "rewards/margins": 2.9583802223205566,
      "rewards/rejected": -5.640941619873047,
      "step": 15950
    },
    {
      "epoch": 2.9126745140980015,
      "grad_norm": 0.5039741396903992,
      "learning_rate": 2.3871799594768834e-06,
      "logits/chosen": -1.192812442779541,
      "logits/rejected": -1.104339599609375,
      "logps/chosen": -165.70587158203125,
      "logps/rejected": -172.58364868164062,
      "loss": 0.4281,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.2551722526550293,
      "rewards/margins": 2.412351131439209,
      "rewards/rejected": -4.667523384094238,
      "step": 15960
    },
    {
      "epoch": 2.9144994981293912,
      "grad_norm": 11.460220336914062,
      "learning_rate": 2.3380610302695403e-06,
      "logits/chosen": -1.2107765674591064,
      "logits/rejected": -1.1262707710266113,
      "logps/chosen": -173.85360717773438,
      "logps/rejected": -172.02476501464844,
      "loss": 0.3657,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.653114080429077,
      "rewards/margins": 2.450759172439575,
      "rewards/rejected": -5.103873252868652,
      "step": 15970
    },
    {
      "epoch": 2.916324482160781,
      "grad_norm": 5.691044807434082,
      "learning_rate": 2.288942101062197e-06,
      "logits/chosen": -1.1793512105941772,
      "logits/rejected": -1.1162992715835571,
      "logps/chosen": -158.35935974121094,
      "logps/rejected": -174.96530151367188,
      "loss": 0.4124,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.3657233715057373,
      "rewards/margins": 2.741443157196045,
      "rewards/rejected": -5.107166290283203,
      "step": 15980
    },
    {
      "epoch": 2.9181494661921707,
      "grad_norm": 9.830245971679688,
      "learning_rate": 2.2398231718548536e-06,
      "logits/chosen": -1.1719615459442139,
      "logits/rejected": -1.1097042560577393,
      "logps/chosen": -168.48361206054688,
      "logps/rejected": -183.9514923095703,
      "loss": 0.352,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.1800758838653564,
      "rewards/margins": 2.582681179046631,
      "rewards/rejected": -4.762757301330566,
      "step": 15990
    },
    {
      "epoch": 2.9199744502235605,
      "grad_norm": 5.405372619628906,
      "learning_rate": 2.1907042426475105e-06,
      "logits/chosen": -1.2191636562347412,
      "logits/rejected": -1.1360422372817993,
      "logps/chosen": -176.3953094482422,
      "logps/rejected": -188.42739868164062,
      "loss": 0.276,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.3072993755340576,
      "rewards/margins": 2.7483468055725098,
      "rewards/rejected": -5.0556464195251465,
      "step": 16000
    },
    {
      "epoch": 2.9217994342549503,
      "grad_norm": 5.665988922119141,
      "learning_rate": 2.141585313440167e-06,
      "logits/chosen": -1.2103506326675415,
      "logits/rejected": -1.1121586561203003,
      "logps/chosen": -143.6016387939453,
      "logps/rejected": -146.0348663330078,
      "loss": 0.3057,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.2320926189422607,
      "rewards/margins": 2.607297420501709,
      "rewards/rejected": -4.839390754699707,
      "step": 16010
    },
    {
      "epoch": 2.92362441828634,
      "grad_norm": 2.7470791339874268,
      "learning_rate": 2.092466384232824e-06,
      "logits/chosen": -1.1980196237564087,
      "logits/rejected": -1.138839602470398,
      "logps/chosen": -165.75498962402344,
      "logps/rejected": -166.37022399902344,
      "loss": 0.2937,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1926989555358887,
      "rewards/margins": 2.750668525695801,
      "rewards/rejected": -4.943367004394531,
      "step": 16020
    },
    {
      "epoch": 2.9254494023177298,
      "grad_norm": 9.161888122558594,
      "learning_rate": 2.0433474550254807e-06,
      "logits/chosen": -1.2127630710601807,
      "logits/rejected": -1.10404372215271,
      "logps/chosen": -173.56752014160156,
      "logps/rejected": -171.7680206298828,
      "loss": 0.3845,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.6375837326049805,
      "rewards/margins": 2.478639602661133,
      "rewards/rejected": -5.116223335266113,
      "step": 16030
    },
    {
      "epoch": 2.9272743863491195,
      "grad_norm": 9.139731407165527,
      "learning_rate": 1.994228525818137e-06,
      "logits/chosen": -1.2127456665039062,
      "logits/rejected": -1.1291553974151611,
      "logps/chosen": -160.65768432617188,
      "logps/rejected": -171.03384399414062,
      "loss": 0.2863,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1819562911987305,
      "rewards/margins": 2.621628999710083,
      "rewards/rejected": -4.803585529327393,
      "step": 16040
    },
    {
      "epoch": 2.9290993703805093,
      "grad_norm": 5.213476181030273,
      "learning_rate": 1.945109596610794e-06,
      "logits/chosen": -1.218180775642395,
      "logits/rejected": -1.1405627727508545,
      "logps/chosen": -180.88624572753906,
      "logps/rejected": -193.3065643310547,
      "loss": 0.2522,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.291322946548462,
      "rewards/margins": 2.5469584465026855,
      "rewards/rejected": -4.838282585144043,
      "step": 16050
    },
    {
      "epoch": 2.930924354411899,
      "grad_norm": 7.620696067810059,
      "learning_rate": 1.895990667403451e-06,
      "logits/chosen": -1.1443023681640625,
      "logits/rejected": -1.0977846384048462,
      "logps/chosen": -177.21292114257812,
      "logps/rejected": -180.91403198242188,
      "loss": 0.309,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.3630919456481934,
      "rewards/margins": 2.6453616619110107,
      "rewards/rejected": -5.008453845977783,
      "step": 16060
    },
    {
      "epoch": 2.932749338443289,
      "grad_norm": 7.91791296005249,
      "learning_rate": 1.8468717381961074e-06,
      "logits/chosen": -1.219528317451477,
      "logits/rejected": -1.1228913068771362,
      "logps/chosen": -173.60842895507812,
      "logps/rejected": -170.19540405273438,
      "loss": 0.3891,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.2563977241516113,
      "rewards/margins": 2.228355884552002,
      "rewards/rejected": -4.484753608703613,
      "step": 16070
    },
    {
      "epoch": 2.9345743224746785,
      "grad_norm": 6.793276309967041,
      "learning_rate": 1.797752808988764e-06,
      "logits/chosen": -1.2144381999969482,
      "logits/rejected": -1.0956023931503296,
      "logps/chosen": -175.3740234375,
      "logps/rejected": -163.46322631835938,
      "loss": 0.2796,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.086402177810669,
      "rewards/margins": 2.75764799118042,
      "rewards/rejected": -4.844050407409668,
      "step": 16080
    },
    {
      "epoch": 2.9363993065060683,
      "grad_norm": 6.6794843673706055,
      "learning_rate": 1.748633879781421e-06,
      "logits/chosen": -1.2004114389419556,
      "logits/rejected": -1.1189861297607422,
      "logps/chosen": -159.92593383789062,
      "logps/rejected": -169.39218139648438,
      "loss": 0.3218,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.198978900909424,
      "rewards/margins": 2.532261610031128,
      "rewards/rejected": -4.731240272521973,
      "step": 16090
    },
    {
      "epoch": 2.938224290537458,
      "grad_norm": 4.369378566741943,
      "learning_rate": 1.6995149505740777e-06,
      "logits/chosen": -1.2484710216522217,
      "logits/rejected": -1.1308788061141968,
      "logps/chosen": -174.2169647216797,
      "logps/rejected": -165.32046508789062,
      "loss": 0.2824,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.7299790382385254,
      "rewards/margins": 2.3021798133850098,
      "rewards/rejected": -5.032158851623535,
      "step": 16100
    },
    {
      "epoch": 2.940049274568848,
      "grad_norm": 9.638741493225098,
      "learning_rate": 1.6503960213667345e-06,
      "logits/chosen": -1.2491123676300049,
      "logits/rejected": -1.132244348526001,
      "logps/chosen": -174.61434936523438,
      "logps/rejected": -178.1377410888672,
      "loss": 0.2322,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8422425985336304,
      "rewards/margins": 2.9984169006347656,
      "rewards/rejected": -4.8406596183776855,
      "step": 16110
    },
    {
      "epoch": 2.941874258600237,
      "grad_norm": 4.277339935302734,
      "learning_rate": 1.601277092159391e-06,
      "logits/chosen": -1.1747581958770752,
      "logits/rejected": -1.110199213027954,
      "logps/chosen": -186.4369354248047,
      "logps/rejected": -186.97555541992188,
      "loss": 0.3163,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.590237855911255,
      "rewards/margins": 2.468881130218506,
      "rewards/rejected": -5.059118270874023,
      "step": 16120
    },
    {
      "epoch": 2.943699242631627,
      "grad_norm": 6.915108680725098,
      "learning_rate": 1.5521581629520477e-06,
      "logits/chosen": -1.1956084966659546,
      "logits/rejected": -1.111344337463379,
      "logps/chosen": -167.25808715820312,
      "logps/rejected": -169.77200317382812,
      "loss": 0.3453,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.136715888977051,
      "rewards/margins": 2.4846200942993164,
      "rewards/rejected": -4.621335506439209,
      "step": 16130
    },
    {
      "epoch": 2.9455242266630166,
      "grad_norm": 9.456753730773926,
      "learning_rate": 1.5030392337447046e-06,
      "logits/chosen": -1.2130275964736938,
      "logits/rejected": -1.0687239170074463,
      "logps/chosen": -197.7381134033203,
      "logps/rejected": -174.7478790283203,
      "loss": 0.3,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.0653693675994873,
      "rewards/margins": 2.6746902465820312,
      "rewards/rejected": -4.7400593757629395,
      "step": 16140
    },
    {
      "epoch": 2.9473492106944064,
      "grad_norm": 7.977790355682373,
      "learning_rate": 1.4539203045373612e-06,
      "logits/chosen": -1.2464733123779297,
      "logits/rejected": -1.1529812812805176,
      "logps/chosen": -167.718017578125,
      "logps/rejected": -167.9443817138672,
      "loss": 0.3652,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.7094998359680176,
      "rewards/margins": 2.3636772632598877,
      "rewards/rejected": -5.073177337646484,
      "step": 16150
    },
    {
      "epoch": 2.949174194725796,
      "grad_norm": 4.171037673950195,
      "learning_rate": 1.404801375330018e-06,
      "logits/chosen": -1.1740068197250366,
      "logits/rejected": -1.0829218626022339,
      "logps/chosen": -165.62307739257812,
      "logps/rejected": -166.42393493652344,
      "loss": 0.2679,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.5016703605651855,
      "rewards/margins": 2.407928943634033,
      "rewards/rejected": -4.909599304199219,
      "step": 16160
    },
    {
      "epoch": 2.950999178757186,
      "grad_norm": 11.55794620513916,
      "learning_rate": 1.3556824461226748e-06,
      "logits/chosen": -1.2198827266693115,
      "logits/rejected": -1.1141624450683594,
      "logps/chosen": -181.92593383789062,
      "logps/rejected": -179.79586791992188,
      "loss": 0.4367,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.3397388458251953,
      "rewards/margins": 2.4951260089874268,
      "rewards/rejected": -4.834864139556885,
      "step": 16170
    },
    {
      "epoch": 2.9528241627885756,
      "grad_norm": 10.607462882995605,
      "learning_rate": 1.3065635169153312e-06,
      "logits/chosen": -1.2608712911605835,
      "logits/rejected": -1.16930091381073,
      "logps/chosen": -170.297119140625,
      "logps/rejected": -178.29379272460938,
      "loss": 0.2502,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.8939311504364014,
      "rewards/margins": 2.939507007598877,
      "rewards/rejected": -4.833437919616699,
      "step": 16180
    },
    {
      "epoch": 2.9546491468199654,
      "grad_norm": 8.385120391845703,
      "learning_rate": 1.257444587707988e-06,
      "logits/chosen": -1.226851224899292,
      "logits/rejected": -1.169649362564087,
      "logps/chosen": -172.8263702392578,
      "logps/rejected": -180.52745056152344,
      "loss": 0.3077,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.0503859519958496,
      "rewards/margins": 2.7377519607543945,
      "rewards/rejected": -4.788138389587402,
      "step": 16190
    },
    {
      "epoch": 2.956474130851355,
      "grad_norm": 7.745423316955566,
      "learning_rate": 1.2083256585006448e-06,
      "logits/chosen": -1.1775166988372803,
      "logits/rejected": -1.1421568393707275,
      "logps/chosen": -168.13912963867188,
      "logps/rejected": -187.7872314453125,
      "loss": 0.287,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.3484396934509277,
      "rewards/margins": 2.678493022918701,
      "rewards/rejected": -5.026932716369629,
      "step": 16200
    },
    {
      "epoch": 2.958299114882745,
      "grad_norm": 9.197589874267578,
      "learning_rate": 1.1592067292933015e-06,
      "logits/chosen": -1.1977198123931885,
      "logits/rejected": -1.1428635120391846,
      "logps/chosen": -167.94821166992188,
      "logps/rejected": -178.40135192871094,
      "loss": 0.4074,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4413654804229736,
      "rewards/margins": 2.2416865825653076,
      "rewards/rejected": -4.683052062988281,
      "step": 16210
    },
    {
      "epoch": 2.9601240989141346,
      "grad_norm": 11.949169158935547,
      "learning_rate": 1.1100878000859581e-06,
      "logits/chosen": -1.2142179012298584,
      "logits/rejected": -1.171596884727478,
      "logps/chosen": -164.1178436279297,
      "logps/rejected": -178.69003295898438,
      "loss": 0.304,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1305384635925293,
      "rewards/margins": 2.321887254714966,
      "rewards/rejected": -4.452425479888916,
      "step": 16220
    },
    {
      "epoch": 2.9619490829455244,
      "grad_norm": 6.981466770172119,
      "learning_rate": 1.0609688708786148e-06,
      "logits/chosen": -1.2292379140853882,
      "logits/rejected": -1.1583210229873657,
      "logps/chosen": -167.0192108154297,
      "logps/rejected": -175.83033752441406,
      "loss": 0.3567,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8663631677627563,
      "rewards/margins": 2.7500414848327637,
      "rewards/rejected": -4.6164045333862305,
      "step": 16230
    },
    {
      "epoch": 2.9637740669769137,
      "grad_norm": 3.1767568588256836,
      "learning_rate": 1.0118499416712717e-06,
      "logits/chosen": -1.2113640308380127,
      "logits/rejected": -1.1527925729751587,
      "logps/chosen": -177.08380126953125,
      "logps/rejected": -189.37155151367188,
      "loss": 0.3221,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.496135711669922,
      "rewards/margins": 2.3036155700683594,
      "rewards/rejected": -4.799751281738281,
      "step": 16240
    },
    {
      "epoch": 2.9655990510083035,
      "grad_norm": 3.67502760887146,
      "learning_rate": 9.627310124639284e-07,
      "logits/chosen": -1.1728966236114502,
      "logits/rejected": -1.1074495315551758,
      "logps/chosen": -163.0431365966797,
      "logps/rejected": -170.70925903320312,
      "loss": 0.2851,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.430988311767578,
      "rewards/margins": 2.219616174697876,
      "rewards/rejected": -4.650604248046875,
      "step": 16250
    },
    {
      "epoch": 2.967424035039693,
      "grad_norm": 4.58963680267334,
      "learning_rate": 9.13612083256585e-07,
      "logits/chosen": -1.2001460790634155,
      "logits/rejected": -1.1345765590667725,
      "logps/chosen": -166.7411651611328,
      "logps/rejected": -171.89651489257812,
      "loss": 0.345,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.627863883972168,
      "rewards/margins": 2.2710068225860596,
      "rewards/rejected": -4.898870468139648,
      "step": 16260
    },
    {
      "epoch": 2.969249019071083,
      "grad_norm": 4.5333662033081055,
      "learning_rate": 8.644931540492418e-07,
      "logits/chosen": -1.2153338193893433,
      "logits/rejected": -1.1241977214813232,
      "logps/chosen": -163.33163452148438,
      "logps/rejected": -170.97789001464844,
      "loss": 0.2961,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9209716320037842,
      "rewards/margins": 2.4914698600769043,
      "rewards/rejected": -4.412442207336426,
      "step": 16270
    },
    {
      "epoch": 2.9710740031024727,
      "grad_norm": 7.859582901000977,
      "learning_rate": 8.153742248418985e-07,
      "logits/chosen": -1.1679422855377197,
      "logits/rejected": -1.163859486579895,
      "logps/chosen": -158.5687255859375,
      "logps/rejected": -185.8282470703125,
      "loss": 0.3946,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.784238576889038,
      "rewards/margins": 2.0694942474365234,
      "rewards/rejected": -4.853732585906982,
      "step": 16280
    },
    {
      "epoch": 2.9728989871338625,
      "grad_norm": 3.3579907417297363,
      "learning_rate": 7.662552956345553e-07,
      "logits/chosen": -1.2083975076675415,
      "logits/rejected": -1.1478378772735596,
      "logps/chosen": -157.88925170898438,
      "logps/rejected": -171.41787719726562,
      "loss": 0.4011,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.157339572906494,
      "rewards/margins": 2.415951728820801,
      "rewards/rejected": -4.573290824890137,
      "step": 16290
    },
    {
      "epoch": 2.9747239711652522,
      "grad_norm": 1.8412076234817505,
      "learning_rate": 7.171363664272119e-07,
      "logits/chosen": -1.1958608627319336,
      "logits/rejected": -1.0833910703659058,
      "logps/chosen": -169.58340454101562,
      "logps/rejected": -170.8647003173828,
      "loss": 0.3034,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.8806625604629517,
      "rewards/margins": 2.6976001262664795,
      "rewards/rejected": -4.578263282775879,
      "step": 16300
    },
    {
      "epoch": 2.976548955196642,
      "grad_norm": 7.441414833068848,
      "learning_rate": 6.680174372198686e-07,
      "logits/chosen": -1.179919958114624,
      "logits/rejected": -1.0926332473754883,
      "logps/chosen": -171.27174377441406,
      "logps/rejected": -171.65611267089844,
      "loss": 0.3346,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.0286731719970703,
      "rewards/margins": 2.5042765140533447,
      "rewards/rejected": -5.532949447631836,
      "step": 16310
    },
    {
      "epoch": 2.9783739392280317,
      "grad_norm": 4.119358062744141,
      "learning_rate": 6.188985080125254e-07,
      "logits/chosen": -1.1715688705444336,
      "logits/rejected": -1.1349668502807617,
      "logps/chosen": -172.77471923828125,
      "logps/rejected": -181.50326538085938,
      "loss": 0.3456,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.0903677940368652,
      "rewards/margins": 2.327087640762329,
      "rewards/rejected": -4.417455196380615,
      "step": 16320
    },
    {
      "epoch": 2.9801989232594215,
      "grad_norm": 6.939027309417725,
      "learning_rate": 5.697795788051821e-07,
      "logits/chosen": -1.2119840383529663,
      "logits/rejected": -1.1089056730270386,
      "logps/chosen": -175.03384399414062,
      "logps/rejected": -182.54347229003906,
      "loss": 0.1911,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.547963857650757,
      "rewards/margins": 3.060445785522461,
      "rewards/rejected": -5.608409881591797,
      "step": 16330
    },
    {
      "epoch": 2.9820239072908112,
      "grad_norm": 1.7253886461257935,
      "learning_rate": 5.206606495978388e-07,
      "logits/chosen": -1.1530455350875854,
      "logits/rejected": -1.0999581813812256,
      "logps/chosen": -163.8236083984375,
      "logps/rejected": -171.546630859375,
      "loss": 0.2632,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.1496620178222656,
      "rewards/margins": 3.0533809661865234,
      "rewards/rejected": -5.203042984008789,
      "step": 16340
    },
    {
      "epoch": 2.983848891322201,
      "grad_norm": 6.589807510375977,
      "learning_rate": 4.715417203904955e-07,
      "logits/chosen": -1.1994402408599854,
      "logits/rejected": -1.1205041408538818,
      "logps/chosen": -173.31626892089844,
      "logps/rejected": -173.07540893554688,
      "loss": 0.3832,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.5204005241394043,
      "rewards/margins": 2.250847101211548,
      "rewards/rejected": -4.771247386932373,
      "step": 16350
    },
    {
      "epoch": 2.9856738753535907,
      "grad_norm": 6.367650985717773,
      "learning_rate": 4.2242279118315225e-07,
      "logits/chosen": -1.2156590223312378,
      "logits/rejected": -1.1406158208847046,
      "logps/chosen": -180.15646362304688,
      "logps/rejected": -185.8402099609375,
      "loss": 0.3107,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.831132411956787,
      "rewards/margins": 2.1922500133514404,
      "rewards/rejected": -5.023382663726807,
      "step": 16360
    },
    {
      "epoch": 2.9874988593849805,
      "grad_norm": 0.894432783126831,
      "learning_rate": 3.733038619758089e-07,
      "logits/chosen": -1.1623142957687378,
      "logits/rejected": -1.1030855178833008,
      "logps/chosen": -160.38821411132812,
      "logps/rejected": -171.91622924804688,
      "loss": 0.3583,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.549067974090576,
      "rewards/margins": 2.4500515460968018,
      "rewards/rejected": -4.999119758605957,
      "step": 16370
    },
    {
      "epoch": 2.9893238434163703,
      "grad_norm": 10.509381294250488,
      "learning_rate": 3.241849327684657e-07,
      "logits/chosen": -1.2307007312774658,
      "logits/rejected": -1.1133397817611694,
      "logps/chosen": -176.56333923339844,
      "logps/rejected": -174.9105224609375,
      "loss": 0.3764,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.539734125137329,
      "rewards/margins": 2.521599531173706,
      "rewards/rejected": -5.061333656311035,
      "step": 16380
    },
    {
      "epoch": 2.99114882744776,
      "grad_norm": 4.704784870147705,
      "learning_rate": 2.7506600356112237e-07,
      "logits/chosen": -1.184822916984558,
      "logits/rejected": -1.088297963142395,
      "logps/chosen": -162.8025665283203,
      "logps/rejected": -174.20794677734375,
      "loss": 0.2219,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.2284767627716064,
      "rewards/margins": 2.9681332111358643,
      "rewards/rejected": -5.1966094970703125,
      "step": 16390
    },
    {
      "epoch": 2.9929738114791498,
      "grad_norm": 6.446755886077881,
      "learning_rate": 2.2594707435377912e-07,
      "logits/chosen": -1.1980727910995483,
      "logits/rejected": -1.1294633150100708,
      "logps/chosen": -186.0906219482422,
      "logps/rejected": -189.67849731445312,
      "loss": 0.2922,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.6091020107269287,
      "rewards/margins": 2.6536290645599365,
      "rewards/rejected": -5.262730598449707,
      "step": 16400
    },
    {
      "epoch": 2.9947987955105395,
      "grad_norm": 6.650631427764893,
      "learning_rate": 1.7682814514643582e-07,
      "logits/chosen": -1.1724475622177124,
      "logits/rejected": -1.1219871044158936,
      "logps/chosen": -162.63003540039062,
      "logps/rejected": -178.00579833984375,
      "loss": 0.2602,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.707231044769287,
      "rewards/margins": 2.175544261932373,
      "rewards/rejected": -4.88277530670166,
      "step": 16410
    },
    {
      "epoch": 2.9966237795419293,
      "grad_norm": 3.237856149673462,
      "learning_rate": 1.2770921593909255e-07,
      "logits/chosen": -1.1642520427703857,
      "logits/rejected": -1.108912706375122,
      "logps/chosen": -158.41928100585938,
      "logps/rejected": -183.48939514160156,
      "loss": 0.2859,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.5503005981445312,
      "rewards/margins": 2.7051262855529785,
      "rewards/rejected": -5.255426406860352,
      "step": 16420
    },
    {
      "epoch": 2.9984487635733186,
      "grad_norm": 8.693984985351562,
      "learning_rate": 7.859028673174924e-08,
      "logits/chosen": -1.2074944972991943,
      "logits/rejected": -1.1382958889007568,
      "logps/chosen": -165.0850830078125,
      "logps/rejected": -189.7885284423828,
      "loss": 0.3134,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.4909560680389404,
      "rewards/margins": 2.909163475036621,
      "rewards/rejected": -5.400119781494141,
      "step": 16430
    }
  ],
  "logging_steps": 10,
  "max_steps": 16437,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
