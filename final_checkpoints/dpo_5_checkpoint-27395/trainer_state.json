{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.999543753992152,
  "eval_steps": 500.0,
  "global_step": 27395,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00018249840313897252,
      "grad_norm": 1.0898160934448242,
      "learning_rate": 5.333333333333335e-07,
      "logits/chosen": -0.8584169149398804,
      "logits/rejected": -0.842930018901825,
      "logps/chosen": -143.1091766357422,
      "logps/rejected": -108.95474243164062,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.0018249840313897254,
      "grad_norm": 1.564947247505188,
      "learning_rate": 4.800000000000001e-06,
      "logits/chosen": -0.91048663854599,
      "logits/rejected": -0.9438562393188477,
      "logps/chosen": -122.74143981933594,
      "logps/rejected": -131.36888122558594,
      "loss": 0.6932,
      "rewards/accuracies": 0.3888888955116272,
      "rewards/chosen": 0.0014348771655932069,
      "rewards/margins": -2.1775576897198334e-05,
      "rewards/rejected": 0.0014566528843715787,
      "step": 10
    },
    {
      "epoch": 0.003649968062779451,
      "grad_norm": 1.3101223707199097,
      "learning_rate": 1.0133333333333335e-05,
      "logits/chosen": -0.9228008985519409,
      "logits/rejected": -0.8869624137878418,
      "logps/chosen": -130.79122924804688,
      "logps/rejected": -122.75114440917969,
      "loss": 0.6928,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.011786375194787979,
      "rewards/margins": 0.0007627249578945339,
      "rewards/rejected": 0.01102364994585514,
      "step": 20
    },
    {
      "epoch": 0.005474952094169176,
      "grad_norm": 1.9350520372390747,
      "learning_rate": 1.546666666666667e-05,
      "logits/chosen": -0.9934896230697632,
      "logits/rejected": -0.9369571805000305,
      "logps/chosen": -166.74766540527344,
      "logps/rejected": -139.41860961914062,
      "loss": 0.6935,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.029555324465036392,
      "rewards/margins": -0.0003591966815292835,
      "rewards/rejected": 0.029914522543549538,
      "step": 30
    },
    {
      "epoch": 0.007299936125558902,
      "grad_norm": 1.0215755701065063,
      "learning_rate": 2.08e-05,
      "logits/chosen": -0.9189378023147583,
      "logits/rejected": -0.9324696660041809,
      "logps/chosen": -142.79660034179688,
      "logps/rejected": -140.0992431640625,
      "loss": 0.6906,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.04416850954294205,
      "rewards/margins": 0.005515861324965954,
      "rewards/rejected": 0.03865264356136322,
      "step": 40
    },
    {
      "epoch": 0.009124920156948626,
      "grad_norm": NaN,
      "learning_rate": 2.5600000000000002e-05,
      "logits/chosen": -0.9619539976119995,
      "logits/rejected": -0.9243555068969727,
      "logps/chosen": -147.6027069091797,
      "logps/rejected": -119.74796295166016,
      "loss": 0.6937,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.060922205448150635,
      "rewards/margins": -0.0004375263233669102,
      "rewards/rejected": 0.06135973334312439,
      "step": 50
    },
    {
      "epoch": 0.010949904188338352,
      "grad_norm": 1.3586170673370361,
      "learning_rate": 3.093333333333334e-05,
      "logits/chosen": -0.9395152926445007,
      "logits/rejected": -0.8860591650009155,
      "logps/chosen": -158.80758666992188,
      "logps/rejected": -123.24256896972656,
      "loss": 0.6867,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.05039261654019356,
      "rewards/margins": 0.013762506656348705,
      "rewards/rejected": 0.03663010522723198,
      "step": 60
    },
    {
      "epoch": 0.012774888219728078,
      "grad_norm": 1.3995997905731201,
      "learning_rate": 3.626666666666667e-05,
      "logits/chosen": -0.9260787963867188,
      "logits/rejected": -0.8847274780273438,
      "logps/chosen": -142.82037353515625,
      "logps/rejected": -127.2763442993164,
      "loss": 0.682,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.05152549222111702,
      "rewards/margins": 0.024945946410298347,
      "rewards/rejected": 0.026579540222883224,
      "step": 70
    },
    {
      "epoch": 0.014599872251117803,
      "grad_norm": 1.593152642250061,
      "learning_rate": 4.16e-05,
      "logits/chosen": -0.9758578538894653,
      "logits/rejected": -0.9479166269302368,
      "logps/chosen": -147.352294921875,
      "logps/rejected": -116.2485122680664,
      "loss": 0.6785,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.05566050857305527,
      "rewards/margins": 0.03338400274515152,
      "rewards/rejected": 0.0222765039652586,
      "step": 80
    },
    {
      "epoch": 0.01642485628250753,
      "grad_norm": 2.0308516025543213,
      "learning_rate": 4.693333333333334e-05,
      "logits/chosen": -0.950125515460968,
      "logits/rejected": -0.915908932685852,
      "logps/chosen": -149.93040466308594,
      "logps/rejected": -122.25999450683594,
      "loss": 0.651,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.04832063987851143,
      "rewards/margins": 0.10286027193069458,
      "rewards/rejected": -0.05453963950276375,
      "step": 90
    },
    {
      "epoch": 0.018249840313897252,
      "grad_norm": 2.2793123722076416,
      "learning_rate": 5.226666666666667e-05,
      "logits/chosen": -0.9219765663146973,
      "logits/rejected": -0.8877030611038208,
      "logps/chosen": -159.6874237060547,
      "logps/rejected": -136.50155639648438,
      "loss": 0.642,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.044868357479572296,
      "rewards/margins": 0.1266249716281891,
      "rewards/rejected": -0.08175663650035858,
      "step": 100
    },
    {
      "epoch": 0.020074824345286978,
      "grad_norm": 2.695131778717041,
      "learning_rate": 5.7600000000000004e-05,
      "logits/chosen": -0.9783161878585815,
      "logits/rejected": -0.9125560522079468,
      "logps/chosen": -172.53140258789062,
      "logps/rejected": -124.75932312011719,
      "loss": 0.6266,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.22083242237567902,
      "rewards/margins": 0.17613255977630615,
      "rewards/rejected": -0.396964967250824,
      "step": 110
    },
    {
      "epoch": 0.021899808376676703,
      "grad_norm": 2.2609004974365234,
      "learning_rate": 6.293333333333334e-05,
      "logits/chosen": -0.9774850010871887,
      "logits/rejected": -0.9581633806228638,
      "logps/chosen": -141.55203247070312,
      "logps/rejected": -129.4984130859375,
      "loss": 0.6201,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.210891455411911,
      "rewards/margins": 0.19103172421455383,
      "rewards/rejected": -0.40192317962646484,
      "step": 120
    },
    {
      "epoch": 0.02372479240806643,
      "grad_norm": 1.8263555765151978,
      "learning_rate": 6.826666666666668e-05,
      "logits/chosen": -0.9680722951889038,
      "logits/rejected": -0.9432428479194641,
      "logps/chosen": -158.24945068359375,
      "logps/rejected": -142.14614868164062,
      "loss": 0.6256,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.18075016140937805,
      "rewards/margins": 0.23435933887958527,
      "rewards/rejected": -0.0536092109978199,
      "step": 130
    },
    {
      "epoch": 0.025549776439456155,
      "grad_norm": 2.8941688537597656,
      "learning_rate": 7.360000000000001e-05,
      "logits/chosen": -0.9448596835136414,
      "logits/rejected": -0.8995448350906372,
      "logps/chosen": -150.5266571044922,
      "logps/rejected": -127.62669372558594,
      "loss": 0.6522,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.146924689412117,
      "rewards/margins": 0.1982944905757904,
      "rewards/rejected": -0.05136982351541519,
      "step": 140
    },
    {
      "epoch": 0.02737476047084588,
      "grad_norm": 3.2532050609588623,
      "learning_rate": 7.893333333333335e-05,
      "logits/chosen": -0.9808006286621094,
      "logits/rejected": -0.9673048257827759,
      "logps/chosen": -139.1657257080078,
      "logps/rejected": -130.98403930664062,
      "loss": 0.6168,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.11927352100610733,
      "rewards/margins": 0.2650730013847351,
      "rewards/rejected": -0.14579951763153076,
      "step": 150
    },
    {
      "epoch": 0.029199744502235607,
      "grad_norm": 4.76623010635376,
      "learning_rate": 7.997650945127547e-05,
      "logits/chosen": -1.00176203250885,
      "logits/rejected": -0.9618108868598938,
      "logps/chosen": -150.1668243408203,
      "logps/rejected": -125.01133728027344,
      "loss": 0.5339,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.12797728180885315,
      "rewards/margins": 0.5563532114028931,
      "rewards/rejected": -0.42837589979171753,
      "step": 160
    },
    {
      "epoch": 0.03102472853362533,
      "grad_norm": 4.16503381729126,
      "learning_rate": 7.99471462653698e-05,
      "logits/chosen": -0.9688172340393066,
      "logits/rejected": -0.929316520690918,
      "logps/chosen": -154.7568359375,
      "logps/rejected": -133.32766723632812,
      "loss": 0.628,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.3006402850151062,
      "rewards/margins": 0.394306480884552,
      "rewards/rejected": -0.6949466466903687,
      "step": 170
    },
    {
      "epoch": 0.03284971256501506,
      "grad_norm": 3.6470673084259033,
      "learning_rate": 7.991778307946413e-05,
      "logits/chosen": -1.064353346824646,
      "logits/rejected": -1.0255712270736694,
      "logps/chosen": -138.1090545654297,
      "logps/rejected": -135.75547790527344,
      "loss": 0.5715,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.6876217126846313,
      "rewards/margins": 0.4562075138092041,
      "rewards/rejected": -1.1438292264938354,
      "step": 180
    },
    {
      "epoch": 0.034674696596404785,
      "grad_norm": 3.6961324214935303,
      "learning_rate": 7.988841989355846e-05,
      "logits/chosen": -1.071190357208252,
      "logits/rejected": -1.0421713590621948,
      "logps/chosen": -137.18106079101562,
      "logps/rejected": -128.80963134765625,
      "loss": 0.5927,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.5148073434829712,
      "rewards/margins": 0.5154567956924438,
      "rewards/rejected": -1.030264139175415,
      "step": 190
    },
    {
      "epoch": 0.036499680627794504,
      "grad_norm": 4.242496013641357,
      "learning_rate": 7.985905670765278e-05,
      "logits/chosen": -1.0629775524139404,
      "logits/rejected": -1.0510963201522827,
      "logps/chosen": -143.15859985351562,
      "logps/rejected": -129.33094787597656,
      "loss": 0.6235,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.410642147064209,
      "rewards/margins": 0.4427415728569031,
      "rewards/rejected": -0.8533836603164673,
      "step": 200
    },
    {
      "epoch": 0.03832466465918423,
      "grad_norm": 5.170274257659912,
      "learning_rate": 7.982969352174712e-05,
      "logits/chosen": -1.065459966659546,
      "logits/rejected": -1.038027048110962,
      "logps/chosen": -149.57424926757812,
      "logps/rejected": -140.15174865722656,
      "loss": 0.6417,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.5361523628234863,
      "rewards/margins": 0.38549602031707764,
      "rewards/rejected": -0.921648383140564,
      "step": 210
    },
    {
      "epoch": 0.040149648690573955,
      "grad_norm": 4.606293678283691,
      "learning_rate": 7.980033033584145e-05,
      "logits/chosen": -1.1080334186553955,
      "logits/rejected": -1.0595256090164185,
      "logps/chosen": -150.40586853027344,
      "logps/rejected": -130.6021728515625,
      "loss": 0.6356,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.2796436548233032,
      "rewards/margins": 0.3652304708957672,
      "rewards/rejected": -0.6448741555213928,
      "step": 220
    },
    {
      "epoch": 0.04197463272196368,
      "grad_norm": 4.8668036460876465,
      "learning_rate": 7.977096714993577e-05,
      "logits/chosen": -1.0148988962173462,
      "logits/rejected": -0.9966965913772583,
      "logps/chosen": -149.80548095703125,
      "logps/rejected": -136.43788146972656,
      "loss": 0.6976,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -0.08637909591197968,
      "rewards/margins": 0.20399396121501923,
      "rewards/rejected": -0.2903730869293213,
      "step": 230
    },
    {
      "epoch": 0.04379961675335341,
      "grad_norm": 2.557466506958008,
      "learning_rate": 7.97416039640301e-05,
      "logits/chosen": -1.0547370910644531,
      "logits/rejected": -1.0205670595169067,
      "logps/chosen": -145.1241455078125,
      "logps/rejected": -131.48269653320312,
      "loss": 0.624,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5103719830513,
      "rewards/margins": 0.3496190905570984,
      "rewards/rejected": -0.8599910736083984,
      "step": 240
    },
    {
      "epoch": 0.04562460078474313,
      "grad_norm": 5.843166828155518,
      "learning_rate": 7.971224077812443e-05,
      "logits/chosen": -1.0814834833145142,
      "logits/rejected": -1.028477668762207,
      "logps/chosen": -146.38131713867188,
      "logps/rejected": -135.99111938476562,
      "loss": 0.6133,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.44291752576828003,
      "rewards/margins": 0.3859063982963562,
      "rewards/rejected": -0.8288238644599915,
      "step": 250
    },
    {
      "epoch": 0.04744958481613286,
      "grad_norm": 5.981142044067383,
      "learning_rate": 7.968287759221876e-05,
      "logits/chosen": -1.1045989990234375,
      "logits/rejected": -1.0748875141143799,
      "logps/chosen": -158.2715606689453,
      "logps/rejected": -145.17013549804688,
      "loss": 0.6576,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.2725814878940582,
      "rewards/margins": 0.31237441301345825,
      "rewards/rejected": -0.5849558115005493,
      "step": 260
    },
    {
      "epoch": 0.049274568847522585,
      "grad_norm": 3.5355982780456543,
      "learning_rate": 7.96535144063131e-05,
      "logits/chosen": -1.13612699508667,
      "logits/rejected": -1.0877556800842285,
      "logps/chosen": -163.6821746826172,
      "logps/rejected": -135.95700073242188,
      "loss": 0.6696,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.28791898488998413,
      "rewards/margins": 0.20702023804187775,
      "rewards/rejected": 0.08089873194694519,
      "step": 270
    },
    {
      "epoch": 0.05109955287891231,
      "grad_norm": 4.895196437835693,
      "learning_rate": 7.962415122040742e-05,
      "logits/chosen": -1.05636727809906,
      "logits/rejected": -1.034322738647461,
      "logps/chosen": -136.21484375,
      "logps/rejected": -118.1675796508789,
      "loss": 0.5979,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.2545627951622009,
      "rewards/margins": 0.3446272313594818,
      "rewards/rejected": -0.09006443619728088,
      "step": 280
    },
    {
      "epoch": 0.052924536910302036,
      "grad_norm": 6.957805156707764,
      "learning_rate": 7.959478803450176e-05,
      "logits/chosen": -1.133874773979187,
      "logits/rejected": -1.0863488912582397,
      "logps/chosen": -159.4194793701172,
      "logps/rejected": -140.9639129638672,
      "loss": 0.5927,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.3950859606266022,
      "rewards/margins": 0.5488882064819336,
      "rewards/rejected": -0.9439741969108582,
      "step": 290
    },
    {
      "epoch": 0.05474952094169176,
      "grad_norm": 4.041208267211914,
      "learning_rate": 7.956542484859608e-05,
      "logits/chosen": -1.0546993017196655,
      "logits/rejected": -1.028648018836975,
      "logps/chosen": -162.6918182373047,
      "logps/rejected": -152.30751037597656,
      "loss": 0.6292,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.0699098110198975,
      "rewards/margins": 0.3893764615058899,
      "rewards/rejected": -1.4592863321304321,
      "step": 300
    },
    {
      "epoch": 0.05657450497308149,
      "grad_norm": 3.613046646118164,
      "learning_rate": 7.953606166269041e-05,
      "logits/chosen": -1.0381486415863037,
      "logits/rejected": -0.983160674571991,
      "logps/chosen": -175.24984741210938,
      "logps/rejected": -151.92086791992188,
      "loss": 0.6201,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.829994797706604,
      "rewards/margins": 0.5043150186538696,
      "rewards/rejected": -1.3343098163604736,
      "step": 310
    },
    {
      "epoch": 0.058399489004471214,
      "grad_norm": 3.4617760181427,
      "learning_rate": 7.950669847678473e-05,
      "logits/chosen": -0.9651535153388977,
      "logits/rejected": -0.9239404797554016,
      "logps/chosen": -142.20303344726562,
      "logps/rejected": -127.36495208740234,
      "loss": 0.6718,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.26539579033851624,
      "rewards/margins": 0.33726510405540466,
      "rewards/rejected": -0.6026608347892761,
      "step": 320
    },
    {
      "epoch": 0.06022447303586093,
      "grad_norm": 4.142534255981445,
      "learning_rate": 7.947733529087907e-05,
      "logits/chosen": -0.9400647282600403,
      "logits/rejected": -0.8783450126647949,
      "logps/chosen": -166.97445678710938,
      "logps/rejected": -143.6549072265625,
      "loss": 0.5149,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.36011701822280884,
      "rewards/margins": 0.6565641164779663,
      "rewards/rejected": -1.0166810750961304,
      "step": 330
    },
    {
      "epoch": 0.06204945706725066,
      "grad_norm": 10.40168571472168,
      "learning_rate": 7.94479721049734e-05,
      "logits/chosen": -0.9650105237960815,
      "logits/rejected": -0.9196087121963501,
      "logps/chosen": -153.68910217285156,
      "logps/rejected": -145.07321166992188,
      "loss": 0.5604,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.5172132849693298,
      "rewards/margins": 0.7523527145385742,
      "rewards/rejected": -1.2695660591125488,
      "step": 340
    },
    {
      "epoch": 0.06387444109864039,
      "grad_norm": 3.653531074523926,
      "learning_rate": 7.941860891906772e-05,
      "logits/chosen": -1.0459372997283936,
      "logits/rejected": -1.0116918087005615,
      "logps/chosen": -150.14370727539062,
      "logps/rejected": -137.5087127685547,
      "loss": 0.595,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.08762054145336151,
      "rewards/margins": 0.5862538814544678,
      "rewards/rejected": -0.6738744974136353,
      "step": 350
    },
    {
      "epoch": 0.06569942513003012,
      "grad_norm": 4.006186008453369,
      "learning_rate": 7.938924573316204e-05,
      "logits/chosen": -1.016739845275879,
      "logits/rejected": -0.9840668439865112,
      "logps/chosen": -151.24301147460938,
      "logps/rejected": -147.01470947265625,
      "loss": 0.6151,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.22856704890727997,
      "rewards/margins": 0.5561391711235046,
      "rewards/rejected": -0.7847062349319458,
      "step": 360
    },
    {
      "epoch": 0.06752440916141984,
      "grad_norm": 3.782273292541504,
      "learning_rate": 7.935988254725638e-05,
      "logits/chosen": -1.1150809526443481,
      "logits/rejected": -1.046367883682251,
      "logps/chosen": -138.7513885498047,
      "logps/rejected": -120.75389099121094,
      "loss": 0.6112,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.3167073130607605,
      "rewards/margins": 0.4925483763217926,
      "rewards/rejected": -0.17584100365638733,
      "step": 370
    },
    {
      "epoch": 0.06934939319280957,
      "grad_norm": 3.714228630065918,
      "learning_rate": 7.933051936135071e-05,
      "logits/chosen": -1.1600655317306519,
      "logits/rejected": -1.1140451431274414,
      "logps/chosen": -152.03677368164062,
      "logps/rejected": -129.1446533203125,
      "loss": 0.6,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.3043971359729767,
      "rewards/margins": 0.5402549505233765,
      "rewards/rejected": -0.8446520566940308,
      "step": 380
    },
    {
      "epoch": 0.0711743772241993,
      "grad_norm": 4.321092128753662,
      "learning_rate": 7.930115617544505e-05,
      "logits/chosen": -1.0949721336364746,
      "logits/rejected": -1.0606014728546143,
      "logps/chosen": -162.33509826660156,
      "logps/rejected": -144.67416381835938,
      "loss": 0.6655,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.4526732563972473,
      "rewards/margins": 0.4239562451839447,
      "rewards/rejected": -0.8766295313835144,
      "step": 390
    },
    {
      "epoch": 0.07299936125558901,
      "grad_norm": 3.642987012863159,
      "learning_rate": 7.927179298953937e-05,
      "logits/chosen": -1.0803018808364868,
      "logits/rejected": -1.0346012115478516,
      "logps/chosen": -149.46311950683594,
      "logps/rejected": -121.87156677246094,
      "loss": 0.6125,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.24643392860889435,
      "rewards/margins": 0.42217588424682617,
      "rewards/rejected": -0.6686097383499146,
      "step": 400
    },
    {
      "epoch": 0.07482434528697873,
      "grad_norm": 4.572582244873047,
      "learning_rate": 7.924242980363371e-05,
      "logits/chosen": -1.1428894996643066,
      "logits/rejected": -1.1259725093841553,
      "logps/chosen": -165.08731079101562,
      "logps/rejected": -154.0595703125,
      "loss": 0.6344,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.3513474464416504,
      "rewards/margins": 0.48824721574783325,
      "rewards/rejected": -1.8395946025848389,
      "step": 410
    },
    {
      "epoch": 0.07664932931836846,
      "grad_norm": 5.240671634674072,
      "learning_rate": 7.921306661772803e-05,
      "logits/chosen": -1.1454085111618042,
      "logits/rejected": -1.1295510530471802,
      "logps/chosen": -155.3128204345703,
      "logps/rejected": -142.51910400390625,
      "loss": 0.6315,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.2517921924591064,
      "rewards/margins": 0.3957967162132263,
      "rewards/rejected": -1.6475889682769775,
      "step": 420
    },
    {
      "epoch": 0.07847431334975818,
      "grad_norm": 3.935856580734253,
      "learning_rate": 7.918370343182236e-05,
      "logits/chosen": -1.0809955596923828,
      "logits/rejected": -1.0606005191802979,
      "logps/chosen": -149.18569946289062,
      "logps/rejected": -136.60354614257812,
      "loss": 0.6211,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.6620206832885742,
      "rewards/margins": 0.3776898980140686,
      "rewards/rejected": -1.0397106409072876,
      "step": 430
    },
    {
      "epoch": 0.08029929738114791,
      "grad_norm": 3.137037754058838,
      "learning_rate": 7.91543402459167e-05,
      "logits/chosen": -1.1124378442764282,
      "logits/rejected": -1.0825040340423584,
      "logps/chosen": -148.25306701660156,
      "logps/rejected": -140.54177856445312,
      "loss": 0.5588,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.30655109882354736,
      "rewards/margins": 0.5236254930496216,
      "rewards/rejected": -0.8301766514778137,
      "step": 440
    },
    {
      "epoch": 0.08212428141253764,
      "grad_norm": 3.475407361984253,
      "learning_rate": 7.912497706001102e-05,
      "logits/chosen": -1.0731024742126465,
      "logits/rejected": -1.059882640838623,
      "logps/chosen": -143.66342163085938,
      "logps/rejected": -134.8927001953125,
      "loss": 0.6327,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.08907409012317657,
      "rewards/margins": 0.39046674966812134,
      "rewards/rejected": -0.3013926148414612,
      "step": 450
    },
    {
      "epoch": 0.08394926544392736,
      "grad_norm": 4.195324420928955,
      "learning_rate": 7.909561387410534e-05,
      "logits/chosen": -1.0502262115478516,
      "logits/rejected": -0.9939346313476562,
      "logps/chosen": -152.2968292236328,
      "logps/rejected": -128.40869140625,
      "loss": 0.5955,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.08952776342630386,
      "rewards/margins": 0.4645400047302246,
      "rewards/rejected": -0.5540677309036255,
      "step": 460
    },
    {
      "epoch": 0.08577424947531709,
      "grad_norm": 4.10453462600708,
      "learning_rate": 7.906625068819967e-05,
      "logits/chosen": -1.0464637279510498,
      "logits/rejected": -1.0261094570159912,
      "logps/chosen": -135.96151733398438,
      "logps/rejected": -130.58929443359375,
      "loss": 0.5732,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.47724080085754395,
      "rewards/margins": 0.5718467831611633,
      "rewards/rejected": -1.049087643623352,
      "step": 470
    },
    {
      "epoch": 0.08759923350670681,
      "grad_norm": 4.090923309326172,
      "learning_rate": 7.903688750229401e-05,
      "logits/chosen": -1.019343376159668,
      "logits/rejected": -1.0143394470214844,
      "logps/chosen": -145.5894775390625,
      "logps/rejected": -142.38136291503906,
      "loss": 0.7017,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.7195013761520386,
      "rewards/margins": 0.21677526831626892,
      "rewards/rejected": -0.9362767338752747,
      "step": 480
    },
    {
      "epoch": 0.08942421753809654,
      "grad_norm": 3.0660383701324463,
      "learning_rate": 7.900752431638833e-05,
      "logits/chosen": -1.0336809158325195,
      "logits/rejected": -0.9490251541137695,
      "logps/chosen": -160.38180541992188,
      "logps/rejected": -129.66810607910156,
      "loss": 0.4965,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.10472533851861954,
      "rewards/margins": 0.753028154373169,
      "rewards/rejected": -0.857753574848175,
      "step": 490
    },
    {
      "epoch": 0.09124920156948627,
      "grad_norm": 3.690039873123169,
      "learning_rate": 7.897816113048266e-05,
      "logits/chosen": -1.062723994255066,
      "logits/rejected": -1.0406954288482666,
      "logps/chosen": -145.66262817382812,
      "logps/rejected": -141.5557861328125,
      "loss": 0.6208,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.07792476564645767,
      "rewards/margins": 0.44037294387817383,
      "rewards/rejected": -0.5182977318763733,
      "step": 500
    },
    {
      "epoch": 0.09307418560087599,
      "grad_norm": 5.216534614562988,
      "learning_rate": 7.8948797944577e-05,
      "logits/chosen": -1.0644428730010986,
      "logits/rejected": -1.0415129661560059,
      "logps/chosen": -155.89492797851562,
      "logps/rejected": -156.86727905273438,
      "loss": 0.6072,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.06793511658906937,
      "rewards/margins": 0.5310906171798706,
      "rewards/rejected": -0.5990257263183594,
      "step": 510
    },
    {
      "epoch": 0.09489916963226572,
      "grad_norm": 6.258150100708008,
      "learning_rate": 7.891943475867132e-05,
      "logits/chosen": -1.111611247062683,
      "logits/rejected": -1.0478538274765015,
      "logps/chosen": -149.76840209960938,
      "logps/rejected": -133.83627319335938,
      "loss": 0.4948,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.019280141219496727,
      "rewards/margins": 0.8497910499572754,
      "rewards/rejected": -0.8690711855888367,
      "step": 520
    },
    {
      "epoch": 0.09672415366365544,
      "grad_norm": 5.2862114906311035,
      "learning_rate": 7.889007157276566e-05,
      "logits/chosen": -1.0331029891967773,
      "logits/rejected": -0.9720662832260132,
      "logps/chosen": -147.7481689453125,
      "logps/rejected": -124.0955581665039,
      "loss": 0.5605,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.06825966387987137,
      "rewards/margins": 0.7273651361465454,
      "rewards/rejected": -0.7956247925758362,
      "step": 530
    },
    {
      "epoch": 0.09854913769504517,
      "grad_norm": 4.641878604888916,
      "learning_rate": 7.886070838685998e-05,
      "logits/chosen": -1.0412089824676514,
      "logits/rejected": -1.002307415008545,
      "logps/chosen": -144.02890014648438,
      "logps/rejected": -136.92181396484375,
      "loss": 0.6504,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.211552232503891,
      "rewards/margins": 0.36430448293685913,
      "rewards/rejected": -0.5758568048477173,
      "step": 540
    },
    {
      "epoch": 0.1003741217264349,
      "grad_norm": 3.1581122875213623,
      "learning_rate": 7.88313452009543e-05,
      "logits/chosen": -1.1115355491638184,
      "logits/rejected": -1.0523440837860107,
      "logps/chosen": -165.24559020996094,
      "logps/rejected": -146.47398376464844,
      "loss": 0.5373,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.024724841117858887,
      "rewards/margins": 0.6454068422317505,
      "rewards/rejected": -0.6206820607185364,
      "step": 550
    },
    {
      "epoch": 0.10219910575782462,
      "grad_norm": 5.1685991287231445,
      "learning_rate": 7.880198201504864e-05,
      "logits/chosen": -1.1163880825042725,
      "logits/rejected": -1.0898711681365967,
      "logps/chosen": -148.0167694091797,
      "logps/rejected": -139.56057739257812,
      "loss": 0.6502,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.40402621030807495,
      "rewards/margins": 0.4372544288635254,
      "rewards/rejected": -0.8412806391716003,
      "step": 560
    },
    {
      "epoch": 0.10402408978921435,
      "grad_norm": 3.977926254272461,
      "learning_rate": 7.877261882914297e-05,
      "logits/chosen": -1.149706482887268,
      "logits/rejected": -1.1437066793441772,
      "logps/chosen": -137.91824340820312,
      "logps/rejected": -139.79444885253906,
      "loss": 0.6179,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.47704869508743286,
      "rewards/margins": 0.40013986825942993,
      "rewards/rejected": -0.8771886825561523,
      "step": 570
    },
    {
      "epoch": 0.10584907382060407,
      "grad_norm": 2.5674479007720947,
      "learning_rate": 7.87432556432373e-05,
      "logits/chosen": -1.1462290287017822,
      "logits/rejected": -1.1341381072998047,
      "logps/chosen": -152.8535919189453,
      "logps/rejected": -143.91018676757812,
      "loss": 0.6094,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.4206930100917816,
      "rewards/margins": 0.5002859830856323,
      "rewards/rejected": -0.9209790229797363,
      "step": 580
    },
    {
      "epoch": 0.1076740578519938,
      "grad_norm": 5.185009479522705,
      "learning_rate": 7.871389245733163e-05,
      "logits/chosen": -1.1216065883636475,
      "logits/rejected": -1.029862642288208,
      "logps/chosen": -153.34085083007812,
      "logps/rejected": -114.56497955322266,
      "loss": 0.6309,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.2647029459476471,
      "rewards/margins": 0.38396844267845154,
      "rewards/rejected": -0.6486713290214539,
      "step": 590
    },
    {
      "epoch": 0.10949904188338352,
      "grad_norm": 3.5644354820251465,
      "learning_rate": 7.868452927142596e-05,
      "logits/chosen": -1.1169922351837158,
      "logits/rejected": -1.0869057178497314,
      "logps/chosen": -157.81759643554688,
      "logps/rejected": -137.7045440673828,
      "loss": 0.5707,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.0525059774518013,
      "rewards/margins": 0.5214213728904724,
      "rewards/rejected": -0.5739272832870483,
      "step": 600
    },
    {
      "epoch": 0.11132402591477325,
      "grad_norm": 3.122122287750244,
      "learning_rate": 7.865516608552028e-05,
      "logits/chosen": -1.1085445880889893,
      "logits/rejected": -1.0589227676391602,
      "logps/chosen": -151.21676635742188,
      "logps/rejected": -141.16249084472656,
      "loss": 0.6068,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.14147453010082245,
      "rewards/margins": 0.4782043993473053,
      "rewards/rejected": -0.6196788549423218,
      "step": 610
    },
    {
      "epoch": 0.11314900994616298,
      "grad_norm": 4.820242881774902,
      "learning_rate": 7.86258028996146e-05,
      "logits/chosen": -1.1189028024673462,
      "logits/rejected": -1.064173936843872,
      "logps/chosen": -137.95889282226562,
      "logps/rejected": -132.2082977294922,
      "loss": 0.6089,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.33559614419937134,
      "rewards/margins": 0.43712764978408813,
      "rewards/rejected": -0.7727237939834595,
      "step": 620
    },
    {
      "epoch": 0.1149739939775527,
      "grad_norm": 3.3383421897888184,
      "learning_rate": 7.859643971370894e-05,
      "logits/chosen": -1.0712811946868896,
      "logits/rejected": -0.9976783990859985,
      "logps/chosen": -149.16903686523438,
      "logps/rejected": -126.0228042602539,
      "loss": 0.5711,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.14300216734409332,
      "rewards/margins": 0.6170294880867004,
      "rewards/rejected": -0.7600316405296326,
      "step": 630
    },
    {
      "epoch": 0.11679897800894243,
      "grad_norm": 3.425287961959839,
      "learning_rate": 7.856707652780327e-05,
      "logits/chosen": -1.0367804765701294,
      "logits/rejected": -0.9581694602966309,
      "logps/chosen": -158.15457153320312,
      "logps/rejected": -131.2992401123047,
      "loss": 0.5599,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.2945539951324463,
      "rewards/margins": 0.639477550983429,
      "rewards/rejected": -0.34492355585098267,
      "step": 640
    },
    {
      "epoch": 0.11862396204033215,
      "grad_norm": 3.426597833633423,
      "learning_rate": 7.85377133418976e-05,
      "logits/chosen": -1.060756802558899,
      "logits/rejected": -0.9891292452812195,
      "logps/chosen": -165.04647827148438,
      "logps/rejected": -137.44371032714844,
      "loss": 0.5381,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.35690468549728394,
      "rewards/margins": 0.7555608153343201,
      "rewards/rejected": -0.3986561894416809,
      "step": 650
    },
    {
      "epoch": 0.12044894607172187,
      "grad_norm": 3.196209192276001,
      "learning_rate": 7.850835015599193e-05,
      "logits/chosen": -1.0720717906951904,
      "logits/rejected": -0.9488928914070129,
      "logps/chosen": -160.4775390625,
      "logps/rejected": -126.85693359375,
      "loss": 0.5242,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 0.3451452851295471,
      "rewards/margins": 0.8075873255729675,
      "rewards/rejected": -0.46244198083877563,
      "step": 660
    },
    {
      "epoch": 0.12227393010311159,
      "grad_norm": 4.9586615562438965,
      "learning_rate": 7.847898697008627e-05,
      "logits/chosen": -1.093194603919983,
      "logits/rejected": -1.0270503759384155,
      "logps/chosen": -152.62216186523438,
      "logps/rejected": -135.93234252929688,
      "loss": 0.6444,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.2609530985355377,
      "rewards/margins": 0.582394003868103,
      "rewards/rejected": -0.3214408755302429,
      "step": 670
    },
    {
      "epoch": 0.12409891413450132,
      "grad_norm": 3.9882965087890625,
      "learning_rate": 7.84496237841806e-05,
      "logits/chosen": -1.0113425254821777,
      "logits/rejected": -0.9539171457290649,
      "logps/chosen": -132.14463806152344,
      "logps/rejected": -118.66886138916016,
      "loss": 0.6185,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.16044697165489197,
      "rewards/margins": 0.566308856010437,
      "rewards/rejected": -0.4058619439601898,
      "step": 680
    },
    {
      "epoch": 0.12592389816589106,
      "grad_norm": 4.81447696685791,
      "learning_rate": 7.842026059827492e-05,
      "logits/chosen": -1.0550854206085205,
      "logits/rejected": -0.9834290742874146,
      "logps/chosen": -154.5780792236328,
      "logps/rejected": -145.8064727783203,
      "loss": 0.5381,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.24508842825889587,
      "rewards/margins": 0.8201261758804321,
      "rewards/rejected": -0.5750376582145691,
      "step": 690
    },
    {
      "epoch": 0.12774888219728078,
      "grad_norm": 3.298694372177124,
      "learning_rate": 7.839089741236924e-05,
      "logits/chosen": -1.0936386585235596,
      "logits/rejected": -0.989093005657196,
      "logps/chosen": -174.80673217773438,
      "logps/rejected": -140.0944366455078,
      "loss": 0.5442,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.3966563642024994,
      "rewards/margins": 0.6683989763259888,
      "rewards/rejected": -1.0650553703308105,
      "step": 700
    },
    {
      "epoch": 0.1295738662286705,
      "grad_norm": 4.149974346160889,
      "learning_rate": 7.836153422646358e-05,
      "logits/chosen": -1.0342298746109009,
      "logits/rejected": -0.9859002828598022,
      "logps/chosen": -145.93203735351562,
      "logps/rejected": -124.43083190917969,
      "loss": 0.6191,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.32628241181373596,
      "rewards/margins": 0.5890875458717346,
      "rewards/rejected": -0.915369987487793,
      "step": 710
    },
    {
      "epoch": 0.13139885026006023,
      "grad_norm": 3.548058271408081,
      "learning_rate": 7.83321710405579e-05,
      "logits/chosen": -1.0777204036712646,
      "logits/rejected": -1.0237641334533691,
      "logps/chosen": -155.93563842773438,
      "logps/rejected": -139.28404235839844,
      "loss": 0.5632,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.2969876527786255,
      "rewards/margins": 0.6075276136398315,
      "rewards/rejected": -0.31054002046585083,
      "step": 720
    },
    {
      "epoch": 0.13322383429144996,
      "grad_norm": 4.114861965179443,
      "learning_rate": 7.830280785465223e-05,
      "logits/chosen": -1.092909574508667,
      "logits/rejected": -1.0311716794967651,
      "logps/chosen": -147.9170379638672,
      "logps/rejected": -133.0970916748047,
      "loss": 0.6187,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.005169021897017956,
      "rewards/margins": 0.5292311906814575,
      "rewards/rejected": -0.534400224685669,
      "step": 730
    },
    {
      "epoch": 0.1350488183228397,
      "grad_norm": 3.467479705810547,
      "learning_rate": 7.827344466874655e-05,
      "logits/chosen": -1.091733694076538,
      "logits/rejected": -1.0273516178131104,
      "logps/chosen": -139.16468811035156,
      "logps/rejected": -128.7537384033203,
      "loss": 0.5542,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.04240913689136505,
      "rewards/margins": 0.6068874001502991,
      "rewards/rejected": -0.6492965817451477,
      "step": 740
    },
    {
      "epoch": 0.1368738023542294,
      "grad_norm": 5.014942646026611,
      "learning_rate": 7.824408148284089e-05,
      "logits/chosen": -1.0731043815612793,
      "logits/rejected": -1.0031335353851318,
      "logps/chosen": -145.31466674804688,
      "logps/rejected": -131.77569580078125,
      "loss": 0.5002,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.27348095178604126,
      "rewards/margins": 0.9841278195381165,
      "rewards/rejected": -1.2576086521148682,
      "step": 750
    },
    {
      "epoch": 0.13869878638561914,
      "grad_norm": 4.595897674560547,
      "learning_rate": 7.821471829693522e-05,
      "logits/chosen": -0.994156002998352,
      "logits/rejected": -0.9102837443351746,
      "logps/chosen": -149.99606323242188,
      "logps/rejected": -133.95193481445312,
      "loss": 0.6334,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.35621243715286255,
      "rewards/margins": 0.5486937761306763,
      "rewards/rejected": -0.904906153678894,
      "step": 760
    },
    {
      "epoch": 0.14052377041700886,
      "grad_norm": 2.301004409790039,
      "learning_rate": 7.818535511102956e-05,
      "logits/chosen": -1.0162920951843262,
      "logits/rejected": -0.9385682940483093,
      "logps/chosen": -160.08737182617188,
      "logps/rejected": -124.25227355957031,
      "loss": 0.6135,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.24870844185352325,
      "rewards/margins": 0.5387632846832275,
      "rewards/rejected": -0.7874718308448792,
      "step": 770
    },
    {
      "epoch": 0.1423487544483986,
      "grad_norm": 4.898268699645996,
      "learning_rate": 7.815599192512388e-05,
      "logits/chosen": -1.0487781763076782,
      "logits/rejected": -1.0543878078460693,
      "logps/chosen": -141.25149536132812,
      "logps/rejected": -153.37155151367188,
      "loss": 0.6444,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.1416386216878891,
      "rewards/margins": 0.47496557235717773,
      "rewards/rejected": -0.616604208946228,
      "step": 780
    },
    {
      "epoch": 0.1441737384797883,
      "grad_norm": 2.675053119659424,
      "learning_rate": 7.812662873921822e-05,
      "logits/chosen": -1.055526614189148,
      "logits/rejected": -1.0243089199066162,
      "logps/chosen": -139.4771270751953,
      "logps/rejected": -129.77053833007812,
      "loss": 0.5344,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.1115197166800499,
      "rewards/margins": 0.6490932703018188,
      "rewards/rejected": -0.7606130242347717,
      "step": 790
    },
    {
      "epoch": 0.14599872251117801,
      "grad_norm": 5.185037612915039,
      "learning_rate": 7.809726555331254e-05,
      "logits/chosen": -1.0743104219436646,
      "logits/rejected": -1.0220983028411865,
      "logps/chosen": -151.2325897216797,
      "logps/rejected": -134.15126037597656,
      "loss": 0.6038,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.598301351070404,
      "rewards/margins": 0.5656665563583374,
      "rewards/rejected": -1.1639678478240967,
      "step": 800
    },
    {
      "epoch": 0.14782370654256774,
      "grad_norm": 3.0890557765960693,
      "learning_rate": 7.806790236740687e-05,
      "logits/chosen": -1.2028039693832397,
      "logits/rejected": -1.155160903930664,
      "logps/chosen": -149.43540954589844,
      "logps/rejected": -136.69883728027344,
      "loss": 0.5164,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.3500615060329437,
      "rewards/margins": 0.7410425543785095,
      "rewards/rejected": -1.0911040306091309,
      "step": 810
    },
    {
      "epoch": 0.14964869057395747,
      "grad_norm": 3.3793673515319824,
      "learning_rate": 7.80385391815012e-05,
      "logits/chosen": -1.2257956266403198,
      "logits/rejected": -1.1830449104309082,
      "logps/chosen": -153.33062744140625,
      "logps/rejected": -140.11170959472656,
      "loss": 0.5656,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.43638983368873596,
      "rewards/margins": 0.679806113243103,
      "rewards/rejected": -1.1161960363388062,
      "step": 820
    },
    {
      "epoch": 0.1514736746053472,
      "grad_norm": 4.266387939453125,
      "learning_rate": 7.800917599559553e-05,
      "logits/chosen": -1.2084981203079224,
      "logits/rejected": -1.1627113819122314,
      "logps/chosen": -156.63381958007812,
      "logps/rejected": -145.3748779296875,
      "loss": 0.6653,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.7700419425964355,
      "rewards/margins": 0.3787039518356323,
      "rewards/rejected": -1.1487456560134888,
      "step": 830
    },
    {
      "epoch": 0.15329865863673692,
      "grad_norm": 3.0012354850769043,
      "learning_rate": 7.797981280968985e-05,
      "logits/chosen": -1.14071786403656,
      "logits/rejected": -1.0861623287200928,
      "logps/chosen": -150.4552764892578,
      "logps/rejected": -137.41729736328125,
      "loss": 0.5253,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.4059997498989105,
      "rewards/margins": 0.7546687126159668,
      "rewards/rejected": -1.1606684923171997,
      "step": 840
    },
    {
      "epoch": 0.15512364266812664,
      "grad_norm": 2.9556548595428467,
      "learning_rate": 7.795044962378418e-05,
      "logits/chosen": -1.0266602039337158,
      "logits/rejected": -0.9924806356430054,
      "logps/chosen": -145.81324768066406,
      "logps/rejected": -136.47518920898438,
      "loss": 0.5083,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.333220899105072,
      "rewards/margins": 0.8997580409049988,
      "rewards/rejected": -1.2329790592193604,
      "step": 850
    },
    {
      "epoch": 0.15694862669951637,
      "grad_norm": 2.620197296142578,
      "learning_rate": 7.792108643787852e-05,
      "logits/chosen": -1.050079584121704,
      "logits/rejected": -1.0040390491485596,
      "logps/chosen": -158.25811767578125,
      "logps/rejected": -146.1085205078125,
      "loss": 0.5591,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.22567124664783478,
      "rewards/margins": 0.7201586365699768,
      "rewards/rejected": -0.9458298683166504,
      "step": 860
    },
    {
      "epoch": 0.1587736107309061,
      "grad_norm": 4.049829483032227,
      "learning_rate": 7.789172325197284e-05,
      "logits/chosen": -1.091841459274292,
      "logits/rejected": -1.0219653844833374,
      "logps/chosen": -164.57565307617188,
      "logps/rejected": -149.21835327148438,
      "loss": 0.5152,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.2686684727668762,
      "rewards/margins": 1.0127276182174683,
      "rewards/rejected": -1.2813961505889893,
      "step": 870
    },
    {
      "epoch": 0.16059859476229582,
      "grad_norm": 4.948313236236572,
      "learning_rate": 7.786236006606718e-05,
      "logits/chosen": -1.1838226318359375,
      "logits/rejected": -1.139215111732483,
      "logps/chosen": -165.02890014648438,
      "logps/rejected": -162.48167419433594,
      "loss": 0.5705,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.5102897882461548,
      "rewards/margins": 0.8226509094238281,
      "rewards/rejected": -1.332940697669983,
      "step": 880
    },
    {
      "epoch": 0.16242357879368555,
      "grad_norm": 4.9352545738220215,
      "learning_rate": 7.78329968801615e-05,
      "logits/chosen": -1.1228965520858765,
      "logits/rejected": -1.0493980646133423,
      "logps/chosen": -172.4934539794922,
      "logps/rejected": -145.76856994628906,
      "loss": 0.5908,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.3439919352531433,
      "rewards/margins": 0.6105409264564514,
      "rewards/rejected": -0.9545329213142395,
      "step": 890
    },
    {
      "epoch": 0.16424856282507527,
      "grad_norm": 5.4068474769592285,
      "learning_rate": 7.780363369425583e-05,
      "logits/chosen": -1.1708896160125732,
      "logits/rejected": -1.1566241979599,
      "logps/chosen": -136.85794067382812,
      "logps/rejected": -138.99246215820312,
      "loss": 0.6227,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.158451646566391,
      "rewards/margins": 0.4730692505836487,
      "rewards/rejected": -0.6315208673477173,
      "step": 900
    },
    {
      "epoch": 0.166073546856465,
      "grad_norm": 4.968242645263672,
      "learning_rate": 7.777427050835017e-05,
      "logits/chosen": -1.1539596319198608,
      "logits/rejected": -1.1218433380126953,
      "logps/chosen": -144.92901611328125,
      "logps/rejected": -141.35263061523438,
      "loss": 0.5761,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.14752405881881714,
      "rewards/margins": 0.5933845043182373,
      "rewards/rejected": -0.7409086227416992,
      "step": 910
    },
    {
      "epoch": 0.16789853088785472,
      "grad_norm": 3.627465009689331,
      "learning_rate": 7.774490732244449e-05,
      "logits/chosen": -1.1068522930145264,
      "logits/rejected": -1.0662301778793335,
      "logps/chosen": -149.15481567382812,
      "logps/rejected": -142.1300811767578,
      "loss": 0.5647,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.13623426854610443,
      "rewards/margins": 0.7387111186981201,
      "rewards/rejected": -0.874945342540741,
      "step": 920
    },
    {
      "epoch": 0.16972351491924445,
      "grad_norm": 4.049441337585449,
      "learning_rate": 7.771554413653883e-05,
      "logits/chosen": -1.0834152698516846,
      "logits/rejected": -1.004062294960022,
      "logps/chosen": -153.20993041992188,
      "logps/rejected": -139.37106323242188,
      "loss": 0.6189,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.4666156768798828,
      "rewards/margins": 0.6328365802764893,
      "rewards/rejected": -1.099452257156372,
      "step": 930
    },
    {
      "epoch": 0.17154849895063418,
      "grad_norm": 4.602026462554932,
      "learning_rate": 7.768618095063315e-05,
      "logits/chosen": -1.0330326557159424,
      "logits/rejected": -0.9633567929267883,
      "logps/chosen": -149.52903747558594,
      "logps/rejected": -135.58322143554688,
      "loss": 0.5746,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.8979214429855347,
      "rewards/margins": 0.5535200834274292,
      "rewards/rejected": -1.4514415264129639,
      "step": 940
    },
    {
      "epoch": 0.1733734829820239,
      "grad_norm": 6.519201278686523,
      "learning_rate": 7.765681776472748e-05,
      "logits/chosen": -1.0707818269729614,
      "logits/rejected": -0.9697572588920593,
      "logps/chosen": -153.7433624267578,
      "logps/rejected": -127.81349182128906,
      "loss": 0.5402,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.43825873732566833,
      "rewards/margins": 0.7358870506286621,
      "rewards/rejected": -1.1741459369659424,
      "step": 950
    },
    {
      "epoch": 0.17519846701341363,
      "grad_norm": 2.513864517211914,
      "learning_rate": 7.76274545788218e-05,
      "logits/chosen": -1.0186506509780884,
      "logits/rejected": -0.943370521068573,
      "logps/chosen": -164.8146209716797,
      "logps/rejected": -146.15725708007812,
      "loss": 0.5453,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9959686398506165,
      "rewards/margins": 0.7188907265663147,
      "rewards/rejected": -1.7148593664169312,
      "step": 960
    },
    {
      "epoch": 0.17702345104480335,
      "grad_norm": 4.21657133102417,
      "learning_rate": 7.759809139291614e-05,
      "logits/chosen": -0.9614707827568054,
      "logits/rejected": -0.8947412371635437,
      "logps/chosen": -153.371337890625,
      "logps/rejected": -149.9136962890625,
      "loss": 0.6063,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.996606707572937,
      "rewards/margins": 0.7354462742805481,
      "rewards/rejected": -1.7320530414581299,
      "step": 970
    },
    {
      "epoch": 0.17884843507619308,
      "grad_norm": 4.630398273468018,
      "learning_rate": 7.756872820701047e-05,
      "logits/chosen": -0.987066388130188,
      "logits/rejected": -0.9320752024650574,
      "logps/chosen": -146.14894104003906,
      "logps/rejected": -142.66830444335938,
      "loss": 0.5851,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.858012318611145,
      "rewards/margins": 0.5375540852546692,
      "rewards/rejected": -1.3955663442611694,
      "step": 980
    },
    {
      "epoch": 0.1806734191075828,
      "grad_norm": 3.809091567993164,
      "learning_rate": 7.753936502110479e-05,
      "logits/chosen": -1.0651179552078247,
      "logits/rejected": -0.9703913927078247,
      "logps/chosen": -146.76388549804688,
      "logps/rejected": -125.96330261230469,
      "loss": 0.6666,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6644124388694763,
      "rewards/margins": 0.507876992225647,
      "rewards/rejected": -1.1722896099090576,
      "step": 990
    },
    {
      "epoch": 0.18249840313897253,
      "grad_norm": 3.3881638050079346,
      "learning_rate": 7.751000183519913e-05,
      "logits/chosen": -1.072084903717041,
      "logits/rejected": -0.9806444048881531,
      "logps/chosen": -168.63491821289062,
      "logps/rejected": -150.00657653808594,
      "loss": 0.5052,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.5320127010345459,
      "rewards/margins": 0.8322691917419434,
      "rewards/rejected": -1.3642820119857788,
      "step": 1000
    },
    {
      "epoch": 0.18432338717036226,
      "grad_norm": 3.9069440364837646,
      "learning_rate": 7.748063864929345e-05,
      "logits/chosen": -0.9600170254707336,
      "logits/rejected": -0.8649061322212219,
      "logps/chosen": -156.88858032226562,
      "logps/rejected": -134.83572387695312,
      "loss": 0.5306,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.8040289878845215,
      "rewards/margins": 0.8313043713569641,
      "rewards/rejected": -1.6353334188461304,
      "step": 1010
    },
    {
      "epoch": 0.18614837120175198,
      "grad_norm": 3.570797920227051,
      "learning_rate": 7.745127546338779e-05,
      "logits/chosen": -0.9946999549865723,
      "logits/rejected": -0.9542436599731445,
      "logps/chosen": -137.41030883789062,
      "logps/rejected": -138.74586486816406,
      "loss": 0.6207,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.22814972698688507,
      "rewards/margins": 0.6054962873458862,
      "rewards/rejected": -0.37734660506248474,
      "step": 1020
    },
    {
      "epoch": 0.1879733552331417,
      "grad_norm": 2.6399552822113037,
      "learning_rate": 7.742191227748212e-05,
      "logits/chosen": -1.0159658193588257,
      "logits/rejected": -0.9592778086662292,
      "logps/chosen": -141.59938049316406,
      "logps/rejected": -134.1619110107422,
      "loss": 0.4966,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.01850414089858532,
      "rewards/margins": 0.8995564579963684,
      "rewards/rejected": -0.9180606603622437,
      "step": 1030
    },
    {
      "epoch": 0.18979833926453143,
      "grad_norm": 3.199202060699463,
      "learning_rate": 7.739254909157644e-05,
      "logits/chosen": -1.0445483922958374,
      "logits/rejected": -0.9848753213882446,
      "logps/chosen": -154.9956817626953,
      "logps/rejected": -134.56690979003906,
      "loss": 0.6167,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.20970681309700012,
      "rewards/margins": 0.6580660343170166,
      "rewards/rejected": -0.4483591914176941,
      "step": 1040
    },
    {
      "epoch": 0.19162332329592116,
      "grad_norm": 2.816115617752075,
      "learning_rate": 7.736318590567078e-05,
      "logits/chosen": -1.0500504970550537,
      "logits/rejected": -0.9900611639022827,
      "logps/chosen": -128.16452026367188,
      "logps/rejected": -123.51436614990234,
      "loss": 0.5319,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.10584263503551483,
      "rewards/margins": 0.7862920165061951,
      "rewards/rejected": -0.6804494261741638,
      "step": 1050
    },
    {
      "epoch": 0.1934483073273109,
      "grad_norm": 4.754820346832275,
      "learning_rate": 7.73338227197651e-05,
      "logits/chosen": -1.053239107131958,
      "logits/rejected": -1.0174306631088257,
      "logps/chosen": -147.58908081054688,
      "logps/rejected": -143.0669403076172,
      "loss": 0.4792,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.17946331202983856,
      "rewards/margins": 0.9420546293258667,
      "rewards/rejected": -1.1215177774429321,
      "step": 1060
    },
    {
      "epoch": 0.1952732913587006,
      "grad_norm": 2.731940269470215,
      "learning_rate": 7.730445953385943e-05,
      "logits/chosen": -1.0488297939300537,
      "logits/rejected": -0.971600353717804,
      "logps/chosen": -178.4073486328125,
      "logps/rejected": -161.48875427246094,
      "loss": 0.5633,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2056328058242798,
      "rewards/margins": 0.862788200378418,
      "rewards/rejected": -2.068420886993408,
      "step": 1070
    },
    {
      "epoch": 0.19709827539009034,
      "grad_norm": 5.020088195800781,
      "learning_rate": 7.727509634795375e-05,
      "logits/chosen": -1.0977516174316406,
      "logits/rejected": -1.0483745336532593,
      "logps/chosen": -161.33383178710938,
      "logps/rejected": -167.81698608398438,
      "loss": 0.5358,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6143968105316162,
      "rewards/margins": 0.9163277745246887,
      "rewards/rejected": -2.5307247638702393,
      "step": 1080
    },
    {
      "epoch": 0.19892325942148006,
      "grad_norm": 3.4968135356903076,
      "learning_rate": 7.724573316204809e-05,
      "logits/chosen": -1.0342092514038086,
      "logits/rejected": -0.956706166267395,
      "logps/chosen": -170.5328369140625,
      "logps/rejected": -150.24893188476562,
      "loss": 0.6562,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0282912254333496,
      "rewards/margins": 0.6608744859695435,
      "rewards/rejected": -1.689165711402893,
      "step": 1090
    },
    {
      "epoch": 0.2007482434528698,
      "grad_norm": 4.050890922546387,
      "learning_rate": 7.721636997614242e-05,
      "logits/chosen": -1.049776315689087,
      "logits/rejected": -1.003607153892517,
      "logps/chosen": -145.85299682617188,
      "logps/rejected": -143.69737243652344,
      "loss": 0.5765,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9206393957138062,
      "rewards/margins": 0.8771928548812866,
      "rewards/rejected": -1.7978324890136719,
      "step": 1100
    },
    {
      "epoch": 0.20257322748425952,
      "grad_norm": 5.8668293952941895,
      "learning_rate": 7.718700679023674e-05,
      "logits/chosen": -1.1224806308746338,
      "logits/rejected": -1.1199308633804321,
      "logps/chosen": -152.51974487304688,
      "logps/rejected": -162.1540985107422,
      "loss": 0.6677,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.24550461769104,
      "rewards/margins": 0.4114247262477875,
      "rewards/rejected": -1.6569292545318604,
      "step": 1110
    },
    {
      "epoch": 0.20439821151564924,
      "grad_norm": 3.4584693908691406,
      "learning_rate": 7.715764360433108e-05,
      "logits/chosen": -1.1331462860107422,
      "logits/rejected": -1.1042017936706543,
      "logps/chosen": -158.93125915527344,
      "logps/rejected": -141.98269653320312,
      "loss": 0.6981,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.1533833742141724,
      "rewards/margins": 0.4296979308128357,
      "rewards/rejected": -1.5830812454223633,
      "step": 1120
    },
    {
      "epoch": 0.20622319554703897,
      "grad_norm": 2.652890682220459,
      "learning_rate": 7.71282804184254e-05,
      "logits/chosen": -1.0567318201065063,
      "logits/rejected": -0.9564302563667297,
      "logps/chosen": -143.2056121826172,
      "logps/rejected": -122.91682434082031,
      "loss": 0.5394,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.5126785039901733,
      "rewards/margins": 0.7483636736869812,
      "rewards/rejected": -1.2610422372817993,
      "step": 1130
    },
    {
      "epoch": 0.2080481795784287,
      "grad_norm": 4.876131534576416,
      "learning_rate": 7.709891723251974e-05,
      "logits/chosen": -1.06788969039917,
      "logits/rejected": -1.0180829763412476,
      "logps/chosen": -143.8057098388672,
      "logps/rejected": -146.43545532226562,
      "loss": 0.6081,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.9429453015327454,
      "rewards/margins": 0.47725415229797363,
      "rewards/rejected": -1.4201995134353638,
      "step": 1140
    },
    {
      "epoch": 0.20987316360981842,
      "grad_norm": 3.825059652328491,
      "learning_rate": 7.706955404661407e-05,
      "logits/chosen": -1.035664439201355,
      "logits/rejected": -0.9671958088874817,
      "logps/chosen": -152.23968505859375,
      "logps/rejected": -144.78622436523438,
      "loss": 0.4977,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9428507089614868,
      "rewards/margins": 0.8403851389884949,
      "rewards/rejected": -1.783235788345337,
      "step": 1150
    },
    {
      "epoch": 0.21169814764120815,
      "grad_norm": 4.316378593444824,
      "learning_rate": 7.70401908607084e-05,
      "logits/chosen": -0.9867626428604126,
      "logits/rejected": -0.9345486760139465,
      "logps/chosen": -155.85519409179688,
      "logps/rejected": -151.22689819335938,
      "loss": 0.4828,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1441067457199097,
      "rewards/margins": 0.9623619318008423,
      "rewards/rejected": -2.106468677520752,
      "step": 1160
    },
    {
      "epoch": 0.21352313167259787,
      "grad_norm": 4.282418727874756,
      "learning_rate": 7.701082767480273e-05,
      "logits/chosen": -1.0193512439727783,
      "logits/rejected": -0.9463318586349487,
      "logps/chosen": -148.70445251464844,
      "logps/rejected": -129.38577270507812,
      "loss": 0.5593,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.3013079166412354,
      "rewards/margins": 0.7560747861862183,
      "rewards/rejected": -2.0573830604553223,
      "step": 1170
    },
    {
      "epoch": 0.2153481157039876,
      "grad_norm": 5.945186614990234,
      "learning_rate": 7.698146448889705e-05,
      "logits/chosen": -1.0539343357086182,
      "logits/rejected": -0.9842418432235718,
      "logps/chosen": -160.66744995117188,
      "logps/rejected": -148.88926696777344,
      "loss": 0.6073,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.6396045684814453,
      "rewards/margins": 0.7140586972236633,
      "rewards/rejected": -2.3536629676818848,
      "step": 1180
    },
    {
      "epoch": 0.21717309973537732,
      "grad_norm": 4.738897800445557,
      "learning_rate": 7.695210130299138e-05,
      "logits/chosen": -1.0334587097167969,
      "logits/rejected": -0.9853776693344116,
      "logps/chosen": -151.1712646484375,
      "logps/rejected": -143.90606689453125,
      "loss": 0.4829,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2539384365081787,
      "rewards/margins": 0.9909086227416992,
      "rewards/rejected": -2.244847059249878,
      "step": 1190
    },
    {
      "epoch": 0.21899808376676705,
      "grad_norm": 3.050381660461426,
      "learning_rate": 7.692273811708572e-05,
      "logits/chosen": -1.0159270763397217,
      "logits/rejected": -0.9865077137947083,
      "logps/chosen": -155.07679748535156,
      "logps/rejected": -149.5540771484375,
      "loss": 0.6578,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.9045713543891907,
      "rewards/margins": 0.45684361457824707,
      "rewards/rejected": -1.361415147781372,
      "step": 1200
    },
    {
      "epoch": 0.22082306779815677,
      "grad_norm": 5.814291000366211,
      "learning_rate": 7.689337493118004e-05,
      "logits/chosen": -1.167236328125,
      "logits/rejected": -1.118161678314209,
      "logps/chosen": -159.14126586914062,
      "logps/rejected": -139.86822509765625,
      "loss": 0.6182,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.38013115525245667,
      "rewards/margins": 0.6361448764801025,
      "rewards/rejected": -1.0162761211395264,
      "step": 1210
    },
    {
      "epoch": 0.2226480518295465,
      "grad_norm": 2.5859384536743164,
      "learning_rate": 7.686401174527436e-05,
      "logits/chosen": -1.0348262786865234,
      "logits/rejected": -0.9677475094795227,
      "logps/chosen": -140.79458618164062,
      "logps/rejected": -127.59175109863281,
      "loss": 0.5313,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.4472106099128723,
      "rewards/margins": 0.6506692171096802,
      "rewards/rejected": -1.0978800058364868,
      "step": 1220
    },
    {
      "epoch": 0.22447303586093623,
      "grad_norm": 2.8312394618988037,
      "learning_rate": 7.683464855936869e-05,
      "logits/chosen": -1.043901801109314,
      "logits/rejected": -0.9812335968017578,
      "logps/chosen": -148.81741333007812,
      "logps/rejected": -143.94815063476562,
      "loss": 0.5485,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7554222345352173,
      "rewards/margins": 0.7701612114906311,
      "rewards/rejected": -1.5255835056304932,
      "step": 1230
    },
    {
      "epoch": 0.22629801989232595,
      "grad_norm": 4.212968349456787,
      "learning_rate": 7.680528537346303e-05,
      "logits/chosen": -1.188000202178955,
      "logits/rejected": -1.1093106269836426,
      "logps/chosen": -175.5146026611328,
      "logps/rejected": -144.84814453125,
      "loss": 0.4829,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7608209252357483,
      "rewards/margins": 0.9238684773445129,
      "rewards/rejected": -1.6846892833709717,
      "step": 1240
    },
    {
      "epoch": 0.22812300392371568,
      "grad_norm": 4.941915512084961,
      "learning_rate": 7.677592218755735e-05,
      "logits/chosen": -1.1536118984222412,
      "logits/rejected": -1.118399977684021,
      "logps/chosen": -156.32144165039062,
      "logps/rejected": -151.01983642578125,
      "loss": 0.5889,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.7932183146476746,
      "rewards/margins": 0.7699486017227173,
      "rewards/rejected": -1.563166856765747,
      "step": 1250
    },
    {
      "epoch": 0.2299479879551054,
      "grad_norm": 4.086972713470459,
      "learning_rate": 7.674655900165169e-05,
      "logits/chosen": -1.1672449111938477,
      "logits/rejected": -1.1095863580703735,
      "logps/chosen": -160.16610717773438,
      "logps/rejected": -153.9096221923828,
      "loss": 0.5678,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0849158763885498,
      "rewards/margins": 0.728373646736145,
      "rewards/rejected": -1.8132894039154053,
      "step": 1260
    },
    {
      "epoch": 0.23177297198649513,
      "grad_norm": 3.281656503677368,
      "learning_rate": 7.671719581574601e-05,
      "logits/chosen": -1.2518774271011353,
      "logits/rejected": -1.1669015884399414,
      "logps/chosen": -180.32070922851562,
      "logps/rejected": -150.27810668945312,
      "loss": 0.528,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1835063695907593,
      "rewards/margins": 0.7795807123184204,
      "rewards/rejected": -1.9630870819091797,
      "step": 1270
    },
    {
      "epoch": 0.23359795601788486,
      "grad_norm": 5.51503324508667,
      "learning_rate": 7.668783262984035e-05,
      "logits/chosen": -1.1897904872894287,
      "logits/rejected": -1.1403684616088867,
      "logps/chosen": -167.87655639648438,
      "logps/rejected": -157.0564727783203,
      "loss": 0.5182,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.7423919439315796,
      "rewards/margins": 0.8596594929695129,
      "rewards/rejected": -2.6020517349243164,
      "step": 1280
    },
    {
      "epoch": 0.23542294004927458,
      "grad_norm": 3.814683198928833,
      "learning_rate": 7.665846944393468e-05,
      "logits/chosen": -1.1177449226379395,
      "logits/rejected": -1.0757930278778076,
      "logps/chosen": -143.7214813232422,
      "logps/rejected": -141.571044921875,
      "loss": 0.5505,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6298185586929321,
      "rewards/margins": 0.8916994333267212,
      "rewards/rejected": -1.5215179920196533,
      "step": 1290
    },
    {
      "epoch": 0.2372479240806643,
      "grad_norm": 4.953035831451416,
      "learning_rate": 7.6629106258029e-05,
      "logits/chosen": -1.1001684665679932,
      "logits/rejected": -1.0623185634613037,
      "logps/chosen": -153.42514038085938,
      "logps/rejected": -143.49856567382812,
      "loss": 0.5533,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8150941729545593,
      "rewards/margins": 0.6274937987327576,
      "rewards/rejected": -1.442587971687317,
      "step": 1300
    },
    {
      "epoch": 0.23907290811205403,
      "grad_norm": 3.2956185340881348,
      "learning_rate": 7.659974307212334e-05,
      "logits/chosen": -1.168672800064087,
      "logits/rejected": -1.137891173362732,
      "logps/chosen": -160.13705444335938,
      "logps/rejected": -147.32138061523438,
      "loss": 0.6027,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1645841598510742,
      "rewards/margins": 0.6824346780776978,
      "rewards/rejected": -1.847018837928772,
      "step": 1310
    },
    {
      "epoch": 0.24089789214344373,
      "grad_norm": 3.2593672275543213,
      "learning_rate": 7.657037988621766e-05,
      "logits/chosen": -1.1614712476730347,
      "logits/rejected": -1.114899754524231,
      "logps/chosen": -151.5415802001953,
      "logps/rejected": -135.33493041992188,
      "loss": 0.5675,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0352169275283813,
      "rewards/margins": 0.654259443283081,
      "rewards/rejected": -1.6894763708114624,
      "step": 1320
    },
    {
      "epoch": 0.24272287617483346,
      "grad_norm": 3.2901740074157715,
      "learning_rate": 7.654101670031199e-05,
      "logits/chosen": -1.0805615186691284,
      "logits/rejected": -1.0305014848709106,
      "logps/chosen": -162.88951110839844,
      "logps/rejected": -139.132080078125,
      "loss": 0.6237,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1612575054168701,
      "rewards/margins": 0.45918527245521545,
      "rewards/rejected": -1.6204427480697632,
      "step": 1330
    },
    {
      "epoch": 0.24454786020622318,
      "grad_norm": 3.7461211681365967,
      "learning_rate": 7.651165351440631e-05,
      "logits/chosen": -1.0772228240966797,
      "logits/rejected": -1.0455657243728638,
      "logps/chosen": -136.6414337158203,
      "logps/rejected": -145.9207763671875,
      "loss": 0.4589,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8269087076187134,
      "rewards/margins": 0.9543544054031372,
      "rewards/rejected": -1.781262993812561,
      "step": 1340
    },
    {
      "epoch": 0.2463728442376129,
      "grad_norm": 4.355655670166016,
      "learning_rate": 7.648229032850065e-05,
      "logits/chosen": -0.9121958017349243,
      "logits/rejected": -0.8814444541931152,
      "logps/chosen": -141.194091796875,
      "logps/rejected": -159.6425018310547,
      "loss": 0.5792,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.0698964595794678,
      "rewards/margins": 0.8820303678512573,
      "rewards/rejected": -1.951926827430725,
      "step": 1350
    },
    {
      "epoch": 0.24819782826900263,
      "grad_norm": 3.7613296508789062,
      "learning_rate": 7.645292714259498e-05,
      "logits/chosen": -0.9104153513908386,
      "logits/rejected": -0.8197941780090332,
      "logps/chosen": -169.56910705566406,
      "logps/rejected": -153.7569122314453,
      "loss": 0.4802,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8265596628189087,
      "rewards/margins": 1.0745892524719238,
      "rewards/rejected": -1.9011491537094116,
      "step": 1360
    },
    {
      "epoch": 0.25002281230039236,
      "grad_norm": 2.9647669792175293,
      "learning_rate": 7.64235639566893e-05,
      "logits/chosen": -0.9101616740226746,
      "logits/rejected": -0.886187732219696,
      "logps/chosen": -148.47157287597656,
      "logps/rejected": -151.67234802246094,
      "loss": 0.5415,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.6013508439064026,
      "rewards/margins": 0.9159553647041321,
      "rewards/rejected": -1.5173060894012451,
      "step": 1370
    },
    {
      "epoch": 0.2518477963317821,
      "grad_norm": 3.7718682289123535,
      "learning_rate": 7.639420077078364e-05,
      "logits/chosen": -0.903467059135437,
      "logits/rejected": -0.8492986559867859,
      "logps/chosen": -160.37606811523438,
      "logps/rejected": -159.59091186523438,
      "loss": 0.4736,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.096798062324524,
      "rewards/margins": 1.026068091392517,
      "rewards/rejected": -2.122866153717041,
      "step": 1380
    },
    {
      "epoch": 0.2536727803631718,
      "grad_norm": 6.88701057434082,
      "learning_rate": 7.636483758487796e-05,
      "logits/chosen": -0.8878709077835083,
      "logits/rejected": -0.7848634719848633,
      "logps/chosen": -167.76199340820312,
      "logps/rejected": -147.69810485839844,
      "loss": 0.5329,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8703517913818359,
      "rewards/margins": 1.0435736179351807,
      "rewards/rejected": -1.9139254093170166,
      "step": 1390
    },
    {
      "epoch": 0.25549776439456157,
      "grad_norm": 4.120141506195068,
      "learning_rate": 7.63354743989723e-05,
      "logits/chosen": -0.8652645349502563,
      "logits/rejected": -0.7774798274040222,
      "logps/chosen": -168.4667510986328,
      "logps/rejected": -141.74974060058594,
      "loss": 0.4886,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.3873837888240814,
      "rewards/margins": 1.1275038719177246,
      "rewards/rejected": -1.5148876905441284,
      "step": 1400
    },
    {
      "epoch": 0.25732274842595126,
      "grad_norm": 3.786499261856079,
      "learning_rate": 7.630611121306663e-05,
      "logits/chosen": -0.7992655038833618,
      "logits/rejected": -0.6514250040054321,
      "logps/chosen": -180.3883819580078,
      "logps/rejected": -148.78895568847656,
      "loss": 0.5827,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8168756365776062,
      "rewards/margins": 1.1309607028961182,
      "rewards/rejected": -1.9478362798690796,
      "step": 1410
    },
    {
      "epoch": 0.259147732457341,
      "grad_norm": 4.617367267608643,
      "learning_rate": 7.627674802716095e-05,
      "logits/chosen": -0.7816836833953857,
      "logits/rejected": -0.7258449792861938,
      "logps/chosen": -150.8448944091797,
      "logps/rejected": -148.98541259765625,
      "loss": 0.5701,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.9181197881698608,
      "rewards/margins": 0.969735324382782,
      "rewards/rejected": -1.8878552913665771,
      "step": 1420
    },
    {
      "epoch": 0.2609727164887307,
      "grad_norm": 3.6252830028533936,
      "learning_rate": 7.624738484125529e-05,
      "logits/chosen": -0.7846227884292603,
      "logits/rejected": -0.7277978658676147,
      "logps/chosen": -149.29605102539062,
      "logps/rejected": -138.90626525878906,
      "loss": 0.647,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -1.433208703994751,
      "rewards/margins": 0.5624998807907104,
      "rewards/rejected": -1.9957084655761719,
      "step": 1430
    },
    {
      "epoch": 0.26279770052012047,
      "grad_norm": 3.8241090774536133,
      "learning_rate": 7.621802165534961e-05,
      "logits/chosen": -0.8280428051948547,
      "logits/rejected": -0.6917144060134888,
      "logps/chosen": -161.5277099609375,
      "logps/rejected": -132.6805419921875,
      "loss": 0.533,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5959910750389099,
      "rewards/margins": 0.9148041009902954,
      "rewards/rejected": -1.5107951164245605,
      "step": 1440
    },
    {
      "epoch": 0.26462268455151017,
      "grad_norm": 2.8044240474700928,
      "learning_rate": 7.618865846944394e-05,
      "logits/chosen": -0.818597674369812,
      "logits/rejected": -0.7916558980941772,
      "logps/chosen": -133.95635986328125,
      "logps/rejected": -137.61526489257812,
      "loss": 0.563,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.32038697600364685,
      "rewards/margins": 0.6714213490486145,
      "rewards/rejected": -0.991808295249939,
      "step": 1450
    },
    {
      "epoch": 0.2664476685828999,
      "grad_norm": 4.222986698150635,
      "learning_rate": 7.615929528353826e-05,
      "logits/chosen": -0.9217425584793091,
      "logits/rejected": -0.8169187307357788,
      "logps/chosen": -146.11337280273438,
      "logps/rejected": -131.85775756835938,
      "loss": 0.4988,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.40818819403648376,
      "rewards/margins": 1.078976035118103,
      "rewards/rejected": -1.4871642589569092,
      "step": 1460
    },
    {
      "epoch": 0.2682726526142896,
      "grad_norm": 3.6540567874908447,
      "learning_rate": 7.61299320976326e-05,
      "logits/chosen": -0.8744317293167114,
      "logits/rejected": -0.803912341594696,
      "logps/chosen": -162.2398223876953,
      "logps/rejected": -147.32974243164062,
      "loss": 0.5817,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.285925269126892,
      "rewards/margins": 0.7185949087142944,
      "rewards/rejected": -2.0045201778411865,
      "step": 1470
    },
    {
      "epoch": 0.2700976366456794,
      "grad_norm": 4.215972423553467,
      "learning_rate": 7.610056891172693e-05,
      "logits/chosen": -0.7779911160469055,
      "logits/rejected": -0.6071653366088867,
      "logps/chosen": -170.92825317382812,
      "logps/rejected": -136.02267456054688,
      "loss": 0.5693,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0541458129882812,
      "rewards/margins": 0.7643245458602905,
      "rewards/rejected": -1.8184703588485718,
      "step": 1480
    },
    {
      "epoch": 0.27192262067706907,
      "grad_norm": 3.1709625720977783,
      "learning_rate": 7.607120572582125e-05,
      "logits/chosen": -0.6681097745895386,
      "logits/rejected": -0.6224811673164368,
      "logps/chosen": -147.7676544189453,
      "logps/rejected": -148.96279907226562,
      "loss": 0.734,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.0794131755828857,
      "rewards/margins": 0.3970082700252533,
      "rewards/rejected": -1.4764217138290405,
      "step": 1490
    },
    {
      "epoch": 0.2737476047084588,
      "grad_norm": 4.4617438316345215,
      "learning_rate": 7.604184253991559e-05,
      "logits/chosen": -0.6782451272010803,
      "logits/rejected": -0.6089515089988708,
      "logps/chosen": -145.40673828125,
      "logps/rejected": -142.42860412597656,
      "loss": 0.5908,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.7519503831863403,
      "rewards/margins": 0.6257781386375427,
      "rewards/rejected": -1.3777284622192383,
      "step": 1500
    },
    {
      "epoch": 0.2755725887398485,
      "grad_norm": 4.1589460372924805,
      "learning_rate": 7.601247935400991e-05,
      "logits/chosen": -0.7416893243789673,
      "logits/rejected": -0.6494014859199524,
      "logps/chosen": -150.78646850585938,
      "logps/rejected": -146.4811553955078,
      "loss": 0.4945,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.3042999804019928,
      "rewards/margins": 1.1039373874664307,
      "rewards/rejected": -1.4082372188568115,
      "step": 1510
    },
    {
      "epoch": 0.2773975727712383,
      "grad_norm": 2.611363172531128,
      "learning_rate": 7.598311616810425e-05,
      "logits/chosen": -0.7290278673171997,
      "logits/rejected": -0.629888653755188,
      "logps/chosen": -148.12747192382812,
      "logps/rejected": -132.74961853027344,
      "loss": 0.5963,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.2707119584083557,
      "rewards/margins": 0.6901367902755737,
      "rewards/rejected": -0.9608488082885742,
      "step": 1520
    },
    {
      "epoch": 0.279222556802628,
      "grad_norm": 2.5728869438171387,
      "learning_rate": 7.595375298219858e-05,
      "logits/chosen": -0.7462584376335144,
      "logits/rejected": -0.5822986364364624,
      "logps/chosen": -163.3343505859375,
      "logps/rejected": -132.8054656982422,
      "loss": 0.5426,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.29057255387306213,
      "rewards/margins": 0.889014720916748,
      "rewards/rejected": -1.1795872449874878,
      "step": 1530
    },
    {
      "epoch": 0.28104754083401773,
      "grad_norm": 2.6636404991149902,
      "learning_rate": 7.592438979629291e-05,
      "logits/chosen": -0.7035537958145142,
      "logits/rejected": -0.6449760794639587,
      "logps/chosen": -136.0725555419922,
      "logps/rejected": -132.47720336914062,
      "loss": 0.6284,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.4918529987335205,
      "rewards/margins": 0.5927333831787109,
      "rewards/rejected": -1.0845863819122314,
      "step": 1540
    },
    {
      "epoch": 0.2828725248654074,
      "grad_norm": 2.471365451812744,
      "learning_rate": 7.589502661038724e-05,
      "logits/chosen": -0.782913327217102,
      "logits/rejected": -0.6491096019744873,
      "logps/chosen": -170.06924438476562,
      "logps/rejected": -141.99539184570312,
      "loss": 0.4747,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.5266931653022766,
      "rewards/margins": 0.8360668420791626,
      "rewards/rejected": -1.3627599477767944,
      "step": 1550
    },
    {
      "epoch": 0.2846975088967972,
      "grad_norm": 2.7349483966827393,
      "learning_rate": 7.586566342448156e-05,
      "logits/chosen": -0.701720118522644,
      "logits/rejected": -0.6067384481430054,
      "logps/chosen": -159.8256072998047,
      "logps/rejected": -140.14205932617188,
      "loss": 0.4725,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.20465902984142303,
      "rewards/margins": 1.1093547344207764,
      "rewards/rejected": -1.3140138387680054,
      "step": 1560
    },
    {
      "epoch": 0.2865224929281869,
      "grad_norm": 3.34689998626709,
      "learning_rate": 7.583630023857589e-05,
      "logits/chosen": -0.694976270198822,
      "logits/rejected": -0.6172457933425903,
      "logps/chosen": -160.68325805664062,
      "logps/rejected": -149.59921264648438,
      "loss": 0.4818,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.21678462624549866,
      "rewards/margins": 1.038736343383789,
      "rewards/rejected": -1.2555210590362549,
      "step": 1570
    },
    {
      "epoch": 0.2883474769595766,
      "grad_norm": 7.105148792266846,
      "learning_rate": 7.580693705267023e-05,
      "logits/chosen": -0.7441640496253967,
      "logits/rejected": -0.7291887998580933,
      "logps/chosen": -150.99227905273438,
      "logps/rejected": -151.11228942871094,
      "loss": 0.62,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.5123957395553589,
      "rewards/margins": 0.6613394021987915,
      "rewards/rejected": -1.17373526096344,
      "step": 1580
    },
    {
      "epoch": 0.29017246099096633,
      "grad_norm": 4.274540424346924,
      "learning_rate": 7.577757386676455e-05,
      "logits/chosen": -0.7932002544403076,
      "logits/rejected": -0.7647358179092407,
      "logps/chosen": -149.96559143066406,
      "logps/rejected": -149.10617065429688,
      "loss": 0.5727,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.2975632846355438,
      "rewards/margins": 0.7346717119216919,
      "rewards/rejected": -1.032235026359558,
      "step": 1590
    },
    {
      "epoch": 0.29199744502235603,
      "grad_norm": 3.233365535736084,
      "learning_rate": 7.574821068085887e-05,
      "logits/chosen": -0.8054699897766113,
      "logits/rejected": -0.7644975781440735,
      "logps/chosen": -143.19595336914062,
      "logps/rejected": -146.77688598632812,
      "loss": 0.663,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.4301369786262512,
      "rewards/margins": 0.760789692401886,
      "rewards/rejected": -1.1909266710281372,
      "step": 1600
    },
    {
      "epoch": 0.2938224290537458,
      "grad_norm": 3.664524555206299,
      "learning_rate": 7.57188474949532e-05,
      "logits/chosen": -0.8309651613235474,
      "logits/rejected": -0.7534620761871338,
      "logps/chosen": -151.73208618164062,
      "logps/rejected": -131.40773010253906,
      "loss": 0.6413,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.25617799162864685,
      "rewards/margins": 0.4420267939567566,
      "rewards/rejected": -0.698204755783081,
      "step": 1610
    },
    {
      "epoch": 0.2956474130851355,
      "grad_norm": 1.5563515424728394,
      "learning_rate": 7.568948430904754e-05,
      "logits/chosen": -0.7814196348190308,
      "logits/rejected": -0.7036306262016296,
      "logps/chosen": -148.74066162109375,
      "logps/rejected": -134.98416137695312,
      "loss": 0.5071,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.14735595881938934,
      "rewards/margins": 0.8475729823112488,
      "rewards/rejected": -0.9949289560317993,
      "step": 1620
    },
    {
      "epoch": 0.29747239711652523,
      "grad_norm": 1.996841549873352,
      "learning_rate": 7.566012112314186e-05,
      "logits/chosen": -0.7408260107040405,
      "logits/rejected": -0.6648949384689331,
      "logps/chosen": -141.8136444091797,
      "logps/rejected": -139.22476196289062,
      "loss": 0.5422,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.3322112262248993,
      "rewards/margins": 1.1434210538864136,
      "rewards/rejected": -1.4756324291229248,
      "step": 1630
    },
    {
      "epoch": 0.29929738114791493,
      "grad_norm": 5.107386589050293,
      "learning_rate": 7.56307579372362e-05,
      "logits/chosen": -0.6627517938613892,
      "logits/rejected": -0.6177089214324951,
      "logps/chosen": -145.02597045898438,
      "logps/rejected": -141.6858673095703,
      "loss": 0.5338,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.783762514591217,
      "rewards/margins": 1.0972387790679932,
      "rewards/rejected": -1.8810012340545654,
      "step": 1640
    },
    {
      "epoch": 0.3011223651793047,
      "grad_norm": 3.8044564723968506,
      "learning_rate": 7.560139475133052e-05,
      "logits/chosen": -0.7960379719734192,
      "logits/rejected": -0.7230075001716614,
      "logps/chosen": -149.3165283203125,
      "logps/rejected": -144.65313720703125,
      "loss": 0.7232,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -0.5284417867660522,
      "rewards/margins": 0.4815092086791992,
      "rewards/rejected": -1.009951114654541,
      "step": 1650
    },
    {
      "epoch": 0.3029473492106944,
      "grad_norm": 2.9236412048339844,
      "learning_rate": 7.557203156542486e-05,
      "logits/chosen": -0.7791401147842407,
      "logits/rejected": -0.7156437039375305,
      "logps/chosen": -150.23760986328125,
      "logps/rejected": -146.46253967285156,
      "loss": 0.5902,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.4735147953033447,
      "rewards/margins": 0.6696544885635376,
      "rewards/rejected": -1.1431692838668823,
      "step": 1660
    },
    {
      "epoch": 0.30477233324208414,
      "grad_norm": 2.5399110317230225,
      "learning_rate": 7.554266837951919e-05,
      "logits/chosen": -0.7580158710479736,
      "logits/rejected": -0.6954588294029236,
      "logps/chosen": -165.25885009765625,
      "logps/rejected": -148.50009155273438,
      "loss": 0.6203,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.2940751910209656,
      "rewards/margins": 0.5241518616676331,
      "rewards/rejected": -0.8182269930839539,
      "step": 1670
    },
    {
      "epoch": 0.30659731727347384,
      "grad_norm": 4.568339824676514,
      "learning_rate": 7.551330519361351e-05,
      "logits/chosen": -0.6944442391395569,
      "logits/rejected": -0.6433879733085632,
      "logps/chosen": -153.79995727539062,
      "logps/rejected": -143.57748413085938,
      "loss": 0.6279,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.08245524019002914,
      "rewards/margins": 0.704127311706543,
      "rewards/rejected": -0.7865825891494751,
      "step": 1680
    },
    {
      "epoch": 0.3084223013048636,
      "grad_norm": 3.7245078086853027,
      "learning_rate": 7.548394200770785e-05,
      "logits/chosen": -0.6967108845710754,
      "logits/rejected": -0.75834721326828,
      "logps/chosen": -115.54917907714844,
      "logps/rejected": -163.5332489013672,
      "loss": 0.7332,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -0.07514020055532455,
      "rewards/margins": 0.21501357853412628,
      "rewards/rejected": -0.29015377163887024,
      "step": 1690
    },
    {
      "epoch": 0.3102472853362533,
      "grad_norm": 3.796069383621216,
      "learning_rate": 7.545457882180217e-05,
      "logits/chosen": -0.7874129414558411,
      "logits/rejected": -0.7738706469535828,
      "logps/chosen": -135.6812286376953,
      "logps/rejected": -144.0625457763672,
      "loss": 0.5361,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.13548512756824493,
      "rewards/margins": 0.740211009979248,
      "rewards/rejected": -0.6047257781028748,
      "step": 1700
    },
    {
      "epoch": 0.31207226936764304,
      "grad_norm": 2.6330456733703613,
      "learning_rate": 7.54252156358965e-05,
      "logits/chosen": -0.7985886931419373,
      "logits/rejected": -0.7280192375183105,
      "logps/chosen": -145.7454376220703,
      "logps/rejected": -128.40074157714844,
      "loss": 0.4726,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 0.13476133346557617,
      "rewards/margins": 0.8543022274971008,
      "rewards/rejected": -0.7195409536361694,
      "step": 1710
    },
    {
      "epoch": 0.31389725339903274,
      "grad_norm": 3.6771321296691895,
      "learning_rate": 7.539585244999082e-05,
      "logits/chosen": -0.787510871887207,
      "logits/rejected": -0.7313063144683838,
      "logps/chosen": -142.61813354492188,
      "logps/rejected": -138.80892944335938,
      "loss": 0.586,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.386065810918808,
      "rewards/margins": 0.6639265418052673,
      "rewards/rejected": -0.27786070108413696,
      "step": 1720
    },
    {
      "epoch": 0.3157222374304225,
      "grad_norm": 2.5126404762268066,
      "learning_rate": 7.536648926408516e-05,
      "logits/chosen": -0.7509558796882629,
      "logits/rejected": -0.660598874092102,
      "logps/chosen": -151.96878051757812,
      "logps/rejected": -134.80130004882812,
      "loss": 0.524,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.3287948966026306,
      "rewards/margins": 0.9117317199707031,
      "rewards/rejected": -0.5829368829727173,
      "step": 1730
    },
    {
      "epoch": 0.3175472214618122,
      "grad_norm": 4.451335906982422,
      "learning_rate": 7.533712607817949e-05,
      "logits/chosen": -0.6753178834915161,
      "logits/rejected": -0.6489692330360413,
      "logps/chosen": -143.35202026367188,
      "logps/rejected": -138.90371704101562,
      "loss": 0.5255,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.009072286076843739,
      "rewards/margins": 0.8434039950370789,
      "rewards/rejected": -0.8524762392044067,
      "step": 1740
    },
    {
      "epoch": 0.31937220549320194,
      "grad_norm": 2.978123903274536,
      "learning_rate": 7.530776289227381e-05,
      "logits/chosen": -0.6997798681259155,
      "logits/rejected": -0.6304519176483154,
      "logps/chosen": -126.62980651855469,
      "logps/rejected": -122.7574234008789,
      "loss": 0.5239,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.3463384211063385,
      "rewards/margins": 1.078563928604126,
      "rewards/rejected": -1.424902319908142,
      "step": 1750
    },
    {
      "epoch": 0.32119718952459164,
      "grad_norm": 4.767264366149902,
      "learning_rate": 7.527839970636815e-05,
      "logits/chosen": -0.8028194308280945,
      "logits/rejected": -0.7526909708976746,
      "logps/chosen": -155.60345458984375,
      "logps/rejected": -151.13201904296875,
      "loss": 0.6384,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.07198336720466614,
      "rewards/margins": 0.8642034530639648,
      "rewards/rejected": -0.9361867904663086,
      "step": 1760
    },
    {
      "epoch": 0.3230221735559814,
      "grad_norm": 3.91294264793396,
      "learning_rate": 7.524903652046247e-05,
      "logits/chosen": -0.8430555462837219,
      "logits/rejected": -0.8015788197517395,
      "logps/chosen": -135.46737670898438,
      "logps/rejected": -138.51040649414062,
      "loss": 0.6023,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.30136770009994507,
      "rewards/margins": 0.7398300170898438,
      "rewards/rejected": -0.4384622573852539,
      "step": 1770
    },
    {
      "epoch": 0.3248471575873711,
      "grad_norm": 3.698227882385254,
      "learning_rate": 7.521967333455681e-05,
      "logits/chosen": -0.8044443130493164,
      "logits/rejected": -0.7461224794387817,
      "logps/chosen": -126.8475112915039,
      "logps/rejected": -114.08453369140625,
      "loss": 0.6773,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.6680386662483215,
      "rewards/margins": 0.47662752866744995,
      "rewards/rejected": 0.19141104817390442,
      "step": 1780
    },
    {
      "epoch": 0.32667214161876085,
      "grad_norm": 3.009636402130127,
      "learning_rate": 7.519031014865114e-05,
      "logits/chosen": -0.7749519348144531,
      "logits/rejected": -0.654521644115448,
      "logps/chosen": -152.80441284179688,
      "logps/rejected": -126.76390075683594,
      "loss": 0.4585,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": 0.5666049718856812,
      "rewards/margins": 0.8528537750244141,
      "rewards/rejected": -0.28624868392944336,
      "step": 1790
    },
    {
      "epoch": 0.32849712565015055,
      "grad_norm": 4.2417778968811035,
      "learning_rate": 7.516094696274546e-05,
      "logits/chosen": -0.7337645292282104,
      "logits/rejected": -0.6520161032676697,
      "logps/chosen": -143.8792266845703,
      "logps/rejected": -130.4830322265625,
      "loss": 0.4628,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.2069990634918213,
      "rewards/margins": 0.9552955627441406,
      "rewards/rejected": -0.7482964396476746,
      "step": 1800
    },
    {
      "epoch": 0.3303221096815403,
      "grad_norm": 6.24832820892334,
      "learning_rate": 7.51315837768398e-05,
      "logits/chosen": -0.6613579988479614,
      "logits/rejected": -0.5513156652450562,
      "logps/chosen": -145.96444702148438,
      "logps/rejected": -131.9650115966797,
      "loss": 0.5867,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.32561227679252625,
      "rewards/margins": 1.0343466997146606,
      "rewards/rejected": -0.7087342739105225,
      "step": 1810
    },
    {
      "epoch": 0.33214709371293,
      "grad_norm": 3.1756951808929443,
      "learning_rate": 7.510222059093412e-05,
      "logits/chosen": -0.681751549243927,
      "logits/rejected": -0.549851655960083,
      "logps/chosen": -149.7694549560547,
      "logps/rejected": -115.77751159667969,
      "loss": 0.5437,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.06081337854266167,
      "rewards/margins": 0.9358089566230774,
      "rewards/rejected": -0.8749955296516418,
      "step": 1820
    },
    {
      "epoch": 0.33397207774431975,
      "grad_norm": 5.948690414428711,
      "learning_rate": 7.507285740502845e-05,
      "logits/chosen": -0.686876654624939,
      "logits/rejected": -0.6099902391433716,
      "logps/chosen": -164.56271362304688,
      "logps/rejected": -151.62477111816406,
      "loss": 0.5095,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.2662549614906311,
      "rewards/margins": 0.9100015759468079,
      "rewards/rejected": -1.1762564182281494,
      "step": 1830
    },
    {
      "epoch": 0.33579706177570945,
      "grad_norm": 2.8086397647857666,
      "learning_rate": 7.504349421912277e-05,
      "logits/chosen": -0.7530263662338257,
      "logits/rejected": -0.6863178610801697,
      "logps/chosen": -157.98825073242188,
      "logps/rejected": -150.2864990234375,
      "loss": 0.5817,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5412908792495728,
      "rewards/margins": 0.840445339679718,
      "rewards/rejected": -1.381736397743225,
      "step": 1840
    },
    {
      "epoch": 0.3376220458070992,
      "grad_norm": 4.371859073638916,
      "learning_rate": 7.501413103321711e-05,
      "logits/chosen": -0.7521522045135498,
      "logits/rejected": -0.6427772045135498,
      "logps/chosen": -166.2580108642578,
      "logps/rejected": -153.15310668945312,
      "loss": 0.5645,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7104251980781555,
      "rewards/margins": 0.8652592897415161,
      "rewards/rejected": -1.5756843090057373,
      "step": 1850
    },
    {
      "epoch": 0.3394470298384889,
      "grad_norm": 3.347862958908081,
      "learning_rate": 7.498476784731144e-05,
      "logits/chosen": -0.6839358806610107,
      "logits/rejected": -0.6131359338760376,
      "logps/chosen": -147.53062438964844,
      "logps/rejected": -133.5747528076172,
      "loss": 0.5841,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.6482211351394653,
      "rewards/margins": 0.6829773187637329,
      "rewards/rejected": -1.3311984539031982,
      "step": 1860
    },
    {
      "epoch": 0.34127201386987865,
      "grad_norm": 2.0075690746307373,
      "learning_rate": 7.495540466140576e-05,
      "logits/chosen": -0.6227172613143921,
      "logits/rejected": -0.5141720175743103,
      "logps/chosen": -153.91256713867188,
      "logps/rejected": -135.96803283691406,
      "loss": 0.5222,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.30860012769699097,
      "rewards/margins": 1.1765106916427612,
      "rewards/rejected": -1.4851107597351074,
      "step": 1870
    },
    {
      "epoch": 0.34309699790126835,
      "grad_norm": 3.3490793704986572,
      "learning_rate": 7.49260414755001e-05,
      "logits/chosen": -0.6658095121383667,
      "logits/rejected": -0.6384779810905457,
      "logps/chosen": -135.82183837890625,
      "logps/rejected": -131.1819305419922,
      "loss": 0.654,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.06979485601186752,
      "rewards/margins": 0.4519144892692566,
      "rewards/rejected": -0.38211971521377563,
      "step": 1880
    },
    {
      "epoch": 0.3449219819326581,
      "grad_norm": 3.94716215133667,
      "learning_rate": 7.489667828959442e-05,
      "logits/chosen": -0.7159487009048462,
      "logits/rejected": -0.6773086190223694,
      "logps/chosen": -143.93991088867188,
      "logps/rejected": -146.49624633789062,
      "loss": 0.7441,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.2188737839460373,
      "rewards/margins": 0.31398528814315796,
      "rewards/rejected": -0.5328590869903564,
      "step": 1890
    },
    {
      "epoch": 0.3467469659640478,
      "grad_norm": 3.469808340072632,
      "learning_rate": 7.486731510368876e-05,
      "logits/chosen": -0.7729493379592896,
      "logits/rejected": -0.7150243520736694,
      "logps/chosen": -142.94436645507812,
      "logps/rejected": -148.63467407226562,
      "loss": 0.5152,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.13813257217407227,
      "rewards/margins": 0.9098296165466309,
      "rewards/rejected": -1.0479620695114136,
      "step": 1900
    },
    {
      "epoch": 0.34857194999543756,
      "grad_norm": 5.642066955566406,
      "learning_rate": 7.483795191778309e-05,
      "logits/chosen": -0.816167950630188,
      "logits/rejected": -0.7449408173561096,
      "logps/chosen": -159.9269561767578,
      "logps/rejected": -134.39779663085938,
      "loss": 0.6677,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.10938513278961182,
      "rewards/margins": 0.5437172651290894,
      "rewards/rejected": -0.653102457523346,
      "step": 1910
    },
    {
      "epoch": 0.35039693402682726,
      "grad_norm": 3.0847980976104736,
      "learning_rate": 7.480858873187742e-05,
      "logits/chosen": -0.7971467971801758,
      "logits/rejected": -0.7500187754631042,
      "logps/chosen": -144.83566284179688,
      "logps/rejected": -140.56121826171875,
      "loss": 0.5907,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.3829667568206787,
      "rewards/margins": 0.5351736545562744,
      "rewards/rejected": -0.9181405305862427,
      "step": 1920
    },
    {
      "epoch": 0.352221918058217,
      "grad_norm": 3.2219550609588623,
      "learning_rate": 7.477922554597175e-05,
      "logits/chosen": -0.7930071949958801,
      "logits/rejected": -0.6874342560768127,
      "logps/chosen": -163.3337860107422,
      "logps/rejected": -130.795654296875,
      "loss": 0.6137,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.5745497941970825,
      "rewards/margins": 0.585030734539032,
      "rewards/rejected": -1.1595804691314697,
      "step": 1930
    },
    {
      "epoch": 0.3540469020896067,
      "grad_norm": 2.8874082565307617,
      "learning_rate": 7.474986236006607e-05,
      "logits/chosen": -0.7681201100349426,
      "logits/rejected": -0.7331876754760742,
      "logps/chosen": -142.18850708007812,
      "logps/rejected": -136.14791870117188,
      "loss": 0.6228,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.5971074104309082,
      "rewards/margins": 0.46273908019065857,
      "rewards/rejected": -1.0598466396331787,
      "step": 1940
    },
    {
      "epoch": 0.35587188612099646,
      "grad_norm": 2.4443414211273193,
      "learning_rate": 7.47204991741604e-05,
      "logits/chosen": -0.7785833477973938,
      "logits/rejected": -0.6890150308609009,
      "logps/chosen": -152.5343017578125,
      "logps/rejected": -132.3754119873047,
      "loss": 0.5261,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.16812457144260406,
      "rewards/margins": 0.8493984937667847,
      "rewards/rejected": -0.6812740564346313,
      "step": 1950
    },
    {
      "epoch": 0.35769687015238616,
      "grad_norm": 3.3277699947357178,
      "learning_rate": 7.469113598825474e-05,
      "logits/chosen": -0.7191213369369507,
      "logits/rejected": -0.6247493028640747,
      "logps/chosen": -144.0257568359375,
      "logps/rejected": -130.63873291015625,
      "loss": 0.5331,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.07990752160549164,
      "rewards/margins": 0.8454455137252808,
      "rewards/rejected": -0.9253530502319336,
      "step": 1960
    },
    {
      "epoch": 0.3595218541837759,
      "grad_norm": 2.595869541168213,
      "learning_rate": 7.466177280234906e-05,
      "logits/chosen": -0.7446668744087219,
      "logits/rejected": -0.6939536929130554,
      "logps/chosen": -137.2421112060547,
      "logps/rejected": -138.15701293945312,
      "loss": 0.6454,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01567806862294674,
      "rewards/margins": 0.49769043922424316,
      "rewards/rejected": -0.4820123612880707,
      "step": 1970
    },
    {
      "epoch": 0.3613468382151656,
      "grad_norm": 3.6983160972595215,
      "learning_rate": 7.463240961644338e-05,
      "logits/chosen": -0.6382211446762085,
      "logits/rejected": -0.5801684260368347,
      "logps/chosen": -148.11607360839844,
      "logps/rejected": -142.04400634765625,
      "loss": 0.5774,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.17169740796089172,
      "rewards/margins": 0.6901152729988098,
      "rewards/rejected": -0.5184177756309509,
      "step": 1980
    },
    {
      "epoch": 0.36317182224655536,
      "grad_norm": 1.7447799444198608,
      "learning_rate": 7.460304643053771e-05,
      "logits/chosen": -0.6824458837509155,
      "logits/rejected": -0.5862237215042114,
      "logps/chosen": -143.7006072998047,
      "logps/rejected": -134.8063201904297,
      "loss": 0.4383,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": 0.046314891427755356,
      "rewards/margins": 1.218442440032959,
      "rewards/rejected": -1.172127366065979,
      "step": 1990
    },
    {
      "epoch": 0.36499680627794506,
      "grad_norm": 5.09261417388916,
      "learning_rate": 7.457368324463205e-05,
      "logits/chosen": -0.5395064353942871,
      "logits/rejected": -0.41035670042037964,
      "logps/chosen": -179.46340942382812,
      "logps/rejected": -145.0850372314453,
      "loss": 0.592,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.5290479063987732,
      "rewards/margins": 0.9376784563064575,
      "rewards/rejected": -1.4667264223098755,
      "step": 2000
    },
    {
      "epoch": 0.3668217903093348,
      "grad_norm": 2.290578603744507,
      "learning_rate": 7.454432005872637e-05,
      "logits/chosen": -0.7296543121337891,
      "logits/rejected": -0.6036590933799744,
      "logps/chosen": -144.7022705078125,
      "logps/rejected": -124.10356140136719,
      "loss": 0.5835,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.13831865787506104,
      "rewards/margins": 0.7774725556373596,
      "rewards/rejected": -0.9157912135124207,
      "step": 2010
    },
    {
      "epoch": 0.3686467743407245,
      "grad_norm": 3.871314525604248,
      "learning_rate": 7.451495687282071e-05,
      "logits/chosen": -0.623369038105011,
      "logits/rejected": -0.5655662417411804,
      "logps/chosen": -136.9499053955078,
      "logps/rejected": -133.31088256835938,
      "loss": 0.521,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.19901448488235474,
      "rewards/margins": 1.0759665966033936,
      "rewards/rejected": -1.2749810218811035,
      "step": 2020
    },
    {
      "epoch": 0.37047175837211427,
      "grad_norm": 3.240462064743042,
      "learning_rate": 7.448559368691503e-05,
      "logits/chosen": -0.6102685928344727,
      "logits/rejected": -0.530996561050415,
      "logps/chosen": -140.4427490234375,
      "logps/rejected": -131.2730712890625,
      "loss": 0.6013,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0859848260879517,
      "rewards/margins": 0.6495922207832336,
      "rewards/rejected": -1.7355769872665405,
      "step": 2030
    },
    {
      "epoch": 0.37229674240350397,
      "grad_norm": 4.2871994972229,
      "learning_rate": 7.445623050100937e-05,
      "logits/chosen": -0.6758203506469727,
      "logits/rejected": -0.6063398122787476,
      "logps/chosen": -166.43043518066406,
      "logps/rejected": -162.142333984375,
      "loss": 0.5545,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.006313681602478,
      "rewards/margins": 0.6439013481140137,
      "rewards/rejected": -1.6502149105072021,
      "step": 2040
    },
    {
      "epoch": 0.3741217264348937,
      "grad_norm": 4.814879417419434,
      "learning_rate": 7.44268673151037e-05,
      "logits/chosen": -0.6357661485671997,
      "logits/rejected": -0.5468010902404785,
      "logps/chosen": -175.61984252929688,
      "logps/rejected": -150.16810607910156,
      "loss": 0.6859,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -1.1317071914672852,
      "rewards/margins": 0.5685523152351379,
      "rewards/rejected": -1.7002595663070679,
      "step": 2050
    },
    {
      "epoch": 0.3759467104662834,
      "grad_norm": 3.512814998626709,
      "learning_rate": 7.439750412919802e-05,
      "logits/chosen": -0.731078028678894,
      "logits/rejected": -0.6681652069091797,
      "logps/chosen": -147.86886596679688,
      "logps/rejected": -156.97415161132812,
      "loss": 0.5355,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.20189805328845978,
      "rewards/margins": 0.7051829099655151,
      "rewards/rejected": -0.9070809483528137,
      "step": 2060
    },
    {
      "epoch": 0.37777169449767317,
      "grad_norm": 3.9312572479248047,
      "learning_rate": 7.436814094329236e-05,
      "logits/chosen": -0.7550873160362244,
      "logits/rejected": -0.6775050163269043,
      "logps/chosen": -140.46713256835938,
      "logps/rejected": -130.53076171875,
      "loss": 0.5651,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.012782469391822815,
      "rewards/margins": 0.759941577911377,
      "rewards/rejected": -0.7727240920066833,
      "step": 2070
    },
    {
      "epoch": 0.37959667852906287,
      "grad_norm": 2.5558664798736572,
      "learning_rate": 7.433877775738668e-05,
      "logits/chosen": -0.7032366991043091,
      "logits/rejected": -0.6391280293464661,
      "logps/chosen": -143.0233917236328,
      "logps/rejected": -134.13742065429688,
      "loss": 0.6326,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.4676262438297272,
      "rewards/margins": 0.5131699442863464,
      "rewards/rejected": -0.9807961583137512,
      "step": 2080
    },
    {
      "epoch": 0.3814216625604526,
      "grad_norm": 5.949202060699463,
      "learning_rate": 7.430941457148101e-05,
      "logits/chosen": -0.6877040266990662,
      "logits/rejected": -0.5886898040771484,
      "logps/chosen": -165.067138671875,
      "logps/rejected": -157.62954711914062,
      "loss": 0.5396,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.1140892282128334,
      "rewards/margins": 0.944752037525177,
      "rewards/rejected": -1.058841347694397,
      "step": 2090
    },
    {
      "epoch": 0.3832466465918423,
      "grad_norm": 6.965453147888184,
      "learning_rate": 7.428005138557533e-05,
      "logits/chosen": -0.6746832132339478,
      "logits/rejected": -0.5777593851089478,
      "logps/chosen": -169.93283081054688,
      "logps/rejected": -149.54397583007812,
      "loss": 0.5647,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.3727281987667084,
      "rewards/margins": 0.8356304168701172,
      "rewards/rejected": -1.2083587646484375,
      "step": 2100
    },
    {
      "epoch": 0.385071630623232,
      "grad_norm": 2.3648195266723633,
      "learning_rate": 7.425068819966967e-05,
      "logits/chosen": -0.699871838092804,
      "logits/rejected": -0.6047069430351257,
      "logps/chosen": -156.87705993652344,
      "logps/rejected": -136.95738220214844,
      "loss": 0.6637,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.32128220796585083,
      "rewards/margins": 0.5370487570762634,
      "rewards/rejected": -0.8583309054374695,
      "step": 2110
    },
    {
      "epoch": 0.3868966146546218,
      "grad_norm": 3.0902597904205322,
      "learning_rate": 7.4221325013764e-05,
      "logits/chosen": -0.7037476301193237,
      "logits/rejected": -0.6118631362915039,
      "logps/chosen": -159.98162841796875,
      "logps/rejected": -143.39598083496094,
      "loss": 0.6132,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.1537812352180481,
      "rewards/margins": 0.5736729502677917,
      "rewards/rejected": -0.41989168524742126,
      "step": 2120
    },
    {
      "epoch": 0.38872159868601147,
      "grad_norm": 1.9531582593917847,
      "learning_rate": 7.419196182785833e-05,
      "logits/chosen": -0.6970584392547607,
      "logits/rejected": -0.586270272731781,
      "logps/chosen": -152.70912170410156,
      "logps/rejected": -142.89208984375,
      "loss": 0.4703,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.0673278346657753,
      "rewards/margins": 1.0370867252349854,
      "rewards/rejected": -0.9697589874267578,
      "step": 2130
    },
    {
      "epoch": 0.3905465827174012,
      "grad_norm": 4.018420219421387,
      "learning_rate": 7.416259864195266e-05,
      "logits/chosen": -0.5340948700904846,
      "logits/rejected": -0.4984036982059479,
      "logps/chosen": -145.14617919921875,
      "logps/rejected": -148.3107147216797,
      "loss": 0.5428,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.521224319934845,
      "rewards/margins": 0.8375752568244934,
      "rewards/rejected": -1.3587995767593384,
      "step": 2140
    },
    {
      "epoch": 0.3923715667487909,
      "grad_norm": 2.326563596725464,
      "learning_rate": 7.4133235456047e-05,
      "logits/chosen": -0.5942973494529724,
      "logits/rejected": -0.5592454075813293,
      "logps/chosen": -154.4207305908203,
      "logps/rejected": -157.91006469726562,
      "loss": 0.6649,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.5276626348495483,
      "rewards/margins": 0.5585580468177795,
      "rewards/rejected": -1.086220622062683,
      "step": 2150
    },
    {
      "epoch": 0.3941965507801807,
      "grad_norm": 5.044795036315918,
      "learning_rate": 7.410387227014132e-05,
      "logits/chosen": -0.5506665706634521,
      "logits/rejected": -0.48381227254867554,
      "logps/chosen": -142.72364807128906,
      "logps/rejected": -132.78294372558594,
      "loss": 0.5934,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6638444662094116,
      "rewards/margins": 0.6685453653335571,
      "rewards/rejected": -1.3323899507522583,
      "step": 2160
    },
    {
      "epoch": 0.3960215348115704,
      "grad_norm": 4.003243923187256,
      "learning_rate": 7.407450908423565e-05,
      "logits/chosen": -0.5734995007514954,
      "logits/rejected": -0.4829063415527344,
      "logps/chosen": -146.1262664794922,
      "logps/rejected": -123.0604476928711,
      "loss": 0.6066,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.438831627368927,
      "rewards/margins": 0.59507817029953,
      "rewards/rejected": -1.033909797668457,
      "step": 2170
    },
    {
      "epoch": 0.39784651884296013,
      "grad_norm": 5.61721134185791,
      "learning_rate": 7.404514589832997e-05,
      "logits/chosen": -0.5724119544029236,
      "logits/rejected": -0.4995972216129303,
      "logps/chosen": -159.56448364257812,
      "logps/rejected": -144.52488708496094,
      "loss": 0.6289,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.508658766746521,
      "rewards/margins": 0.6324828267097473,
      "rewards/rejected": -1.141141653060913,
      "step": 2180
    },
    {
      "epoch": 0.3996715028743498,
      "grad_norm": 2.555440664291382,
      "learning_rate": 7.401578271242431e-05,
      "logits/chosen": -0.6087273955345154,
      "logits/rejected": -0.5155989527702332,
      "logps/chosen": -151.4270782470703,
      "logps/rejected": -137.81692504882812,
      "loss": 0.5379,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5831995606422424,
      "rewards/margins": 0.9269992709159851,
      "rewards/rejected": -1.5101988315582275,
      "step": 2190
    },
    {
      "epoch": 0.4014964869057396,
      "grad_norm": 3.486456871032715,
      "learning_rate": 7.398641952651863e-05,
      "logits/chosen": -0.6934180855751038,
      "logits/rejected": -0.6447641849517822,
      "logps/chosen": -130.87445068359375,
      "logps/rejected": -135.62828063964844,
      "loss": 0.6232,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.3722306787967682,
      "rewards/margins": 0.5912906527519226,
      "rewards/rejected": -0.9635213017463684,
      "step": 2200
    },
    {
      "epoch": 0.4033214709371293,
      "grad_norm": 2.7604832649230957,
      "learning_rate": 7.395705634061296e-05,
      "logits/chosen": -0.7014784216880798,
      "logits/rejected": -0.5860210657119751,
      "logps/chosen": -168.7037353515625,
      "logps/rejected": -144.86570739746094,
      "loss": 0.5096,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.4445107877254486,
      "rewards/margins": 0.8611415028572083,
      "rewards/rejected": -1.3056522607803345,
      "step": 2210
    },
    {
      "epoch": 0.40514645496851903,
      "grad_norm": 3.7508127689361572,
      "learning_rate": 7.393062947329786e-05,
      "logits/chosen": -0.6194111108779907,
      "logits/rejected": -0.5287784337997437,
      "logps/chosen": -160.7008056640625,
      "logps/rejected": -143.0409393310547,
      "loss": 0.5499,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8275142908096313,
      "rewards/margins": 1.0775327682495117,
      "rewards/rejected": -1.905046820640564,
      "step": 2220
    },
    {
      "epoch": 0.40697143899990873,
      "grad_norm": 3.5904626846313477,
      "learning_rate": 7.390126628739218e-05,
      "logits/chosen": -0.6467819213867188,
      "logits/rejected": -0.52931147813797,
      "logps/chosen": -153.0914306640625,
      "logps/rejected": -136.16195678710938,
      "loss": 0.6274,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5160499811172485,
      "rewards/margins": 0.6282052397727966,
      "rewards/rejected": -1.14425528049469,
      "step": 2230
    },
    {
      "epoch": 0.4087964230312985,
      "grad_norm": 6.100580215454102,
      "learning_rate": 7.387190310148652e-05,
      "logits/chosen": -0.7122694849967957,
      "logits/rejected": -0.663392186164856,
      "logps/chosen": -140.12045288085938,
      "logps/rejected": -131.7053680419922,
      "loss": 0.5975,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.17334046959877014,
      "rewards/margins": 0.7757099866867065,
      "rewards/rejected": -0.9490504264831543,
      "step": 2240
    },
    {
      "epoch": 0.4106214070626882,
      "grad_norm": 3.376011371612549,
      "learning_rate": 7.384253991558085e-05,
      "logits/chosen": -0.7505723237991333,
      "logits/rejected": -0.634682297706604,
      "logps/chosen": -153.73912048339844,
      "logps/rejected": -130.01882934570312,
      "loss": 0.5975,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.3664490580558777,
      "rewards/margins": 0.6901370286941528,
      "rewards/rejected": -1.0565860271453857,
      "step": 2250
    },
    {
      "epoch": 0.41244639109407794,
      "grad_norm": 5.2770562171936035,
      "learning_rate": 7.381317672967518e-05,
      "logits/chosen": -0.7036348581314087,
      "logits/rejected": -0.6496163606643677,
      "logps/chosen": -153.8267364501953,
      "logps/rejected": -158.8370819091797,
      "loss": 0.5391,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.5170730352401733,
      "rewards/margins": 0.8428946733474731,
      "rewards/rejected": -1.359967827796936,
      "step": 2260
    },
    {
      "epoch": 0.41427137512546763,
      "grad_norm": 3.215642213821411,
      "learning_rate": 7.378381354376951e-05,
      "logits/chosen": -0.696725606918335,
      "logits/rejected": -0.5874724984169006,
      "logps/chosen": -152.78073120117188,
      "logps/rejected": -130.05892944335938,
      "loss": 0.5896,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7955839037895203,
      "rewards/margins": 0.5910943150520325,
      "rewards/rejected": -1.3866782188415527,
      "step": 2270
    },
    {
      "epoch": 0.4160963591568574,
      "grad_norm": 2.7005367279052734,
      "learning_rate": 7.375445035786383e-05,
      "logits/chosen": -0.7039961218833923,
      "logits/rejected": -0.6402538418769836,
      "logps/chosen": -135.19186401367188,
      "logps/rejected": -123.97344970703125,
      "loss": 0.5532,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.600503146648407,
      "rewards/margins": 0.7733690142631531,
      "rewards/rejected": -1.3738722801208496,
      "step": 2280
    },
    {
      "epoch": 0.4179213431882471,
      "grad_norm": 4.664793014526367,
      "learning_rate": 7.372508717195816e-05,
      "logits/chosen": -0.6998586654663086,
      "logits/rejected": -0.5891596674919128,
      "logps/chosen": -163.15078735351562,
      "logps/rejected": -144.03103637695312,
      "loss": 0.5013,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6029291152954102,
      "rewards/margins": 0.8505878448486328,
      "rewards/rejected": -1.4535170793533325,
      "step": 2290
    },
    {
      "epoch": 0.41974632721963684,
      "grad_norm": 2.6652824878692627,
      "learning_rate": 7.36957239860525e-05,
      "logits/chosen": -0.6621743440628052,
      "logits/rejected": -0.6185258626937866,
      "logps/chosen": -148.1436767578125,
      "logps/rejected": -148.12008666992188,
      "loss": 0.5356,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8789350390434265,
      "rewards/margins": 0.7011271715164185,
      "rewards/rejected": -1.5800621509552002,
      "step": 2300
    },
    {
      "epoch": 0.42157131125102654,
      "grad_norm": 3.9935576915740967,
      "learning_rate": 7.366636080014682e-05,
      "logits/chosen": -0.6559274792671204,
      "logits/rejected": -0.6013444066047668,
      "logps/chosen": -148.65670776367188,
      "logps/rejected": -134.7237548828125,
      "loss": 0.6202,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5072080492973328,
      "rewards/margins": 0.7727264761924744,
      "rewards/rejected": -1.2799346446990967,
      "step": 2310
    },
    {
      "epoch": 0.4233962952824163,
      "grad_norm": 4.5056915283203125,
      "learning_rate": 7.363699761424115e-05,
      "logits/chosen": -0.6601952910423279,
      "logits/rejected": -0.603937566280365,
      "logps/chosen": -142.78680419921875,
      "logps/rejected": -135.55517578125,
      "loss": 0.6145,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.4575555920600891,
      "rewards/margins": 0.6252661943435669,
      "rewards/rejected": -1.0828216075897217,
      "step": 2320
    },
    {
      "epoch": 0.425221279313806,
      "grad_norm": 2.925950527191162,
      "learning_rate": 7.360763442833547e-05,
      "logits/chosen": -0.6506463289260864,
      "logits/rejected": -0.5959860682487488,
      "logps/chosen": -147.83935546875,
      "logps/rejected": -125.3599853515625,
      "loss": 0.6316,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.41577476263046265,
      "rewards/margins": 0.5169851183891296,
      "rewards/rejected": -0.9327598810195923,
      "step": 2330
    },
    {
      "epoch": 0.42704626334519574,
      "grad_norm": 1.8818941116333008,
      "learning_rate": 7.357827124242981e-05,
      "logits/chosen": -0.6726404428482056,
      "logits/rejected": -0.6475046277046204,
      "logps/chosen": -147.0395965576172,
      "logps/rejected": -152.44473266601562,
      "loss": 0.527,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.22127433121204376,
      "rewards/margins": 0.9731857180595398,
      "rewards/rejected": -1.1944599151611328,
      "step": 2340
    },
    {
      "epoch": 0.42887124737658544,
      "grad_norm": 3.3686249256134033,
      "learning_rate": 7.354890805652413e-05,
      "logits/chosen": -0.6803114414215088,
      "logits/rejected": -0.6158112287521362,
      "logps/chosen": -152.49923706054688,
      "logps/rejected": -145.832275390625,
      "loss": 0.5337,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.3293211758136749,
      "rewards/margins": 1.0540916919708252,
      "rewards/rejected": -1.3834127187728882,
      "step": 2350
    },
    {
      "epoch": 0.4306962314079752,
      "grad_norm": 2.196608543395996,
      "learning_rate": 7.351954487061847e-05,
      "logits/chosen": -0.6743851900100708,
      "logits/rejected": -0.6248313784599304,
      "logps/chosen": -140.79690551757812,
      "logps/rejected": -141.9838104248047,
      "loss": 0.5187,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.5646274089813232,
      "rewards/margins": 1.058763027191162,
      "rewards/rejected": -1.623390555381775,
      "step": 2360
    },
    {
      "epoch": 0.4325212154393649,
      "grad_norm": 3.6400861740112305,
      "learning_rate": 7.34901816847128e-05,
      "logits/chosen": -0.6420709490776062,
      "logits/rejected": -0.5414714217185974,
      "logps/chosen": -147.90928649902344,
      "logps/rejected": -127.9409408569336,
      "loss": 0.4438,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.5230439305305481,
      "rewards/margins": 1.2044622898101807,
      "rewards/rejected": -1.7275060415267944,
      "step": 2370
    },
    {
      "epoch": 0.43434619947075465,
      "grad_norm": 4.400579452514648,
      "learning_rate": 7.346081849880713e-05,
      "logits/chosen": -0.6692538857460022,
      "logits/rejected": -0.5551987886428833,
      "logps/chosen": -156.2931365966797,
      "logps/rejected": -136.1761932373047,
      "loss": 0.5869,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.8153865933418274,
      "rewards/margins": 0.7797976732254028,
      "rewards/rejected": -1.5951842069625854,
      "step": 2380
    },
    {
      "epoch": 0.43617118350214434,
      "grad_norm": 3.5810611248016357,
      "learning_rate": 7.343145531290146e-05,
      "logits/chosen": -0.6430825591087341,
      "logits/rejected": -0.5013296008110046,
      "logps/chosen": -176.41322326660156,
      "logps/rejected": -134.33572387695312,
      "loss": 0.4906,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9400852918624878,
      "rewards/margins": 1.0682414770126343,
      "rewards/rejected": -2.008327007293701,
      "step": 2390
    },
    {
      "epoch": 0.4379961675335341,
      "grad_norm": 4.912792682647705,
      "learning_rate": 7.340209212699578e-05,
      "logits/chosen": -0.624430239200592,
      "logits/rejected": -0.6014470458030701,
      "logps/chosen": -147.25375366210938,
      "logps/rejected": -147.80535888671875,
      "loss": 0.5699,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.859756588935852,
      "rewards/margins": 0.8806560635566711,
      "rewards/rejected": -1.740412712097168,
      "step": 2400
    },
    {
      "epoch": 0.4398211515649238,
      "grad_norm": 3.304882526397705,
      "learning_rate": 7.337272894109011e-05,
      "logits/chosen": -0.716737687587738,
      "logits/rejected": -0.6425653696060181,
      "logps/chosen": -152.04953002929688,
      "logps/rejected": -136.28268432617188,
      "loss": 0.5597,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.539681077003479,
      "rewards/margins": 0.8063451051712036,
      "rewards/rejected": -1.3460261821746826,
      "step": 2410
    },
    {
      "epoch": 0.44164613559631355,
      "grad_norm": 3.733015775680542,
      "learning_rate": 7.334336575518445e-05,
      "logits/chosen": -0.6467206478118896,
      "logits/rejected": -0.5843666791915894,
      "logps/chosen": -132.8911895751953,
      "logps/rejected": -130.39793395996094,
      "loss": 0.5401,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.24683217704296112,
      "rewards/margins": 1.143761396408081,
      "rewards/rejected": -1.3905935287475586,
      "step": 2420
    },
    {
      "epoch": 0.44347111962770325,
      "grad_norm": 2.224836587905884,
      "learning_rate": 7.331400256927877e-05,
      "logits/chosen": -0.6653000712394714,
      "logits/rejected": -0.6499640345573425,
      "logps/chosen": -152.08432006835938,
      "logps/rejected": -159.20443725585938,
      "loss": 0.4949,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.44780978560447693,
      "rewards/margins": 1.0464787483215332,
      "rewards/rejected": -1.494288682937622,
      "step": 2430
    },
    {
      "epoch": 0.445296103659093,
      "grad_norm": 3.6708827018737793,
      "learning_rate": 7.32846393833731e-05,
      "logits/chosen": -0.7020033597946167,
      "logits/rejected": -0.6403369307518005,
      "logps/chosen": -146.95693969726562,
      "logps/rejected": -142.54067993164062,
      "loss": 0.6119,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.2489914894104004,
      "rewards/margins": 0.7607144713401794,
      "rewards/rejected": -1.0097060203552246,
      "step": 2440
    },
    {
      "epoch": 0.4471210876904827,
      "grad_norm": 4.274928092956543,
      "learning_rate": 7.325527619746743e-05,
      "logits/chosen": -0.6967611908912659,
      "logits/rejected": -0.66847825050354,
      "logps/chosen": -145.24241638183594,
      "logps/rejected": -144.51229858398438,
      "loss": 0.5724,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.9434070587158203,
      "rewards/margins": 0.8007663488388062,
      "rewards/rejected": -1.7441734075546265,
      "step": 2450
    },
    {
      "epoch": 0.44894607172187245,
      "grad_norm": 4.2500810623168945,
      "learning_rate": 7.322591301156176e-05,
      "logits/chosen": -0.7909157276153564,
      "logits/rejected": -0.6893015503883362,
      "logps/chosen": -172.96856689453125,
      "logps/rejected": -144.44577026367188,
      "loss": 0.6679,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.717963695526123,
      "rewards/margins": 0.5240525007247925,
      "rewards/rejected": -1.242016077041626,
      "step": 2460
    },
    {
      "epoch": 0.45077105575326215,
      "grad_norm": 2.833805799484253,
      "learning_rate": 7.31965498256561e-05,
      "logits/chosen": -0.7677038908004761,
      "logits/rejected": -0.6650553941726685,
      "logps/chosen": -165.11880493164062,
      "logps/rejected": -139.41065979003906,
      "loss": 0.5814,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.7998901009559631,
      "rewards/margins": 0.7006889581680298,
      "rewards/rejected": -1.5005789995193481,
      "step": 2470
    },
    {
      "epoch": 0.4525960397846519,
      "grad_norm": 4.210772514343262,
      "learning_rate": 7.316718663975042e-05,
      "logits/chosen": -0.7713340520858765,
      "logits/rejected": -0.7212933301925659,
      "logps/chosen": -154.59323120117188,
      "logps/rejected": -151.29986572265625,
      "loss": 0.5716,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.8010939359664917,
      "rewards/margins": 0.7029439210891724,
      "rewards/rejected": -1.504037857055664,
      "step": 2480
    },
    {
      "epoch": 0.4544210238160416,
      "grad_norm": 3.2855257987976074,
      "learning_rate": 7.313782345384476e-05,
      "logits/chosen": -0.7113465666770935,
      "logits/rejected": -0.6674953103065491,
      "logps/chosen": -146.13514709472656,
      "logps/rejected": -144.42063903808594,
      "loss": 0.4996,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6100684404373169,
      "rewards/margins": 0.997553825378418,
      "rewards/rejected": -1.6076223850250244,
      "step": 2490
    },
    {
      "epoch": 0.45624600784743136,
      "grad_norm": 3.2827532291412354,
      "learning_rate": 7.310846026793908e-05,
      "logits/chosen": -0.7321363091468811,
      "logits/rejected": -0.6274175047874451,
      "logps/chosen": -147.46380615234375,
      "logps/rejected": -124.7658920288086,
      "loss": 0.5034,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8099678754806519,
      "rewards/margins": 0.8947059512138367,
      "rewards/rejected": -1.7046737670898438,
      "step": 2500
    },
    {
      "epoch": 0.45807099187882105,
      "grad_norm": 5.256844520568848,
      "learning_rate": 7.307909708203341e-05,
      "logits/chosen": -0.6286723613739014,
      "logits/rejected": -0.45387402176856995,
      "logps/chosen": -177.7067413330078,
      "logps/rejected": -144.3550567626953,
      "loss": 0.5582,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.927302360534668,
      "rewards/margins": 1.1745027303695679,
      "rewards/rejected": -2.1018052101135254,
      "step": 2510
    },
    {
      "epoch": 0.4598959759102108,
      "grad_norm": 3.1962358951568604,
      "learning_rate": 7.304973389612773e-05,
      "logits/chosen": -0.6770737767219543,
      "logits/rejected": -0.557721734046936,
      "logps/chosen": -172.63711547851562,
      "logps/rejected": -145.94000244140625,
      "loss": 0.5606,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.26477867364883423,
      "rewards/margins": 0.8290731310844421,
      "rewards/rejected": -1.0938518047332764,
      "step": 2520
    },
    {
      "epoch": 0.4617209599416005,
      "grad_norm": 3.784651756286621,
      "learning_rate": 7.302037071022207e-05,
      "logits/chosen": -0.7274614572525024,
      "logits/rejected": -0.6739749908447266,
      "logps/chosen": -156.01316833496094,
      "logps/rejected": -145.26324462890625,
      "loss": 0.6132,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.1503475457429886,
      "rewards/margins": 0.7626832127571106,
      "rewards/rejected": -0.9130308032035828,
      "step": 2530
    },
    {
      "epoch": 0.46354594397299026,
      "grad_norm": 1.5679956674575806,
      "learning_rate": 7.29910075243164e-05,
      "logits/chosen": -0.7110081911087036,
      "logits/rejected": -0.6343948245048523,
      "logps/chosen": -153.70761108398438,
      "logps/rejected": -139.27023315429688,
      "loss": 0.6049,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.5895023345947266,
      "rewards/margins": 0.6252359747886658,
      "rewards/rejected": -1.214738368988037,
      "step": 2540
    },
    {
      "epoch": 0.46537092800437996,
      "grad_norm": 3.7304131984710693,
      "learning_rate": 7.296164433841072e-05,
      "logits/chosen": -0.6801994442939758,
      "logits/rejected": -0.5813683271408081,
      "logps/chosen": -137.86514282226562,
      "logps/rejected": -130.187255859375,
      "loss": 0.5095,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.659759521484375,
      "rewards/margins": 0.8034418225288391,
      "rewards/rejected": -1.4632012844085693,
      "step": 2550
    },
    {
      "epoch": 0.4671959120357697,
      "grad_norm": 3.8424603939056396,
      "learning_rate": 7.293228115250504e-05,
      "logits/chosen": -0.6254434585571289,
      "logits/rejected": -0.5202309489250183,
      "logps/chosen": -144.88226318359375,
      "logps/rejected": -129.55030822753906,
      "loss": 0.5721,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.920464813709259,
      "rewards/margins": 0.9038735628128052,
      "rewards/rejected": -1.8243385553359985,
      "step": 2560
    },
    {
      "epoch": 0.4690208960671594,
      "grad_norm": 1.877216100692749,
      "learning_rate": 7.290291796659938e-05,
      "logits/chosen": -0.6140252947807312,
      "logits/rejected": -0.5952880382537842,
      "logps/chosen": -149.44790649414062,
      "logps/rejected": -161.8412322998047,
      "loss": 0.7149,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.0107638835906982,
      "rewards/margins": 0.5944310426712036,
      "rewards/rejected": -1.6051948070526123,
      "step": 2570
    },
    {
      "epoch": 0.47084588009854916,
      "grad_norm": 1.9495913982391357,
      "learning_rate": 7.287355478069371e-05,
      "logits/chosen": -0.6834467053413391,
      "logits/rejected": -0.5888972282409668,
      "logps/chosen": -149.0191650390625,
      "logps/rejected": -138.4154510498047,
      "loss": 0.5084,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9970537424087524,
      "rewards/margins": 0.7896490693092346,
      "rewards/rejected": -1.7867025136947632,
      "step": 2580
    },
    {
      "epoch": 0.47267086412993886,
      "grad_norm": 2.2021114826202393,
      "learning_rate": 7.284419159478804e-05,
      "logits/chosen": -0.5926562547683716,
      "logits/rejected": -0.5274113416671753,
      "logps/chosen": -149.17738342285156,
      "logps/rejected": -140.40817260742188,
      "loss": 0.5369,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.3888745307922363,
      "rewards/margins": 0.7977504730224609,
      "rewards/rejected": -2.1866250038146973,
      "step": 2590
    },
    {
      "epoch": 0.4744958481613286,
      "grad_norm": 2.583075523376465,
      "learning_rate": 7.281482840888237e-05,
      "logits/chosen": -0.6329566836357117,
      "logits/rejected": -0.5873833298683167,
      "logps/chosen": -155.52255249023438,
      "logps/rejected": -149.74038696289062,
      "loss": 0.6341,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.5127209424972534,
      "rewards/margins": 0.5978111624717712,
      "rewards/rejected": -2.110532283782959,
      "step": 2600
    },
    {
      "epoch": 0.4763208321927183,
      "grad_norm": 1.5113122463226318,
      "learning_rate": 7.278546522297671e-05,
      "logits/chosen": -0.7494021654129028,
      "logits/rejected": -0.6554102301597595,
      "logps/chosen": -159.0017547607422,
      "logps/rejected": -152.95533752441406,
      "loss": 0.5132,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.9842454195022583,
      "rewards/margins": 1.0360498428344727,
      "rewards/rejected": -2.0202956199645996,
      "step": 2610
    },
    {
      "epoch": 0.47814581622410807,
      "grad_norm": 3.405294418334961,
      "learning_rate": 7.275610203707103e-05,
      "logits/chosen": -0.6521739363670349,
      "logits/rejected": -0.5403637886047363,
      "logps/chosen": -166.14547729492188,
      "logps/rejected": -144.9794158935547,
      "loss": 0.5325,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9482137560844421,
      "rewards/margins": 1.0872055292129517,
      "rewards/rejected": -2.03541898727417,
      "step": 2620
    },
    {
      "epoch": 0.47997080025549776,
      "grad_norm": 3.927928924560547,
      "learning_rate": 7.272673885116536e-05,
      "logits/chosen": -0.7017767429351807,
      "logits/rejected": -0.6312030553817749,
      "logps/chosen": -164.9398651123047,
      "logps/rejected": -157.23428344726562,
      "loss": 0.5778,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.2567849159240723,
      "rewards/margins": 0.9570941925048828,
      "rewards/rejected": -2.213879108428955,
      "step": 2630
    },
    {
      "epoch": 0.48179578428688746,
      "grad_norm": 2.320858955383301,
      "learning_rate": 7.26973756652597e-05,
      "logits/chosen": -0.7599939107894897,
      "logits/rejected": -0.6412782669067383,
      "logps/chosen": -172.0311737060547,
      "logps/rejected": -149.30831909179688,
      "loss": 0.5697,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.1703680753707886,
      "rewards/margins": 0.9615341424942017,
      "rewards/rejected": -2.1319022178649902,
      "step": 2640
    },
    {
      "epoch": 0.4836207683182772,
      "grad_norm": 3.090287923812866,
      "learning_rate": 7.266801247935402e-05,
      "logits/chosen": -0.7523730397224426,
      "logits/rejected": -0.6642736196517944,
      "logps/chosen": -175.3834228515625,
      "logps/rejected": -159.70425415039062,
      "loss": 0.5287,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.9592370986938477,
      "rewards/margins": 0.9288276433944702,
      "rewards/rejected": -1.8880647420883179,
      "step": 2650
    },
    {
      "epoch": 0.4854457523496669,
      "grad_norm": 4.8045525550842285,
      "learning_rate": 7.263864929344834e-05,
      "logits/chosen": -0.7729834318161011,
      "logits/rejected": -0.7408597469329834,
      "logps/chosen": -151.54466247558594,
      "logps/rejected": -155.7266387939453,
      "loss": 0.6302,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.130580186843872,
      "rewards/margins": 0.6800117492675781,
      "rewards/rejected": -1.8105919361114502,
      "step": 2660
    },
    {
      "epoch": 0.48727073638105667,
      "grad_norm": 3.7161152362823486,
      "learning_rate": 7.260928610754267e-05,
      "logits/chosen": -0.7418195009231567,
      "logits/rejected": -0.7150311470031738,
      "logps/chosen": -171.40521240234375,
      "logps/rejected": -169.3893280029297,
      "loss": 0.6046,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.2240616083145142,
      "rewards/margins": 0.7420328855514526,
      "rewards/rejected": -1.9660946130752563,
      "step": 2670
    },
    {
      "epoch": 0.48909572041244637,
      "grad_norm": 3.902817726135254,
      "learning_rate": 7.257992292163701e-05,
      "logits/chosen": -0.7309229373931885,
      "logits/rejected": -0.6260526776313782,
      "logps/chosen": -156.1722869873047,
      "logps/rejected": -134.16763305664062,
      "loss": 0.5197,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.222333312034607,
      "rewards/margins": 0.8479378819465637,
      "rewards/rejected": -2.0702710151672363,
      "step": 2680
    },
    {
      "epoch": 0.4909207044438361,
      "grad_norm": 2.7731845378875732,
      "learning_rate": 7.255055973573133e-05,
      "logits/chosen": -0.7417929768562317,
      "logits/rejected": -0.6094976663589478,
      "logps/chosen": -185.25172424316406,
      "logps/rejected": -158.95962524414062,
      "loss": 0.4156,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5178874731063843,
      "rewards/margins": 1.2839854955673218,
      "rewards/rejected": -2.801872730255127,
      "step": 2690
    },
    {
      "epoch": 0.4927456884752258,
      "grad_norm": 2.755699872970581,
      "learning_rate": 7.252119654982566e-05,
      "logits/chosen": -0.7145636081695557,
      "logits/rejected": -0.6006425619125366,
      "logps/chosen": -178.1199188232422,
      "logps/rejected": -159.05389404296875,
      "loss": 0.5925,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.38565194606781,
      "rewards/margins": 1.0436550378799438,
      "rewards/rejected": -2.429306745529175,
      "step": 2700
    },
    {
      "epoch": 0.49457067250661557,
      "grad_norm": 4.712676525115967,
      "learning_rate": 7.249183336392e-05,
      "logits/chosen": -0.6150165796279907,
      "logits/rejected": -0.5981577634811401,
      "logps/chosen": -153.64630126953125,
      "logps/rejected": -161.36886596679688,
      "loss": 0.6475,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8997154235839844,
      "rewards/margins": 0.7171791791915894,
      "rewards/rejected": -1.6168944835662842,
      "step": 2710
    },
    {
      "epoch": 0.49639565653800527,
      "grad_norm": 4.683394908905029,
      "learning_rate": 7.246247017801432e-05,
      "logits/chosen": -0.6741385459899902,
      "logits/rejected": -0.6461267471313477,
      "logps/chosen": -164.89315795898438,
      "logps/rejected": -159.89901733398438,
      "loss": 0.7048,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.1534225940704346,
      "rewards/margins": 0.6147521734237671,
      "rewards/rejected": -1.7681747674942017,
      "step": 2720
    },
    {
      "epoch": 0.498220640569395,
      "grad_norm": 2.691871166229248,
      "learning_rate": 7.243310699210866e-05,
      "logits/chosen": -0.6965173482894897,
      "logits/rejected": -0.5960980653762817,
      "logps/chosen": -135.99087524414062,
      "logps/rejected": -122.62471008300781,
      "loss": 0.4676,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6430038213729858,
      "rewards/margins": 1.0294209718704224,
      "rewards/rejected": -1.6724246740341187,
      "step": 2730
    },
    {
      "epoch": 0.5000456246007847,
      "grad_norm": 2.901684284210205,
      "learning_rate": 7.240374380620298e-05,
      "logits/chosen": -0.6325380206108093,
      "logits/rejected": -0.5204185247421265,
      "logps/chosen": -177.91326904296875,
      "logps/rejected": -151.7935028076172,
      "loss": 0.5616,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6648274660110474,
      "rewards/margins": 0.9893681406974792,
      "rewards/rejected": -1.6541955471038818,
      "step": 2740
    },
    {
      "epoch": 0.5018706086321745,
      "grad_norm": 3.5319712162017822,
      "learning_rate": 7.23743806202973e-05,
      "logits/chosen": -0.6431334614753723,
      "logits/rejected": -0.6032387018203735,
      "logps/chosen": -152.78652954101562,
      "logps/rejected": -152.08255004882812,
      "loss": 0.6262,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.7807295322418213,
      "rewards/margins": 0.7250557541847229,
      "rewards/rejected": -1.5057852268218994,
      "step": 2750
    },
    {
      "epoch": 0.5036955926635642,
      "grad_norm": 2.180210828781128,
      "learning_rate": 7.234501743439164e-05,
      "logits/chosen": -0.7545489072799683,
      "logits/rejected": -0.724437415599823,
      "logps/chosen": -157.04049682617188,
      "logps/rejected": -154.79736328125,
      "loss": 0.593,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.40875110030174255,
      "rewards/margins": 0.6209474205970764,
      "rewards/rejected": -1.0296986103057861,
      "step": 2760
    },
    {
      "epoch": 0.5055205766949539,
      "grad_norm": 3.551887273788452,
      "learning_rate": 7.231565424848597e-05,
      "logits/chosen": -0.7865661382675171,
      "logits/rejected": -0.7328236699104309,
      "logps/chosen": -130.26693725585938,
      "logps/rejected": -143.02577209472656,
      "loss": 0.3916,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -0.16870316863059998,
      "rewards/margins": 1.233915090560913,
      "rewards/rejected": -1.4026182889938354,
      "step": 2770
    },
    {
      "epoch": 0.5073455607263436,
      "grad_norm": 3.5613579750061035,
      "learning_rate": 7.228629106258029e-05,
      "logits/chosen": -0.6372331976890564,
      "logits/rejected": -0.47901734709739685,
      "logps/chosen": -171.70639038085938,
      "logps/rejected": -137.23031616210938,
      "loss": 0.5125,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.501665711402893,
      "rewards/margins": 1.1761573553085327,
      "rewards/rejected": -2.677823305130005,
      "step": 2780
    },
    {
      "epoch": 0.5091705447577334,
      "grad_norm": 3.703889846801758,
      "learning_rate": 7.225692787667462e-05,
      "logits/chosen": -0.6025227308273315,
      "logits/rejected": -0.5157483220100403,
      "logps/chosen": -170.063720703125,
      "logps/rejected": -165.55288696289062,
      "loss": 0.5774,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.4427686929702759,
      "rewards/margins": 1.0332882404327393,
      "rewards/rejected": -2.4760570526123047,
      "step": 2790
    },
    {
      "epoch": 0.5109955287891231,
      "grad_norm": 4.339788436889648,
      "learning_rate": 7.222756469076896e-05,
      "logits/chosen": -0.5840216875076294,
      "logits/rejected": -0.42845869064331055,
      "logps/chosen": -160.22463989257812,
      "logps/rejected": -143.3257293701172,
      "loss": 0.502,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4135968685150146,
      "rewards/margins": 1.1175652742385864,
      "rewards/rejected": -2.5311617851257324,
      "step": 2800
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 3.0199034214019775,
      "learning_rate": 7.219820150486328e-05,
      "logits/chosen": -0.7424505949020386,
      "logits/rejected": -0.6223662495613098,
      "logps/chosen": -161.0779571533203,
      "logps/rejected": -144.38551330566406,
      "loss": 0.5966,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.8782275915145874,
      "rewards/margins": 0.840521514415741,
      "rewards/rejected": -2.7187490463256836,
      "step": 2810
    },
    {
      "epoch": 0.5146454968519025,
      "grad_norm": 2.919487476348877,
      "learning_rate": 7.21688383189576e-05,
      "logits/chosen": -0.7415130734443665,
      "logits/rejected": -0.688200831413269,
      "logps/chosen": -159.4149627685547,
      "logps/rejected": -149.46160888671875,
      "loss": 0.511,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.083396553993225,
      "rewards/margins": 0.8729711771011353,
      "rewards/rejected": -1.95636785030365,
      "step": 2820
    },
    {
      "epoch": 0.5164704808832923,
      "grad_norm": 3.721243381500244,
      "learning_rate": 7.213947513305194e-05,
      "logits/chosen": -0.7994957566261292,
      "logits/rejected": -0.6894048452377319,
      "logps/chosen": -162.7493896484375,
      "logps/rejected": -149.58837890625,
      "loss": 0.4757,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.3684885501861572,
      "rewards/margins": 1.1961437463760376,
      "rewards/rejected": -2.5646321773529053,
      "step": 2830
    },
    {
      "epoch": 0.518295464914682,
      "grad_norm": 3.4359030723571777,
      "learning_rate": 7.211011194714627e-05,
      "logits/chosen": -0.7047557234764099,
      "logits/rejected": -0.6456694602966309,
      "logps/chosen": -152.0314483642578,
      "logps/rejected": -161.24978637695312,
      "loss": 0.4537,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.6057054996490479,
      "rewards/margins": 1.4298421144485474,
      "rewards/rejected": -3.0355477333068848,
      "step": 2840
    },
    {
      "epoch": 0.5201204489460717,
      "grad_norm": 2.970724582672119,
      "learning_rate": 7.20807487612406e-05,
      "logits/chosen": -0.6818934082984924,
      "logits/rejected": -0.6167895197868347,
      "logps/chosen": -163.19436645507812,
      "logps/rejected": -169.96163940429688,
      "loss": 0.4531,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.706618070602417,
      "rewards/margins": 1.3654320240020752,
      "rewards/rejected": -3.072050094604492,
      "step": 2850
    },
    {
      "epoch": 0.5219454329774614,
      "grad_norm": 4.399497032165527,
      "learning_rate": 7.205138557533493e-05,
      "logits/chosen": -0.7484350800514221,
      "logits/rejected": -0.6673645973205566,
      "logps/chosen": -154.55868530273438,
      "logps/rejected": -152.17254638671875,
      "loss": 0.5115,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2593185901641846,
      "rewards/margins": 1.3578741550445557,
      "rewards/rejected": -2.617192506790161,
      "step": 2860
    },
    {
      "epoch": 0.5237704170088512,
      "grad_norm": 3.207779884338379,
      "learning_rate": 7.202202238942927e-05,
      "logits/chosen": -0.7703563570976257,
      "logits/rejected": -0.6766351461410522,
      "logps/chosen": -152.74813842773438,
      "logps/rejected": -140.70138549804688,
      "loss": 0.4917,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.7151485085487366,
      "rewards/margins": 1.341008186340332,
      "rewards/rejected": -2.056156635284424,
      "step": 2870
    },
    {
      "epoch": 0.5255954010402409,
      "grad_norm": 2.3217999935150146,
      "learning_rate": 7.199265920352359e-05,
      "logits/chosen": -0.7891944050788879,
      "logits/rejected": -0.6253344416618347,
      "logps/chosen": -164.76739501953125,
      "logps/rejected": -140.13180541992188,
      "loss": 0.4904,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6713147759437561,
      "rewards/margins": 1.298794150352478,
      "rewards/rejected": -1.970108985900879,
      "step": 2880
    },
    {
      "epoch": 0.5274203850716306,
      "grad_norm": 3.7908143997192383,
      "learning_rate": 7.196329601761792e-05,
      "logits/chosen": -0.7647516131401062,
      "logits/rejected": -0.6489277482032776,
      "logps/chosen": -159.26441955566406,
      "logps/rejected": -147.5607452392578,
      "loss": 0.4313,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.4616737365722656,
      "rewards/margins": 1.6166582107543945,
      "rewards/rejected": -2.078331708908081,
      "step": 2890
    },
    {
      "epoch": 0.5292453691030203,
      "grad_norm": 4.065466403961182,
      "learning_rate": 7.193393283171224e-05,
      "logits/chosen": -0.6845085620880127,
      "logits/rejected": -0.6154611706733704,
      "logps/chosen": -139.1667938232422,
      "logps/rejected": -145.11570739746094,
      "loss": 0.5363,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.9869273900985718,
      "rewards/margins": 1.370896816253662,
      "rewards/rejected": -2.3578240871429443,
      "step": 2900
    },
    {
      "epoch": 0.5310703531344101,
      "grad_norm": 2.631725788116455,
      "learning_rate": 7.190456964580658e-05,
      "logits/chosen": -0.6483429074287415,
      "logits/rejected": -0.5948302745819092,
      "logps/chosen": -168.1858673095703,
      "logps/rejected": -156.86953735351562,
      "loss": 0.6692,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.9031264781951904,
      "rewards/margins": 0.6003493070602417,
      "rewards/rejected": -2.503476142883301,
      "step": 2910
    },
    {
      "epoch": 0.5328953371657998,
      "grad_norm": 3.6463046073913574,
      "learning_rate": 7.18752064599009e-05,
      "logits/chosen": -0.6603574752807617,
      "logits/rejected": -0.47282496094703674,
      "logps/chosen": -172.96014404296875,
      "logps/rejected": -137.53692626953125,
      "loss": 0.531,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8382374048233032,
      "rewards/margins": 1.1586155891418457,
      "rewards/rejected": -2.9968531131744385,
      "step": 2920
    },
    {
      "epoch": 0.5347203211971895,
      "grad_norm": 4.627556324005127,
      "learning_rate": 7.184584327399523e-05,
      "logits/chosen": -0.6462758779525757,
      "logits/rejected": -0.5757710337638855,
      "logps/chosen": -150.22567749023438,
      "logps/rejected": -146.0014190673828,
      "loss": 0.5751,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.3698432445526123,
      "rewards/margins": 0.8303367495536804,
      "rewards/rejected": -3.2001800537109375,
      "step": 2930
    },
    {
      "epoch": 0.5365453052285792,
      "grad_norm": 2.590820074081421,
      "learning_rate": 7.181648008808955e-05,
      "logits/chosen": -0.7498568296432495,
      "logits/rejected": -0.6371501684188843,
      "logps/chosen": -173.8258819580078,
      "logps/rejected": -160.8434295654297,
      "loss": 0.547,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.8786605596542358,
      "rewards/margins": 1.0942833423614502,
      "rewards/rejected": -2.9729437828063965,
      "step": 2940
    },
    {
      "epoch": 0.538370289259969,
      "grad_norm": 2.4354686737060547,
      "learning_rate": 7.178711690218389e-05,
      "logits/chosen": -0.5949864387512207,
      "logits/rejected": -0.5773953795433044,
      "logps/chosen": -147.45811462402344,
      "logps/rejected": -157.28091430664062,
      "loss": 0.7058,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -2.4012763500213623,
      "rewards/margins": 0.6282918453216553,
      "rewards/rejected": -3.0295679569244385,
      "step": 2950
    },
    {
      "epoch": 0.5401952732913587,
      "grad_norm": 6.170446395874023,
      "learning_rate": 7.175775371627822e-05,
      "logits/chosen": -0.725879430770874,
      "logits/rejected": -0.5902756452560425,
      "logps/chosen": -172.17237854003906,
      "logps/rejected": -148.8973388671875,
      "loss": 0.576,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.76361882686615,
      "rewards/margins": 0.7752827405929565,
      "rewards/rejected": -2.5389015674591064,
      "step": 2960
    },
    {
      "epoch": 0.5420202573227484,
      "grad_norm": 2.928556203842163,
      "learning_rate": 7.172839053037255e-05,
      "logits/chosen": -0.7568915486335754,
      "logits/rejected": -0.7080308794975281,
      "logps/chosen": -159.64157104492188,
      "logps/rejected": -156.20704650878906,
      "loss": 0.5539,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.4182432889938354,
      "rewards/margins": 0.7650874257087708,
      "rewards/rejected": -2.183330535888672,
      "step": 2970
    },
    {
      "epoch": 0.5438452413541381,
      "grad_norm": 4.379262447357178,
      "learning_rate": 7.169902734446688e-05,
      "logits/chosen": -0.7581981420516968,
      "logits/rejected": -0.7153096199035645,
      "logps/chosen": -160.26205444335938,
      "logps/rejected": -156.3214874267578,
      "loss": 0.6443,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.6545099020004272,
      "rewards/margins": 0.7120416164398193,
      "rewards/rejected": -2.366551399230957,
      "step": 2980
    },
    {
      "epoch": 0.5456702253855279,
      "grad_norm": 1.6361274719238281,
      "learning_rate": 7.166966415856122e-05,
      "logits/chosen": -0.7239270210266113,
      "logits/rejected": -0.6257848143577576,
      "logps/chosen": -163.37454223632812,
      "logps/rejected": -144.7734375,
      "loss": 0.5227,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.3610626459121704,
      "rewards/margins": 0.8475139737129211,
      "rewards/rejected": -2.2085766792297363,
      "step": 2990
    },
    {
      "epoch": 0.5474952094169176,
      "grad_norm": 2.0536630153656006,
      "learning_rate": 7.164030097265554e-05,
      "logits/chosen": -0.7187393307685852,
      "logits/rejected": -0.5973706245422363,
      "logps/chosen": -151.2727508544922,
      "logps/rejected": -138.3560791015625,
      "loss": 0.5199,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0880638360977173,
      "rewards/margins": 1.0696641206741333,
      "rewards/rejected": -2.1577279567718506,
      "step": 3000
    },
    {
      "epoch": 0.5493201934483073,
      "grad_norm": 2.4719157218933105,
      "learning_rate": 7.161093778674987e-05,
      "logits/chosen": -0.6406737565994263,
      "logits/rejected": -0.5527309775352478,
      "logps/chosen": -154.4395294189453,
      "logps/rejected": -144.18333435058594,
      "loss": 0.6309,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.4843780994415283,
      "rewards/margins": 0.8492968678474426,
      "rewards/rejected": -2.3336751461029053,
      "step": 3010
    },
    {
      "epoch": 0.551145177479697,
      "grad_norm": 1.2844407558441162,
      "learning_rate": 7.15815746008442e-05,
      "logits/chosen": -0.7252798080444336,
      "logits/rejected": -0.6410350799560547,
      "logps/chosen": -169.27621459960938,
      "logps/rejected": -158.75680541992188,
      "loss": 0.5611,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.5959736108779907,
      "rewards/margins": 0.8396889567375183,
      "rewards/rejected": -2.4356625080108643,
      "step": 3020
    },
    {
      "epoch": 0.5529701615110868,
      "grad_norm": 6.306741714477539,
      "learning_rate": 7.155221141493853e-05,
      "logits/chosen": -0.6594666838645935,
      "logits/rejected": -0.551562488079071,
      "logps/chosen": -164.70028686523438,
      "logps/rejected": -151.2136688232422,
      "loss": 0.5099,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2688246965408325,
      "rewards/margins": 0.9732993841171265,
      "rewards/rejected": -2.242124080657959,
      "step": 3030
    },
    {
      "epoch": 0.5547951455424766,
      "grad_norm": 5.175998687744141,
      "learning_rate": 7.152284822903285e-05,
      "logits/chosen": -0.7531172037124634,
      "logits/rejected": -0.6948055028915405,
      "logps/chosen": -144.38438415527344,
      "logps/rejected": -146.13641357421875,
      "loss": 0.5657,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1321690082550049,
      "rewards/margins": 0.8171045184135437,
      "rewards/rejected": -1.949273705482483,
      "step": 3040
    },
    {
      "epoch": 0.5566201295738662,
      "grad_norm": 2.4683148860931396,
      "learning_rate": 7.149348504312718e-05,
      "logits/chosen": -0.5549854040145874,
      "logits/rejected": -0.5213226079940796,
      "logps/chosen": -131.5201873779297,
      "logps/rejected": -135.82144165039062,
      "loss": 0.6248,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.0165412425994873,
      "rewards/margins": 0.7656784057617188,
      "rewards/rejected": -2.782219886779785,
      "step": 3050
    },
    {
      "epoch": 0.558445113605256,
      "grad_norm": 3.6068789958953857,
      "learning_rate": 7.146412185722152e-05,
      "logits/chosen": -0.5592762231826782,
      "logits/rejected": -0.4518621861934662,
      "logps/chosen": -171.17532348632812,
      "logps/rejected": -166.30909729003906,
      "loss": 0.4891,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6175305843353271,
      "rewards/margins": 1.2132295370101929,
      "rewards/rejected": -2.8307602405548096,
      "step": 3060
    },
    {
      "epoch": 0.5602700976366457,
      "grad_norm": 1.8998934030532837,
      "learning_rate": 7.143475867131584e-05,
      "logits/chosen": -0.6040241718292236,
      "logits/rejected": -0.5692564249038696,
      "logps/chosen": -151.35986328125,
      "logps/rejected": -162.86392211914062,
      "loss": 0.5753,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.535154104232788,
      "rewards/margins": 0.9694622159004211,
      "rewards/rejected": -2.5046162605285645,
      "step": 3070
    },
    {
      "epoch": 0.5620950816680355,
      "grad_norm": 2.056638717651367,
      "learning_rate": 7.140539548541017e-05,
      "logits/chosen": -0.607974648475647,
      "logits/rejected": -0.5342530608177185,
      "logps/chosen": -154.23797607421875,
      "logps/rejected": -153.5091094970703,
      "loss": 0.615,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.48045015335083,
      "rewards/margins": 0.9445725679397583,
      "rewards/rejected": -2.425022602081299,
      "step": 3080
    },
    {
      "epoch": 0.5639200656994251,
      "grad_norm": 2.2855911254882812,
      "learning_rate": 7.13760322995045e-05,
      "logits/chosen": -0.6936929225921631,
      "logits/rejected": -0.5922433733940125,
      "logps/chosen": -163.55523681640625,
      "logps/rejected": -146.1541748046875,
      "loss": 0.5852,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.2108498811721802,
      "rewards/margins": 0.8433207273483276,
      "rewards/rejected": -2.054170608520508,
      "step": 3090
    },
    {
      "epoch": 0.5657450497308149,
      "grad_norm": 3.3242552280426025,
      "learning_rate": 7.134666911359883e-05,
      "logits/chosen": -0.719498336315155,
      "logits/rejected": -0.6704504489898682,
      "logps/chosen": -146.3444061279297,
      "logps/rejected": -163.41293334960938,
      "loss": 0.5316,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.3107101917266846,
      "rewards/margins": 1.3125721216201782,
      "rewards/rejected": -2.6232821941375732,
      "step": 3100
    },
    {
      "epoch": 0.5675700337622046,
      "grad_norm": 2.2536027431488037,
      "learning_rate": 7.131730592769317e-05,
      "logits/chosen": -0.6800351142883301,
      "logits/rejected": -0.5970970392227173,
      "logps/chosen": -172.66151428222656,
      "logps/rejected": -157.29310607910156,
      "loss": 0.5482,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.3567311763763428,
      "rewards/margins": 1.0290380716323853,
      "rewards/rejected": -2.3857693672180176,
      "step": 3110
    },
    {
      "epoch": 0.5693950177935944,
      "grad_norm": 5.795915126800537,
      "learning_rate": 7.128794274178749e-05,
      "logits/chosen": -0.6779457330703735,
      "logits/rejected": -0.5938040614128113,
      "logps/chosen": -163.26828002929688,
      "logps/rejected": -167.7277069091797,
      "loss": 0.6153,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.8836485743522644,
      "rewards/margins": 1.0900475978851318,
      "rewards/rejected": -1.9736961126327515,
      "step": 3120
    },
    {
      "epoch": 0.571220001824984,
      "grad_norm": 2.6613903045654297,
      "learning_rate": 7.125857955588182e-05,
      "logits/chosen": -0.7611029148101807,
      "logits/rejected": -0.6165603995323181,
      "logps/chosen": -149.89353942871094,
      "logps/rejected": -131.04641723632812,
      "loss": 0.4983,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6255596280097961,
      "rewards/margins": 1.1518446207046509,
      "rewards/rejected": -1.7774040699005127,
      "step": 3130
    },
    {
      "epoch": 0.5730449858563738,
      "grad_norm": 4.373587131500244,
      "learning_rate": 7.122921636997615e-05,
      "logits/chosen": -0.712673544883728,
      "logits/rejected": -0.6842149496078491,
      "logps/chosen": -163.80282592773438,
      "logps/rejected": -173.97500610351562,
      "loss": 0.5348,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1415032148361206,
      "rewards/margins": 0.8465530276298523,
      "rewards/rejected": -1.9880565404891968,
      "step": 3140
    },
    {
      "epoch": 0.5748699698877635,
      "grad_norm": 3.639655590057373,
      "learning_rate": 7.119985318407048e-05,
      "logits/chosen": -0.656336784362793,
      "logits/rejected": -0.5852913856506348,
      "logps/chosen": -148.4059600830078,
      "logps/rejected": -138.74252319335938,
      "loss": 0.6474,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.2712969779968262,
      "rewards/margins": 0.7011188864707947,
      "rewards/rejected": -1.9724156856536865,
      "step": 3150
    },
    {
      "epoch": 0.5766949539191532,
      "grad_norm": 2.844670534133911,
      "learning_rate": 7.11704899981648e-05,
      "logits/chosen": -0.6704117059707642,
      "logits/rejected": -0.5426780581474304,
      "logps/chosen": -149.959716796875,
      "logps/rejected": -137.26681518554688,
      "loss": 0.46,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0057830810546875,
      "rewards/margins": 1.2855643033981323,
      "rewards/rejected": -2.2913472652435303,
      "step": 3160
    },
    {
      "epoch": 0.5785199379505429,
      "grad_norm": 2.8198940753936768,
      "learning_rate": 7.114112681225914e-05,
      "logits/chosen": -0.6970421075820923,
      "logits/rejected": -0.5610743761062622,
      "logps/chosen": -154.2815399169922,
      "logps/rejected": -138.64907836914062,
      "loss": 0.5548,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1073129177093506,
      "rewards/margins": 0.9571770429611206,
      "rewards/rejected": -2.0644898414611816,
      "step": 3170
    },
    {
      "epoch": 0.5803449219819327,
      "grad_norm": 3.478935956954956,
      "learning_rate": 7.111176362635347e-05,
      "logits/chosen": -0.7037934064865112,
      "logits/rejected": -0.6348236799240112,
      "logps/chosen": -160.81390380859375,
      "logps/rejected": -156.0274200439453,
      "loss": 0.6472,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.2575989961624146,
      "rewards/margins": 0.6684223413467407,
      "rewards/rejected": -1.9260213375091553,
      "step": 3180
    },
    {
      "epoch": 0.5821699060133224,
      "grad_norm": 2.336838960647583,
      "learning_rate": 7.108240044044779e-05,
      "logits/chosen": -0.680219292640686,
      "logits/rejected": -0.5818848609924316,
      "logps/chosen": -158.00289916992188,
      "logps/rejected": -143.1271514892578,
      "loss": 0.5247,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.4175121784210205,
      "rewards/margins": 0.9204186201095581,
      "rewards/rejected": -2.337930679321289,
      "step": 3190
    },
    {
      "epoch": 0.5839948900447121,
      "grad_norm": 4.792450428009033,
      "learning_rate": 7.105303725454212e-05,
      "logits/chosen": -0.6562718152999878,
      "logits/rejected": -0.5418550968170166,
      "logps/chosen": -159.30844116210938,
      "logps/rejected": -150.0797576904297,
      "loss": 0.4924,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4067370891571045,
      "rewards/margins": 1.1682316064834595,
      "rewards/rejected": -2.5749685764312744,
      "step": 3200
    },
    {
      "epoch": 0.5858198740761018,
      "grad_norm": 1.6822322607040405,
      "learning_rate": 7.102367406863645e-05,
      "logits/chosen": -0.7474437952041626,
      "logits/rejected": -0.6106264591217041,
      "logps/chosen": -174.03604125976562,
      "logps/rejected": -148.1977081298828,
      "loss": 0.4613,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9826247096061707,
      "rewards/margins": 1.2425899505615234,
      "rewards/rejected": -2.225214719772339,
      "step": 3210
    },
    {
      "epoch": 0.5876448581074916,
      "grad_norm": 3.341130256652832,
      "learning_rate": 7.099431088273078e-05,
      "logits/chosen": -0.6645511388778687,
      "logits/rejected": -0.5682407021522522,
      "logps/chosen": -166.7140655517578,
      "logps/rejected": -155.87112426757812,
      "loss": 0.6471,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.1256704330444336,
      "rewards/margins": 0.8974243402481079,
      "rewards/rejected": -2.023094892501831,
      "step": 3220
    },
    {
      "epoch": 0.5894698421388813,
      "grad_norm": 4.115780830383301,
      "learning_rate": 7.096494769682512e-05,
      "logits/chosen": -0.6503152847290039,
      "logits/rejected": -0.5704332590103149,
      "logps/chosen": -151.85211181640625,
      "logps/rejected": -149.068115234375,
      "loss": 0.5252,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.6863263249397278,
      "rewards/margins": 1.0975831747055054,
      "rewards/rejected": -1.783909559249878,
      "step": 3230
    },
    {
      "epoch": 0.591294826170271,
      "grad_norm": 4.006682395935059,
      "learning_rate": 7.093558451091944e-05,
      "logits/chosen": -0.6047874093055725,
      "logits/rejected": -0.46731656789779663,
      "logps/chosen": -150.5746612548828,
      "logps/rejected": -143.86181640625,
      "loss": 0.4308,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.5848667025566101,
      "rewards/margins": 1.3630732297897339,
      "rewards/rejected": -1.9479401111602783,
      "step": 3240
    },
    {
      "epoch": 0.5931198102016607,
      "grad_norm": 2.0173237323760986,
      "learning_rate": 7.090622132501378e-05,
      "logits/chosen": -0.5997028946876526,
      "logits/rejected": -0.5105392932891846,
      "logps/chosen": -150.52230834960938,
      "logps/rejected": -139.55438232421875,
      "loss": 0.5224,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.5433990359306335,
      "rewards/margins": 1.0921432971954346,
      "rewards/rejected": -1.6355422735214233,
      "step": 3250
    },
    {
      "epoch": 0.5949447942330505,
      "grad_norm": 2.9858524799346924,
      "learning_rate": 7.08768581391081e-05,
      "logits/chosen": -0.6524502038955688,
      "logits/rejected": -0.5557714700698853,
      "logps/chosen": -161.45542907714844,
      "logps/rejected": -151.1380157470703,
      "loss": 0.4736,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.4296308159828186,
      "rewards/margins": 1.0284481048583984,
      "rewards/rejected": -1.4580790996551514,
      "step": 3260
    },
    {
      "epoch": 0.5967697782644402,
      "grad_norm": 2.7327449321746826,
      "learning_rate": 7.084749495320243e-05,
      "logits/chosen": -0.6077120304107666,
      "logits/rejected": -0.5736700296401978,
      "logps/chosen": -139.89755249023438,
      "logps/rejected": -148.43966674804688,
      "loss": 0.5252,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6111730337142944,
      "rewards/margins": 0.9701024293899536,
      "rewards/rejected": -1.5812755823135376,
      "step": 3270
    },
    {
      "epoch": 0.5985947622958299,
      "grad_norm": 2.469257354736328,
      "learning_rate": 7.081813176729675e-05,
      "logits/chosen": -0.7007298469543457,
      "logits/rejected": -0.559683084487915,
      "logps/chosen": -153.24874877929688,
      "logps/rejected": -139.69558715820312,
      "loss": 0.4777,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.34709638357162476,
      "rewards/margins": 1.257263422012329,
      "rewards/rejected": -1.6043598651885986,
      "step": 3280
    },
    {
      "epoch": 0.6004197463272196,
      "grad_norm": 2.8022549152374268,
      "learning_rate": 7.078876858139109e-05,
      "logits/chosen": -0.6003028154373169,
      "logits/rejected": -0.5313816666603088,
      "logps/chosen": -155.6958770751953,
      "logps/rejected": -149.52493286132812,
      "loss": 0.5492,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9126312136650085,
      "rewards/margins": 0.8278845548629761,
      "rewards/rejected": -1.7405160665512085,
      "step": 3290
    },
    {
      "epoch": 0.6022447303586094,
      "grad_norm": 2.416827917098999,
      "learning_rate": 7.075940539548541e-05,
      "logits/chosen": -0.7683023810386658,
      "logits/rejected": -0.6322290897369385,
      "logps/chosen": -158.0135955810547,
      "logps/rejected": -144.6757354736328,
      "loss": 0.4907,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8711622357368469,
      "rewards/margins": 1.0303285121917725,
      "rewards/rejected": -1.9014908075332642,
      "step": 3300
    },
    {
      "epoch": 0.6040697143899991,
      "grad_norm": 4.137497425079346,
      "learning_rate": 7.073004220957974e-05,
      "logits/chosen": -0.6958609819412231,
      "logits/rejected": -0.5544192790985107,
      "logps/chosen": -175.3427734375,
      "logps/rejected": -150.55523681640625,
      "loss": 0.5529,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.243618369102478,
      "rewards/margins": 0.9310887455940247,
      "rewards/rejected": -2.1747069358825684,
      "step": 3310
    },
    {
      "epoch": 0.6058946984213888,
      "grad_norm": 4.6047749519348145,
      "learning_rate": 7.070067902367406e-05,
      "logits/chosen": -0.6985040307044983,
      "logits/rejected": -0.6165301203727722,
      "logps/chosen": -145.9700927734375,
      "logps/rejected": -149.29443359375,
      "loss": 0.569,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.5559966564178467,
      "rewards/margins": 0.9089118838310242,
      "rewards/rejected": -1.4649085998535156,
      "step": 3320
    },
    {
      "epoch": 0.6077196824527785,
      "grad_norm": 5.129817962646484,
      "learning_rate": 7.06713158377684e-05,
      "logits/chosen": -0.7983272671699524,
      "logits/rejected": -0.7242308855056763,
      "logps/chosen": -136.58970642089844,
      "logps/rejected": -131.54818725585938,
      "loss": 0.5499,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.1587717980146408,
      "rewards/margins": 0.8760579824447632,
      "rewards/rejected": -0.717286229133606,
      "step": 3330
    },
    {
      "epoch": 0.6095446664841683,
      "grad_norm": 2.4439103603363037,
      "learning_rate": 7.064195265186273e-05,
      "logits/chosen": -0.7992510795593262,
      "logits/rejected": -0.6433647274971008,
      "logps/chosen": -172.00961303710938,
      "logps/rejected": -137.5550079345703,
      "loss": 0.5662,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.014152035117149353,
      "rewards/margins": 0.9191895723342896,
      "rewards/rejected": -0.9333416223526001,
      "step": 3340
    },
    {
      "epoch": 0.611369650515558,
      "grad_norm": 3.008208751678467,
      "learning_rate": 7.061258946595706e-05,
      "logits/chosen": -0.7717737555503845,
      "logits/rejected": -0.7358261942863464,
      "logps/chosen": -156.35806274414062,
      "logps/rejected": -160.91957092285156,
      "loss": 0.5263,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.4008975625038147,
      "rewards/margins": 0.9928821325302124,
      "rewards/rejected": -1.3937798738479614,
      "step": 3350
    },
    {
      "epoch": 0.6131946345469477,
      "grad_norm": 3.0109028816223145,
      "learning_rate": 7.058322628005139e-05,
      "logits/chosen": -0.7086166143417358,
      "logits/rejected": -0.6699290871620178,
      "logps/chosen": -151.9590301513672,
      "logps/rejected": -155.6531982421875,
      "loss": 0.5407,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.4840170741081238,
      "rewards/margins": 0.987368106842041,
      "rewards/rejected": -1.4713852405548096,
      "step": 3360
    },
    {
      "epoch": 0.6150196185783374,
      "grad_norm": 3.2508010864257812,
      "learning_rate": 7.055386309414573e-05,
      "logits/chosen": -0.7321388125419617,
      "logits/rejected": -0.6720605492591858,
      "logps/chosen": -151.73155212402344,
      "logps/rejected": -147.28634643554688,
      "loss": 0.583,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.23331749439239502,
      "rewards/margins": 0.9118741750717163,
      "rewards/rejected": -1.1451916694641113,
      "step": 3370
    },
    {
      "epoch": 0.6168446026097272,
      "grad_norm": 3.1410036087036133,
      "learning_rate": 7.052449990824005e-05,
      "logits/chosen": -0.8255783915519714,
      "logits/rejected": -0.736944317817688,
      "logps/chosen": -146.53619384765625,
      "logps/rejected": -135.64804077148438,
      "loss": 0.5905,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.5065317153930664,
      "rewards/margins": 0.809785008430481,
      "rewards/rejected": -1.3163167238235474,
      "step": 3380
    },
    {
      "epoch": 0.6186695866411169,
      "grad_norm": 2.8524208068847656,
      "learning_rate": 7.049513672233438e-05,
      "logits/chosen": -0.7881305813789368,
      "logits/rejected": -0.7326042652130127,
      "logps/chosen": -141.7664794921875,
      "logps/rejected": -146.0765380859375,
      "loss": 0.5183,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.5213133692741394,
      "rewards/margins": 0.9418379068374634,
      "rewards/rejected": -1.463151216506958,
      "step": 3390
    },
    {
      "epoch": 0.6204945706725066,
      "grad_norm": 2.440109968185425,
      "learning_rate": 7.046577353642871e-05,
      "logits/chosen": -0.7197063565254211,
      "logits/rejected": -0.6672293543815613,
      "logps/chosen": -156.81314086914062,
      "logps/rejected": -152.61842346191406,
      "loss": 0.5865,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.849043071269989,
      "rewards/margins": 0.8538346290588379,
      "rewards/rejected": -1.7028777599334717,
      "step": 3400
    },
    {
      "epoch": 0.6223195547038963,
      "grad_norm": 4.978855133056641,
      "learning_rate": 7.043641035052304e-05,
      "logits/chosen": -0.695268988609314,
      "logits/rejected": -0.596371591091156,
      "logps/chosen": -156.09420776367188,
      "logps/rejected": -144.77145385742188,
      "loss": 0.5485,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.6658948063850403,
      "rewards/margins": 0.8475257754325867,
      "rewards/rejected": -1.513420581817627,
      "step": 3410
    },
    {
      "epoch": 0.6241445387352861,
      "grad_norm": 1.674210548400879,
      "learning_rate": 7.040704716461736e-05,
      "logits/chosen": -0.6978384852409363,
      "logits/rejected": -0.5942490696907043,
      "logps/chosen": -168.575439453125,
      "logps/rejected": -144.77352905273438,
      "loss": 0.5983,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.31780391931533813,
      "rewards/margins": 0.8568509817123413,
      "rewards/rejected": -1.1746550798416138,
      "step": 3420
    },
    {
      "epoch": 0.6259695227666758,
      "grad_norm": 2.6516828536987305,
      "learning_rate": 7.037768397871169e-05,
      "logits/chosen": -0.6858533024787903,
      "logits/rejected": -0.5885909795761108,
      "logps/chosen": -159.9815673828125,
      "logps/rejected": -142.72683715820312,
      "loss": 0.5097,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.42752018570899963,
      "rewards/margins": 0.9001997709274292,
      "rewards/rejected": -1.327720046043396,
      "step": 3430
    },
    {
      "epoch": 0.6277945067980655,
      "grad_norm": 2.479794979095459,
      "learning_rate": 7.034832079280603e-05,
      "logits/chosen": -0.698309063911438,
      "logits/rejected": -0.581961452960968,
      "logps/chosen": -146.28721618652344,
      "logps/rejected": -130.11239624023438,
      "loss": 0.6537,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.801472544670105,
      "rewards/margins": 0.6102494597434998,
      "rewards/rejected": -1.41172194480896,
      "step": 3440
    },
    {
      "epoch": 0.6296194908294552,
      "grad_norm": 3.230355978012085,
      "learning_rate": 7.031895760690035e-05,
      "logits/chosen": -0.7478859424591064,
      "logits/rejected": -0.6873027682304382,
      "logps/chosen": -146.37387084960938,
      "logps/rejected": -145.5383758544922,
      "loss": 0.5433,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0296058654785156,
      "rewards/margins": 0.8772515058517456,
      "rewards/rejected": -1.9068572521209717,
      "step": 3450
    },
    {
      "epoch": 0.631444474860845,
      "grad_norm": 2.6357786655426025,
      "learning_rate": 7.028959442099468e-05,
      "logits/chosen": -0.7137506008148193,
      "logits/rejected": -0.6668392419815063,
      "logps/chosen": -155.5914764404297,
      "logps/rejected": -155.06053161621094,
      "loss": 0.5325,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.6650816202163696,
      "rewards/margins": 1.038429617881775,
      "rewards/rejected": -1.7035112380981445,
      "step": 3460
    },
    {
      "epoch": 0.6332694588922347,
      "grad_norm": 2.61734938621521,
      "learning_rate": 7.026023123508901e-05,
      "logits/chosen": -0.6796461343765259,
      "logits/rejected": -0.6118725538253784,
      "logps/chosen": -150.88388061523438,
      "logps/rejected": -142.6805419921875,
      "loss": 0.5773,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.5669348835945129,
      "rewards/margins": 0.854753851890564,
      "rewards/rejected": -1.4216885566711426,
      "step": 3470
    },
    {
      "epoch": 0.6350944429236244,
      "grad_norm": 3.63995099067688,
      "learning_rate": 7.023086804918334e-05,
      "logits/chosen": -0.7574812173843384,
      "logits/rejected": -0.6737512350082397,
      "logps/chosen": -163.03305053710938,
      "logps/rejected": -134.34893798828125,
      "loss": 0.644,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.7493129968643188,
      "rewards/margins": 0.5908897519111633,
      "rewards/rejected": -1.340202808380127,
      "step": 3480
    },
    {
      "epoch": 0.6369194269550141,
      "grad_norm": 5.02350378036499,
      "learning_rate": 7.020150486327768e-05,
      "logits/chosen": -0.6474050879478455,
      "logits/rejected": -0.5239337682723999,
      "logps/chosen": -161.6125946044922,
      "logps/rejected": -139.19192504882812,
      "loss": 0.5852,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.9416913986206055,
      "rewards/margins": 0.9397304654121399,
      "rewards/rejected": -1.8814218044281006,
      "step": 3490
    },
    {
      "epoch": 0.6387444109864039,
      "grad_norm": 2.652881145477295,
      "learning_rate": 7.0172141677372e-05,
      "logits/chosen": -0.6847745180130005,
      "logits/rejected": -0.5654172301292419,
      "logps/chosen": -162.2532501220703,
      "logps/rejected": -144.81732177734375,
      "loss": 0.4404,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8717538714408875,
      "rewards/margins": 1.0820814371109009,
      "rewards/rejected": -1.9538352489471436,
      "step": 3500
    },
    {
      "epoch": 0.6405693950177936,
      "grad_norm": 2.302791118621826,
      "learning_rate": 7.014277849146633e-05,
      "logits/chosen": -0.7040154933929443,
      "logits/rejected": -0.6521788239479065,
      "logps/chosen": -143.5860137939453,
      "logps/rejected": -144.10223388671875,
      "loss": 0.5739,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.334710955619812,
      "rewards/margins": 0.9350050687789917,
      "rewards/rejected": -2.269716501235962,
      "step": 3510
    },
    {
      "epoch": 0.6423943790491833,
      "grad_norm": 2.1960630416870117,
      "learning_rate": 7.011341530556066e-05,
      "logits/chosen": -0.7218536138534546,
      "logits/rejected": -0.6676973104476929,
      "logps/chosen": -146.07064819335938,
      "logps/rejected": -145.53555297851562,
      "loss": 0.492,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.4243558645248413,
      "rewards/margins": 1.0710095167160034,
      "rewards/rejected": -2.495365619659424,
      "step": 3520
    },
    {
      "epoch": 0.644219363080573,
      "grad_norm": 3.2595837116241455,
      "learning_rate": 7.008405211965499e-05,
      "logits/chosen": -0.7420881986618042,
      "logits/rejected": -0.6733807325363159,
      "logps/chosen": -170.9510040283203,
      "logps/rejected": -158.0852813720703,
      "loss": 0.6194,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.692020058631897,
      "rewards/margins": 0.8130935430526733,
      "rewards/rejected": -2.5051136016845703,
      "step": 3530
    },
    {
      "epoch": 0.6460443471119628,
      "grad_norm": 2.979947805404663,
      "learning_rate": 7.005468893374931e-05,
      "logits/chosen": -0.6852187514305115,
      "logits/rejected": -0.5852307081222534,
      "logps/chosen": -175.2542266845703,
      "logps/rejected": -148.82151794433594,
      "loss": 0.5207,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.804962158203125,
      "rewards/margins": 1.0411022901535034,
      "rewards/rejected": -2.846064329147339,
      "step": 3540
    },
    {
      "epoch": 0.6478693311433525,
      "grad_norm": 3.8752307891845703,
      "learning_rate": 7.002532574784365e-05,
      "logits/chosen": -0.6759439706802368,
      "logits/rejected": -0.6695101857185364,
      "logps/chosen": -144.14828491210938,
      "logps/rejected": -160.1475067138672,
      "loss": 0.68,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -1.9773576259613037,
      "rewards/margins": 0.5448579788208008,
      "rewards/rejected": -2.5222158432006836,
      "step": 3550
    },
    {
      "epoch": 0.6496943151747422,
      "grad_norm": 4.741639614105225,
      "learning_rate": 6.999596256193798e-05,
      "logits/chosen": -0.7067119479179382,
      "logits/rejected": -0.6005030274391174,
      "logps/chosen": -179.15304565429688,
      "logps/rejected": -157.80630493164062,
      "loss": 0.5959,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.9854304790496826,
      "rewards/margins": 0.6580127477645874,
      "rewards/rejected": -2.6434433460235596,
      "step": 3560
    },
    {
      "epoch": 0.6515192992061319,
      "grad_norm": 1.8764418363571167,
      "learning_rate": 6.99665993760323e-05,
      "logits/chosen": -0.6983920335769653,
      "logits/rejected": -0.5836349725723267,
      "logps/chosen": -167.4131317138672,
      "logps/rejected": -153.35775756835938,
      "loss": 0.5608,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.8792369365692139,
      "rewards/margins": 0.9678621292114258,
      "rewards/rejected": -2.8470990657806396,
      "step": 3570
    },
    {
      "epoch": 0.6533442832375217,
      "grad_norm": 3.5051286220550537,
      "learning_rate": 6.993723619012663e-05,
      "logits/chosen": -0.7160120606422424,
      "logits/rejected": -0.6141168475151062,
      "logps/chosen": -169.4886016845703,
      "logps/rejected": -157.9351806640625,
      "loss": 0.454,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5720937252044678,
      "rewards/margins": 1.144623875617981,
      "rewards/rejected": -2.716717481613159,
      "step": 3580
    },
    {
      "epoch": 0.6551692672689114,
      "grad_norm": 3.178877353668213,
      "learning_rate": 6.990787300422096e-05,
      "logits/chosen": -0.7467072010040283,
      "logits/rejected": -0.6832951307296753,
      "logps/chosen": -143.06153869628906,
      "logps/rejected": -142.40750122070312,
      "loss": 0.6084,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.8918997049331665,
      "rewards/margins": 0.6198627352714539,
      "rewards/rejected": -2.5117621421813965,
      "step": 3590
    },
    {
      "epoch": 0.6569942513003011,
      "grad_norm": 3.218508720397949,
      "learning_rate": 6.987850981831529e-05,
      "logits/chosen": -0.7833589315414429,
      "logits/rejected": -0.7108933925628662,
      "logps/chosen": -147.43663024902344,
      "logps/rejected": -147.34686279296875,
      "loss": 0.4872,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4616737365722656,
      "rewards/margins": 1.037022352218628,
      "rewards/rejected": -2.4986958503723145,
      "step": 3600
    },
    {
      "epoch": 0.6588192353316908,
      "grad_norm": 2.141690731048584,
      "learning_rate": 6.984914663240963e-05,
      "logits/chosen": -0.7692545652389526,
      "logits/rejected": -0.7309562563896179,
      "logps/chosen": -146.34579467773438,
      "logps/rejected": -148.61935424804688,
      "loss": 0.5951,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -1.4177849292755127,
      "rewards/margins": 0.6195380091667175,
      "rewards/rejected": -2.037322998046875,
      "step": 3610
    },
    {
      "epoch": 0.6606442193630806,
      "grad_norm": 2.548529863357544,
      "learning_rate": 6.981978344650395e-05,
      "logits/chosen": -0.7221793532371521,
      "logits/rejected": -0.6277306079864502,
      "logps/chosen": -163.07772827148438,
      "logps/rejected": -145.84768676757812,
      "loss": 0.556,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2794439792633057,
      "rewards/margins": 1.0171043872833252,
      "rewards/rejected": -2.2965481281280518,
      "step": 3620
    },
    {
      "epoch": 0.6624692033944704,
      "grad_norm": 2.2708301544189453,
      "learning_rate": 6.979042026059829e-05,
      "logits/chosen": -0.7988341450691223,
      "logits/rejected": -0.7159932851791382,
      "logps/chosen": -168.2911834716797,
      "logps/rejected": -168.77120971679688,
      "loss": 0.5078,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.1039665937423706,
      "rewards/margins": 0.9021981358528137,
      "rewards/rejected": -2.006164789199829,
      "step": 3630
    },
    {
      "epoch": 0.66429418742586,
      "grad_norm": 3.288022756576538,
      "learning_rate": 6.976105707469261e-05,
      "logits/chosen": -0.7761214971542358,
      "logits/rejected": -0.6539862155914307,
      "logps/chosen": -154.7091522216797,
      "logps/rejected": -141.74331665039062,
      "loss": 0.4996,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5337846279144287,
      "rewards/margins": 1.1328940391540527,
      "rewards/rejected": -2.6666786670684814,
      "step": 3640
    },
    {
      "epoch": 0.6661191714572497,
      "grad_norm": 1.8401638269424438,
      "learning_rate": 6.973169388878694e-05,
      "logits/chosen": -0.8520975112915039,
      "logits/rejected": -0.7724419832229614,
      "logps/chosen": -155.3649139404297,
      "logps/rejected": -149.80299377441406,
      "loss": 0.5384,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1087009906768799,
      "rewards/margins": 0.8973647356033325,
      "rewards/rejected": -2.0060653686523438,
      "step": 3650
    },
    {
      "epoch": 0.6679441554886395,
      "grad_norm": 2.8809051513671875,
      "learning_rate": 6.970233070288126e-05,
      "logits/chosen": -0.8712906837463379,
      "logits/rejected": -0.8046821355819702,
      "logps/chosen": -154.8902130126953,
      "logps/rejected": -143.18316650390625,
      "loss": 0.5704,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8726509213447571,
      "rewards/margins": 0.961223304271698,
      "rewards/rejected": -1.8338744640350342,
      "step": 3660
    },
    {
      "epoch": 0.6697691395200293,
      "grad_norm": 2.854095458984375,
      "learning_rate": 6.96729675169756e-05,
      "logits/chosen": -0.9276820421218872,
      "logits/rejected": -0.8982657194137573,
      "logps/chosen": -152.9005889892578,
      "logps/rejected": -153.87734985351562,
      "loss": 0.5485,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9867340326309204,
      "rewards/margins": 0.8770901560783386,
      "rewards/rejected": -1.8638242483139038,
      "step": 3670
    },
    {
      "epoch": 0.6715941235514189,
      "grad_norm": 3.643665075302124,
      "learning_rate": 6.964360433106992e-05,
      "logits/chosen": -0.9231342077255249,
      "logits/rejected": -0.81866455078125,
      "logps/chosen": -155.93199157714844,
      "logps/rejected": -129.05514526367188,
      "loss": 0.5782,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1244672536849976,
      "rewards/margins": 0.7416871786117554,
      "rewards/rejected": -1.8661543130874634,
      "step": 3680
    },
    {
      "epoch": 0.6734191075828087,
      "grad_norm": 3.249936819076538,
      "learning_rate": 6.961424114516425e-05,
      "logits/chosen": -0.8079736828804016,
      "logits/rejected": -0.7213280200958252,
      "logps/chosen": -156.66702270507812,
      "logps/rejected": -139.01719665527344,
      "loss": 0.5744,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.776975393295288,
      "rewards/margins": 0.8983927965164185,
      "rewards/rejected": -2.675368070602417,
      "step": 3690
    },
    {
      "epoch": 0.6752440916141984,
      "grad_norm": 1.4938687086105347,
      "learning_rate": 6.958487795925859e-05,
      "logits/chosen": -0.7437248229980469,
      "logits/rejected": -0.6476515531539917,
      "logps/chosen": -158.29942321777344,
      "logps/rejected": -160.2462615966797,
      "loss": 0.4805,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.89948308467865,
      "rewards/margins": 1.1069543361663818,
      "rewards/rejected": -3.006437301635742,
      "step": 3700
    },
    {
      "epoch": 0.677069075645588,
      "grad_norm": 3.029132127761841,
      "learning_rate": 6.955551477335291e-05,
      "logits/chosen": -0.7489228248596191,
      "logits/rejected": -0.7048638463020325,
      "logps/chosen": -159.34756469726562,
      "logps/rejected": -173.65354919433594,
      "loss": 0.6043,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.320570945739746,
      "rewards/margins": 0.8526005744934082,
      "rewards/rejected": -3.1731715202331543,
      "step": 3710
    },
    {
      "epoch": 0.6788940596769778,
      "grad_norm": 2.673708200454712,
      "learning_rate": 6.952615158744725e-05,
      "logits/chosen": -0.6593331098556519,
      "logits/rejected": -0.54176265001297,
      "logps/chosen": -172.62161254882812,
      "logps/rejected": -161.3697509765625,
      "loss": 0.6354,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.60964298248291,
      "rewards/margins": 0.704382061958313,
      "rewards/rejected": -3.314025402069092,
      "step": 3720
    },
    {
      "epoch": 0.6807190437083676,
      "grad_norm": 3.0861356258392334,
      "learning_rate": 6.949678840154157e-05,
      "logits/chosen": -0.7131654620170593,
      "logits/rejected": -0.6119409799575806,
      "logps/chosen": -166.18011474609375,
      "logps/rejected": -154.0790252685547,
      "loss": 0.5779,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.4399893283843994,
      "rewards/margins": 0.6722244024276733,
      "rewards/rejected": -3.112213611602783,
      "step": 3730
    },
    {
      "epoch": 0.6825440277397573,
      "grad_norm": 3.9215354919433594,
      "learning_rate": 6.946742521563591e-05,
      "logits/chosen": -0.7362950444221497,
      "logits/rejected": -0.5338648557662964,
      "logps/chosen": -169.04266357421875,
      "logps/rejected": -134.31906127929688,
      "loss": 0.4633,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8150136470794678,
      "rewards/margins": 1.212695837020874,
      "rewards/rejected": -3.027709484100342,
      "step": 3740
    },
    {
      "epoch": 0.684369011771147,
      "grad_norm": 2.378899097442627,
      "learning_rate": 6.943806202973024e-05,
      "logits/chosen": -0.6574743390083313,
      "logits/rejected": -0.5764607191085815,
      "logps/chosen": -167.16421508789062,
      "logps/rejected": -167.6478271484375,
      "loss": 0.5397,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5816138982772827,
      "rewards/margins": 0.9422904849052429,
      "rewards/rejected": -2.523904323577881,
      "step": 3750
    },
    {
      "epoch": 0.6861939958025367,
      "grad_norm": 3.208942174911499,
      "learning_rate": 6.940869884382456e-05,
      "logits/chosen": -0.6624542474746704,
      "logits/rejected": -0.5787996053695679,
      "logps/chosen": -168.8900604248047,
      "logps/rejected": -173.2392578125,
      "loss": 0.5471,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.6474418640136719,
      "rewards/margins": 0.9636437296867371,
      "rewards/rejected": -2.6110854148864746,
      "step": 3760
    },
    {
      "epoch": 0.6880189798339265,
      "grad_norm": 3.042383909225464,
      "learning_rate": 6.937933565791889e-05,
      "logits/chosen": -0.6626226902008057,
      "logits/rejected": -0.5332155227661133,
      "logps/chosen": -169.83035278320312,
      "logps/rejected": -146.591552734375,
      "loss": 0.53,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1152939796447754,
      "rewards/margins": 1.1735953092575073,
      "rewards/rejected": -2.288889169692993,
      "step": 3770
    },
    {
      "epoch": 0.6898439638653162,
      "grad_norm": 2.4587528705596924,
      "learning_rate": 6.934997247201322e-05,
      "logits/chosen": -0.7387425899505615,
      "logits/rejected": -0.6022529006004333,
      "logps/chosen": -163.62557983398438,
      "logps/rejected": -137.3695831298828,
      "loss": 0.5581,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.43695932626724243,
      "rewards/margins": 0.9179400205612183,
      "rewards/rejected": -1.354899287223816,
      "step": 3780
    },
    {
      "epoch": 0.6916689478967059,
      "grad_norm": 1.2243801355361938,
      "learning_rate": 6.932060928610755e-05,
      "logits/chosen": -0.7519932985305786,
      "logits/rejected": -0.6137281656265259,
      "logps/chosen": -157.35064697265625,
      "logps/rejected": -141.5988311767578,
      "loss": 0.6108,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.4017293453216553,
      "rewards/margins": 0.7382132411003113,
      "rewards/rejected": -2.1399428844451904,
      "step": 3790
    },
    {
      "epoch": 0.6934939319280956,
      "grad_norm": 2.7870280742645264,
      "learning_rate": 6.929124610020187e-05,
      "logits/chosen": -0.6261541843414307,
      "logits/rejected": -0.5814295411109924,
      "logps/chosen": -155.009033203125,
      "logps/rejected": -151.81784057617188,
      "loss": 0.6185,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.473494291305542,
      "rewards/margins": 0.6776002645492554,
      "rewards/rejected": -2.151094675064087,
      "step": 3800
    },
    {
      "epoch": 0.6953189159594854,
      "grad_norm": 2.1901378631591797,
      "learning_rate": 6.92618829142962e-05,
      "logits/chosen": -0.6517738103866577,
      "logits/rejected": -0.5551846027374268,
      "logps/chosen": -155.08001708984375,
      "logps/rejected": -143.93722534179688,
      "loss": 0.5061,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.2244021892547607,
      "rewards/margins": 0.8938377499580383,
      "rewards/rejected": -2.1182398796081543,
      "step": 3810
    },
    {
      "epoch": 0.6971438999908751,
      "grad_norm": 2.9675958156585693,
      "learning_rate": 6.923251972839054e-05,
      "logits/chosen": -0.7773928046226501,
      "logits/rejected": -0.6382996439933777,
      "logps/chosen": -165.2516632080078,
      "logps/rejected": -147.36434936523438,
      "loss": 0.5238,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.2362170219421387,
      "rewards/margins": 1.0101858377456665,
      "rewards/rejected": -2.2464029788970947,
      "step": 3820
    },
    {
      "epoch": 0.6989688840222648,
      "grad_norm": 2.551571846008301,
      "learning_rate": 6.920315654248486e-05,
      "logits/chosen": -0.6833823919296265,
      "logits/rejected": -0.5222808718681335,
      "logps/chosen": -183.1801300048828,
      "logps/rejected": -143.74600219726562,
      "loss": 0.4765,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7020816802978516,
      "rewards/margins": 1.0182113647460938,
      "rewards/rejected": -2.7202930450439453,
      "step": 3830
    },
    {
      "epoch": 0.7007938680536545,
      "grad_norm": 3.114048719406128,
      "learning_rate": 6.91737933565792e-05,
      "logits/chosen": -0.7505455613136292,
      "logits/rejected": -0.6217564344406128,
      "logps/chosen": -162.5281524658203,
      "logps/rejected": -145.38905334472656,
      "loss": 0.6242,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.4600169658660889,
      "rewards/margins": 0.8566959500312805,
      "rewards/rejected": -2.3167128562927246,
      "step": 3840
    },
    {
      "epoch": 0.7026188520850443,
      "grad_norm": 5.651786804199219,
      "learning_rate": 6.914443017067352e-05,
      "logits/chosen": -0.7131317853927612,
      "logits/rejected": -0.6635977029800415,
      "logps/chosen": -157.69888305664062,
      "logps/rejected": -156.07659912109375,
      "loss": 0.5356,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9507042169570923,
      "rewards/margins": 0.9019626379013062,
      "rewards/rejected": -2.8526668548583984,
      "step": 3850
    },
    {
      "epoch": 0.704443836116434,
      "grad_norm": 2.1528923511505127,
      "learning_rate": 6.911506698476786e-05,
      "logits/chosen": -0.7857321500778198,
      "logits/rejected": -0.6301261782646179,
      "logps/chosen": -175.74075317382812,
      "logps/rejected": -157.0568084716797,
      "loss": 0.5426,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6338001489639282,
      "rewards/margins": 1.3096517324447632,
      "rewards/rejected": -2.9434518814086914,
      "step": 3860
    },
    {
      "epoch": 0.7062688201478237,
      "grad_norm": 3.824432134628296,
      "learning_rate": 6.908570379886219e-05,
      "logits/chosen": -0.7099621295928955,
      "logits/rejected": -0.6466184854507446,
      "logps/chosen": -157.94906616210938,
      "logps/rejected": -157.98695373535156,
      "loss": 0.4929,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9917175769805908,
      "rewards/margins": 0.9940601587295532,
      "rewards/rejected": -2.9857773780822754,
      "step": 3870
    },
    {
      "epoch": 0.7080938041792134,
      "grad_norm": 3.6717379093170166,
      "learning_rate": 6.905634061295651e-05,
      "logits/chosen": -0.7194492220878601,
      "logits/rejected": -0.651091992855072,
      "logps/chosen": -174.3331756591797,
      "logps/rejected": -167.21299743652344,
      "loss": 0.6419,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.111961841583252,
      "rewards/margins": 0.6796753406524658,
      "rewards/rejected": -2.7916371822357178,
      "step": 3880
    },
    {
      "epoch": 0.7099187882106032,
      "grad_norm": 3.883695125579834,
      "learning_rate": 6.902697742705084e-05,
      "logits/chosen": -0.7449798583984375,
      "logits/rejected": -0.7321644425392151,
      "logps/chosen": -165.6887664794922,
      "logps/rejected": -166.72979736328125,
      "loss": 0.6931,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.9608526229858398,
      "rewards/margins": 0.5347078442573547,
      "rewards/rejected": -2.4955601692199707,
      "step": 3890
    },
    {
      "epoch": 0.7117437722419929,
      "grad_norm": 2.68438458442688,
      "learning_rate": 6.899761424114517e-05,
      "logits/chosen": -0.8331300020217896,
      "logits/rejected": -0.7661287188529968,
      "logps/chosen": -168.0682373046875,
      "logps/rejected": -158.88743591308594,
      "loss": 0.6492,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.6569255590438843,
      "rewards/margins": 0.5586389303207397,
      "rewards/rejected": -2.215564727783203,
      "step": 3900
    },
    {
      "epoch": 0.7135687562733826,
      "grad_norm": 2.5248053073883057,
      "learning_rate": 6.89682510552395e-05,
      "logits/chosen": -0.7197823524475098,
      "logits/rejected": -0.6635115742683411,
      "logps/chosen": -160.7461395263672,
      "logps/rejected": -154.42037963867188,
      "loss": 0.5499,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.758235216140747,
      "rewards/margins": 0.6623924970626831,
      "rewards/rejected": -2.420628070831299,
      "step": 3910
    },
    {
      "epoch": 0.7153937403047723,
      "grad_norm": 2.767266273498535,
      "learning_rate": 6.893888786933382e-05,
      "logits/chosen": -0.716789722442627,
      "logits/rejected": -0.6070404052734375,
      "logps/chosen": -173.21560668945312,
      "logps/rejected": -155.79837036132812,
      "loss": 0.5756,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.780411958694458,
      "rewards/margins": 0.7053995132446289,
      "rewards/rejected": -2.485811233520508,
      "step": 3920
    },
    {
      "epoch": 0.7172187243361621,
      "grad_norm": 2.198925018310547,
      "learning_rate": 6.890952468342816e-05,
      "logits/chosen": -0.7375169992446899,
      "logits/rejected": -0.6715705990791321,
      "logps/chosen": -150.8544464111328,
      "logps/rejected": -159.07540893554688,
      "loss": 0.6245,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.7725435495376587,
      "rewards/margins": 0.7223625183105469,
      "rewards/rejected": -2.494905948638916,
      "step": 3930
    },
    {
      "epoch": 0.7190437083675518,
      "grad_norm": 2.4144234657287598,
      "learning_rate": 6.888016149752249e-05,
      "logits/chosen": -0.7557548880577087,
      "logits/rejected": -0.7134020328521729,
      "logps/chosen": -144.25357055664062,
      "logps/rejected": -146.7098388671875,
      "loss": 0.5948,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.7084239721298218,
      "rewards/margins": 0.6108112931251526,
      "rewards/rejected": -2.3192355632781982,
      "step": 3940
    },
    {
      "epoch": 0.7208686923989415,
      "grad_norm": 1.5062925815582275,
      "learning_rate": 6.885079831161681e-05,
      "logits/chosen": -0.7289193868637085,
      "logits/rejected": -0.5900840163230896,
      "logps/chosen": -177.15040588378906,
      "logps/rejected": -154.2858428955078,
      "loss": 0.4313,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4712245464324951,
      "rewards/margins": 1.10385262966156,
      "rewards/rejected": -2.5750772953033447,
      "step": 3950
    },
    {
      "epoch": 0.7226936764303312,
      "grad_norm": 4.43183708190918,
      "learning_rate": 6.882143512571115e-05,
      "logits/chosen": -0.6801363229751587,
      "logits/rejected": -0.6404984593391418,
      "logps/chosen": -167.2665557861328,
      "logps/rejected": -159.55101013183594,
      "loss": 0.5962,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.6292005777359009,
      "rewards/margins": 0.7798529863357544,
      "rewards/rejected": -2.4090538024902344,
      "step": 3960
    },
    {
      "epoch": 0.724518660461721,
      "grad_norm": 2.211029052734375,
      "learning_rate": 6.879207193980547e-05,
      "logits/chosen": -0.6863324642181396,
      "logits/rejected": -0.617013156414032,
      "logps/chosen": -146.26193237304688,
      "logps/rejected": -147.46495056152344,
      "loss": 0.5044,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3731968402862549,
      "rewards/margins": 1.0393173694610596,
      "rewards/rejected": -2.4125142097473145,
      "step": 3970
    },
    {
      "epoch": 0.7263436444931107,
      "grad_norm": 1.7517006397247314,
      "learning_rate": 6.876270875389981e-05,
      "logits/chosen": -0.7453656792640686,
      "logits/rejected": -0.6152423620223999,
      "logps/chosen": -156.74063110351562,
      "logps/rejected": -137.5039825439453,
      "loss": 0.5031,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1491801738739014,
      "rewards/margins": 1.115616798400879,
      "rewards/rejected": -2.264796733856201,
      "step": 3980
    },
    {
      "epoch": 0.7281686285245004,
      "grad_norm": 1.857405662536621,
      "learning_rate": 6.873334556799414e-05,
      "logits/chosen": -0.7974168062210083,
      "logits/rejected": -0.6349353194236755,
      "logps/chosen": -180.60098266601562,
      "logps/rejected": -152.63943481445312,
      "loss": 0.496,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.007352590560913,
      "rewards/margins": 1.3180644512176514,
      "rewards/rejected": -2.3254172801971436,
      "step": 3990
    },
    {
      "epoch": 0.7299936125558901,
      "grad_norm": 3.1907384395599365,
      "learning_rate": 6.870398238208846e-05,
      "logits/chosen": -0.7659955024719238,
      "logits/rejected": -0.6419355273246765,
      "logps/chosen": -162.8803253173828,
      "logps/rejected": -148.05450439453125,
      "loss": 0.5864,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2872332334518433,
      "rewards/margins": 0.9782289266586304,
      "rewards/rejected": -2.2654623985290527,
      "step": 4000
    },
    {
      "epoch": 0.7318185965872799,
      "grad_norm": 2.640172004699707,
      "learning_rate": 6.86746191961828e-05,
      "logits/chosen": -0.7549894452095032,
      "logits/rejected": -0.6420636177062988,
      "logps/chosen": -153.16159057617188,
      "logps/rejected": -137.1372833251953,
      "loss": 0.5413,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2408267259597778,
      "rewards/margins": 1.031566858291626,
      "rewards/rejected": -2.2723934650421143,
      "step": 4010
    },
    {
      "epoch": 0.7336435806186696,
      "grad_norm": 2.2895522117614746,
      "learning_rate": 6.864525601027712e-05,
      "logits/chosen": -0.7331340312957764,
      "logits/rejected": -0.5996438264846802,
      "logps/chosen": -159.53311157226562,
      "logps/rejected": -150.60768127441406,
      "loss": 0.4291,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4596686363220215,
      "rewards/margins": 1.2622684240341187,
      "rewards/rejected": -2.721937417984009,
      "step": 4020
    },
    {
      "epoch": 0.7354685646500593,
      "grad_norm": 2.0878143310546875,
      "learning_rate": 6.861589282437145e-05,
      "logits/chosen": -0.7037376165390015,
      "logits/rejected": -0.5979651212692261,
      "logps/chosen": -164.59210205078125,
      "logps/rejected": -163.14590454101562,
      "loss": 0.4858,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.1212354898452759,
      "rewards/margins": 1.2323718070983887,
      "rewards/rejected": -2.353607416152954,
      "step": 4030
    },
    {
      "epoch": 0.737293548681449,
      "grad_norm": 2.5514755249023438,
      "learning_rate": 6.858652963846577e-05,
      "logits/chosen": -0.7238073348999023,
      "logits/rejected": -0.44982776045799255,
      "logps/chosen": -180.6258544921875,
      "logps/rejected": -140.39256286621094,
      "loss": 0.3589,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0492398738861084,
      "rewards/margins": 1.6686222553253174,
      "rewards/rejected": -2.7178618907928467,
      "step": 4040
    },
    {
      "epoch": 0.7391185327128388,
      "grad_norm": 3.9434306621551514,
      "learning_rate": 6.855716645256011e-05,
      "logits/chosen": -0.6421836614608765,
      "logits/rejected": -0.5008178949356079,
      "logps/chosen": -160.1022186279297,
      "logps/rejected": -145.0019989013672,
      "loss": 0.5657,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.1447877883911133,
      "rewards/margins": 1.3915458917617798,
      "rewards/rejected": -2.5363335609436035,
      "step": 4050
    },
    {
      "epoch": 0.7409435167442285,
      "grad_norm": 3.745295524597168,
      "learning_rate": 6.852780326665443e-05,
      "logits/chosen": -0.7911707162857056,
      "logits/rejected": -0.7451134920120239,
      "logps/chosen": -152.4678497314453,
      "logps/rejected": -154.0222625732422,
      "loss": 0.6028,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.9020711183547974,
      "rewards/margins": 0.9351116418838501,
      "rewards/rejected": -1.837182641029358,
      "step": 4060
    },
    {
      "epoch": 0.7427685007756182,
      "grad_norm": 1.8213120698928833,
      "learning_rate": 6.849844008074876e-05,
      "logits/chosen": -0.7724484205245972,
      "logits/rejected": -0.6871269345283508,
      "logps/chosen": -152.9003143310547,
      "logps/rejected": -149.1898651123047,
      "loss": 0.6005,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0162736177444458,
      "rewards/margins": 0.8950620889663696,
      "rewards/rejected": -1.9113355875015259,
      "step": 4070
    },
    {
      "epoch": 0.7445934848070079,
      "grad_norm": 4.5003557205200195,
      "learning_rate": 6.84690768948431e-05,
      "logits/chosen": -0.8182181119918823,
      "logits/rejected": -0.7028304934501648,
      "logps/chosen": -163.083984375,
      "logps/rejected": -151.83975219726562,
      "loss": 0.5038,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2786171436309814,
      "rewards/margins": 1.1145706176757812,
      "rewards/rejected": -2.3931875228881836,
      "step": 4080
    },
    {
      "epoch": 0.7464184688383977,
      "grad_norm": 4.0312724113464355,
      "learning_rate": 6.843971370893742e-05,
      "logits/chosen": -0.7244436144828796,
      "logits/rejected": -0.6766031384468079,
      "logps/chosen": -166.7550506591797,
      "logps/rejected": -166.14779663085938,
      "loss": 0.6452,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.7514444589614868,
      "rewards/margins": 0.6197963953018188,
      "rewards/rejected": -2.3712408542633057,
      "step": 4090
    },
    {
      "epoch": 0.7482434528697874,
      "grad_norm": 2.145655393600464,
      "learning_rate": 6.841035052303176e-05,
      "logits/chosen": -0.8249757885932922,
      "logits/rejected": -0.7403771281242371,
      "logps/chosen": -160.14389038085938,
      "logps/rejected": -152.6417236328125,
      "loss": 0.578,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.638343095779419,
      "rewards/margins": 0.8384479284286499,
      "rewards/rejected": -2.4767911434173584,
      "step": 4100
    },
    {
      "epoch": 0.7500684369011771,
      "grad_norm": 3.200199604034424,
      "learning_rate": 6.838098733712608e-05,
      "logits/chosen": -0.7425527572631836,
      "logits/rejected": -0.6950700879096985,
      "logps/chosen": -144.76812744140625,
      "logps/rejected": -147.75570678710938,
      "loss": 0.6433,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.6401689052581787,
      "rewards/margins": 0.5618118047714233,
      "rewards/rejected": -2.2019808292388916,
      "step": 4110
    },
    {
      "epoch": 0.7518934209325668,
      "grad_norm": 2.4634478092193604,
      "learning_rate": 6.835162415122042e-05,
      "logits/chosen": -0.7617400288581848,
      "logits/rejected": -0.5768904685974121,
      "logps/chosen": -179.23974609375,
      "logps/rejected": -150.8242950439453,
      "loss": 0.4612,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3562498092651367,
      "rewards/margins": 1.1774907112121582,
      "rewards/rejected": -2.533740520477295,
      "step": 4120
    },
    {
      "epoch": 0.7537184049639566,
      "grad_norm": 2.8289153575897217,
      "learning_rate": 6.832226096531475e-05,
      "logits/chosen": -0.7449511289596558,
      "logits/rejected": -0.6807596683502197,
      "logps/chosen": -161.9536590576172,
      "logps/rejected": -157.05502319335938,
      "loss": 0.6615,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.8194841146469116,
      "rewards/margins": 0.7311004400253296,
      "rewards/rejected": -1.5505844354629517,
      "step": 4130
    },
    {
      "epoch": 0.7555433889953463,
      "grad_norm": 2.0160439014434814,
      "learning_rate": 6.829289777940907e-05,
      "logits/chosen": -0.717212975025177,
      "logits/rejected": -0.6233886480331421,
      "logps/chosen": -165.7155303955078,
      "logps/rejected": -134.58328247070312,
      "loss": 0.5969,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.845994770526886,
      "rewards/margins": 0.8050025105476379,
      "rewards/rejected": -1.6509974002838135,
      "step": 4140
    },
    {
      "epoch": 0.757368373026736,
      "grad_norm": 2.4711592197418213,
      "learning_rate": 6.82635345935034e-05,
      "logits/chosen": -0.7842024564743042,
      "logits/rejected": -0.7379547953605652,
      "logps/chosen": -138.87808227539062,
      "logps/rejected": -137.1134033203125,
      "loss": 0.5174,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.7302266359329224,
      "rewards/margins": 0.6945947408676147,
      "rewards/rejected": -1.4248214960098267,
      "step": 4150
    },
    {
      "epoch": 0.7591933570581257,
      "grad_norm": 3.45780348777771,
      "learning_rate": 6.823417140759773e-05,
      "logits/chosen": -0.8283699154853821,
      "logits/rejected": -0.7827849984169006,
      "logps/chosen": -152.7436981201172,
      "logps/rejected": -154.88275146484375,
      "loss": 0.6119,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7858819961547852,
      "rewards/margins": 0.8421408534049988,
      "rewards/rejected": -1.6280227899551392,
      "step": 4160
    },
    {
      "epoch": 0.7610183410895155,
      "grad_norm": 2.6397950649261475,
      "learning_rate": 6.820480822169206e-05,
      "logits/chosen": -0.8910045623779297,
      "logits/rejected": -0.8040716052055359,
      "logps/chosen": -163.2649383544922,
      "logps/rejected": -141.87850952148438,
      "loss": 0.6143,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.4337429404258728,
      "rewards/margins": 0.809930682182312,
      "rewards/rejected": -1.2436736822128296,
      "step": 4170
    },
    {
      "epoch": 0.7628433251209052,
      "grad_norm": 2.6198904514312744,
      "learning_rate": 6.817544503578638e-05,
      "logits/chosen": -0.8414807319641113,
      "logits/rejected": -0.7848888039588928,
      "logps/chosen": -152.31314086914062,
      "logps/rejected": -147.24789428710938,
      "loss": 0.5046,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5534150004386902,
      "rewards/margins": 0.9267619848251343,
      "rewards/rejected": -1.4801771640777588,
      "step": 4180
    },
    {
      "epoch": 0.7646683091522949,
      "grad_norm": 2.0923423767089844,
      "learning_rate": 6.814608184988071e-05,
      "logits/chosen": -0.736179530620575,
      "logits/rejected": -0.6834598183631897,
      "logps/chosen": -155.61056518554688,
      "logps/rejected": -154.7886962890625,
      "loss": 0.669,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.7686270475387573,
      "rewards/margins": 0.518928587436676,
      "rewards/rejected": -1.2875556945800781,
      "step": 4190
    },
    {
      "epoch": 0.7664932931836846,
      "grad_norm": 13.509511947631836,
      "learning_rate": 6.811671866397505e-05,
      "logits/chosen": -0.7748426198959351,
      "logits/rejected": -0.6675485372543335,
      "logps/chosen": -154.24217224121094,
      "logps/rejected": -150.11221313476562,
      "loss": 0.5475,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.5948293209075928,
      "rewards/margins": 1.1031596660614014,
      "rewards/rejected": -1.6979888677597046,
      "step": 4200
    },
    {
      "epoch": 0.7683182772150744,
      "grad_norm": 4.12882137298584,
      "learning_rate": 6.808735547806937e-05,
      "logits/chosen": -0.651978611946106,
      "logits/rejected": -0.5800803899765015,
      "logps/chosen": -152.1433563232422,
      "logps/rejected": -143.0028076171875,
      "loss": 0.5844,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.447072148323059,
      "rewards/margins": 0.8472091555595398,
      "rewards/rejected": -2.294281244277954,
      "step": 4210
    },
    {
      "epoch": 0.770143261246464,
      "grad_norm": 2.2239129543304443,
      "learning_rate": 6.805799229216371e-05,
      "logits/chosen": -0.7279149293899536,
      "logits/rejected": -0.5542062520980835,
      "logps/chosen": -170.94786071777344,
      "logps/rejected": -148.02114868164062,
      "loss": 0.5436,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.9227546453475952,
      "rewards/margins": 0.9886964559555054,
      "rewards/rejected": -2.9114511013031006,
      "step": 4220
    },
    {
      "epoch": 0.7719682452778538,
      "grad_norm": 1.9804728031158447,
      "learning_rate": 6.802862910625803e-05,
      "logits/chosen": -0.6947470903396606,
      "logits/rejected": -0.5678025484085083,
      "logps/chosen": -158.16708374023438,
      "logps/rejected": -155.86251831054688,
      "loss": 0.4975,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.9449065923690796,
      "rewards/margins": 0.9504501223564148,
      "rewards/rejected": -2.8953566551208496,
      "step": 4230
    },
    {
      "epoch": 0.7737932293092435,
      "grad_norm": 4.609824180603027,
      "learning_rate": 6.799926592035237e-05,
      "logits/chosen": -0.6430015563964844,
      "logits/rejected": -0.49606579542160034,
      "logps/chosen": -171.6602325439453,
      "logps/rejected": -160.72637939453125,
      "loss": 0.5326,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7941583395004272,
      "rewards/margins": 1.147200107574463,
      "rewards/rejected": -2.9413585662841797,
      "step": 4240
    },
    {
      "epoch": 0.7756182133406333,
      "grad_norm": 2.203123092651367,
      "learning_rate": 6.79699027344467e-05,
      "logits/chosen": -0.7449097037315369,
      "logits/rejected": -0.6480550169944763,
      "logps/chosen": -158.75985717773438,
      "logps/rejected": -155.9651336669922,
      "loss": 0.5201,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.462524652481079,
      "rewards/margins": 1.2284669876098633,
      "rewards/rejected": -2.6909916400909424,
      "step": 4250
    },
    {
      "epoch": 0.7774431973720229,
      "grad_norm": 2.7019612789154053,
      "learning_rate": 6.794053954854102e-05,
      "logits/chosen": -0.7710071206092834,
      "logits/rejected": -0.7056077718734741,
      "logps/chosen": -151.05030822753906,
      "logps/rejected": -154.76881408691406,
      "loss": 0.5271,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2579530477523804,
      "rewards/margins": 1.0535882711410522,
      "rewards/rejected": -2.3115413188934326,
      "step": 4260
    },
    {
      "epoch": 0.7792681814034127,
      "grad_norm": 3.384472608566284,
      "learning_rate": 6.791117636263535e-05,
      "logits/chosen": -0.7780755758285522,
      "logits/rejected": -0.6968086361885071,
      "logps/chosen": -164.03514099121094,
      "logps/rejected": -156.31887817382812,
      "loss": 0.558,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.3533995151519775,
      "rewards/margins": 0.783101499080658,
      "rewards/rejected": -2.136500835418701,
      "step": 4270
    },
    {
      "epoch": 0.7810931654348024,
      "grad_norm": 2.793923854827881,
      "learning_rate": 6.788181317672968e-05,
      "logits/chosen": -0.7152191400527954,
      "logits/rejected": -0.604622483253479,
      "logps/chosen": -150.7987060546875,
      "logps/rejected": -146.71389770507812,
      "loss": 0.5966,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.7216274738311768,
      "rewards/margins": 0.8244907259941101,
      "rewards/rejected": -2.5461182594299316,
      "step": 4280
    },
    {
      "epoch": 0.7829181494661922,
      "grad_norm": 3.7140963077545166,
      "learning_rate": 6.785244999082401e-05,
      "logits/chosen": -0.7566756010055542,
      "logits/rejected": -0.6693369150161743,
      "logps/chosen": -166.50961303710938,
      "logps/rejected": -152.82630920410156,
      "loss": 0.6243,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.2877719402313232,
      "rewards/margins": 0.7553191184997559,
      "rewards/rejected": -2.043091058731079,
      "step": 4290
    },
    {
      "epoch": 0.7847431334975818,
      "grad_norm": 2.5824499130249023,
      "learning_rate": 6.782308680491833e-05,
      "logits/chosen": -0.7518852949142456,
      "logits/rejected": -0.6514049172401428,
      "logps/chosen": -153.7366485595703,
      "logps/rejected": -144.3124237060547,
      "loss": 0.5907,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.4143182039260864,
      "rewards/margins": 0.8401039242744446,
      "rewards/rejected": -2.2544219493865967,
      "step": 4300
    },
    {
      "epoch": 0.7865681175289716,
      "grad_norm": 2.7829461097717285,
      "learning_rate": 6.779372361901267e-05,
      "logits/chosen": -0.7580298185348511,
      "logits/rejected": -0.5942461490631104,
      "logps/chosen": -156.14158630371094,
      "logps/rejected": -150.56529235839844,
      "loss": 0.4332,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2360652685165405,
      "rewards/margins": 1.3350449800491333,
      "rewards/rejected": -2.571110248565674,
      "step": 4310
    },
    {
      "epoch": 0.7883931015603614,
      "grad_norm": 2.866825819015503,
      "learning_rate": 6.7764360433107e-05,
      "logits/chosen": -0.689907431602478,
      "logits/rejected": -0.5521929264068604,
      "logps/chosen": -174.74887084960938,
      "logps/rejected": -152.07846069335938,
      "loss": 0.4797,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5611815452575684,
      "rewards/margins": 1.0980476140975952,
      "rewards/rejected": -2.659229040145874,
      "step": 4320
    },
    {
      "epoch": 0.7902180855917511,
      "grad_norm": 3.392799139022827,
      "learning_rate": 6.773499724720132e-05,
      "logits/chosen": -0.6790720224380493,
      "logits/rejected": -0.6003470420837402,
      "logps/chosen": -160.25733947753906,
      "logps/rejected": -150.3109588623047,
      "loss": 0.5394,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9830663204193115,
      "rewards/margins": 0.9482975006103516,
      "rewards/rejected": -2.931364059448242,
      "step": 4330
    },
    {
      "epoch": 0.7920430696231407,
      "grad_norm": 2.7843751907348633,
      "learning_rate": 6.770563406129566e-05,
      "logits/chosen": -0.7358406186103821,
      "logits/rejected": -0.6000573635101318,
      "logps/chosen": -164.2168426513672,
      "logps/rejected": -148.65963745117188,
      "loss": 0.4754,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.101196050643921,
      "rewards/margins": 1.1085164546966553,
      "rewards/rejected": -3.209712505340576,
      "step": 4340
    },
    {
      "epoch": 0.7938680536545305,
      "grad_norm": 2.402414083480835,
      "learning_rate": 6.767627087538998e-05,
      "logits/chosen": -0.787987232208252,
      "logits/rejected": -0.5762315988540649,
      "logps/chosen": -193.10794067382812,
      "logps/rejected": -151.5908966064453,
      "loss": 0.4945,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4717483520507812,
      "rewards/margins": 1.0970666408538818,
      "rewards/rejected": -2.568814992904663,
      "step": 4350
    },
    {
      "epoch": 0.7956930376859203,
      "grad_norm": 3.951702117919922,
      "learning_rate": 6.764690768948432e-05,
      "logits/chosen": -0.8227222561836243,
      "logits/rejected": -0.6713930368423462,
      "logps/chosen": -184.94497680664062,
      "logps/rejected": -171.2152099609375,
      "loss": 0.4851,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4080705642700195,
      "rewards/margins": 1.243966817855835,
      "rewards/rejected": -2.6520373821258545,
      "step": 4360
    },
    {
      "epoch": 0.79751802171731,
      "grad_norm": 3.4837114810943604,
      "learning_rate": 6.761754450357865e-05,
      "logits/chosen": -0.84379643201828,
      "logits/rejected": -0.659417450428009,
      "logps/chosen": -168.3465118408203,
      "logps/rejected": -139.93455505371094,
      "loss": 0.4689,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.3642895221710205,
      "rewards/margins": 1.2677785158157349,
      "rewards/rejected": -2.632068157196045,
      "step": 4370
    },
    {
      "epoch": 0.7993430057486997,
      "grad_norm": 2.1604363918304443,
      "learning_rate": 6.758818131767297e-05,
      "logits/chosen": -0.7874475717544556,
      "logits/rejected": -0.5747506022453308,
      "logps/chosen": -171.43173217773438,
      "logps/rejected": -143.5664825439453,
      "loss": 0.4232,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4763400554656982,
      "rewards/margins": 1.6191294193267822,
      "rewards/rejected": -3.0954697132110596,
      "step": 4380
    },
    {
      "epoch": 0.8011679897800894,
      "grad_norm": 2.000117063522339,
      "learning_rate": 6.755881813176731e-05,
      "logits/chosen": -0.8975410461425781,
      "logits/rejected": -0.7849862575531006,
      "logps/chosen": -161.4645538330078,
      "logps/rejected": -154.47682189941406,
      "loss": 0.6526,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.5898665189743042,
      "rewards/margins": 0.9905803799629211,
      "rewards/rejected": -2.58044695854187,
      "step": 4390
    },
    {
      "epoch": 0.8029929738114792,
      "grad_norm": 3.118556261062622,
      "learning_rate": 6.752945494586163e-05,
      "logits/chosen": -0.8390337228775024,
      "logits/rejected": -0.6791284680366516,
      "logps/chosen": -166.2728729248047,
      "logps/rejected": -155.93161010742188,
      "loss": 0.4562,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1595790386199951,
      "rewards/margins": 1.4093631505966187,
      "rewards/rejected": -2.5689425468444824,
      "step": 4400
    },
    {
      "epoch": 0.8048179578428689,
      "grad_norm": 1.6468003988265991,
      "learning_rate": 6.750009175995596e-05,
      "logits/chosen": -0.8495961427688599,
      "logits/rejected": -0.7453035116195679,
      "logps/chosen": -164.74948120117188,
      "logps/rejected": -152.18716430664062,
      "loss": 0.6591,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.9207167625427246,
      "rewards/margins": 0.8808662295341492,
      "rewards/rejected": -1.8015830516815186,
      "step": 4410
    },
    {
      "epoch": 0.8066429418742586,
      "grad_norm": 2.1272857189178467,
      "learning_rate": 6.747072857405028e-05,
      "logits/chosen": -0.7480705380439758,
      "logits/rejected": -0.6768757104873657,
      "logps/chosen": -146.24075317382812,
      "logps/rejected": -147.58982849121094,
      "loss": 0.5265,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.0458457469940186,
      "rewards/margins": 1.1962932348251343,
      "rewards/rejected": -2.2421391010284424,
      "step": 4420
    },
    {
      "epoch": 0.8084679259056483,
      "grad_norm": 3.5616838932037354,
      "learning_rate": 6.744136538814462e-05,
      "logits/chosen": -0.7095596194267273,
      "logits/rejected": -0.6010621786117554,
      "logps/chosen": -174.26947021484375,
      "logps/rejected": -166.18881225585938,
      "loss": 0.5012,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6376352310180664,
      "rewards/margins": 1.4066146612167358,
      "rewards/rejected": -3.044250011444092,
      "step": 4430
    },
    {
      "epoch": 0.8102929099370381,
      "grad_norm": 3.7922115325927734,
      "learning_rate": 6.741200220223894e-05,
      "logits/chosen": -0.7119532823562622,
      "logits/rejected": -0.6033880710601807,
      "logps/chosen": -170.10928344726562,
      "logps/rejected": -161.61257934570312,
      "loss": 0.4597,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.7538650035858154,
      "rewards/margins": 1.176393747329712,
      "rewards/rejected": -2.9302589893341064,
      "step": 4440
    },
    {
      "epoch": 0.8121178939684278,
      "grad_norm": 2.488981008529663,
      "learning_rate": 6.738263901633327e-05,
      "logits/chosen": -0.7810338735580444,
      "logits/rejected": -0.6457694172859192,
      "logps/chosen": -174.07066345214844,
      "logps/rejected": -165.3219757080078,
      "loss": 0.5676,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.6065019369125366,
      "rewards/margins": 1.1963374614715576,
      "rewards/rejected": -2.802839756011963,
      "step": 4450
    },
    {
      "epoch": 0.8139428779998175,
      "grad_norm": 3.962191343307495,
      "learning_rate": 6.735327583042761e-05,
      "logits/chosen": -0.7401260733604431,
      "logits/rejected": -0.6947961449623108,
      "logps/chosen": -163.5504150390625,
      "logps/rejected": -181.94346618652344,
      "loss": 0.5425,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9843991994857788,
      "rewards/margins": 0.9771747589111328,
      "rewards/rejected": -2.961573600769043,
      "step": 4460
    },
    {
      "epoch": 0.8157678620312072,
      "grad_norm": 4.910130977630615,
      "learning_rate": 6.732391264452193e-05,
      "logits/chosen": -0.6992546319961548,
      "logits/rejected": -0.6179176568984985,
      "logps/chosen": -167.62356567382812,
      "logps/rejected": -157.60523986816406,
      "loss": 0.6294,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -2.1956658363342285,
      "rewards/margins": 0.7582303285598755,
      "rewards/rejected": -2.9538960456848145,
      "step": 4470
    },
    {
      "epoch": 0.817592846062597,
      "grad_norm": 2.3299660682678223,
      "learning_rate": 6.729454945861627e-05,
      "logits/chosen": -0.7815731167793274,
      "logits/rejected": -0.7280713319778442,
      "logps/chosen": -159.40817260742188,
      "logps/rejected": -165.8960723876953,
      "loss": 0.5813,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.0942978858947754,
      "rewards/margins": 0.8938900232315063,
      "rewards/rejected": -2.988187551498413,
      "step": 4480
    },
    {
      "epoch": 0.8194178300939867,
      "grad_norm": 3.686988592147827,
      "learning_rate": 6.72651862727106e-05,
      "logits/chosen": -0.7632848024368286,
      "logits/rejected": -0.6553806066513062,
      "logps/chosen": -148.3970489501953,
      "logps/rejected": -147.11734008789062,
      "loss": 0.485,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.165893316268921,
      "rewards/margins": 1.1908116340637207,
      "rewards/rejected": -2.3567047119140625,
      "step": 4490
    },
    {
      "epoch": 0.8212428141253764,
      "grad_norm": 2.8886830806732178,
      "learning_rate": 6.723582308680493e-05,
      "logits/chosen": -0.8629992604255676,
      "logits/rejected": -0.7335671186447144,
      "logps/chosen": -176.68882751464844,
      "logps/rejected": -160.0289764404297,
      "loss": 0.4703,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3665250539779663,
      "rewards/margins": 1.3706789016723633,
      "rewards/rejected": -2.737204074859619,
      "step": 4500
    },
    {
      "epoch": 0.8230677981567661,
      "grad_norm": 3.0764122009277344,
      "learning_rate": 6.720645990089926e-05,
      "logits/chosen": -0.8012495040893555,
      "logits/rejected": -0.7845036387443542,
      "logps/chosen": -153.87399291992188,
      "logps/rejected": -160.8091278076172,
      "loss": 0.5464,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.3125083446502686,
      "rewards/margins": 0.9282886385917664,
      "rewards/rejected": -2.2407968044281006,
      "step": 4510
    },
    {
      "epoch": 0.8248927821881559,
      "grad_norm": 2.643808126449585,
      "learning_rate": 6.717709671499358e-05,
      "logits/chosen": -0.835157036781311,
      "logits/rejected": -0.7358731627464294,
      "logps/chosen": -153.4261016845703,
      "logps/rejected": -144.57342529296875,
      "loss": 0.4016,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1722187995910645,
      "rewards/margins": 1.5100374221801758,
      "rewards/rejected": -2.6822562217712402,
      "step": 4520
    },
    {
      "epoch": 0.8267177662195456,
      "grad_norm": 4.219725608825684,
      "learning_rate": 6.71477335290879e-05,
      "logits/chosen": -0.7438288331031799,
      "logits/rejected": -0.7312108278274536,
      "logps/chosen": -149.6900634765625,
      "logps/rejected": -167.71160888671875,
      "loss": 0.6023,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6466325521469116,
      "rewards/margins": 0.9010545611381531,
      "rewards/rejected": -2.54768705368042,
      "step": 4530
    },
    {
      "epoch": 0.8285427502509353,
      "grad_norm": 3.9492244720458984,
      "learning_rate": 6.711837034318224e-05,
      "logits/chosen": -0.8227437734603882,
      "logits/rejected": -0.7603210210800171,
      "logps/chosen": -146.4143829345703,
      "logps/rejected": -141.10594177246094,
      "loss": 0.5665,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6530590057373047,
      "rewards/margins": 0.7270416021347046,
      "rewards/rejected": -2.3801004886627197,
      "step": 4540
    },
    {
      "epoch": 0.830367734282325,
      "grad_norm": 1.4527567625045776,
      "learning_rate": 6.708900715727657e-05,
      "logits/chosen": -0.8509737849235535,
      "logits/rejected": -0.7541943192481995,
      "logps/chosen": -147.23834228515625,
      "logps/rejected": -132.377685546875,
      "loss": 0.4639,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.5489366054534912,
      "rewards/margins": 1.2836917638778687,
      "rewards/rejected": -2.8326287269592285,
      "step": 4550
    },
    {
      "epoch": 0.8321927183137148,
      "grad_norm": 3.3745548725128174,
      "learning_rate": 6.70596439713709e-05,
      "logits/chosen": -0.832107424736023,
      "logits/rejected": -0.6878344416618347,
      "logps/chosen": -170.9215087890625,
      "logps/rejected": -144.62530517578125,
      "loss": 0.4149,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.2361125946044922,
      "rewards/margins": 1.2499842643737793,
      "rewards/rejected": -2.4860968589782715,
      "step": 4560
    },
    {
      "epoch": 0.8340177023451045,
      "grad_norm": 2.8209645748138428,
      "learning_rate": 6.703028078546522e-05,
      "logits/chosen": -0.8133862614631653,
      "logits/rejected": -0.6659313440322876,
      "logps/chosen": -165.4938201904297,
      "logps/rejected": -154.29595947265625,
      "loss": 0.4692,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4655296802520752,
      "rewards/margins": 1.3255844116210938,
      "rewards/rejected": -2.791114330291748,
      "step": 4570
    },
    {
      "epoch": 0.8358426863764942,
      "grad_norm": 1.5616886615753174,
      "learning_rate": 6.700091759955956e-05,
      "logits/chosen": -0.7938339114189148,
      "logits/rejected": -0.7005857229232788,
      "logps/chosen": -178.48338317871094,
      "logps/rejected": -167.01112365722656,
      "loss": 0.5126,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7562789916992188,
      "rewards/margins": 1.005924940109253,
      "rewards/rejected": -2.7622036933898926,
      "step": 4580
    },
    {
      "epoch": 0.8376676704078839,
      "grad_norm": 3.9823977947235107,
      "learning_rate": 6.697155441365388e-05,
      "logits/chosen": -0.7375873327255249,
      "logits/rejected": -0.6855405569076538,
      "logps/chosen": -154.81646728515625,
      "logps/rejected": -158.0688018798828,
      "loss": 0.6685,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.2374744415283203,
      "rewards/margins": 0.8195223808288574,
      "rewards/rejected": -3.0569965839385986,
      "step": 4590
    },
    {
      "epoch": 0.8394926544392737,
      "grad_norm": 2.308871030807495,
      "learning_rate": 6.694219122774822e-05,
      "logits/chosen": -0.8233457803726196,
      "logits/rejected": -0.7019887566566467,
      "logps/chosen": -169.49871826171875,
      "logps/rejected": -160.33731079101562,
      "loss": 0.4375,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.1874616146087646,
      "rewards/margins": 1.2683441638946533,
      "rewards/rejected": -3.455806016921997,
      "step": 4600
    },
    {
      "epoch": 0.8413176384706634,
      "grad_norm": 4.176077365875244,
      "learning_rate": 6.691282804184254e-05,
      "logits/chosen": -0.8107792735099792,
      "logits/rejected": -0.6633369326591492,
      "logps/chosen": -179.61117553710938,
      "logps/rejected": -141.78500366210938,
      "loss": 0.6274,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.5482497215270996,
      "rewards/margins": 0.9585906863212585,
      "rewards/rejected": -3.506840229034424,
      "step": 4610
    },
    {
      "epoch": 0.8431426225020531,
      "grad_norm": 2.7266387939453125,
      "learning_rate": 6.688346485593688e-05,
      "logits/chosen": -0.7733293771743774,
      "logits/rejected": -0.6954002380371094,
      "logps/chosen": -149.92971801757812,
      "logps/rejected": -141.37794494628906,
      "loss": 0.5042,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.122302532196045,
      "rewards/margins": 1.189318060874939,
      "rewards/rejected": -3.3116207122802734,
      "step": 4620
    },
    {
      "epoch": 0.8449676065334428,
      "grad_norm": 1.2290992736816406,
      "learning_rate": 6.68541016700312e-05,
      "logits/chosen": -0.8689333200454712,
      "logits/rejected": -0.7886602282524109,
      "logps/chosen": -150.56356811523438,
      "logps/rejected": -147.64559936523438,
      "loss": 0.4959,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4467201232910156,
      "rewards/margins": 1.4232275485992432,
      "rewards/rejected": -2.869947910308838,
      "step": 4630
    },
    {
      "epoch": 0.8467925905648326,
      "grad_norm": 3.663166046142578,
      "learning_rate": 6.682473848412553e-05,
      "logits/chosen": -0.8180766105651855,
      "logits/rejected": -0.759549081325531,
      "logps/chosen": -163.06539916992188,
      "logps/rejected": -164.4351043701172,
      "loss": 0.5386,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8819631338119507,
      "rewards/margins": 1.2739167213439941,
      "rewards/rejected": -3.1558799743652344,
      "step": 4640
    },
    {
      "epoch": 0.8486175745962223,
      "grad_norm": 2.7978672981262207,
      "learning_rate": 6.679537529821987e-05,
      "logits/chosen": -0.8909714818000793,
      "logits/rejected": -0.7972880601882935,
      "logps/chosen": -170.6517333984375,
      "logps/rejected": -165.37557983398438,
      "loss": 0.4941,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.1854039430618286,
      "rewards/margins": 1.3604053258895874,
      "rewards/rejected": -2.545809268951416,
      "step": 4650
    },
    {
      "epoch": 0.850442558627612,
      "grad_norm": 1.9660903215408325,
      "learning_rate": 6.67660121123142e-05,
      "logits/chosen": -0.8286207914352417,
      "logits/rejected": -0.7903076410293579,
      "logps/chosen": -172.00143432617188,
      "logps/rejected": -174.7010955810547,
      "loss": 0.5246,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.314065933227539,
      "rewards/margins": 1.1502971649169922,
      "rewards/rejected": -2.4643630981445312,
      "step": 4660
    },
    {
      "epoch": 0.8522675426590017,
      "grad_norm": 5.135979175567627,
      "learning_rate": 6.673664892640852e-05,
      "logits/chosen": -0.8226895332336426,
      "logits/rejected": -0.7138473391532898,
      "logps/chosen": -144.90101623535156,
      "logps/rejected": -146.65090942382812,
      "loss": 0.4326,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3008654117584229,
      "rewards/margins": 1.749643325805664,
      "rewards/rejected": -3.050508975982666,
      "step": 4670
    },
    {
      "epoch": 0.8540925266903915,
      "grad_norm": 3.948455572128296,
      "learning_rate": 6.670728574050284e-05,
      "logits/chosen": -0.7627484798431396,
      "logits/rejected": -0.7057358026504517,
      "logps/chosen": -149.54335021972656,
      "logps/rejected": -164.24172973632812,
      "loss": 0.7509,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -1.6611387729644775,
      "rewards/margins": 0.8408230543136597,
      "rewards/rejected": -2.5019617080688477,
      "step": 4680
    },
    {
      "epoch": 0.8559175107217812,
      "grad_norm": 4.245830059051514,
      "learning_rate": 6.667792255459718e-05,
      "logits/chosen": -0.8475648164749146,
      "logits/rejected": -0.7951038479804993,
      "logps/chosen": -153.09214782714844,
      "logps/rejected": -165.78256225585938,
      "loss": 0.5393,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.5945050716400146,
      "rewards/margins": 0.9347454309463501,
      "rewards/rejected": -2.5292506217956543,
      "step": 4690
    },
    {
      "epoch": 0.8577424947531709,
      "grad_norm": 2.2173616886138916,
      "learning_rate": 6.66485593686915e-05,
      "logits/chosen": -0.8091325759887695,
      "logits/rejected": -0.7344128489494324,
      "logps/chosen": -152.8523712158203,
      "logps/rejected": -144.45706176757812,
      "loss": 0.4627,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1363877058029175,
      "rewards/margins": 1.3213328123092651,
      "rewards/rejected": -2.4577207565307617,
      "step": 4700
    },
    {
      "epoch": 0.8595674787845606,
      "grad_norm": 2.586280584335327,
      "learning_rate": 6.661919618278583e-05,
      "logits/chosen": -0.7904096841812134,
      "logits/rejected": -0.6766827702522278,
      "logps/chosen": -147.59774780273438,
      "logps/rejected": -139.40829467773438,
      "loss": 0.5308,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.3155701160430908,
      "rewards/margins": 1.2145990133285522,
      "rewards/rejected": -2.5301690101623535,
      "step": 4710
    },
    {
      "epoch": 0.8613924628159504,
      "grad_norm": 5.197314739227295,
      "learning_rate": 6.659276931547073e-05,
      "logits/chosen": -0.8473007082939148,
      "logits/rejected": -0.7414082884788513,
      "logps/chosen": -149.3888702392578,
      "logps/rejected": -139.5355682373047,
      "loss": 0.5321,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3717485666275024,
      "rewards/margins": 1.2930086851119995,
      "rewards/rejected": -2.664757251739502,
      "step": 4720
    },
    {
      "epoch": 0.86321744684734,
      "grad_norm": 1.8442671298980713,
      "learning_rate": 6.656340612956507e-05,
      "logits/chosen": -0.9063470959663391,
      "logits/rejected": -0.8587808609008789,
      "logps/chosen": -135.17044067382812,
      "logps/rejected": -140.0547332763672,
      "loss": 0.606,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9342009425163269,
      "rewards/margins": 0.7836192846298218,
      "rewards/rejected": -1.717820167541504,
      "step": 4730
    },
    {
      "epoch": 0.8650424308787298,
      "grad_norm": 3.711343765258789,
      "learning_rate": 6.65340429436594e-05,
      "logits/chosen": -0.9104471206665039,
      "logits/rejected": -0.752282977104187,
      "logps/chosen": -187.93125915527344,
      "logps/rejected": -151.4071044921875,
      "loss": 0.5606,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9023697972297668,
      "rewards/margins": 1.06288480758667,
      "rewards/rejected": -1.965254545211792,
      "step": 4740
    },
    {
      "epoch": 0.8668674149101195,
      "grad_norm": 2.1779396533966064,
      "learning_rate": 6.650467975775372e-05,
      "logits/chosen": -0.8127234578132629,
      "logits/rejected": -0.7245170474052429,
      "logps/chosen": -158.1537628173828,
      "logps/rejected": -165.138916015625,
      "loss": 0.6153,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.7813365459442139,
      "rewards/margins": 0.918623149394989,
      "rewards/rejected": -2.6999599933624268,
      "step": 4750
    },
    {
      "epoch": 0.8686923989415093,
      "grad_norm": 2.1245176792144775,
      "learning_rate": 6.647531657184804e-05,
      "logits/chosen": -0.7801513671875,
      "logits/rejected": -0.7801653146743774,
      "logps/chosen": -144.94387817382812,
      "logps/rejected": -184.5348663330078,
      "loss": 0.5255,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.0016682147979736,
      "rewards/margins": 1.099338173866272,
      "rewards/rejected": -3.1010067462921143,
      "step": 4760
    },
    {
      "epoch": 0.8705173829728989,
      "grad_norm": 4.580167770385742,
      "learning_rate": 6.644595338594238e-05,
      "logits/chosen": -0.7873636484146118,
      "logits/rejected": -0.6551500558853149,
      "logps/chosen": -156.4499053955078,
      "logps/rejected": -160.91453552246094,
      "loss": 0.4896,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8274402618408203,
      "rewards/margins": 1.3538930416107178,
      "rewards/rejected": -3.181333541870117,
      "step": 4770
    },
    {
      "epoch": 0.8723423670042887,
      "grad_norm": 2.9503159523010254,
      "learning_rate": 6.64165902000367e-05,
      "logits/chosen": -0.8076726198196411,
      "logits/rejected": -0.7745363116264343,
      "logps/chosen": -174.8584442138672,
      "logps/rejected": -174.546142578125,
      "loss": 0.5889,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.9505767822265625,
      "rewards/margins": 0.9995611906051636,
      "rewards/rejected": -2.9501378536224365,
      "step": 4780
    },
    {
      "epoch": 0.8741673510356784,
      "grad_norm": 2.9903857707977295,
      "learning_rate": 6.638722701413103e-05,
      "logits/chosen": -0.8838626742362976,
      "logits/rejected": -0.7935594320297241,
      "logps/chosen": -145.16726684570312,
      "logps/rejected": -138.16319274902344,
      "loss": 0.4285,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0323203802108765,
      "rewards/margins": 1.4093010425567627,
      "rewards/rejected": -2.4416215419769287,
      "step": 4790
    },
    {
      "epoch": 0.8759923350670682,
      "grad_norm": 3.2731714248657227,
      "learning_rate": 6.635786382822537e-05,
      "logits/chosen": -0.9346240758895874,
      "logits/rejected": -0.8738948106765747,
      "logps/chosen": -153.2035675048828,
      "logps/rejected": -160.6624298095703,
      "loss": 0.5703,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.1146838665008545,
      "rewards/margins": 1.0759583711624146,
      "rewards/rejected": -2.1906425952911377,
      "step": 4800
    },
    {
      "epoch": 0.8778173190984578,
      "grad_norm": 3.758791923522949,
      "learning_rate": 6.63285006423197e-05,
      "logits/chosen": -0.9473285675048828,
      "logits/rejected": -0.8815422058105469,
      "logps/chosen": -152.40615844726562,
      "logps/rejected": -153.12115478515625,
      "loss": 0.4816,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2453643083572388,
      "rewards/margins": 1.0822129249572754,
      "rewards/rejected": -2.3275771141052246,
      "step": 4810
    },
    {
      "epoch": 0.8796423031298476,
      "grad_norm": 3.0096631050109863,
      "learning_rate": 6.629913745641403e-05,
      "logits/chosen": -0.9529681205749512,
      "logits/rejected": -0.9046812057495117,
      "logps/chosen": -153.5877685546875,
      "logps/rejected": -154.27642822265625,
      "loss": 0.474,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7537017464637756,
      "rewards/margins": 1.191925287246704,
      "rewards/rejected": -1.945626974105835,
      "step": 4820
    },
    {
      "epoch": 0.8814672871612373,
      "grad_norm": 3.1369950771331787,
      "learning_rate": 6.626977427050836e-05,
      "logits/chosen": -0.8134369850158691,
      "logits/rejected": -0.7088549733161926,
      "logps/chosen": -172.18496704101562,
      "logps/rejected": -149.3909454345703,
      "loss": 0.5469,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6717716455459595,
      "rewards/margins": 1.1366766691207886,
      "rewards/rejected": -1.8084484338760376,
      "step": 4830
    },
    {
      "epoch": 0.8832922711926271,
      "grad_norm": 2.624526262283325,
      "learning_rate": 6.624041108460268e-05,
      "logits/chosen": -0.7816326022148132,
      "logits/rejected": -0.6796708106994629,
      "logps/chosen": -154.8347930908203,
      "logps/rejected": -132.31092834472656,
      "loss": 0.5668,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.9718451499938965,
      "rewards/margins": 0.8949082493782043,
      "rewards/rejected": -1.866753339767456,
      "step": 4840
    },
    {
      "epoch": 0.8851172552240167,
      "grad_norm": 3.9181811809539795,
      "learning_rate": 6.621104789869702e-05,
      "logits/chosen": -0.8194998502731323,
      "logits/rejected": -0.7995456457138062,
      "logps/chosen": -168.7191162109375,
      "logps/rejected": -162.73861694335938,
      "loss": 0.5928,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6590813994407654,
      "rewards/margins": 0.7859543561935425,
      "rewards/rejected": -1.445035696029663,
      "step": 4850
    },
    {
      "epoch": 0.8869422392554065,
      "grad_norm": 1.8000231981277466,
      "learning_rate": 6.618168471279134e-05,
      "logits/chosen": -0.8955357670783997,
      "logits/rejected": -0.7599506974220276,
      "logps/chosen": -165.3992462158203,
      "logps/rejected": -125.9820327758789,
      "loss": 0.4973,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.5985656976699829,
      "rewards/margins": 1.000870943069458,
      "rewards/rejected": -1.5994365215301514,
      "step": 4860
    },
    {
      "epoch": 0.8887672232867962,
      "grad_norm": 2.645329236984253,
      "learning_rate": 6.615232152688567e-05,
      "logits/chosen": -0.8123053312301636,
      "logits/rejected": -0.7555404305458069,
      "logps/chosen": -141.6542510986328,
      "logps/rejected": -139.21908569335938,
      "loss": 0.542,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6998283267021179,
      "rewards/margins": 0.8518511056900024,
      "rewards/rejected": -1.5516793727874756,
      "step": 4870
    },
    {
      "epoch": 0.890592207318186,
      "grad_norm": 4.573713779449463,
      "learning_rate": 6.612295834098e-05,
      "logits/chosen": -0.8254936933517456,
      "logits/rejected": -0.7498854398727417,
      "logps/chosen": -154.36558532714844,
      "logps/rejected": -147.51327514648438,
      "loss": 0.5473,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8805974125862122,
      "rewards/margins": 0.744265615940094,
      "rewards/rejected": -1.6248630285263062,
      "step": 4880
    },
    {
      "epoch": 0.8924171913495756,
      "grad_norm": 3.6219489574432373,
      "learning_rate": 6.609359515507433e-05,
      "logits/chosen": -0.749717116355896,
      "logits/rejected": -0.6961039900779724,
      "logps/chosen": -139.26123046875,
      "logps/rejected": -148.68002319335938,
      "loss": 0.499,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5023423433303833,
      "rewards/margins": 1.1086080074310303,
      "rewards/rejected": -2.610950231552124,
      "step": 4890
    },
    {
      "epoch": 0.8942421753809654,
      "grad_norm": 1.6254960298538208,
      "learning_rate": 6.606423196916866e-05,
      "logits/chosen": -0.8898972272872925,
      "logits/rejected": -0.8313041925430298,
      "logps/chosen": -164.4539337158203,
      "logps/rejected": -182.18197631835938,
      "loss": 0.567,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3010179996490479,
      "rewards/margins": 1.064989447593689,
      "rewards/rejected": -2.3660075664520264,
      "step": 4900
    },
    {
      "epoch": 0.8960671594123552,
      "grad_norm": 2.429788589477539,
      "learning_rate": 6.603486878326298e-05,
      "logits/chosen": -0.8193272352218628,
      "logits/rejected": -0.6878059506416321,
      "logps/chosen": -147.4210205078125,
      "logps/rejected": -135.5611572265625,
      "loss": 0.4726,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9111260175704956,
      "rewards/margins": 1.1719555854797363,
      "rewards/rejected": -2.0830812454223633,
      "step": 4910
    },
    {
      "epoch": 0.8978921434437449,
      "grad_norm": 2.746744394302368,
      "learning_rate": 6.600550559735732e-05,
      "logits/chosen": -0.8793023228645325,
      "logits/rejected": -0.8114112615585327,
      "logps/chosen": -166.68185424804688,
      "logps/rejected": -150.0730438232422,
      "loss": 0.5636,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0334116220474243,
      "rewards/margins": 0.9105150103569031,
      "rewards/rejected": -1.9439265727996826,
      "step": 4920
    },
    {
      "epoch": 0.8997171274751345,
      "grad_norm": 2.559420585632324,
      "learning_rate": 6.597614241145164e-05,
      "logits/chosen": -0.8771060705184937,
      "logits/rejected": -0.7982131838798523,
      "logps/chosen": -160.48367309570312,
      "logps/rejected": -152.1996307373047,
      "loss": 0.5204,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.5238944888114929,
      "rewards/margins": 0.9380069971084595,
      "rewards/rejected": -1.4619014263153076,
      "step": 4930
    },
    {
      "epoch": 0.9015421115065243,
      "grad_norm": 3.1343204975128174,
      "learning_rate": 6.594677922554598e-05,
      "logits/chosen": -0.7912925481796265,
      "logits/rejected": -0.7133745551109314,
      "logps/chosen": -150.09738159179688,
      "logps/rejected": -138.73904418945312,
      "loss": 0.5214,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2236144542694092,
      "rewards/margins": 1.0434070825576782,
      "rewards/rejected": -2.267021417617798,
      "step": 4940
    },
    {
      "epoch": 0.903367095537914,
      "grad_norm": 2.363698959350586,
      "learning_rate": 6.59174160396403e-05,
      "logits/chosen": -0.700783371925354,
      "logits/rejected": -0.6517772674560547,
      "logps/chosen": -137.84197998046875,
      "logps/rejected": -144.90830993652344,
      "loss": 0.4853,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.674377679824829,
      "rewards/margins": 0.9893064498901367,
      "rewards/rejected": -2.663684129714966,
      "step": 4950
    },
    {
      "epoch": 0.9051920795693038,
      "grad_norm": 1.7202355861663818,
      "learning_rate": 6.588805285373464e-05,
      "logits/chosen": -0.7750736474990845,
      "logits/rejected": -0.6319166421890259,
      "logps/chosen": -167.01364135742188,
      "logps/rejected": -144.02981567382812,
      "loss": 0.5325,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4326372146606445,
      "rewards/margins": 1.2087476253509521,
      "rewards/rejected": -2.641385078430176,
      "step": 4960
    },
    {
      "epoch": 0.9070170636006935,
      "grad_norm": 3.2930190563201904,
      "learning_rate": 6.585868966782897e-05,
      "logits/chosen": -0.6900298595428467,
      "logits/rejected": -0.6020596027374268,
      "logps/chosen": -166.9464111328125,
      "logps/rejected": -171.92153930664062,
      "loss": 0.3976,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5593849420547485,
      "rewards/margins": 1.2876560688018799,
      "rewards/rejected": -2.847040891647339,
      "step": 4970
    },
    {
      "epoch": 0.9088420476320832,
      "grad_norm": 2.2892069816589355,
      "learning_rate": 6.582932648192329e-05,
      "logits/chosen": -0.732231855392456,
      "logits/rejected": -0.6439281105995178,
      "logps/chosen": -155.81539916992188,
      "logps/rejected": -152.76564025878906,
      "loss": 0.6262,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.8301479816436768,
      "rewards/margins": 0.9759515523910522,
      "rewards/rejected": -2.8060996532440186,
      "step": 4980
    },
    {
      "epoch": 0.910667031663473,
      "grad_norm": 2.9309792518615723,
      "learning_rate": 6.579996329601762e-05,
      "logits/chosen": -0.8184243440628052,
      "logits/rejected": -0.5828207731246948,
      "logps/chosen": -180.15692138671875,
      "logps/rejected": -153.93556213378906,
      "loss": 0.5216,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.814562201499939,
      "rewards/margins": 1.33025324344635,
      "rewards/rejected": -3.14481520652771,
      "step": 4990
    },
    {
      "epoch": 0.9124920156948627,
      "grad_norm": 3.2714474201202393,
      "learning_rate": 6.577060011011196e-05,
      "logits/chosen": -0.7962809205055237,
      "logits/rejected": -0.6436556577682495,
      "logps/chosen": -164.72885131835938,
      "logps/rejected": -153.88865661621094,
      "loss": 0.5124,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.2217319011688232,
      "rewards/margins": 1.4561712741851807,
      "rewards/rejected": -2.677902936935425,
      "step": 5000
    },
    {
      "epoch": 0.9143169997262524,
      "grad_norm": 3.039649486541748,
      "learning_rate": 6.574123692420628e-05,
      "logits/chosen": -0.7713520526885986,
      "logits/rejected": -0.5899566411972046,
      "logps/chosen": -179.0646209716797,
      "logps/rejected": -151.7043914794922,
      "loss": 0.4718,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.3948290348052979,
      "rewards/margins": 1.4613765478134155,
      "rewards/rejected": -2.856205463409424,
      "step": 5010
    },
    {
      "epoch": 0.9161419837576421,
      "grad_norm": 3.6108553409576416,
      "learning_rate": 6.57118737383006e-05,
      "logits/chosen": -0.8069576025009155,
      "logits/rejected": -0.6803492307662964,
      "logps/chosen": -145.82040405273438,
      "logps/rejected": -142.52572631835938,
      "loss": 0.5969,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.4978599548339844,
      "rewards/margins": 1.1796443462371826,
      "rewards/rejected": -2.677504539489746,
      "step": 5020
    },
    {
      "epoch": 0.9179669677890319,
      "grad_norm": 4.061691761016846,
      "learning_rate": 6.568251055239493e-05,
      "logits/chosen": -0.8036836385726929,
      "logits/rejected": -0.7104582786560059,
      "logps/chosen": -166.23385620117188,
      "logps/rejected": -162.4412078857422,
      "loss": 0.5604,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.855915367603302,
      "rewards/margins": 1.0316715240478516,
      "rewards/rejected": -1.8875869512557983,
      "step": 5030
    },
    {
      "epoch": 0.9197919518204216,
      "grad_norm": 4.182262420654297,
      "learning_rate": 6.565314736648927e-05,
      "logits/chosen": -0.872978687286377,
      "logits/rejected": -0.7954176664352417,
      "logps/chosen": -167.03643798828125,
      "logps/rejected": -150.20419311523438,
      "loss": 0.6263,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.8051416277885437,
      "rewards/margins": 0.7685574889183044,
      "rewards/rejected": -1.5736992359161377,
      "step": 5040
    },
    {
      "epoch": 0.9216169358518113,
      "grad_norm": 4.132946968078613,
      "learning_rate": 6.562378418058359e-05,
      "logits/chosen": -0.8081084489822388,
      "logits/rejected": -0.6972749829292297,
      "logps/chosen": -138.73519897460938,
      "logps/rejected": -141.4405975341797,
      "loss": 0.4588,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7713086605072021,
      "rewards/margins": 1.312401533126831,
      "rewards/rejected": -2.083710193634033,
      "step": 5050
    },
    {
      "epoch": 0.923441919883201,
      "grad_norm": 7.894914627075195,
      "learning_rate": 6.559442099467793e-05,
      "logits/chosen": -0.7770703434944153,
      "logits/rejected": -0.5960803627967834,
      "logps/chosen": -168.6443634033203,
      "logps/rejected": -130.35137939453125,
      "loss": 0.5589,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8657239675521851,
      "rewards/margins": 1.1540361642837524,
      "rewards/rejected": -2.0197606086730957,
      "step": 5060
    },
    {
      "epoch": 0.9252669039145908,
      "grad_norm": 1.9685380458831787,
      "learning_rate": 6.556505780877225e-05,
      "logits/chosen": -0.8945780992507935,
      "logits/rejected": -0.8102420568466187,
      "logps/chosen": -147.8573760986328,
      "logps/rejected": -155.28868103027344,
      "loss": 0.5022,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6924237012863159,
      "rewards/margins": 1.128162145614624,
      "rewards/rejected": -1.82058584690094,
      "step": 5070
    },
    {
      "epoch": 0.9270918879459805,
      "grad_norm": 2.0713913440704346,
      "learning_rate": 6.553569462286659e-05,
      "logits/chosen": -0.7738059759140015,
      "logits/rejected": -0.6710410118103027,
      "logps/chosen": -144.08181762695312,
      "logps/rejected": -148.724853515625,
      "loss": 0.4955,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9014719128608704,
      "rewards/margins": 1.3952836990356445,
      "rewards/rejected": -2.296755313873291,
      "step": 5080
    },
    {
      "epoch": 0.9289168719773702,
      "grad_norm": 4.905527114868164,
      "learning_rate": 6.550633143696092e-05,
      "logits/chosen": -0.7506402134895325,
      "logits/rejected": -0.6594531536102295,
      "logps/chosen": -141.0092010498047,
      "logps/rejected": -150.35610961914062,
      "loss": 0.5934,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.3135383725166321,
      "rewards/margins": 1.0639007091522217,
      "rewards/rejected": -1.3774391412734985,
      "step": 5090
    },
    {
      "epoch": 0.9307418560087599,
      "grad_norm": 2.88173508644104,
      "learning_rate": 6.547696825105524e-05,
      "logits/chosen": -0.830978274345398,
      "logits/rejected": -0.7614370584487915,
      "logps/chosen": -153.9720001220703,
      "logps/rejected": -149.1043701171875,
      "loss": 0.6314,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.27574628591537476,
      "rewards/margins": 0.6987950205802917,
      "rewards/rejected": -0.9745413064956665,
      "step": 5100
    },
    {
      "epoch": 0.9325668400401497,
      "grad_norm": 1.8166385889053345,
      "learning_rate": 6.544760506514958e-05,
      "logits/chosen": -0.9110747575759888,
      "logits/rejected": -0.7684963941574097,
      "logps/chosen": -149.5879669189453,
      "logps/rejected": -122.14727783203125,
      "loss": 0.5,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.0076179117895662785,
      "rewards/margins": 1.031851053237915,
      "rewards/rejected": -1.0394690036773682,
      "step": 5110
    },
    {
      "epoch": 0.9343918240715394,
      "grad_norm": 2.156318426132202,
      "learning_rate": 6.54182418792439e-05,
      "logits/chosen": -0.8537201881408691,
      "logits/rejected": -0.7602399587631226,
      "logps/chosen": -138.01808166503906,
      "logps/rejected": -129.4761962890625,
      "loss": 0.5512,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8092015385627747,
      "rewards/margins": 0.8962557911872864,
      "rewards/rejected": -1.705457329750061,
      "step": 5120
    },
    {
      "epoch": 0.9362168081029291,
      "grad_norm": 2.9792466163635254,
      "learning_rate": 6.538887869333823e-05,
      "logits/chosen": -0.8094876408576965,
      "logits/rejected": -0.7081291675567627,
      "logps/chosen": -169.63558959960938,
      "logps/rejected": -147.12216186523438,
      "loss": 0.5331,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6314132809638977,
      "rewards/margins": 0.8908014297485352,
      "rewards/rejected": -1.5222147703170776,
      "step": 5130
    },
    {
      "epoch": 0.9380417921343188,
      "grad_norm": 3.2992420196533203,
      "learning_rate": 6.535951550743255e-05,
      "logits/chosen": -0.8393169641494751,
      "logits/rejected": -0.7460343837738037,
      "logps/chosen": -156.24705505371094,
      "logps/rejected": -141.70126342773438,
      "loss": 0.5284,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7013314962387085,
      "rewards/margins": 0.9572118520736694,
      "rewards/rejected": -1.658543348312378,
      "step": 5140
    },
    {
      "epoch": 0.9398667761657086,
      "grad_norm": 3.6379876136779785,
      "learning_rate": 6.533015232152689e-05,
      "logits/chosen": -0.8593770861625671,
      "logits/rejected": -0.7745065093040466,
      "logps/chosen": -155.5247344970703,
      "logps/rejected": -137.07070922851562,
      "loss": 0.6364,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.9052578210830688,
      "rewards/margins": 0.804049015045166,
      "rewards/rejected": -1.7093069553375244,
      "step": 5150
    },
    {
      "epoch": 0.9416917601970983,
      "grad_norm": 3.1694421768188477,
      "learning_rate": 6.530078913562122e-05,
      "logits/chosen": -0.834904670715332,
      "logits/rejected": -0.8048081398010254,
      "logps/chosen": -154.14938354492188,
      "logps/rejected": -158.58119201660156,
      "loss": 0.5915,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.133087396621704,
      "rewards/margins": 0.6220393180847168,
      "rewards/rejected": -1.7551265954971313,
      "step": 5160
    },
    {
      "epoch": 0.943516744228488,
      "grad_norm": 2.9184961318969727,
      "learning_rate": 6.527142594971554e-05,
      "logits/chosen": -0.9733872413635254,
      "logits/rejected": -0.8542104959487915,
      "logps/chosen": -152.01107788085938,
      "logps/rejected": -130.8506622314453,
      "loss": 0.5186,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9495959281921387,
      "rewards/margins": 0.8155695199966431,
      "rewards/rejected": -1.7651653289794922,
      "step": 5170
    },
    {
      "epoch": 0.9453417282598777,
      "grad_norm": 2.7150416374206543,
      "learning_rate": 6.524206276380988e-05,
      "logits/chosen": -0.8386073112487793,
      "logits/rejected": -0.6907715201377869,
      "logps/chosen": -164.3971405029297,
      "logps/rejected": -138.54733276367188,
      "loss": 0.4793,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1474601030349731,
      "rewards/margins": 1.053060531616211,
      "rewards/rejected": -2.2005207538604736,
      "step": 5180
    },
    {
      "epoch": 0.9471667122912675,
      "grad_norm": 3.3369274139404297,
      "learning_rate": 6.52126995779042e-05,
      "logits/chosen": -0.7295775413513184,
      "logits/rejected": -0.6500508189201355,
      "logps/chosen": -158.9022979736328,
      "logps/rejected": -159.2156982421875,
      "loss": 0.4711,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.253129243850708,
      "rewards/margins": 1.2557474374771118,
      "rewards/rejected": -2.5088765621185303,
      "step": 5190
    },
    {
      "epoch": 0.9489916963226572,
      "grad_norm": 3.460970878601074,
      "learning_rate": 6.518333639199854e-05,
      "logits/chosen": -0.7721942067146301,
      "logits/rejected": -0.6352086663246155,
      "logps/chosen": -167.69639587402344,
      "logps/rejected": -153.83615112304688,
      "loss": 0.4968,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3144716024398804,
      "rewards/margins": 1.42400324344635,
      "rewards/rejected": -2.7384750843048096,
      "step": 5200
    },
    {
      "epoch": 0.9508166803540469,
      "grad_norm": 1.8551121950149536,
      "learning_rate": 6.515397320609287e-05,
      "logits/chosen": -0.765529990196228,
      "logits/rejected": -0.6824508905410767,
      "logps/chosen": -165.68319702148438,
      "logps/rejected": -149.62106323242188,
      "loss": 0.6607,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.8380893468856812,
      "rewards/margins": 0.7874830961227417,
      "rewards/rejected": -2.625572681427002,
      "step": 5210
    },
    {
      "epoch": 0.9526416643854366,
      "grad_norm": 1.9875859022140503,
      "learning_rate": 6.51246100201872e-05,
      "logits/chosen": -0.8245090246200562,
      "logits/rejected": -0.7122918367385864,
      "logps/chosen": -154.70603942871094,
      "logps/rejected": -149.13116455078125,
      "loss": 0.5293,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.3952703475952148,
      "rewards/margins": 1.074396014213562,
      "rewards/rejected": -2.4696662425994873,
      "step": 5220
    },
    {
      "epoch": 0.9544666484168264,
      "grad_norm": 2.3421812057495117,
      "learning_rate": 6.509524683428153e-05,
      "logits/chosen": -0.8902027010917664,
      "logits/rejected": -0.755988597869873,
      "logps/chosen": -170.94485473632812,
      "logps/rejected": -141.9720916748047,
      "loss": 0.4998,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8636020421981812,
      "rewards/margins": 1.2400548458099365,
      "rewards/rejected": -2.1036572456359863,
      "step": 5230
    },
    {
      "epoch": 0.9562916324482161,
      "grad_norm": 3.102398633956909,
      "learning_rate": 6.506588364837585e-05,
      "logits/chosen": -0.8616834878921509,
      "logits/rejected": -0.7991760969161987,
      "logps/chosen": -157.14605712890625,
      "logps/rejected": -149.56375122070312,
      "loss": 0.6326,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.1599823236465454,
      "rewards/margins": 0.7002595663070679,
      "rewards/rejected": -1.8602418899536133,
      "step": 5240
    },
    {
      "epoch": 0.9581166164796058,
      "grad_norm": 3.094750165939331,
      "learning_rate": 6.503652046247018e-05,
      "logits/chosen": -0.8806014060974121,
      "logits/rejected": -0.8102753758430481,
      "logps/chosen": -150.3762969970703,
      "logps/rejected": -164.17758178710938,
      "loss": 0.5641,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.873222827911377,
      "rewards/margins": 0.8875032663345337,
      "rewards/rejected": -1.760725975036621,
      "step": 5250
    },
    {
      "epoch": 0.9599416005109955,
      "grad_norm": 2.3281826972961426,
      "learning_rate": 6.500715727656452e-05,
      "logits/chosen": -0.8768485188484192,
      "logits/rejected": -0.8025970458984375,
      "logps/chosen": -147.23275756835938,
      "logps/rejected": -138.98020935058594,
      "loss": 0.5795,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.7607508897781372,
      "rewards/margins": 0.81720370054245,
      "rewards/rejected": -1.5779545307159424,
      "step": 5260
    },
    {
      "epoch": 0.9617665845423853,
      "grad_norm": 3.3011507987976074,
      "learning_rate": 6.497779409065884e-05,
      "logits/chosen": -0.8841274976730347,
      "logits/rejected": -0.8213359713554382,
      "logps/chosen": -147.9486541748047,
      "logps/rejected": -142.28012084960938,
      "loss": 0.5902,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.5534430742263794,
      "rewards/margins": 0.8516899347305298,
      "rewards/rejected": -1.4051330089569092,
      "step": 5270
    },
    {
      "epoch": 0.9635915685737749,
      "grad_norm": 3.3581249713897705,
      "learning_rate": 6.494843090475317e-05,
      "logits/chosen": -0.8447098731994629,
      "logits/rejected": -0.7699534893035889,
      "logps/chosen": -151.37327575683594,
      "logps/rejected": -146.3124542236328,
      "loss": 0.5295,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9065724611282349,
      "rewards/margins": 1.303924798965454,
      "rewards/rejected": -2.2104973793029785,
      "step": 5280
    },
    {
      "epoch": 0.9654165526051647,
      "grad_norm": 2.54640531539917,
      "learning_rate": 6.49190677188475e-05,
      "logits/chosen": -0.8302594423294067,
      "logits/rejected": -0.7480618953704834,
      "logps/chosen": -164.58837890625,
      "logps/rejected": -155.83529663085938,
      "loss": 0.5827,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.218496561050415,
      "rewards/margins": 0.8146659135818481,
      "rewards/rejected": -2.0331625938415527,
      "step": 5290
    },
    {
      "epoch": 0.9672415366365544,
      "grad_norm": 2.3428728580474854,
      "learning_rate": 6.488970453294183e-05,
      "logits/chosen": -0.7661646604537964,
      "logits/rejected": -0.6703905463218689,
      "logps/chosen": -170.0782012939453,
      "logps/rejected": -136.47190856933594,
      "loss": 0.6062,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.1917177438735962,
      "rewards/margins": 0.7285842895507812,
      "rewards/rejected": -1.9203020334243774,
      "step": 5300
    },
    {
      "epoch": 0.9690665206679442,
      "grad_norm": 2.357781410217285,
      "learning_rate": 6.486034134703617e-05,
      "logits/chosen": -0.8524957895278931,
      "logits/rejected": -0.7982252836227417,
      "logps/chosen": -160.2202911376953,
      "logps/rejected": -161.0946502685547,
      "loss": 0.7044,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.4694966077804565,
      "rewards/margins": 0.44858264923095703,
      "rewards/rejected": -1.9180793762207031,
      "step": 5310
    },
    {
      "epoch": 0.9708915046993338,
      "grad_norm": 2.9097518920898438,
      "learning_rate": 6.483097816113049e-05,
      "logits/chosen": -0.872850775718689,
      "logits/rejected": -0.7362498044967651,
      "logps/chosen": -167.32919311523438,
      "logps/rejected": -140.7884063720703,
      "loss": 0.468,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1821396350860596,
      "rewards/margins": 1.146065354347229,
      "rewards/rejected": -2.328205108642578,
      "step": 5320
    },
    {
      "epoch": 0.9727164887307236,
      "grad_norm": 2.0437099933624268,
      "learning_rate": 6.480161497522482e-05,
      "logits/chosen": -0.8116321563720703,
      "logits/rejected": -0.7361246347427368,
      "logps/chosen": -163.36737060546875,
      "logps/rejected": -153.52578735351562,
      "loss": 0.5268,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.213179588317871,
      "rewards/margins": 0.8664870262145996,
      "rewards/rejected": -2.0796666145324707,
      "step": 5330
    },
    {
      "epoch": 0.9745414727621133,
      "grad_norm": 2.74099063873291,
      "learning_rate": 6.477225178931915e-05,
      "logits/chosen": -0.6871558427810669,
      "logits/rejected": -0.6435545682907104,
      "logps/chosen": -152.6147003173828,
      "logps/rejected": -146.88888549804688,
      "loss": 0.5707,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.3341739177703857,
      "rewards/margins": 0.7643071413040161,
      "rewards/rejected": -2.0984811782836914,
      "step": 5340
    },
    {
      "epoch": 0.9763664567935031,
      "grad_norm": 4.158938407897949,
      "learning_rate": 6.474288860341348e-05,
      "logits/chosen": -0.7677850723266602,
      "logits/rejected": -0.721660852432251,
      "logps/chosen": -172.06362915039062,
      "logps/rejected": -157.47964477539062,
      "loss": 0.6619,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.706054449081421,
      "rewards/margins": 0.4931480288505554,
      "rewards/rejected": -2.199202299118042,
      "step": 5350
    },
    {
      "epoch": 0.9781914408248927,
      "grad_norm": 3.0093417167663574,
      "learning_rate": 6.47135254175078e-05,
      "logits/chosen": -0.7202891111373901,
      "logits/rejected": -0.6807507276535034,
      "logps/chosen": -159.3977508544922,
      "logps/rejected": -145.0062713623047,
      "loss": 0.6915,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.3039354085922241,
      "rewards/margins": 0.341653972864151,
      "rewards/rejected": -1.6455894708633423,
      "step": 5360
    },
    {
      "epoch": 0.9800164248562825,
      "grad_norm": 3.136240243911743,
      "learning_rate": 6.468416223160213e-05,
      "logits/chosen": -0.7628060579299927,
      "logits/rejected": -0.6621026992797852,
      "logps/chosen": -155.35177612304688,
      "logps/rejected": -149.3052978515625,
      "loss": 0.4989,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3023927211761475,
      "rewards/margins": 0.7779628038406372,
      "rewards/rejected": -2.080355167388916,
      "step": 5370
    },
    {
      "epoch": 0.9818414088876722,
      "grad_norm": 2.057363986968994,
      "learning_rate": 6.465479904569647e-05,
      "logits/chosen": -0.7223504781723022,
      "logits/rejected": -0.6608473062515259,
      "logps/chosen": -144.66094970703125,
      "logps/rejected": -143.81747436523438,
      "loss": 0.5521,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2759358882904053,
      "rewards/margins": 0.7923084497451782,
      "rewards/rejected": -2.068244218826294,
      "step": 5380
    },
    {
      "epoch": 0.983666392919062,
      "grad_norm": 1.8191940784454346,
      "learning_rate": 6.462543585979079e-05,
      "logits/chosen": -0.7076049447059631,
      "logits/rejected": -0.6876681447029114,
      "logps/chosen": -135.1798095703125,
      "logps/rejected": -148.85067749023438,
      "loss": 0.5726,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.2202129364013672,
      "rewards/margins": 0.729629397392273,
      "rewards/rejected": -1.9498424530029297,
      "step": 5390
    },
    {
      "epoch": 0.9854913769504516,
      "grad_norm": 4.630258560180664,
      "learning_rate": 6.459607267388511e-05,
      "logits/chosen": -0.7335582971572876,
      "logits/rejected": -0.6369153261184692,
      "logps/chosen": -168.3631591796875,
      "logps/rejected": -159.37603759765625,
      "loss": 0.5346,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2760244607925415,
      "rewards/margins": 0.9251181483268738,
      "rewards/rejected": -2.2011425495147705,
      "step": 5400
    },
    {
      "epoch": 0.9873163609818414,
      "grad_norm": 2.943154811859131,
      "learning_rate": 6.456670948797945e-05,
      "logits/chosen": -0.7277633547782898,
      "logits/rejected": -0.6908088326454163,
      "logps/chosen": -140.97933959960938,
      "logps/rejected": -153.19741821289062,
      "loss": 0.4529,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9739187359809875,
      "rewards/margins": 1.1769386529922485,
      "rewards/rejected": -2.1508572101593018,
      "step": 5410
    },
    {
      "epoch": 0.9891413450132311,
      "grad_norm": 2.0220513343811035,
      "learning_rate": 6.453734630207378e-05,
      "logits/chosen": -0.7183916568756104,
      "logits/rejected": -0.5782408714294434,
      "logps/chosen": -168.78683471679688,
      "logps/rejected": -152.87855529785156,
      "loss": 0.464,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.6043171286582947,
      "rewards/margins": 1.1300745010375977,
      "rewards/rejected": -1.7343918085098267,
      "step": 5420
    },
    {
      "epoch": 0.9909663290446209,
      "grad_norm": 3.2312440872192383,
      "learning_rate": 6.450798311616812e-05,
      "logits/chosen": -0.7071480751037598,
      "logits/rejected": -0.6295821666717529,
      "logps/chosen": -161.8720245361328,
      "logps/rejected": -168.15225219726562,
      "loss": 0.4122,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.7231976985931396,
      "rewards/margins": 1.4483164548873901,
      "rewards/rejected": -2.1715140342712402,
      "step": 5430
    },
    {
      "epoch": 0.9927913130760105,
      "grad_norm": 1.541922926902771,
      "learning_rate": 6.447861993026244e-05,
      "logits/chosen": -0.6815416812896729,
      "logits/rejected": -0.5323148965835571,
      "logps/chosen": -166.4720458984375,
      "logps/rejected": -137.78775024414062,
      "loss": 0.5181,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.4204348623752594,
      "rewards/margins": 1.2523698806762695,
      "rewards/rejected": -1.672804594039917,
      "step": 5440
    },
    {
      "epoch": 0.9946162971074003,
      "grad_norm": 4.715480327606201,
      "learning_rate": 6.444925674435678e-05,
      "logits/chosen": -0.5805304050445557,
      "logits/rejected": -0.42706137895584106,
      "logps/chosen": -145.0935821533203,
      "logps/rejected": -154.3216552734375,
      "loss": 0.4151,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.039851427078247,
      "rewards/margins": 1.693023920059204,
      "rewards/rejected": -2.732875347137451,
      "step": 5450
    },
    {
      "epoch": 0.99644128113879,
      "grad_norm": 1.9928758144378662,
      "learning_rate": 6.44198935584511e-05,
      "logits/chosen": -0.5112844109535217,
      "logits/rejected": -0.42386800050735474,
      "logps/chosen": -149.81719970703125,
      "logps/rejected": -153.36680603027344,
      "loss": 0.55,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7204490303993225,
      "rewards/margins": 1.1540920734405518,
      "rewards/rejected": -1.8745410442352295,
      "step": 5460
    },
    {
      "epoch": 0.9982662651701798,
      "grad_norm": 1.7769638299942017,
      "learning_rate": 6.439053037254543e-05,
      "logits/chosen": -0.6337646842002869,
      "logits/rejected": -0.5315260887145996,
      "logps/chosen": -159.27835083007812,
      "logps/rejected": -150.17552185058594,
      "loss": 0.5404,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.4808920919895172,
      "rewards/margins": 1.2350280284881592,
      "rewards/rejected": -1.7159202098846436,
      "step": 5470
    },
    {
      "epoch": 1.0000912492015694,
      "grad_norm": 6.119528770446777,
      "learning_rate": 6.436116718663975e-05,
      "logits/chosen": -0.5565532445907593,
      "logits/rejected": -0.5022914409637451,
      "logps/chosen": -126.1720199584961,
      "logps/rejected": -138.03857421875,
      "loss": 0.5687,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.30543431639671326,
      "rewards/margins": 1.0319947004318237,
      "rewards/rejected": -1.3374290466308594,
      "step": 5480
    },
    {
      "epoch": 1.0019162332329592,
      "grad_norm": 4.422054767608643,
      "learning_rate": 6.433180400073409e-05,
      "logits/chosen": -0.6420284509658813,
      "logits/rejected": -0.48751869797706604,
      "logps/chosen": -161.20953369140625,
      "logps/rejected": -132.23831176757812,
      "loss": 0.5548,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.4026305675506592,
      "rewards/margins": 1.1083732843399048,
      "rewards/rejected": -1.5110039710998535,
      "step": 5490
    },
    {
      "epoch": 1.003741217264349,
      "grad_norm": 2.892194986343384,
      "learning_rate": 6.430244081482841e-05,
      "logits/chosen": -0.7381410598754883,
      "logits/rejected": -0.6123502850532532,
      "logps/chosen": -152.72882080078125,
      "logps/rejected": -129.827880859375,
      "loss": 0.4331,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.5283882021903992,
      "rewards/margins": 1.1416046619415283,
      "rewards/rejected": -1.6699930429458618,
      "step": 5500
    },
    {
      "epoch": 1.0055662012957387,
      "grad_norm": 1.536293864250183,
      "learning_rate": 6.427307762892274e-05,
      "logits/chosen": -0.5398645997047424,
      "logits/rejected": -0.32129257917404175,
      "logps/chosen": -174.02769470214844,
      "logps/rejected": -150.34103393554688,
      "loss": 0.3985,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.627610445022583,
      "rewards/margins": 1.7198588848114014,
      "rewards/rejected": -2.3474693298339844,
      "step": 5510
    },
    {
      "epoch": 1.0073911853271285,
      "grad_norm": 1.6027438640594482,
      "learning_rate": 6.424371444301706e-05,
      "logits/chosen": -0.3626944124698639,
      "logits/rejected": -0.27516135573387146,
      "logps/chosen": -141.29347229003906,
      "logps/rejected": -157.88731384277344,
      "loss": 0.4845,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.730330228805542,
      "rewards/margins": 1.2362622022628784,
      "rewards/rejected": -2.96659255027771,
      "step": 5520
    },
    {
      "epoch": 1.0092161693585182,
      "grad_norm": 1.4780259132385254,
      "learning_rate": 6.42143512571114e-05,
      "logits/chosen": -0.4875341057777405,
      "logits/rejected": -0.28828954696655273,
      "logps/chosen": -177.4107666015625,
      "logps/rejected": -161.14303588867188,
      "loss": 0.402,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.5978100299835205,
      "rewards/margins": 1.5997493267059326,
      "rewards/rejected": -3.197559118270874,
      "step": 5530
    },
    {
      "epoch": 1.0110411533899077,
      "grad_norm": 1.8008922338485718,
      "learning_rate": 6.418498807120573e-05,
      "logits/chosen": -0.5530327558517456,
      "logits/rejected": -0.4403414726257324,
      "logps/chosen": -162.79837036132812,
      "logps/rejected": -154.4676055908203,
      "loss": 0.4123,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.4972494840621948,
      "rewards/margins": 1.6139570474624634,
      "rewards/rejected": -3.111206531524658,
      "step": 5540
    },
    {
      "epoch": 1.0128661374212975,
      "grad_norm": 4.231796741485596,
      "learning_rate": 6.415562488530006e-05,
      "logits/chosen": -0.5860615372657776,
      "logits/rejected": -0.4185641407966614,
      "logps/chosen": -171.5230712890625,
      "logps/rejected": -164.414794921875,
      "loss": 0.5147,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5197803974151611,
      "rewards/margins": 1.4931371212005615,
      "rewards/rejected": -3.0129177570343018,
      "step": 5550
    },
    {
      "epoch": 1.0146911214526873,
      "grad_norm": 4.261178970336914,
      "learning_rate": 6.412626169939439e-05,
      "logits/chosen": -0.5263468027114868,
      "logits/rejected": -0.3397127091884613,
      "logps/chosen": -176.77072143554688,
      "logps/rejected": -158.4198760986328,
      "loss": 0.454,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4260753393173218,
      "rewards/margins": 1.5404703617095947,
      "rewards/rejected": -2.966546058654785,
      "step": 5560
    },
    {
      "epoch": 1.016516105484077,
      "grad_norm": 2.9030327796936035,
      "learning_rate": 6.409689851348873e-05,
      "logits/chosen": -0.38063719868659973,
      "logits/rejected": -0.2119283378124237,
      "logps/chosen": -164.63450622558594,
      "logps/rejected": -162.94737243652344,
      "loss": 0.4346,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7787834405899048,
      "rewards/margins": 1.4571233987808228,
      "rewards/rejected": -3.2359066009521484,
      "step": 5570
    },
    {
      "epoch": 1.0183410895154668,
      "grad_norm": 3.10356068611145,
      "learning_rate": 6.406753532758305e-05,
      "logits/chosen": -0.5472859144210815,
      "logits/rejected": -0.44518351554870605,
      "logps/chosen": -164.63201904296875,
      "logps/rejected": -152.79405212402344,
      "loss": 0.5332,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7696651220321655,
      "rewards/margins": 1.0654538869857788,
      "rewards/rejected": -2.8351187705993652,
      "step": 5580
    },
    {
      "epoch": 1.0201660735468565,
      "grad_norm": 2.589674472808838,
      "learning_rate": 6.403817214167738e-05,
      "logits/chosen": -0.5309813618659973,
      "logits/rejected": -0.33752062916755676,
      "logps/chosen": -184.1675567626953,
      "logps/rejected": -156.08010864257812,
      "loss": 0.5005,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9249244928359985,
      "rewards/margins": 1.2931725978851318,
      "rewards/rejected": -3.21809720993042,
      "step": 5590
    },
    {
      "epoch": 1.0219910575782463,
      "grad_norm": 3.0117645263671875,
      "learning_rate": 6.400880895577171e-05,
      "logits/chosen": -0.597131609916687,
      "logits/rejected": -0.45697450637817383,
      "logps/chosen": -159.16897583007812,
      "logps/rejected": -156.79847717285156,
      "loss": 0.3809,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5619280338287354,
      "rewards/margins": 1.5166856050491333,
      "rewards/rejected": -3.07861328125,
      "step": 5600
    },
    {
      "epoch": 1.023816041609636,
      "grad_norm": 2.44808030128479,
      "learning_rate": 6.397944576986604e-05,
      "logits/chosen": -0.6343420743942261,
      "logits/rejected": -0.5992885828018188,
      "logps/chosen": -157.55482482910156,
      "logps/rejected": -182.08013916015625,
      "loss": 0.4122,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7987563610076904,
      "rewards/margins": 1.6251726150512695,
      "rewards/rejected": -3.423929214477539,
      "step": 5610
    },
    {
      "epoch": 1.0256410256410255,
      "grad_norm": 1.7681307792663574,
      "learning_rate": 6.395008258396036e-05,
      "logits/chosen": -0.7247345447540283,
      "logits/rejected": -0.6231305599212646,
      "logps/chosen": -160.25137329101562,
      "logps/rejected": -156.6611328125,
      "loss": 0.4785,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3199067115783691,
      "rewards/margins": 1.0868682861328125,
      "rewards/rejected": -2.4067752361297607,
      "step": 5620
    },
    {
      "epoch": 1.0274660096724153,
      "grad_norm": 4.10255765914917,
      "learning_rate": 6.392071939805469e-05,
      "logits/chosen": -0.6077435612678528,
      "logits/rejected": -0.47967633605003357,
      "logps/chosen": -172.93333435058594,
      "logps/rejected": -168.23423767089844,
      "loss": 0.4448,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7790052890777588,
      "rewards/margins": 1.6142253875732422,
      "rewards/rejected": -3.39323091506958,
      "step": 5630
    },
    {
      "epoch": 1.029290993703805,
      "grad_norm": 2.336123466491699,
      "learning_rate": 6.389135621214903e-05,
      "logits/chosen": -0.530392050743103,
      "logits/rejected": -0.4166535437107086,
      "logps/chosen": -167.57650756835938,
      "logps/rejected": -156.7416534423828,
      "loss": 0.4695,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.825079321861267,
      "rewards/margins": 1.2138173580169678,
      "rewards/rejected": -3.038896322250366,
      "step": 5640
    },
    {
      "epoch": 1.0311159777351948,
      "grad_norm": 4.548708438873291,
      "learning_rate": 6.386199302624335e-05,
      "logits/chosen": -0.6759635210037231,
      "logits/rejected": -0.5269520282745361,
      "logps/chosen": -194.19265747070312,
      "logps/rejected": -189.01132202148438,
      "loss": 0.4686,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4353429079055786,
      "rewards/margins": 1.375650405883789,
      "rewards/rejected": -2.8109934329986572,
      "step": 5650
    },
    {
      "epoch": 1.0329409617665846,
      "grad_norm": 3.6018316745758057,
      "learning_rate": 6.383262984033768e-05,
      "logits/chosen": -0.6616724729537964,
      "logits/rejected": -0.6108511686325073,
      "logps/chosen": -152.29122924804688,
      "logps/rejected": -164.69784545898438,
      "loss": 0.5208,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.463253378868103,
      "rewards/margins": 1.0299508571624756,
      "rewards/rejected": -2.493204116821289,
      "step": 5660
    },
    {
      "epoch": 1.0347659457979743,
      "grad_norm": 1.8434031009674072,
      "learning_rate": 6.380326665443201e-05,
      "logits/chosen": -0.6448317766189575,
      "logits/rejected": -0.45675331354141235,
      "logps/chosen": -163.68753051757812,
      "logps/rejected": -135.03741455078125,
      "loss": 0.4369,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3803071975708008,
      "rewards/margins": 1.5119653940200806,
      "rewards/rejected": -2.892272472381592,
      "step": 5670
    },
    {
      "epoch": 1.036590929829364,
      "grad_norm": 2.1463499069213867,
      "learning_rate": 6.377390346852634e-05,
      "logits/chosen": -0.6293485760688782,
      "logits/rejected": -0.5106307864189148,
      "logps/chosen": -164.21856689453125,
      "logps/rejected": -158.6774139404297,
      "loss": 0.3958,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.0070723295211792,
      "rewards/margins": 1.542955994606018,
      "rewards/rejected": -2.5500283241271973,
      "step": 5680
    },
    {
      "epoch": 1.0384159138607538,
      "grad_norm": 3.3240127563476562,
      "learning_rate": 6.374454028262068e-05,
      "logits/chosen": -0.606593906879425,
      "logits/rejected": -0.49921974539756775,
      "logps/chosen": -153.66795349121094,
      "logps/rejected": -141.32308959960938,
      "loss": 0.4661,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.0583488941192627,
      "rewards/margins": 1.4020119905471802,
      "rewards/rejected": -2.4603607654571533,
      "step": 5690
    },
    {
      "epoch": 1.0402408978921434,
      "grad_norm": 3.755011558532715,
      "learning_rate": 6.3715177096715e-05,
      "logits/chosen": -0.639191210269928,
      "logits/rejected": -0.5411599278450012,
      "logps/chosen": -161.2498016357422,
      "logps/rejected": -149.67208862304688,
      "loss": 0.4626,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4600088596343994,
      "rewards/margins": 1.2859394550323486,
      "rewards/rejected": -2.745948314666748,
      "step": 5700
    },
    {
      "epoch": 1.042065881923533,
      "grad_norm": 3.503048896789551,
      "learning_rate": 6.368581391080933e-05,
      "logits/chosen": -0.7637280225753784,
      "logits/rejected": -0.6726837158203125,
      "logps/chosen": -158.65719604492188,
      "logps/rejected": -164.15518188476562,
      "loss": 0.4243,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8065878748893738,
      "rewards/margins": 1.5369666814804077,
      "rewards/rejected": -2.343554735183716,
      "step": 5710
    },
    {
      "epoch": 1.0438908659549229,
      "grad_norm": 2.1986422538757324,
      "learning_rate": 6.365645072490366e-05,
      "logits/chosen": -0.7413007616996765,
      "logits/rejected": -0.7183662056922913,
      "logps/chosen": -157.18472290039062,
      "logps/rejected": -183.21298217773438,
      "loss": 0.4609,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.181980848312378,
      "rewards/margins": 1.4541254043579102,
      "rewards/rejected": -2.636106014251709,
      "step": 5720
    },
    {
      "epoch": 1.0457158499863126,
      "grad_norm": 3.761337995529175,
      "learning_rate": 6.362708753899799e-05,
      "logits/chosen": -0.6247678995132446,
      "logits/rejected": -0.49537211656570435,
      "logps/chosen": -174.04965209960938,
      "logps/rejected": -168.45672607421875,
      "loss": 0.5481,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.430849313735962,
      "rewards/margins": 1.0739445686340332,
      "rewards/rejected": -3.504793643951416,
      "step": 5730
    },
    {
      "epoch": 1.0475408340177024,
      "grad_norm": 3.406484603881836,
      "learning_rate": 6.359772435309231e-05,
      "logits/chosen": -0.5989847779273987,
      "logits/rejected": -0.4608948826789856,
      "logps/chosen": -166.21420288085938,
      "logps/rejected": -177.6361846923828,
      "loss": 0.3993,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.2165563106536865,
      "rewards/margins": 1.5328292846679688,
      "rewards/rejected": -3.7493858337402344,
      "step": 5740
    },
    {
      "epoch": 1.0493658180490921,
      "grad_norm": 2.0655338764190674,
      "learning_rate": 6.356836116718664e-05,
      "logits/chosen": -0.7106723189353943,
      "logits/rejected": -0.5795159339904785,
      "logps/chosen": -186.314208984375,
      "logps/rejected": -176.511474609375,
      "loss": 0.493,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8609927892684937,
      "rewards/margins": 1.160836100578308,
      "rewards/rejected": -3.0218286514282227,
      "step": 5750
    },
    {
      "epoch": 1.0511908020804819,
      "grad_norm": 3.9155290126800537,
      "learning_rate": 6.353899798128098e-05,
      "logits/chosen": -0.6800404191017151,
      "logits/rejected": -0.4958677887916565,
      "logps/chosen": -187.97657775878906,
      "logps/rejected": -165.0723419189453,
      "loss": 0.3871,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.189457416534424,
      "rewards/margins": 1.6032661199569702,
      "rewards/rejected": -3.7927231788635254,
      "step": 5760
    },
    {
      "epoch": 1.0530157861118714,
      "grad_norm": 4.7212347984313965,
      "learning_rate": 6.35096347953753e-05,
      "logits/chosen": -0.7850632667541504,
      "logits/rejected": -0.6394342184066772,
      "logps/chosen": -161.09129333496094,
      "logps/rejected": -161.57852172851562,
      "loss": 0.4522,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7209478616714478,
      "rewards/margins": 1.3776543140411377,
      "rewards/rejected": -3.098602056503296,
      "step": 5770
    },
    {
      "epoch": 1.0548407701432612,
      "grad_norm": 2.1977813243865967,
      "learning_rate": 6.348027160946962e-05,
      "logits/chosen": -0.7660350799560547,
      "logits/rejected": -0.6419476270675659,
      "logps/chosen": -157.36724853515625,
      "logps/rejected": -147.3818359375,
      "loss": 0.4869,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8038902282714844,
      "rewards/margins": 1.4367988109588623,
      "rewards/rejected": -3.2406890392303467,
      "step": 5780
    },
    {
      "epoch": 1.056665754174651,
      "grad_norm": 3.0396885871887207,
      "learning_rate": 6.345090842356396e-05,
      "logits/chosen": -0.8400640487670898,
      "logits/rejected": -0.6788256764411926,
      "logps/chosen": -183.819580078125,
      "logps/rejected": -158.35552978515625,
      "loss": 0.4288,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5462881326675415,
      "rewards/margins": 1.450993537902832,
      "rewards/rejected": -2.997281551361084,
      "step": 5790
    },
    {
      "epoch": 1.0584907382060407,
      "grad_norm": 2.4321601390838623,
      "learning_rate": 6.342154523765829e-05,
      "logits/chosen": -0.9101929664611816,
      "logits/rejected": -0.8177310824394226,
      "logps/chosen": -156.31820678710938,
      "logps/rejected": -149.6764678955078,
      "loss": 0.5898,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7186365127563477,
      "rewards/margins": 0.9453977346420288,
      "rewards/rejected": -2.664034366607666,
      "step": 5800
    },
    {
      "epoch": 1.0603157222374304,
      "grad_norm": 2.197058916091919,
      "learning_rate": 6.339218205175263e-05,
      "logits/chosen": -0.8915064930915833,
      "logits/rejected": -0.7472825646400452,
      "logps/chosen": -174.51385498046875,
      "logps/rejected": -161.0206756591797,
      "loss": 0.4359,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1756104230880737,
      "rewards/margins": 1.3105989694595337,
      "rewards/rejected": -2.4862091541290283,
      "step": 5810
    },
    {
      "epoch": 1.0621407062688202,
      "grad_norm": 2.7526583671569824,
      "learning_rate": 6.336281886584695e-05,
      "logits/chosen": -0.8457952737808228,
      "logits/rejected": -0.702318549156189,
      "logps/chosen": -164.8127899169922,
      "logps/rejected": -146.7538604736328,
      "loss": 0.3362,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.4918053150177002,
      "rewards/margins": 1.7154853343963623,
      "rewards/rejected": -3.2072906494140625,
      "step": 5820
    },
    {
      "epoch": 1.06396569030021,
      "grad_norm": 2.6890389919281006,
      "learning_rate": 6.333345567994129e-05,
      "logits/chosen": -0.7540114521980286,
      "logits/rejected": -0.6002928018569946,
      "logps/chosen": -171.9306182861328,
      "logps/rejected": -167.01602172851562,
      "loss": 0.3697,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.037158489227295,
      "rewards/margins": 1.8916330337524414,
      "rewards/rejected": -3.9287917613983154,
      "step": 5830
    },
    {
      "epoch": 1.0657906743315997,
      "grad_norm": 3.150545358657837,
      "learning_rate": 6.330409249403561e-05,
      "logits/chosen": -0.6846485733985901,
      "logits/rejected": -0.6328535079956055,
      "logps/chosen": -167.57254028320312,
      "logps/rejected": -173.15895080566406,
      "loss": 0.3955,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.399151563644409,
      "rewards/margins": 1.6091864109039307,
      "rewards/rejected": -4.00833797454834,
      "step": 5840
    },
    {
      "epoch": 1.0676156583629894,
      "grad_norm": 3.6545021533966064,
      "learning_rate": 6.327472930812994e-05,
      "logits/chosen": -0.753416895866394,
      "logits/rejected": -0.5896686911582947,
      "logps/chosen": -185.84483337402344,
      "logps/rejected": -172.46255493164062,
      "loss": 0.3932,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.4082484245300293,
      "rewards/margins": 1.797254204750061,
      "rewards/rejected": -4.205502510070801,
      "step": 5850
    },
    {
      "epoch": 1.069440642394379,
      "grad_norm": 4.424505710601807,
      "learning_rate": 6.324536612222426e-05,
      "logits/chosen": -0.6661549806594849,
      "logits/rejected": -0.620346188545227,
      "logps/chosen": -156.68313598632812,
      "logps/rejected": -156.44285583496094,
      "loss": 0.5117,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.225379467010498,
      "rewards/margins": 1.1146600246429443,
      "rewards/rejected": -3.340039014816284,
      "step": 5860
    },
    {
      "epoch": 1.0712656264257687,
      "grad_norm": 3.4102132320404053,
      "learning_rate": 6.32160029363186e-05,
      "logits/chosen": -0.7460139989852905,
      "logits/rejected": -0.6191354990005493,
      "logps/chosen": -177.05487060546875,
      "logps/rejected": -170.20925903320312,
      "loss": 0.5236,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.4313056468963623,
      "rewards/margins": 1.2232216596603394,
      "rewards/rejected": -3.6545276641845703,
      "step": 5870
    },
    {
      "epoch": 1.0730906104571585,
      "grad_norm": 2.109323024749756,
      "learning_rate": 6.318663975041292e-05,
      "logits/chosen": -0.8027035593986511,
      "logits/rejected": -0.5892555117607117,
      "logps/chosen": -187.5743865966797,
      "logps/rejected": -169.68368530273438,
      "loss": 0.4682,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.210284471511841,
      "rewards/margins": 1.3769840002059937,
      "rewards/rejected": -3.587268829345703,
      "step": 5880
    },
    {
      "epoch": 1.0749155944885482,
      "grad_norm": 5.541615009307861,
      "learning_rate": 6.315727656450725e-05,
      "logits/chosen": -0.7888079285621643,
      "logits/rejected": -0.6356797218322754,
      "logps/chosen": -168.17800903320312,
      "logps/rejected": -154.13218688964844,
      "loss": 0.4303,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9429155588150024,
      "rewards/margins": 1.5430841445922852,
      "rewards/rejected": -3.485999584197998,
      "step": 5890
    },
    {
      "epoch": 1.076740578519938,
      "grad_norm": 3.6127004623413086,
      "learning_rate": 6.312791337860157e-05,
      "logits/chosen": -0.7351537942886353,
      "logits/rejected": -0.5883548855781555,
      "logps/chosen": -169.81878662109375,
      "logps/rejected": -153.66639709472656,
      "loss": 0.4147,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3726962804794312,
      "rewards/margins": 1.487220048904419,
      "rewards/rejected": -2.8599162101745605,
      "step": 5900
    },
    {
      "epoch": 1.0785655625513277,
      "grad_norm": 1.9093233346939087,
      "learning_rate": 6.309855019269591e-05,
      "logits/chosen": -0.7479936480522156,
      "logits/rejected": -0.6177975535392761,
      "logps/chosen": -162.96546936035156,
      "logps/rejected": -161.8978729248047,
      "loss": 0.5366,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9146158695220947,
      "rewards/margins": 1.2308635711669922,
      "rewards/rejected": -3.145479202270508,
      "step": 5910
    },
    {
      "epoch": 1.0803905465827175,
      "grad_norm": 4.139476776123047,
      "learning_rate": 6.306918700679024e-05,
      "logits/chosen": -0.7543007731437683,
      "logits/rejected": -0.5633798837661743,
      "logps/chosen": -170.31735229492188,
      "logps/rejected": -180.69337463378906,
      "loss": 0.3145,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.709494948387146,
      "rewards/margins": 2.5839295387268066,
      "rewards/rejected": -4.293424606323242,
      "step": 5920
    },
    {
      "epoch": 1.082215530614107,
      "grad_norm": 4.682804584503174,
      "learning_rate": 6.303982382088457e-05,
      "logits/chosen": -0.770878791809082,
      "logits/rejected": -0.6953245401382446,
      "logps/chosen": -166.9320526123047,
      "logps/rejected": -179.58543395996094,
      "loss": 0.5377,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.9869880676269531,
      "rewards/margins": 1.439271092414856,
      "rewards/rejected": -3.4262592792510986,
      "step": 5930
    },
    {
      "epoch": 1.0840405146454968,
      "grad_norm": 3.590501308441162,
      "learning_rate": 6.30104606349789e-05,
      "logits/chosen": -0.8036152124404907,
      "logits/rejected": -0.6829372644424438,
      "logps/chosen": -156.08554077148438,
      "logps/rejected": -141.66110229492188,
      "loss": 0.5332,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.032165050506592,
      "rewards/margins": 1.1131312847137451,
      "rewards/rejected": -3.145296573638916,
      "step": 5940
    },
    {
      "epoch": 1.0858654986768865,
      "grad_norm": 4.5172224044799805,
      "learning_rate": 6.298109744907324e-05,
      "logits/chosen": -0.705018162727356,
      "logits/rejected": -0.614895224571228,
      "logps/chosen": -164.74827575683594,
      "logps/rejected": -163.02554321289062,
      "loss": 0.4275,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7057983875274658,
      "rewards/margins": 1.3254426717758179,
      "rewards/rejected": -3.031240940093994,
      "step": 5950
    },
    {
      "epoch": 1.0876904827082763,
      "grad_norm": 2.848036766052246,
      "learning_rate": 6.295173426316756e-05,
      "logits/chosen": -0.7118406891822815,
      "logits/rejected": -0.5704129934310913,
      "logps/chosen": -154.9495849609375,
      "logps/rejected": -150.38670349121094,
      "loss": 0.3906,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.775090217590332,
      "rewards/margins": 1.5026025772094727,
      "rewards/rejected": -3.2776927947998047,
      "step": 5960
    },
    {
      "epoch": 1.089515466739666,
      "grad_norm": 2.313793897628784,
      "learning_rate": 6.292237107726189e-05,
      "logits/chosen": -0.6382349729537964,
      "logits/rejected": -0.4674808382987976,
      "logps/chosen": -171.1011199951172,
      "logps/rejected": -166.1039276123047,
      "loss": 0.4365,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.1787590980529785,
      "rewards/margins": 1.7212871313095093,
      "rewards/rejected": -3.9000465869903564,
      "step": 5970
    },
    {
      "epoch": 1.0913404507710558,
      "grad_norm": 2.7340006828308105,
      "learning_rate": 6.289300789135622e-05,
      "logits/chosen": -0.6505469083786011,
      "logits/rejected": -0.5345195531845093,
      "logps/chosen": -158.1067352294922,
      "logps/rejected": -164.62509155273438,
      "loss": 0.4522,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0388011932373047,
      "rewards/margins": 1.7524229288101196,
      "rewards/rejected": -3.7912240028381348,
      "step": 5980
    },
    {
      "epoch": 1.0931654348024455,
      "grad_norm": 5.017877101898193,
      "learning_rate": 6.286364470545055e-05,
      "logits/chosen": -0.5934066772460938,
      "logits/rejected": -0.43198060989379883,
      "logps/chosen": -156.07241821289062,
      "logps/rejected": -156.4458770751953,
      "loss": 0.4015,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.1283023357391357,
      "rewards/margins": 1.853690505027771,
      "rewards/rejected": -3.981992721557617,
      "step": 5990
    },
    {
      "epoch": 1.0949904188338353,
      "grad_norm": 5.843588829040527,
      "learning_rate": 6.283428151954487e-05,
      "logits/chosen": -0.7162147760391235,
      "logits/rejected": -0.4916412830352783,
      "logps/chosen": -177.72122192382812,
      "logps/rejected": -141.96981811523438,
      "loss": 0.4497,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.689751386642456,
      "rewards/margins": 1.4756901264190674,
      "rewards/rejected": -3.1654417514801025,
      "step": 6000
    },
    {
      "epoch": 1.0968154028652248,
      "grad_norm": 3.498487710952759,
      "learning_rate": 6.28049183336392e-05,
      "logits/chosen": -0.6989659070968628,
      "logits/rejected": -0.6170878410339355,
      "logps/chosen": -182.24758911132812,
      "logps/rejected": -183.90817260742188,
      "loss": 0.4393,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8520383834838867,
      "rewards/margins": 1.4342942237854004,
      "rewards/rejected": -3.286332607269287,
      "step": 6010
    },
    {
      "epoch": 1.0986403868966146,
      "grad_norm": 4.242270469665527,
      "learning_rate": 6.277555514773354e-05,
      "logits/chosen": -0.6894181966781616,
      "logits/rejected": -0.5180826783180237,
      "logps/chosen": -169.25323486328125,
      "logps/rejected": -160.11972045898438,
      "loss": 0.4439,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7757622003555298,
      "rewards/margins": 1.6879823207855225,
      "rewards/rejected": -3.4637444019317627,
      "step": 6020
    },
    {
      "epoch": 1.1004653709280043,
      "grad_norm": 4.330788612365723,
      "learning_rate": 6.274619196182786e-05,
      "logits/chosen": -0.7250025868415833,
      "logits/rejected": -0.6089102029800415,
      "logps/chosen": -159.57467651367188,
      "logps/rejected": -153.5621337890625,
      "loss": 0.4212,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.7036809921264648,
      "rewards/margins": 1.418826699256897,
      "rewards/rejected": -3.1225075721740723,
      "step": 6030
    },
    {
      "epoch": 1.102290354959394,
      "grad_norm": 4.3421149253845215,
      "learning_rate": 6.271682877592219e-05,
      "logits/chosen": -0.7032038569450378,
      "logits/rejected": -0.5802026987075806,
      "logps/chosen": -170.29562377929688,
      "logps/rejected": -176.17697143554688,
      "loss": 0.3563,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5850555896759033,
      "rewards/margins": 1.9033515453338623,
      "rewards/rejected": -3.4884071350097656,
      "step": 6040
    },
    {
      "epoch": 1.1041153389907838,
      "grad_norm": 4.189027786254883,
      "learning_rate": 6.268746559001652e-05,
      "logits/chosen": -0.7402170896530151,
      "logits/rejected": -0.7072362899780273,
      "logps/chosen": -157.02633666992188,
      "logps/rejected": -174.06002807617188,
      "loss": 0.5107,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7781572341918945,
      "rewards/margins": 1.4641971588134766,
      "rewards/rejected": -3.24235463142395,
      "step": 6050
    },
    {
      "epoch": 1.1059403230221736,
      "grad_norm": 2.7144155502319336,
      "learning_rate": 6.265810240411085e-05,
      "logits/chosen": -0.7560636401176453,
      "logits/rejected": -0.6375064253807068,
      "logps/chosen": -157.83485412597656,
      "logps/rejected": -162.67259216308594,
      "loss": 0.3482,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.370252013206482,
      "rewards/margins": 1.8177988529205322,
      "rewards/rejected": -3.1880507469177246,
      "step": 6060
    },
    {
      "epoch": 1.1077653070535634,
      "grad_norm": 3.7881851196289062,
      "learning_rate": 6.262873921820519e-05,
      "logits/chosen": -0.7857351303100586,
      "logits/rejected": -0.6203340291976929,
      "logps/chosen": -153.44827270507812,
      "logps/rejected": -155.7795867919922,
      "loss": 0.4612,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.4285938739776611,
      "rewards/margins": 1.5342410802841187,
      "rewards/rejected": -2.9628348350524902,
      "step": 6070
    },
    {
      "epoch": 1.109590291084953,
      "grad_norm": 5.003942489624023,
      "learning_rate": 6.259937603229951e-05,
      "logits/chosen": -0.7816725969314575,
      "logits/rejected": -0.7644147276878357,
      "logps/chosen": -135.8924102783203,
      "logps/rejected": -148.4257049560547,
      "loss": 0.5161,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.719423532485962,
      "rewards/margins": 1.3024225234985352,
      "rewards/rejected": -3.021845817565918,
      "step": 6080
    },
    {
      "epoch": 1.1114152751163426,
      "grad_norm": 4.025974273681641,
      "learning_rate": 6.257001284639384e-05,
      "logits/chosen": -0.7865272760391235,
      "logits/rejected": -0.6637139320373535,
      "logps/chosen": -166.06393432617188,
      "logps/rejected": -153.134765625,
      "loss": 0.5487,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.3984920978546143,
      "rewards/margins": 0.9669920802116394,
      "rewards/rejected": -2.3654839992523193,
      "step": 6090
    },
    {
      "epoch": 1.1132402591477324,
      "grad_norm": 2.169861078262329,
      "learning_rate": 6.254064966048817e-05,
      "logits/chosen": -0.8000937700271606,
      "logits/rejected": -0.7075483798980713,
      "logps/chosen": -155.0614776611328,
      "logps/rejected": -163.5400390625,
      "loss": 0.5079,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3805850744247437,
      "rewards/margins": 1.1453232765197754,
      "rewards/rejected": -2.5259082317352295,
      "step": 6100
    },
    {
      "epoch": 1.1150652431791221,
      "grad_norm": 3.7100367546081543,
      "learning_rate": 6.25112864745825e-05,
      "logits/chosen": -0.7791115045547485,
      "logits/rejected": -0.7206988334655762,
      "logps/chosen": -166.3573760986328,
      "logps/rejected": -183.64248657226562,
      "loss": 0.4736,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4979912042617798,
      "rewards/margins": 1.4381320476531982,
      "rewards/rejected": -2.9361233711242676,
      "step": 6110
    },
    {
      "epoch": 1.116890227210512,
      "grad_norm": 4.343199253082275,
      "learning_rate": 6.248192328867682e-05,
      "logits/chosen": -0.7813694477081299,
      "logits/rejected": -0.7041343450546265,
      "logps/chosen": -140.87185668945312,
      "logps/rejected": -150.19583129882812,
      "loss": 0.4322,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4243075847625732,
      "rewards/margins": 1.4418141841888428,
      "rewards/rejected": -2.866121768951416,
      "step": 6120
    },
    {
      "epoch": 1.1187152112419017,
      "grad_norm": 3.451680898666382,
      "learning_rate": 6.245256010277115e-05,
      "logits/chosen": -0.7747524976730347,
      "logits/rejected": -0.6775029897689819,
      "logps/chosen": -157.8356170654297,
      "logps/rejected": -164.4462432861328,
      "loss": 0.4542,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.7284507751464844,
      "rewards/margins": 1.3482897281646729,
      "rewards/rejected": -3.076740264892578,
      "step": 6130
    },
    {
      "epoch": 1.1205401952732914,
      "grad_norm": 2.382897138595581,
      "learning_rate": 6.242319691686549e-05,
      "logits/chosen": -0.7462030649185181,
      "logits/rejected": -0.569243848323822,
      "logps/chosen": -157.81253051757812,
      "logps/rejected": -146.6170196533203,
      "loss": 0.3698,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.647613525390625,
      "rewards/margins": 1.660994291305542,
      "rewards/rejected": -3.308608293533325,
      "step": 6140
    },
    {
      "epoch": 1.1223651793046812,
      "grad_norm": 3.2304046154022217,
      "learning_rate": 6.239383373095981e-05,
      "logits/chosen": -0.733962893486023,
      "logits/rejected": -0.6237901449203491,
      "logps/chosen": -153.00469970703125,
      "logps/rejected": -160.8491973876953,
      "loss": 0.3834,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7588531970977783,
      "rewards/margins": 1.7142566442489624,
      "rewards/rejected": -3.473109722137451,
      "step": 6150
    },
    {
      "epoch": 1.124190163336071,
      "grad_norm": 1.9978150129318237,
      "learning_rate": 6.236447054505413e-05,
      "logits/chosen": -0.7115598917007446,
      "logits/rejected": -0.6346403956413269,
      "logps/chosen": -148.7363739013672,
      "logps/rejected": -159.38632202148438,
      "loss": 0.419,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.312126398086548,
      "rewards/margins": 1.4634448289871216,
      "rewards/rejected": -3.775571346282959,
      "step": 6160
    },
    {
      "epoch": 1.1260151473674604,
      "grad_norm": 2.4047889709472656,
      "learning_rate": 6.233510735914847e-05,
      "logits/chosen": -0.639689564704895,
      "logits/rejected": -0.5461100339889526,
      "logps/chosen": -153.54150390625,
      "logps/rejected": -154.65914916992188,
      "loss": 0.5905,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.163486957550049,
      "rewards/margins": 0.9525507688522339,
      "rewards/rejected": -3.1160380840301514,
      "step": 6170
    },
    {
      "epoch": 1.1278401313988502,
      "grad_norm": 1.6366592645645142,
      "learning_rate": 6.23057441732428e-05,
      "logits/chosen": -0.8008020520210266,
      "logits/rejected": -0.6134785413742065,
      "logps/chosen": -169.1972198486328,
      "logps/rejected": -165.25498962402344,
      "loss": 0.3433,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5543277263641357,
      "rewards/margins": 1.7302570343017578,
      "rewards/rejected": -3.2845847606658936,
      "step": 6180
    },
    {
      "epoch": 1.12966511543024,
      "grad_norm": 1.4269065856933594,
      "learning_rate": 6.227638098733714e-05,
      "logits/chosen": -0.7507084608078003,
      "logits/rejected": -0.5458153486251831,
      "logps/chosen": -168.8995819091797,
      "logps/rejected": -167.14219665527344,
      "loss": 0.3983,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7213523387908936,
      "rewards/margins": 1.7885425090789795,
      "rewards/rejected": -3.509894847869873,
      "step": 6190
    },
    {
      "epoch": 1.1314900994616297,
      "grad_norm": 2.6677517890930176,
      "learning_rate": 6.224701780143146e-05,
      "logits/chosen": -0.767907977104187,
      "logits/rejected": -0.6337826251983643,
      "logps/chosen": -156.50596618652344,
      "logps/rejected": -169.3897705078125,
      "loss": 0.4124,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.4695321321487427,
      "rewards/margins": 1.9804527759552002,
      "rewards/rejected": -3.4499847888946533,
      "step": 6200
    },
    {
      "epoch": 1.1333150834930195,
      "grad_norm": 3.7767136096954346,
      "learning_rate": 6.22176546155258e-05,
      "logits/chosen": -0.7614262104034424,
      "logits/rejected": -0.5995272397994995,
      "logps/chosen": -172.6307373046875,
      "logps/rejected": -159.4301300048828,
      "loss": 0.4589,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6942946910858154,
      "rewards/margins": 1.7150189876556396,
      "rewards/rejected": -3.409313678741455,
      "step": 6210
    },
    {
      "epoch": 1.1351400675244092,
      "grad_norm": 3.2314066886901855,
      "learning_rate": 6.218829142962012e-05,
      "logits/chosen": -0.7146409749984741,
      "logits/rejected": -0.5640746355056763,
      "logps/chosen": -179.12326049804688,
      "logps/rejected": -156.8474578857422,
      "loss": 0.5392,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.6956707239151,
      "rewards/margins": 1.2367973327636719,
      "rewards/rejected": -2.9324679374694824,
      "step": 6220
    },
    {
      "epoch": 1.136965051555799,
      "grad_norm": 2.7969322204589844,
      "learning_rate": 6.215892824371445e-05,
      "logits/chosen": -0.7425128817558289,
      "logits/rejected": -0.5156199336051941,
      "logps/chosen": -160.47283935546875,
      "logps/rejected": -162.05557250976562,
      "loss": 0.357,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4053030014038086,
      "rewards/margins": 1.7431392669677734,
      "rewards/rejected": -3.148441791534424,
      "step": 6230
    },
    {
      "epoch": 1.1387900355871885,
      "grad_norm": 3.0903146266937256,
      "learning_rate": 6.212956505780877e-05,
      "logits/chosen": -0.7951772809028625,
      "logits/rejected": -0.6664162278175354,
      "logps/chosen": -162.48411560058594,
      "logps/rejected": -154.51156616210938,
      "loss": 0.4195,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4220625162124634,
      "rewards/margins": 1.5041394233703613,
      "rewards/rejected": -2.926201820373535,
      "step": 6240
    },
    {
      "epoch": 1.1406150196185783,
      "grad_norm": 3.8038527965545654,
      "learning_rate": 6.210020187190311e-05,
      "logits/chosen": -0.818442702293396,
      "logits/rejected": -0.6633504033088684,
      "logps/chosen": -153.02346801757812,
      "logps/rejected": -154.21792602539062,
      "loss": 0.5283,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2279378175735474,
      "rewards/margins": 1.8070869445800781,
      "rewards/rejected": -3.035024642944336,
      "step": 6250
    },
    {
      "epoch": 1.142440003649968,
      "grad_norm": 2.9002177715301514,
      "learning_rate": 6.207083868599743e-05,
      "logits/chosen": -0.8060271143913269,
      "logits/rejected": -0.6768648028373718,
      "logps/chosen": -171.7257080078125,
      "logps/rejected": -155.1990966796875,
      "loss": 0.5012,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.2581961154937744,
      "rewards/margins": 1.2114728689193726,
      "rewards/rejected": -2.4696688652038574,
      "step": 6260
    },
    {
      "epoch": 1.1442649876813578,
      "grad_norm": 2.158480167388916,
      "learning_rate": 6.204147550009176e-05,
      "logits/chosen": -0.9748996496200562,
      "logits/rejected": -0.7824895977973938,
      "logps/chosen": -172.39187622070312,
      "logps/rejected": -144.520263671875,
      "loss": 0.3538,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.9738461375236511,
      "rewards/margins": 1.638990044593811,
      "rewards/rejected": -2.6128361225128174,
      "step": 6270
    },
    {
      "epoch": 1.1460899717127475,
      "grad_norm": 2.4332075119018555,
      "learning_rate": 6.201211231418608e-05,
      "logits/chosen": -0.9048616290092468,
      "logits/rejected": -0.8002263903617859,
      "logps/chosen": -166.706298828125,
      "logps/rejected": -161.66416931152344,
      "loss": 0.4377,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1582763195037842,
      "rewards/margins": 1.3934634923934937,
      "rewards/rejected": -2.5517399311065674,
      "step": 6280
    },
    {
      "epoch": 1.1479149557441373,
      "grad_norm": 2.5089669227600098,
      "learning_rate": 6.198274912828042e-05,
      "logits/chosen": -0.8999268412590027,
      "logits/rejected": -0.861914336681366,
      "logps/chosen": -143.4618682861328,
      "logps/rejected": -168.70602416992188,
      "loss": 0.3997,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1362183094024658,
      "rewards/margins": 1.6180737018585205,
      "rewards/rejected": -2.7542920112609863,
      "step": 6290
    },
    {
      "epoch": 1.149739939775527,
      "grad_norm": 4.505843162536621,
      "learning_rate": 6.195338594237475e-05,
      "logits/chosen": -0.9098811149597168,
      "logits/rejected": -0.7663337588310242,
      "logps/chosen": -161.51377868652344,
      "logps/rejected": -167.39547729492188,
      "loss": 0.4652,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3232672214508057,
      "rewards/margins": 1.7026405334472656,
      "rewards/rejected": -3.0259077548980713,
      "step": 6300
    },
    {
      "epoch": 1.1515649238069168,
      "grad_norm": 3.19372820854187,
      "learning_rate": 6.192402275646908e-05,
      "logits/chosen": -0.971746563911438,
      "logits/rejected": -0.8241367340087891,
      "logps/chosen": -164.8202362060547,
      "logps/rejected": -161.9679718017578,
      "loss": 0.5564,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.5383903980255127,
      "rewards/margins": 1.4086042642593384,
      "rewards/rejected": -2.9469947814941406,
      "step": 6310
    },
    {
      "epoch": 1.1533899078383065,
      "grad_norm": 5.598068714141846,
      "learning_rate": 6.189465957056341e-05,
      "logits/chosen": -0.9290395975112915,
      "logits/rejected": -0.742841899394989,
      "logps/chosen": -171.01016235351562,
      "logps/rejected": -152.2485809326172,
      "loss": 0.4264,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5020784139633179,
      "rewards/margins": 1.9161211252212524,
      "rewards/rejected": -3.418199062347412,
      "step": 6320
    },
    {
      "epoch": 1.155214891869696,
      "grad_norm": 3.427760362625122,
      "learning_rate": 6.186529638465775e-05,
      "logits/chosen": -0.8700571060180664,
      "logits/rejected": -0.760186493396759,
      "logps/chosen": -166.44308471679688,
      "logps/rejected": -165.18698120117188,
      "loss": 0.4926,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.885357141494751,
      "rewards/margins": 1.451070785522461,
      "rewards/rejected": -3.336427688598633,
      "step": 6330
    },
    {
      "epoch": 1.1570398759010858,
      "grad_norm": 4.840034008026123,
      "learning_rate": 6.183593319875207e-05,
      "logits/chosen": -0.894454300403595,
      "logits/rejected": -0.8209188580513,
      "logps/chosen": -164.55531311035156,
      "logps/rejected": -166.34242248535156,
      "loss": 0.5131,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4417088031768799,
      "rewards/margins": 0.9996150732040405,
      "rewards/rejected": -2.441323757171631,
      "step": 6340
    },
    {
      "epoch": 1.1588648599324756,
      "grad_norm": 1.2493221759796143,
      "learning_rate": 6.18065700128464e-05,
      "logits/chosen": -0.8793816566467285,
      "logits/rejected": -0.7960892915725708,
      "logps/chosen": -158.13519287109375,
      "logps/rejected": -150.25169372558594,
      "loss": 0.5049,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4015510082244873,
      "rewards/margins": 1.2104727029800415,
      "rewards/rejected": -2.61202335357666,
      "step": 6350
    },
    {
      "epoch": 1.1606898439638653,
      "grad_norm": 3.556414842605591,
      "learning_rate": 6.177720682694073e-05,
      "logits/chosen": -1.0156774520874023,
      "logits/rejected": -0.8708551526069641,
      "logps/chosen": -155.43638610839844,
      "logps/rejected": -152.32884216308594,
      "loss": 0.3267,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.2540525197982788,
      "rewards/margins": 1.7720062732696533,
      "rewards/rejected": -3.0260586738586426,
      "step": 6360
    },
    {
      "epoch": 1.162514827995255,
      "grad_norm": 4.627910137176514,
      "learning_rate": 6.174784364103506e-05,
      "logits/chosen": -0.9034485816955566,
      "logits/rejected": -0.8010517954826355,
      "logps/chosen": -174.9706268310547,
      "logps/rejected": -170.39324951171875,
      "loss": 0.551,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7948169708251953,
      "rewards/margins": 1.2788560390472412,
      "rewards/rejected": -3.0736727714538574,
      "step": 6370
    },
    {
      "epoch": 1.1643398120266448,
      "grad_norm": 3.9706718921661377,
      "learning_rate": 6.171848045512938e-05,
      "logits/chosen": -0.9259781837463379,
      "logits/rejected": -0.7618755102157593,
      "logps/chosen": -166.6340789794922,
      "logps/rejected": -154.57290649414062,
      "loss": 0.4783,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7744709253311157,
      "rewards/margins": 1.365064263343811,
      "rewards/rejected": -3.1395349502563477,
      "step": 6380
    },
    {
      "epoch": 1.1661647960580346,
      "grad_norm": 4.669676780700684,
      "learning_rate": 6.168911726922371e-05,
      "logits/chosen": -0.8844391703605652,
      "logits/rejected": -0.8578652143478394,
      "logps/chosen": -150.3603057861328,
      "logps/rejected": -167.88357543945312,
      "loss": 0.4679,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.9088424444198608,
      "rewards/margins": 1.1017100811004639,
      "rewards/rejected": -3.0105526447296143,
      "step": 6390
    },
    {
      "epoch": 1.1679897800894241,
      "grad_norm": 2.127641201019287,
      "learning_rate": 6.165975408331805e-05,
      "logits/chosen": -0.9035337567329407,
      "logits/rejected": -0.776156485080719,
      "logps/chosen": -159.525634765625,
      "logps/rejected": -147.50416564941406,
      "loss": 0.455,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3060524463653564,
      "rewards/margins": 1.2768992185592651,
      "rewards/rejected": -2.5829520225524902,
      "step": 6400
    },
    {
      "epoch": 1.1698147641208139,
      "grad_norm": 2.599700450897217,
      "learning_rate": 6.163039089741237e-05,
      "logits/chosen": -0.9859136343002319,
      "logits/rejected": -0.8394643664360046,
      "logps/chosen": -165.38442993164062,
      "logps/rejected": -166.80824279785156,
      "loss": 0.3421,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.2512714862823486,
      "rewards/margins": 1.6740663051605225,
      "rewards/rejected": -2.925337553024292,
      "step": 6410
    },
    {
      "epoch": 1.1716397481522036,
      "grad_norm": 3.3045296669006348,
      "learning_rate": 6.16010277115067e-05,
      "logits/chosen": -0.8366388082504272,
      "logits/rejected": -0.6821971535682678,
      "logps/chosen": -171.13839721679688,
      "logps/rejected": -158.80014038085938,
      "loss": 0.4005,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8612101078033447,
      "rewards/margins": 1.6174386739730835,
      "rewards/rejected": -3.478649139404297,
      "step": 6420
    },
    {
      "epoch": 1.1734647321835934,
      "grad_norm": 5.833937168121338,
      "learning_rate": 6.157166452560103e-05,
      "logits/chosen": -0.7806700468063354,
      "logits/rejected": -0.5430468916893005,
      "logps/chosen": -180.2732391357422,
      "logps/rejected": -162.09017944335938,
      "loss": 0.5116,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9090344905853271,
      "rewards/margins": 1.5444304943084717,
      "rewards/rejected": -3.453465223312378,
      "step": 6430
    },
    {
      "epoch": 1.1752897162149831,
      "grad_norm": 3.1305720806121826,
      "learning_rate": 6.154230133969536e-05,
      "logits/chosen": -0.6712128520011902,
      "logits/rejected": -0.5745506286621094,
      "logps/chosen": -159.06170654296875,
      "logps/rejected": -176.02542114257812,
      "loss": 0.4511,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.0168352127075195,
      "rewards/margins": 1.7233556509017944,
      "rewards/rejected": -3.7401905059814453,
      "step": 6440
    },
    {
      "epoch": 1.1771147002463729,
      "grad_norm": 4.298421382904053,
      "learning_rate": 6.15129381537897e-05,
      "logits/chosen": -0.7780605554580688,
      "logits/rejected": -0.6148108243942261,
      "logps/chosen": -160.40188598632812,
      "logps/rejected": -144.41384887695312,
      "loss": 0.5904,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.930676817893982,
      "rewards/margins": 0.8691805005073547,
      "rewards/rejected": -2.7998573780059814,
      "step": 6450
    },
    {
      "epoch": 1.1789396842777626,
      "grad_norm": 3.1640708446502686,
      "learning_rate": 6.148357496788402e-05,
      "logits/chosen": -0.8196236491203308,
      "logits/rejected": -0.675930380821228,
      "logps/chosen": -156.91079711914062,
      "logps/rejected": -146.41622924804688,
      "loss": 0.4177,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8366832733154297,
      "rewards/margins": 1.5487229824066162,
      "rewards/rejected": -3.385406494140625,
      "step": 6460
    },
    {
      "epoch": 1.1807646683091524,
      "grad_norm": 4.552563667297363,
      "learning_rate": 6.145421178197835e-05,
      "logits/chosen": -0.9031389951705933,
      "logits/rejected": -0.7276844382286072,
      "logps/chosen": -165.43673706054688,
      "logps/rejected": -152.96536254882812,
      "loss": 0.54,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.5408246517181396,
      "rewards/margins": 1.382676362991333,
      "rewards/rejected": -2.9235007762908936,
      "step": 6470
    },
    {
      "epoch": 1.1825896523405421,
      "grad_norm": 11.264114379882812,
      "learning_rate": 6.142484859607268e-05,
      "logits/chosen": -0.9018158912658691,
      "logits/rejected": -0.7893477082252502,
      "logps/chosen": -164.2369842529297,
      "logps/rejected": -149.67526245117188,
      "loss": 0.5827,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.2726271152496338,
      "rewards/margins": 1.22304368019104,
      "rewards/rejected": -2.495670795440674,
      "step": 6480
    },
    {
      "epoch": 1.1844146363719317,
      "grad_norm": 3.583357572555542,
      "learning_rate": 6.139548541016701e-05,
      "logits/chosen": -0.8893367648124695,
      "logits/rejected": -0.8462902307510376,
      "logps/chosen": -149.337646484375,
      "logps/rejected": -164.0736541748047,
      "loss": 0.3939,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.3796800374984741,
      "rewards/margins": 1.5592339038848877,
      "rewards/rejected": -2.9389138221740723,
      "step": 6490
    },
    {
      "epoch": 1.1862396204033214,
      "grad_norm": 4.580393314361572,
      "learning_rate": 6.136612222426133e-05,
      "logits/chosen": -0.9919595718383789,
      "logits/rejected": -0.963278591632843,
      "logps/chosen": -157.46128845214844,
      "logps/rejected": -157.28964233398438,
      "loss": 0.5568,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7211024761199951,
      "rewards/margins": 1.0613962411880493,
      "rewards/rejected": -2.782498359680176,
      "step": 6500
    },
    {
      "epoch": 1.1880646044347112,
      "grad_norm": 4.945354461669922,
      "learning_rate": 6.133675903835567e-05,
      "logits/chosen": -0.8584488034248352,
      "logits/rejected": -0.7960694432258606,
      "logps/chosen": -150.67733764648438,
      "logps/rejected": -161.52493286132812,
      "loss": 0.4343,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.506780982017517,
      "rewards/margins": 1.4326915740966797,
      "rewards/rejected": -2.9394726753234863,
      "step": 6510
    },
    {
      "epoch": 1.189889588466101,
      "grad_norm": 3.572695255279541,
      "learning_rate": 6.130739585245e-05,
      "logits/chosen": -0.9268800616264343,
      "logits/rejected": -0.8265691995620728,
      "logps/chosen": -167.73635864257812,
      "logps/rejected": -164.2139434814453,
      "loss": 0.4068,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5340609550476074,
      "rewards/margins": 1.4250545501708984,
      "rewards/rejected": -2.959115505218506,
      "step": 6520
    },
    {
      "epoch": 1.1917145724974907,
      "grad_norm": 2.2820425033569336,
      "learning_rate": 6.127803266654432e-05,
      "logits/chosen": -0.8456516265869141,
      "logits/rejected": -0.7183722257614136,
      "logps/chosen": -155.40194702148438,
      "logps/rejected": -136.92160034179688,
      "loss": 0.4019,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.5552749633789062,
      "rewards/margins": 1.360068678855896,
      "rewards/rejected": -2.915343761444092,
      "step": 6530
    },
    {
      "epoch": 1.1935395565288804,
      "grad_norm": 3.5264177322387695,
      "learning_rate": 6.124866948063866e-05,
      "logits/chosen": -0.855068564414978,
      "logits/rejected": -0.734127402305603,
      "logps/chosen": -170.53297424316406,
      "logps/rejected": -163.6237030029297,
      "loss": 0.3968,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6608362197875977,
      "rewards/margins": 1.5627377033233643,
      "rewards/rejected": -3.223574161529541,
      "step": 6540
    },
    {
      "epoch": 1.1953645405602702,
      "grad_norm": 2.052314519882202,
      "learning_rate": 6.121930629473298e-05,
      "logits/chosen": -0.8856455087661743,
      "logits/rejected": -0.7106274366378784,
      "logps/chosen": -160.4823455810547,
      "logps/rejected": -152.69146728515625,
      "loss": 0.3848,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4134809970855713,
      "rewards/margins": 1.8578779697418213,
      "rewards/rejected": -3.2713589668273926,
      "step": 6550
    },
    {
      "epoch": 1.1971895245916597,
      "grad_norm": 1.7308963537216187,
      "learning_rate": 6.118994310882732e-05,
      "logits/chosen": -0.9645616412162781,
      "logits/rejected": -0.8256431818008423,
      "logps/chosen": -169.93698120117188,
      "logps/rejected": -166.66015625,
      "loss": 0.3302,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.722830057144165,
      "rewards/margins": 2.0609421730041504,
      "rewards/rejected": -3.783771514892578,
      "step": 6560
    },
    {
      "epoch": 1.1990145086230495,
      "grad_norm": 3.3358688354492188,
      "learning_rate": 6.116057992292165e-05,
      "logits/chosen": -0.8642688989639282,
      "logits/rejected": -0.8290683627128601,
      "logps/chosen": -168.16880798339844,
      "logps/rejected": -171.9276885986328,
      "loss": 0.6229,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6003992557525635,
      "rewards/margins": 1.1088930368423462,
      "rewards/rejected": -2.7092926502227783,
      "step": 6570
    },
    {
      "epoch": 1.2008394926544392,
      "grad_norm": 6.6963677406311035,
      "learning_rate": 6.113121673701597e-05,
      "logits/chosen": -0.9253114461898804,
      "logits/rejected": -0.8178844451904297,
      "logps/chosen": -150.50186157226562,
      "logps/rejected": -151.8726348876953,
      "loss": 0.5353,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.067470908164978,
      "rewards/margins": 1.39591383934021,
      "rewards/rejected": -2.4633846282958984,
      "step": 6580
    },
    {
      "epoch": 1.202664476685829,
      "grad_norm": 3.6245720386505127,
      "learning_rate": 6.110185355111031e-05,
      "logits/chosen": -0.9643775224685669,
      "logits/rejected": -0.837842583656311,
      "logps/chosen": -148.91604614257812,
      "logps/rejected": -138.726806640625,
      "loss": 0.4447,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5773894786834717,
      "rewards/margins": 1.4861137866973877,
      "rewards/rejected": -2.0635032653808594,
      "step": 6590
    },
    {
      "epoch": 1.2044894607172187,
      "grad_norm": 12.03420639038086,
      "learning_rate": 6.107249036520463e-05,
      "logits/chosen": -0.9881973266601562,
      "logits/rejected": -0.9292610883712769,
      "logps/chosen": -163.453857421875,
      "logps/rejected": -161.74954223632812,
      "loss": 0.6286,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9293276071548462,
      "rewards/margins": 1.1187738180160522,
      "rewards/rejected": -2.0481011867523193,
      "step": 6600
    },
    {
      "epoch": 1.2063144447486085,
      "grad_norm": 2.7327358722686768,
      "learning_rate": 6.104312717929896e-05,
      "logits/chosen": -1.0447189807891846,
      "logits/rejected": -0.9446014165878296,
      "logps/chosen": -163.41690063476562,
      "logps/rejected": -156.98582458496094,
      "loss": 0.4874,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9676612019538879,
      "rewards/margins": 1.2349402904510498,
      "rewards/rejected": -2.202601671218872,
      "step": 6610
    },
    {
      "epoch": 1.2081394287799982,
      "grad_norm": 2.8825597763061523,
      "learning_rate": 6.101376399339328e-05,
      "logits/chosen": -1.002789855003357,
      "logits/rejected": -0.9364486932754517,
      "logps/chosen": -154.45912170410156,
      "logps/rejected": -145.10755920410156,
      "loss": 0.5132,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8510954976081848,
      "rewards/margins": 1.0779887437820435,
      "rewards/rejected": -1.9290844202041626,
      "step": 6620
    },
    {
      "epoch": 1.209964412811388,
      "grad_norm": 2.7965779304504395,
      "learning_rate": 6.098440080748762e-05,
      "logits/chosen": -1.090372920036316,
      "logits/rejected": -0.9709946513175964,
      "logps/chosen": -163.862060546875,
      "logps/rejected": -139.76858520507812,
      "loss": 0.4386,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.5472094416618347,
      "rewards/margins": 1.1696016788482666,
      "rewards/rejected": -1.7168114185333252,
      "step": 6630
    },
    {
      "epoch": 1.2117893968427775,
      "grad_norm": 3.1208040714263916,
      "learning_rate": 6.0955037621581945e-05,
      "logits/chosen": -1.0135680437088013,
      "logits/rejected": -0.9314403533935547,
      "logps/chosen": -149.94467163085938,
      "logps/rejected": -147.4669647216797,
      "loss": 0.415,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.8651425242424011,
      "rewards/margins": 1.303335189819336,
      "rewards/rejected": -2.1684775352478027,
      "step": 6640
    },
    {
      "epoch": 1.2136143808741673,
      "grad_norm": 3.246422290802002,
      "learning_rate": 6.0925674435676276e-05,
      "logits/chosen": -1.0781710147857666,
      "logits/rejected": -0.9741804003715515,
      "logps/chosen": -171.89720153808594,
      "logps/rejected": -153.85629272460938,
      "loss": 0.4599,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.938759982585907,
      "rewards/margins": 1.363096833229065,
      "rewards/rejected": -2.3018569946289062,
      "step": 6650
    },
    {
      "epoch": 1.215439364905557,
      "grad_norm": 1.0315719842910767,
      "learning_rate": 6.08963112497706e-05,
      "logits/chosen": -1.0350054502487183,
      "logits/rejected": -0.8870651125907898,
      "logps/chosen": -172.70199584960938,
      "logps/rejected": -141.68048095703125,
      "loss": 0.41,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9993032217025757,
      "rewards/margins": 1.3725804090499878,
      "rewards/rejected": -2.3718838691711426,
      "step": 6660
    },
    {
      "epoch": 1.2172643489369468,
      "grad_norm": 4.238272666931152,
      "learning_rate": 6.086694806386494e-05,
      "logits/chosen": -0.9487968683242798,
      "logits/rejected": -0.8755757212638855,
      "logps/chosen": -171.01661682128906,
      "logps/rejected": -171.53089904785156,
      "loss": 0.4745,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4950206279754639,
      "rewards/margins": 1.3617316484451294,
      "rewards/rejected": -2.8567521572113037,
      "step": 6670
    },
    {
      "epoch": 1.2190893329683365,
      "grad_norm": 4.673513889312744,
      "learning_rate": 6.083758487795926e-05,
      "logits/chosen": -1.0063265562057495,
      "logits/rejected": -0.9625825881958008,
      "logps/chosen": -152.86273193359375,
      "logps/rejected": -163.68460083007812,
      "loss": 0.4829,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0402737855911255,
      "rewards/margins": 1.2409635782241821,
      "rewards/rejected": -2.2812371253967285,
      "step": 6680
    },
    {
      "epoch": 1.2209143169997263,
      "grad_norm": 4.491058349609375,
      "learning_rate": 6.080822169205359e-05,
      "logits/chosen": -0.9816083908081055,
      "logits/rejected": -0.8800209164619446,
      "logps/chosen": -169.87228393554688,
      "logps/rejected": -169.7873077392578,
      "loss": 0.358,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.4225351810455322,
      "rewards/margins": 1.7879400253295898,
      "rewards/rejected": -3.210475206375122,
      "step": 6690
    },
    {
      "epoch": 1.222739301031116,
      "grad_norm": 4.902456760406494,
      "learning_rate": 6.0778858506147926e-05,
      "logits/chosen": -0.9717394113540649,
      "logits/rejected": -0.8395986557006836,
      "logps/chosen": -161.92953491210938,
      "logps/rejected": -161.47488403320312,
      "loss": 0.5359,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7054522037506104,
      "rewards/margins": 1.4652007818222046,
      "rewards/rejected": -3.1706531047821045,
      "step": 6700
    },
    {
      "epoch": 1.2245642850625056,
      "grad_norm": 1.9158037900924683,
      "learning_rate": 6.074949532024225e-05,
      "logits/chosen": -0.9685631990432739,
      "logits/rejected": -0.9032056927680969,
      "logps/chosen": -155.07119750976562,
      "logps/rejected": -151.60911560058594,
      "loss": 0.4493,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.6162481307983398,
      "rewards/margins": 1.3970063924789429,
      "rewards/rejected": -3.013254404067993,
      "step": 6710
    },
    {
      "epoch": 1.2263892690938953,
      "grad_norm": 2.082563638687134,
      "learning_rate": 6.072013213433658e-05,
      "logits/chosen": -0.9616392254829407,
      "logits/rejected": -0.8441351056098938,
      "logps/chosen": -182.29397583007812,
      "logps/rejected": -173.28280639648438,
      "loss": 0.4756,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4033753871917725,
      "rewards/margins": 1.4613173007965088,
      "rewards/rejected": -2.8646929264068604,
      "step": 6720
    },
    {
      "epoch": 1.228214253125285,
      "grad_norm": 4.423558235168457,
      "learning_rate": 6.0690768948430906e-05,
      "logits/chosen": -0.8807233572006226,
      "logits/rejected": -0.786737322807312,
      "logps/chosen": -185.85702514648438,
      "logps/rejected": -164.3293914794922,
      "loss": 0.487,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.906681776046753,
      "rewards/margins": 1.1712762117385864,
      "rewards/rejected": -3.07795786857605,
      "step": 6730
    },
    {
      "epoch": 1.2300392371566748,
      "grad_norm": 1.799878478050232,
      "learning_rate": 6.0661405762525245e-05,
      "logits/chosen": -0.9371502995491028,
      "logits/rejected": -0.8336410522460938,
      "logps/chosen": -172.92477416992188,
      "logps/rejected": -159.44418334960938,
      "loss": 0.4251,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.1860949993133545,
      "rewards/margins": 1.344561219215393,
      "rewards/rejected": -2.530656337738037,
      "step": 6740
    },
    {
      "epoch": 1.2318642211880646,
      "grad_norm": 2.4002747535705566,
      "learning_rate": 6.063204257661957e-05,
      "logits/chosen": -0.9319372177124023,
      "logits/rejected": -0.8233499526977539,
      "logps/chosen": -158.94485473632812,
      "logps/rejected": -142.4461212158203,
      "loss": 0.46,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1786390542984009,
      "rewards/margins": 1.3188998699188232,
      "rewards/rejected": -2.4975388050079346,
      "step": 6750
    },
    {
      "epoch": 1.2336892052194544,
      "grad_norm": 4.115514278411865,
      "learning_rate": 6.0605615709304464e-05,
      "logits/chosen": -0.9398530125617981,
      "logits/rejected": -0.7979262471199036,
      "logps/chosen": -161.8992462158203,
      "logps/rejected": -149.85501098632812,
      "loss": 0.413,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.8185380101203918,
      "rewards/margins": 1.4370746612548828,
      "rewards/rejected": -2.25561261177063,
      "step": 6760
    },
    {
      "epoch": 1.235514189250844,
      "grad_norm": 2.2816479206085205,
      "learning_rate": 6.057625252339879e-05,
      "logits/chosen": -0.9488178491592407,
      "logits/rejected": -0.8878422975540161,
      "logps/chosen": -162.84800720214844,
      "logps/rejected": -163.70533752441406,
      "loss": 0.4965,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9617176055908203,
      "rewards/margins": 1.1225316524505615,
      "rewards/rejected": -2.084249496459961,
      "step": 6770
    },
    {
      "epoch": 1.2373391732822339,
      "grad_norm": 3.619204044342041,
      "learning_rate": 6.054688933749313e-05,
      "logits/chosen": -1.0572988986968994,
      "logits/rejected": -0.9675111770629883,
      "logps/chosen": -162.56417846679688,
      "logps/rejected": -148.93006896972656,
      "loss": 0.5152,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8126013875007629,
      "rewards/margins": 1.2343664169311523,
      "rewards/rejected": -2.0469679832458496,
      "step": 6780
    },
    {
      "epoch": 1.2391641573136236,
      "grad_norm": 3.487534761428833,
      "learning_rate": 6.051752615158745e-05,
      "logits/chosen": -1.0733706951141357,
      "logits/rejected": -0.9889717102050781,
      "logps/chosen": -164.4490966796875,
      "logps/rejected": -149.78765869140625,
      "loss": 0.4339,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6422812938690186,
      "rewards/margins": 1.2733726501464844,
      "rewards/rejected": -1.915653944015503,
      "step": 6790
    },
    {
      "epoch": 1.2409891413450131,
      "grad_norm": 5.379982948303223,
      "learning_rate": 6.048816296568178e-05,
      "logits/chosen": -0.9661857485771179,
      "logits/rejected": -0.8578316569328308,
      "logps/chosen": -141.22593688964844,
      "logps/rejected": -144.30404663085938,
      "loss": 0.3658,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.6203505992889404,
      "rewards/margins": 1.7139055728912354,
      "rewards/rejected": -2.334256410598755,
      "step": 6800
    },
    {
      "epoch": 1.242814125376403,
      "grad_norm": 3.963700532913208,
      "learning_rate": 6.045879977977611e-05,
      "logits/chosen": -0.9839147329330444,
      "logits/rejected": -0.8844223022460938,
      "logps/chosen": -159.3676300048828,
      "logps/rejected": -149.9813995361328,
      "loss": 0.4729,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0403454303741455,
      "rewards/margins": 1.1562572717666626,
      "rewards/rejected": -2.1966028213500977,
      "step": 6810
    },
    {
      "epoch": 1.2446391094077927,
      "grad_norm": 2.2808334827423096,
      "learning_rate": 6.0429436593870445e-05,
      "logits/chosen": -0.8824844360351562,
      "logits/rejected": -0.7798314094543457,
      "logps/chosen": -153.52777099609375,
      "logps/rejected": -159.4026641845703,
      "loss": 0.4109,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.4940674304962158,
      "rewards/margins": 1.4737778902053833,
      "rewards/rejected": -2.9678454399108887,
      "step": 6820
    },
    {
      "epoch": 1.2464640934391824,
      "grad_norm": 4.919368743896484,
      "learning_rate": 6.040007340796477e-05,
      "logits/chosen": -0.8441566228866577,
      "logits/rejected": -0.7277094721794128,
      "logps/chosen": -163.23033142089844,
      "logps/rejected": -158.2183074951172,
      "loss": 0.4424,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0445923805236816,
      "rewards/margins": 1.4282418489456177,
      "rewards/rejected": -3.4728341102600098,
      "step": 6830
    },
    {
      "epoch": 1.2482890774705722,
      "grad_norm": 3.7965571880340576,
      "learning_rate": 6.0370710222059094e-05,
      "logits/chosen": -0.7683447003364563,
      "logits/rejected": -0.7154226303100586,
      "logps/chosen": -148.96170043945312,
      "logps/rejected": -163.70962524414062,
      "loss": 0.3284,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7229095697402954,
      "rewards/margins": 1.8741447925567627,
      "rewards/rejected": -3.5970542430877686,
      "step": 6840
    },
    {
      "epoch": 1.250114061501962,
      "grad_norm": 2.470245599746704,
      "learning_rate": 6.0341347036153426e-05,
      "logits/chosen": -0.740281343460083,
      "logits/rejected": -0.6165847182273865,
      "logps/chosen": -168.04446411132812,
      "logps/rejected": -162.47393798828125,
      "loss": 0.5219,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.729003429412842,
      "rewards/margins": 1.3885432481765747,
      "rewards/rejected": -4.117547035217285,
      "step": 6850
    },
    {
      "epoch": 1.2519390455333514,
      "grad_norm": 2.8504817485809326,
      "learning_rate": 6.031198385024776e-05,
      "logits/chosen": -0.9269019961357117,
      "logits/rejected": -0.8155795931816101,
      "logps/chosen": -169.56460571289062,
      "logps/rejected": -171.631591796875,
      "loss": 0.4489,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.1015524864196777,
      "rewards/margins": 1.643082618713379,
      "rewards/rejected": -3.7446351051330566,
      "step": 6860
    },
    {
      "epoch": 1.2537640295647412,
      "grad_norm": 1.5001848936080933,
      "learning_rate": 6.028262066434209e-05,
      "logits/chosen": -0.9137238264083862,
      "logits/rejected": -0.8574304580688477,
      "logps/chosen": -168.27777099609375,
      "logps/rejected": -185.509033203125,
      "loss": 0.4116,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7481622695922852,
      "rewards/margins": 1.4370787143707275,
      "rewards/rejected": -3.1852407455444336,
      "step": 6870
    },
    {
      "epoch": 1.255589013596131,
      "grad_norm": 4.19337272644043,
      "learning_rate": 6.025325747843641e-05,
      "logits/chosen": -0.9419749975204468,
      "logits/rejected": -0.8623820543289185,
      "logps/chosen": -156.99557495117188,
      "logps/rejected": -165.9616241455078,
      "loss": 0.5108,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8968366384506226,
      "rewards/margins": 1.4204758405685425,
      "rewards/rejected": -3.317312240600586,
      "step": 6880
    },
    {
      "epoch": 1.2574139976275207,
      "grad_norm": 4.605240345001221,
      "learning_rate": 6.022389429253074e-05,
      "logits/chosen": -0.9488863945007324,
      "logits/rejected": -0.9302082061767578,
      "logps/chosen": -157.1571807861328,
      "logps/rejected": -169.33609008789062,
      "loss": 0.4219,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9418962001800537,
      "rewards/margins": 1.557012677192688,
      "rewards/rejected": -3.4989089965820312,
      "step": 6890
    },
    {
      "epoch": 1.2592389816589105,
      "grad_norm": 4.15259313583374,
      "learning_rate": 6.0194531106625076e-05,
      "logits/chosen": -1.0106078386306763,
      "logits/rejected": -0.9345579147338867,
      "logps/chosen": -164.21029663085938,
      "logps/rejected": -172.22866821289062,
      "loss": 0.4153,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8350616693496704,
      "rewards/margins": 1.6808347702026367,
      "rewards/rejected": -3.5158963203430176,
      "step": 6900
    },
    {
      "epoch": 1.2610639656903002,
      "grad_norm": 4.311319351196289,
      "learning_rate": 6.01651679207194e-05,
      "logits/chosen": -1.0327712297439575,
      "logits/rejected": -0.912580132484436,
      "logps/chosen": -163.7930908203125,
      "logps/rejected": -150.75860595703125,
      "loss": 0.5172,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.816136360168457,
      "rewards/margins": 1.3788621425628662,
      "rewards/rejected": -3.1949985027313232,
      "step": 6910
    },
    {
      "epoch": 1.26288894972169,
      "grad_norm": 4.803352355957031,
      "learning_rate": 6.013580473481373e-05,
      "logits/chosen": -1.0401265621185303,
      "logits/rejected": -0.9158290028572083,
      "logps/chosen": -161.294189453125,
      "logps/rejected": -154.9691619873047,
      "loss": 0.5131,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.5680434703826904,
      "rewards/margins": 1.252082109451294,
      "rewards/rejected": -2.8201258182525635,
      "step": 6920
    },
    {
      "epoch": 1.2647139337530797,
      "grad_norm": 5.119632244110107,
      "learning_rate": 6.010644154890806e-05,
      "logits/chosen": -1.048034906387329,
      "logits/rejected": -0.9402639269828796,
      "logps/chosen": -157.6425018310547,
      "logps/rejected": -151.6448974609375,
      "loss": 0.4929,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4725172519683838,
      "rewards/margins": 1.3987418413162231,
      "rewards/rejected": -2.8712592124938965,
      "step": 6930
    },
    {
      "epoch": 1.2665389177844695,
      "grad_norm": 5.221075057983398,
      "learning_rate": 6.0077078363002394e-05,
      "logits/chosen": -0.8846890330314636,
      "logits/rejected": -0.8028217554092407,
      "logps/chosen": -151.8274688720703,
      "logps/rejected": -150.85101318359375,
      "loss": 0.3917,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6689761877059937,
      "rewards/margins": 1.5780690908432007,
      "rewards/rejected": -3.247044801712036,
      "step": 6940
    },
    {
      "epoch": 1.2683639018158592,
      "grad_norm": 2.2949881553649902,
      "learning_rate": 6.004771517709672e-05,
      "logits/chosen": -0.9438832998275757,
      "logits/rejected": -0.8793133497238159,
      "logps/chosen": -167.0399932861328,
      "logps/rejected": -170.63046264648438,
      "loss": 0.3578,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.667999505996704,
      "rewards/margins": 1.5992937088012695,
      "rewards/rejected": -3.2672932147979736,
      "step": 6950
    },
    {
      "epoch": 1.2701888858472488,
      "grad_norm": 3.33949875831604,
      "learning_rate": 6.0018351991191044e-05,
      "logits/chosen": -0.9024327993392944,
      "logits/rejected": -0.8371990323066711,
      "logps/chosen": -149.7896270751953,
      "logps/rejected": -158.61508178710938,
      "loss": 0.4308,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.033618211746216,
      "rewards/margins": 1.408826470375061,
      "rewards/rejected": -3.4424445629119873,
      "step": 6960
    },
    {
      "epoch": 1.2720138698786385,
      "grad_norm": 4.657779216766357,
      "learning_rate": 5.998898880528538e-05,
      "logits/chosen": -0.9207421541213989,
      "logits/rejected": -0.8592159152030945,
      "logps/chosen": -155.45742797851562,
      "logps/rejected": -162.044677734375,
      "loss": 0.6196,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.356762409210205,
      "rewards/margins": 1.1552156209945679,
      "rewards/rejected": -3.511977434158325,
      "step": 6970
    },
    {
      "epoch": 1.2738388539100283,
      "grad_norm": 2.175309419631958,
      "learning_rate": 5.9959625619379706e-05,
      "logits/chosen": -0.9431098699569702,
      "logits/rejected": -0.8645105361938477,
      "logps/chosen": -149.9037628173828,
      "logps/rejected": -158.16445922851562,
      "loss": 0.4058,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.544838786125183,
      "rewards/margins": 1.3795326948165894,
      "rewards/rejected": -2.9243712425231934,
      "step": 6980
    },
    {
      "epoch": 1.275663837941418,
      "grad_norm": 2.1377062797546387,
      "learning_rate": 5.993026243347404e-05,
      "logits/chosen": -1.0387747287750244,
      "logits/rejected": -0.8756492733955383,
      "logps/chosen": -168.31973266601562,
      "logps/rejected": -151.3746337890625,
      "loss": 0.464,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3891949653625488,
      "rewards/margins": 1.3559253215789795,
      "rewards/rejected": -2.7451205253601074,
      "step": 6990
    },
    {
      "epoch": 1.2774888219728078,
      "grad_norm": 3.728633165359497,
      "learning_rate": 5.990089924756836e-05,
      "logits/chosen": -0.8913254737854004,
      "logits/rejected": -0.8033381700515747,
      "logps/chosen": -163.32444763183594,
      "logps/rejected": -158.07704162597656,
      "loss": 0.3647,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.493487000465393,
      "rewards/margins": 1.4794126749038696,
      "rewards/rejected": -2.9728996753692627,
      "step": 7000
    },
    {
      "epoch": 1.2793138060041975,
      "grad_norm": 4.343076229095459,
      "learning_rate": 5.98715360616627e-05,
      "logits/chosen": -0.9184039235115051,
      "logits/rejected": -0.8368476629257202,
      "logps/chosen": -149.77952575683594,
      "logps/rejected": -178.5841522216797,
      "loss": 0.3631,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3001863956451416,
      "rewards/margins": 1.9718519449234009,
      "rewards/rejected": -3.272038221359253,
      "step": 7010
    },
    {
      "epoch": 1.281138790035587,
      "grad_norm": 4.85047721862793,
      "learning_rate": 5.9842172875757025e-05,
      "logits/chosen": -0.9767521619796753,
      "logits/rejected": -0.8772943615913391,
      "logps/chosen": -147.35531616210938,
      "logps/rejected": -158.89950561523438,
      "loss": 0.335,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.0625183582305908,
      "rewards/margins": 2.149773597717285,
      "rewards/rejected": -3.212292194366455,
      "step": 7020
    },
    {
      "epoch": 1.2829637740669768,
      "grad_norm": 2.329875946044922,
      "learning_rate": 5.981280968985135e-05,
      "logits/chosen": -0.9092711210250854,
      "logits/rejected": -0.7912769317626953,
      "logps/chosen": -171.37864685058594,
      "logps/rejected": -170.4783935546875,
      "loss": 0.3518,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5954300165176392,
      "rewards/margins": 2.110382556915283,
      "rewards/rejected": -3.705812454223633,
      "step": 7030
    },
    {
      "epoch": 1.2847887580983666,
      "grad_norm": 6.357914447784424,
      "learning_rate": 5.978344650394568e-05,
      "logits/chosen": -0.995246410369873,
      "logits/rejected": -0.8473409414291382,
      "logps/chosen": -159.35842895507812,
      "logps/rejected": -159.02346801757812,
      "loss": 0.4687,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8908824920654297,
      "rewards/margins": 1.7725753784179688,
      "rewards/rejected": -3.6634573936462402,
      "step": 7040
    },
    {
      "epoch": 1.2866137421297563,
      "grad_norm": 4.079943656921387,
      "learning_rate": 5.975408331804001e-05,
      "logits/chosen": -0.9818516969680786,
      "logits/rejected": -0.7730769515037537,
      "logps/chosen": -192.5352020263672,
      "logps/rejected": -165.4364471435547,
      "loss": 0.4389,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7780224084854126,
      "rewards/margins": 1.7654645442962646,
      "rewards/rejected": -3.5434868335723877,
      "step": 7050
    },
    {
      "epoch": 1.288438726161146,
      "grad_norm": 8.687076568603516,
      "learning_rate": 5.9724720132134344e-05,
      "logits/chosen": -0.9009017944335938,
      "logits/rejected": -0.8207456469535828,
      "logps/chosen": -171.48828125,
      "logps/rejected": -160.2182159423828,
      "loss": 0.6536,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.3838770389556885,
      "rewards/margins": 0.8339754939079285,
      "rewards/rejected": -3.2178523540496826,
      "step": 7060
    },
    {
      "epoch": 1.2902637101925358,
      "grad_norm": 3.5610415935516357,
      "learning_rate": 5.969535694622867e-05,
      "logits/chosen": -0.7940400838851929,
      "logits/rejected": -0.7019205093383789,
      "logps/chosen": -161.03863525390625,
      "logps/rejected": -159.74623107910156,
      "loss": 0.4756,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9331382513046265,
      "rewards/margins": 1.2293914556503296,
      "rewards/rejected": -3.162529706954956,
      "step": 7070
    },
    {
      "epoch": 1.2920886942239256,
      "grad_norm": 6.037431716918945,
      "learning_rate": 5.966599376032299e-05,
      "logits/chosen": -0.8555848002433777,
      "logits/rejected": -0.6941037178039551,
      "logps/chosen": -164.7423553466797,
      "logps/rejected": -149.88409423828125,
      "loss": 0.521,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.2005951404571533,
      "rewards/margins": 1.1918281316757202,
      "rewards/rejected": -3.392423152923584,
      "step": 7080
    },
    {
      "epoch": 1.2939136782553153,
      "grad_norm": 2.654301404953003,
      "learning_rate": 5.963663057441733e-05,
      "logits/chosen": -0.8385500907897949,
      "logits/rejected": -0.7864644527435303,
      "logps/chosen": -155.00555419921875,
      "logps/rejected": -160.80722045898438,
      "loss": 0.4452,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.8042569160461426,
      "rewards/margins": 1.201353907585144,
      "rewards/rejected": -4.005610466003418,
      "step": 7090
    },
    {
      "epoch": 1.295738662286705,
      "grad_norm": 3.674147605895996,
      "learning_rate": 5.9607267388511655e-05,
      "logits/chosen": -0.9705337285995483,
      "logits/rejected": -0.763814389705658,
      "logps/chosen": -184.76547241210938,
      "logps/rejected": -167.68807983398438,
      "loss": 0.3522,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.656632900238037,
      "rewards/margins": 1.769991159439087,
      "rewards/rejected": -4.426623344421387,
      "step": 7100
    },
    {
      "epoch": 1.2975636463180948,
      "grad_norm": 2.3113882541656494,
      "learning_rate": 5.957790420260599e-05,
      "logits/chosen": -1.0001543760299683,
      "logits/rejected": -0.8500981330871582,
      "logps/chosen": -204.83493041992188,
      "logps/rejected": -180.85263061523438,
      "loss": 0.4312,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.1889278888702393,
      "rewards/margins": 1.7777763605117798,
      "rewards/rejected": -3.9667041301727295,
      "step": 7110
    },
    {
      "epoch": 1.2993886303494844,
      "grad_norm": 1.6474350690841675,
      "learning_rate": 5.954854101670032e-05,
      "logits/chosen": -0.9407293200492859,
      "logits/rejected": -0.8428236246109009,
      "logps/chosen": -176.3234405517578,
      "logps/rejected": -182.37503051757812,
      "loss": 0.4414,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.647369146347046,
      "rewards/margins": 1.580196499824524,
      "rewards/rejected": -3.227565288543701,
      "step": 7120
    },
    {
      "epoch": 1.3012136143808741,
      "grad_norm": 1.3071810007095337,
      "learning_rate": 5.951917783079465e-05,
      "logits/chosen": -0.9957066774368286,
      "logits/rejected": -0.817282497882843,
      "logps/chosen": -166.7518310546875,
      "logps/rejected": -163.41671752929688,
      "loss": 0.2674,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.5692369937896729,
      "rewards/margins": 2.331421375274658,
      "rewards/rejected": -3.900658130645752,
      "step": 7130
    },
    {
      "epoch": 1.3030385984122639,
      "grad_norm": 2.6438825130462646,
      "learning_rate": 5.9489814644888974e-05,
      "logits/chosen": -0.9990862011909485,
      "logits/rejected": -0.8861100077629089,
      "logps/chosen": -167.08319091796875,
      "logps/rejected": -164.80307006835938,
      "loss": 0.4983,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.8367564678192139,
      "rewards/margins": 1.704490303993225,
      "rewards/rejected": -3.5412468910217285,
      "step": 7140
    },
    {
      "epoch": 1.3048635824436536,
      "grad_norm": 4.604410648345947,
      "learning_rate": 5.94604514589833e-05,
      "logits/chosen": -1.1408662796020508,
      "logits/rejected": -1.0173251628875732,
      "logps/chosen": -159.2974395751953,
      "logps/rejected": -155.30279541015625,
      "loss": 0.4753,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1303503513336182,
      "rewards/margins": 1.5728412866592407,
      "rewards/rejected": -2.7031917572021484,
      "step": 7150
    },
    {
      "epoch": 1.3066885664750434,
      "grad_norm": 6.415056228637695,
      "learning_rate": 5.943108827307764e-05,
      "logits/chosen": -1.0877676010131836,
      "logits/rejected": -0.9735584259033203,
      "logps/chosen": -161.6050567626953,
      "logps/rejected": -170.37767028808594,
      "loss": 0.4939,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8690865635871887,
      "rewards/margins": 1.9074079990386963,
      "rewards/rejected": -2.7764945030212402,
      "step": 7160
    },
    {
      "epoch": 1.3085135505064331,
      "grad_norm": 5.163024425506592,
      "learning_rate": 5.940172508717196e-05,
      "logits/chosen": -1.0782753229141235,
      "logits/rejected": -0.985733687877655,
      "logps/chosen": -153.91490173339844,
      "logps/rejected": -153.83497619628906,
      "loss": 0.4842,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.975411057472229,
      "rewards/margins": 1.5785210132598877,
      "rewards/rejected": -2.5539321899414062,
      "step": 7170
    },
    {
      "epoch": 1.3103385345378227,
      "grad_norm": 3.5974254608154297,
      "learning_rate": 5.937236190126629e-05,
      "logits/chosen": -1.0612541437149048,
      "logits/rejected": -1.0244544744491577,
      "logps/chosen": -151.24851989746094,
      "logps/rejected": -161.46444702148438,
      "loss": 0.5098,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1063768863677979,
      "rewards/margins": 1.1765468120574951,
      "rewards/rejected": -2.282923698425293,
      "step": 7180
    },
    {
      "epoch": 1.3121635185692124,
      "grad_norm": 3.794464349746704,
      "learning_rate": 5.934299871536062e-05,
      "logits/chosen": -1.0928661823272705,
      "logits/rejected": -0.9790596961975098,
      "logps/chosen": -147.1354217529297,
      "logps/rejected": -141.95716857910156,
      "loss": 0.408,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.788589358329773,
      "rewards/margins": 1.4451253414154053,
      "rewards/rejected": -2.2337145805358887,
      "step": 7190
    },
    {
      "epoch": 1.3139885026006022,
      "grad_norm": 1.6315853595733643,
      "learning_rate": 5.9313635529454955e-05,
      "logits/chosen": -1.030385136604309,
      "logits/rejected": -0.8660558462142944,
      "logps/chosen": -166.8406982421875,
      "logps/rejected": -155.473876953125,
      "loss": 0.3542,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -0.8579629063606262,
      "rewards/margins": 1.8821163177490234,
      "rewards/rejected": -2.740079164505005,
      "step": 7200
    },
    {
      "epoch": 1.315813486631992,
      "grad_norm": 4.554275035858154,
      "learning_rate": 5.928427234354928e-05,
      "logits/chosen": -1.0136322975158691,
      "logits/rejected": -0.9242779016494751,
      "logps/chosen": -166.0612030029297,
      "logps/rejected": -169.05593872070312,
      "loss": 0.4389,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5796573162078857,
      "rewards/margins": 1.5506303310394287,
      "rewards/rejected": -3.1302878856658936,
      "step": 7210
    },
    {
      "epoch": 1.3176384706633817,
      "grad_norm": 6.592234134674072,
      "learning_rate": 5.9254909157643604e-05,
      "logits/chosen": -1.0918577909469604,
      "logits/rejected": -0.9694703221321106,
      "logps/chosen": -163.99229431152344,
      "logps/rejected": -170.3456573486328,
      "loss": 0.4856,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5078312158584595,
      "rewards/margins": 1.7847884893417358,
      "rewards/rejected": -3.2926197052001953,
      "step": 7220
    },
    {
      "epoch": 1.3194634546947714,
      "grad_norm": 1.8066645860671997,
      "learning_rate": 5.9225545971737936e-05,
      "logits/chosen": -1.0778664350509644,
      "logits/rejected": -0.9714909791946411,
      "logps/chosen": -163.99862670898438,
      "logps/rejected": -149.94964599609375,
      "loss": 0.4748,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1851047277450562,
      "rewards/margins": 1.3041120767593384,
      "rewards/rejected": -2.4892170429229736,
      "step": 7230
    },
    {
      "epoch": 1.3212884387261612,
      "grad_norm": 1.6099249124526978,
      "learning_rate": 5.919618278583227e-05,
      "logits/chosen": -1.0563737154006958,
      "logits/rejected": -0.954401969909668,
      "logps/chosen": -154.63662719726562,
      "logps/rejected": -159.30712890625,
      "loss": 0.3627,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.1721383333206177,
      "rewards/margins": 1.7632591724395752,
      "rewards/rejected": -2.9353973865509033,
      "step": 7240
    },
    {
      "epoch": 1.323113422757551,
      "grad_norm": 3.1566576957702637,
      "learning_rate": 5.91668195999266e-05,
      "logits/chosen": -0.9586159586906433,
      "logits/rejected": -0.8615878224372864,
      "logps/chosen": -165.87049865722656,
      "logps/rejected": -163.36404418945312,
      "loss": 0.5189,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7538343667984009,
      "rewards/margins": 1.3588312864303589,
      "rewards/rejected": -3.1126656532287598,
      "step": 7250
    },
    {
      "epoch": 1.3249384067889407,
      "grad_norm": 1.547446846961975,
      "learning_rate": 5.913745641402092e-05,
      "logits/chosen": -1.0866093635559082,
      "logits/rejected": -0.9729068875312805,
      "logps/chosen": -167.50048828125,
      "logps/rejected": -155.15382385253906,
      "loss": 0.5836,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.6110283136367798,
      "rewards/margins": 1.1031689643859863,
      "rewards/rejected": -2.7141973972320557,
      "step": 7260
    },
    {
      "epoch": 1.3267633908203305,
      "grad_norm": 2.589815378189087,
      "learning_rate": 5.910809322811526e-05,
      "logits/chosen": -1.0236072540283203,
      "logits/rejected": -0.9053326845169067,
      "logps/chosen": -164.35072326660156,
      "logps/rejected": -159.51071166992188,
      "loss": 0.358,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.8875793218612671,
      "rewards/margins": 1.5791282653808594,
      "rewards/rejected": -2.466707468032837,
      "step": 7270
    },
    {
      "epoch": 1.32858837485172,
      "grad_norm": 4.453499794006348,
      "learning_rate": 5.9078730042209586e-05,
      "logits/chosen": -0.9844241142272949,
      "logits/rejected": -0.850512683391571,
      "logps/chosen": -152.45127868652344,
      "logps/rejected": -140.52252197265625,
      "loss": 0.4613,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.85248202085495,
      "rewards/margins": 1.5673381090164185,
      "rewards/rejected": -2.4198200702667236,
      "step": 7280
    },
    {
      "epoch": 1.3304133588831097,
      "grad_norm": 3.633242130279541,
      "learning_rate": 5.904936685630391e-05,
      "logits/chosen": -0.9810178875923157,
      "logits/rejected": -0.909214198589325,
      "logps/chosen": -165.43751525878906,
      "logps/rejected": -173.65013122558594,
      "loss": 0.5546,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3581112623214722,
      "rewards/margins": 1.5433485507965088,
      "rewards/rejected": -2.9014596939086914,
      "step": 7290
    },
    {
      "epoch": 1.3322383429144995,
      "grad_norm": 3.274362802505493,
      "learning_rate": 5.902000367039824e-05,
      "logits/chosen": -1.0537782907485962,
      "logits/rejected": -0.9490222930908203,
      "logps/chosen": -156.9615936279297,
      "logps/rejected": -142.3565216064453,
      "loss": 0.413,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.95551598072052,
      "rewards/margins": 1.5093944072723389,
      "rewards/rejected": -2.4649105072021484,
      "step": 7300
    },
    {
      "epoch": 1.3340633269458892,
      "grad_norm": 3.7898333072662354,
      "learning_rate": 5.899064048449257e-05,
      "logits/chosen": -1.0462758541107178,
      "logits/rejected": -0.948686957359314,
      "logps/chosen": -149.01882934570312,
      "logps/rejected": -154.36639404296875,
      "loss": 0.439,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7502150535583496,
      "rewards/margins": 1.7372350692749023,
      "rewards/rejected": -2.487450122833252,
      "step": 7310
    },
    {
      "epoch": 1.335888310977279,
      "grad_norm": 1.2650386095046997,
      "learning_rate": 5.8961277298586904e-05,
      "logits/chosen": -0.9530588984489441,
      "logits/rejected": -0.8462276458740234,
      "logps/chosen": -149.41134643554688,
      "logps/rejected": -158.07028198242188,
      "loss": 0.4751,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.2724573612213135,
      "rewards/margins": 1.6797291040420532,
      "rewards/rejected": -2.952186107635498,
      "step": 7320
    },
    {
      "epoch": 1.3377132950086688,
      "grad_norm": 3.994621992111206,
      "learning_rate": 5.893191411268123e-05,
      "logits/chosen": -0.9168756604194641,
      "logits/rejected": -0.7504675984382629,
      "logps/chosen": -168.8767852783203,
      "logps/rejected": -157.55104064941406,
      "loss": 0.4886,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.8539146184921265,
      "rewards/margins": 1.685752272605896,
      "rewards/rejected": -2.5396666526794434,
      "step": 7330
    },
    {
      "epoch": 1.3395382790400583,
      "grad_norm": 2.781810998916626,
      "learning_rate": 5.8902550926775554e-05,
      "logits/chosen": -0.8758487701416016,
      "logits/rejected": -0.7855128049850464,
      "logps/chosen": -151.12063598632812,
      "logps/rejected": -159.8740997314453,
      "loss": 0.3767,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.313697338104248,
      "rewards/margins": 1.7510162591934204,
      "rewards/rejected": -3.0647132396698,
      "step": 7340
    },
    {
      "epoch": 1.341363263071448,
      "grad_norm": 4.918287754058838,
      "learning_rate": 5.887318774086989e-05,
      "logits/chosen": -0.8673502802848816,
      "logits/rejected": -0.6936624050140381,
      "logps/chosen": -174.8683624267578,
      "logps/rejected": -151.36172485351562,
      "loss": 0.4486,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4601385593414307,
      "rewards/margins": 1.4649348258972168,
      "rewards/rejected": -2.9250731468200684,
      "step": 7350
    },
    {
      "epoch": 1.3431882471028378,
      "grad_norm": 3.136589288711548,
      "learning_rate": 5.8843824554964216e-05,
      "logits/chosen": -0.8417031168937683,
      "logits/rejected": -0.6965886354446411,
      "logps/chosen": -161.492919921875,
      "logps/rejected": -157.8614044189453,
      "loss": 0.4382,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6384775638580322,
      "rewards/margins": 1.5404001474380493,
      "rewards/rejected": -3.178877592086792,
      "step": 7360
    },
    {
      "epoch": 1.3450132311342275,
      "grad_norm": 4.759377956390381,
      "learning_rate": 5.881446136905855e-05,
      "logits/chosen": -0.882102370262146,
      "logits/rejected": -0.7781692743301392,
      "logps/chosen": -164.07611083984375,
      "logps/rejected": -156.2054901123047,
      "loss": 0.6757,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.134899616241455,
      "rewards/margins": 0.9248906373977661,
      "rewards/rejected": -3.0597901344299316,
      "step": 7370
    },
    {
      "epoch": 1.3468382151656173,
      "grad_norm": 4.812835693359375,
      "learning_rate": 5.878509818315287e-05,
      "logits/chosen": -0.8228098750114441,
      "logits/rejected": -0.7454235553741455,
      "logps/chosen": -171.38673400878906,
      "logps/rejected": -178.37124633789062,
      "loss": 0.4968,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9557594060897827,
      "rewards/margins": 1.30525803565979,
      "rewards/rejected": -3.2610175609588623,
      "step": 7380
    },
    {
      "epoch": 1.348663199197007,
      "grad_norm": 2.2430453300476074,
      "learning_rate": 5.875573499724721e-05,
      "logits/chosen": -0.8962517976760864,
      "logits/rejected": -0.7541285753250122,
      "logps/chosen": -154.96432495117188,
      "logps/rejected": -157.94151306152344,
      "loss": 0.4501,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.0383598804473877,
      "rewards/margins": 1.3645769357681274,
      "rewards/rejected": -3.4029364585876465,
      "step": 7390
    },
    {
      "epoch": 1.3504881832283968,
      "grad_norm": 2.4905781745910645,
      "learning_rate": 5.8726371811341535e-05,
      "logits/chosen": -0.8614410161972046,
      "logits/rejected": -0.6965538263320923,
      "logps/chosen": -172.10324096679688,
      "logps/rejected": -159.28500366210938,
      "loss": 0.434,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8615974187850952,
      "rewards/margins": 1.3353345394134521,
      "rewards/rejected": -3.196932077407837,
      "step": 7400
    },
    {
      "epoch": 1.3523131672597866,
      "grad_norm": 3.943368673324585,
      "learning_rate": 5.8697008625435866e-05,
      "logits/chosen": -0.8569372892379761,
      "logits/rejected": -0.7636125683784485,
      "logps/chosen": -161.7509765625,
      "logps/rejected": -159.75167846679688,
      "loss": 0.5443,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.2004354000091553,
      "rewards/margins": 1.1635268926620483,
      "rewards/rejected": -3.363962173461914,
      "step": 7410
    },
    {
      "epoch": 1.3541381512911763,
      "grad_norm": 2.6499924659729004,
      "learning_rate": 5.866764543953019e-05,
      "logits/chosen": -0.8347287178039551,
      "logits/rejected": -0.6840965151786804,
      "logps/chosen": -160.545166015625,
      "logps/rejected": -154.8023223876953,
      "loss": 0.438,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9953041076660156,
      "rewards/margins": 1.344036340713501,
      "rewards/rejected": -3.3393402099609375,
      "step": 7420
    },
    {
      "epoch": 1.3559631353225658,
      "grad_norm": 5.136423110961914,
      "learning_rate": 5.863828225362452e-05,
      "logits/chosen": -0.8051662445068359,
      "logits/rejected": -0.6430810689926147,
      "logps/chosen": -180.60324096679688,
      "logps/rejected": -181.1326141357422,
      "loss": 0.5535,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.659546375274658,
      "rewards/margins": 1.2909367084503174,
      "rewards/rejected": -3.9504826068878174,
      "step": 7430
    },
    {
      "epoch": 1.3577881193539556,
      "grad_norm": 3.5687155723571777,
      "learning_rate": 5.8608919067718854e-05,
      "logits/chosen": -0.773626446723938,
      "logits/rejected": -0.6709675788879395,
      "logps/chosen": -172.15594482421875,
      "logps/rejected": -165.10342407226562,
      "loss": 0.4252,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.187427043914795,
      "rewards/margins": 1.3229717016220093,
      "rewards/rejected": -3.5103988647460938,
      "step": 7440
    },
    {
      "epoch": 1.3596131033853454,
      "grad_norm": 5.3079047203063965,
      "learning_rate": 5.857955588181318e-05,
      "logits/chosen": -0.7556249499320984,
      "logits/rejected": -0.5888876914978027,
      "logps/chosen": -210.91970825195312,
      "logps/rejected": -180.229248046875,
      "loss": 0.5878,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9623291492462158,
      "rewards/margins": 1.1075278520584106,
      "rewards/rejected": -3.069856882095337,
      "step": 7450
    },
    {
      "epoch": 1.361438087416735,
      "grad_norm": 3.077347755432129,
      "learning_rate": 5.8550192695907516e-05,
      "logits/chosen": -0.883201003074646,
      "logits/rejected": -0.6440815925598145,
      "logps/chosen": -190.45753479003906,
      "logps/rejected": -145.8561553955078,
      "loss": 0.4508,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.846552848815918,
      "rewards/margins": 1.2419798374176025,
      "rewards/rejected": -3.0885326862335205,
      "step": 7460
    },
    {
      "epoch": 1.3632630714481249,
      "grad_norm": 2.5742123126983643,
      "learning_rate": 5.852082951000184e-05,
      "logits/chosen": -0.6981700658798218,
      "logits/rejected": -0.5643692016601562,
      "logps/chosen": -167.34725952148438,
      "logps/rejected": -166.80050659179688,
      "loss": 0.3849,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.8554799556732178,
      "rewards/margins": 1.6244455575942993,
      "rewards/rejected": -3.4799256324768066,
      "step": 7470
    },
    {
      "epoch": 1.3650880554795146,
      "grad_norm": 2.038299083709717,
      "learning_rate": 5.849146632409617e-05,
      "logits/chosen": -0.6635239720344543,
      "logits/rejected": -0.610503613948822,
      "logps/chosen": -175.3639678955078,
      "logps/rejected": -187.67465209960938,
      "loss": 0.4848,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.6289408206939697,
      "rewards/margins": 1.5975695848464966,
      "rewards/rejected": -4.226510047912598,
      "step": 7480
    },
    {
      "epoch": 1.3669130395109041,
      "grad_norm": 3.9275026321411133,
      "learning_rate": 5.84621031381905e-05,
      "logits/chosen": -0.7307555079460144,
      "logits/rejected": -0.6355918049812317,
      "logps/chosen": -163.28286743164062,
      "logps/rejected": -173.97015380859375,
      "loss": 0.3498,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.5949809551239014,
      "rewards/margins": 1.862091064453125,
      "rewards/rejected": -4.4570722579956055,
      "step": 7490
    },
    {
      "epoch": 1.368738023542294,
      "grad_norm": 3.347297191619873,
      "learning_rate": 5.8432739952284835e-05,
      "logits/chosen": -0.820941150188446,
      "logits/rejected": -0.6979185938835144,
      "logps/chosen": -174.62551879882812,
      "logps/rejected": -172.21005249023438,
      "loss": 0.4138,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.2852938175201416,
      "rewards/margins": 1.8105885982513428,
      "rewards/rejected": -4.095881938934326,
      "step": 7500
    },
    {
      "epoch": 1.3705630075736837,
      "grad_norm": 2.733680248260498,
      "learning_rate": 5.840337676637916e-05,
      "logits/chosen": -0.7420223951339722,
      "logits/rejected": -0.5489177703857422,
      "logps/chosen": -179.28042602539062,
      "logps/rejected": -157.75453186035156,
      "loss": 0.5151,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.2155892848968506,
      "rewards/margins": 1.4447557926177979,
      "rewards/rejected": -3.6603455543518066,
      "step": 7510
    },
    {
      "epoch": 1.3723879916050734,
      "grad_norm": 4.69254732131958,
      "learning_rate": 5.8374013580473484e-05,
      "logits/chosen": -0.7492245435714722,
      "logits/rejected": -0.524552047252655,
      "logps/chosen": -163.10227966308594,
      "logps/rejected": -137.4322052001953,
      "loss": 0.4149,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5542271137237549,
      "rewards/margins": 1.6329625844955444,
      "rewards/rejected": -3.187189817428589,
      "step": 7520
    },
    {
      "epoch": 1.3742129756364632,
      "grad_norm": 2.4934332370758057,
      "learning_rate": 5.8344650394567815e-05,
      "logits/chosen": -0.7507108449935913,
      "logits/rejected": -0.5785233378410339,
      "logps/chosen": -161.69998168945312,
      "logps/rejected": -147.1982421875,
      "loss": 0.4889,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1685144901275635,
      "rewards/margins": 1.48060142993927,
      "rewards/rejected": -2.649115800857544,
      "step": 7530
    },
    {
      "epoch": 1.376037959667853,
      "grad_norm": 1.7881780862808228,
      "learning_rate": 5.831528720866215e-05,
      "logits/chosen": -0.8093733787536621,
      "logits/rejected": -0.5860682725906372,
      "logps/chosen": -171.48207092285156,
      "logps/rejected": -165.89407348632812,
      "loss": 0.3066,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.3631293773651123,
      "rewards/margins": 2.048962116241455,
      "rewards/rejected": -3.4120914936065674,
      "step": 7540
    },
    {
      "epoch": 1.3778629436992427,
      "grad_norm": 2.6495864391326904,
      "learning_rate": 5.828592402275648e-05,
      "logits/chosen": -0.8045634031295776,
      "logits/rejected": -0.5805209875106812,
      "logps/chosen": -180.55679321289062,
      "logps/rejected": -161.76956176757812,
      "loss": 0.4282,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.7157020568847656,
      "rewards/margins": 1.8022754192352295,
      "rewards/rejected": -3.517977476119995,
      "step": 7550
    },
    {
      "epoch": 1.3796879277306324,
      "grad_norm": 2.0817337036132812,
      "learning_rate": 5.82565608368508e-05,
      "logits/chosen": -0.7428202033042908,
      "logits/rejected": -0.6156570315361023,
      "logps/chosen": -162.4901123046875,
      "logps/rejected": -157.6334686279297,
      "loss": 0.413,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4725868701934814,
      "rewards/margins": 1.5336188077926636,
      "rewards/rejected": -3.0062060356140137,
      "step": 7560
    },
    {
      "epoch": 1.3815129117620222,
      "grad_norm": 3.6850850582122803,
      "learning_rate": 5.822719765094513e-05,
      "logits/chosen": -0.7286638617515564,
      "logits/rejected": -0.5924575924873352,
      "logps/chosen": -159.49391174316406,
      "logps/rejected": -155.4482879638672,
      "loss": 0.4272,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5294325351715088,
      "rewards/margins": 1.7488778829574585,
      "rewards/rejected": -3.2783102989196777,
      "step": 7570
    },
    {
      "epoch": 1.383337895793412,
      "grad_norm": 4.170952320098877,
      "learning_rate": 5.8197834465039465e-05,
      "logits/chosen": -0.8738645315170288,
      "logits/rejected": -0.752088189125061,
      "logps/chosen": -161.62286376953125,
      "logps/rejected": -154.4145050048828,
      "loss": 0.4106,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.7003120183944702,
      "rewards/margins": 1.7405141592025757,
      "rewards/rejected": -2.440825939178467,
      "step": 7580
    },
    {
      "epoch": 1.3851628798248015,
      "grad_norm": 5.24131441116333,
      "learning_rate": 5.816847127913379e-05,
      "logits/chosen": -0.7747819423675537,
      "logits/rejected": -0.6150802969932556,
      "logps/chosen": -144.82655334472656,
      "logps/rejected": -145.268798828125,
      "loss": 0.4107,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.047438383102417,
      "rewards/margins": 1.997534990310669,
      "rewards/rejected": -3.044973611831665,
      "step": 7590
    },
    {
      "epoch": 1.3869878638561912,
      "grad_norm": 3.3326570987701416,
      "learning_rate": 5.813910809322812e-05,
      "logits/chosen": -0.6791151762008667,
      "logits/rejected": -0.5584253668785095,
      "logps/chosen": -156.6949462890625,
      "logps/rejected": -159.18711853027344,
      "loss": 0.3686,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.7131894826889038,
      "rewards/margins": 1.4966789484024048,
      "rewards/rejected": -3.2098681926727295,
      "step": 7600
    },
    {
      "epoch": 1.388812847887581,
      "grad_norm": 5.1591572761535645,
      "learning_rate": 5.8109744907322446e-05,
      "logits/chosen": -0.8230751156806946,
      "logits/rejected": -0.6316412687301636,
      "logps/chosen": -176.4565887451172,
      "logps/rejected": -156.3733367919922,
      "loss": 0.4626,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6048485040664673,
      "rewards/margins": 1.4992828369140625,
      "rewards/rejected": -3.1041312217712402,
      "step": 7610
    },
    {
      "epoch": 1.3906378319189707,
      "grad_norm": 3.2120888233184814,
      "learning_rate": 5.8080381721416784e-05,
      "logits/chosen": -0.7185931205749512,
      "logits/rejected": -0.5783572793006897,
      "logps/chosen": -171.64170837402344,
      "logps/rejected": -175.22210693359375,
      "loss": 0.4111,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7982523441314697,
      "rewards/margins": 1.8003203868865967,
      "rewards/rejected": -3.5985729694366455,
      "step": 7620
    },
    {
      "epoch": 1.3924628159503605,
      "grad_norm": 1.9594093561172485,
      "learning_rate": 5.805101853551111e-05,
      "logits/chosen": -0.7253844738006592,
      "logits/rejected": -0.47134432196617126,
      "logps/chosen": -183.884765625,
      "logps/rejected": -161.45437622070312,
      "loss": 0.3893,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8199599981307983,
      "rewards/margins": 1.762408971786499,
      "rewards/rejected": -3.582369327545166,
      "step": 7630
    },
    {
      "epoch": 1.3942877999817502,
      "grad_norm": 1.9957318305969238,
      "learning_rate": 5.802165534960543e-05,
      "logits/chosen": -0.7249312996864319,
      "logits/rejected": -0.6467804908752441,
      "logps/chosen": -166.28701782226562,
      "logps/rejected": -159.0596160888672,
      "loss": 0.4681,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.9207051992416382,
      "rewards/margins": 1.2343882322311401,
      "rewards/rejected": -3.155093193054199,
      "step": 7640
    },
    {
      "epoch": 1.3961127840131398,
      "grad_norm": 4.650106430053711,
      "learning_rate": 5.799229216369977e-05,
      "logits/chosen": -0.6947463750839233,
      "logits/rejected": -0.5446063280105591,
      "logps/chosen": -164.4542694091797,
      "logps/rejected": -154.3345947265625,
      "loss": 0.5227,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1528160572052,
      "rewards/margins": 1.4285311698913574,
      "rewards/rejected": -3.5813469886779785,
      "step": 7650
    },
    {
      "epoch": 1.3979377680445295,
      "grad_norm": 5.063981533050537,
      "learning_rate": 5.7962928977794096e-05,
      "logits/chosen": -0.8114233016967773,
      "logits/rejected": -0.7276885509490967,
      "logps/chosen": -167.83346557617188,
      "logps/rejected": -171.6820068359375,
      "loss": 0.4773,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9005005359649658,
      "rewards/margins": 1.525763750076294,
      "rewards/rejected": -3.4262642860412598,
      "step": 7660
    },
    {
      "epoch": 1.3997627520759193,
      "grad_norm": 6.456507205963135,
      "learning_rate": 5.793356579188843e-05,
      "logits/chosen": -0.7634409666061401,
      "logits/rejected": -0.5888391733169556,
      "logps/chosen": -154.72314453125,
      "logps/rejected": -146.30038452148438,
      "loss": 0.4251,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0735104084014893,
      "rewards/margins": 1.4210631847381592,
      "rewards/rejected": -3.4945735931396484,
      "step": 7670
    },
    {
      "epoch": 1.401587736107309,
      "grad_norm": 3.9394047260284424,
      "learning_rate": 5.790420260598275e-05,
      "logits/chosen": -0.7342292070388794,
      "logits/rejected": -0.5565439462661743,
      "logps/chosen": -191.7999725341797,
      "logps/rejected": -179.2275390625,
      "loss": 0.3577,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.8720133304595947,
      "rewards/margins": 2.0490450859069824,
      "rewards/rejected": -3.9210586547851562,
      "step": 7680
    },
    {
      "epoch": 1.4034127201386988,
      "grad_norm": 6.015439510345459,
      "learning_rate": 5.787483942007709e-05,
      "logits/chosen": -0.7098038792610168,
      "logits/rejected": -0.6375763416290283,
      "logps/chosen": -150.3398895263672,
      "logps/rejected": -164.9958953857422,
      "loss": 0.4017,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.4047794342041016,
      "rewards/margins": 1.7293651103973389,
      "rewards/rejected": -4.134144306182861,
      "step": 7690
    },
    {
      "epoch": 1.4052377041700885,
      "grad_norm": 6.1394453048706055,
      "learning_rate": 5.7845476234171414e-05,
      "logits/chosen": -0.6657894849777222,
      "logits/rejected": -0.5464149713516235,
      "logps/chosen": -165.1771697998047,
      "logps/rejected": -157.712158203125,
      "loss": 0.4703,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.707204580307007,
      "rewards/margins": 1.4220912456512451,
      "rewards/rejected": -4.12929630279541,
      "step": 7700
    },
    {
      "epoch": 1.4070626882014783,
      "grad_norm": 4.213093280792236,
      "learning_rate": 5.781611304826574e-05,
      "logits/chosen": -0.6502979397773743,
      "logits/rejected": -0.5915036797523499,
      "logps/chosen": -170.23428344726562,
      "logps/rejected": -193.03378295898438,
      "loss": 0.4394,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.705575942993164,
      "rewards/margins": 1.6451292037963867,
      "rewards/rejected": -4.350705146789551,
      "step": 7710
    },
    {
      "epoch": 1.408887672232868,
      "grad_norm": 7.1141228675842285,
      "learning_rate": 5.778674986236007e-05,
      "logits/chosen": -0.7578588724136353,
      "logits/rejected": -0.6701928973197937,
      "logps/chosen": -173.0312957763672,
      "logps/rejected": -181.6326141357422,
      "loss": 0.4659,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.8966493606567383,
      "rewards/margins": 1.4914376735687256,
      "rewards/rejected": -4.388087272644043,
      "step": 7720
    },
    {
      "epoch": 1.4107126562642578,
      "grad_norm": 6.322772026062012,
      "learning_rate": 5.77573866764544e-05,
      "logits/chosen": -0.8199437856674194,
      "logits/rejected": -0.5550835728645325,
      "logps/chosen": -182.44607543945312,
      "logps/rejected": -157.03298950195312,
      "loss": 0.4035,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.628047227859497,
      "rewards/margins": 1.5712217092514038,
      "rewards/rejected": -4.1992692947387695,
      "step": 7730
    },
    {
      "epoch": 1.4125376402956475,
      "grad_norm": 4.735891342163086,
      "learning_rate": 5.772802349054873e-05,
      "logits/chosen": -0.8619707226753235,
      "logits/rejected": -0.7243013978004456,
      "logps/chosen": -169.63253784179688,
      "logps/rejected": -168.53916931152344,
      "loss": 0.4196,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.208930253982544,
      "rewards/margins": 1.6504509449005127,
      "rewards/rejected": -3.8593811988830566,
      "step": 7740
    },
    {
      "epoch": 1.414362624327037,
      "grad_norm": 3.7413687705993652,
      "learning_rate": 5.769866030464306e-05,
      "logits/chosen": -0.7931135892868042,
      "logits/rejected": -0.7031943798065186,
      "logps/chosen": -157.11160278320312,
      "logps/rejected": -167.59878540039062,
      "loss": 0.3287,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.2174813747406006,
      "rewards/margins": 1.8264135122299194,
      "rewards/rejected": -4.043895244598389,
      "step": 7750
    },
    {
      "epoch": 1.4161876083584268,
      "grad_norm": 3.476775646209717,
      "learning_rate": 5.766929711873738e-05,
      "logits/chosen": -0.8300648927688599,
      "logits/rejected": -0.6558430790901184,
      "logps/chosen": -163.53175354003906,
      "logps/rejected": -159.51779174804688,
      "loss": 0.4685,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.6251909732818604,
      "rewards/margins": 1.6387481689453125,
      "rewards/rejected": -4.2639384269714355,
      "step": 7760
    },
    {
      "epoch": 1.4180125923898166,
      "grad_norm": 4.311789035797119,
      "learning_rate": 5.763993393283172e-05,
      "logits/chosen": -0.8225126266479492,
      "logits/rejected": -0.6857927441596985,
      "logps/chosen": -162.52316284179688,
      "logps/rejected": -170.86416625976562,
      "loss": 0.386,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.045215129852295,
      "rewards/margins": 2.0527687072753906,
      "rewards/rejected": -4.0979838371276855,
      "step": 7770
    },
    {
      "epoch": 1.4198375764212063,
      "grad_norm": 2.574097156524658,
      "learning_rate": 5.7610570746926045e-05,
      "logits/chosen": -0.871806800365448,
      "logits/rejected": -0.7997238636016846,
      "logps/chosen": -160.4951171875,
      "logps/rejected": -164.96315002441406,
      "loss": 0.4512,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9581701755523682,
      "rewards/margins": 1.4824984073638916,
      "rewards/rejected": -3.4406685829162598,
      "step": 7780
    },
    {
      "epoch": 1.421662560452596,
      "grad_norm": 5.555874347686768,
      "learning_rate": 5.7581207561020376e-05,
      "logits/chosen": -0.8837414979934692,
      "logits/rejected": -0.7863675951957703,
      "logps/chosen": -162.05697631835938,
      "logps/rejected": -173.98562622070312,
      "loss": 0.4695,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.5969167947769165,
      "rewards/margins": 1.5090227127075195,
      "rewards/rejected": -3.1059393882751465,
      "step": 7790
    },
    {
      "epoch": 1.4234875444839858,
      "grad_norm": 6.407856464385986,
      "learning_rate": 5.75518443751147e-05,
      "logits/chosen": -0.9193845987319946,
      "logits/rejected": -0.7446982264518738,
      "logps/chosen": -181.93153381347656,
      "logps/rejected": -156.14205932617188,
      "loss": 0.4209,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2908258438110352,
      "rewards/margins": 1.9024585485458374,
      "rewards/rejected": -3.193284511566162,
      "step": 7800
    },
    {
      "epoch": 1.4253125285153754,
      "grad_norm": 3.87581729888916,
      "learning_rate": 5.752248118920904e-05,
      "logits/chosen": -0.8722759485244751,
      "logits/rejected": -0.6903582811355591,
      "logps/chosen": -175.11886596679688,
      "logps/rejected": -166.0702362060547,
      "loss": 0.4597,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8453471660614014,
      "rewards/margins": 1.7725756168365479,
      "rewards/rejected": -3.6179230213165283,
      "step": 7810
    },
    {
      "epoch": 1.4271375125467651,
      "grad_norm": 3.444807529449463,
      "learning_rate": 5.7493118003303364e-05,
      "logits/chosen": -0.8269603848457336,
      "logits/rejected": -0.6383498311042786,
      "logps/chosen": -185.28298950195312,
      "logps/rejected": -175.36569213867188,
      "loss": 0.3287,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.181147575378418,
      "rewards/margins": 1.8549625873565674,
      "rewards/rejected": -4.036110877990723,
      "step": 7820
    },
    {
      "epoch": 1.4289624965781549,
      "grad_norm": 3.6836678981781006,
      "learning_rate": 5.746375481739769e-05,
      "logits/chosen": -0.7656346559524536,
      "logits/rejected": -0.6311212778091431,
      "logps/chosen": -154.24562072753906,
      "logps/rejected": -157.8504638671875,
      "loss": 0.4845,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1693737506866455,
      "rewards/margins": 1.5291109085083008,
      "rewards/rejected": -3.6984848976135254,
      "step": 7830
    },
    {
      "epoch": 1.4307874806095446,
      "grad_norm": 2.317429304122925,
      "learning_rate": 5.7434391631492026e-05,
      "logits/chosen": -0.8964046239852905,
      "logits/rejected": -0.7856365442276001,
      "logps/chosen": -162.98960876464844,
      "logps/rejected": -176.51016235351562,
      "loss": 0.3402,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.180082082748413,
      "rewards/margins": 1.930198073387146,
      "rewards/rejected": -4.110280513763428,
      "step": 7840
    },
    {
      "epoch": 1.4326124646409344,
      "grad_norm": 8.205146789550781,
      "learning_rate": 5.740502844558635e-05,
      "logits/chosen": -0.8007739186286926,
      "logits/rejected": -0.7158434987068176,
      "logps/chosen": -152.7459259033203,
      "logps/rejected": -163.9939727783203,
      "loss": 0.5876,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.335552215576172,
      "rewards/margins": 1.264268159866333,
      "rewards/rejected": -3.599820375442505,
      "step": 7850
    },
    {
      "epoch": 1.4344374486723241,
      "grad_norm": 5.523355484008789,
      "learning_rate": 5.737566525968068e-05,
      "logits/chosen": -0.7840276956558228,
      "logits/rejected": -0.6412205100059509,
      "logps/chosen": -163.08245849609375,
      "logps/rejected": -155.42442321777344,
      "loss": 0.4613,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9746720790863037,
      "rewards/margins": 1.759282112121582,
      "rewards/rejected": -3.7339541912078857,
      "step": 7860
    },
    {
      "epoch": 1.436262432703714,
      "grad_norm": 4.502974033355713,
      "learning_rate": 5.734630207377501e-05,
      "logits/chosen": -0.7746320366859436,
      "logits/rejected": -0.6784423589706421,
      "logps/chosen": -178.6085662841797,
      "logps/rejected": -183.8133087158203,
      "loss": 0.5413,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.5671868324279785,
      "rewards/margins": 1.5574623346328735,
      "rewards/rejected": -4.1246490478515625,
      "step": 7870
    },
    {
      "epoch": 1.4380874167351037,
      "grad_norm": 2.3430135250091553,
      "learning_rate": 5.7316938887869345e-05,
      "logits/chosen": -0.7758641242980957,
      "logits/rejected": -0.6754454374313354,
      "logps/chosen": -164.05848693847656,
      "logps/rejected": -156.4312744140625,
      "loss": 0.4212,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.396592378616333,
      "rewards/margins": 1.4888360500335693,
      "rewards/rejected": -3.885427951812744,
      "step": 7880
    },
    {
      "epoch": 1.4399124007664934,
      "grad_norm": 6.0082879066467285,
      "learning_rate": 5.728757570196367e-05,
      "logits/chosen": -0.789892852306366,
      "logits/rejected": -0.6848157644271851,
      "logps/chosen": -163.89968872070312,
      "logps/rejected": -174.8707275390625,
      "loss": 0.3575,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.3655102252960205,
      "rewards/margins": 1.8367446660995483,
      "rewards/rejected": -4.202254772186279,
      "step": 7890
    },
    {
      "epoch": 1.441737384797883,
      "grad_norm": 3.4049289226531982,
      "learning_rate": 5.7258212516057994e-05,
      "logits/chosen": -0.8986174464225769,
      "logits/rejected": -0.7578078508377075,
      "logps/chosen": -173.81576538085938,
      "logps/rejected": -163.43414306640625,
      "loss": 0.4931,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.8250064849853516,
      "rewards/margins": 1.505853533744812,
      "rewards/rejected": -4.330860137939453,
      "step": 7900
    },
    {
      "epoch": 1.4435623688292727,
      "grad_norm": 3.1653037071228027,
      "learning_rate": 5.7228849330152325e-05,
      "logits/chosen": -0.7695002555847168,
      "logits/rejected": -0.6325846910476685,
      "logps/chosen": -153.86280822753906,
      "logps/rejected": -158.16152954101562,
      "loss": 0.3418,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9554855823516846,
      "rewards/margins": 1.8943074941635132,
      "rewards/rejected": -3.849792957305908,
      "step": 7910
    },
    {
      "epoch": 1.4453873528606624,
      "grad_norm": 3.0422582626342773,
      "learning_rate": 5.719948614424666e-05,
      "logits/chosen": -0.8635067939758301,
      "logits/rejected": -0.7350850701332092,
      "logps/chosen": -176.1587371826172,
      "logps/rejected": -164.00845336914062,
      "loss": 0.4256,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4806649684906006,
      "rewards/margins": 1.643705129623413,
      "rewards/rejected": -3.1243700981140137,
      "step": 7920
    },
    {
      "epoch": 1.4472123368920522,
      "grad_norm": 3.537785768508911,
      "learning_rate": 5.717012295834099e-05,
      "logits/chosen": -0.7897462248802185,
      "logits/rejected": -0.6340762376785278,
      "logps/chosen": -179.34169006347656,
      "logps/rejected": -148.32920837402344,
      "loss": 0.4934,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.2419145107269287,
      "rewards/margins": 1.1525099277496338,
      "rewards/rejected": -3.3944244384765625,
      "step": 7930
    },
    {
      "epoch": 1.449037320923442,
      "grad_norm": 4.865908145904541,
      "learning_rate": 5.714075977243531e-05,
      "logits/chosen": -0.7465839982032776,
      "logits/rejected": -0.7018879652023315,
      "logps/chosen": -156.14039611816406,
      "logps/rejected": -177.4220733642578,
      "loss": 0.3775,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7851288318634033,
      "rewards/margins": 2.0361664295196533,
      "rewards/rejected": -3.8212952613830566,
      "step": 7940
    },
    {
      "epoch": 1.4508623049548317,
      "grad_norm": 5.056313991546631,
      "learning_rate": 5.711139658652964e-05,
      "logits/chosen": -0.7739691138267517,
      "logits/rejected": -0.6627927422523499,
      "logps/chosen": -185.95562744140625,
      "logps/rejected": -184.1698455810547,
      "loss": 0.5665,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.016312837600708,
      "rewards/margins": 1.4688154458999634,
      "rewards/rejected": -3.4851279258728027,
      "step": 7950
    },
    {
      "epoch": 1.4526872889862212,
      "grad_norm": 3.809378147125244,
      "learning_rate": 5.7082033400623975e-05,
      "logits/chosen": -0.8384135961532593,
      "logits/rejected": -0.6579211950302124,
      "logps/chosen": -161.450439453125,
      "logps/rejected": -156.8760528564453,
      "loss": 0.4383,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.6442238092422485,
      "rewards/margins": 1.8907743692398071,
      "rewards/rejected": -3.5349979400634766,
      "step": 7960
    },
    {
      "epoch": 1.454512273017611,
      "grad_norm": 2.5966854095458984,
      "learning_rate": 5.70526702147183e-05,
      "logits/chosen": -0.7838340401649475,
      "logits/rejected": -0.6197670102119446,
      "logps/chosen": -176.62794494628906,
      "logps/rejected": -161.76300048828125,
      "loss": 0.4654,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.1155924797058105,
      "rewards/margins": 1.4741172790527344,
      "rewards/rejected": -3.589709520339966,
      "step": 7970
    },
    {
      "epoch": 1.4563372570490007,
      "grad_norm": 6.038224697113037,
      "learning_rate": 5.702330702881263e-05,
      "logits/chosen": -0.7028825283050537,
      "logits/rejected": -0.6162906885147095,
      "logps/chosen": -162.80838012695312,
      "logps/rejected": -170.90780639648438,
      "loss": 0.5346,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.4072513580322266,
      "rewards/margins": 1.2668075561523438,
      "rewards/rejected": -3.6740589141845703,
      "step": 7980
    },
    {
      "epoch": 1.4581622410803905,
      "grad_norm": 3.786971092224121,
      "learning_rate": 5.6993943842906956e-05,
      "logits/chosen": -0.7766138315200806,
      "logits/rejected": -0.6558496356010437,
      "logps/chosen": -153.51844787597656,
      "logps/rejected": -159.19992065429688,
      "loss": 0.4396,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9389642477035522,
      "rewards/margins": 1.48153817653656,
      "rewards/rejected": -3.4205024242401123,
      "step": 7990
    },
    {
      "epoch": 1.4599872251117803,
      "grad_norm": 2.502197504043579,
      "learning_rate": 5.6964580657001294e-05,
      "logits/chosen": -0.7315078377723694,
      "logits/rejected": -0.6642872095108032,
      "logps/chosen": -149.28407287597656,
      "logps/rejected": -175.62632751464844,
      "loss": 0.4011,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.133815288543701,
      "rewards/margins": 1.5847232341766357,
      "rewards/rejected": -3.718538761138916,
      "step": 8000
    },
    {
      "epoch": 1.46181220914317,
      "grad_norm": 4.669615745544434,
      "learning_rate": 5.693521747109562e-05,
      "logits/chosen": -0.8240987658500671,
      "logits/rejected": -0.6651365756988525,
      "logps/chosen": -164.8978271484375,
      "logps/rejected": -151.2295379638672,
      "loss": 0.4538,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.141752004623413,
      "rewards/margins": 1.5773723125457764,
      "rewards/rejected": -3.7191243171691895,
      "step": 8010
    },
    {
      "epoch": 1.4636371931745598,
      "grad_norm": 7.097532272338867,
      "learning_rate": 5.690585428518994e-05,
      "logits/chosen": -0.8337051272392273,
      "logits/rejected": -0.7466820478439331,
      "logps/chosen": -160.29095458984375,
      "logps/rejected": -158.86447143554688,
      "loss": 0.4526,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8422893285751343,
      "rewards/margins": 1.461154580116272,
      "rewards/rejected": -3.3034439086914062,
      "step": 8020
    },
    {
      "epoch": 1.4654621772059495,
      "grad_norm": 2.2549524307250977,
      "learning_rate": 5.687649109928428e-05,
      "logits/chosen": -0.7955289483070374,
      "logits/rejected": -0.6826122403144836,
      "logps/chosen": -168.84242248535156,
      "logps/rejected": -160.9374542236328,
      "loss": 0.4965,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.0229506492614746,
      "rewards/margins": 1.4429787397384644,
      "rewards/rejected": -3.4659290313720703,
      "step": 8030
    },
    {
      "epoch": 1.4672871612373393,
      "grad_norm": 4.312414169311523,
      "learning_rate": 5.6847127913378606e-05,
      "logits/chosen": -0.7960649728775024,
      "logits/rejected": -0.7034794092178345,
      "logps/chosen": -146.4803924560547,
      "logps/rejected": -153.4623260498047,
      "loss": 0.4533,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6751493215560913,
      "rewards/margins": 1.2491264343261719,
      "rewards/rejected": -2.9242758750915527,
      "step": 8040
    },
    {
      "epoch": 1.469112145268729,
      "grad_norm": 4.021172523498535,
      "learning_rate": 5.681776472747294e-05,
      "logits/chosen": -0.6880982518196106,
      "logits/rejected": -0.7020691633224487,
      "logps/chosen": -139.5452117919922,
      "logps/rejected": -172.00758361816406,
      "loss": 0.522,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.058096408843994,
      "rewards/margins": 1.1317418813705444,
      "rewards/rejected": -3.189838409423828,
      "step": 8050
    },
    {
      "epoch": 1.4709371293001186,
      "grad_norm": 1.3160064220428467,
      "learning_rate": 5.678840154156726e-05,
      "logits/chosen": -0.7287816405296326,
      "logits/rejected": -0.6273022890090942,
      "logps/chosen": -160.34207153320312,
      "logps/rejected": -164.3768768310547,
      "loss": 0.4878,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.33099365234375,
      "rewards/margins": 1.1299970149993896,
      "rewards/rejected": -3.4609901905059814,
      "step": 8060
    },
    {
      "epoch": 1.4727621133315083,
      "grad_norm": 2.791811466217041,
      "learning_rate": 5.67590383556616e-05,
      "logits/chosen": -0.7799413204193115,
      "logits/rejected": -0.6325722932815552,
      "logps/chosen": -165.50657653808594,
      "logps/rejected": -155.31385803222656,
      "loss": 0.358,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.6123592853546143,
      "rewards/margins": 1.5894968509674072,
      "rewards/rejected": -3.2018566131591797,
      "step": 8070
    },
    {
      "epoch": 1.474587097362898,
      "grad_norm": 2.5659339427948,
      "learning_rate": 5.6729675169755924e-05,
      "logits/chosen": -0.7826648950576782,
      "logits/rejected": -0.7226189374923706,
      "logps/chosen": -159.50949096679688,
      "logps/rejected": -168.71292114257812,
      "loss": 0.5105,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.8596951961517334,
      "rewards/margins": 1.2703474760055542,
      "rewards/rejected": -3.130042552947998,
      "step": 8080
    },
    {
      "epoch": 1.4764120813942878,
      "grad_norm": 4.103099346160889,
      "learning_rate": 5.670031198385025e-05,
      "logits/chosen": -0.7592712640762329,
      "logits/rejected": -0.6022087335586548,
      "logps/chosen": -183.39785766601562,
      "logps/rejected": -157.12454223632812,
      "loss": 0.4944,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7657111883163452,
      "rewards/margins": 1.1966211795806885,
      "rewards/rejected": -2.962332248687744,
      "step": 8090
    },
    {
      "epoch": 1.4782370654256776,
      "grad_norm": 4.205650806427002,
      "learning_rate": 5.667094879794458e-05,
      "logits/chosen": -0.7036186456680298,
      "logits/rejected": -0.5826482176780701,
      "logps/chosen": -152.32473754882812,
      "logps/rejected": -161.68508911132812,
      "loss": 0.4264,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.954135537147522,
      "rewards/margins": 1.4732706546783447,
      "rewards/rejected": -3.4274063110351562,
      "step": 8100
    },
    {
      "epoch": 1.4800620494570673,
      "grad_norm": 4.43128776550293,
      "learning_rate": 5.664158561203891e-05,
      "logits/chosen": -0.7931938171386719,
      "logits/rejected": -0.5121945738792419,
      "logps/chosen": -189.23597717285156,
      "logps/rejected": -170.77703857421875,
      "loss": 0.3785,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.289039373397827,
      "rewards/margins": 1.61865234375,
      "rewards/rejected": -3.907691478729248,
      "step": 8110
    },
    {
      "epoch": 1.4818870334884569,
      "grad_norm": 2.574702024459839,
      "learning_rate": 5.661222242613324e-05,
      "logits/chosen": -0.7800981998443604,
      "logits/rejected": -0.6194342374801636,
      "logps/chosen": -168.82479858398438,
      "logps/rejected": -160.41860961914062,
      "loss": 0.4227,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.394434928894043,
      "rewards/margins": 1.3385850191116333,
      "rewards/rejected": -3.733020067214966,
      "step": 8120
    },
    {
      "epoch": 1.4837120175198466,
      "grad_norm": 1.9986544847488403,
      "learning_rate": 5.658285924022757e-05,
      "logits/chosen": -0.7574604153633118,
      "logits/rejected": -0.6112402081489563,
      "logps/chosen": -178.93972778320312,
      "logps/rejected": -177.3493194580078,
      "loss": 0.4589,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4328279495239258,
      "rewards/margins": 1.648471474647522,
      "rewards/rejected": -3.081299304962158,
      "step": 8130
    },
    {
      "epoch": 1.4855370015512364,
      "grad_norm": 3.8131816387176514,
      "learning_rate": 5.655349605432189e-05,
      "logits/chosen": -0.7307034134864807,
      "logits/rejected": -0.5983909964561462,
      "logps/chosen": -170.10971069335938,
      "logps/rejected": -152.41293334960938,
      "loss": 0.5265,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.0326874256134033,
      "rewards/margins": 1.367209792137146,
      "rewards/rejected": -3.399897336959839,
      "step": 8140
    },
    {
      "epoch": 1.4873619855826261,
      "grad_norm": 2.4914844036102295,
      "learning_rate": 5.652413286841623e-05,
      "logits/chosen": -0.8393871188163757,
      "logits/rejected": -0.773054301738739,
      "logps/chosen": -154.39602661132812,
      "logps/rejected": -166.72952270507812,
      "loss": 0.4687,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6007928848266602,
      "rewards/margins": 1.382739543914795,
      "rewards/rejected": -2.983532667160034,
      "step": 8150
    },
    {
      "epoch": 1.4891869696140159,
      "grad_norm": 2.8647968769073486,
      "learning_rate": 5.6494769682510555e-05,
      "logits/chosen": -0.8686505556106567,
      "logits/rejected": -0.744947075843811,
      "logps/chosen": -175.3722686767578,
      "logps/rejected": -165.75241088867188,
      "loss": 0.4006,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7344751358032227,
      "rewards/margins": 1.5701299905776978,
      "rewards/rejected": -3.304605007171631,
      "step": 8160
    },
    {
      "epoch": 1.4910119536454056,
      "grad_norm": 2.5142526626586914,
      "learning_rate": 5.6465406496604886e-05,
      "logits/chosen": -0.7496124505996704,
      "logits/rejected": -0.6244401931762695,
      "logps/chosen": -154.8418426513672,
      "logps/rejected": -154.1830291748047,
      "loss": 0.4721,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9037981033325195,
      "rewards/margins": 1.3194820880889893,
      "rewards/rejected": -3.223280429840088,
      "step": 8170
    },
    {
      "epoch": 1.4928369376767954,
      "grad_norm": 4.391809463500977,
      "learning_rate": 5.643604331069921e-05,
      "logits/chosen": -0.7598472237586975,
      "logits/rejected": -0.6896473169326782,
      "logps/chosen": -162.89083862304688,
      "logps/rejected": -170.7461395263672,
      "loss": 0.3882,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.6623964309692383,
      "rewards/margins": 1.5703999996185303,
      "rewards/rejected": -3.2327964305877686,
      "step": 8180
    },
    {
      "epoch": 1.4946619217081851,
      "grad_norm": 4.007624626159668,
      "learning_rate": 5.640668012479355e-05,
      "logits/chosen": -0.7164275050163269,
      "logits/rejected": -0.5638670325279236,
      "logps/chosen": -156.89260864257812,
      "logps/rejected": -147.63125610351562,
      "loss": 0.4235,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3997142314910889,
      "rewards/margins": 1.5136520862579346,
      "rewards/rejected": -2.9133663177490234,
      "step": 8190
    },
    {
      "epoch": 1.4964869057395749,
      "grad_norm": 2.7354209423065186,
      "learning_rate": 5.6377316938887873e-05,
      "logits/chosen": -0.770971417427063,
      "logits/rejected": -0.6637798547744751,
      "logps/chosen": -159.7659912109375,
      "logps/rejected": -162.7552032470703,
      "loss": 0.3683,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.0084939002990723,
      "rewards/margins": 1.7873601913452148,
      "rewards/rejected": -3.795854091644287,
      "step": 8200
    },
    {
      "epoch": 1.4983118897709646,
      "grad_norm": 2.1153957843780518,
      "learning_rate": 5.63479537529822e-05,
      "logits/chosen": -0.8049808740615845,
      "logits/rejected": -0.6509476900100708,
      "logps/chosen": -174.21275329589844,
      "logps/rejected": -146.25259399414062,
      "loss": 0.3672,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8248050212860107,
      "rewards/margins": 1.8973203897476196,
      "rewards/rejected": -3.72212553024292,
      "step": 8210
    },
    {
      "epoch": 1.5001368738023544,
      "grad_norm": 2.29422926902771,
      "learning_rate": 5.6318590567076536e-05,
      "logits/chosen": -0.7397888898849487,
      "logits/rejected": -0.6261367201805115,
      "logps/chosen": -160.66094970703125,
      "logps/rejected": -169.04519653320312,
      "loss": 0.3385,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.2916369438171387,
      "rewards/margins": 1.915273666381836,
      "rewards/rejected": -4.206911087036133,
      "step": 8220
    },
    {
      "epoch": 1.501961857833744,
      "grad_norm": 3.5283913612365723,
      "learning_rate": 5.628922738117086e-05,
      "logits/chosen": -0.8040685653686523,
      "logits/rejected": -0.7358130216598511,
      "logps/chosen": -151.0899200439453,
      "logps/rejected": -160.62228393554688,
      "loss": 0.5441,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.258174419403076,
      "rewards/margins": 1.167637586593628,
      "rewards/rejected": -3.425811767578125,
      "step": 8230
    },
    {
      "epoch": 1.5037868418651337,
      "grad_norm": 6.359671115875244,
      "learning_rate": 5.625986419526519e-05,
      "logits/chosen": -0.7621361017227173,
      "logits/rejected": -0.640910267829895,
      "logps/chosen": -158.47354125976562,
      "logps/rejected": -164.71774291992188,
      "loss": 0.495,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.959320068359375,
      "rewards/margins": 1.643035650253296,
      "rewards/rejected": -3.602355480194092,
      "step": 8240
    },
    {
      "epoch": 1.5056118258965234,
      "grad_norm": 2.4391703605651855,
      "learning_rate": 5.623050100935952e-05,
      "logits/chosen": -0.7440823316574097,
      "logits/rejected": -0.596487283706665,
      "logps/chosen": -160.03659057617188,
      "logps/rejected": -170.19772338867188,
      "loss": 0.3595,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7964756488800049,
      "rewards/margins": 1.9315776824951172,
      "rewards/rejected": -3.728053569793701,
      "step": 8250
    },
    {
      "epoch": 1.5074368099279132,
      "grad_norm": 3.515772819519043,
      "learning_rate": 5.6201137823453855e-05,
      "logits/chosen": -0.7363412976264954,
      "logits/rejected": -0.6134968400001526,
      "logps/chosen": -157.62838745117188,
      "logps/rejected": -170.1610107421875,
      "loss": 0.449,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.032651424407959,
      "rewards/margins": 1.7212082147598267,
      "rewards/rejected": -3.753859758377075,
      "step": 8260
    },
    {
      "epoch": 1.5092617939593027,
      "grad_norm": 4.602713584899902,
      "learning_rate": 5.617177463754818e-05,
      "logits/chosen": -0.8177179098129272,
      "logits/rejected": -0.8161761164665222,
      "logps/chosen": -183.4900665283203,
      "logps/rejected": -195.72669982910156,
      "loss": 0.6231,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.364417552947998,
      "rewards/margins": 1.287501573562622,
      "rewards/rejected": -3.65191912651062,
      "step": 8270
    },
    {
      "epoch": 1.5110867779906925,
      "grad_norm": 3.788872480392456,
      "learning_rate": 5.6142411451642504e-05,
      "logits/chosen": -0.6318415403366089,
      "logits/rejected": -0.5909072756767273,
      "logps/chosen": -157.84597778320312,
      "logps/rejected": -170.2560272216797,
      "loss": 0.5652,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.259765148162842,
      "rewards/margins": 1.0709956884384155,
      "rewards/rejected": -3.330760955810547,
      "step": 8280
    },
    {
      "epoch": 1.5129117620220822,
      "grad_norm": 3.79410457611084,
      "learning_rate": 5.6113048265736835e-05,
      "logits/chosen": -0.6502240896224976,
      "logits/rejected": -0.46501603722572327,
      "logps/chosen": -177.00711059570312,
      "logps/rejected": -169.47952270507812,
      "loss": 0.3862,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.103043794631958,
      "rewards/margins": 1.6700397729873657,
      "rewards/rejected": -3.773083448410034,
      "step": 8290
    },
    {
      "epoch": 1.514736746053472,
      "grad_norm": 3.6047191619873047,
      "learning_rate": 5.608368507983117e-05,
      "logits/chosen": -0.7956193089485168,
      "logits/rejected": -0.6896752119064331,
      "logps/chosen": -172.33106994628906,
      "logps/rejected": -168.46343994140625,
      "loss": 0.4996,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.0295016765594482,
      "rewards/margins": 1.2357804775238037,
      "rewards/rejected": -3.265282392501831,
      "step": 8300
    },
    {
      "epoch": 1.5165617300848617,
      "grad_norm": 5.112574577331543,
      "learning_rate": 5.60543218939255e-05,
      "logits/chosen": -0.7085318565368652,
      "logits/rejected": -0.5271984338760376,
      "logps/chosen": -180.25421142578125,
      "logps/rejected": -162.79421997070312,
      "loss": 0.494,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.0540664196014404,
      "rewards/margins": 1.3652160167694092,
      "rewards/rejected": -3.4192821979522705,
      "step": 8310
    },
    {
      "epoch": 1.5183867141162515,
      "grad_norm": 6.543447017669678,
      "learning_rate": 5.602495870801982e-05,
      "logits/chosen": -0.7456539869308472,
      "logits/rejected": -0.6387985944747925,
      "logps/chosen": -166.0206756591797,
      "logps/rejected": -169.77999877929688,
      "loss": 0.4784,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.2930827140808105,
      "rewards/margins": 1.3270578384399414,
      "rewards/rejected": -3.620140552520752,
      "step": 8320
    },
    {
      "epoch": 1.5202116981476412,
      "grad_norm": 6.25576114654541,
      "learning_rate": 5.599559552211415e-05,
      "logits/chosen": -0.8145977258682251,
      "logits/rejected": -0.5930917859077454,
      "logps/chosen": -162.89523315429688,
      "logps/rejected": -148.52040100097656,
      "loss": 0.4141,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9051721096038818,
      "rewards/margins": 1.6225240230560303,
      "rewards/rejected": -3.5276966094970703,
      "step": 8330
    },
    {
      "epoch": 1.522036682179031,
      "grad_norm": 5.607640743255615,
      "learning_rate": 5.5966232336208485e-05,
      "logits/chosen": -0.8488187789916992,
      "logits/rejected": -0.7579963207244873,
      "logps/chosen": -153.64541625976562,
      "logps/rejected": -160.17129516601562,
      "loss": 0.4274,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.267090082168579,
      "rewards/margins": 1.6332874298095703,
      "rewards/rejected": -2.9003772735595703,
      "step": 8340
    },
    {
      "epoch": 1.5238616662104207,
      "grad_norm": 3.8877809047698975,
      "learning_rate": 5.593686915030281e-05,
      "logits/chosen": -0.8427473306655884,
      "logits/rejected": -0.7718321084976196,
      "logps/chosen": -160.35777282714844,
      "logps/rejected": -158.32217407226562,
      "loss": 0.504,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4316703081130981,
      "rewards/margins": 1.5055482387542725,
      "rewards/rejected": -2.937218189239502,
      "step": 8350
    },
    {
      "epoch": 1.5256866502418105,
      "grad_norm": 3.7736997604370117,
      "learning_rate": 5.590750596439714e-05,
      "logits/chosen": -0.8525239825248718,
      "logits/rejected": -0.7396212220191956,
      "logps/chosen": -161.19137573242188,
      "logps/rejected": -170.91746520996094,
      "loss": 0.3815,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4460468292236328,
      "rewards/margins": 1.80154287815094,
      "rewards/rejected": -3.247589588165283,
      "step": 8360
    },
    {
      "epoch": 1.5275116342732002,
      "grad_norm": 3.876539945602417,
      "learning_rate": 5.5878142778491466e-05,
      "logits/chosen": -0.7722451686859131,
      "logits/rejected": -0.6881936192512512,
      "logps/chosen": -163.72128295898438,
      "logps/rejected": -159.7679443359375,
      "loss": 0.4017,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5108387470245361,
      "rewards/margins": 1.4733526706695557,
      "rewards/rejected": -2.984191656112671,
      "step": 8370
    },
    {
      "epoch": 1.52933661830459,
      "grad_norm": 3.6541242599487305,
      "learning_rate": 5.5848779592585804e-05,
      "logits/chosen": -0.8120943307876587,
      "logits/rejected": -0.7580727934837341,
      "logps/chosen": -154.88685607910156,
      "logps/rejected": -169.0078887939453,
      "loss": 0.511,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6864416599273682,
      "rewards/margins": 1.3696768283843994,
      "rewards/rejected": -3.0561182498931885,
      "step": 8380
    },
    {
      "epoch": 1.5311616023359795,
      "grad_norm": 4.9235100746154785,
      "learning_rate": 5.581941640668013e-05,
      "logits/chosen": -0.9712046384811401,
      "logits/rejected": -0.8726472854614258,
      "logps/chosen": -175.32884216308594,
      "logps/rejected": -162.88815307617188,
      "loss": 0.4607,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7497546672821045,
      "rewards/margins": 1.3259437084197998,
      "rewards/rejected": -3.0756983757019043,
      "step": 8390
    },
    {
      "epoch": 1.5329865863673693,
      "grad_norm": 4.896070957183838,
      "learning_rate": 5.579005322077445e-05,
      "logits/chosen": -0.8881241083145142,
      "logits/rejected": -0.8799735903739929,
      "logps/chosen": -153.92015075683594,
      "logps/rejected": -167.50189208984375,
      "loss": 0.4768,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.954240083694458,
      "rewards/margins": 1.2456573247909546,
      "rewards/rejected": -3.199897289276123,
      "step": 8400
    },
    {
      "epoch": 1.534811570398759,
      "grad_norm": 2.645833969116211,
      "learning_rate": 5.576069003486879e-05,
      "logits/chosen": -0.8696613311767578,
      "logits/rejected": -0.6985686421394348,
      "logps/chosen": -173.84686279296875,
      "logps/rejected": -140.86834716796875,
      "loss": 0.4124,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.2692314386367798,
      "rewards/margins": 1.4254173040390015,
      "rewards/rejected": -2.6946487426757812,
      "step": 8410
    },
    {
      "epoch": 1.5366365544301486,
      "grad_norm": 2.7241733074188232,
      "learning_rate": 5.5731326848963116e-05,
      "logits/chosen": -0.7493292689323425,
      "logits/rejected": -0.636459469795227,
      "logps/chosen": -151.0874786376953,
      "logps/rejected": -154.19384765625,
      "loss": 0.3875,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5820728540420532,
      "rewards/margins": 1.5961220264434814,
      "rewards/rejected": -3.178194761276245,
      "step": 8420
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 3.4565131664276123,
      "learning_rate": 5.570196366305745e-05,
      "logits/chosen": -0.7568687200546265,
      "logits/rejected": -0.6679677963256836,
      "logps/chosen": -177.99081420898438,
      "logps/rejected": -184.46804809570312,
      "loss": 0.4337,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8059301376342773,
      "rewards/margins": 1.6014608144760132,
      "rewards/rejected": -3.407391309738159,
      "step": 8430
    },
    {
      "epoch": 1.540286522492928,
      "grad_norm": 6.548091888427734,
      "learning_rate": 5.567260047715177e-05,
      "logits/chosen": -0.9145206212997437,
      "logits/rejected": -0.7334659695625305,
      "logps/chosen": -178.7244110107422,
      "logps/rejected": -156.55722045898438,
      "loss": 0.4873,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5489447116851807,
      "rewards/margins": 1.2999781370162964,
      "rewards/rejected": -2.8489232063293457,
      "step": 8440
    },
    {
      "epoch": 1.5421115065243178,
      "grad_norm": 2.7047643661499023,
      "learning_rate": 5.564323729124611e-05,
      "logits/chosen": -0.7123521566390991,
      "logits/rejected": -0.5203863978385925,
      "logps/chosen": -174.40029907226562,
      "logps/rejected": -150.21009826660156,
      "loss": 0.515,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7918899059295654,
      "rewards/margins": 1.3287023305892944,
      "rewards/rejected": -3.1205921173095703,
      "step": 8450
    },
    {
      "epoch": 1.5439364905557076,
      "grad_norm": 3.221609115600586,
      "learning_rate": 5.5613874105340434e-05,
      "logits/chosen": -0.6907220482826233,
      "logits/rejected": -0.4851014018058777,
      "logps/chosen": -182.3730010986328,
      "logps/rejected": -152.77005004882812,
      "loss": 0.4544,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8921194076538086,
      "rewards/margins": 1.4896687269210815,
      "rewards/rejected": -3.3817877769470215,
      "step": 8460
    },
    {
      "epoch": 1.5457614745870973,
      "grad_norm": 3.6379199028015137,
      "learning_rate": 5.558451091943476e-05,
      "logits/chosen": -0.7091361284255981,
      "logits/rejected": -0.5308017134666443,
      "logps/chosen": -154.07260131835938,
      "logps/rejected": -155.6608428955078,
      "loss": 0.37,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.1257903575897217,
      "rewards/margins": 1.4737722873687744,
      "rewards/rejected": -3.599562406539917,
      "step": 8470
    },
    {
      "epoch": 1.547586458618487,
      "grad_norm": 2.9693422317504883,
      "learning_rate": 5.555514773352909e-05,
      "logits/chosen": -0.788420557975769,
      "logits/rejected": -0.5842230319976807,
      "logps/chosen": -170.61036682128906,
      "logps/rejected": -153.85385131835938,
      "loss": 0.4276,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4887458086013794,
      "rewards/margins": 1.7851037979125977,
      "rewards/rejected": -3.2738494873046875,
      "step": 8480
    },
    {
      "epoch": 1.5494114426498768,
      "grad_norm": 3.0249993801116943,
      "learning_rate": 5.552578454762342e-05,
      "logits/chosen": -0.732503354549408,
      "logits/rejected": -0.591598391532898,
      "logps/chosen": -158.4365692138672,
      "logps/rejected": -147.5429229736328,
      "loss": 0.544,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8041203022003174,
      "rewards/margins": 1.2406522035598755,
      "rewards/rejected": -3.0447723865509033,
      "step": 8490
    },
    {
      "epoch": 1.5512364266812666,
      "grad_norm": 2.132411479949951,
      "learning_rate": 5.549642136171775e-05,
      "logits/chosen": -0.7506055235862732,
      "logits/rejected": -0.6200000047683716,
      "logps/chosen": -170.4293212890625,
      "logps/rejected": -156.5737762451172,
      "loss": 0.5475,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.3475375175476074,
      "rewards/margins": 0.9729146957397461,
      "rewards/rejected": -3.3204522132873535,
      "step": 8500
    },
    {
      "epoch": 1.5530614107126564,
      "grad_norm": 2.442931890487671,
      "learning_rate": 5.546705817581208e-05,
      "logits/chosen": -0.6894310712814331,
      "logits/rejected": -0.5753330588340759,
      "logps/chosen": -159.34115600585938,
      "logps/rejected": -167.90541076660156,
      "loss": 0.3798,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.182309627532959,
      "rewards/margins": 1.4648464918136597,
      "rewards/rejected": -3.6471564769744873,
      "step": 8510
    },
    {
      "epoch": 1.554886394744046,
      "grad_norm": 1.949755311012268,
      "learning_rate": 5.54376949899064e-05,
      "logits/chosen": -0.7534153461456299,
      "logits/rejected": -0.6012445688247681,
      "logps/chosen": -172.9136962890625,
      "logps/rejected": -158.60281372070312,
      "loss": 0.5281,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8954130411148071,
      "rewards/margins": 1.2659740447998047,
      "rewards/rejected": -3.1613869667053223,
      "step": 8520
    },
    {
      "epoch": 1.5567113787754359,
      "grad_norm": 2.5035324096679688,
      "learning_rate": 5.540833180400074e-05,
      "logits/chosen": -0.7007793188095093,
      "logits/rejected": -0.6226032972335815,
      "logps/chosen": -163.95724487304688,
      "logps/rejected": -186.66709899902344,
      "loss": 0.4365,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9884376525878906,
      "rewards/margins": 1.5517480373382568,
      "rewards/rejected": -3.5401859283447266,
      "step": 8530
    },
    {
      "epoch": 1.5585363628068254,
      "grad_norm": 2.0225532054901123,
      "learning_rate": 5.5378968618095065e-05,
      "logits/chosen": -0.7365349531173706,
      "logits/rejected": -0.5888396501541138,
      "logps/chosen": -164.00363159179688,
      "logps/rejected": -155.35183715820312,
      "loss": 0.3154,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6466048955917358,
      "rewards/margins": 1.8909868001937866,
      "rewards/rejected": -3.5375914573669434,
      "step": 8540
    },
    {
      "epoch": 1.5603613468382151,
      "grad_norm": 3.212770700454712,
      "learning_rate": 5.5349605432189396e-05,
      "logits/chosen": -0.7051973342895508,
      "logits/rejected": -0.4834120273590088,
      "logps/chosen": -176.18832397460938,
      "logps/rejected": -162.1681671142578,
      "loss": 0.4971,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7804906368255615,
      "rewards/margins": 1.448133945465088,
      "rewards/rejected": -3.2286248207092285,
      "step": 8550
    },
    {
      "epoch": 1.562186330869605,
      "grad_norm": 5.863872528076172,
      "learning_rate": 5.532024224628373e-05,
      "logits/chosen": -0.689002513885498,
      "logits/rejected": -0.5447074770927429,
      "logps/chosen": -164.55850219726562,
      "logps/rejected": -154.22999572753906,
      "loss": 0.4358,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7125682830810547,
      "rewards/margins": 1.397350788116455,
      "rewards/rejected": -3.1099190711975098,
      "step": 8560
    },
    {
      "epoch": 1.5640113149009947,
      "grad_norm": 4.318201541900635,
      "learning_rate": 5.529087906037806e-05,
      "logits/chosen": -0.7122108340263367,
      "logits/rejected": -0.5961578488349915,
      "logps/chosen": -164.82949829101562,
      "logps/rejected": -166.3362579345703,
      "loss": 0.4394,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3466600179672241,
      "rewards/margins": 1.5835282802581787,
      "rewards/rejected": -2.9301884174346924,
      "step": 8570
    },
    {
      "epoch": 1.5658362989323842,
      "grad_norm": 4.583192348480225,
      "learning_rate": 5.5261515874472383e-05,
      "logits/chosen": -0.7507892847061157,
      "logits/rejected": -0.6502711176872253,
      "logps/chosen": -149.19009399414062,
      "logps/rejected": -158.07069396972656,
      "loss": 0.4139,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.5234289169311523,
      "rewards/margins": 1.467356562614441,
      "rewards/rejected": -2.990785837173462,
      "step": 8580
    },
    {
      "epoch": 1.567661282963774,
      "grad_norm": 5.245556354522705,
      "learning_rate": 5.523215268856671e-05,
      "logits/chosen": -0.8033668398857117,
      "logits/rejected": -0.6222624182701111,
      "logps/chosen": -164.38812255859375,
      "logps/rejected": -151.69288635253906,
      "loss": 0.494,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.912274956703186,
      "rewards/margins": 1.5428059101104736,
      "rewards/rejected": -3.45508074760437,
      "step": 8590
    },
    {
      "epoch": 1.5694862669951637,
      "grad_norm": 3.2593600749969482,
      "learning_rate": 5.5202789502661046e-05,
      "logits/chosen": -0.7490991950035095,
      "logits/rejected": -0.6864482760429382,
      "logps/chosen": -140.5825653076172,
      "logps/rejected": -143.4306182861328,
      "loss": 0.5854,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.759293556213379,
      "rewards/margins": 1.0733979940414429,
      "rewards/rejected": -2.8326916694641113,
      "step": 8600
    },
    {
      "epoch": 1.5713112510265534,
      "grad_norm": 3.1681020259857178,
      "learning_rate": 5.517342631675537e-05,
      "logits/chosen": -0.7398751974105835,
      "logits/rejected": -0.6571977138519287,
      "logps/chosen": -158.56956481933594,
      "logps/rejected": -167.58734130859375,
      "loss": 0.4732,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2407199144363403,
      "rewards/margins": 1.4625377655029297,
      "rewards/rejected": -2.7032573223114014,
      "step": 8610
    },
    {
      "epoch": 1.5731362350579432,
      "grad_norm": 3.1866164207458496,
      "learning_rate": 5.51440631308497e-05,
      "logits/chosen": -0.7311409711837769,
      "logits/rejected": -0.6130319833755493,
      "logps/chosen": -154.4145050048828,
      "logps/rejected": -156.1685333251953,
      "loss": 0.4578,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5683834552764893,
      "rewards/margins": 1.31626296043396,
      "rewards/rejected": -2.884646415710449,
      "step": 8620
    },
    {
      "epoch": 1.574961219089333,
      "grad_norm": 3.659130096435547,
      "learning_rate": 5.511469994494403e-05,
      "logits/chosen": -0.7547529935836792,
      "logits/rejected": -0.6610623002052307,
      "logps/chosen": -152.02200317382812,
      "logps/rejected": -158.06930541992188,
      "loss": 0.3664,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7236963510513306,
      "rewards/margins": 1.4934786558151245,
      "rewards/rejected": -3.217175006866455,
      "step": 8630
    },
    {
      "epoch": 1.5767862031207227,
      "grad_norm": 6.532323360443115,
      "learning_rate": 5.5085336759038365e-05,
      "logits/chosen": -0.7602704167366028,
      "logits/rejected": -0.623526930809021,
      "logps/chosen": -167.05999755859375,
      "logps/rejected": -168.49838256835938,
      "loss": 0.4424,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.2379465103149414,
      "rewards/margins": 1.5802503824234009,
      "rewards/rejected": -3.8181967735290527,
      "step": 8640
    },
    {
      "epoch": 1.5786111871521125,
      "grad_norm": 1.2994496822357178,
      "learning_rate": 5.505597357313269e-05,
      "logits/chosen": -0.7030478715896606,
      "logits/rejected": -0.5757797956466675,
      "logps/chosen": -137.6416778564453,
      "logps/rejected": -146.0397186279297,
      "loss": 0.3613,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5414118766784668,
      "rewards/margins": 1.664101243019104,
      "rewards/rejected": -3.2055130004882812,
      "step": 8650
    },
    {
      "epoch": 1.5804361711835022,
      "grad_norm": 4.251623630523682,
      "learning_rate": 5.502661038722702e-05,
      "logits/chosen": -0.7886340618133545,
      "logits/rejected": -0.6236928701400757,
      "logps/chosen": -155.52206420898438,
      "logps/rejected": -142.6641082763672,
      "loss": 0.4888,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7027082443237305,
      "rewards/margins": 1.3645347356796265,
      "rewards/rejected": -3.0672428607940674,
      "step": 8660
    },
    {
      "epoch": 1.582261155214892,
      "grad_norm": 3.100524663925171,
      "learning_rate": 5.4997247201321345e-05,
      "logits/chosen": -0.7214373350143433,
      "logits/rejected": -0.5556591153144836,
      "logps/chosen": -151.66629028320312,
      "logps/rejected": -154.75936889648438,
      "loss": 0.4067,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.297882318496704,
      "rewards/margins": 1.836703896522522,
      "rewards/rejected": -3.1345863342285156,
      "step": 8670
    },
    {
      "epoch": 1.5840861392462817,
      "grad_norm": 3.3594892024993896,
      "learning_rate": 5.4967884015415683e-05,
      "logits/chosen": -0.7576358914375305,
      "logits/rejected": -0.6494555473327637,
      "logps/chosen": -148.09793090820312,
      "logps/rejected": -148.2765350341797,
      "loss": 0.4559,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8587509989738464,
      "rewards/margins": 1.695504903793335,
      "rewards/rejected": -2.554255723953247,
      "step": 8680
    },
    {
      "epoch": 1.5859111232776715,
      "grad_norm": 1.365256428718567,
      "learning_rate": 5.493852082951001e-05,
      "logits/chosen": -0.7660923004150391,
      "logits/rejected": -0.6508513689041138,
      "logps/chosen": -173.09188842773438,
      "logps/rejected": -165.1510772705078,
      "loss": 0.3795,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4136569499969482,
      "rewards/margins": 1.5408529043197632,
      "rewards/rejected": -2.954509735107422,
      "step": 8690
    },
    {
      "epoch": 1.587736107309061,
      "grad_norm": 3.898496389389038,
      "learning_rate": 5.490915764360433e-05,
      "logits/chosen": -0.7079988718032837,
      "logits/rejected": -0.5050624012947083,
      "logps/chosen": -158.39053344726562,
      "logps/rejected": -156.95236206054688,
      "loss": 0.3824,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.4225660562515259,
      "rewards/margins": 1.7589811086654663,
      "rewards/rejected": -3.1815476417541504,
      "step": 8700
    },
    {
      "epoch": 1.5895610913404508,
      "grad_norm": 3.8395743370056152,
      "learning_rate": 5.4879794457698664e-05,
      "logits/chosen": -0.7442148327827454,
      "logits/rejected": -0.6522220373153687,
      "logps/chosen": -161.04039001464844,
      "logps/rejected": -161.82579040527344,
      "loss": 0.5123,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3748183250427246,
      "rewards/margins": 1.0990570783615112,
      "rewards/rejected": -2.4738752841949463,
      "step": 8710
    },
    {
      "epoch": 1.5913860753718405,
      "grad_norm": 1.8676835298538208,
      "learning_rate": 5.4850431271792995e-05,
      "logits/chosen": -0.6877840161323547,
      "logits/rejected": -0.6282302141189575,
      "logps/chosen": -151.80645751953125,
      "logps/rejected": -155.71810913085938,
      "loss": 0.4074,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.486445665359497,
      "rewards/margins": 1.4357988834381104,
      "rewards/rejected": -2.9222443103790283,
      "step": 8720
    },
    {
      "epoch": 1.5932110594032303,
      "grad_norm": 5.223482608795166,
      "learning_rate": 5.482106808588733e-05,
      "logits/chosen": -0.8582056164741516,
      "logits/rejected": -0.7123206853866577,
      "logps/chosen": -166.15850830078125,
      "logps/rejected": -162.2378692626953,
      "loss": 0.4171,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.2708779573440552,
      "rewards/margins": 1.7262729406356812,
      "rewards/rejected": -2.9971511363983154,
      "step": 8730
    },
    {
      "epoch": 1.5950360434346198,
      "grad_norm": 3.16221284866333,
      "learning_rate": 5.479170489998165e-05,
      "logits/chosen": -0.7943257689476013,
      "logits/rejected": -0.6827279329299927,
      "logps/chosen": -161.64996337890625,
      "logps/rejected": -158.52232360839844,
      "loss": 0.5222,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6071058511734009,
      "rewards/margins": 1.4482448101043701,
      "rewards/rejected": -3.0553507804870605,
      "step": 8740
    },
    {
      "epoch": 1.5968610274660096,
      "grad_norm": 3.0476396083831787,
      "learning_rate": 5.476234171407599e-05,
      "logits/chosen": -0.8054792284965515,
      "logits/rejected": -0.5830670595169067,
      "logps/chosen": -186.91293334960938,
      "logps/rejected": -164.68359375,
      "loss": 0.4087,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.3355704545974731,
      "rewards/margins": 1.5444787740707397,
      "rewards/rejected": -2.880049467086792,
      "step": 8750
    },
    {
      "epoch": 1.5986860114973993,
      "grad_norm": 5.824613094329834,
      "learning_rate": 5.4732978528170314e-05,
      "logits/chosen": -0.6735326051712036,
      "logits/rejected": -0.6354929804801941,
      "logps/chosen": -153.56021118164062,
      "logps/rejected": -167.91946411132812,
      "loss": 0.4876,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7882254123687744,
      "rewards/margins": 1.1684565544128418,
      "rewards/rejected": -2.956681728363037,
      "step": 8760
    },
    {
      "epoch": 1.600510995528789,
      "grad_norm": 2.4449167251586914,
      "learning_rate": 5.470361534226464e-05,
      "logits/chosen": -0.6857126951217651,
      "logits/rejected": -0.5509170293807983,
      "logps/chosen": -164.68209838867188,
      "logps/rejected": -157.83053588867188,
      "loss": 0.4139,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5044713020324707,
      "rewards/margins": 1.2927906513214111,
      "rewards/rejected": -2.797262191772461,
      "step": 8770
    },
    {
      "epoch": 1.6023359795601788,
      "grad_norm": 4.1737260818481445,
      "learning_rate": 5.467425215635897e-05,
      "logits/chosen": -0.7665271162986755,
      "logits/rejected": -0.706112265586853,
      "logps/chosen": -150.4933624267578,
      "logps/rejected": -170.89894104003906,
      "loss": 0.415,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3374049663543701,
      "rewards/margins": 1.839240312576294,
      "rewards/rejected": -3.176645040512085,
      "step": 8780
    },
    {
      "epoch": 1.6041609635915686,
      "grad_norm": 4.467074871063232,
      "learning_rate": 5.46448889704533e-05,
      "logits/chosen": -0.8344370126724243,
      "logits/rejected": -0.7272748947143555,
      "logps/chosen": -143.59707641601562,
      "logps/rejected": -139.71237182617188,
      "loss": 0.4189,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7573137283325195,
      "rewards/margins": 1.4562783241271973,
      "rewards/rejected": -3.213592052459717,
      "step": 8790
    },
    {
      "epoch": 1.6059859476229583,
      "grad_norm": 3.491529941558838,
      "learning_rate": 5.461552578454763e-05,
      "logits/chosen": -0.8372023701667786,
      "logits/rejected": -0.7484207153320312,
      "logps/chosen": -161.65615844726562,
      "logps/rejected": -165.1872100830078,
      "loss": 0.3966,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.7090950012207031,
      "rewards/margins": 1.5477248430252075,
      "rewards/rejected": -3.2568199634552,
      "step": 8800
    },
    {
      "epoch": 1.607810931654348,
      "grad_norm": 2.1596004962921143,
      "learning_rate": 5.458616259864196e-05,
      "logits/chosen": -0.8102420568466187,
      "logits/rejected": -0.6543752551078796,
      "logps/chosen": -167.8916473388672,
      "logps/rejected": -163.60455322265625,
      "loss": 0.438,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4358537197113037,
      "rewards/margins": 1.6761882305145264,
      "rewards/rejected": -3.11204195022583,
      "step": 8810
    },
    {
      "epoch": 1.6096359156857378,
      "grad_norm": 5.136312484741211,
      "learning_rate": 5.455679941273628e-05,
      "logits/chosen": -0.7663372159004211,
      "logits/rejected": -0.6148306727409363,
      "logps/chosen": -152.7006378173828,
      "logps/rejected": -149.08499145507812,
      "loss": 0.4787,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0116982460021973,
      "rewards/margins": 1.4675204753875732,
      "rewards/rejected": -3.4792189598083496,
      "step": 8820
    },
    {
      "epoch": 1.6114608997171276,
      "grad_norm": 2.2828898429870605,
      "learning_rate": 5.453037254542118e-05,
      "logits/chosen": -0.6977453827857971,
      "logits/rejected": -0.5115978121757507,
      "logps/chosen": -154.54808044433594,
      "logps/rejected": -142.43907165527344,
      "loss": 0.3838,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8208221197128296,
      "rewards/margins": 1.695165991783142,
      "rewards/rejected": -3.5159878730773926,
      "step": 8830
    },
    {
      "epoch": 1.6132858837485173,
      "grad_norm": 2.469940185546875,
      "learning_rate": 5.4501009359515515e-05,
      "logits/chosen": -0.7712079286575317,
      "logits/rejected": -0.5763196349143982,
      "logps/chosen": -169.47789001464844,
      "logps/rejected": -162.6542510986328,
      "loss": 0.3133,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.449705958366394,
      "rewards/margins": 2.2477660179138184,
      "rewards/rejected": -3.6974716186523438,
      "step": 8840
    },
    {
      "epoch": 1.615110867779907,
      "grad_norm": 3.6073293685913086,
      "learning_rate": 5.447164617360984e-05,
      "logits/chosen": -0.7419239282608032,
      "logits/rejected": -0.6393232941627502,
      "logps/chosen": -146.0301971435547,
      "logps/rejected": -164.12844848632812,
      "loss": 0.4299,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5519922971725464,
      "rewards/margins": 2.0021958351135254,
      "rewards/rejected": -3.5541884899139404,
      "step": 8850
    },
    {
      "epoch": 1.6169358518112966,
      "grad_norm": 5.392892360687256,
      "learning_rate": 5.4442282987704164e-05,
      "logits/chosen": -0.746364951133728,
      "logits/rejected": -0.5154580473899841,
      "logps/chosen": -161.38050842285156,
      "logps/rejected": -151.62168884277344,
      "loss": 0.4056,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.5535427331924438,
      "rewards/margins": 1.8816286325454712,
      "rewards/rejected": -3.435171127319336,
      "step": 8860
    },
    {
      "epoch": 1.6187608358426864,
      "grad_norm": 5.243763446807861,
      "learning_rate": 5.44129198017985e-05,
      "logits/chosen": -0.6907976865768433,
      "logits/rejected": -0.597359299659729,
      "logps/chosen": -162.81637573242188,
      "logps/rejected": -180.6486358642578,
      "loss": 0.3976,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.6116701364517212,
      "rewards/margins": 1.5829312801361084,
      "rewards/rejected": -3.194601535797119,
      "step": 8870
    },
    {
      "epoch": 1.6205858198740761,
      "grad_norm": 6.074575901031494,
      "learning_rate": 5.4383556615892826e-05,
      "logits/chosen": -0.7262837290763855,
      "logits/rejected": -0.5853039622306824,
      "logps/chosen": -177.207275390625,
      "logps/rejected": -172.12484741210938,
      "loss": 0.3338,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7754371166229248,
      "rewards/margins": 1.9708127975463867,
      "rewards/rejected": -3.7462501525878906,
      "step": 8880
    },
    {
      "epoch": 1.6224108039054659,
      "grad_norm": 2.376641035079956,
      "learning_rate": 5.435419342998716e-05,
      "logits/chosen": -0.754433810710907,
      "logits/rejected": -0.5263136625289917,
      "logps/chosen": -158.84146118164062,
      "logps/rejected": -154.00723266601562,
      "loss": 0.3153,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5298457145690918,
      "rewards/margins": 2.075345516204834,
      "rewards/rejected": -3.6051909923553467,
      "step": 8890
    },
    {
      "epoch": 1.6242357879368554,
      "grad_norm": 6.421777248382568,
      "learning_rate": 5.432483024408148e-05,
      "logits/chosen": -0.7077679634094238,
      "logits/rejected": -0.6219953298568726,
      "logps/chosen": -164.2028350830078,
      "logps/rejected": -178.34323120117188,
      "loss": 0.5022,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.016810894012451,
      "rewards/margins": 2.0343146324157715,
      "rewards/rejected": -4.051126003265381,
      "step": 8900
    },
    {
      "epoch": 1.6260607719682452,
      "grad_norm": 3.8819963932037354,
      "learning_rate": 5.429546705817582e-05,
      "logits/chosen": -0.7278231978416443,
      "logits/rejected": -0.5413780808448792,
      "logps/chosen": -165.7674560546875,
      "logps/rejected": -163.04833984375,
      "loss": 0.2813,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8430655002593994,
      "rewards/margins": 2.2205309867858887,
      "rewards/rejected": -4.063595771789551,
      "step": 8910
    },
    {
      "epoch": 1.627885755999635,
      "grad_norm": 2.836336612701416,
      "learning_rate": 5.4266103872270145e-05,
      "logits/chosen": -0.8198927044868469,
      "logits/rejected": -0.7284419536590576,
      "logps/chosen": -149.31967163085938,
      "logps/rejected": -154.90687561035156,
      "loss": 0.4979,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7193429470062256,
      "rewards/margins": 1.6177222728729248,
      "rewards/rejected": -3.3370654582977295,
      "step": 8920
    },
    {
      "epoch": 1.6297107400310247,
      "grad_norm": 4.605287551879883,
      "learning_rate": 5.423674068636447e-05,
      "logits/chosen": -0.7387948036193848,
      "logits/rejected": -0.5369099974632263,
      "logps/chosen": -175.75289916992188,
      "logps/rejected": -169.56124877929688,
      "loss": 0.3585,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.65423583984375,
      "rewards/margins": 2.0965113639831543,
      "rewards/rejected": -3.7507472038269043,
      "step": 8930
    },
    {
      "epoch": 1.6315357240624144,
      "grad_norm": 2.656029462814331,
      "learning_rate": 5.42073775004588e-05,
      "logits/chosen": -0.7756011486053467,
      "logits/rejected": -0.5033277869224548,
      "logps/chosen": -166.81607055664062,
      "logps/rejected": -157.09921264648438,
      "loss": 0.2898,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8604485988616943,
      "rewards/margins": 2.170532464981079,
      "rewards/rejected": -4.030980587005615,
      "step": 8940
    },
    {
      "epoch": 1.6333607080938042,
      "grad_norm": 3.8482046127319336,
      "learning_rate": 5.417801431455313e-05,
      "logits/chosen": -0.7026586532592773,
      "logits/rejected": -0.5612009763717651,
      "logps/chosen": -155.40975952148438,
      "logps/rejected": -163.48556518554688,
      "loss": 0.5059,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7489469051361084,
      "rewards/margins": 1.7689749002456665,
      "rewards/rejected": -3.5179214477539062,
      "step": 8950
    },
    {
      "epoch": 1.635185692125194,
      "grad_norm": 2.0508601665496826,
      "learning_rate": 5.4148651128647464e-05,
      "logits/chosen": -0.7582114338874817,
      "logits/rejected": -0.6009660959243774,
      "logps/chosen": -173.91098022460938,
      "logps/rejected": -164.0534210205078,
      "loss": 0.3896,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7927392721176147,
      "rewards/margins": 1.8394405841827393,
      "rewards/rejected": -3.6321804523468018,
      "step": 8960
    },
    {
      "epoch": 1.6370106761565837,
      "grad_norm": 8.109673500061035,
      "learning_rate": 5.411928794274179e-05,
      "logits/chosen": -0.7518876194953918,
      "logits/rejected": -0.6229661703109741,
      "logps/chosen": -169.05328369140625,
      "logps/rejected": -171.02850341796875,
      "loss": 0.4869,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8691046237945557,
      "rewards/margins": 1.5375419855117798,
      "rewards/rejected": -3.406646251678467,
      "step": 8970
    },
    {
      "epoch": 1.6388356601879734,
      "grad_norm": 2.9091856479644775,
      "learning_rate": 5.4089924756836126e-05,
      "logits/chosen": -0.8665105700492859,
      "logits/rejected": -0.652216374874115,
      "logps/chosen": -169.39230346679688,
      "logps/rejected": -176.1182098388672,
      "loss": 0.4508,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6655933856964111,
      "rewards/margins": 1.6701101064682007,
      "rewards/rejected": -3.3357033729553223,
      "step": 8980
    },
    {
      "epoch": 1.6406606442193632,
      "grad_norm": 1.9392845630645752,
      "learning_rate": 5.406056157093045e-05,
      "logits/chosen": -0.8158400654792786,
      "logits/rejected": -0.6813217997550964,
      "logps/chosen": -142.7188262939453,
      "logps/rejected": -144.7447967529297,
      "loss": 0.5043,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.7102177143096924,
      "rewards/margins": 1.5160367488861084,
      "rewards/rejected": -3.2262542247772217,
      "step": 8990
    },
    {
      "epoch": 1.642485628250753,
      "grad_norm": 5.925378799438477,
      "learning_rate": 5.403119838502478e-05,
      "logits/chosen": -0.9157373309135437,
      "logits/rejected": -0.8115960359573364,
      "logps/chosen": -164.1044158935547,
      "logps/rejected": -167.60018920898438,
      "loss": 0.5163,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.0489282608032227,
      "rewards/margins": 1.342156171798706,
      "rewards/rejected": -3.3910841941833496,
      "step": 9000
    },
    {
      "epoch": 1.6443106122821425,
      "grad_norm": 3.4530012607574463,
      "learning_rate": 5.400183519911911e-05,
      "logits/chosen": -0.8590089678764343,
      "logits/rejected": -0.6570523381233215,
      "logps/chosen": -185.561767578125,
      "logps/rejected": -157.01571655273438,
      "loss": 0.3993,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9120210409164429,
      "rewards/margins": 1.4655423164367676,
      "rewards/rejected": -3.377562999725342,
      "step": 9010
    },
    {
      "epoch": 1.6461355963135322,
      "grad_norm": 2.4831275939941406,
      "learning_rate": 5.397247201321344e-05,
      "logits/chosen": -0.8665457963943481,
      "logits/rejected": -0.7388747930526733,
      "logps/chosen": -176.9500274658203,
      "logps/rejected": -165.14381408691406,
      "loss": 0.499,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7602918148040771,
      "rewards/margins": 1.0829746723175049,
      "rewards/rejected": -2.843266487121582,
      "step": 9020
    },
    {
      "epoch": 1.647960580344922,
      "grad_norm": 5.404387950897217,
      "learning_rate": 5.394310882730777e-05,
      "logits/chosen": -0.8349982500076294,
      "logits/rejected": -0.699905276298523,
      "logps/chosen": -166.8180389404297,
      "logps/rejected": -159.42701721191406,
      "loss": 0.403,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4760191440582275,
      "rewards/margins": 1.578608751296997,
      "rewards/rejected": -3.0546276569366455,
      "step": 9030
    },
    {
      "epoch": 1.6497855643763117,
      "grad_norm": 4.579071998596191,
      "learning_rate": 5.3913745641402094e-05,
      "logits/chosen": -0.7657942175865173,
      "logits/rejected": -0.596500039100647,
      "logps/chosen": -174.2603302001953,
      "logps/rejected": -164.2151336669922,
      "loss": 0.5245,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4353268146514893,
      "rewards/margins": 1.4292821884155273,
      "rewards/rejected": -2.8646087646484375,
      "step": 9040
    },
    {
      "epoch": 1.6516105484077013,
      "grad_norm": 5.073993682861328,
      "learning_rate": 5.3884382455496426e-05,
      "logits/chosen": -0.7285631895065308,
      "logits/rejected": -0.5435426831245422,
      "logps/chosen": -166.1300506591797,
      "logps/rejected": -147.89337158203125,
      "loss": 0.4567,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.6222755908966064,
      "rewards/margins": 1.3560689687728882,
      "rewards/rejected": -2.978344440460205,
      "step": 9050
    },
    {
      "epoch": 1.653435532439091,
      "grad_norm": 6.556577205657959,
      "learning_rate": 5.385501926959076e-05,
      "logits/chosen": -0.6077072024345398,
      "logits/rejected": -0.41848984360694885,
      "logps/chosen": -160.83914184570312,
      "logps/rejected": -148.49969482421875,
      "loss": 0.4443,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.9772526025772095,
      "rewards/margins": 1.5171688795089722,
      "rewards/rejected": -3.4944210052490234,
      "step": 9060
    },
    {
      "epoch": 1.6552605164704808,
      "grad_norm": 3.987921953201294,
      "learning_rate": 5.382565608368509e-05,
      "logits/chosen": -0.7149794697761536,
      "logits/rejected": -0.4305225908756256,
      "logps/chosen": -185.12380981445312,
      "logps/rejected": -162.60206604003906,
      "loss": 0.4746,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.0441606044769287,
      "rewards/margins": 1.551340103149414,
      "rewards/rejected": -3.595500946044922,
      "step": 9070
    },
    {
      "epoch": 1.6570855005018705,
      "grad_norm": 2.7670536041259766,
      "learning_rate": 5.379629289777941e-05,
      "logits/chosen": -0.6046667695045471,
      "logits/rejected": -0.4375367760658264,
      "logps/chosen": -165.38218688964844,
      "logps/rejected": -175.09097290039062,
      "loss": 0.3671,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.2187600135803223,
      "rewards/margins": 1.7947981357574463,
      "rewards/rejected": -4.0135579109191895,
      "step": 9080
    },
    {
      "epoch": 1.6589104845332603,
      "grad_norm": 4.485965251922607,
      "learning_rate": 5.376692971187374e-05,
      "logits/chosen": -0.6720690727233887,
      "logits/rejected": -0.5315279960632324,
      "logps/chosen": -174.62669372558594,
      "logps/rejected": -167.6746063232422,
      "loss": 0.5054,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.1500439643859863,
      "rewards/margins": 1.486013412475586,
      "rewards/rejected": -3.6360573768615723,
      "step": 9090
    },
    {
      "epoch": 1.66073546856465,
      "grad_norm": 4.009457588195801,
      "learning_rate": 5.3737566525968076e-05,
      "logits/chosen": -0.6367877721786499,
      "logits/rejected": -0.45117053389549255,
      "logps/chosen": -148.91259765625,
      "logps/rejected": -150.2353057861328,
      "loss": 0.3555,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.819738745689392,
      "rewards/margins": 1.782586693763733,
      "rewards/rejected": -3.602325439453125,
      "step": 9100
    },
    {
      "epoch": 1.6625604525960398,
      "grad_norm": 2.0254032611846924,
      "learning_rate": 5.37082033400624e-05,
      "logits/chosen": -0.6789895296096802,
      "logits/rejected": -0.5767074823379517,
      "logps/chosen": -158.08595275878906,
      "logps/rejected": -167.08157348632812,
      "loss": 0.4196,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.8354800939559937,
      "rewards/margins": 1.8134968280792236,
      "rewards/rejected": -3.6489768028259277,
      "step": 9110
    },
    {
      "epoch": 1.6643854366274295,
      "grad_norm": 2.580101728439331,
      "learning_rate": 5.367884015415673e-05,
      "logits/chosen": -0.644121527671814,
      "logits/rejected": -0.4671536087989807,
      "logps/chosen": -161.13125610351562,
      "logps/rejected": -168.7645721435547,
      "loss": 0.3478,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8727524280548096,
      "rewards/margins": 2.0736894607543945,
      "rewards/rejected": -3.946442127227783,
      "step": 9120
    },
    {
      "epoch": 1.6662104206588193,
      "grad_norm": 5.378569602966309,
      "learning_rate": 5.3649476968251056e-05,
      "logits/chosen": -0.7048455476760864,
      "logits/rejected": -0.5617445707321167,
      "logps/chosen": -173.4818115234375,
      "logps/rejected": -170.6681365966797,
      "loss": 0.5035,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.328739643096924,
      "rewards/margins": 1.5642030239105225,
      "rewards/rejected": -3.8929431438446045,
      "step": 9130
    },
    {
      "epoch": 1.668035404690209,
      "grad_norm": 2.862530469894409,
      "learning_rate": 5.3620113782345394e-05,
      "logits/chosen": -0.5136743783950806,
      "logits/rejected": -0.37908241152763367,
      "logps/chosen": -165.81005859375,
      "logps/rejected": -170.19229125976562,
      "loss": 0.4442,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.750227451324463,
      "rewards/margins": 1.5301121473312378,
      "rewards/rejected": -4.280339241027832,
      "step": 9140
    },
    {
      "epoch": 1.6698603887215988,
      "grad_norm": 4.412618160247803,
      "learning_rate": 5.359075059643972e-05,
      "logits/chosen": -0.5092862844467163,
      "logits/rejected": -0.37873977422714233,
      "logps/chosen": -179.58309936523438,
      "logps/rejected": -179.22409057617188,
      "loss": 0.5386,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.726357936859131,
      "rewards/margins": 1.277733325958252,
      "rewards/rejected": -4.004090785980225,
      "step": 9150
    },
    {
      "epoch": 1.6716853727529886,
      "grad_norm": 4.14938497543335,
      "learning_rate": 5.356138741053404e-05,
      "logits/chosen": -0.5635154843330383,
      "logits/rejected": -0.30771923065185547,
      "logps/chosen": -186.1726837158203,
      "logps/rejected": -163.4176483154297,
      "loss": 0.4545,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.0411276817321777,
      "rewards/margins": 1.3395181894302368,
      "rewards/rejected": -4.380645751953125,
      "step": 9160
    },
    {
      "epoch": 1.673510356784378,
      "grad_norm": 4.922418594360352,
      "learning_rate": 5.353202422462838e-05,
      "logits/chosen": -0.5297099947929382,
      "logits/rejected": -0.22886185348033905,
      "logps/chosen": -188.56121826171875,
      "logps/rejected": -163.9191131591797,
      "loss": 0.3847,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.471165657043457,
      "rewards/margins": 1.5721837282180786,
      "rewards/rejected": -4.043349266052246,
      "step": 9170
    },
    {
      "epoch": 1.6753353408157678,
      "grad_norm": 6.14599609375,
      "learning_rate": 5.3502661038722706e-05,
      "logits/chosen": -0.6398353576660156,
      "logits/rejected": -0.3845254182815552,
      "logps/chosen": -192.05039978027344,
      "logps/rejected": -173.8568572998047,
      "loss": 0.3869,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.1954867839813232,
      "rewards/margins": 1.8493086099624634,
      "rewards/rejected": -4.044795513153076,
      "step": 9180
    },
    {
      "epoch": 1.6771603248471576,
      "grad_norm": 3.1283183097839355,
      "learning_rate": 5.347329785281704e-05,
      "logits/chosen": -0.3796505331993103,
      "logits/rejected": -0.26502639055252075,
      "logps/chosen": -152.08204650878906,
      "logps/rejected": -158.3999481201172,
      "loss": 0.4566,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.0344738960266113,
      "rewards/margins": 1.6486791372299194,
      "rewards/rejected": -3.683152675628662,
      "step": 9190
    },
    {
      "epoch": 1.6789853088785474,
      "grad_norm": 6.468986511230469,
      "learning_rate": 5.344393466691136e-05,
      "logits/chosen": -0.49133405089378357,
      "logits/rejected": -0.2530744969844818,
      "logps/chosen": -153.88882446289062,
      "logps/rejected": -144.39768981933594,
      "loss": 0.3889,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.33345627784729,
      "rewards/margins": 1.5693260431289673,
      "rewards/rejected": -3.902782440185547,
      "step": 9200
    },
    {
      "epoch": 1.6808102929099369,
      "grad_norm": 4.237631797790527,
      "learning_rate": 5.34145714810057e-05,
      "logits/chosen": -0.5938333868980408,
      "logits/rejected": -0.5062910914421082,
      "logps/chosen": -145.10769653320312,
      "logps/rejected": -165.6722869873047,
      "loss": 0.4884,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9383022785186768,
      "rewards/margins": 1.8200862407684326,
      "rewards/rejected": -3.7583885192871094,
      "step": 9210
    },
    {
      "epoch": 1.6826352769413266,
      "grad_norm": 4.468080043792725,
      "learning_rate": 5.3385208295100025e-05,
      "logits/chosen": -0.6759947538375854,
      "logits/rejected": -0.5482823848724365,
      "logps/chosen": -154.1144256591797,
      "logps/rejected": -169.70431518554688,
      "loss": 0.4579,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9415690898895264,
      "rewards/margins": 1.6068172454833984,
      "rewards/rejected": -3.548386335372925,
      "step": 9220
    },
    {
      "epoch": 1.6844602609727164,
      "grad_norm": 2.356456756591797,
      "learning_rate": 5.335584510919435e-05,
      "logits/chosen": -0.7071202397346497,
      "logits/rejected": -0.5805263519287109,
      "logps/chosen": -154.35940551757812,
      "logps/rejected": -163.9297637939453,
      "loss": 0.3879,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.538339376449585,
      "rewards/margins": 1.6978709697723389,
      "rewards/rejected": -3.236210584640503,
      "step": 9230
    },
    {
      "epoch": 1.6862852450041061,
      "grad_norm": 4.293164253234863,
      "learning_rate": 5.332648192328868e-05,
      "logits/chosen": -0.6564167141914368,
      "logits/rejected": -0.5626581907272339,
      "logps/chosen": -156.94369506835938,
      "logps/rejected": -175.47462463378906,
      "loss": 0.4623,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8381166458129883,
      "rewards/margins": 1.7725508213043213,
      "rewards/rejected": -3.6106674671173096,
      "step": 9240
    },
    {
      "epoch": 1.688110229035496,
      "grad_norm": 6.153064727783203,
      "learning_rate": 5.329711873738301e-05,
      "logits/chosen": -0.7477336525917053,
      "logits/rejected": -0.5685438513755798,
      "logps/chosen": -172.66725158691406,
      "logps/rejected": -168.63754272460938,
      "loss": 0.3797,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.884330153465271,
      "rewards/margins": 1.7176717519760132,
      "rewards/rejected": -3.602001905441284,
      "step": 9250
    },
    {
      "epoch": 1.6899352130668857,
      "grad_norm": 2.377828359603882,
      "learning_rate": 5.326775555147734e-05,
      "logits/chosen": -0.675930380821228,
      "logits/rejected": -0.5658676624298096,
      "logps/chosen": -169.25320434570312,
      "logps/rejected": -164.367919921875,
      "loss": 0.5741,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.320995807647705,
      "rewards/margins": 1.2019994258880615,
      "rewards/rejected": -3.5229954719543457,
      "step": 9260
    },
    {
      "epoch": 1.6917601970982754,
      "grad_norm": 3.247249126434326,
      "learning_rate": 5.323839236557167e-05,
      "logits/chosen": -0.6956832408905029,
      "logits/rejected": -0.6010067462921143,
      "logps/chosen": -158.83023071289062,
      "logps/rejected": -172.81875610351562,
      "loss": 0.4404,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.1912808418273926,
      "rewards/margins": 1.616586446762085,
      "rewards/rejected": -3.8078670501708984,
      "step": 9270
    },
    {
      "epoch": 1.6935851811296652,
      "grad_norm": 3.4113001823425293,
      "learning_rate": 5.320902917966599e-05,
      "logits/chosen": -0.680406391620636,
      "logits/rejected": -0.538427472114563,
      "logps/chosen": -156.40933227539062,
      "logps/rejected": -157.13198852539062,
      "loss": 0.4137,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.2799763679504395,
      "rewards/margins": 1.504575252532959,
      "rewards/rejected": -3.7845516204833984,
      "step": 9280
    },
    {
      "epoch": 1.695410165161055,
      "grad_norm": 6.472352504730225,
      "learning_rate": 5.317966599376033e-05,
      "logits/chosen": -0.7087767720222473,
      "logits/rejected": -0.5122714042663574,
      "logps/chosen": -165.07020568847656,
      "logps/rejected": -159.23629760742188,
      "loss": 0.3779,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7134368419647217,
      "rewards/margins": 1.5821962356567383,
      "rewards/rejected": -3.295632839202881,
      "step": 9290
    },
    {
      "epoch": 1.6972351491924447,
      "grad_norm": 3.6596693992614746,
      "learning_rate": 5.3150302807854655e-05,
      "logits/chosen": -0.7261379957199097,
      "logits/rejected": -0.6331136226654053,
      "logps/chosen": -151.5318145751953,
      "logps/rejected": -156.35855102539062,
      "loss": 0.4637,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.636530876159668,
      "rewards/margins": 1.3602879047393799,
      "rewards/rejected": -2.996818780899048,
      "step": 9300
    },
    {
      "epoch": 1.6990601332238344,
      "grad_norm": 4.387225151062012,
      "learning_rate": 5.3120939621948986e-05,
      "logits/chosen": -0.6495432257652283,
      "logits/rejected": -0.5967971086502075,
      "logps/chosen": -165.3771514892578,
      "logps/rejected": -182.0154266357422,
      "loss": 0.2851,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.4152135848999023,
      "rewards/margins": 1.9142999649047852,
      "rewards/rejected": -3.3295135498046875,
      "step": 9310
    },
    {
      "epoch": 1.7008851172552242,
      "grad_norm": 4.997095584869385,
      "learning_rate": 5.309157643604332e-05,
      "logits/chosen": -0.8596266508102417,
      "logits/rejected": -0.6385084390640259,
      "logps/chosen": -168.7864990234375,
      "logps/rejected": -153.63584899902344,
      "loss": 0.371,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.482054352760315,
      "rewards/margins": 2.0326528549194336,
      "rewards/rejected": -3.514707088470459,
      "step": 9320
    },
    {
      "epoch": 1.7027101012866137,
      "grad_norm": 3.9004015922546387,
      "learning_rate": 5.306221325013765e-05,
      "logits/chosen": -0.8058316111564636,
      "logits/rejected": -0.5769909620285034,
      "logps/chosen": -166.89138793945312,
      "logps/rejected": -155.4854278564453,
      "loss": 0.452,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7322728633880615,
      "rewards/margins": 1.7862682342529297,
      "rewards/rejected": -3.5185413360595703,
      "step": 9330
    },
    {
      "epoch": 1.7045350853180035,
      "grad_norm": 4.245923042297363,
      "learning_rate": 5.3032850064231974e-05,
      "logits/chosen": -0.6988359689712524,
      "logits/rejected": -0.611104428768158,
      "logps/chosen": -167.30274963378906,
      "logps/rejected": -157.8892822265625,
      "loss": 0.5256,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.4295196533203125,
      "rewards/margins": 1.2266178131103516,
      "rewards/rejected": -3.6561379432678223,
      "step": 9340
    },
    {
      "epoch": 1.7063600693493932,
      "grad_norm": 5.57770299911499,
      "learning_rate": 5.30034868783263e-05,
      "logits/chosen": -0.8129757642745972,
      "logits/rejected": -0.7087060213088989,
      "logps/chosen": -159.70147705078125,
      "logps/rejected": -167.2619171142578,
      "loss": 0.4971,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.013434886932373,
      "rewards/margins": 1.3414853811264038,
      "rewards/rejected": -3.3549206256866455,
      "step": 9350
    },
    {
      "epoch": 1.708185053380783,
      "grad_norm": 3.1126670837402344,
      "learning_rate": 5.2974123692420636e-05,
      "logits/chosen": -0.8328245282173157,
      "logits/rejected": -0.6158806681632996,
      "logps/chosen": -182.48089599609375,
      "logps/rejected": -169.64169311523438,
      "loss": 0.5101,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.8412545919418335,
      "rewards/margins": 1.1257481575012207,
      "rewards/rejected": -2.9670028686523438,
      "step": 9360
    },
    {
      "epoch": 1.7100100374121725,
      "grad_norm": 4.526181221008301,
      "learning_rate": 5.294476050651496e-05,
      "logits/chosen": -0.8246287107467651,
      "logits/rejected": -0.6388654112815857,
      "logps/chosen": -158.9348602294922,
      "logps/rejected": -150.58602905273438,
      "loss": 0.3942,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.2183313369750977,
      "rewards/margins": 1.5622546672821045,
      "rewards/rejected": -2.780586004257202,
      "step": 9370
    },
    {
      "epoch": 1.7118350214435623,
      "grad_norm": 3.6991326808929443,
      "learning_rate": 5.291539732060929e-05,
      "logits/chosen": -0.7688473463058472,
      "logits/rejected": -0.5986037850379944,
      "logps/chosen": -151.9234161376953,
      "logps/rejected": -152.76205444335938,
      "loss": 0.4506,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.6090316772460938,
      "rewards/margins": 1.5792614221572876,
      "rewards/rejected": -3.188292980194092,
      "step": 9380
    },
    {
      "epoch": 1.713660005474952,
      "grad_norm": 5.998112201690674,
      "learning_rate": 5.288603413470362e-05,
      "logits/chosen": -0.7195872068405151,
      "logits/rejected": -0.4977957606315613,
      "logps/chosen": -172.81317138671875,
      "logps/rejected": -154.15719604492188,
      "loss": 0.4395,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.536117672920227,
      "rewards/margins": 1.5104048252105713,
      "rewards/rejected": -3.046522617340088,
      "step": 9390
    },
    {
      "epoch": 1.7154849895063418,
      "grad_norm": 3.7425625324249268,
      "learning_rate": 5.2856670948797955e-05,
      "logits/chosen": -0.7725022435188293,
      "logits/rejected": -0.67584627866745,
      "logps/chosen": -156.63906860351562,
      "logps/rejected": -164.39828491210938,
      "loss": 0.4521,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4531450271606445,
      "rewards/margins": 1.440096378326416,
      "rewards/rejected": -2.8932414054870605,
      "step": 9400
    },
    {
      "epoch": 1.7173099735377315,
      "grad_norm": 2.038104772567749,
      "learning_rate": 5.282730776289228e-05,
      "logits/chosen": -0.6876988410949707,
      "logits/rejected": -0.5276810526847839,
      "logps/chosen": -153.32620239257812,
      "logps/rejected": -140.88082885742188,
      "loss": 0.4466,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.511914849281311,
      "rewards/margins": 1.3883031606674194,
      "rewards/rejected": -2.9002177715301514,
      "step": 9410
    },
    {
      "epoch": 1.7191349575691213,
      "grad_norm": 2.9168670177459717,
      "learning_rate": 5.2797944576986604e-05,
      "logits/chosen": -0.7498071789741516,
      "logits/rejected": -0.6083294749259949,
      "logps/chosen": -168.13571166992188,
      "logps/rejected": -155.3182373046875,
      "loss": 0.4778,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.375107765197754,
      "rewards/margins": 1.4364930391311646,
      "rewards/rejected": -2.8116002082824707,
      "step": 9420
    },
    {
      "epoch": 1.720959941600511,
      "grad_norm": 4.08005952835083,
      "learning_rate": 5.2768581391080936e-05,
      "logits/chosen": -0.7271852493286133,
      "logits/rejected": -0.6350951194763184,
      "logps/chosen": -149.37684631347656,
      "logps/rejected": -160.0890350341797,
      "loss": 0.4177,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7026885747909546,
      "rewards/margins": 1.4817657470703125,
      "rewards/rejected": -3.1844544410705566,
      "step": 9430
    },
    {
      "epoch": 1.7227849256319008,
      "grad_norm": 3.36875581741333,
      "learning_rate": 5.273921820517527e-05,
      "logits/chosen": -0.7916982769966125,
      "logits/rejected": -0.6614004969596863,
      "logps/chosen": -152.09400939941406,
      "logps/rejected": -161.6115264892578,
      "loss": 0.522,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4247868061065674,
      "rewards/margins": 1.4041955471038818,
      "rewards/rejected": -2.8289825916290283,
      "step": 9440
    },
    {
      "epoch": 1.7246099096632905,
      "grad_norm": 2.299903154373169,
      "learning_rate": 5.27098550192696e-05,
      "logits/chosen": -0.7706027030944824,
      "logits/rejected": -0.6565459370613098,
      "logps/chosen": -158.30868530273438,
      "logps/rejected": -154.94961547851562,
      "loss": 0.4152,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0715339183807373,
      "rewards/margins": 1.323988914489746,
      "rewards/rejected": -2.3955228328704834,
      "step": 9450
    },
    {
      "epoch": 1.7264348936946803,
      "grad_norm": 5.123685836791992,
      "learning_rate": 5.268049183336392e-05,
      "logits/chosen": -0.7767300009727478,
      "logits/rejected": -0.6283906102180481,
      "logps/chosen": -147.5431365966797,
      "logps/rejected": -156.85025024414062,
      "loss": 0.4176,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.0480705499649048,
      "rewards/margins": 1.512332558631897,
      "rewards/rejected": -2.5604031085968018,
      "step": 9460
    },
    {
      "epoch": 1.72825987772607,
      "grad_norm": 7.074647903442383,
      "learning_rate": 5.265112864745825e-05,
      "logits/chosen": -0.8740046620368958,
      "logits/rejected": -0.7721131443977356,
      "logps/chosen": -139.7830810546875,
      "logps/rejected": -148.77066040039062,
      "loss": 0.3935,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0267724990844727,
      "rewards/margins": 1.6037476062774658,
      "rewards/rejected": -2.6305203437805176,
      "step": 9470
    },
    {
      "epoch": 1.7300848617574596,
      "grad_norm": 4.232585906982422,
      "learning_rate": 5.2621765461552586e-05,
      "logits/chosen": -0.7972810864448547,
      "logits/rejected": -0.6218938827514648,
      "logps/chosen": -153.36038208007812,
      "logps/rejected": -152.311767578125,
      "loss": 0.3954,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.2964756488800049,
      "rewards/margins": 1.69150710105896,
      "rewards/rejected": -2.987982749938965,
      "step": 9480
    },
    {
      "epoch": 1.7319098457888493,
      "grad_norm": 3.38895320892334,
      "learning_rate": 5.259240227564691e-05,
      "logits/chosen": -0.8031366467475891,
      "logits/rejected": -0.6158300638198853,
      "logps/chosen": -147.0954132080078,
      "logps/rejected": -137.49850463867188,
      "loss": 0.4137,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.9764227867126465,
      "rewards/margins": 1.6902412176132202,
      "rewards/rejected": -2.666663646697998,
      "step": 9490
    },
    {
      "epoch": 1.733734829820239,
      "grad_norm": 2.3947818279266357,
      "learning_rate": 5.256303908974124e-05,
      "logits/chosen": -0.734546959400177,
      "logits/rejected": -0.6397764682769775,
      "logps/chosen": -158.80929565429688,
      "logps/rejected": -168.34532165527344,
      "loss": 0.3661,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1913737058639526,
      "rewards/margins": 1.7799932956695557,
      "rewards/rejected": -2.971367359161377,
      "step": 9500
    },
    {
      "epoch": 1.7355598138516288,
      "grad_norm": 3.5746912956237793,
      "learning_rate": 5.253367590383557e-05,
      "logits/chosen": -0.7633213996887207,
      "logits/rejected": -0.594651460647583,
      "logps/chosen": -183.9090118408203,
      "logps/rejected": -167.57192993164062,
      "loss": 0.4243,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4029035568237305,
      "rewards/margins": 1.7794361114501953,
      "rewards/rejected": -3.182339906692505,
      "step": 9510
    },
    {
      "epoch": 1.7373847978830184,
      "grad_norm": 5.592887878417969,
      "learning_rate": 5.2504312717929904e-05,
      "logits/chosen": -0.7699569463729858,
      "logits/rejected": -0.635825514793396,
      "logps/chosen": -159.62509155273438,
      "logps/rejected": -156.1348419189453,
      "loss": 0.4883,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2290302515029907,
      "rewards/margins": 1.4921401739120483,
      "rewards/rejected": -2.721170663833618,
      "step": 9520
    },
    {
      "epoch": 1.7392097819144081,
      "grad_norm": 5.6912431716918945,
      "learning_rate": 5.247494953202423e-05,
      "logits/chosen": -0.7853401899337769,
      "logits/rejected": -0.6531379818916321,
      "logps/chosen": -182.27102661132812,
      "logps/rejected": -172.54067993164062,
      "loss": 0.5548,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9191423654556274,
      "rewards/margins": 1.3884477615356445,
      "rewards/rejected": -3.3075897693634033,
      "step": 9530
    },
    {
      "epoch": 1.7410347659457979,
      "grad_norm": 3.2073113918304443,
      "learning_rate": 5.244558634611855e-05,
      "logits/chosen": -0.7901981472969055,
      "logits/rejected": -0.6287926435470581,
      "logps/chosen": -153.484130859375,
      "logps/rejected": -151.95411682128906,
      "loss": 0.4514,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5250910520553589,
      "rewards/margins": 1.4675474166870117,
      "rewards/rejected": -2.992638111114502,
      "step": 9540
    },
    {
      "epoch": 1.7428597499771876,
      "grad_norm": 5.138407230377197,
      "learning_rate": 5.241622316021289e-05,
      "logits/chosen": -0.8106976747512817,
      "logits/rejected": -0.7323046922683716,
      "logps/chosen": -146.88809204101562,
      "logps/rejected": -160.6128387451172,
      "loss": 0.4876,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6985381841659546,
      "rewards/margins": 1.359069585800171,
      "rewards/rejected": -2.057607650756836,
      "step": 9550
    },
    {
      "epoch": 1.7446847340085774,
      "grad_norm": 2.931133985519409,
      "learning_rate": 5.2386859974307216e-05,
      "logits/chosen": -0.8827934265136719,
      "logits/rejected": -0.7025946974754333,
      "logps/chosen": -154.4095458984375,
      "logps/rejected": -139.84951782226562,
      "loss": 0.4178,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.401271104812622,
      "rewards/margins": 1.6430641412734985,
      "rewards/rejected": -3.044335126876831,
      "step": 9560
    },
    {
      "epoch": 1.7465097180399671,
      "grad_norm": 2.4556310176849365,
      "learning_rate": 5.235749678840155e-05,
      "logits/chosen": -0.8170748949050903,
      "logits/rejected": -0.6377414464950562,
      "logps/chosen": -169.69358825683594,
      "logps/rejected": -144.1219024658203,
      "loss": 0.5349,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0512018203735352,
      "rewards/margins": 1.235595703125,
      "rewards/rejected": -2.286797523498535,
      "step": 9570
    },
    {
      "epoch": 1.7483347020713569,
      "grad_norm": 4.0290117263793945,
      "learning_rate": 5.232813360249587e-05,
      "logits/chosen": -0.8361994028091431,
      "logits/rejected": -0.6689885258674622,
      "logps/chosen": -157.84613037109375,
      "logps/rejected": -142.22442626953125,
      "loss": 0.3939,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.8554846048355103,
      "rewards/margins": 1.6844373941421509,
      "rewards/rejected": -2.539921998977661,
      "step": 9580
    },
    {
      "epoch": 1.7501596861027466,
      "grad_norm": 4.653162002563477,
      "learning_rate": 5.229877041659021e-05,
      "logits/chosen": -0.8789536356925964,
      "logits/rejected": -0.6836637258529663,
      "logps/chosen": -163.21922302246094,
      "logps/rejected": -140.6446075439453,
      "loss": 0.4032,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8411914706230164,
      "rewards/margins": 1.7825927734375,
      "rewards/rejected": -2.6237845420837402,
      "step": 9590
    },
    {
      "epoch": 1.7519846701341364,
      "grad_norm": 2.9611268043518066,
      "learning_rate": 5.2269407230684535e-05,
      "logits/chosen": -0.9244953989982605,
      "logits/rejected": -0.7686169147491455,
      "logps/chosen": -147.68992614746094,
      "logps/rejected": -145.98141479492188,
      "loss": 0.4165,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.8728102445602417,
      "rewards/margins": 1.6520226001739502,
      "rewards/rejected": -2.5248324871063232,
      "step": 9600
    },
    {
      "epoch": 1.7538096541655261,
      "grad_norm": 4.376156806945801,
      "learning_rate": 5.224004404477886e-05,
      "logits/chosen": -0.850326418876648,
      "logits/rejected": -0.7396530508995056,
      "logps/chosen": -157.18630981445312,
      "logps/rejected": -154.05215454101562,
      "loss": 0.4868,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.3088291883468628,
      "rewards/margins": 1.2467823028564453,
      "rewards/rejected": -2.5556118488311768,
      "step": 9610
    },
    {
      "epoch": 1.755634638196916,
      "grad_norm": 3.1470935344696045,
      "learning_rate": 5.221068085887319e-05,
      "logits/chosen": -0.7154198288917542,
      "logits/rejected": -0.6202624440193176,
      "logps/chosen": -164.5823211669922,
      "logps/rejected": -168.11453247070312,
      "loss": 0.4964,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6283674240112305,
      "rewards/margins": 1.3458821773529053,
      "rewards/rejected": -2.974249839782715,
      "step": 9620
    },
    {
      "epoch": 1.7574596222283057,
      "grad_norm": 3.9983558654785156,
      "learning_rate": 5.218131767296752e-05,
      "logits/chosen": -0.7122269868850708,
      "logits/rejected": -0.619306743144989,
      "logps/chosen": -159.64390563964844,
      "logps/rejected": -173.51434326171875,
      "loss": 0.4847,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.1763949394226074,
      "rewards/margins": 1.4331005811691284,
      "rewards/rejected": -3.6094956398010254,
      "step": 9630
    },
    {
      "epoch": 1.7592846062596952,
      "grad_norm": 4.169983386993408,
      "learning_rate": 5.215195448706185e-05,
      "logits/chosen": -0.9329649806022644,
      "logits/rejected": -0.8169642686843872,
      "logps/chosen": -164.69808959960938,
      "logps/rejected": -161.73854064941406,
      "loss": 0.361,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.489345669746399,
      "rewards/margins": 1.729673147201538,
      "rewards/rejected": -3.2190184593200684,
      "step": 9640
    },
    {
      "epoch": 1.761109590291085,
      "grad_norm": 2.7720370292663574,
      "learning_rate": 5.212259130115618e-05,
      "logits/chosen": -0.7605909705162048,
      "logits/rejected": -0.6469212770462036,
      "logps/chosen": -153.86984252929688,
      "logps/rejected": -165.38131713867188,
      "loss": 0.4782,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0558016300201416,
      "rewards/margins": 1.5109965801239014,
      "rewards/rejected": -3.566798448562622,
      "step": 9650
    },
    {
      "epoch": 1.7629345743224747,
      "grad_norm": 5.094736576080322,
      "learning_rate": 5.20932281152505e-05,
      "logits/chosen": -0.8216455578804016,
      "logits/rejected": -0.66530442237854,
      "logps/chosen": -175.05252075195312,
      "logps/rejected": -176.66619873046875,
      "loss": 0.4608,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.0853841304779053,
      "rewards/margins": 1.603345274925232,
      "rewards/rejected": -3.688729763031006,
      "step": 9660
    },
    {
      "epoch": 1.7647595583538644,
      "grad_norm": 5.513991355895996,
      "learning_rate": 5.206386492934484e-05,
      "logits/chosen": -0.7741551995277405,
      "logits/rejected": -0.6612845063209534,
      "logps/chosen": -163.388916015625,
      "logps/rejected": -165.7245330810547,
      "loss": 0.4649,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.885549783706665,
      "rewards/margins": 1.2283700704574585,
      "rewards/rejected": -3.113919734954834,
      "step": 9670
    },
    {
      "epoch": 1.766584542385254,
      "grad_norm": 3.711638927459717,
      "learning_rate": 5.2034501743439165e-05,
      "logits/chosen": -0.8573988080024719,
      "logits/rejected": -0.7152446508407593,
      "logps/chosen": -155.66390991210938,
      "logps/rejected": -161.61361694335938,
      "loss": 0.4288,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.107913017272949,
      "rewards/margins": 1.6079782247543335,
      "rewards/rejected": -3.7158913612365723,
      "step": 9680
    },
    {
      "epoch": 1.7684095264166437,
      "grad_norm": 7.696120738983154,
      "learning_rate": 5.2005138557533496e-05,
      "logits/chosen": -0.7681593298912048,
      "logits/rejected": -0.6588089466094971,
      "logps/chosen": -165.73741149902344,
      "logps/rejected": -162.19100952148438,
      "loss": 0.556,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.4078752994537354,
      "rewards/margins": 1.3605962991714478,
      "rewards/rejected": -3.7684712409973145,
      "step": 9690
    },
    {
      "epoch": 1.7702345104480335,
      "grad_norm": 2.586554527282715,
      "learning_rate": 5.197577537162783e-05,
      "logits/chosen": -0.7260798811912537,
      "logits/rejected": -0.5221675634384155,
      "logps/chosen": -173.131591796875,
      "logps/rejected": -152.0140380859375,
      "loss": 0.4352,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.601097822189331,
      "rewards/margins": 1.3314262628555298,
      "rewards/rejected": -3.9325242042541504,
      "step": 9700
    },
    {
      "epoch": 1.7720594944794232,
      "grad_norm": 4.263115406036377,
      "learning_rate": 5.194641218572216e-05,
      "logits/chosen": -0.6705259680747986,
      "logits/rejected": -0.5810501575469971,
      "logps/chosen": -175.00039672851562,
      "logps/rejected": -173.36668395996094,
      "loss": 0.4515,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.4315686225891113,
      "rewards/margins": 1.3556653261184692,
      "rewards/rejected": -3.78723406791687,
      "step": 9710
    },
    {
      "epoch": 1.773884478510813,
      "grad_norm": 1.9449462890625,
      "learning_rate": 5.1917048999816484e-05,
      "logits/chosen": -0.8372136950492859,
      "logits/rejected": -0.7149425148963928,
      "logps/chosen": -166.84854125976562,
      "logps/rejected": -175.46070861816406,
      "loss": 0.4552,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8603641986846924,
      "rewards/margins": 1.623059868812561,
      "rewards/rejected": -3.4834237098693848,
      "step": 9720
    },
    {
      "epoch": 1.7757094625422027,
      "grad_norm": 1.5735969543457031,
      "learning_rate": 5.188768581391081e-05,
      "logits/chosen": -0.7091313600540161,
      "logits/rejected": -0.6311138868331909,
      "logps/chosen": -161.4400177001953,
      "logps/rejected": -173.63998413085938,
      "loss": 0.565,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.4913878440856934,
      "rewards/margins": 1.2523102760314941,
      "rewards/rejected": -3.7436976432800293,
      "step": 9730
    },
    {
      "epoch": 1.7775344465735925,
      "grad_norm": 5.815669536590576,
      "learning_rate": 5.1858322628005146e-05,
      "logits/chosen": -0.7043816447257996,
      "logits/rejected": -0.5840823650360107,
      "logps/chosen": -165.83767700195312,
      "logps/rejected": -173.48733520507812,
      "loss": 0.4976,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.2953202724456787,
      "rewards/margins": 1.4118198156356812,
      "rewards/rejected": -3.7071404457092285,
      "step": 9740
    },
    {
      "epoch": 1.7793594306049823,
      "grad_norm": 4.281561851501465,
      "learning_rate": 5.182895944209947e-05,
      "logits/chosen": -0.7502521276473999,
      "logits/rejected": -0.6280051469802856,
      "logps/chosen": -166.8783721923828,
      "logps/rejected": -154.46133422851562,
      "loss": 0.4584,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.3276896476745605,
      "rewards/margins": 1.359877347946167,
      "rewards/rejected": -3.6875672340393066,
      "step": 9750
    },
    {
      "epoch": 1.781184414636372,
      "grad_norm": 3.885741710662842,
      "learning_rate": 5.17995962561938e-05,
      "logits/chosen": -0.8686590194702148,
      "logits/rejected": -0.6012960076332092,
      "logps/chosen": -175.78762817382812,
      "logps/rejected": -164.90196228027344,
      "loss": 0.3377,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.2318809032440186,
      "rewards/margins": 1.7990891933441162,
      "rewards/rejected": -4.030970573425293,
      "step": 9760
    },
    {
      "epoch": 1.7830093986677618,
      "grad_norm": 4.577423095703125,
      "learning_rate": 5.177023307028813e-05,
      "logits/chosen": -0.7014292478561401,
      "logits/rejected": -0.5116246938705444,
      "logps/chosen": -174.42686462402344,
      "logps/rejected": -157.6353302001953,
      "loss": 0.4276,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.68029522895813,
      "rewards/margins": 1.5331246852874756,
      "rewards/rejected": -4.2134199142456055,
      "step": 9770
    },
    {
      "epoch": 1.7848343826991515,
      "grad_norm": 5.040829658508301,
      "learning_rate": 5.1740869884382465e-05,
      "logits/chosen": -0.8157591819763184,
      "logits/rejected": -0.6658414602279663,
      "logps/chosen": -178.19827270507812,
      "logps/rejected": -162.44882202148438,
      "loss": 0.4972,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.3320472240448,
      "rewards/margins": 1.4625893831253052,
      "rewards/rejected": -3.7946364879608154,
      "step": 9780
    },
    {
      "epoch": 1.7866593667305413,
      "grad_norm": 4.663619041442871,
      "learning_rate": 5.171150669847679e-05,
      "logits/chosen": -0.6918176412582397,
      "logits/rejected": -0.5612452030181885,
      "logps/chosen": -156.57095336914062,
      "logps/rejected": -162.68128967285156,
      "loss": 0.4657,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.178433656692505,
      "rewards/margins": 1.4968798160552979,
      "rewards/rejected": -3.6753132343292236,
      "step": 9790
    },
    {
      "epoch": 1.7884843507619308,
      "grad_norm": 3.0981221199035645,
      "learning_rate": 5.1682143512571114e-05,
      "logits/chosen": -0.7195034027099609,
      "logits/rejected": -0.5753286480903625,
      "logps/chosen": -160.75299072265625,
      "logps/rejected": -152.28436279296875,
      "loss": 0.4948,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.988663911819458,
      "rewards/margins": 1.3842732906341553,
      "rewards/rejected": -3.3729374408721924,
      "step": 9800
    },
    {
      "epoch": 1.7903093347933206,
      "grad_norm": 3.294912815093994,
      "learning_rate": 5.1652780326665446e-05,
      "logits/chosen": -0.6017364263534546,
      "logits/rejected": -0.5159411430358887,
      "logps/chosen": -161.92909240722656,
      "logps/rejected": -171.29415893554688,
      "loss": 0.5759,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.416318655014038,
      "rewards/margins": 1.072871208190918,
      "rewards/rejected": -3.4891891479492188,
      "step": 9810
    },
    {
      "epoch": 1.7921343188247103,
      "grad_norm": 4.695901870727539,
      "learning_rate": 5.162341714075978e-05,
      "logits/chosen": -0.6353659629821777,
      "logits/rejected": -0.5208567380905151,
      "logps/chosen": -153.07354736328125,
      "logps/rejected": -154.03819274902344,
      "loss": 0.4747,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.10398530960083,
      "rewards/margins": 1.3472397327423096,
      "rewards/rejected": -3.4512245655059814,
      "step": 9820
    },
    {
      "epoch": 1.7939593028561,
      "grad_norm": 2.94277286529541,
      "learning_rate": 5.159405395485411e-05,
      "logits/chosen": -0.7410942316055298,
      "logits/rejected": -0.5729818344116211,
      "logps/chosen": -164.62283325195312,
      "logps/rejected": -160.83560180664062,
      "loss": 0.4469,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.263451099395752,
      "rewards/margins": 1.4527432918548584,
      "rewards/rejected": -3.7161946296691895,
      "step": 9830
    },
    {
      "epoch": 1.7957842868874896,
      "grad_norm": 4.244044303894043,
      "learning_rate": 5.156469076894843e-05,
      "logits/chosen": -0.7974835634231567,
      "logits/rejected": -0.6032618284225464,
      "logps/chosen": -164.11117553710938,
      "logps/rejected": -146.7271728515625,
      "loss": 0.3803,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6019411087036133,
      "rewards/margins": 1.7213506698608398,
      "rewards/rejected": -3.323291778564453,
      "step": 9840
    },
    {
      "epoch": 1.7976092709188793,
      "grad_norm": 6.154384136199951,
      "learning_rate": 5.153532758304276e-05,
      "logits/chosen": -0.7052302360534668,
      "logits/rejected": -0.5675954818725586,
      "logps/chosen": -156.4216766357422,
      "logps/rejected": -161.54026794433594,
      "loss": 0.5065,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7848405838012695,
      "rewards/margins": 1.516914963722229,
      "rewards/rejected": -3.301755428314209,
      "step": 9850
    },
    {
      "epoch": 1.799434254950269,
      "grad_norm": 3.3676881790161133,
      "learning_rate": 5.1505964397137096e-05,
      "logits/chosen": -0.7908400297164917,
      "logits/rejected": -0.6055790185928345,
      "logps/chosen": -155.9329376220703,
      "logps/rejected": -159.3877410888672,
      "loss": 0.392,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.375984787940979,
      "rewards/margins": 1.9044344425201416,
      "rewards/rejected": -3.280418872833252,
      "step": 9860
    },
    {
      "epoch": 1.8012592389816589,
      "grad_norm": 4.419447422027588,
      "learning_rate": 5.147660121123142e-05,
      "logits/chosen": -0.7797046303749084,
      "logits/rejected": -0.5503531694412231,
      "logps/chosen": -164.3910675048828,
      "logps/rejected": -149.6238555908203,
      "loss": 0.3243,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8267614841461182,
      "rewards/margins": 1.8992977142333984,
      "rewards/rejected": -3.7260589599609375,
      "step": 9870
    },
    {
      "epoch": 1.8030842230130486,
      "grad_norm": 2.994208335876465,
      "learning_rate": 5.144723802532575e-05,
      "logits/chosen": -0.6683794260025024,
      "logits/rejected": -0.5310730934143066,
      "logps/chosen": -154.9215545654297,
      "logps/rejected": -152.82806396484375,
      "loss": 0.5284,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9536495208740234,
      "rewards/margins": 1.4427978992462158,
      "rewards/rejected": -3.3964476585388184,
      "step": 9880
    },
    {
      "epoch": 1.8049092070444384,
      "grad_norm": 5.163686275482178,
      "learning_rate": 5.141787483942008e-05,
      "logits/chosen": -0.7588859796524048,
      "logits/rejected": -0.6012219190597534,
      "logps/chosen": -154.01431274414062,
      "logps/rejected": -151.80828857421875,
      "loss": 0.4264,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7193477153778076,
      "rewards/margins": 1.6122910976409912,
      "rewards/rejected": -3.331638813018799,
      "step": 9890
    },
    {
      "epoch": 1.806734191075828,
      "grad_norm": 3.0494437217712402,
      "learning_rate": 5.1388511653514414e-05,
      "logits/chosen": -0.7572299838066101,
      "logits/rejected": -0.5481073260307312,
      "logps/chosen": -169.94761657714844,
      "logps/rejected": -151.64944458007812,
      "loss": 0.3413,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.98019540309906,
      "rewards/margins": 1.6779334545135498,
      "rewards/rejected": -3.6581292152404785,
      "step": 9900
    },
    {
      "epoch": 1.8085591751072179,
      "grad_norm": 2.2839608192443848,
      "learning_rate": 5.135914846760874e-05,
      "logits/chosen": -0.6468619704246521,
      "logits/rejected": -0.4945107102394104,
      "logps/chosen": -157.47781372070312,
      "logps/rejected": -152.3957061767578,
      "loss": 0.4166,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8614879846572876,
      "rewards/margins": 1.7447292804718018,
      "rewards/rejected": -3.606217622756958,
      "step": 9910
    },
    {
      "epoch": 1.8103841591386076,
      "grad_norm": 7.059767723083496,
      "learning_rate": 5.132978528170306e-05,
      "logits/chosen": -0.7672163248062134,
      "logits/rejected": -0.6033241152763367,
      "logps/chosen": -185.53228759765625,
      "logps/rejected": -169.6576690673828,
      "loss": 0.4434,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.201354503631592,
      "rewards/margins": 1.5369962453842163,
      "rewards/rejected": -3.7383506298065186,
      "step": 9920
    },
    {
      "epoch": 1.8122091431699974,
      "grad_norm": 3.9881179332733154,
      "learning_rate": 5.13004220957974e-05,
      "logits/chosen": -0.6769838929176331,
      "logits/rejected": -0.6221407651901245,
      "logps/chosen": -170.00686645507812,
      "logps/rejected": -183.99639892578125,
      "loss": 0.446,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.073967218399048,
      "rewards/margins": 1.6893815994262695,
      "rewards/rejected": -3.7633488178253174,
      "step": 9930
    },
    {
      "epoch": 1.8140341272013871,
      "grad_norm": 2.719975471496582,
      "learning_rate": 5.1271058909891726e-05,
      "logits/chosen": -0.6829192042350769,
      "logits/rejected": -0.5820701718330383,
      "logps/chosen": -158.82113647460938,
      "logps/rejected": -168.4652557373047,
      "loss": 0.5326,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.276698350906372,
      "rewards/margins": 1.3503612279891968,
      "rewards/rejected": -3.6270599365234375,
      "step": 9940
    },
    {
      "epoch": 1.8158591112327769,
      "grad_norm": 4.129153251647949,
      "learning_rate": 5.124169572398606e-05,
      "logits/chosen": -0.7997365593910217,
      "logits/rejected": -0.5824999809265137,
      "logps/chosen": -180.98721313476562,
      "logps/rejected": -170.6663055419922,
      "loss": 0.4157,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.115473747253418,
      "rewards/margins": 1.865271806716919,
      "rewards/rejected": -3.980745792388916,
      "step": 9950
    },
    {
      "epoch": 1.8176840952641664,
      "grad_norm": 2.117931842803955,
      "learning_rate": 5.121233253808038e-05,
      "logits/chosen": -0.7890589237213135,
      "logits/rejected": -0.5706743001937866,
      "logps/chosen": -174.55487060546875,
      "logps/rejected": -159.95660400390625,
      "loss": 0.441,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7638823986053467,
      "rewards/margins": 1.5919402837753296,
      "rewards/rejected": -3.355822801589966,
      "step": 9960
    },
    {
      "epoch": 1.8195090792955562,
      "grad_norm": 2.638061285018921,
      "learning_rate": 5.118296935217472e-05,
      "logits/chosen": -0.7557129263877869,
      "logits/rejected": -0.5891444683074951,
      "logps/chosen": -174.86227416992188,
      "logps/rejected": -159.96578979492188,
      "loss": 0.4199,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5573666095733643,
      "rewards/margins": 1.6498973369598389,
      "rewards/rejected": -3.2072644233703613,
      "step": 9970
    },
    {
      "epoch": 1.821334063326946,
      "grad_norm": 2.413076877593994,
      "learning_rate": 5.1153606166269045e-05,
      "logits/chosen": -0.715898871421814,
      "logits/rejected": -0.5479682087898254,
      "logps/chosen": -162.65289306640625,
      "logps/rejected": -160.27133178710938,
      "loss": 0.4862,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9710865020751953,
      "rewards/margins": 1.3129419088363647,
      "rewards/rejected": -3.2840282917022705,
      "step": 9980
    },
    {
      "epoch": 1.8231590473583354,
      "grad_norm": 4.3686652183532715,
      "learning_rate": 5.112424298036337e-05,
      "logits/chosen": -0.7202932238578796,
      "logits/rejected": -0.5089868903160095,
      "logps/chosen": -174.31370544433594,
      "logps/rejected": -160.9657440185547,
      "loss": 0.5246,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.0893282890319824,
      "rewards/margins": 1.3855081796646118,
      "rewards/rejected": -3.4748363494873047,
      "step": 9990
    },
    {
      "epoch": 1.8249840313897252,
      "grad_norm": 5.7731032371521,
      "learning_rate": 5.10948797944577e-05,
      "logits/chosen": -0.6076946258544922,
      "logits/rejected": -0.40347152948379517,
      "logps/chosen": -167.2472381591797,
      "logps/rejected": -162.1888885498047,
      "loss": 0.4905,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.5551505088806152,
      "rewards/margins": 1.2604060173034668,
      "rewards/rejected": -3.8155570030212402,
      "step": 10000
    },
    {
      "epoch": 1.826809015421115,
      "grad_norm": 3.3309218883514404,
      "learning_rate": 5.106551660855203e-05,
      "logits/chosen": -0.6634346842765808,
      "logits/rejected": -0.5189889669418335,
      "logps/chosen": -163.33731079101562,
      "logps/rejected": -156.64971923828125,
      "loss": 0.4359,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.059528112411499,
      "rewards/margins": 1.3586448431015015,
      "rewards/rejected": -3.418172836303711,
      "step": 10010
    },
    {
      "epoch": 1.8286339994525047,
      "grad_norm": 4.125459671020508,
      "learning_rate": 5.103615342264636e-05,
      "logits/chosen": -0.6810863018035889,
      "logits/rejected": -0.5351683497428894,
      "logps/chosen": -173.3533172607422,
      "logps/rejected": -161.15841674804688,
      "loss": 0.567,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.2790653705596924,
      "rewards/margins": 1.082861304283142,
      "rewards/rejected": -3.361926555633545,
      "step": 10020
    },
    {
      "epoch": 1.8304589834838945,
      "grad_norm": 2.3831238746643066,
      "learning_rate": 5.100679023674069e-05,
      "logits/chosen": -0.7970131039619446,
      "logits/rejected": -0.5888631343841553,
      "logps/chosen": -160.11550903320312,
      "logps/rejected": -147.41653442382812,
      "loss": 0.4799,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9665277004241943,
      "rewards/margins": 1.2906842231750488,
      "rewards/rejected": -3.257211685180664,
      "step": 10030
    },
    {
      "epoch": 1.8322839675152842,
      "grad_norm": 3.207946538925171,
      "learning_rate": 5.097742705083501e-05,
      "logits/chosen": -0.8106409907341003,
      "logits/rejected": -0.6320111155509949,
      "logps/chosen": -168.7186737060547,
      "logps/rejected": -165.68556213378906,
      "loss": 0.3511,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.872788667678833,
      "rewards/margins": 1.652881383895874,
      "rewards/rejected": -3.525669813156128,
      "step": 10040
    },
    {
      "epoch": 1.834108951546674,
      "grad_norm": 5.823963165283203,
      "learning_rate": 5.094806386492935e-05,
      "logits/chosen": -0.8076027631759644,
      "logits/rejected": -0.6064525842666626,
      "logps/chosen": -167.7007293701172,
      "logps/rejected": -152.37252807617188,
      "loss": 0.4577,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.3484630584716797,
      "rewards/margins": 1.4605581760406494,
      "rewards/rejected": -3.8090217113494873,
      "step": 10050
    },
    {
      "epoch": 1.8359339355780637,
      "grad_norm": 3.6301891803741455,
      "learning_rate": 5.0918700679023675e-05,
      "logits/chosen": -0.6872624754905701,
      "logits/rejected": -0.49211087822914124,
      "logps/chosen": -183.97787475585938,
      "logps/rejected": -173.59963989257812,
      "loss": 0.3645,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.444995164871216,
      "rewards/margins": 1.6291377544403076,
      "rewards/rejected": -4.074132442474365,
      "step": 10060
    },
    {
      "epoch": 1.8377589196094535,
      "grad_norm": 3.4515910148620605,
      "learning_rate": 5.0889337493118006e-05,
      "logits/chosen": -0.7043421864509583,
      "logits/rejected": -0.5325634479522705,
      "logps/chosen": -156.13394165039062,
      "logps/rejected": -158.93165588378906,
      "loss": 0.3734,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.3194198608398438,
      "rewards/margins": 1.772870659828186,
      "rewards/rejected": -4.09229040145874,
      "step": 10070
    },
    {
      "epoch": 1.8395839036408432,
      "grad_norm": 2.5432987213134766,
      "learning_rate": 5.085997430721234e-05,
      "logits/chosen": -0.7957817912101746,
      "logits/rejected": -0.6556071043014526,
      "logps/chosen": -180.36697387695312,
      "logps/rejected": -169.47576904296875,
      "loss": 0.5298,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.704890489578247,
      "rewards/margins": 1.1831655502319336,
      "rewards/rejected": -3.8880562782287598,
      "step": 10080
    },
    {
      "epoch": 1.841408887672233,
      "grad_norm": 5.213864803314209,
      "learning_rate": 5.083061112130667e-05,
      "logits/chosen": -0.7502147555351257,
      "logits/rejected": -0.5729690790176392,
      "logps/chosen": -187.1422576904297,
      "logps/rejected": -186.26776123046875,
      "loss": 0.4589,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.737999200820923,
      "rewards/margins": 1.4243364334106445,
      "rewards/rejected": -4.162335395812988,
      "step": 10090
    },
    {
      "epoch": 1.8432338717036227,
      "grad_norm": 3.6794817447662354,
      "learning_rate": 5.0801247935400994e-05,
      "logits/chosen": -0.7899101972579956,
      "logits/rejected": -0.607414722442627,
      "logps/chosen": -175.3638458251953,
      "logps/rejected": -174.56265258789062,
      "loss": 0.4306,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.3289942741394043,
      "rewards/margins": 1.5006824731826782,
      "rewards/rejected": -3.829676389694214,
      "step": 10100
    },
    {
      "epoch": 1.8450588557350123,
      "grad_norm": 1.5664931535720825,
      "learning_rate": 5.077188474949532e-05,
      "logits/chosen": -0.896469235420227,
      "logits/rejected": -0.6756246089935303,
      "logps/chosen": -191.4417266845703,
      "logps/rejected": -167.89251708984375,
      "loss": 0.4775,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.4836597442626953,
      "rewards/margins": 1.4134042263031006,
      "rewards/rejected": -3.897064208984375,
      "step": 10110
    },
    {
      "epoch": 1.846883839766402,
      "grad_norm": 5.075519561767578,
      "learning_rate": 5.0742521563589656e-05,
      "logits/chosen": -0.6191632747650146,
      "logits/rejected": -0.48780614137649536,
      "logps/chosen": -181.77386474609375,
      "logps/rejected": -174.4348907470703,
      "loss": 0.4214,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.594045639038086,
      "rewards/margins": 1.4315578937530518,
      "rewards/rejected": -4.025603294372559,
      "step": 10120
    },
    {
      "epoch": 1.8487088237977918,
      "grad_norm": 2.336376428604126,
      "learning_rate": 5.071315837768398e-05,
      "logits/chosen": -0.7503122091293335,
      "logits/rejected": -0.5971171259880066,
      "logps/chosen": -169.83566284179688,
      "logps/rejected": -170.88369750976562,
      "loss": 0.4849,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.681136131286621,
      "rewards/margins": 1.2775545120239258,
      "rewards/rejected": -3.958690643310547,
      "step": 10130
    },
    {
      "epoch": 1.8505338078291815,
      "grad_norm": 5.619973659515381,
      "learning_rate": 5.068379519177831e-05,
      "logits/chosen": -0.6374356150627136,
      "logits/rejected": -0.5942887663841248,
      "logps/chosen": -161.6262664794922,
      "logps/rejected": -175.4738311767578,
      "loss": 0.543,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.8799350261688232,
      "rewards/margins": 1.2531769275665283,
      "rewards/rejected": -4.133111953735352,
      "step": 10140
    },
    {
      "epoch": 1.852358791860571,
      "grad_norm": 4.201780796051025,
      "learning_rate": 5.065443200587264e-05,
      "logits/chosen": -0.7916563749313354,
      "logits/rejected": -0.627435564994812,
      "logps/chosen": -171.97354125976562,
      "logps/rejected": -170.7937469482422,
      "loss": 0.4247,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.3191277980804443,
      "rewards/margins": 1.620173454284668,
      "rewards/rejected": -3.9393017292022705,
      "step": 10150
    },
    {
      "epoch": 1.8541837758919608,
      "grad_norm": 2.679708480834961,
      "learning_rate": 5.0625068819966975e-05,
      "logits/chosen": -0.6505854725837708,
      "logits/rejected": -0.5190926790237427,
      "logps/chosen": -159.3781280517578,
      "logps/rejected": -177.51808166503906,
      "loss": 0.4215,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.323671579360962,
      "rewards/margins": 1.7452876567840576,
      "rewards/rejected": -4.0689592361450195,
      "step": 10160
    },
    {
      "epoch": 1.8560087599233506,
      "grad_norm": 4.620489597320557,
      "learning_rate": 5.05957056340613e-05,
      "logits/chosen": -0.7323779463768005,
      "logits/rejected": -0.5932962894439697,
      "logps/chosen": -179.24208068847656,
      "logps/rejected": -170.10739135742188,
      "loss": 0.5045,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.2094759941101074,
      "rewards/margins": 1.404168725013733,
      "rewards/rejected": -3.61364483833313,
      "step": 10170
    },
    {
      "epoch": 1.8578337439547403,
      "grad_norm": 5.010225772857666,
      "learning_rate": 5.0566342448155624e-05,
      "logits/chosen": -0.6120424866676331,
      "logits/rejected": -0.3516264259815216,
      "logps/chosen": -180.8888397216797,
      "logps/rejected": -162.44937133789062,
      "loss": 0.3637,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.0851352214813232,
      "rewards/margins": 1.6697591543197632,
      "rewards/rejected": -3.754894256591797,
      "step": 10180
    },
    {
      "epoch": 1.85965872798613,
      "grad_norm": 3.525790214538574,
      "learning_rate": 5.0536979262249956e-05,
      "logits/chosen": -0.7284189462661743,
      "logits/rejected": -0.5707371830940247,
      "logps/chosen": -176.04150390625,
      "logps/rejected": -168.48300170898438,
      "loss": 0.4454,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6630662679672241,
      "rewards/margins": 1.6209924221038818,
      "rewards/rejected": -3.2840588092803955,
      "step": 10190
    },
    {
      "epoch": 1.8614837120175198,
      "grad_norm": 4.157329559326172,
      "learning_rate": 5.050761607634429e-05,
      "logits/chosen": -0.7850725054740906,
      "logits/rejected": -0.6780687570571899,
      "logps/chosen": -153.81192016601562,
      "logps/rejected": -155.50143432617188,
      "loss": 0.4627,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3072491884231567,
      "rewards/margins": 1.5370419025421143,
      "rewards/rejected": -2.8442912101745605,
      "step": 10200
    },
    {
      "epoch": 1.8633086960489096,
      "grad_norm": 2.983802080154419,
      "learning_rate": 5.047825289043862e-05,
      "logits/chosen": -0.734726071357727,
      "logits/rejected": -0.6395283937454224,
      "logps/chosen": -171.82278442382812,
      "logps/rejected": -173.2628936767578,
      "loss": 0.4435,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5591275691986084,
      "rewards/margins": 1.4970035552978516,
      "rewards/rejected": -3.05613112449646,
      "step": 10210
    },
    {
      "epoch": 1.8651336800802993,
      "grad_norm": 3.6162235736846924,
      "learning_rate": 5.044888970453294e-05,
      "logits/chosen": -0.7117089629173279,
      "logits/rejected": -0.4995957314968109,
      "logps/chosen": -146.9200439453125,
      "logps/rejected": -142.18338012695312,
      "loss": 0.4934,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7795120477676392,
      "rewards/margins": 1.1007766723632812,
      "rewards/rejected": -2.880288600921631,
      "step": 10220
    },
    {
      "epoch": 1.866958664111689,
      "grad_norm": 3.544032335281372,
      "learning_rate": 5.0419526518627274e-05,
      "logits/chosen": -0.7905892133712769,
      "logits/rejected": -0.5426238775253296,
      "logps/chosen": -175.50473022460938,
      "logps/rejected": -161.62240600585938,
      "loss": 0.3788,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4236756563186646,
      "rewards/margins": 1.635144591331482,
      "rewards/rejected": -3.0588200092315674,
      "step": 10230
    },
    {
      "epoch": 1.8687836481430788,
      "grad_norm": 5.158690929412842,
      "learning_rate": 5.0390163332721605e-05,
      "logits/chosen": -0.8039568066596985,
      "logits/rejected": -0.6309245824813843,
      "logps/chosen": -180.28961181640625,
      "logps/rejected": -169.31039428710938,
      "loss": 0.4459,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.6859973669052124,
      "rewards/margins": 1.335886836051941,
      "rewards/rejected": -3.0218842029571533,
      "step": 10240
    },
    {
      "epoch": 1.8706086321744686,
      "grad_norm": 3.6004796028137207,
      "learning_rate": 5.036080014681594e-05,
      "logits/chosen": -0.6852707862854004,
      "logits/rejected": -0.649256706237793,
      "logps/chosen": -140.59310913085938,
      "logps/rejected": -164.3785400390625,
      "loss": 0.5089,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.9273484945297241,
      "rewards/margins": 1.208776831626892,
      "rewards/rejected": -3.136125087738037,
      "step": 10250
    },
    {
      "epoch": 1.8724336162058584,
      "grad_norm": 7.312672138214111,
      "learning_rate": 5.033143696091026e-05,
      "logits/chosen": -0.6859539151191711,
      "logits/rejected": -0.6207901239395142,
      "logps/chosen": -162.58944702148438,
      "logps/rejected": -163.5731201171875,
      "loss": 0.5016,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6687326431274414,
      "rewards/margins": 1.114379644393921,
      "rewards/rejected": -2.7831122875213623,
      "step": 10260
    },
    {
      "epoch": 1.8742586002372479,
      "grad_norm": 1.48995840549469,
      "learning_rate": 5.03020737750046e-05,
      "logits/chosen": -0.7163066864013672,
      "logits/rejected": -0.5700435638427734,
      "logps/chosen": -169.9525909423828,
      "logps/rejected": -155.07449340820312,
      "loss": 0.4848,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.723323106765747,
      "rewards/margins": 1.2237656116485596,
      "rewards/rejected": -2.9470887184143066,
      "step": 10270
    },
    {
      "epoch": 1.8760835842686376,
      "grad_norm": 2.9998958110809326,
      "learning_rate": 5.0272710589098924e-05,
      "logits/chosen": -0.7542606592178345,
      "logits/rejected": -0.5447336435317993,
      "logps/chosen": -176.95394897460938,
      "logps/rejected": -148.36251831054688,
      "loss": 0.4502,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7392746210098267,
      "rewards/margins": 1.371730923652649,
      "rewards/rejected": -3.1110053062438965,
      "step": 10280
    },
    {
      "epoch": 1.8779085683000274,
      "grad_norm": 2.1346819400787354,
      "learning_rate": 5.024334740319325e-05,
      "logits/chosen": -0.8583941459655762,
      "logits/rejected": -0.6710507869720459,
      "logps/chosen": -167.6903839111328,
      "logps/rejected": -165.5405731201172,
      "loss": 0.4135,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7682768106460571,
      "rewards/margins": 1.6618320941925049,
      "rewards/rejected": -3.4301090240478516,
      "step": 10290
    },
    {
      "epoch": 1.8797335523314171,
      "grad_norm": 2.610309600830078,
      "learning_rate": 5.021398421728758e-05,
      "logits/chosen": -0.8012385368347168,
      "logits/rejected": -0.6879732012748718,
      "logps/chosen": -179.94497680664062,
      "logps/rejected": -178.3027801513672,
      "loss": 0.4299,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7886947393417358,
      "rewards/margins": 1.4007701873779297,
      "rewards/rejected": -3.189465045928955,
      "step": 10300
    },
    {
      "epoch": 1.8815585363628067,
      "grad_norm": 3.413647174835205,
      "learning_rate": 5.018462103138191e-05,
      "logits/chosen": -0.7324885129928589,
      "logits/rejected": -0.5825719833374023,
      "logps/chosen": -167.67120361328125,
      "logps/rejected": -161.20059204101562,
      "loss": 0.4661,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8631569147109985,
      "rewards/margins": 1.3520123958587646,
      "rewards/rejected": -3.2151694297790527,
      "step": 10310
    },
    {
      "epoch": 1.8833835203941964,
      "grad_norm": 4.357355117797852,
      "learning_rate": 5.015525784547624e-05,
      "logits/chosen": -0.8315046429634094,
      "logits/rejected": -0.653150737285614,
      "logps/chosen": -164.86526489257812,
      "logps/rejected": -166.53306579589844,
      "loss": 0.5056,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.001786470413208,
      "rewards/margins": 1.2270629405975342,
      "rewards/rejected": -3.228848934173584,
      "step": 10320
    },
    {
      "epoch": 1.8852085044255862,
      "grad_norm": 3.0482358932495117,
      "learning_rate": 5.012589465957057e-05,
      "logits/chosen": -0.7766758799552917,
      "logits/rejected": -0.6041678786277771,
      "logps/chosen": -154.033203125,
      "logps/rejected": -143.0325164794922,
      "loss": 0.4613,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7935035228729248,
      "rewards/margins": 1.261435627937317,
      "rewards/rejected": -3.054939031600952,
      "step": 10330
    },
    {
      "epoch": 1.887033488456976,
      "grad_norm": 3.0382018089294434,
      "learning_rate": 5.009653147366489e-05,
      "logits/chosen": -0.6504616737365723,
      "logits/rejected": -0.5416460037231445,
      "logps/chosen": -161.6745147705078,
      "logps/rejected": -165.880126953125,
      "loss": 0.4556,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.160619020462036,
      "rewards/margins": 1.30755615234375,
      "rewards/rejected": -3.468175172805786,
      "step": 10340
    },
    {
      "epoch": 1.8888584724883657,
      "grad_norm": 5.423734188079834,
      "learning_rate": 5.006716828775923e-05,
      "logits/chosen": -0.7922874689102173,
      "logits/rejected": -0.5804976224899292,
      "logps/chosen": -173.7205047607422,
      "logps/rejected": -156.04185485839844,
      "loss": 0.5113,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.2231926918029785,
      "rewards/margins": 1.425672173500061,
      "rewards/rejected": -3.64886474609375,
      "step": 10350
    },
    {
      "epoch": 1.8906834565197554,
      "grad_norm": 3.2701122760772705,
      "learning_rate": 5.0037805101853555e-05,
      "logits/chosen": -0.7800930738449097,
      "logits/rejected": -0.5187982320785522,
      "logps/chosen": -150.73080444335938,
      "logps/rejected": -145.9851531982422,
      "loss": 0.4018,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7980877161026,
      "rewards/margins": 1.6980819702148438,
      "rewards/rejected": -3.496169328689575,
      "step": 10360
    },
    {
      "epoch": 1.8925084405511452,
      "grad_norm": 1.405734658241272,
      "learning_rate": 5.0008441915947886e-05,
      "logits/chosen": -0.7855030298233032,
      "logits/rejected": -0.5963141918182373,
      "logps/chosen": -162.8117218017578,
      "logps/rejected": -147.5720672607422,
      "loss": 0.3643,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7221591472625732,
      "rewards/margins": 1.6765222549438477,
      "rewards/rejected": -3.398681163787842,
      "step": 10370
    },
    {
      "epoch": 1.894333424582535,
      "grad_norm": 3.403979778289795,
      "learning_rate": 4.997907873004221e-05,
      "logits/chosen": -0.7208425402641296,
      "logits/rejected": -0.6021662354469299,
      "logps/chosen": -160.2203826904297,
      "logps/rejected": -157.5631103515625,
      "loss": 0.5088,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6978693008422852,
      "rewards/margins": 1.3096779584884644,
      "rewards/rejected": -3.007547378540039,
      "step": 10380
    },
    {
      "epoch": 1.8961584086139247,
      "grad_norm": 5.156877517700195,
      "learning_rate": 4.994971554413655e-05,
      "logits/chosen": -0.775276780128479,
      "logits/rejected": -0.5367681384086609,
      "logps/chosen": -155.66773986816406,
      "logps/rejected": -136.9457244873047,
      "loss": 0.4643,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2738332748413086,
      "rewards/margins": 1.4733489751815796,
      "rewards/rejected": -2.7471823692321777,
      "step": 10390
    },
    {
      "epoch": 1.8979833926453145,
      "grad_norm": 3.992413282394409,
      "learning_rate": 4.992035235823087e-05,
      "logits/chosen": -0.7035597562789917,
      "logits/rejected": -0.5655942559242249,
      "logps/chosen": -162.6836700439453,
      "logps/rejected": -149.35035705566406,
      "loss": 0.4929,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3873417377471924,
      "rewards/margins": 1.5821647644042969,
      "rewards/rejected": -2.96950626373291,
      "step": 10400
    },
    {
      "epoch": 1.8998083766767042,
      "grad_norm": 5.2303385734558105,
      "learning_rate": 4.98909891723252e-05,
      "logits/chosen": -0.7463200688362122,
      "logits/rejected": -0.6369324922561646,
      "logps/chosen": -157.18896484375,
      "logps/rejected": -158.24171447753906,
      "loss": 0.4503,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2735073566436768,
      "rewards/margins": 1.4201700687408447,
      "rewards/rejected": -2.6936771869659424,
      "step": 10410
    },
    {
      "epoch": 1.901633360708094,
      "grad_norm": 3.3057851791381836,
      "learning_rate": 4.986162598641953e-05,
      "logits/chosen": -0.7716684341430664,
      "logits/rejected": -0.6247727274894714,
      "logps/chosen": -162.71380615234375,
      "logps/rejected": -156.57362365722656,
      "loss": 0.426,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.42855703830719,
      "rewards/margins": 1.6244051456451416,
      "rewards/rejected": -3.052961826324463,
      "step": 10420
    },
    {
      "epoch": 1.9034583447394835,
      "grad_norm": 3.466176986694336,
      "learning_rate": 4.983226280051386e-05,
      "logits/chosen": -0.8362568020820618,
      "logits/rejected": -0.6585443615913391,
      "logps/chosen": -157.54598999023438,
      "logps/rejected": -148.9540557861328,
      "loss": 0.3659,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.3353593349456787,
      "rewards/margins": 1.563966989517212,
      "rewards/rejected": -2.8993258476257324,
      "step": 10430
    },
    {
      "epoch": 1.9052833287708733,
      "grad_norm": 5.31744909286499,
      "learning_rate": 4.980289961460819e-05,
      "logits/chosen": -0.7491160035133362,
      "logits/rejected": -0.6086007952690125,
      "logps/chosen": -177.66244506835938,
      "logps/rejected": -190.83633422851562,
      "loss": 0.3063,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8168928623199463,
      "rewards/margins": 1.99843430519104,
      "rewards/rejected": -3.815326690673828,
      "step": 10440
    },
    {
      "epoch": 1.907108312802263,
      "grad_norm": 3.6433398723602295,
      "learning_rate": 4.9773536428702516e-05,
      "logits/chosen": -0.838145911693573,
      "logits/rejected": -0.6376897096633911,
      "logps/chosen": -178.64573669433594,
      "logps/rejected": -172.87069702148438,
      "loss": 0.4134,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0303313732147217,
      "rewards/margins": 1.8678367137908936,
      "rewards/rejected": -2.8981680870056152,
      "step": 10450
    },
    {
      "epoch": 1.9089332968336528,
      "grad_norm": 5.125823020935059,
      "learning_rate": 4.9744173242796855e-05,
      "logits/chosen": -0.7914631962776184,
      "logits/rejected": -0.7040079832077026,
      "logps/chosen": -145.01043701171875,
      "logps/rejected": -151.79283142089844,
      "loss": 0.4543,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7288129329681396,
      "rewards/margins": 1.3030970096588135,
      "rewards/rejected": -3.0319101810455322,
      "step": 10460
    },
    {
      "epoch": 1.9107582808650423,
      "grad_norm": 4.7447333335876465,
      "learning_rate": 4.971481005689118e-05,
      "logits/chosen": -0.7987368106842041,
      "logits/rejected": -0.652863621711731,
      "logps/chosen": -145.99130249023438,
      "logps/rejected": -156.44979858398438,
      "loss": 0.4628,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3334392309188843,
      "rewards/margins": 1.4786531925201416,
      "rewards/rejected": -2.8120923042297363,
      "step": 10470
    },
    {
      "epoch": 1.912583264896432,
      "grad_norm": 4.237392425537109,
      "learning_rate": 4.9685446870985504e-05,
      "logits/chosen": -0.748749315738678,
      "logits/rejected": -0.5675579905509949,
      "logps/chosen": -174.9046173095703,
      "logps/rejected": -159.11712646484375,
      "loss": 0.3917,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3062591552734375,
      "rewards/margins": 1.7048578262329102,
      "rewards/rejected": -3.0111172199249268,
      "step": 10480
    },
    {
      "epoch": 1.9144082489278218,
      "grad_norm": 4.121066093444824,
      "learning_rate": 4.9656083685079835e-05,
      "logits/chosen": -0.8379846811294556,
      "logits/rejected": -0.5941022634506226,
      "logps/chosen": -155.11343383789062,
      "logps/rejected": -157.57595825195312,
      "loss": 0.3227,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5475294589996338,
      "rewards/margins": 2.07720685005188,
      "rewards/rejected": -3.6247360706329346,
      "step": 10490
    },
    {
      "epoch": 1.9162332329592116,
      "grad_norm": 1.7159976959228516,
      "learning_rate": 4.9626720499174166e-05,
      "logits/chosen": -0.6404479146003723,
      "logits/rejected": -0.4699626564979553,
      "logps/chosen": -168.95436096191406,
      "logps/rejected": -165.9386444091797,
      "loss": 0.4808,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.832668662071228,
      "rewards/margins": 1.5860048532485962,
      "rewards/rejected": -3.418673276901245,
      "step": 10500
    },
    {
      "epoch": 1.9180582169906013,
      "grad_norm": 4.484981536865234,
      "learning_rate": 4.95973573132685e-05,
      "logits/chosen": -0.7744439840316772,
      "logits/rejected": -0.6002283692359924,
      "logps/chosen": -169.89764404296875,
      "logps/rejected": -171.67396545410156,
      "loss": 0.4565,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.968770980834961,
      "rewards/margins": 1.5249274969100952,
      "rewards/rejected": -3.4936985969543457,
      "step": 10510
    },
    {
      "epoch": 1.919883201021991,
      "grad_norm": 5.12604284286499,
      "learning_rate": 4.956799412736282e-05,
      "logits/chosen": -0.7473068833351135,
      "logits/rejected": -0.5544828176498413,
      "logps/chosen": -161.1129150390625,
      "logps/rejected": -160.90480041503906,
      "loss": 0.3935,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.2409632205963135,
      "rewards/margins": 1.5907076597213745,
      "rewards/rejected": -3.8316712379455566,
      "step": 10520
    },
    {
      "epoch": 1.9217081850533808,
      "grad_norm": 2.699052572250366,
      "learning_rate": 4.953863094145715e-05,
      "logits/chosen": -0.7231194376945496,
      "logits/rejected": -0.48504891991615295,
      "logps/chosen": -173.95114135742188,
      "logps/rejected": -152.54153442382812,
      "loss": 0.4156,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.884299635887146,
      "rewards/margins": 1.8693132400512695,
      "rewards/rejected": -3.753612518310547,
      "step": 10530
    },
    {
      "epoch": 1.9235331690847706,
      "grad_norm": 6.340444087982178,
      "learning_rate": 4.9509267755551485e-05,
      "logits/chosen": -0.7473477125167847,
      "logits/rejected": -0.4864322543144226,
      "logps/chosen": -168.82562255859375,
      "logps/rejected": -162.60227966308594,
      "loss": 0.4528,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.6745688915252686,
      "rewards/margins": 2.013481616973877,
      "rewards/rejected": -3.6880507469177246,
      "step": 10540
    },
    {
      "epoch": 1.9253581531161603,
      "grad_norm": 4.514102935791016,
      "learning_rate": 4.947990456964581e-05,
      "logits/chosen": -0.7938756942749023,
      "logits/rejected": -0.647505521774292,
      "logps/chosen": -153.19784545898438,
      "logps/rejected": -156.22506713867188,
      "loss": 0.531,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7141532897949219,
      "rewards/margins": 1.6497910022735596,
      "rewards/rejected": -3.3639438152313232,
      "step": 10550
    },
    {
      "epoch": 1.92718313714755,
      "grad_norm": 3.0831239223480225,
      "learning_rate": 4.945054138374014e-05,
      "logits/chosen": -0.9005343317985535,
      "logits/rejected": -0.7209084033966064,
      "logps/chosen": -176.2610626220703,
      "logps/rejected": -157.9180908203125,
      "loss": 0.4834,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.5651805400848389,
      "rewards/margins": 1.3403736352920532,
      "rewards/rejected": -2.9055542945861816,
      "step": 10560
    },
    {
      "epoch": 1.9290081211789398,
      "grad_norm": 6.436668395996094,
      "learning_rate": 4.9421178197834466e-05,
      "logits/chosen": -0.809439480304718,
      "logits/rejected": -0.6729676723480225,
      "logps/chosen": -176.02651977539062,
      "logps/rejected": -169.41014099121094,
      "loss": 0.4892,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.0523557662963867,
      "rewards/margins": 1.4009160995483398,
      "rewards/rejected": -3.4532718658447266,
      "step": 10570
    },
    {
      "epoch": 1.9308331052103294,
      "grad_norm": 8.408857345581055,
      "learning_rate": 4.9391815011928804e-05,
      "logits/chosen": -0.8255780935287476,
      "logits/rejected": -0.6414704322814941,
      "logps/chosen": -160.73287963867188,
      "logps/rejected": -152.3209991455078,
      "loss": 0.4151,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.253248691558838,
      "rewards/margins": 1.7778851985931396,
      "rewards/rejected": -4.031133651733398,
      "step": 10580
    },
    {
      "epoch": 1.9326580892417191,
      "grad_norm": 4.479369163513184,
      "learning_rate": 4.936245182602313e-05,
      "logits/chosen": -0.9218088984489441,
      "logits/rejected": -0.7668777704238892,
      "logps/chosen": -166.22866821289062,
      "logps/rejected": -152.93577575683594,
      "loss": 0.489,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.3257882595062256,
      "rewards/margins": 1.3026913404464722,
      "rewards/rejected": -3.6284797191619873,
      "step": 10590
    },
    {
      "epoch": 1.9344830732731089,
      "grad_norm": 3.3116188049316406,
      "learning_rate": 4.933308864011745e-05,
      "logits/chosen": -0.9490834474563599,
      "logits/rejected": -0.810799241065979,
      "logps/chosen": -165.61569213867188,
      "logps/rejected": -172.37969970703125,
      "loss": 0.3659,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7482526302337646,
      "rewards/margins": 1.8335731029510498,
      "rewards/rejected": -3.5818259716033936,
      "step": 10600
    },
    {
      "epoch": 1.9363080573044986,
      "grad_norm": 2.5561258792877197,
      "learning_rate": 4.9303725454211784e-05,
      "logits/chosen": -0.9833232760429382,
      "logits/rejected": -0.8497675061225891,
      "logps/chosen": -182.90830993652344,
      "logps/rejected": -159.68211364746094,
      "loss": 0.4915,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9859079122543335,
      "rewards/margins": 1.350059151649475,
      "rewards/rejected": -3.3359668254852295,
      "step": 10610
    },
    {
      "epoch": 1.9381330413358882,
      "grad_norm": 3.12628436088562,
      "learning_rate": 4.9274362268306115e-05,
      "logits/chosen": -0.944460391998291,
      "logits/rejected": -0.7613884210586548,
      "logps/chosen": -191.8308868408203,
      "logps/rejected": -174.40859985351562,
      "loss": 0.3339,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8885730504989624,
      "rewards/margins": 1.8478482961654663,
      "rewards/rejected": -3.736421585083008,
      "step": 10620
    },
    {
      "epoch": 1.939958025367278,
      "grad_norm": 3.6841318607330322,
      "learning_rate": 4.924499908240045e-05,
      "logits/chosen": -0.9431161880493164,
      "logits/rejected": -0.7737663984298706,
      "logps/chosen": -176.1107635498047,
      "logps/rejected": -160.9385223388672,
      "loss": 0.485,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0469672679901123,
      "rewards/margins": 1.5500481128692627,
      "rewards/rejected": -3.597015380859375,
      "step": 10630
    },
    {
      "epoch": 1.9417830093986677,
      "grad_norm": 7.666611194610596,
      "learning_rate": 4.921563589649477e-05,
      "logits/chosen": -0.9057989120483398,
      "logits/rejected": -0.8077651262283325,
      "logps/chosen": -176.11741638183594,
      "logps/rejected": -172.18246459960938,
      "loss": 0.4478,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.331566095352173,
      "rewards/margins": 1.3401520252227783,
      "rewards/rejected": -3.671717882156372,
      "step": 10640
    },
    {
      "epoch": 1.9436079934300574,
      "grad_norm": 2.8290202617645264,
      "learning_rate": 4.918627271058911e-05,
      "logits/chosen": -0.796159029006958,
      "logits/rejected": -0.7004097700119019,
      "logps/chosen": -163.61361694335938,
      "logps/rejected": -169.05963134765625,
      "loss": 0.5185,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.624410629272461,
      "rewards/margins": 1.2813920974731445,
      "rewards/rejected": -3.9058029651641846,
      "step": 10650
    },
    {
      "epoch": 1.9454329774614472,
      "grad_norm": 2.991903781890869,
      "learning_rate": 4.9156909524683434e-05,
      "logits/chosen": -0.978402316570282,
      "logits/rejected": -0.704651951789856,
      "logps/chosen": -178.33224487304688,
      "logps/rejected": -146.2991485595703,
      "loss": 0.4185,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.4765782356262207,
      "rewards/margins": 1.4975258111953735,
      "rewards/rejected": -3.974104404449463,
      "step": 10660
    },
    {
      "epoch": 1.947257961492837,
      "grad_norm": 5.574475288391113,
      "learning_rate": 4.912754633877776e-05,
      "logits/chosen": -0.767571210861206,
      "logits/rejected": -0.5925400853157043,
      "logps/chosen": -161.54901123046875,
      "logps/rejected": -161.71665954589844,
      "loss": 0.4343,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.632833957672119,
      "rewards/margins": 1.6964514255523682,
      "rewards/rejected": -4.329285621643066,
      "step": 10670
    },
    {
      "epoch": 1.9490829455242267,
      "grad_norm": 5.324308395385742,
      "learning_rate": 4.909818315287209e-05,
      "logits/chosen": -0.815345287322998,
      "logits/rejected": -0.7014023065567017,
      "logps/chosen": -168.80679321289062,
      "logps/rejected": -166.5966033935547,
      "loss": 0.6004,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.653233051300049,
      "rewards/margins": 1.010262370109558,
      "rewards/rejected": -3.6634953022003174,
      "step": 10680
    },
    {
      "epoch": 1.9509079295556164,
      "grad_norm": 3.6495275497436523,
      "learning_rate": 4.906881996696642e-05,
      "logits/chosen": -0.8291229009628296,
      "logits/rejected": -0.6460552215576172,
      "logps/chosen": -172.60435485839844,
      "logps/rejected": -163.85501098632812,
      "loss": 0.3766,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.0532307624816895,
      "rewards/margins": 1.5526880025863647,
      "rewards/rejected": -3.6059188842773438,
      "step": 10690
    },
    {
      "epoch": 1.9527329135870062,
      "grad_norm": 2.8898208141326904,
      "learning_rate": 4.903945678106075e-05,
      "logits/chosen": -0.8853474855422974,
      "logits/rejected": -0.6714210510253906,
      "logps/chosen": -161.29287719726562,
      "logps/rejected": -150.70846557617188,
      "loss": 0.3506,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.4287323951721191,
      "rewards/margins": 1.8808494806289673,
      "rewards/rejected": -3.309581756591797,
      "step": 10700
    },
    {
      "epoch": 1.954557897618396,
      "grad_norm": 2.544455051422119,
      "learning_rate": 4.901009359515508e-05,
      "logits/chosen": -0.8755836486816406,
      "logits/rejected": -0.7143206596374512,
      "logps/chosen": -159.587890625,
      "logps/rejected": -155.41818237304688,
      "loss": 0.4838,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8779172897338867,
      "rewards/margins": 1.4472404718399048,
      "rewards/rejected": -3.325157642364502,
      "step": 10710
    },
    {
      "epoch": 1.9563828816497857,
      "grad_norm": 4.733287334442139,
      "learning_rate": 4.89807304092494e-05,
      "logits/chosen": -0.7782635688781738,
      "logits/rejected": -0.6217392086982727,
      "logps/chosen": -179.28802490234375,
      "logps/rejected": -181.17364501953125,
      "loss": 0.4429,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9080240726470947,
      "rewards/margins": 1.7761844396591187,
      "rewards/rejected": -3.684209108352661,
      "step": 10720
    },
    {
      "epoch": 1.9582078656811754,
      "grad_norm": 3.546691417694092,
      "learning_rate": 4.895136722334374e-05,
      "logits/chosen": -0.801643967628479,
      "logits/rejected": -0.5357929468154907,
      "logps/chosen": -169.86924743652344,
      "logps/rejected": -155.2530975341797,
      "loss": 0.3849,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.99300217628479,
      "rewards/margins": 1.9335542917251587,
      "rewards/rejected": -3.926556348800659,
      "step": 10730
    },
    {
      "epoch": 1.960032849712565,
      "grad_norm": 3.847139835357666,
      "learning_rate": 4.8922004037438065e-05,
      "logits/chosen": -0.8971148729324341,
      "logits/rejected": -0.7362886667251587,
      "logps/chosen": -158.61434936523438,
      "logps/rejected": -142.7834014892578,
      "loss": 0.4232,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.0834109783172607,
      "rewards/margins": 1.3484742641448975,
      "rewards/rejected": -3.431884765625,
      "step": 10740
    },
    {
      "epoch": 1.9618578337439547,
      "grad_norm": 3.189476251602173,
      "learning_rate": 4.8892640851532396e-05,
      "logits/chosen": -0.9062978625297546,
      "logits/rejected": -0.7927637100219727,
      "logps/chosen": -160.61749267578125,
      "logps/rejected": -160.20028686523438,
      "loss": 0.4691,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.3027689456939697,
      "rewards/margins": 1.4005491733551025,
      "rewards/rejected": -3.7033181190490723,
      "step": 10750
    },
    {
      "epoch": 1.9636828177753445,
      "grad_norm": 3.786440134048462,
      "learning_rate": 4.886327766562672e-05,
      "logits/chosen": -0.8212659955024719,
      "logits/rejected": -0.6822653412818909,
      "logps/chosen": -177.57667541503906,
      "logps/rejected": -175.61351013183594,
      "loss": 0.4711,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.1977758407592773,
      "rewards/margins": 1.6136653423309326,
      "rewards/rejected": -3.811440944671631,
      "step": 10760
    },
    {
      "epoch": 1.9655078018067342,
      "grad_norm": 5.618334770202637,
      "learning_rate": 4.883391447972106e-05,
      "logits/chosen": -0.8995960354804993,
      "logits/rejected": -0.7333115339279175,
      "logps/chosen": -151.79110717773438,
      "logps/rejected": -155.38967895507812,
      "loss": 0.3679,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.952035903930664,
      "rewards/margins": 1.9798768758773804,
      "rewards/rejected": -3.931912660598755,
      "step": 10770
    },
    {
      "epoch": 1.9673327858381238,
      "grad_norm": 3.3577895164489746,
      "learning_rate": 4.880455129381538e-05,
      "logits/chosen": -0.9850627779960632,
      "logits/rejected": -0.8315289616584778,
      "logps/chosen": -181.82669067382812,
      "logps/rejected": -167.84144592285156,
      "loss": 0.3938,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.311661958694458,
      "rewards/margins": 1.7076761722564697,
      "rewards/rejected": -4.019338130950928,
      "step": 10780
    },
    {
      "epoch": 1.9691577698695135,
      "grad_norm": 3.017686128616333,
      "learning_rate": 4.877518810790971e-05,
      "logits/chosen": -0.8601466417312622,
      "logits/rejected": -0.8150070309638977,
      "logps/chosen": -165.61416625976562,
      "logps/rejected": -164.26901245117188,
      "loss": 0.5422,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.4499213695526123,
      "rewards/margins": 1.3250705003738403,
      "rewards/rejected": -3.774991273880005,
      "step": 10790
    },
    {
      "epoch": 1.9709827539009033,
      "grad_norm": 3.106762170791626,
      "learning_rate": 4.8745824922004046e-05,
      "logits/chosen": -0.918787956237793,
      "logits/rejected": -0.8220866918563843,
      "logps/chosen": -164.88320922851562,
      "logps/rejected": -159.435302734375,
      "loss": 0.5386,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9960777759552002,
      "rewards/margins": 1.3956111669540405,
      "rewards/rejected": -3.391688585281372,
      "step": 10800
    },
    {
      "epoch": 1.972807737932293,
      "grad_norm": 2.191593647003174,
      "learning_rate": 4.871646173609837e-05,
      "logits/chosen": -0.8967521786689758,
      "logits/rejected": -0.7866909503936768,
      "logps/chosen": -154.69837951660156,
      "logps/rejected": -163.7462921142578,
      "loss": 0.3823,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7838232517242432,
      "rewards/margins": 1.5489919185638428,
      "rewards/rejected": -3.3328146934509277,
      "step": 10810
    },
    {
      "epoch": 1.9746327219636828,
      "grad_norm": 6.194456100463867,
      "learning_rate": 4.86870985501927e-05,
      "logits/chosen": -0.994796097278595,
      "logits/rejected": -0.7911322712898254,
      "logps/chosen": -161.45352172851562,
      "logps/rejected": -158.58694458007812,
      "loss": 0.3376,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.549975037574768,
      "rewards/margins": 2.243701696395874,
      "rewards/rejected": -3.7936768531799316,
      "step": 10820
    },
    {
      "epoch": 1.9764577059950725,
      "grad_norm": 6.308773517608643,
      "learning_rate": 4.8657735364287026e-05,
      "logits/chosen": -1.0360605716705322,
      "logits/rejected": -0.9345577359199524,
      "logps/chosen": -180.02725219726562,
      "logps/rejected": -173.8331756591797,
      "loss": 0.6197,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.2989917993545532,
      "rewards/margins": 1.4444389343261719,
      "rewards/rejected": -2.7434308528900146,
      "step": 10830
    },
    {
      "epoch": 1.9782826900264623,
      "grad_norm": 2.957702398300171,
      "learning_rate": 4.8628372178381365e-05,
      "logits/chosen": -0.9421728253364563,
      "logits/rejected": -0.7543922662734985,
      "logps/chosen": -164.7067108154297,
      "logps/rejected": -158.7349090576172,
      "loss": 0.3752,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5853307247161865,
      "rewards/margins": 1.915917992591858,
      "rewards/rejected": -3.501248836517334,
      "step": 10840
    },
    {
      "epoch": 1.980107674057852,
      "grad_norm": 2.873953104019165,
      "learning_rate": 4.859900899247569e-05,
      "logits/chosen": -0.9822731018066406,
      "logits/rejected": -0.8517709970474243,
      "logps/chosen": -157.5792694091797,
      "logps/rejected": -154.2222442626953,
      "loss": 0.3838,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.430928349494934,
      "rewards/margins": 1.5691163539886475,
      "rewards/rejected": -3.000044822692871,
      "step": 10850
    },
    {
      "epoch": 1.9819326580892418,
      "grad_norm": 4.653965950012207,
      "learning_rate": 4.8569645806570014e-05,
      "logits/chosen": -0.9794025421142578,
      "logits/rejected": -0.8867707252502441,
      "logps/chosen": -148.08651733398438,
      "logps/rejected": -163.6849365234375,
      "loss": 0.4079,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5211360454559326,
      "rewards/margins": 1.7299751043319702,
      "rewards/rejected": -3.2511112689971924,
      "step": 10860
    },
    {
      "epoch": 1.9837576421206315,
      "grad_norm": 3.4281506538391113,
      "learning_rate": 4.8540282620664345e-05,
      "logits/chosen": -1.0076982975006104,
      "logits/rejected": -0.9354092478752136,
      "logps/chosen": -152.19140625,
      "logps/rejected": -162.93661499023438,
      "loss": 0.5768,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7558389902114868,
      "rewards/margins": 1.2636054754257202,
      "rewards/rejected": -3.019444465637207,
      "step": 10870
    },
    {
      "epoch": 1.9855826261520213,
      "grad_norm": 2.7396364212036133,
      "learning_rate": 4.851385575334925e-05,
      "logits/chosen": -1.0557982921600342,
      "logits/rejected": -0.9221097826957703,
      "logps/chosen": -184.50205993652344,
      "logps/rejected": -159.77438354492188,
      "loss": 0.4475,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6699864864349365,
      "rewards/margins": 1.2857669591903687,
      "rewards/rejected": -2.9557533264160156,
      "step": 10880
    },
    {
      "epoch": 1.987407610183411,
      "grad_norm": 2.6957571506500244,
      "learning_rate": 4.848449256744357e-05,
      "logits/chosen": -0.9724753499031067,
      "logits/rejected": -0.7963169813156128,
      "logps/chosen": -171.12220764160156,
      "logps/rejected": -171.98233032226562,
      "loss": 0.3958,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8773233890533447,
      "rewards/margins": 1.5959256887435913,
      "rewards/rejected": -3.4732487201690674,
      "step": 10890
    },
    {
      "epoch": 1.9892325942148006,
      "grad_norm": 2.0106077194213867,
      "learning_rate": 4.84551293815379e-05,
      "logits/chosen": -0.9841340780258179,
      "logits/rejected": -0.8475261926651001,
      "logps/chosen": -156.89161682128906,
      "logps/rejected": -146.25355529785156,
      "loss": 0.4058,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7580175399780273,
      "rewards/margins": 1.6380592584609985,
      "rewards/rejected": -3.3960769176483154,
      "step": 10900
    },
    {
      "epoch": 1.9910575782461903,
      "grad_norm": 5.018434524536133,
      "learning_rate": 4.842576619563223e-05,
      "logits/chosen": -0.9992120862007141,
      "logits/rejected": -0.859732449054718,
      "logps/chosen": -186.0130157470703,
      "logps/rejected": -173.66574096679688,
      "loss": 0.4399,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6454395055770874,
      "rewards/margins": 1.7531249523162842,
      "rewards/rejected": -3.398564577102661,
      "step": 10910
    },
    {
      "epoch": 1.99288256227758,
      "grad_norm": 4.022810935974121,
      "learning_rate": 4.8396403009726565e-05,
      "logits/chosen": -0.9772774577140808,
      "logits/rejected": -0.897689163684845,
      "logps/chosen": -165.98501586914062,
      "logps/rejected": -160.66758728027344,
      "loss": 0.5091,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.889100432395935,
      "rewards/margins": 1.1977938413619995,
      "rewards/rejected": -3.0868945121765137,
      "step": 10920
    },
    {
      "epoch": 1.9947075463089698,
      "grad_norm": 4.859121799468994,
      "learning_rate": 4.836703982382089e-05,
      "logits/chosen": -0.9898250699043274,
      "logits/rejected": -0.8793845176696777,
      "logps/chosen": -163.284912109375,
      "logps/rejected": -158.95358276367188,
      "loss": 0.4292,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.0325160026550293,
      "rewards/margins": 1.793239951133728,
      "rewards/rejected": -3.8257555961608887,
      "step": 10930
    },
    {
      "epoch": 1.9965325303403594,
      "grad_norm": 3.085678815841675,
      "learning_rate": 4.8337676637915214e-05,
      "logits/chosen": -0.8979531526565552,
      "logits/rejected": -0.769736647605896,
      "logps/chosen": -161.7999725341797,
      "logps/rejected": -155.6096954345703,
      "loss": 0.3934,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.1048996448516846,
      "rewards/margins": 1.7429507970809937,
      "rewards/rejected": -3.847850799560547,
      "step": 10940
    },
    {
      "epoch": 1.9983575143717491,
      "grad_norm": 2.889564037322998,
      "learning_rate": 4.8308313452009546e-05,
      "logits/chosen": -1.02041494846344,
      "logits/rejected": -0.9410462379455566,
      "logps/chosen": -173.9781951904297,
      "logps/rejected": -166.60267639160156,
      "loss": 0.4345,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.2683262825012207,
      "rewards/margins": 1.3857886791229248,
      "rewards/rejected": -3.6541152000427246,
      "step": 10950
    },
    {
      "epoch": 2.000182498403139,
      "grad_norm": 2.9862420558929443,
      "learning_rate": 4.827895026610388e-05,
      "logits/chosen": -0.9406806230545044,
      "logits/rejected": -0.8274402618408203,
      "logps/chosen": -161.8750457763672,
      "logps/rejected": -153.6890411376953,
      "loss": 0.4399,
      "rewards/accuracies": 0.7791666984558105,
      "rewards/chosen": -2.165620803833008,
      "rewards/margins": 1.5361307859420776,
      "rewards/rejected": -3.701751708984375,
      "step": 10960
    },
    {
      "epoch": 2.0020074824345286,
      "grad_norm": 4.0206522941589355,
      "learning_rate": 4.824958708019821e-05,
      "logits/chosen": -1.00265371799469,
      "logits/rejected": -0.8636611104011536,
      "logps/chosen": -184.91827392578125,
      "logps/rejected": -185.4206085205078,
      "loss": 0.2305,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.7335971593856812,
      "rewards/margins": 2.6918747425079346,
      "rewards/rejected": -4.425471782684326,
      "step": 10970
    },
    {
      "epoch": 2.0038324664659184,
      "grad_norm": 4.704131126403809,
      "learning_rate": 4.822022389429253e-05,
      "logits/chosen": -0.9556711316108704,
      "logits/rejected": -0.8629730343818665,
      "logps/chosen": -166.55886840820312,
      "logps/rejected": -164.4969940185547,
      "loss": 0.4445,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.1272759437561035,
      "rewards/margins": 1.3591047525405884,
      "rewards/rejected": -3.4863808155059814,
      "step": 10980
    },
    {
      "epoch": 2.005657450497308,
      "grad_norm": 1.8522872924804688,
      "learning_rate": 4.819086070838686e-05,
      "logits/chosen": -0.9231324195861816,
      "logits/rejected": -0.8048051595687866,
      "logps/chosen": -175.69949340820312,
      "logps/rejected": -169.07806396484375,
      "loss": 0.33,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.029693841934204,
      "rewards/margins": 2.0159647464752197,
      "rewards/rejected": -4.045659065246582,
      "step": 10990
    },
    {
      "epoch": 2.007482434528698,
      "grad_norm": 2.7464520931243896,
      "learning_rate": 4.8161497522481196e-05,
      "logits/chosen": -0.9453096389770508,
      "logits/rejected": -0.8193637132644653,
      "logps/chosen": -159.3949432373047,
      "logps/rejected": -159.34957885742188,
      "loss": 0.3125,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1873281002044678,
      "rewards/margins": 2.012791156768799,
      "rewards/rejected": -4.200119495391846,
      "step": 11000
    },
    {
      "epoch": 2.0093074185600877,
      "grad_norm": 2.466142416000366,
      "learning_rate": 4.813213433657552e-05,
      "logits/chosen": -0.9361087679862976,
      "logits/rejected": -0.7359268665313721,
      "logps/chosen": -168.69174194335938,
      "logps/rejected": -175.3530731201172,
      "loss": 0.1732,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.9134349822998047,
      "rewards/margins": 2.7759103775024414,
      "rewards/rejected": -4.689345359802246,
      "step": 11010
    },
    {
      "epoch": 2.0111324025914774,
      "grad_norm": 1.7098941802978516,
      "learning_rate": 4.810277115066985e-05,
      "logits/chosen": -0.8817442059516907,
      "logits/rejected": -0.763609766960144,
      "logps/chosen": -177.60427856445312,
      "logps/rejected": -181.7240447998047,
      "loss": 0.3785,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.5182790756225586,
      "rewards/margins": 2.090794801712036,
      "rewards/rejected": -4.609074115753174,
      "step": 11020
    },
    {
      "epoch": 2.012957386622867,
      "grad_norm": 4.49768590927124,
      "learning_rate": 4.807340796476418e-05,
      "logits/chosen": -0.8452345132827759,
      "logits/rejected": -0.7466391324996948,
      "logps/chosen": -168.04513549804688,
      "logps/rejected": -176.4070281982422,
      "loss": 0.3053,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.941873073577881,
      "rewards/margins": 2.1813137531280518,
      "rewards/rejected": -5.123187065124512,
      "step": 11030
    },
    {
      "epoch": 2.014782370654257,
      "grad_norm": 3.321904420852661,
      "learning_rate": 4.8044044778858514e-05,
      "logits/chosen": -0.9615486860275269,
      "logits/rejected": -0.7984465956687927,
      "logps/chosen": -161.79843139648438,
      "logps/rejected": -175.90049743652344,
      "loss": 0.2179,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.6916427612304688,
      "rewards/margins": 2.7503108978271484,
      "rewards/rejected": -5.441953659057617,
      "step": 11040
    },
    {
      "epoch": 2.0166073546856467,
      "grad_norm": 4.324514865875244,
      "learning_rate": 4.801468159295284e-05,
      "logits/chosen": -0.841529369354248,
      "logits/rejected": -0.689728856086731,
      "logps/chosen": -189.58177185058594,
      "logps/rejected": -197.71304321289062,
      "loss": 0.3629,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.0559463500976562,
      "rewards/margins": 2.354495048522949,
      "rewards/rejected": -5.4104413986206055,
      "step": 11050
    },
    {
      "epoch": 2.0184323387170364,
      "grad_norm": 3.157982587814331,
      "learning_rate": 4.7985318407047164e-05,
      "logits/chosen": -0.8507965207099915,
      "logits/rejected": -0.6490380167961121,
      "logps/chosen": -180.3185272216797,
      "logps/rejected": -171.7914276123047,
      "loss": 0.3243,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.744325637817383,
      "rewards/margins": 2.27231764793396,
      "rewards/rejected": -5.01664400100708,
      "step": 11060
    },
    {
      "epoch": 2.0202573227484257,
      "grad_norm": 4.267670154571533,
      "learning_rate": 4.79559552211415e-05,
      "logits/chosen": -0.8306698799133301,
      "logits/rejected": -0.6903353929519653,
      "logps/chosen": -176.79336547851562,
      "logps/rejected": -184.32864379882812,
      "loss": 0.3507,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4593470096588135,
      "rewards/margins": 2.3130249977111816,
      "rewards/rejected": -4.772372245788574,
      "step": 11070
    },
    {
      "epoch": 2.0220823067798155,
      "grad_norm": 2.2580833435058594,
      "learning_rate": 4.7926592035235826e-05,
      "logits/chosen": -0.9486898183822632,
      "logits/rejected": -0.653938889503479,
      "logps/chosen": -185.04220581054688,
      "logps/rejected": -178.8876495361328,
      "loss": 0.1668,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -1.6708961725234985,
      "rewards/margins": 3.086590051651001,
      "rewards/rejected": -4.757486343383789,
      "step": 11080
    },
    {
      "epoch": 2.0239072908112052,
      "grad_norm": 5.905601501464844,
      "learning_rate": 4.789722884933016e-05,
      "logits/chosen": -0.7398231625556946,
      "logits/rejected": -0.6655824780464172,
      "logps/chosen": -165.0732421875,
      "logps/rejected": -191.2904052734375,
      "loss": 0.3384,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.047211170196533,
      "rewards/margins": 2.2504069805145264,
      "rewards/rejected": -5.297618389129639,
      "step": 11090
    },
    {
      "epoch": 2.025732274842595,
      "grad_norm": 2.5686700344085693,
      "learning_rate": 4.786786566342448e-05,
      "logits/chosen": -0.9185886383056641,
      "logits/rejected": -0.820530891418457,
      "logps/chosen": -181.55398559570312,
      "logps/rejected": -202.23214721679688,
      "loss": 0.207,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.514256238937378,
      "rewards/margins": 2.7400848865509033,
      "rewards/rejected": -5.254340648651123,
      "step": 11100
    },
    {
      "epoch": 2.0275572588739847,
      "grad_norm": 4.647547721862793,
      "learning_rate": 4.783850247751882e-05,
      "logits/chosen": -0.9383803606033325,
      "logits/rejected": -0.7721745371818542,
      "logps/chosen": -171.4166259765625,
      "logps/rejected": -183.311767578125,
      "loss": 0.1738,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.149674415588379,
      "rewards/margins": 3.248272657394409,
      "rewards/rejected": -5.397947788238525,
      "step": 11110
    },
    {
      "epoch": 2.0293822429053745,
      "grad_norm": 5.264084815979004,
      "learning_rate": 4.7809139291613145e-05,
      "logits/chosen": -0.9170470237731934,
      "logits/rejected": -0.6971664428710938,
      "logps/chosen": -179.65000915527344,
      "logps/rejected": -189.6792755126953,
      "loss": 0.2864,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.514692783355713,
      "rewards/margins": 2.826214551925659,
      "rewards/rejected": -5.340906620025635,
      "step": 11120
    },
    {
      "epoch": 2.0312072269367643,
      "grad_norm": 3.5180115699768066,
      "learning_rate": 4.777977610570747e-05,
      "logits/chosen": -0.9206428527832031,
      "logits/rejected": -0.7406994104385376,
      "logps/chosen": -180.85072326660156,
      "logps/rejected": -180.72225952148438,
      "loss": 0.3332,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.6872670650482178,
      "rewards/margins": 2.3708436489105225,
      "rewards/rejected": -5.05811071395874,
      "step": 11130
    },
    {
      "epoch": 2.033032210968154,
      "grad_norm": 0.9128323197364807,
      "learning_rate": 4.77504129198018e-05,
      "logits/chosen": -0.8327935338020325,
      "logits/rejected": -0.6882308125495911,
      "logps/chosen": -185.27719116210938,
      "logps/rejected": -195.2984619140625,
      "loss": 0.2123,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.3095810413360596,
      "rewards/margins": 2.8226547241210938,
      "rewards/rejected": -5.132235527038574,
      "step": 11140
    },
    {
      "epoch": 2.0348571949995438,
      "grad_norm": 2.2006614208221436,
      "learning_rate": 4.772104973389613e-05,
      "logits/chosen": -0.9035993814468384,
      "logits/rejected": -0.7519180178642273,
      "logps/chosen": -177.6427764892578,
      "logps/rejected": -186.60475158691406,
      "loss": 0.2273,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.502573013305664,
      "rewards/margins": 2.937892436981201,
      "rewards/rejected": -5.440464973449707,
      "step": 11150
    },
    {
      "epoch": 2.0366821790309335,
      "grad_norm": 3.27620530128479,
      "learning_rate": 4.7691686547990463e-05,
      "logits/chosen": -0.8358815908432007,
      "logits/rejected": -0.7451026439666748,
      "logps/chosen": -170.5209197998047,
      "logps/rejected": -185.4712677001953,
      "loss": 0.3701,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.295886516571045,
      "rewards/margins": 2.1903977394104004,
      "rewards/rejected": -5.486283779144287,
      "step": 11160
    },
    {
      "epoch": 2.0385071630623233,
      "grad_norm": 2.2980825901031494,
      "learning_rate": 4.766232336208479e-05,
      "logits/chosen": -0.9269145727157593,
      "logits/rejected": -0.7832823991775513,
      "logps/chosen": -177.17079162597656,
      "logps/rejected": -172.9226837158203,
      "loss": 0.3277,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.0771093368530273,
      "rewards/margins": 2.18156099319458,
      "rewards/rejected": -5.258670330047607,
      "step": 11170
    },
    {
      "epoch": 2.040332147093713,
      "grad_norm": 2.019979238510132,
      "learning_rate": 4.763296017617911e-05,
      "logits/chosen": -0.9346439242362976,
      "logits/rejected": -0.8049826622009277,
      "logps/chosen": -166.24798583984375,
      "logps/rejected": -182.67962646484375,
      "loss": 0.2611,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2806568145751953,
      "rewards/margins": 2.6853222846984863,
      "rewards/rejected": -4.96597957611084,
      "step": 11180
    },
    {
      "epoch": 2.0421571311251028,
      "grad_norm": 1.23842191696167,
      "learning_rate": 4.760359699027345e-05,
      "logits/chosen": -0.8947038650512695,
      "logits/rejected": -0.7290595769882202,
      "logps/chosen": -180.3114471435547,
      "logps/rejected": -190.1239013671875,
      "loss": 0.1668,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.9299168586730957,
      "rewards/margins": 3.3072457313537598,
      "rewards/rejected": -6.237162113189697,
      "step": 11190
    },
    {
      "epoch": 2.0439821151564925,
      "grad_norm": 3.9721014499664307,
      "learning_rate": 4.7574233804367775e-05,
      "logits/chosen": -0.7722517251968384,
      "logits/rejected": -0.5103170871734619,
      "logps/chosen": -164.82705688476562,
      "logps/rejected": -171.324462890625,
      "loss": 0.1769,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.412214756011963,
      "rewards/margins": 3.3002769947052,
      "rewards/rejected": -6.7124924659729,
      "step": 11200
    },
    {
      "epoch": 2.0458070991878823,
      "grad_norm": 5.701937675476074,
      "learning_rate": 4.754487061846211e-05,
      "logits/chosen": -0.8120640516281128,
      "logits/rejected": -0.6485363245010376,
      "logps/chosen": -172.01007080078125,
      "logps/rejected": -176.25918579101562,
      "loss": 0.4292,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.704028367996216,
      "rewards/margins": 2.158705711364746,
      "rewards/rejected": -4.862734794616699,
      "step": 11210
    },
    {
      "epoch": 2.047632083219272,
      "grad_norm": 3.034442663192749,
      "learning_rate": 4.751550743255644e-05,
      "logits/chosen": -0.7463478446006775,
      "logits/rejected": -0.5685945749282837,
      "logps/chosen": -163.26101684570312,
      "logps/rejected": -164.52944946289062,
      "loss": 0.243,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.1652629375457764,
      "rewards/margins": 2.3681578636169434,
      "rewards/rejected": -5.533421516418457,
      "step": 11220
    },
    {
      "epoch": 2.0494570672506613,
      "grad_norm": 1.3721880912780762,
      "learning_rate": 4.748614424665077e-05,
      "logits/chosen": -0.9802840948104858,
      "logits/rejected": -0.725349485874176,
      "logps/chosen": -181.57139587402344,
      "logps/rejected": -178.26516723632812,
      "loss": 0.2288,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.1932311058044434,
      "rewards/margins": 3.208012104034424,
      "rewards/rejected": -5.401243209838867,
      "step": 11230
    },
    {
      "epoch": 2.051282051282051,
      "grad_norm": 3.477811574935913,
      "learning_rate": 4.7456781060745094e-05,
      "logits/chosen": -0.8089726567268372,
      "logits/rejected": -0.7407901287078857,
      "logps/chosen": -157.97158813476562,
      "logps/rejected": -176.5093536376953,
      "loss": 0.5069,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.4627647399902344,
      "rewards/margins": 1.8264760971069336,
      "rewards/rejected": -5.289240837097168,
      "step": 11240
    },
    {
      "epoch": 2.053107035313441,
      "grad_norm": 5.857339382171631,
      "learning_rate": 4.742741787483942e-05,
      "logits/chosen": -0.8860365152359009,
      "logits/rejected": -0.71113121509552,
      "logps/chosen": -190.73574829101562,
      "logps/rejected": -196.60272216796875,
      "loss": 0.2892,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.8541009426116943,
      "rewards/margins": 2.612734317779541,
      "rewards/rejected": -5.466835021972656,
      "step": 11250
    },
    {
      "epoch": 2.0549320193448306,
      "grad_norm": 3.648160457611084,
      "learning_rate": 4.739805468893376e-05,
      "logits/chosen": -0.903465747833252,
      "logits/rejected": -0.7440172433853149,
      "logps/chosen": -176.04429626464844,
      "logps/rejected": -177.5970916748047,
      "loss": 0.216,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.7570037841796875,
      "rewards/margins": 2.7372429370880127,
      "rewards/rejected": -5.494246482849121,
      "step": 11260
    },
    {
      "epoch": 2.0567570033762204,
      "grad_norm": 4.792855262756348,
      "learning_rate": 4.736869150302808e-05,
      "logits/chosen": -0.9023900032043457,
      "logits/rejected": -0.8120924234390259,
      "logps/chosen": -171.16867065429688,
      "logps/rejected": -189.34408569335938,
      "loss": 0.3696,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4324874877929688,
      "rewards/margins": 2.2170517444610596,
      "rewards/rejected": -4.649539470672607,
      "step": 11270
    },
    {
      "epoch": 2.05858198740761,
      "grad_norm": 3.928311824798584,
      "learning_rate": 4.733932831712241e-05,
      "logits/chosen": -0.9074169397354126,
      "logits/rejected": -0.7413555979728699,
      "logps/chosen": -169.5259246826172,
      "logps/rejected": -177.92294311523438,
      "loss": 0.4454,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.727731227874756,
      "rewards/margins": 2.282458782196045,
      "rewards/rejected": -5.010190486907959,
      "step": 11280
    },
    {
      "epoch": 2.060406971439,
      "grad_norm": 5.2240495681762695,
      "learning_rate": 4.730996513121674e-05,
      "logits/chosen": -0.834065318107605,
      "logits/rejected": -0.7407434582710266,
      "logps/chosen": -168.89085388183594,
      "logps/rejected": -179.43197631835938,
      "loss": 0.4411,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.8085310459136963,
      "rewards/margins": 1.8148996829986572,
      "rewards/rejected": -4.623431205749512,
      "step": 11290
    },
    {
      "epoch": 2.0622319554703896,
      "grad_norm": 4.388286590576172,
      "learning_rate": 4.7280601945311075e-05,
      "logits/chosen": -0.919283390045166,
      "logits/rejected": -0.6492131948471069,
      "logps/chosen": -183.77029418945312,
      "logps/rejected": -170.10546875,
      "loss": 0.1923,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -2.5950429439544678,
      "rewards/margins": 2.760108232498169,
      "rewards/rejected": -5.355151176452637,
      "step": 11300
    },
    {
      "epoch": 2.0640569395017794,
      "grad_norm": 4.1302080154418945,
      "learning_rate": 4.72512387594054e-05,
      "logits/chosen": -0.7603809237480164,
      "logits/rejected": -0.6289986371994019,
      "logps/chosen": -157.76132202148438,
      "logps/rejected": -180.43453979492188,
      "loss": 0.2804,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.6992151737213135,
      "rewards/margins": 2.870405435562134,
      "rewards/rejected": -5.569620609283447,
      "step": 11310
    },
    {
      "epoch": 2.065881923533169,
      "grad_norm": 3.70737886428833,
      "learning_rate": 4.7221875573499724e-05,
      "logits/chosen": -0.871199905872345,
      "logits/rejected": -0.6655958890914917,
      "logps/chosen": -163.91110229492188,
      "logps/rejected": -158.16159057617188,
      "loss": 0.3618,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.0577139854431152,
      "rewards/margins": 2.256831407546997,
      "rewards/rejected": -4.314545631408691,
      "step": 11320
    },
    {
      "epoch": 2.067706907564559,
      "grad_norm": 6.223038673400879,
      "learning_rate": 4.7192512387594056e-05,
      "logits/chosen": -0.8407586216926575,
      "logits/rejected": -0.6967983841896057,
      "logps/chosen": -184.15206909179688,
      "logps/rejected": -176.51919555664062,
      "loss": 0.3287,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.551384925842285,
      "rewards/margins": 2.059204578399658,
      "rewards/rejected": -4.610589504241943,
      "step": 11330
    },
    {
      "epoch": 2.0695318915959486,
      "grad_norm": 2.4849579334259033,
      "learning_rate": 4.716314920168839e-05,
      "logits/chosen": -0.7923370003700256,
      "logits/rejected": -0.6182488203048706,
      "logps/chosen": -175.35202026367188,
      "logps/rejected": -178.19810485839844,
      "loss": 0.252,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.6592774391174316,
      "rewards/margins": 2.5988001823425293,
      "rewards/rejected": -5.258077621459961,
      "step": 11340
    },
    {
      "epoch": 2.0713568756273384,
      "grad_norm": 4.667974948883057,
      "learning_rate": 4.713378601578272e-05,
      "logits/chosen": -0.7769020795822144,
      "logits/rejected": -0.5508897304534912,
      "logps/chosen": -183.40711975097656,
      "logps/rejected": -173.41647338867188,
      "loss": 0.3124,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.646573305130005,
      "rewards/margins": 2.1949362754821777,
      "rewards/rejected": -4.841508865356445,
      "step": 11350
    },
    {
      "epoch": 2.073181859658728,
      "grad_norm": 4.562648773193359,
      "learning_rate": 4.710442282987704e-05,
      "logits/chosen": -0.6408452987670898,
      "logits/rejected": -0.4653531014919281,
      "logps/chosen": -180.87173461914062,
      "logps/rejected": -183.07070922851562,
      "loss": 0.3046,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.0739951133728027,
      "rewards/margins": 2.3981759548187256,
      "rewards/rejected": -5.472170829772949,
      "step": 11360
    },
    {
      "epoch": 2.075006843690118,
      "grad_norm": 5.3841938972473145,
      "learning_rate": 4.707505964397138e-05,
      "logits/chosen": -0.6712086796760559,
      "logits/rejected": -0.53619784116745,
      "logps/chosen": -167.57015991210938,
      "logps/rejected": -179.68817138671875,
      "loss": 0.3086,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.260810136795044,
      "rewards/margins": 2.761328935623169,
      "rewards/rejected": -6.022139072418213,
      "step": 11370
    },
    {
      "epoch": 2.0768318277215077,
      "grad_norm": 3.8994510173797607,
      "learning_rate": 4.7045696458065706e-05,
      "logits/chosen": -0.7604044079780579,
      "logits/rejected": -0.5828434824943542,
      "logps/chosen": -176.16549682617188,
      "logps/rejected": -184.5384063720703,
      "loss": 0.2252,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.789437770843506,
      "rewards/margins": 2.8315701484680176,
      "rewards/rejected": -5.621007919311523,
      "step": 11380
    },
    {
      "epoch": 2.078656811752897,
      "grad_norm": 3.3700244426727295,
      "learning_rate": 4.701633327216003e-05,
      "logits/chosen": -0.80792236328125,
      "logits/rejected": -0.6870784163475037,
      "logps/chosen": -169.90249633789062,
      "logps/rejected": -198.48818969726562,
      "loss": 0.2987,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.4418766498565674,
      "rewards/margins": 2.9138264656066895,
      "rewards/rejected": -5.355702877044678,
      "step": 11390
    },
    {
      "epoch": 2.0804817957842867,
      "grad_norm": 6.887240886688232,
      "learning_rate": 4.698697008625436e-05,
      "logits/chosen": -0.8687082529067993,
      "logits/rejected": -0.6650433540344238,
      "logps/chosen": -171.8711700439453,
      "logps/rejected": -186.88626098632812,
      "loss": 0.3448,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.600632429122925,
      "rewards/margins": 2.854551315307617,
      "rewards/rejected": -5.455183982849121,
      "step": 11400
    },
    {
      "epoch": 2.0823067798156765,
      "grad_norm": 1.5525974035263062,
      "learning_rate": 4.695760690034869e-05,
      "logits/chosen": -0.8209400177001953,
      "logits/rejected": -0.638821005821228,
      "logps/chosen": -190.1111297607422,
      "logps/rejected": -188.65325927734375,
      "loss": 0.2464,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.562189817428589,
      "rewards/margins": 2.765472888946533,
      "rewards/rejected": -5.327663421630859,
      "step": 11410
    },
    {
      "epoch": 2.084131763847066,
      "grad_norm": 5.315143585205078,
      "learning_rate": 4.6928243714443024e-05,
      "logits/chosen": -0.7558001279830933,
      "logits/rejected": -0.5447959899902344,
      "logps/chosen": -180.5609588623047,
      "logps/rejected": -173.15036010742188,
      "loss": 0.3467,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.0882725715637207,
      "rewards/margins": 2.3076014518737793,
      "rewards/rejected": -5.395873546600342,
      "step": 11420
    },
    {
      "epoch": 2.085956747878456,
      "grad_norm": 2.971090316772461,
      "learning_rate": 4.689888052853735e-05,
      "logits/chosen": -0.9661127924919128,
      "logits/rejected": -0.9024428129196167,
      "logps/chosen": -177.88076782226562,
      "logps/rejected": -181.59690856933594,
      "loss": 0.5248,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.3501105308532715,
      "rewards/margins": 1.7284290790557861,
      "rewards/rejected": -4.078539848327637,
      "step": 11430
    },
    {
      "epoch": 2.0877817319098457,
      "grad_norm": 8.402434349060059,
      "learning_rate": 4.6869517342631673e-05,
      "logits/chosen": -0.9059662818908691,
      "logits/rejected": -0.7307857275009155,
      "logps/chosen": -169.77403259277344,
      "logps/rejected": -169.82083129882812,
      "loss": 0.3144,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2453958988189697,
      "rewards/margins": 2.1940078735351562,
      "rewards/rejected": -4.439403533935547,
      "step": 11440
    },
    {
      "epoch": 2.0896067159412355,
      "grad_norm": 3.4589812755584717,
      "learning_rate": 4.684015415672601e-05,
      "logits/chosen": -0.8378406763076782,
      "logits/rejected": -0.6840118169784546,
      "logps/chosen": -154.55599975585938,
      "logps/rejected": -163.6234893798828,
      "loss": 0.2941,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.7653305530548096,
      "rewards/margins": 2.4082653522491455,
      "rewards/rejected": -5.173595428466797,
      "step": 11450
    },
    {
      "epoch": 2.0914316999726252,
      "grad_norm": 7.692785739898682,
      "learning_rate": 4.6810790970820336e-05,
      "logits/chosen": -0.8699391484260559,
      "logits/rejected": -0.8082442283630371,
      "logps/chosen": -176.5182342529297,
      "logps/rejected": -206.19168090820312,
      "loss": 0.321,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.19380259513855,
      "rewards/margins": 2.2746031284332275,
      "rewards/rejected": -5.468405723571777,
      "step": 11460
    },
    {
      "epoch": 2.093256684004015,
      "grad_norm": 6.963125705718994,
      "learning_rate": 4.678142778491467e-05,
      "logits/chosen": -0.8498098254203796,
      "logits/rejected": -0.7027909159660339,
      "logps/chosen": -166.24110412597656,
      "logps/rejected": -179.80972290039062,
      "loss": 0.3778,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.4561469554901123,
      "rewards/margins": 2.116687297821045,
      "rewards/rejected": -5.572834491729736,
      "step": 11470
    },
    {
      "epoch": 2.0950816680354047,
      "grad_norm": 0.8622714877128601,
      "learning_rate": 4.675206459900899e-05,
      "logits/chosen": -0.9556323885917664,
      "logits/rejected": -0.6611062288284302,
      "logps/chosen": -199.15049743652344,
      "logps/rejected": -176.74591064453125,
      "loss": 0.2162,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -2.883695125579834,
      "rewards/margins": 2.5859434604644775,
      "rewards/rejected": -5.469639301300049,
      "step": 11480
    },
    {
      "epoch": 2.0969066520667945,
      "grad_norm": 5.541003227233887,
      "learning_rate": 4.672270141310333e-05,
      "logits/chosen": -0.8861532211303711,
      "logits/rejected": -0.6994872689247131,
      "logps/chosen": -168.1788787841797,
      "logps/rejected": -175.13070678710938,
      "loss": 0.1785,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -3.46787691116333,
      "rewards/margins": 2.719778299331665,
      "rewards/rejected": -6.187654972076416,
      "step": 11490
    },
    {
      "epoch": 2.0987316360981843,
      "grad_norm": 4.470088005065918,
      "learning_rate": 4.6693338227197655e-05,
      "logits/chosen": -0.8757190704345703,
      "logits/rejected": -0.8315346837043762,
      "logps/chosen": -174.7644500732422,
      "logps/rejected": -201.98190307617188,
      "loss": 0.2715,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.2918381690979004,
      "rewards/margins": 2.390219211578369,
      "rewards/rejected": -5.6820573806762695,
      "step": 11500
    },
    {
      "epoch": 2.100556620129574,
      "grad_norm": 9.221217155456543,
      "learning_rate": 4.666397504129198e-05,
      "logits/chosen": -0.9253943562507629,
      "logits/rejected": -0.7586915493011475,
      "logps/chosen": -169.44451904296875,
      "logps/rejected": -191.2091522216797,
      "loss": 0.2945,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.8800113201141357,
      "rewards/margins": 2.8988125324249268,
      "rewards/rejected": -5.7788238525390625,
      "step": 11510
    },
    {
      "epoch": 2.1023816041609638,
      "grad_norm": 6.843909740447998,
      "learning_rate": 4.663461185538631e-05,
      "logits/chosen": -0.9635930061340332,
      "logits/rejected": -0.7636271119117737,
      "logps/chosen": -213.78451538085938,
      "logps/rejected": -195.2668914794922,
      "loss": 0.2916,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.5163986682891846,
      "rewards/margins": 2.579608678817749,
      "rewards/rejected": -6.096007347106934,
      "step": 11520
    },
    {
      "epoch": 2.1042065881923535,
      "grad_norm": 4.959878921508789,
      "learning_rate": 4.660524866948064e-05,
      "logits/chosen": -0.8180863261222839,
      "logits/rejected": -0.7110638618469238,
      "logps/chosen": -175.47422790527344,
      "logps/rejected": -201.93170166015625,
      "loss": 0.2903,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.372344493865967,
      "rewards/margins": 3.10878324508667,
      "rewards/rejected": -6.481128692626953,
      "step": 11530
    },
    {
      "epoch": 2.106031572223743,
      "grad_norm": 3.1891798973083496,
      "learning_rate": 4.6575885483574973e-05,
      "logits/chosen": -0.8524258732795715,
      "logits/rejected": -0.638167142868042,
      "logps/chosen": -175.2665252685547,
      "logps/rejected": -177.99998474121094,
      "loss": 0.2724,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.1706972122192383,
      "rewards/margins": 2.5719809532165527,
      "rewards/rejected": -5.742678165435791,
      "step": 11540
    },
    {
      "epoch": 2.1078565562551326,
      "grad_norm": 3.184994697570801,
      "learning_rate": 4.65465222976693e-05,
      "logits/chosen": -0.7385218739509583,
      "logits/rejected": -0.548568606376648,
      "logps/chosen": -186.365478515625,
      "logps/rejected": -186.09725952148438,
      "loss": 0.1815,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -3.2558255195617676,
      "rewards/margins": 2.846008777618408,
      "rewards/rejected": -6.101834297180176,
      "step": 11550
    },
    {
      "epoch": 2.1096815402865223,
      "grad_norm": 3.6607587337493896,
      "learning_rate": 4.6517159111763636e-05,
      "logits/chosen": -0.8848415613174438,
      "logits/rejected": -0.5912333726882935,
      "logps/chosen": -191.05580139160156,
      "logps/rejected": -193.78018188476562,
      "loss": 0.1949,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.818297863006592,
      "rewards/margins": 3.596717119216919,
      "rewards/rejected": -6.41501522064209,
      "step": 11560
    },
    {
      "epoch": 2.111506524317912,
      "grad_norm": 2.2701497077941895,
      "learning_rate": 4.648779592585796e-05,
      "logits/chosen": -0.7949560880661011,
      "logits/rejected": -0.5402036905288696,
      "logps/chosen": -185.255126953125,
      "logps/rejected": -186.72921752929688,
      "loss": 0.2971,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.9546451568603516,
      "rewards/margins": 3.08878755569458,
      "rewards/rejected": -6.043432235717773,
      "step": 11570
    },
    {
      "epoch": 2.113331508349302,
      "grad_norm": 2.614461660385132,
      "learning_rate": 4.6458432739952285e-05,
      "logits/chosen": -0.8524497151374817,
      "logits/rejected": -0.6002166867256165,
      "logps/chosen": -194.3535919189453,
      "logps/rejected": -194.79847717285156,
      "loss": 0.2826,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.418710231781006,
      "rewards/margins": 3.0295050144195557,
      "rewards/rejected": -6.448215484619141,
      "step": 11580
    },
    {
      "epoch": 2.1151564923806916,
      "grad_norm": 4.966829776763916,
      "learning_rate": 4.642906955404662e-05,
      "logits/chosen": -0.895281970500946,
      "logits/rejected": -0.6583199501037598,
      "logps/chosen": -189.72097778320312,
      "logps/rejected": -180.98468017578125,
      "loss": 0.2853,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.082761526107788,
      "rewards/margins": 2.971705913543701,
      "rewards/rejected": -6.054467678070068,
      "step": 11590
    },
    {
      "epoch": 2.1169814764120813,
      "grad_norm": 2.211790084838867,
      "learning_rate": 4.639970636814095e-05,
      "logits/chosen": -0.9143978357315063,
      "logits/rejected": -0.7399577498435974,
      "logps/chosen": -190.48538208007812,
      "logps/rejected": -191.14794921875,
      "loss": 0.3617,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.63629412651062,
      "rewards/margins": 2.6459872722625732,
      "rewards/rejected": -6.282281398773193,
      "step": 11600
    },
    {
      "epoch": 2.118806460443471,
      "grad_norm": 4.769850730895996,
      "learning_rate": 4.637034318223528e-05,
      "logits/chosen": -0.8221007585525513,
      "logits/rejected": -0.6602374911308289,
      "logps/chosen": -179.26101684570312,
      "logps/rejected": -193.17608642578125,
      "loss": 0.2413,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -3.2199883460998535,
      "rewards/margins": 2.843543529510498,
      "rewards/rejected": -6.063531875610352,
      "step": 11610
    },
    {
      "epoch": 2.120631444474861,
      "grad_norm": 8.686467170715332,
      "learning_rate": 4.6340979996329604e-05,
      "logits/chosen": -0.8211122751235962,
      "logits/rejected": -0.7289284467697144,
      "logps/chosen": -189.91061401367188,
      "logps/rejected": -201.88034057617188,
      "loss": 0.3152,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.513396739959717,
      "rewards/margins": 2.7785069942474365,
      "rewards/rejected": -6.291903495788574,
      "step": 11620
    },
    {
      "epoch": 2.1224564285062506,
      "grad_norm": 4.136913776397705,
      "learning_rate": 4.631161681042393e-05,
      "logits/chosen": -0.7586946487426758,
      "logits/rejected": -0.7011021971702576,
      "logps/chosen": -156.56532287597656,
      "logps/rejected": -181.2555694580078,
      "loss": 0.4003,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.062039852142334,
      "rewards/margins": 2.005157947540283,
      "rewards/rejected": -5.067196846008301,
      "step": 11630
    },
    {
      "epoch": 2.1242814125376404,
      "grad_norm": 2.1866633892059326,
      "learning_rate": 4.628225362451827e-05,
      "logits/chosen": -0.9537493586540222,
      "logits/rejected": -0.7243857383728027,
      "logps/chosen": -173.1136016845703,
      "logps/rejected": -156.2947540283203,
      "loss": 0.2932,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.6087253093719482,
      "rewards/margins": 2.0932250022888184,
      "rewards/rejected": -4.701950550079346,
      "step": 11640
    },
    {
      "epoch": 2.12610639656903,
      "grad_norm": 3.3471364974975586,
      "learning_rate": 4.625289043861259e-05,
      "logits/chosen": -0.636516273021698,
      "logits/rejected": -0.5779858827590942,
      "logps/chosen": -182.04959106445312,
      "logps/rejected": -213.92422485351562,
      "loss": 0.2572,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.45149564743042,
      "rewards/margins": 2.7905259132385254,
      "rewards/rejected": -6.2420220375061035,
      "step": 11650
    },
    {
      "epoch": 2.12793138060042,
      "grad_norm": 3.3828964233398438,
      "learning_rate": 4.6226463571297486e-05,
      "logits/chosen": -0.6822385191917419,
      "logits/rejected": -0.48068803548812866,
      "logps/chosen": -189.4056396484375,
      "logps/rejected": -190.5864715576172,
      "loss": 0.3632,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -4.103096008300781,
      "rewards/margins": 2.6352806091308594,
      "rewards/rejected": -6.738376617431641,
      "step": 11660
    },
    {
      "epoch": 2.1297563646318096,
      "grad_norm": 4.468780994415283,
      "learning_rate": 4.619710038539182e-05,
      "logits/chosen": -0.6678848266601562,
      "logits/rejected": -0.5139912366867065,
      "logps/chosen": -180.54232788085938,
      "logps/rejected": -194.98922729492188,
      "loss": 0.1997,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -3.1966004371643066,
      "rewards/margins": 2.768368721008301,
      "rewards/rejected": -5.964968681335449,
      "step": 11670
    },
    {
      "epoch": 2.1315813486631994,
      "grad_norm": 2.9717071056365967,
      "learning_rate": 4.616773719948615e-05,
      "logits/chosen": -0.7892469763755798,
      "logits/rejected": -0.5316407680511475,
      "logps/chosen": -178.09779357910156,
      "logps/rejected": -202.5231475830078,
      "loss": 0.2499,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.5436177253723145,
      "rewards/margins": 3.008175849914551,
      "rewards/rejected": -6.551793098449707,
      "step": 11680
    },
    {
      "epoch": 2.133406332694589,
      "grad_norm": 7.165925025939941,
      "learning_rate": 4.613837401358048e-05,
      "logits/chosen": -0.7782489061355591,
      "logits/rejected": -0.6187471151351929,
      "logps/chosen": -181.53408813476562,
      "logps/rejected": -182.38497924804688,
      "loss": 0.3852,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.4251797199249268,
      "rewards/margins": 2.0570695400238037,
      "rewards/rejected": -5.4822492599487305,
      "step": 11690
    },
    {
      "epoch": 2.135231316725979,
      "grad_norm": 3.963139295578003,
      "learning_rate": 4.6109010827674805e-05,
      "logits/chosen": -0.6616045832633972,
      "logits/rejected": -0.5193344354629517,
      "logps/chosen": -169.23422241210938,
      "logps/rejected": -181.24063110351562,
      "loss": 0.2347,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.1719892024993896,
      "rewards/margins": 2.9544520378112793,
      "rewards/rejected": -6.12644100189209,
      "step": 11700
    },
    {
      "epoch": 2.137056300757368,
      "grad_norm": 3.9671947956085205,
      "learning_rate": 4.607964764176913e-05,
      "logits/chosen": -0.689900279045105,
      "logits/rejected": -0.486510694026947,
      "logps/chosen": -173.81129455566406,
      "logps/rejected": -186.71592712402344,
      "loss": 0.2601,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.098978042602539,
      "rewards/margins": 2.7947680950164795,
      "rewards/rejected": -5.893746376037598,
      "step": 11710
    },
    {
      "epoch": 2.138881284788758,
      "grad_norm": 1.2727086544036865,
      "learning_rate": 4.605028445586347e-05,
      "logits/chosen": -0.7972608804702759,
      "logits/rejected": -0.5627650618553162,
      "logps/chosen": -183.93875122070312,
      "logps/rejected": -182.27243041992188,
      "loss": 0.2071,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.511444091796875,
      "rewards/margins": 3.0914998054504395,
      "rewards/rejected": -5.602944374084473,
      "step": 11720
    },
    {
      "epoch": 2.1407062688201477,
      "grad_norm": 3.5870981216430664,
      "learning_rate": 4.602092126995779e-05,
      "logits/chosen": -0.7604089975357056,
      "logits/rejected": -0.4851214289665222,
      "logps/chosen": -195.391845703125,
      "logps/rejected": -201.62191772460938,
      "loss": 0.2592,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.234915256500244,
      "rewards/margins": 3.298326015472412,
      "rewards/rejected": -6.533242225646973,
      "step": 11730
    },
    {
      "epoch": 2.1425312528515374,
      "grad_norm": 6.409492492675781,
      "learning_rate": 4.599155808405212e-05,
      "logits/chosen": -0.6261996030807495,
      "logits/rejected": -0.5213394165039062,
      "logps/chosen": -166.34921264648438,
      "logps/rejected": -196.02076721191406,
      "loss": 0.3748,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.474391222000122,
      "rewards/margins": 2.891596794128418,
      "rewards/rejected": -6.365987777709961,
      "step": 11740
    },
    {
      "epoch": 2.144356236882927,
      "grad_norm": 3.229118824005127,
      "learning_rate": 4.596219489814645e-05,
      "logits/chosen": -0.7855943441390991,
      "logits/rejected": -0.7448784708976746,
      "logps/chosen": -172.82444763183594,
      "logps/rejected": -212.8843994140625,
      "loss": 0.2385,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.0481064319610596,
      "rewards/margins": 2.6008009910583496,
      "rewards/rejected": -5.64890718460083,
      "step": 11750
    },
    {
      "epoch": 2.146181220914317,
      "grad_norm": 6.269476413726807,
      "learning_rate": 4.5932831712240786e-05,
      "logits/chosen": -0.7893067598342896,
      "logits/rejected": -0.6604593396186829,
      "logps/chosen": -177.78514099121094,
      "logps/rejected": -201.150146484375,
      "loss": 0.3167,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.2850260734558105,
      "rewards/margins": 2.9270317554473877,
      "rewards/rejected": -6.212058067321777,
      "step": 11760
    },
    {
      "epoch": 2.1480062049457067,
      "grad_norm": 2.408693313598633,
      "learning_rate": 4.590346852633511e-05,
      "logits/chosen": -0.7506126165390015,
      "logits/rejected": -0.564493715763092,
      "logps/chosen": -176.9370880126953,
      "logps/rejected": -190.3300018310547,
      "loss": 0.2529,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.204918622970581,
      "rewards/margins": 2.553039312362671,
      "rewards/rejected": -5.757957458496094,
      "step": 11770
    },
    {
      "epoch": 2.1498311889770965,
      "grad_norm": 2.2246975898742676,
      "learning_rate": 4.5874105340429435e-05,
      "logits/chosen": -0.7664982676506042,
      "logits/rejected": -0.506725549697876,
      "logps/chosen": -173.53909301757812,
      "logps/rejected": -188.45455932617188,
      "loss": 0.2566,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.089679479598999,
      "rewards/margins": 3.0362253189086914,
      "rewards/rejected": -6.1259050369262695,
      "step": 11780
    },
    {
      "epoch": 2.151656173008486,
      "grad_norm": 3.344644784927368,
      "learning_rate": 4.584474215452377e-05,
      "logits/chosen": -0.8375242948532104,
      "logits/rejected": -0.5926703214645386,
      "logps/chosen": -185.65573120117188,
      "logps/rejected": -197.65982055664062,
      "loss": 0.264,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.5010876655578613,
      "rewards/margins": 3.2507567405700684,
      "rewards/rejected": -5.75184440612793,
      "step": 11790
    },
    {
      "epoch": 2.153481157039876,
      "grad_norm": 3.4942514896392822,
      "learning_rate": 4.58153789686181e-05,
      "logits/chosen": -0.6579838395118713,
      "logits/rejected": -0.42768335342407227,
      "logps/chosen": -182.07652282714844,
      "logps/rejected": -195.2007598876953,
      "loss": 0.2621,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.4620070457458496,
      "rewards/margins": 2.8182644844055176,
      "rewards/rejected": -6.280271053314209,
      "step": 11800
    },
    {
      "epoch": 2.1553061410712657,
      "grad_norm": 6.966980457305908,
      "learning_rate": 4.578601578271243e-05,
      "logits/chosen": -0.7221869826316833,
      "logits/rejected": -0.5782352089881897,
      "logps/chosen": -181.80075073242188,
      "logps/rejected": -198.51986694335938,
      "loss": 0.3256,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.1878952980041504,
      "rewards/margins": 2.7043089866638184,
      "rewards/rejected": -5.892205238342285,
      "step": 11810
    },
    {
      "epoch": 2.1571311251026555,
      "grad_norm": 1.7447227239608765,
      "learning_rate": 4.5756652596806754e-05,
      "logits/chosen": -0.7557780742645264,
      "logits/rejected": -0.5715340375900269,
      "logps/chosen": -177.5086669921875,
      "logps/rejected": -187.91281127929688,
      "loss": 0.2813,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.006859302520752,
      "rewards/margins": 2.781444549560547,
      "rewards/rejected": -5.788303852081299,
      "step": 11820
    },
    {
      "epoch": 2.1589561091340452,
      "grad_norm": 4.535478115081787,
      "learning_rate": 4.572728941090109e-05,
      "logits/chosen": -0.8350367546081543,
      "logits/rejected": -0.6051198840141296,
      "logps/chosen": -185.31338500976562,
      "logps/rejected": -187.50741577148438,
      "loss": 0.2186,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.149376630783081,
      "rewards/margins": 2.871127128601074,
      "rewards/rejected": -6.020503520965576,
      "step": 11830
    },
    {
      "epoch": 2.160781093165435,
      "grad_norm": 9.776022911071777,
      "learning_rate": 4.5697926224995416e-05,
      "logits/chosen": -0.5810545682907104,
      "logits/rejected": -0.4683360159397125,
      "logps/chosen": -176.4652099609375,
      "logps/rejected": -204.79531860351562,
      "loss": 0.1897,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.7053439617156982,
      "rewards/margins": 3.1712989807128906,
      "rewards/rejected": -6.87664270401001,
      "step": 11840
    },
    {
      "epoch": 2.1626060771968243,
      "grad_norm": 9.23449420928955,
      "learning_rate": 4.566856303908974e-05,
      "logits/chosen": -0.7740330696105957,
      "logits/rejected": -0.5463113784790039,
      "logps/chosen": -179.47589111328125,
      "logps/rejected": -190.38656616210938,
      "loss": 0.3864,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.677719831466675,
      "rewards/margins": 2.4078075885772705,
      "rewards/rejected": -6.085527420043945,
      "step": 11850
    },
    {
      "epoch": 2.164431061228214,
      "grad_norm": 6.321337699890137,
      "learning_rate": 4.563919985318407e-05,
      "logits/chosen": -0.6191099286079407,
      "logits/rejected": -0.39096611738204956,
      "logps/chosen": -191.88040161132812,
      "logps/rejected": -191.7138214111328,
      "loss": 0.2319,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.321625232696533,
      "rewards/margins": 3.627030849456787,
      "rewards/rejected": -6.948655605316162,
      "step": 11860
    },
    {
      "epoch": 2.166256045259604,
      "grad_norm": 3.3864336013793945,
      "learning_rate": 4.5609836667278404e-05,
      "logits/chosen": -0.6246240735054016,
      "logits/rejected": -0.4758062958717346,
      "logps/chosen": -165.52175903320312,
      "logps/rejected": -177.8154754638672,
      "loss": 0.2951,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.669022798538208,
      "rewards/margins": 2.338447332382202,
      "rewards/rejected": -6.007469177246094,
      "step": 11870
    },
    {
      "epoch": 2.1680810292909936,
      "grad_norm": 7.627488613128662,
      "learning_rate": 4.5580473481372735e-05,
      "logits/chosen": -0.581196665763855,
      "logits/rejected": -0.4936141073703766,
      "logps/chosen": -170.75497436523438,
      "logps/rejected": -205.21035766601562,
      "loss": 0.4019,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.559058666229248,
      "rewards/margins": 3.0954318046569824,
      "rewards/rejected": -6.6544904708862305,
      "step": 11880
    },
    {
      "epoch": 2.1699060133223833,
      "grad_norm": 1.9183604717254639,
      "learning_rate": 4.555111029546706e-05,
      "logits/chosen": -0.7191826105117798,
      "logits/rejected": -0.5177597999572754,
      "logps/chosen": -181.4974365234375,
      "logps/rejected": -199.9799346923828,
      "loss": 0.3491,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.6254830360412598,
      "rewards/margins": 2.7546164989471436,
      "rewards/rejected": -6.380100250244141,
      "step": 11890
    },
    {
      "epoch": 2.171730997353773,
      "grad_norm": 7.7890448570251465,
      "learning_rate": 4.5521747109561384e-05,
      "logits/chosen": -0.679463267326355,
      "logits/rejected": -0.6724513173103333,
      "logps/chosen": -178.09243774414062,
      "logps/rejected": -227.88412475585938,
      "loss": 0.3331,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.5491085052490234,
      "rewards/margins": 3.145393133163452,
      "rewards/rejected": -6.6945013999938965,
      "step": 11900
    },
    {
      "epoch": 2.173555981385163,
      "grad_norm": 5.232985496520996,
      "learning_rate": 4.549238392365572e-05,
      "logits/chosen": -0.8001424670219421,
      "logits/rejected": -0.5945414304733276,
      "logps/chosen": -178.1655731201172,
      "logps/rejected": -182.65968322753906,
      "loss": 0.2202,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.9448342323303223,
      "rewards/margins": 2.797126293182373,
      "rewards/rejected": -5.7419610023498535,
      "step": 11910
    },
    {
      "epoch": 2.1753809654165526,
      "grad_norm": 2.1511473655700684,
      "learning_rate": 4.546302073775005e-05,
      "logits/chosen": -0.787559986114502,
      "logits/rejected": -0.5394144654273987,
      "logps/chosen": -186.0308380126953,
      "logps/rejected": -201.78543090820312,
      "loss": 0.2325,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.9130899906158447,
      "rewards/margins": 3.2046825885772705,
      "rewards/rejected": -6.117772579193115,
      "step": 11920
    },
    {
      "epoch": 2.1772059494479423,
      "grad_norm": 6.05551290512085,
      "learning_rate": 4.543365755184438e-05,
      "logits/chosen": -0.7876346707344055,
      "logits/rejected": -0.5396913290023804,
      "logps/chosen": -191.5136260986328,
      "logps/rejected": -182.66238403320312,
      "loss": 0.3997,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.382521867752075,
      "rewards/margins": 2.701310634613037,
      "rewards/rejected": -6.083832740783691,
      "step": 11930
    },
    {
      "epoch": 2.179030933479332,
      "grad_norm": 1.3489108085632324,
      "learning_rate": 4.54042943659387e-05,
      "logits/chosen": -0.7247390747070312,
      "logits/rejected": -0.5489028692245483,
      "logps/chosen": -182.9346160888672,
      "logps/rejected": -190.26162719726562,
      "loss": 0.3292,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.151627540588379,
      "rewards/margins": 2.7624809741973877,
      "rewards/rejected": -5.914108753204346,
      "step": 11940
    },
    {
      "epoch": 2.180855917510722,
      "grad_norm": 2.711153268814087,
      "learning_rate": 4.537493118003304e-05,
      "logits/chosen": -0.6807699203491211,
      "logits/rejected": -0.4669509530067444,
      "logps/chosen": -170.6363983154297,
      "logps/rejected": -171.94810485839844,
      "loss": 0.2916,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.344883680343628,
      "rewards/margins": 2.5301785469055176,
      "rewards/rejected": -5.875062465667725,
      "step": 11950
    },
    {
      "epoch": 2.1826809015421116,
      "grad_norm": 8.574676513671875,
      "learning_rate": 4.5345567994127366e-05,
      "logits/chosen": -0.7136000394821167,
      "logits/rejected": -0.4802325367927551,
      "logps/chosen": -189.45965576171875,
      "logps/rejected": -189.4425048828125,
      "loss": 0.305,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.3596718311309814,
      "rewards/margins": 2.551499605178833,
      "rewards/rejected": -5.9111714363098145,
      "step": 11960
    },
    {
      "epoch": 2.1845058855735013,
      "grad_norm": 7.306252479553223,
      "learning_rate": 4.531620480822169e-05,
      "logits/chosen": -0.743308961391449,
      "logits/rejected": -0.5251660346984863,
      "logps/chosen": -172.0584259033203,
      "logps/rejected": -181.66871643066406,
      "loss": 0.3051,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.2035396099090576,
      "rewards/margins": 2.965327739715576,
      "rewards/rejected": -6.168867588043213,
      "step": 11970
    },
    {
      "epoch": 2.186330869604891,
      "grad_norm": 7.2878875732421875,
      "learning_rate": 4.528684162231603e-05,
      "logits/chosen": -0.6777247190475464,
      "logits/rejected": -0.5485318899154663,
      "logps/chosen": -184.10110473632812,
      "logps/rejected": -206.25692749023438,
      "loss": 0.2919,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.4080214500427246,
      "rewards/margins": 3.0202574729919434,
      "rewards/rejected": -6.428278923034668,
      "step": 11980
    },
    {
      "epoch": 2.188155853636281,
      "grad_norm": 2.8442916870117188,
      "learning_rate": 4.525747843641035e-05,
      "logits/chosen": -0.736184298992157,
      "logits/rejected": -0.6344114542007446,
      "logps/chosen": -164.10643005371094,
      "logps/rejected": -198.7475128173828,
      "loss": 0.1723,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.014400005340576,
      "rewards/margins": 3.2482590675354004,
      "rewards/rejected": -6.262659072875977,
      "step": 11990
    },
    {
      "epoch": 2.1899808376676706,
      "grad_norm": 1.6214144229888916,
      "learning_rate": 4.5228115250504684e-05,
      "logits/chosen": -0.7767557501792908,
      "logits/rejected": -0.6098055839538574,
      "logps/chosen": -175.25758361816406,
      "logps/rejected": -192.47650146484375,
      "loss": 0.213,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.019564628601074,
      "rewards/margins": 3.3158466815948486,
      "rewards/rejected": -6.335411548614502,
      "step": 12000
    },
    {
      "epoch": 2.1918058216990604,
      "grad_norm": 4.46328592300415,
      "learning_rate": 4.519875206459901e-05,
      "logits/chosen": -0.5953312516212463,
      "logits/rejected": -0.3566058874130249,
      "logps/chosen": -174.97901916503906,
      "logps/rejected": -192.846923828125,
      "loss": 0.2058,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.2216880321502686,
      "rewards/margins": 3.1629750728607178,
      "rewards/rejected": -6.384662628173828,
      "step": 12010
    },
    {
      "epoch": 2.1936308057304497,
      "grad_norm": 6.853446006774902,
      "learning_rate": 4.516938887869335e-05,
      "logits/chosen": -0.6272035837173462,
      "logits/rejected": -0.5268732309341431,
      "logps/chosen": -172.4687042236328,
      "logps/rejected": -195.6302032470703,
      "loss": 0.4416,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.8865559101104736,
      "rewards/margins": 2.3410675525665283,
      "rewards/rejected": -6.227622985839844,
      "step": 12020
    },
    {
      "epoch": 2.1954557897618394,
      "grad_norm": 5.862795829772949,
      "learning_rate": 4.514002569278767e-05,
      "logits/chosen": -0.7079511880874634,
      "logits/rejected": -0.5140379071235657,
      "logps/chosen": -188.66053771972656,
      "logps/rejected": -195.23355102539062,
      "loss": 0.3545,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.934274435043335,
      "rewards/margins": 2.4422738552093506,
      "rewards/rejected": -5.376547813415527,
      "step": 12030
    },
    {
      "epoch": 2.197280773793229,
      "grad_norm": 8.1541109085083,
      "learning_rate": 4.5110662506881996e-05,
      "logits/chosen": -0.7173277735710144,
      "logits/rejected": -0.515228807926178,
      "logps/chosen": -189.3631591796875,
      "logps/rejected": -197.75729370117188,
      "loss": 0.3008,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.148190975189209,
      "rewards/margins": 2.473038673400879,
      "rewards/rejected": -5.621230125427246,
      "step": 12040
    },
    {
      "epoch": 2.199105757824619,
      "grad_norm": 4.071662425994873,
      "learning_rate": 4.508129932097633e-05,
      "logits/chosen": -0.5764442682266235,
      "logits/rejected": -0.5088974237442017,
      "logps/chosen": -159.86514282226562,
      "logps/rejected": -172.8023223876953,
      "loss": 0.3288,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.9251811504364014,
      "rewards/margins": 2.387075901031494,
      "rewards/rejected": -5.312257289886475,
      "step": 12050
    },
    {
      "epoch": 2.2009307418560087,
      "grad_norm": 4.528292655944824,
      "learning_rate": 4.505193613507066e-05,
      "logits/chosen": -0.6451615691184998,
      "logits/rejected": -0.44820553064346313,
      "logps/chosen": -177.38388061523438,
      "logps/rejected": -192.2130584716797,
      "loss": 0.1858,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.118535041809082,
      "rewards/margins": 2.820265293121338,
      "rewards/rejected": -5.938800811767578,
      "step": 12060
    },
    {
      "epoch": 2.2027557258873984,
      "grad_norm": 5.4281158447265625,
      "learning_rate": 4.502257294916499e-05,
      "logits/chosen": -0.7411229014396667,
      "logits/rejected": -0.523248016834259,
      "logps/chosen": -174.75535583496094,
      "logps/rejected": -189.30531311035156,
      "loss": 0.2149,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.99591064453125,
      "rewards/margins": 2.919039249420166,
      "rewards/rejected": -5.914950370788574,
      "step": 12070
    },
    {
      "epoch": 2.204580709918788,
      "grad_norm": 6.32103967666626,
      "learning_rate": 4.4993209763259315e-05,
      "logits/chosen": -0.8489481210708618,
      "logits/rejected": -0.5758177042007446,
      "logps/chosen": -178.6312255859375,
      "logps/rejected": -176.12840270996094,
      "loss": 0.3417,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.6274051666259766,
      "rewards/margins": 2.6675899028778076,
      "rewards/rejected": -5.294995307922363,
      "step": 12080
    },
    {
      "epoch": 2.206405693950178,
      "grad_norm": 1.8588076829910278,
      "learning_rate": 4.496384657735364e-05,
      "logits/chosen": -0.8335126638412476,
      "logits/rejected": -0.7143180966377258,
      "logps/chosen": -170.61338806152344,
      "logps/rejected": -190.1040496826172,
      "loss": 0.2813,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2451107501983643,
      "rewards/margins": 2.733232259750366,
      "rewards/rejected": -4.9783430099487305,
      "step": 12090
    },
    {
      "epoch": 2.2082306779815677,
      "grad_norm": 6.573986530303955,
      "learning_rate": 4.493448339144798e-05,
      "logits/chosen": -0.7244085669517517,
      "logits/rejected": -0.5778390765190125,
      "logps/chosen": -175.320556640625,
      "logps/rejected": -190.03665161132812,
      "loss": 0.3795,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.4378433227539062,
      "rewards/margins": 2.2264156341552734,
      "rewards/rejected": -5.6642584800720215,
      "step": 12100
    },
    {
      "epoch": 2.2100556620129574,
      "grad_norm": 1.4779855012893677,
      "learning_rate": 4.49051202055423e-05,
      "logits/chosen": -0.8332594037055969,
      "logits/rejected": -0.676526665687561,
      "logps/chosen": -164.58047485351562,
      "logps/rejected": -172.3680877685547,
      "loss": 0.2711,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.7965986728668213,
      "rewards/margins": 2.6964404582977295,
      "rewards/rejected": -5.493039131164551,
      "step": 12110
    },
    {
      "epoch": 2.211880646044347,
      "grad_norm": 2.6135199069976807,
      "learning_rate": 4.487575701963663e-05,
      "logits/chosen": -0.814876914024353,
      "logits/rejected": -0.48267459869384766,
      "logps/chosen": -180.49380493164062,
      "logps/rejected": -179.9648895263672,
      "loss": 0.2742,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.0142295360565186,
      "rewards/margins": 2.7975895404815674,
      "rewards/rejected": -5.811819076538086,
      "step": 12120
    },
    {
      "epoch": 2.213705630075737,
      "grad_norm": 3.513967752456665,
      "learning_rate": 4.4846393833730965e-05,
      "logits/chosen": -0.6585016250610352,
      "logits/rejected": -0.4157010614871979,
      "logps/chosen": -200.6866912841797,
      "logps/rejected": -181.6538848876953,
      "loss": 0.3697,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.206774950027466,
      "rewards/margins": 2.6517868041992188,
      "rewards/rejected": -5.858561038970947,
      "step": 12130
    },
    {
      "epoch": 2.2155306141071267,
      "grad_norm": 3.5543880462646484,
      "learning_rate": 4.4817030647825296e-05,
      "logits/chosen": -0.7520834803581238,
      "logits/rejected": -0.525732159614563,
      "logps/chosen": -181.1475372314453,
      "logps/rejected": -182.61956787109375,
      "loss": 0.1975,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.8349967002868652,
      "rewards/margins": 3.0796446800231934,
      "rewards/rejected": -5.914641380310059,
      "step": 12140
    },
    {
      "epoch": 2.2173555981385165,
      "grad_norm": 8.992934226989746,
      "learning_rate": 4.478766746191962e-05,
      "logits/chosen": -0.6342276334762573,
      "logits/rejected": -0.3199400305747986,
      "logps/chosen": -169.5918731689453,
      "logps/rejected": -180.13743591308594,
      "loss": 0.3544,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.729769229888916,
      "rewards/margins": 2.9174399375915527,
      "rewards/rejected": -6.647209167480469,
      "step": 12150
    },
    {
      "epoch": 2.219180582169906,
      "grad_norm": 6.190186500549316,
      "learning_rate": 4.475830427601395e-05,
      "logits/chosen": -0.757896900177002,
      "logits/rejected": -0.5132501721382141,
      "logps/chosen": -179.86793518066406,
      "logps/rejected": -185.2980499267578,
      "loss": 0.3789,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.2158093452453613,
      "rewards/margins": 2.706521511077881,
      "rewards/rejected": -5.922330379486084,
      "step": 12160
    },
    {
      "epoch": 2.2210055662012955,
      "grad_norm": 8.505056381225586,
      "learning_rate": 4.472894109010828e-05,
      "logits/chosen": -0.7257798910140991,
      "logits/rejected": -0.4811972975730896,
      "logps/chosen": -194.20516967773438,
      "logps/rejected": -185.8407745361328,
      "loss": 0.4305,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.987205982208252,
      "rewards/margins": 2.3824291229248047,
      "rewards/rejected": -6.369635105133057,
      "step": 12170
    },
    {
      "epoch": 2.2228305502326853,
      "grad_norm": 7.31108283996582,
      "learning_rate": 4.4699577904202615e-05,
      "logits/chosen": -0.8440583348274231,
      "logits/rejected": -0.5342146754264832,
      "logps/chosen": -194.93319702148438,
      "logps/rejected": -182.98458862304688,
      "loss": 0.3588,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.139214038848877,
      "rewards/margins": 2.4290871620178223,
      "rewards/rejected": -5.568301200866699,
      "step": 12180
    },
    {
      "epoch": 2.224655534264075,
      "grad_norm": 4.678274154663086,
      "learning_rate": 4.467021471829694e-05,
      "logits/chosen": -0.9649489521980286,
      "logits/rejected": -0.8353565335273743,
      "logps/chosen": -175.25662231445312,
      "logps/rejected": -173.7810821533203,
      "loss": 0.4028,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.5941567420959473,
      "rewards/margins": 2.271486759185791,
      "rewards/rejected": -4.8656439781188965,
      "step": 12190
    },
    {
      "epoch": 2.226480518295465,
      "grad_norm": 3.889174461364746,
      "learning_rate": 4.4640851532391264e-05,
      "logits/chosen": -0.9872052073478699,
      "logits/rejected": -0.8610379099845886,
      "logps/chosen": -176.32102966308594,
      "logps/rejected": -189.04376220703125,
      "loss": 0.308,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.6640212535858154,
      "rewards/margins": 2.2034168243408203,
      "rewards/rejected": -4.867438316345215,
      "step": 12200
    },
    {
      "epoch": 2.2283055023268545,
      "grad_norm": 2.9741101264953613,
      "learning_rate": 4.46114883464856e-05,
      "logits/chosen": -0.9531146883964539,
      "logits/rejected": -0.7483360767364502,
      "logps/chosen": -170.85171508789062,
      "logps/rejected": -184.8012237548828,
      "loss": 0.2524,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.7535948753356934,
      "rewards/margins": 2.759661912918091,
      "rewards/rejected": -5.513257026672363,
      "step": 12210
    },
    {
      "epoch": 2.2301304863582443,
      "grad_norm": 10.77651309967041,
      "learning_rate": 4.4582125160579926e-05,
      "logits/chosen": -0.9600052833557129,
      "logits/rejected": -0.7888203859329224,
      "logps/chosen": -181.6905975341797,
      "logps/rejected": -168.20321655273438,
      "loss": 0.3585,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.7375550270080566,
      "rewards/margins": 2.306276559829712,
      "rewards/rejected": -5.043831825256348,
      "step": 12220
    },
    {
      "epoch": 2.231955470389634,
      "grad_norm": 8.474812507629395,
      "learning_rate": 4.455276197467426e-05,
      "logits/chosen": -0.8784372210502625,
      "logits/rejected": -0.6471021771430969,
      "logps/chosen": -160.3846893310547,
      "logps/rejected": -168.27523803710938,
      "loss": 0.3285,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.9472169876098633,
      "rewards/margins": 2.638984441757202,
      "rewards/rejected": -5.5862016677856445,
      "step": 12230
    },
    {
      "epoch": 2.233780454421024,
      "grad_norm": 1.2310655117034912,
      "learning_rate": 4.452339878876858e-05,
      "logits/chosen": -1.009699821472168,
      "logits/rejected": -0.8616000413894653,
      "logps/chosen": -168.85519409179688,
      "logps/rejected": -180.40670776367188,
      "loss": 0.2193,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.3311400413513184,
      "rewards/margins": 2.708244800567627,
      "rewards/rejected": -5.039384365081787,
      "step": 12240
    },
    {
      "epoch": 2.2356054384524136,
      "grad_norm": 6.013247013092041,
      "learning_rate": 4.449403560286292e-05,
      "logits/chosen": -0.9696642160415649,
      "logits/rejected": -0.8028929829597473,
      "logps/chosen": -176.29995727539062,
      "logps/rejected": -181.6535186767578,
      "loss": 0.3634,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.0060391426086426,
      "rewards/margins": 2.4854252338409424,
      "rewards/rejected": -5.491464614868164,
      "step": 12250
    },
    {
      "epoch": 2.2374304224838033,
      "grad_norm": 4.333967685699463,
      "learning_rate": 4.4464672416957245e-05,
      "logits/chosen": -0.9203758239746094,
      "logits/rejected": -0.7641528248786926,
      "logps/chosen": -171.08815002441406,
      "logps/rejected": -176.66189575195312,
      "loss": 0.3329,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.647791624069214,
      "rewards/margins": 2.2242238521575928,
      "rewards/rejected": -5.872015953063965,
      "step": 12260
    },
    {
      "epoch": 2.239255406515193,
      "grad_norm": 5.209307670593262,
      "learning_rate": 4.443530923105157e-05,
      "logits/chosen": -0.9951151013374329,
      "logits/rejected": -0.7726733684539795,
      "logps/chosen": -184.6086883544922,
      "logps/rejected": -191.38917541503906,
      "loss": 0.2292,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.665660858154297,
      "rewards/margins": 2.8257107734680176,
      "rewards/rejected": -5.491372108459473,
      "step": 12270
    },
    {
      "epoch": 2.241080390546583,
      "grad_norm": 8.071515083312988,
      "learning_rate": 4.44059460451459e-05,
      "logits/chosen": -0.9501153826713562,
      "logits/rejected": -0.68776535987854,
      "logps/chosen": -170.444580078125,
      "logps/rejected": -173.92564392089844,
      "loss": 0.1994,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -2.6893832683563232,
      "rewards/margins": 2.8863956928253174,
      "rewards/rejected": -5.575778007507324,
      "step": 12280
    },
    {
      "epoch": 2.2429053745779726,
      "grad_norm": 1.4052900075912476,
      "learning_rate": 4.437658285924023e-05,
      "logits/chosen": -0.7550358772277832,
      "logits/rejected": -0.658973753452301,
      "logps/chosen": -173.44259643554688,
      "logps/rejected": -188.86376953125,
      "loss": 0.4458,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.937694787979126,
      "rewards/margins": 2.259455680847168,
      "rewards/rejected": -5.197150230407715,
      "step": 12290
    },
    {
      "epoch": 2.2447303586093623,
      "grad_norm": 2.7470247745513916,
      "learning_rate": 4.4347219673334564e-05,
      "logits/chosen": -0.8042799234390259,
      "logits/rejected": -0.4128652513027191,
      "logps/chosen": -182.59323120117188,
      "logps/rejected": -183.66909790039062,
      "loss": 0.3355,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.7570059299468994,
      "rewards/margins": 2.907966375350952,
      "rewards/rejected": -5.664972305297852,
      "step": 12300
    },
    {
      "epoch": 2.246555342640752,
      "grad_norm": 6.7097930908203125,
      "learning_rate": 4.431785648742889e-05,
      "logits/chosen": -0.7993330359458923,
      "logits/rejected": -0.5425052046775818,
      "logps/chosen": -168.9424285888672,
      "logps/rejected": -165.81353759765625,
      "loss": 0.3403,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.7139899730682373,
      "rewards/margins": 2.959327220916748,
      "rewards/rejected": -5.673317909240723,
      "step": 12310
    },
    {
      "epoch": 2.248380326672142,
      "grad_norm": 7.3626837730407715,
      "learning_rate": 4.4288493301523226e-05,
      "logits/chosen": -0.8391681909561157,
      "logits/rejected": -0.6957331895828247,
      "logps/chosen": -154.9628143310547,
      "logps/rejected": -175.94210815429688,
      "loss": 0.3005,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.179978847503662,
      "rewards/margins": 2.651559352874756,
      "rewards/rejected": -4.831538200378418,
      "step": 12320
    },
    {
      "epoch": 2.2502053107035316,
      "grad_norm": 2.4581410884857178,
      "learning_rate": 4.425913011561755e-05,
      "logits/chosen": -0.7081080675125122,
      "logits/rejected": -0.3797835409641266,
      "logps/chosen": -179.86959838867188,
      "logps/rejected": -167.06512451171875,
      "loss": 0.2736,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.9917492866516113,
      "rewards/margins": 2.740341901779175,
      "rewards/rejected": -5.732090950012207,
      "step": 12330
    },
    {
      "epoch": 2.252030294734921,
      "grad_norm": 2.9323155879974365,
      "learning_rate": 4.4229766929711876e-05,
      "logits/chosen": -0.7566007375717163,
      "logits/rejected": -0.42096585035324097,
      "logps/chosen": -196.96067810058594,
      "logps/rejected": -183.01611328125,
      "loss": 0.3001,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.662987470626831,
      "rewards/margins": 2.439800262451172,
      "rewards/rejected": -6.102787971496582,
      "step": 12340
    },
    {
      "epoch": 2.2538552787663106,
      "grad_norm": 5.133657455444336,
      "learning_rate": 4.420040374380621e-05,
      "logits/chosen": -0.7018426656723022,
      "logits/rejected": -0.4465098977088928,
      "logps/chosen": -200.42495727539062,
      "logps/rejected": -191.53335571289062,
      "loss": 0.2692,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.734952449798584,
      "rewards/margins": 2.5061280727386475,
      "rewards/rejected": -6.241080284118652,
      "step": 12350
    },
    {
      "epoch": 2.2556802627977004,
      "grad_norm": 7.069591999053955,
      "learning_rate": 4.417104055790054e-05,
      "logits/chosen": -0.8226413726806641,
      "logits/rejected": -0.6437158584594727,
      "logps/chosen": -168.68287658691406,
      "logps/rejected": -169.62867736816406,
      "loss": 0.4189,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.3263373374938965,
      "rewards/margins": 2.045053243637085,
      "rewards/rejected": -5.371391296386719,
      "step": 12360
    },
    {
      "epoch": 2.25750524682909,
      "grad_norm": 3.358781337738037,
      "learning_rate": 4.414167737199487e-05,
      "logits/chosen": -0.8368722796440125,
      "logits/rejected": -0.6347025632858276,
      "logps/chosen": -202.12973022460938,
      "logps/rejected": -189.39369201660156,
      "loss": 0.3123,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.057326555252075,
      "rewards/margins": 2.0979726314544678,
      "rewards/rejected": -5.155299186706543,
      "step": 12370
    },
    {
      "epoch": 2.25933023086048,
      "grad_norm": 1.885462999343872,
      "learning_rate": 4.4112314186089194e-05,
      "logits/chosen": -0.9274389147758484,
      "logits/rejected": -0.7214728593826294,
      "logps/chosen": -174.15597534179688,
      "logps/rejected": -186.17054748535156,
      "loss": 0.2549,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.695679187774658,
      "rewards/margins": 2.6221542358398438,
      "rewards/rejected": -5.31783390045166,
      "step": 12380
    },
    {
      "epoch": 2.2611552148918697,
      "grad_norm": 3.8257369995117188,
      "learning_rate": 4.408295100018352e-05,
      "logits/chosen": -0.8661986589431763,
      "logits/rejected": -0.6549539566040039,
      "logps/chosen": -173.89859008789062,
      "logps/rejected": -177.96607971191406,
      "loss": 0.2174,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.780043363571167,
      "rewards/margins": 2.9541618824005127,
      "rewards/rejected": -5.734205722808838,
      "step": 12390
    },
    {
      "epoch": 2.2629801989232594,
      "grad_norm": 4.032148361206055,
      "learning_rate": 4.405358781427786e-05,
      "logits/chosen": -0.7782129049301147,
      "logits/rejected": -0.601310670375824,
      "logps/chosen": -162.48226928710938,
      "logps/rejected": -171.68038940429688,
      "loss": 0.2324,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.747941493988037,
      "rewards/margins": 2.849713087081909,
      "rewards/rejected": -5.597654342651367,
      "step": 12400
    },
    {
      "epoch": 2.264805182954649,
      "grad_norm": 6.458631992340088,
      "learning_rate": 4.402422462837218e-05,
      "logits/chosen": -0.7064906358718872,
      "logits/rejected": -0.5152745246887207,
      "logps/chosen": -177.28150939941406,
      "logps/rejected": -194.66842651367188,
      "loss": 0.2351,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.950801372528076,
      "rewards/margins": 2.7468318939208984,
      "rewards/rejected": -5.697632789611816,
      "step": 12410
    },
    {
      "epoch": 2.266630166986039,
      "grad_norm": 4.176929473876953,
      "learning_rate": 4.399486144246651e-05,
      "logits/chosen": -0.8311792612075806,
      "logits/rejected": -0.5903052091598511,
      "logps/chosen": -165.71963500976562,
      "logps/rejected": -174.58383178710938,
      "loss": 0.2732,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1305630207061768,
      "rewards/margins": 3.1961841583251953,
      "rewards/rejected": -5.326746940612793,
      "step": 12420
    },
    {
      "epoch": 2.2684551510174287,
      "grad_norm": 7.159020900726318,
      "learning_rate": 4.396549825656084e-05,
      "logits/chosen": -0.7772089242935181,
      "logits/rejected": -0.5146600008010864,
      "logps/chosen": -177.30258178710938,
      "logps/rejected": -165.0668182373047,
      "loss": 0.4033,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.6478500366210938,
      "rewards/margins": 2.2638442516326904,
      "rewards/rejected": -4.911694049835205,
      "step": 12430
    },
    {
      "epoch": 2.2702801350488184,
      "grad_norm": 11.853086471557617,
      "learning_rate": 4.3936135070655175e-05,
      "logits/chosen": -0.8763269186019897,
      "logits/rejected": -0.6780468821525574,
      "logps/chosen": -164.8409881591797,
      "logps/rejected": -183.13185119628906,
      "loss": 0.2584,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.006422758102417,
      "rewards/margins": 3.2306694984436035,
      "rewards/rejected": -5.237092018127441,
      "step": 12440
    },
    {
      "epoch": 2.272105119080208,
      "grad_norm": 2.6768405437469482,
      "learning_rate": 4.39067718847495e-05,
      "logits/chosen": -0.9442954063415527,
      "logits/rejected": -0.7531677484512329,
      "logps/chosen": -162.4495849609375,
      "logps/rejected": -172.94540405273438,
      "loss": 0.2511,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.138065814971924,
      "rewards/margins": 2.620156764984131,
      "rewards/rejected": -4.7582221031188965,
      "step": 12450
    },
    {
      "epoch": 2.273930103111598,
      "grad_norm": 9.829131126403809,
      "learning_rate": 4.3877408698843825e-05,
      "logits/chosen": -0.8538768887519836,
      "logits/rejected": -0.6607596278190613,
      "logps/chosen": -187.12689208984375,
      "logps/rejected": -198.38986206054688,
      "loss": 0.3171,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.56797456741333,
      "rewards/margins": 2.92120099067688,
      "rewards/rejected": -6.489175319671631,
      "step": 12460
    },
    {
      "epoch": 2.2757550871429877,
      "grad_norm": 5.646313190460205,
      "learning_rate": 4.3848045512938156e-05,
      "logits/chosen": -0.8992859125137329,
      "logits/rejected": -0.6391393542289734,
      "logps/chosen": -187.54408264160156,
      "logps/rejected": -168.22561645507812,
      "loss": 0.2868,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.743893623352051,
      "rewards/margins": 2.497159481048584,
      "rewards/rejected": -5.241053581237793,
      "step": 12470
    },
    {
      "epoch": 2.277580071174377,
      "grad_norm": 2.9370181560516357,
      "learning_rate": 4.381868232703249e-05,
      "logits/chosen": -0.8609712719917297,
      "logits/rejected": -0.7543050646781921,
      "logps/chosen": -162.77642822265625,
      "logps/rejected": -184.47116088867188,
      "loss": 0.225,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.804304599761963,
      "rewards/margins": 3.1060261726379395,
      "rewards/rejected": -5.910330772399902,
      "step": 12480
    },
    {
      "epoch": 2.2794050552057668,
      "grad_norm": 2.6478471755981445,
      "learning_rate": 4.378931914112682e-05,
      "logits/chosen": -0.7730172276496887,
      "logits/rejected": -0.6278344392776489,
      "logps/chosen": -160.87283325195312,
      "logps/rejected": -176.17556762695312,
      "loss": 0.4271,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.4956748485565186,
      "rewards/margins": 2.1577513217926025,
      "rewards/rejected": -5.653426170349121,
      "step": 12490
    },
    {
      "epoch": 2.2812300392371565,
      "grad_norm": 4.050796031951904,
      "learning_rate": 4.375995595522114e-05,
      "logits/chosen": -0.8743329048156738,
      "logits/rejected": -0.6785476207733154,
      "logps/chosen": -155.64816284179688,
      "logps/rejected": -179.1172332763672,
      "loss": 0.2894,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.318303346633911,
      "rewards/margins": 2.6825602054595947,
      "rewards/rejected": -5.000863075256348,
      "step": 12500
    },
    {
      "epoch": 2.2830550232685463,
      "grad_norm": 18.528066635131836,
      "learning_rate": 4.373059276931548e-05,
      "logits/chosen": -0.8036348223686218,
      "logits/rejected": -0.7410045862197876,
      "logps/chosen": -158.6121368408203,
      "logps/rejected": -197.6213836669922,
      "loss": 0.3722,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.5948424339294434,
      "rewards/margins": 2.6656689643859863,
      "rewards/rejected": -5.26051139831543,
      "step": 12510
    },
    {
      "epoch": 2.284880007299936,
      "grad_norm": 6.683254718780518,
      "learning_rate": 4.3701229583409806e-05,
      "logits/chosen": -0.7962316274642944,
      "logits/rejected": -0.6072032451629639,
      "logps/chosen": -156.17745971679688,
      "logps/rejected": -180.22247314453125,
      "loss": 0.3628,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.48757004737854,
      "rewards/margins": 2.7845256328582764,
      "rewards/rejected": -5.272095203399658,
      "step": 12520
    },
    {
      "epoch": 2.2867049913313258,
      "grad_norm": 5.7729411125183105,
      "learning_rate": 4.367186639750413e-05,
      "logits/chosen": -0.9674422144889832,
      "logits/rejected": -0.767180323600769,
      "logps/chosen": -158.91238403320312,
      "logps/rejected": -178.7311248779297,
      "loss": 0.3068,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.2164316177368164,
      "rewards/margins": 2.590571641921997,
      "rewards/rejected": -4.807002544403076,
      "step": 12530
    },
    {
      "epoch": 2.2885299753627155,
      "grad_norm": 2.4171745777130127,
      "learning_rate": 4.364250321159846e-05,
      "logits/chosen": -0.9972273111343384,
      "logits/rejected": -0.7138992547988892,
      "logps/chosen": -176.72702026367188,
      "logps/rejected": -169.31419372558594,
      "loss": 0.2511,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.3504977226257324,
      "rewards/margins": 2.9159913063049316,
      "rewards/rejected": -5.266488552093506,
      "step": 12540
    },
    {
      "epoch": 2.2903549593941053,
      "grad_norm": 7.772388935089111,
      "learning_rate": 4.361314002569279e-05,
      "logits/chosen": -0.9429523348808289,
      "logits/rejected": -0.8431353569030762,
      "logps/chosen": -180.6961669921875,
      "logps/rejected": -181.8842010498047,
      "loss": 0.4124,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.0810930728912354,
      "rewards/margins": 2.697890281677246,
      "rewards/rejected": -4.778983116149902,
      "step": 12550
    },
    {
      "epoch": 2.292179943425495,
      "grad_norm": 3.9283812046051025,
      "learning_rate": 4.3583776839787125e-05,
      "logits/chosen": -1.0102405548095703,
      "logits/rejected": -0.8508063554763794,
      "logps/chosen": -170.97634887695312,
      "logps/rejected": -178.5166778564453,
      "loss": 0.2633,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.524281620979309,
      "rewards/margins": 2.600733518600464,
      "rewards/rejected": -4.1250152587890625,
      "step": 12560
    },
    {
      "epoch": 2.294004927456885,
      "grad_norm": 8.245351791381836,
      "learning_rate": 4.355441365388145e-05,
      "logits/chosen": -1.1017696857452393,
      "logits/rejected": -0.9399141073226929,
      "logps/chosen": -164.7119140625,
      "logps/rejected": -188.14761352539062,
      "loss": 0.2987,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.4743739366531372,
      "rewards/margins": 2.804774761199951,
      "rewards/rejected": -4.279148578643799,
      "step": 12570
    },
    {
      "epoch": 2.2958299114882745,
      "grad_norm": 8.982291221618652,
      "learning_rate": 4.3525050467975774e-05,
      "logits/chosen": -1.026930570602417,
      "logits/rejected": -0.887696385383606,
      "logps/chosen": -149.8509063720703,
      "logps/rejected": -154.41427612304688,
      "loss": 0.4934,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.1368117332458496,
      "rewards/margins": 1.6622133255004883,
      "rewards/rejected": -3.7990245819091797,
      "step": 12580
    },
    {
      "epoch": 2.2976548955196643,
      "grad_norm": 5.975180625915527,
      "learning_rate": 4.349568728207011e-05,
      "logits/chosen": -0.9825197458267212,
      "logits/rejected": -0.7960139513015747,
      "logps/chosen": -178.88916015625,
      "logps/rejected": -172.42433166503906,
      "loss": 0.3483,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.343518018722534,
      "rewards/margins": 2.3581058979034424,
      "rewards/rejected": -4.701623439788818,
      "step": 12590
    },
    {
      "epoch": 2.299479879551054,
      "grad_norm": 10.276504516601562,
      "learning_rate": 4.3466324096164436e-05,
      "logits/chosen": -1.0207560062408447,
      "logits/rejected": -0.909088134765625,
      "logps/chosen": -160.8119659423828,
      "logps/rejected": -178.6800994873047,
      "loss": 0.2682,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9203466176986694,
      "rewards/margins": 2.5271620750427246,
      "rewards/rejected": -4.447508811950684,
      "step": 12600
    },
    {
      "epoch": 2.301304863582444,
      "grad_norm": 4.9111647605896,
      "learning_rate": 4.343696091025877e-05,
      "logits/chosen": -0.9584492444992065,
      "logits/rejected": -0.8857280015945435,
      "logps/chosen": -170.258544921875,
      "logps/rejected": -199.01551818847656,
      "loss": 0.2485,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.536738157272339,
      "rewards/margins": 2.3572192192077637,
      "rewards/rejected": -4.893957614898682,
      "step": 12610
    },
    {
      "epoch": 2.3031298476138335,
      "grad_norm": 7.204931735992432,
      "learning_rate": 4.340759772435309e-05,
      "logits/chosen": -0.9666274785995483,
      "logits/rejected": -0.6736518144607544,
      "logps/chosen": -200.11611938476562,
      "logps/rejected": -195.0283660888672,
      "loss": 0.264,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.6872451305389404,
      "rewards/margins": 2.6076748371124268,
      "rewards/rejected": -5.294919967651367,
      "step": 12620
    },
    {
      "epoch": 2.3049548316452233,
      "grad_norm": 6.7337141036987305,
      "learning_rate": 4.337823453844743e-05,
      "logits/chosen": -0.8687019348144531,
      "logits/rejected": -0.5694323778152466,
      "logps/chosen": -168.52993774414062,
      "logps/rejected": -169.74606323242188,
      "loss": 0.2717,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.664097309112549,
      "rewards/margins": 2.75022554397583,
      "rewards/rejected": -5.414322853088379,
      "step": 12630
    },
    {
      "epoch": 2.306779815676613,
      "grad_norm": 3.9413933753967285,
      "learning_rate": 4.3348871352541755e-05,
      "logits/chosen": -0.8127902150154114,
      "logits/rejected": -0.521318256855011,
      "logps/chosen": -171.39376831054688,
      "logps/rejected": -181.55580139160156,
      "loss": 0.2185,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.7744088172912598,
      "rewards/margins": 3.0047755241394043,
      "rewards/rejected": -5.779183864593506,
      "step": 12640
    },
    {
      "epoch": 2.3086047997080024,
      "grad_norm": 9.522673606872559,
      "learning_rate": 4.331950816663608e-05,
      "logits/chosen": -0.8183561563491821,
      "logits/rejected": -0.6415868401527405,
      "logps/chosen": -181.15444946289062,
      "logps/rejected": -191.8888702392578,
      "loss": 0.2828,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.037088394165039,
      "rewards/margins": 2.900641918182373,
      "rewards/rejected": -5.937730312347412,
      "step": 12650
    },
    {
      "epoch": 2.310429783739392,
      "grad_norm": 3.661763906478882,
      "learning_rate": 4.329014498073041e-05,
      "logits/chosen": -0.8426777720451355,
      "logits/rejected": -0.49419698119163513,
      "logps/chosen": -178.9687042236328,
      "logps/rejected": -174.21405029296875,
      "loss": 0.1449,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -3.253077745437622,
      "rewards/margins": 3.32124400138855,
      "rewards/rejected": -6.574321746826172,
      "step": 12660
    },
    {
      "epoch": 2.312254767770782,
      "grad_norm": 8.431367874145508,
      "learning_rate": 4.326078179482474e-05,
      "logits/chosen": -0.6354469060897827,
      "logits/rejected": -0.34532099962234497,
      "logps/chosen": -166.72030639648438,
      "logps/rejected": -183.11253356933594,
      "loss": 0.2797,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.641298770904541,
      "rewards/margins": 3.1933913230895996,
      "rewards/rejected": -6.834690093994141,
      "step": 12670
    },
    {
      "epoch": 2.3140797518021716,
      "grad_norm": 7.298835277557373,
      "learning_rate": 4.3231418608919074e-05,
      "logits/chosen": -0.6762964725494385,
      "logits/rejected": -0.49142804741859436,
      "logps/chosen": -192.49935913085938,
      "logps/rejected": -193.19467163085938,
      "loss": 0.2823,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.502652406692505,
      "rewards/margins": 3.009888172149658,
      "rewards/rejected": -6.512540340423584,
      "step": 12680
    },
    {
      "epoch": 2.3159047358335614,
      "grad_norm": 7.55780553817749,
      "learning_rate": 4.32020554230134e-05,
      "logits/chosen": -0.6330563426017761,
      "logits/rejected": -0.4939099848270416,
      "logps/chosen": -165.92112731933594,
      "logps/rejected": -184.50645446777344,
      "loss": 0.3842,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.815666675567627,
      "rewards/margins": 2.137315273284912,
      "rewards/rejected": -5.952981472015381,
      "step": 12690
    },
    {
      "epoch": 2.317729719864951,
      "grad_norm": 3.7257943153381348,
      "learning_rate": 4.3172692237107736e-05,
      "logits/chosen": -0.6825114488601685,
      "logits/rejected": -0.49198564887046814,
      "logps/chosen": -174.69049072265625,
      "logps/rejected": -180.17330932617188,
      "loss": 0.3007,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.176635503768921,
      "rewards/margins": 2.8691813945770264,
      "rewards/rejected": -6.045816898345947,
      "step": 12700
    },
    {
      "epoch": 2.319554703896341,
      "grad_norm": 4.712722301483154,
      "learning_rate": 4.314332905120206e-05,
      "logits/chosen": -0.8707534074783325,
      "logits/rejected": -0.5804941654205322,
      "logps/chosen": -193.9473876953125,
      "logps/rejected": -202.75991821289062,
      "loss": 0.1764,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.6467957496643066,
      "rewards/margins": 3.2412517070770264,
      "rewards/rejected": -5.888047218322754,
      "step": 12710
    },
    {
      "epoch": 2.3213796879277306,
      "grad_norm": 5.533111572265625,
      "learning_rate": 4.3113965865296386e-05,
      "logits/chosen": -0.6153692603111267,
      "logits/rejected": -0.23383910953998566,
      "logps/chosen": -187.6588134765625,
      "logps/rejected": -197.62271118164062,
      "loss": 0.3301,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.308905839920044,
      "rewards/margins": 3.342125654220581,
      "rewards/rejected": -6.651031494140625,
      "step": 12720
    },
    {
      "epoch": 2.3232046719591204,
      "grad_norm": 3.304096221923828,
      "learning_rate": 4.308460267939072e-05,
      "logits/chosen": -0.7176167964935303,
      "logits/rejected": -0.5947300791740417,
      "logps/chosen": -165.87527465820312,
      "logps/rejected": -185.9402313232422,
      "loss": 0.3299,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.1158640384674072,
      "rewards/margins": 2.5922319889068604,
      "rewards/rejected": -5.708095550537109,
      "step": 12730
    },
    {
      "epoch": 2.32502965599051,
      "grad_norm": 5.740825653076172,
      "learning_rate": 4.305523949348505e-05,
      "logits/chosen": -0.732340931892395,
      "logits/rejected": -0.5029290914535522,
      "logps/chosen": -181.84449768066406,
      "logps/rejected": -189.5731201171875,
      "loss": 0.236,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.7247979640960693,
      "rewards/margins": 2.7914230823516846,
      "rewards/rejected": -5.516221046447754,
      "step": 12740
    },
    {
      "epoch": 2.3268546400219,
      "grad_norm": 5.726057529449463,
      "learning_rate": 4.302587630757938e-05,
      "logits/chosen": -0.6296395063400269,
      "logits/rejected": -0.47704967856407166,
      "logps/chosen": -168.55091857910156,
      "logps/rejected": -182.73081970214844,
      "loss": 0.3734,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.653754472732544,
      "rewards/margins": 2.5470972061157227,
      "rewards/rejected": -6.2008514404296875,
      "step": 12750
    },
    {
      "epoch": 2.3286796240532897,
      "grad_norm": 2.312851667404175,
      "learning_rate": 4.2996513121673704e-05,
      "logits/chosen": -0.5502179265022278,
      "logits/rejected": -0.3837089240550995,
      "logps/chosen": -178.95164489746094,
      "logps/rejected": -194.41717529296875,
      "loss": 0.2742,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.4839260578155518,
      "rewards/margins": 3.1906962394714355,
      "rewards/rejected": -6.67462158203125,
      "step": 12760
    },
    {
      "epoch": 2.3305046080846794,
      "grad_norm": 6.219540119171143,
      "learning_rate": 4.296714993576803e-05,
      "logits/chosen": -0.727659285068512,
      "logits/rejected": -0.47053131461143494,
      "logps/chosen": -173.9056396484375,
      "logps/rejected": -179.32525634765625,
      "loss": 0.2364,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.2298569679260254,
      "rewards/margins": 2.9824705123901367,
      "rewards/rejected": -6.212327480316162,
      "step": 12770
    },
    {
      "epoch": 2.332329592116069,
      "grad_norm": 5.586278915405273,
      "learning_rate": 4.293778674986237e-05,
      "logits/chosen": -0.758688747882843,
      "logits/rejected": -0.4526504576206207,
      "logps/chosen": -189.1553955078125,
      "logps/rejected": -189.7262725830078,
      "loss": 0.2843,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.8166871070861816,
      "rewards/margins": 2.8434290885925293,
      "rewards/rejected": -5.660115718841553,
      "step": 12780
    },
    {
      "epoch": 2.3341545761474585,
      "grad_norm": 6.8187575340271,
      "learning_rate": 4.290842356395669e-05,
      "logits/chosen": -0.6110619306564331,
      "logits/rejected": -0.3790423274040222,
      "logps/chosen": -189.6236572265625,
      "logps/rejected": -186.11062622070312,
      "loss": 0.2619,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.1694326400756836,
      "rewards/margins": 2.807339906692505,
      "rewards/rejected": -5.976772308349609,
      "step": 12790
    },
    {
      "epoch": 2.3359795601788482,
      "grad_norm": 3.8392388820648193,
      "learning_rate": 4.287906037805102e-05,
      "logits/chosen": -0.4149446487426758,
      "logits/rejected": -0.19226548075675964,
      "logps/chosen": -194.468505859375,
      "logps/rejected": -208.9101104736328,
      "loss": 0.2974,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.357236385345459,
      "rewards/margins": 3.2558789253234863,
      "rewards/rejected": -7.6131157875061035,
      "step": 12800
    },
    {
      "epoch": 2.337804544210238,
      "grad_norm": 2.0338993072509766,
      "learning_rate": 4.284969719214535e-05,
      "logits/chosen": -0.47126418352127075,
      "logits/rejected": -0.23639337718486786,
      "logps/chosen": -186.63185119628906,
      "logps/rejected": -197.10696411132812,
      "loss": 0.2837,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -3.6951255798339844,
      "rewards/margins": 3.062896728515625,
      "rewards/rejected": -6.758023262023926,
      "step": 12810
    },
    {
      "epoch": 2.3396295282416277,
      "grad_norm": 4.334644794464111,
      "learning_rate": 4.2820334006239685e-05,
      "logits/chosen": -0.5136317610740662,
      "logits/rejected": -0.25239649415016174,
      "logps/chosen": -187.5774383544922,
      "logps/rejected": -182.5768280029297,
      "loss": 0.2991,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.2523155212402344,
      "rewards/margins": 2.6043190956115723,
      "rewards/rejected": -5.856634140014648,
      "step": 12820
    },
    {
      "epoch": 2.3414545122730175,
      "grad_norm": 4.069055080413818,
      "learning_rate": 4.279097082033401e-05,
      "logits/chosen": -0.6393588781356812,
      "logits/rejected": -0.2390137016773224,
      "logps/chosen": -195.59390258789062,
      "logps/rejected": -173.13980102539062,
      "loss": 0.2447,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.11259126663208,
      "rewards/margins": 2.8658926486968994,
      "rewards/rejected": -5.978483200073242,
      "step": 12830
    },
    {
      "epoch": 2.3432794963044072,
      "grad_norm": 5.0548095703125,
      "learning_rate": 4.2761607634428335e-05,
      "logits/chosen": -0.4368809163570404,
      "logits/rejected": -0.1666257530450821,
      "logps/chosen": -176.01986694335938,
      "logps/rejected": -172.14788818359375,
      "loss": 0.3858,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.7988295555114746,
      "rewards/margins": 2.3179147243499756,
      "rewards/rejected": -6.116744518280029,
      "step": 12840
    },
    {
      "epoch": 2.345104480335797,
      "grad_norm": 2.7808914184570312,
      "learning_rate": 4.2732244448522666e-05,
      "logits/chosen": -0.4651608467102051,
      "logits/rejected": -0.28322839736938477,
      "logps/chosen": -177.22312927246094,
      "logps/rejected": -200.12673950195312,
      "loss": 0.3274,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.461137294769287,
      "rewards/margins": 2.5400688648223877,
      "rewards/rejected": -6.001206398010254,
      "step": 12850
    },
    {
      "epoch": 2.3469294643671867,
      "grad_norm": 6.232387065887451,
      "learning_rate": 4.2702881262617e-05,
      "logits/chosen": -0.4779109060764313,
      "logits/rejected": -0.18669945001602173,
      "logps/chosen": -179.1188201904297,
      "logps/rejected": -192.7717742919922,
      "loss": 0.2806,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.531466007232666,
      "rewards/margins": 3.2203307151794434,
      "rewards/rejected": -6.751796722412109,
      "step": 12860
    },
    {
      "epoch": 2.3487544483985765,
      "grad_norm": 1.9625781774520874,
      "learning_rate": 4.267351807671133e-05,
      "logits/chosen": -0.3181349039077759,
      "logits/rejected": -0.0772814005613327,
      "logps/chosen": -187.64297485351562,
      "logps/rejected": -196.8914794921875,
      "loss": 0.2821,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -4.122470855712891,
      "rewards/margins": 3.0228569507598877,
      "rewards/rejected": -7.145327568054199,
      "step": 12870
    },
    {
      "epoch": 2.3505794324299663,
      "grad_norm": 1.691687822341919,
      "learning_rate": 4.264415489080565e-05,
      "logits/chosen": -0.4489400386810303,
      "logits/rejected": -0.37568187713623047,
      "logps/chosen": -179.6162872314453,
      "logps/rejected": -211.7554931640625,
      "loss": 0.2669,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.8476696014404297,
      "rewards/margins": 3.0109095573425293,
      "rewards/rejected": -6.858579158782959,
      "step": 12880
    },
    {
      "epoch": 2.352404416461356,
      "grad_norm": 6.7899041175842285,
      "learning_rate": 4.261479170489999e-05,
      "logits/chosen": -0.6108691096305847,
      "logits/rejected": -0.36938193440437317,
      "logps/chosen": -178.8008270263672,
      "logps/rejected": -180.40597534179688,
      "loss": 0.4,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.459211826324463,
      "rewards/margins": 2.4738423824310303,
      "rewards/rejected": -5.933053493499756,
      "step": 12890
    },
    {
      "epoch": 2.3542294004927458,
      "grad_norm": 3.7729978561401367,
      "learning_rate": 4.2585428518994316e-05,
      "logits/chosen": -0.6435583233833313,
      "logits/rejected": -0.58329176902771,
      "logps/chosen": -170.1678924560547,
      "logps/rejected": -208.6536407470703,
      "loss": 0.3658,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.0892090797424316,
      "rewards/margins": 2.5065085887908936,
      "rewards/rejected": -5.595717430114746,
      "step": 12900
    },
    {
      "epoch": 2.3560543845241355,
      "grad_norm": 3.1457173824310303,
      "learning_rate": 4.255606533308864e-05,
      "logits/chosen": -0.7370783090591431,
      "logits/rejected": -0.49047499895095825,
      "logps/chosen": -182.9866180419922,
      "logps/rejected": -183.9626922607422,
      "loss": 0.3266,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.651737689971924,
      "rewards/margins": 2.725257158279419,
      "rewards/rejected": -5.376995086669922,
      "step": 12910
    },
    {
      "epoch": 2.3578793685555253,
      "grad_norm": 3.163818836212158,
      "learning_rate": 4.252670214718297e-05,
      "logits/chosen": -0.5419801473617554,
      "logits/rejected": -0.3753473162651062,
      "logps/chosen": -163.55264282226562,
      "logps/rejected": -176.23733520507812,
      "loss": 0.2818,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.023272752761841,
      "rewards/margins": 2.6586222648620605,
      "rewards/rejected": -5.681894779205322,
      "step": 12920
    },
    {
      "epoch": 2.359704352586915,
      "grad_norm": 1.7497944831848145,
      "learning_rate": 4.24973389612773e-05,
      "logits/chosen": -0.6683983206748962,
      "logits/rejected": -0.5778146982192993,
      "logps/chosen": -170.62525939941406,
      "logps/rejected": -191.11370849609375,
      "loss": 0.2748,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.875312328338623,
      "rewards/margins": 2.2065014839172363,
      "rewards/rejected": -5.081814765930176,
      "step": 12930
    },
    {
      "epoch": 2.3615293366183048,
      "grad_norm": 7.813135623931885,
      "learning_rate": 4.2467975775371635e-05,
      "logits/chosen": -0.764607310295105,
      "logits/rejected": -0.5092350244522095,
      "logps/chosen": -184.67115783691406,
      "logps/rejected": -167.7421417236328,
      "loss": 0.3149,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.7120678424835205,
      "rewards/margins": 2.3326377868652344,
      "rewards/rejected": -5.044705390930176,
      "step": 12940
    },
    {
      "epoch": 2.3633543206496945,
      "grad_norm": 6.502517223358154,
      "learning_rate": 4.243861258946596e-05,
      "logits/chosen": -0.672810971736908,
      "logits/rejected": -0.43999186158180237,
      "logps/chosen": -175.85336303710938,
      "logps/rejected": -166.53085327148438,
      "loss": 0.3424,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.587449550628662,
      "rewards/margins": 2.2480626106262207,
      "rewards/rejected": -4.835512161254883,
      "step": 12950
    },
    {
      "epoch": 2.3651793046810843,
      "grad_norm": 3.0545907020568848,
      "learning_rate": 4.2409249403560284e-05,
      "logits/chosen": -0.8050901293754578,
      "logits/rejected": -0.5965843796730042,
      "logps/chosen": -178.62994384765625,
      "logps/rejected": -181.7721710205078,
      "loss": 0.3847,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.64245867729187,
      "rewards/margins": 2.3070125579833984,
      "rewards/rejected": -4.949471473693848,
      "step": 12960
    },
    {
      "epoch": 2.3670042887124736,
      "grad_norm": 4.845169544219971,
      "learning_rate": 4.237988621765462e-05,
      "logits/chosen": -0.7492955923080444,
      "logits/rejected": -0.5701985359191895,
      "logps/chosen": -162.332275390625,
      "logps/rejected": -175.04183959960938,
      "loss": 0.2751,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.3741204738616943,
      "rewards/margins": 2.4950976371765137,
      "rewards/rejected": -4.869218826293945,
      "step": 12970
    },
    {
      "epoch": 2.3688292727438633,
      "grad_norm": 4.798072814941406,
      "learning_rate": 4.2350523031748946e-05,
      "logits/chosen": -0.6610622406005859,
      "logits/rejected": -0.41078051924705505,
      "logps/chosen": -171.13157653808594,
      "logps/rejected": -169.03271484375,
      "loss": 0.3359,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.331202983856201,
      "rewards/margins": 2.2365384101867676,
      "rewards/rejected": -4.567741870880127,
      "step": 12980
    },
    {
      "epoch": 2.370654256775253,
      "grad_norm": 6.397465229034424,
      "learning_rate": 4.232115984584328e-05,
      "logits/chosen": -0.6525493860244751,
      "logits/rejected": -0.526974081993103,
      "logps/chosen": -168.5336151123047,
      "logps/rejected": -175.21615600585938,
      "loss": 0.3426,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.571890354156494,
      "rewards/margins": 2.1727938652038574,
      "rewards/rejected": -4.744683742523193,
      "step": 12990
    },
    {
      "epoch": 2.372479240806643,
      "grad_norm": 8.381142616271973,
      "learning_rate": 4.22917966599376e-05,
      "logits/chosen": -0.6598596572875977,
      "logits/rejected": -0.46910515427589417,
      "logps/chosen": -157.04904174804688,
      "logps/rejected": -168.49913024902344,
      "loss": 0.3296,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.108837366104126,
      "rewards/margins": 2.4888923168182373,
      "rewards/rejected": -4.597729682922363,
      "step": 13000
    },
    {
      "epoch": 2.3743042248380326,
      "grad_norm": 6.290065765380859,
      "learning_rate": 4.226243347403194e-05,
      "logits/chosen": -0.5726609230041504,
      "logits/rejected": -0.4128357470035553,
      "logps/chosen": -170.4321746826172,
      "logps/rejected": -163.5260772705078,
      "loss": 0.387,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.88643479347229,
      "rewards/margins": 1.7083947658538818,
      "rewards/rejected": -4.59483003616333,
      "step": 13010
    },
    {
      "epoch": 2.3761292088694224,
      "grad_norm": 9.071537017822266,
      "learning_rate": 4.2233070288126265e-05,
      "logits/chosen": -0.6629807949066162,
      "logits/rejected": -0.3850913345813751,
      "logps/chosen": -193.49679565429688,
      "logps/rejected": -186.4019012451172,
      "loss": 0.277,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.3664588928222656,
      "rewards/margins": 2.260040760040283,
      "rewards/rejected": -4.626500129699707,
      "step": 13020
    },
    {
      "epoch": 2.377954192900812,
      "grad_norm": 2.6092963218688965,
      "learning_rate": 4.220370710222059e-05,
      "logits/chosen": -0.6908241510391235,
      "logits/rejected": -0.45482125878334045,
      "logps/chosen": -174.73080444335938,
      "logps/rejected": -192.33908081054688,
      "loss": 0.2444,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.697256565093994,
      "rewards/margins": 2.6642539501190186,
      "rewards/rejected": -5.361510753631592,
      "step": 13030
    },
    {
      "epoch": 2.379779176932202,
      "grad_norm": 8.276688575744629,
      "learning_rate": 4.217434391631492e-05,
      "logits/chosen": -0.604771077632904,
      "logits/rejected": -0.20157265663146973,
      "logps/chosen": -177.06466674804688,
      "logps/rejected": -163.7521514892578,
      "loss": 0.2877,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.396358013153076,
      "rewards/margins": 2.6771702766418457,
      "rewards/rejected": -5.073528289794922,
      "step": 13040
    },
    {
      "epoch": 2.3816041609635916,
      "grad_norm": 7.090481281280518,
      "learning_rate": 4.214498073040925e-05,
      "logits/chosen": -0.5561552047729492,
      "logits/rejected": -0.3793593645095825,
      "logps/chosen": -159.1334991455078,
      "logps/rejected": -173.4262237548828,
      "loss": 0.3193,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.6657583713531494,
      "rewards/margins": 2.312377452850342,
      "rewards/rejected": -4.97813606262207,
      "step": 13050
    },
    {
      "epoch": 2.3834291449949814,
      "grad_norm": 4.2172746658325195,
      "learning_rate": 4.2115617544503584e-05,
      "logits/chosen": -0.6309081315994263,
      "logits/rejected": -0.33981555700302124,
      "logps/chosen": -192.8446807861328,
      "logps/rejected": -182.28582763671875,
      "loss": 0.2418,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8816791772842407,
      "rewards/margins": 3.1303834915161133,
      "rewards/rejected": -5.012063026428223,
      "step": 13060
    },
    {
      "epoch": 2.385254129026371,
      "grad_norm": 4.947913646697998,
      "learning_rate": 4.208625435859791e-05,
      "logits/chosen": -0.6474932432174683,
      "logits/rejected": -0.5454524755477905,
      "logps/chosen": -168.1970977783203,
      "logps/rejected": -168.69418334960938,
      "loss": 0.3679,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.582186222076416,
      "rewards/margins": 2.3122801780700684,
      "rewards/rejected": -4.894465923309326,
      "step": 13070
    },
    {
      "epoch": 2.387079113057761,
      "grad_norm": 1.6681935787200928,
      "learning_rate": 4.2056891172692246e-05,
      "logits/chosen": -0.6133075952529907,
      "logits/rejected": -0.3341746926307678,
      "logps/chosen": -178.93557739257812,
      "logps/rejected": -176.86941528320312,
      "loss": 0.2211,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0447940826416016,
      "rewards/margins": 2.998711109161377,
      "rewards/rejected": -5.043505668640137,
      "step": 13080
    },
    {
      "epoch": 2.3889040970891506,
      "grad_norm": 10.151555061340332,
      "learning_rate": 4.202752798678657e-05,
      "logits/chosen": -0.5392584800720215,
      "logits/rejected": -0.4064871370792389,
      "logps/chosen": -170.21890258789062,
      "logps/rejected": -190.7361297607422,
      "loss": 0.3419,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.183051109313965,
      "rewards/margins": 2.5636589527130127,
      "rewards/rejected": -5.746710777282715,
      "step": 13090
    },
    {
      "epoch": 2.3907290811205404,
      "grad_norm": 10.12702751159668,
      "learning_rate": 4.1998164800880896e-05,
      "logits/chosen": -0.4639647603034973,
      "logits/rejected": -0.30176475644111633,
      "logps/chosen": -182.70668029785156,
      "logps/rejected": -195.2327423095703,
      "loss": 0.3593,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.602400302886963,
      "rewards/margins": 2.6110520362854004,
      "rewards/rejected": -6.213452339172363,
      "step": 13100
    },
    {
      "epoch": 2.3925540651519297,
      "grad_norm": 4.689276218414307,
      "learning_rate": 4.196880161497523e-05,
      "logits/chosen": -0.6550394296646118,
      "logits/rejected": -0.31849440932273865,
      "logps/chosen": -188.0086669921875,
      "logps/rejected": -175.59158325195312,
      "loss": 0.3273,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.798664093017578,
      "rewards/margins": 2.625485897064209,
      "rewards/rejected": -5.424149513244629,
      "step": 13110
    },
    {
      "epoch": 2.3943790491833195,
      "grad_norm": 6.617003440856934,
      "learning_rate": 4.193943842906956e-05,
      "logits/chosen": -0.6039382219314575,
      "logits/rejected": -0.3346477448940277,
      "logps/chosen": -179.53871154785156,
      "logps/rejected": -160.06484985351562,
      "loss": 0.3432,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.756044864654541,
      "rewards/margins": 2.2132058143615723,
      "rewards/rejected": -4.969250679016113,
      "step": 13120
    },
    {
      "epoch": 2.396204033214709,
      "grad_norm": 2.9780917167663574,
      "learning_rate": 4.191007524316389e-05,
      "logits/chosen": -0.6491557955741882,
      "logits/rejected": -0.3508301377296448,
      "logps/chosen": -165.9811553955078,
      "logps/rejected": -171.82608032226562,
      "loss": 0.2262,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.1425061225891113,
      "rewards/margins": 3.3315701484680176,
      "rewards/rejected": -5.474076271057129,
      "step": 13130
    },
    {
      "epoch": 2.398029017246099,
      "grad_norm": 10.241156578063965,
      "learning_rate": 4.1880712057258214e-05,
      "logits/chosen": -0.633394718170166,
      "logits/rejected": -0.4393848478794098,
      "logps/chosen": -170.82666015625,
      "logps/rejected": -187.06263732910156,
      "loss": 0.3189,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.724541187286377,
      "rewards/margins": 2.6990888118743896,
      "rewards/rejected": -5.4236297607421875,
      "step": 13140
    },
    {
      "epoch": 2.3998540012774887,
      "grad_norm": 6.067865371704102,
      "learning_rate": 4.185134887135254e-05,
      "logits/chosen": -0.5094481110572815,
      "logits/rejected": -0.21696516871452332,
      "logps/chosen": -190.45480346679688,
      "logps/rejected": -182.78811645507812,
      "loss": 0.2721,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.867096185684204,
      "rewards/margins": 2.578831434249878,
      "rewards/rejected": -5.44592809677124,
      "step": 13150
    },
    {
      "epoch": 2.4016789853088785,
      "grad_norm": 1.629915475845337,
      "learning_rate": 4.182198568544688e-05,
      "logits/chosen": -0.41841426491737366,
      "logits/rejected": -0.19036312401294708,
      "logps/chosen": -171.93917846679688,
      "logps/rejected": -192.54408264160156,
      "loss": 0.282,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.9697844982147217,
      "rewards/margins": 2.958709239959717,
      "rewards/rejected": -5.928493499755859,
      "step": 13160
    },
    {
      "epoch": 2.403503969340268,
      "grad_norm": 5.4534454345703125,
      "learning_rate": 4.17926224995412e-05,
      "logits/chosen": -0.5318703651428223,
      "logits/rejected": -0.25597769021987915,
      "logps/chosen": -177.72964477539062,
      "logps/rejected": -190.11163330078125,
      "loss": 0.2964,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.9245293140411377,
      "rewards/margins": 2.7216098308563232,
      "rewards/rejected": -5.646139144897461,
      "step": 13170
    },
    {
      "epoch": 2.405328953371658,
      "grad_norm": 3.126753330230713,
      "learning_rate": 4.176325931363553e-05,
      "logits/chosen": -0.6781778931617737,
      "logits/rejected": -0.4716724455356598,
      "logps/chosen": -181.46206665039062,
      "logps/rejected": -192.60601806640625,
      "loss": 0.2793,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.989025115966797,
      "rewards/margins": 2.743380069732666,
      "rewards/rejected": -5.732405185699463,
      "step": 13180
    },
    {
      "epoch": 2.4071539374030477,
      "grad_norm": 5.512510299682617,
      "learning_rate": 4.173389612772986e-05,
      "logits/chosen": -0.5277173519134521,
      "logits/rejected": -0.359813392162323,
      "logps/chosen": -171.6991729736328,
      "logps/rejected": -180.67477416992188,
      "loss": 0.2673,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.7792553901672363,
      "rewards/margins": 2.862107038497925,
      "rewards/rejected": -5.64136266708374,
      "step": 13190
    },
    {
      "epoch": 2.4089789214344375,
      "grad_norm": 7.165764808654785,
      "learning_rate": 4.1704532941824195e-05,
      "logits/chosen": -0.6443504691123962,
      "logits/rejected": -0.36449941992759705,
      "logps/chosen": -187.37925720214844,
      "logps/rejected": -193.06105041503906,
      "loss": 0.2001,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.8614346981048584,
      "rewards/margins": 3.432497501373291,
      "rewards/rejected": -6.2939324378967285,
      "step": 13200
    },
    {
      "epoch": 2.4108039054658272,
      "grad_norm": 13.434041023254395,
      "learning_rate": 4.167516975591852e-05,
      "logits/chosen": -0.5642459988594055,
      "logits/rejected": -0.25865885615348816,
      "logps/chosen": -178.96331787109375,
      "logps/rejected": -194.43527221679688,
      "loss": 0.3264,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4205355644226074,
      "rewards/margins": 3.306466579437256,
      "rewards/rejected": -5.7270026206970215,
      "step": 13210
    },
    {
      "epoch": 2.412628889497217,
      "grad_norm": 12.876891136169434,
      "learning_rate": 4.1645806570012845e-05,
      "logits/chosen": -0.5201319456100464,
      "logits/rejected": -0.254573255777359,
      "logps/chosen": -178.65179443359375,
      "logps/rejected": -202.70594787597656,
      "loss": 0.2039,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.3660097122192383,
      "rewards/margins": 3.233790636062622,
      "rewards/rejected": -5.599800109863281,
      "step": 13220
    },
    {
      "epoch": 2.4144538735286067,
      "grad_norm": 7.330395698547363,
      "learning_rate": 4.1616443384107176e-05,
      "logits/chosen": -0.6233471632003784,
      "logits/rejected": -0.2059599906206131,
      "logps/chosen": -193.6149444580078,
      "logps/rejected": -188.5715789794922,
      "loss": 0.2725,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.618166446685791,
      "rewards/margins": 3.3257365226745605,
      "rewards/rejected": -5.943902492523193,
      "step": 13230
    },
    {
      "epoch": 2.4162788575599965,
      "grad_norm": 12.109949111938477,
      "learning_rate": 4.158708019820151e-05,
      "logits/chosen": -0.5952734351158142,
      "logits/rejected": -0.4463379979133606,
      "logps/chosen": -177.1131591796875,
      "logps/rejected": -211.5620574951172,
      "loss": 0.2186,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.295146942138672,
      "rewards/margins": 3.5725598335266113,
      "rewards/rejected": -6.867707252502441,
      "step": 13240
    },
    {
      "epoch": 2.4181038415913862,
      "grad_norm": 3.55963134765625,
      "learning_rate": 4.15606533308864e-05,
      "logits/chosen": -0.6346011161804199,
      "logits/rejected": -0.4686550199985504,
      "logps/chosen": -171.45938110351562,
      "logps/rejected": -182.9719696044922,
      "loss": 0.4049,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.872424602508545,
      "rewards/margins": 2.4852547645568848,
      "rewards/rejected": -5.357679843902588,
      "step": 13250
    },
    {
      "epoch": 2.419928825622776,
      "grad_norm": 3.027888774871826,
      "learning_rate": 4.1531290144980733e-05,
      "logits/chosen": -0.6162073612213135,
      "logits/rejected": -0.4797094762325287,
      "logps/chosen": -158.12667846679688,
      "logps/rejected": -171.2028350830078,
      "loss": 0.3808,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.5139434337615967,
      "rewards/margins": 2.496142625808716,
      "rewards/rejected": -5.010087013244629,
      "step": 13260
    },
    {
      "epoch": 2.4217538096541658,
      "grad_norm": 12.426116943359375,
      "learning_rate": 4.1501926959075065e-05,
      "logits/chosen": -0.7773377895355225,
      "logits/rejected": -0.539043128490448,
      "logps/chosen": -186.19186401367188,
      "logps/rejected": -194.8925323486328,
      "loss": 0.2597,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.154832363128662,
      "rewards/margins": 3.563706874847412,
      "rewards/rejected": -5.718539237976074,
      "step": 13270
    },
    {
      "epoch": 2.423578793685555,
      "grad_norm": 5.277679443359375,
      "learning_rate": 4.1472563773169396e-05,
      "logits/chosen": -0.537413477897644,
      "logits/rejected": -0.24307219684123993,
      "logps/chosen": -170.45712280273438,
      "logps/rejected": -179.8086395263672,
      "loss": 0.2465,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.933563470840454,
      "rewards/margins": 3.161839723587036,
      "rewards/rejected": -6.095402717590332,
      "step": 13280
    },
    {
      "epoch": 2.425403777716945,
      "grad_norm": 7.916383743286133,
      "learning_rate": 4.144320058726372e-05,
      "logits/chosen": -0.5631870627403259,
      "logits/rejected": -0.2167421132326126,
      "logps/chosen": -194.7960205078125,
      "logps/rejected": -189.87013244628906,
      "loss": 0.2966,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.7630772590637207,
      "rewards/margins": 3.012935161590576,
      "rewards/rejected": -5.776012420654297,
      "step": 13290
    },
    {
      "epoch": 2.4272287617483346,
      "grad_norm": 6.292763710021973,
      "learning_rate": 4.1413837401358045e-05,
      "logits/chosen": -0.41105666756629944,
      "logits/rejected": -0.08869399130344391,
      "logps/chosen": -199.16757202148438,
      "logps/rejected": -180.10079956054688,
      "loss": 0.2761,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.5270590782165527,
      "rewards/margins": 2.671996593475342,
      "rewards/rejected": -6.1990556716918945,
      "step": 13300
    },
    {
      "epoch": 2.4290537457797243,
      "grad_norm": 3.7548460960388184,
      "learning_rate": 4.1384474215452383e-05,
      "logits/chosen": -0.297437459230423,
      "logits/rejected": 0.08464790880680084,
      "logps/chosen": -179.33883666992188,
      "logps/rejected": -176.6848602294922,
      "loss": 0.2231,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.153193712234497,
      "rewards/margins": 3.0255942344665527,
      "rewards/rejected": -6.178787708282471,
      "step": 13310
    },
    {
      "epoch": 2.430878729811114,
      "grad_norm": 1.4080049991607666,
      "learning_rate": 4.135511102954671e-05,
      "logits/chosen": -0.4935196042060852,
      "logits/rejected": -0.23876693844795227,
      "logps/chosen": -174.5382080078125,
      "logps/rejected": -188.55264282226562,
      "loss": 0.2727,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.040593385696411,
      "rewards/margins": 3.122199058532715,
      "rewards/rejected": -6.162792205810547,
      "step": 13320
    },
    {
      "epoch": 2.432703713842504,
      "grad_norm": 4.620199680328369,
      "learning_rate": 4.132574784364104e-05,
      "logits/chosen": -0.5246986150741577,
      "logits/rejected": -0.3245011270046234,
      "logps/chosen": -180.50906372070312,
      "logps/rejected": -199.8642578125,
      "loss": 0.2446,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.3860023021698,
      "rewards/margins": 2.8529276847839355,
      "rewards/rejected": -6.238930702209473,
      "step": 13330
    },
    {
      "epoch": 2.4345286978738936,
      "grad_norm": 8.02157211303711,
      "learning_rate": 4.1296384657735364e-05,
      "logits/chosen": -0.5621109008789062,
      "logits/rejected": -0.3375968337059021,
      "logps/chosen": -183.27793884277344,
      "logps/rejected": -179.53170776367188,
      "loss": 0.3264,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.5869078636169434,
      "rewards/margins": 2.5206525325775146,
      "rewards/rejected": -6.107560634613037,
      "step": 13340
    },
    {
      "epoch": 2.4363536819052833,
      "grad_norm": 6.171517848968506,
      "learning_rate": 4.12670214718297e-05,
      "logits/chosen": -0.6531578302383423,
      "logits/rejected": -0.4795362949371338,
      "logps/chosen": -174.27333068847656,
      "logps/rejected": -196.26095581054688,
      "loss": 0.2798,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.3503265380859375,
      "rewards/margins": 2.865412712097168,
      "rewards/rejected": -6.2157392501831055,
      "step": 13350
    },
    {
      "epoch": 2.438178665936673,
      "grad_norm": 1.878140926361084,
      "learning_rate": 4.123765828592403e-05,
      "logits/chosen": -0.6755245327949524,
      "logits/rejected": -0.5361959934234619,
      "logps/chosen": -181.31329345703125,
      "logps/rejected": -195.0155792236328,
      "loss": 0.2724,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.7007107734680176,
      "rewards/margins": 2.464524984359741,
      "rewards/rejected": -6.165235996246338,
      "step": 13360
    },
    {
      "epoch": 2.440003649968063,
      "grad_norm": 2.6017632484436035,
      "learning_rate": 4.120829510001835e-05,
      "logits/chosen": -0.6106939911842346,
      "logits/rejected": -0.39116984605789185,
      "logps/chosen": -181.819580078125,
      "logps/rejected": -202.44203186035156,
      "loss": 0.308,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -4.0630598068237305,
      "rewards/margins": 2.6324620246887207,
      "rewards/rejected": -6.695523262023926,
      "step": 13370
    },
    {
      "epoch": 2.4418286339994526,
      "grad_norm": 5.311052322387695,
      "learning_rate": 4.117893191411268e-05,
      "logits/chosen": -0.710440993309021,
      "logits/rejected": -0.5025907754898071,
      "logps/chosen": -198.89865112304688,
      "logps/rejected": -209.27572631835938,
      "loss": 0.3104,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.812100887298584,
      "rewards/margins": 2.7319321632385254,
      "rewards/rejected": -6.544033050537109,
      "step": 13380
    },
    {
      "epoch": 2.4436536180308424,
      "grad_norm": 8.036091804504395,
      "learning_rate": 4.1149568728207014e-05,
      "logits/chosen": -0.6174408197402954,
      "logits/rejected": -0.405211865901947,
      "logps/chosen": -176.23013305664062,
      "logps/rejected": -188.0094757080078,
      "loss": 0.3155,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.71372652053833,
      "rewards/margins": 2.696812152862549,
      "rewards/rejected": -6.410539150238037,
      "step": 13390
    },
    {
      "epoch": 2.445478602062232,
      "grad_norm": 3.774549961090088,
      "learning_rate": 4.1120205542301345e-05,
      "logits/chosen": -0.6208266019821167,
      "logits/rejected": -0.462146133184433,
      "logps/chosen": -182.37220764160156,
      "logps/rejected": -190.1514892578125,
      "loss": 0.2745,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.9700798988342285,
      "rewards/margins": 2.6649856567382812,
      "rewards/rejected": -6.635064601898193,
      "step": 13400
    },
    {
      "epoch": 2.447303586093622,
      "grad_norm": 6.247945308685303,
      "learning_rate": 4.109084235639567e-05,
      "logits/chosen": -0.6870529055595398,
      "logits/rejected": -0.2865573465824127,
      "logps/chosen": -193.8037567138672,
      "logps/rejected": -189.85910034179688,
      "loss": 0.2562,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.4475855827331543,
      "rewards/margins": 3.2424774169921875,
      "rewards/rejected": -6.6900634765625,
      "step": 13410
    },
    {
      "epoch": 2.449128570125011,
      "grad_norm": 2.551034450531006,
      "learning_rate": 4.1061479170489994e-05,
      "logits/chosen": -0.7842884063720703,
      "logits/rejected": -0.5368531346321106,
      "logps/chosen": -206.1670684814453,
      "logps/rejected": -210.1992645263672,
      "loss": 0.2344,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.4593939781188965,
      "rewards/margins": 3.351567029953003,
      "rewards/rejected": -6.8109612464904785,
      "step": 13420
    },
    {
      "epoch": 2.450953554156401,
      "grad_norm": 7.694979667663574,
      "learning_rate": 4.103211598458433e-05,
      "logits/chosen": -0.7236377000808716,
      "logits/rejected": -0.49432405829429626,
      "logps/chosen": -184.9778594970703,
      "logps/rejected": -194.3828887939453,
      "loss": 0.1868,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.179340124130249,
      "rewards/margins": 3.458362102508545,
      "rewards/rejected": -6.637701988220215,
      "step": 13430
    },
    {
      "epoch": 2.4527785381877907,
      "grad_norm": 3.19905686378479,
      "learning_rate": 4.100275279867866e-05,
      "logits/chosen": -0.6176217198371887,
      "logits/rejected": -0.38276150822639465,
      "logps/chosen": -170.1068878173828,
      "logps/rejected": -207.26016235351562,
      "loss": 0.3233,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.554548740386963,
      "rewards/margins": 3.1408684253692627,
      "rewards/rejected": -6.695417881011963,
      "step": 13440
    },
    {
      "epoch": 2.4546035222191804,
      "grad_norm": 4.676618576049805,
      "learning_rate": 4.097338961277299e-05,
      "logits/chosen": -0.5668419003486633,
      "logits/rejected": -0.25864630937576294,
      "logps/chosen": -173.82952880859375,
      "logps/rejected": -173.3646697998047,
      "loss": 0.2247,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.8447203636169434,
      "rewards/margins": 3.245558261871338,
      "rewards/rejected": -7.090278625488281,
      "step": 13450
    },
    {
      "epoch": 2.45642850625057,
      "grad_norm": 4.839829921722412,
      "learning_rate": 4.094402642686732e-05,
      "logits/chosen": -0.5986262559890747,
      "logits/rejected": -0.2735362648963928,
      "logps/chosen": -183.80209350585938,
      "logps/rejected": -187.51605224609375,
      "loss": 0.3726,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.3115761280059814,
      "rewards/margins": 2.8299882411956787,
      "rewards/rejected": -6.14156436920166,
      "step": 13460
    },
    {
      "epoch": 2.45825349028196,
      "grad_norm": 11.578734397888184,
      "learning_rate": 4.091466324096165e-05,
      "logits/chosen": -0.5892940163612366,
      "logits/rejected": -0.5213472843170166,
      "logps/chosen": -156.77023315429688,
      "logps/rejected": -186.38201904296875,
      "loss": 0.3066,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.204180955886841,
      "rewards/margins": 3.016160488128662,
      "rewards/rejected": -5.220341682434082,
      "step": 13470
    },
    {
      "epoch": 2.4600784743133497,
      "grad_norm": 11.925721168518066,
      "learning_rate": 4.0885300055055976e-05,
      "logits/chosen": -0.7380408644676208,
      "logits/rejected": -0.5438774824142456,
      "logps/chosen": -184.63253784179688,
      "logps/rejected": -177.64053344726562,
      "loss": 0.3138,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.639127254486084,
      "rewards/margins": 2.417813539505005,
      "rewards/rejected": -5.05694055557251,
      "step": 13480
    },
    {
      "epoch": 2.4619034583447394,
      "grad_norm": 7.141635894775391,
      "learning_rate": 4.08559368691503e-05,
      "logits/chosen": -0.7816417813301086,
      "logits/rejected": -0.5479363203048706,
      "logps/chosen": -184.4154815673828,
      "logps/rejected": -181.55917358398438,
      "loss": 0.2372,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.0133728981018066,
      "rewards/margins": 2.704878568649292,
      "rewards/rejected": -5.718251705169678,
      "step": 13490
    },
    {
      "epoch": 2.463728442376129,
      "grad_norm": 8.335843086242676,
      "learning_rate": 4.082657368324464e-05,
      "logits/chosen": -0.5940420627593994,
      "logits/rejected": -0.37740492820739746,
      "logps/chosen": -164.62844848632812,
      "logps/rejected": -194.45758056640625,
      "loss": 0.3732,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.978388547897339,
      "rewards/margins": 3.0800585746765137,
      "rewards/rejected": -6.05844783782959,
      "step": 13500
    },
    {
      "epoch": 2.465553426407519,
      "grad_norm": 2.3431177139282227,
      "learning_rate": 4.079721049733896e-05,
      "logits/chosen": -0.6845195889472961,
      "logits/rejected": -0.517351508140564,
      "logps/chosen": -165.6134796142578,
      "logps/rejected": -185.41696166992188,
      "loss": 0.2301,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.8370394706726074,
      "rewards/margins": 2.8970696926116943,
      "rewards/rejected": -5.734109401702881,
      "step": 13510
    },
    {
      "epoch": 2.4673784104389087,
      "grad_norm": 8.450813293457031,
      "learning_rate": 4.0767847311433294e-05,
      "logits/chosen": -0.5054720044136047,
      "logits/rejected": -0.32799118757247925,
      "logps/chosen": -188.1468963623047,
      "logps/rejected": -195.75979614257812,
      "loss": 0.2905,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.4019463062286377,
      "rewards/margins": 2.9970314502716064,
      "rewards/rejected": -6.398977756500244,
      "step": 13520
    },
    {
      "epoch": 2.4692033944702985,
      "grad_norm": 3.097043514251709,
      "learning_rate": 4.073848412552762e-05,
      "logits/chosen": -0.5894840359687805,
      "logits/rejected": -0.4386005401611328,
      "logps/chosen": -169.3683624267578,
      "logps/rejected": -189.83627319335938,
      "loss": 0.4066,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.5705275535583496,
      "rewards/margins": 2.471224546432495,
      "rewards/rejected": -6.041751861572266,
      "step": 13530
    },
    {
      "epoch": 2.471028378501688,
      "grad_norm": 9.439695358276367,
      "learning_rate": 4.070912093962196e-05,
      "logits/chosen": -0.6043334007263184,
      "logits/rejected": -0.4309051036834717,
      "logps/chosen": -192.94847106933594,
      "logps/rejected": -210.6016387939453,
      "loss": 0.2747,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.5881431102752686,
      "rewards/margins": 2.9699959754943848,
      "rewards/rejected": -6.558138370513916,
      "step": 13540
    },
    {
      "epoch": 2.472853362533078,
      "grad_norm": 2.068244218826294,
      "learning_rate": 4.067975775371628e-05,
      "logits/chosen": -0.5971055626869202,
      "logits/rejected": -0.4097253382205963,
      "logps/chosen": -180.58428955078125,
      "logps/rejected": -189.4720916748047,
      "loss": 0.3445,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.193189859390259,
      "rewards/margins": 2.382542133331299,
      "rewards/rejected": -5.575732231140137,
      "step": 13550
    },
    {
      "epoch": 2.4746783465644677,
      "grad_norm": 5.516907691955566,
      "learning_rate": 4.0650394567810606e-05,
      "logits/chosen": -0.5220627784729004,
      "logits/rejected": -0.36001721024513245,
      "logps/chosen": -184.34805297851562,
      "logps/rejected": -188.69595336914062,
      "loss": 0.2366,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.039731979370117,
      "rewards/margins": 2.5552029609680176,
      "rewards/rejected": -6.594935417175293,
      "step": 13560
    },
    {
      "epoch": 2.4765033305958575,
      "grad_norm": 5.158419132232666,
      "learning_rate": 4.062103138190494e-05,
      "logits/chosen": -0.4928719401359558,
      "logits/rejected": -0.27426770329475403,
      "logps/chosen": -181.09603881835938,
      "logps/rejected": -180.7420196533203,
      "loss": 0.3718,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.778820037841797,
      "rewards/margins": 2.177675724029541,
      "rewards/rejected": -5.956495761871338,
      "step": 13570
    },
    {
      "epoch": 2.4783283146272472,
      "grad_norm": 4.023253917694092,
      "learning_rate": 4.059166819599927e-05,
      "logits/chosen": -0.7228018045425415,
      "logits/rejected": -0.4904004633426666,
      "logps/chosen": -181.51918029785156,
      "logps/rejected": -174.6160888671875,
      "loss": 0.34,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.1273484230041504,
      "rewards/margins": 2.2240328788757324,
      "rewards/rejected": -5.351380348205566,
      "step": 13580
    },
    {
      "epoch": 2.480153298658637,
      "grad_norm": 2.591940402984619,
      "learning_rate": 4.05623050100936e-05,
      "logits/chosen": -0.7137001752853394,
      "logits/rejected": -0.6133630275726318,
      "logps/chosen": -154.22067260742188,
      "logps/rejected": -180.98553466796875,
      "loss": 0.2822,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.535351514816284,
      "rewards/margins": 2.738898515701294,
      "rewards/rejected": -5.27424955368042,
      "step": 13590
    },
    {
      "epoch": 2.4819782826900263,
      "grad_norm": 7.7906951904296875,
      "learning_rate": 4.0532941824187925e-05,
      "logits/chosen": -0.8194440603256226,
      "logits/rejected": -0.6058453321456909,
      "logps/chosen": -174.78439331054688,
      "logps/rejected": -199.19268798828125,
      "loss": 0.2856,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.605329990386963,
      "rewards/margins": 3.021146297454834,
      "rewards/rejected": -5.626476287841797,
      "step": 13600
    },
    {
      "epoch": 2.483803266721416,
      "grad_norm": 6.881811141967773,
      "learning_rate": 4.050357863828225e-05,
      "logits/chosen": -0.7148836851119995,
      "logits/rejected": -0.5701650977134705,
      "logps/chosen": -179.37721252441406,
      "logps/rejected": -185.26809692382812,
      "loss": 0.3804,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.8366827964782715,
      "rewards/margins": 2.312546730041504,
      "rewards/rejected": -5.149230003356934,
      "step": 13610
    },
    {
      "epoch": 2.485628250752806,
      "grad_norm": 4.878965377807617,
      "learning_rate": 4.047421545237659e-05,
      "logits/chosen": -0.7856994271278381,
      "logits/rejected": -0.5662187933921814,
      "logps/chosen": -179.89682006835938,
      "logps/rejected": -176.8377227783203,
      "loss": 0.2474,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.9622018337249756,
      "rewards/margins": 2.8463857173919678,
      "rewards/rejected": -5.808588027954102,
      "step": 13620
    },
    {
      "epoch": 2.4874532347841956,
      "grad_norm": 10.710511207580566,
      "learning_rate": 4.044485226647091e-05,
      "logits/chosen": -0.7976264953613281,
      "logits/rejected": -0.6152589917182922,
      "logps/chosen": -176.9357452392578,
      "logps/rejected": -184.78433227539062,
      "loss": 0.3034,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.7019150257110596,
      "rewards/margins": 2.702255964279175,
      "rewards/rejected": -5.404170989990234,
      "step": 13630
    },
    {
      "epoch": 2.4892782188155853,
      "grad_norm": 9.208146095275879,
      "learning_rate": 4.0415489080565243e-05,
      "logits/chosen": -0.6009257435798645,
      "logits/rejected": -0.4071223735809326,
      "logps/chosen": -181.8997039794922,
      "logps/rejected": -186.63929748535156,
      "loss": 0.2533,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.765515089035034,
      "rewards/margins": 2.9240939617156982,
      "rewards/rejected": -6.689608573913574,
      "step": 13640
    },
    {
      "epoch": 2.491103202846975,
      "grad_norm": 7.2062578201293945,
      "learning_rate": 4.0386125894659575e-05,
      "logits/chosen": -0.5866480469703674,
      "logits/rejected": -0.34490257501602173,
      "logps/chosen": -169.95181274414062,
      "logps/rejected": -186.06692504882812,
      "loss": 0.2431,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.619061231613159,
      "rewards/margins": 2.8198158740997314,
      "rewards/rejected": -6.438877105712891,
      "step": 13650
    },
    {
      "epoch": 2.492928186878365,
      "grad_norm": 5.19691276550293,
      "learning_rate": 4.0356762708753906e-05,
      "logits/chosen": -0.5578439235687256,
      "logits/rejected": -0.3193119168281555,
      "logps/chosen": -193.2476348876953,
      "logps/rejected": -197.74362182617188,
      "loss": 0.3164,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.541346788406372,
      "rewards/margins": 3.01054048538208,
      "rewards/rejected": -6.551886558532715,
      "step": 13660
    },
    {
      "epoch": 2.4947531709097546,
      "grad_norm": 6.331545352935791,
      "learning_rate": 4.032739952284823e-05,
      "logits/chosen": -0.6992283463478088,
      "logits/rejected": -0.5311673283576965,
      "logps/chosen": -177.05882263183594,
      "logps/rejected": -191.16036987304688,
      "loss": 0.2777,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.384549617767334,
      "rewards/margins": 2.9814810752868652,
      "rewards/rejected": -6.366030693054199,
      "step": 13670
    },
    {
      "epoch": 2.4965781549411443,
      "grad_norm": 9.228150367736816,
      "learning_rate": 4.0298036336942555e-05,
      "logits/chosen": -0.7405750155448914,
      "logits/rejected": -0.5137273073196411,
      "logps/chosen": -180.58352661132812,
      "logps/rejected": -188.24903869628906,
      "loss": 0.4047,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.296175479888916,
      "rewards/margins": 2.8496768474578857,
      "rewards/rejected": -6.145852088928223,
      "step": 13680
    },
    {
      "epoch": 2.498403138972534,
      "grad_norm": 5.060422897338867,
      "learning_rate": 4.0268673151036893e-05,
      "logits/chosen": -0.6219225525856018,
      "logits/rejected": -0.3734492361545563,
      "logps/chosen": -178.4434814453125,
      "logps/rejected": -180.03384399414062,
      "loss": 0.3743,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.523646116256714,
      "rewards/margins": 2.8311970233917236,
      "rewards/rejected": -6.354842185974121,
      "step": 13690
    },
    {
      "epoch": 2.500228123003924,
      "grad_norm": 4.6800737380981445,
      "learning_rate": 4.023930996513122e-05,
      "logits/chosen": -0.729386031627655,
      "logits/rejected": -0.5058496594429016,
      "logps/chosen": -168.2530975341797,
      "logps/rejected": -181.00265502929688,
      "loss": 0.2156,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.1555094718933105,
      "rewards/margins": 3.0386760234832764,
      "rewards/rejected": -6.194185256958008,
      "step": 13700
    },
    {
      "epoch": 2.5020531070353136,
      "grad_norm": 4.027235507965088,
      "learning_rate": 4.020994677922555e-05,
      "logits/chosen": -0.6378278732299805,
      "logits/rejected": -0.36952298879623413,
      "logps/chosen": -162.86636352539062,
      "logps/rejected": -168.93179321289062,
      "loss": 0.2565,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.133744955062866,
      "rewards/margins": 3.0733141899108887,
      "rewards/rejected": -6.207059860229492,
      "step": 13710
    },
    {
      "epoch": 2.503878091066703,
      "grad_norm": 7.169280529022217,
      "learning_rate": 4.0180583593319874e-05,
      "logits/chosen": -0.6088584661483765,
      "logits/rejected": -0.37783271074295044,
      "logps/chosen": -186.25421142578125,
      "logps/rejected": -189.19424438476562,
      "loss": 0.2915,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.3689868450164795,
      "rewards/margins": 2.7877793312072754,
      "rewards/rejected": -6.156766414642334,
      "step": 13720
    },
    {
      "epoch": 2.5057030750980926,
      "grad_norm": 5.632132053375244,
      "learning_rate": 4.015122040741421e-05,
      "logits/chosen": -0.7663296461105347,
      "logits/rejected": -0.6041357517242432,
      "logps/chosen": -175.3887176513672,
      "logps/rejected": -190.577392578125,
      "loss": 0.4001,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.225917100906372,
      "rewards/margins": 2.4647390842437744,
      "rewards/rejected": -5.6906561851501465,
      "step": 13730
    },
    {
      "epoch": 2.5075280591294824,
      "grad_norm": 4.836274147033691,
      "learning_rate": 4.012185722150854e-05,
      "logits/chosen": -0.8249773979187012,
      "logits/rejected": -0.6199814081192017,
      "logps/chosen": -190.5259246826172,
      "logps/rejected": -182.63900756835938,
      "loss": 0.301,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.7390847206115723,
      "rewards/margins": 2.58297061920166,
      "rewards/rejected": -5.322054862976074,
      "step": 13740
    },
    {
      "epoch": 2.509353043160872,
      "grad_norm": 6.53187894821167,
      "learning_rate": 4.009249403560287e-05,
      "logits/chosen": -0.7455594539642334,
      "logits/rejected": -0.5949721336364746,
      "logps/chosen": -181.06967163085938,
      "logps/rejected": -186.61439514160156,
      "loss": 0.3476,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.6595470905303955,
      "rewards/margins": 2.4098591804504395,
      "rewards/rejected": -6.069406032562256,
      "step": 13750
    },
    {
      "epoch": 2.511178027192262,
      "grad_norm": 4.296844959259033,
      "learning_rate": 4.006313084969719e-05,
      "logits/chosen": -0.8077684640884399,
      "logits/rejected": -0.6383679509162903,
      "logps/chosen": -187.74124145507812,
      "logps/rejected": -189.4136505126953,
      "loss": 0.3523,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.4599690437316895,
      "rewards/margins": 2.311835527420044,
      "rewards/rejected": -5.771804332733154,
      "step": 13760
    },
    {
      "epoch": 2.5130030112236517,
      "grad_norm": 4.263110160827637,
      "learning_rate": 4.003376766379153e-05,
      "logits/chosen": -0.8193869590759277,
      "logits/rejected": -0.6698232889175415,
      "logps/chosen": -177.01588439941406,
      "logps/rejected": -188.17250061035156,
      "loss": 0.3253,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.33638072013855,
      "rewards/margins": 2.472745418548584,
      "rewards/rejected": -5.809126377105713,
      "step": 13770
    },
    {
      "epoch": 2.5148279952550414,
      "grad_norm": 6.473967552185059,
      "learning_rate": 4.0004404477885855e-05,
      "logits/chosen": -0.8337791562080383,
      "logits/rejected": -0.6403740048408508,
      "logps/chosen": -179.83570861816406,
      "logps/rejected": -197.71876525878906,
      "loss": 0.2665,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.2879669666290283,
      "rewards/margins": 3.1088385581970215,
      "rewards/rejected": -6.396805763244629,
      "step": 13780
    },
    {
      "epoch": 2.516652979286431,
      "grad_norm": 5.448689937591553,
      "learning_rate": 3.997504129198018e-05,
      "logits/chosen": -0.8789548873901367,
      "logits/rejected": -0.7315806150436401,
      "logps/chosen": -172.82315063476562,
      "logps/rejected": -181.90634155273438,
      "loss": 0.3333,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.5135490894317627,
      "rewards/margins": 2.3125452995300293,
      "rewards/rejected": -5.8260931968688965,
      "step": 13790
    },
    {
      "epoch": 2.518477963317821,
      "grad_norm": 6.119162559509277,
      "learning_rate": 3.994567810607451e-05,
      "logits/chosen": -0.7629311084747314,
      "logits/rejected": -0.5745548009872437,
      "logps/chosen": -169.5449981689453,
      "logps/rejected": -178.8170623779297,
      "loss": 0.2333,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.5081169605255127,
      "rewards/margins": 2.7131338119506836,
      "rewards/rejected": -6.221251010894775,
      "step": 13800
    },
    {
      "epoch": 2.5203029473492107,
      "grad_norm": 5.896471977233887,
      "learning_rate": 3.991631492016884e-05,
      "logits/chosen": -0.8083996772766113,
      "logits/rejected": -0.5943275690078735,
      "logps/chosen": -184.62063598632812,
      "logps/rejected": -191.71832275390625,
      "loss": 0.2262,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.4669947624206543,
      "rewards/margins": 3.0186822414398193,
      "rewards/rejected": -6.485677242279053,
      "step": 13810
    },
    {
      "epoch": 2.5221279313806004,
      "grad_norm": 7.566993713378906,
      "learning_rate": 3.9886951734263174e-05,
      "logits/chosen": -0.7888813018798828,
      "logits/rejected": -0.6364989876747131,
      "logps/chosen": -196.8616180419922,
      "logps/rejected": -204.02481079101562,
      "loss": 0.3593,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.5734734535217285,
      "rewards/margins": 2.5324487686157227,
      "rewards/rejected": -6.105921745300293,
      "step": 13820
    },
    {
      "epoch": 2.52395291541199,
      "grad_norm": 4.4295148849487305,
      "learning_rate": 3.9857588548357505e-05,
      "logits/chosen": -0.9409187436103821,
      "logits/rejected": -0.8214925527572632,
      "logps/chosen": -175.7929229736328,
      "logps/rejected": -191.38775634765625,
      "loss": 0.3253,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.1249728202819824,
      "rewards/margins": 2.5546741485595703,
      "rewards/rejected": -5.6796464920043945,
      "step": 13830
    },
    {
      "epoch": 2.52577789944338,
      "grad_norm": 2.5351710319519043,
      "learning_rate": 3.982822536245183e-05,
      "logits/chosen": -0.9059879183769226,
      "logits/rejected": -0.7472622990608215,
      "logps/chosen": -161.18397521972656,
      "logps/rejected": -185.3994140625,
      "loss": 0.1731,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.8307082653045654,
      "rewards/margins": 3.2362771034240723,
      "rewards/rejected": -6.066985130310059,
      "step": 13840
    },
    {
      "epoch": 2.5276028834747697,
      "grad_norm": 3.764756679534912,
      "learning_rate": 3.979886217654616e-05,
      "logits/chosen": -0.8936768770217896,
      "logits/rejected": -0.736092209815979,
      "logps/chosen": -180.60195922851562,
      "logps/rejected": -175.05413818359375,
      "loss": 0.3219,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.0602540969848633,
      "rewards/margins": 2.7716305255889893,
      "rewards/rejected": -5.831884860992432,
      "step": 13850
    },
    {
      "epoch": 2.5294278675061594,
      "grad_norm": 8.306784629821777,
      "learning_rate": 3.9769498990640486e-05,
      "logits/chosen": -0.9496220350265503,
      "logits/rejected": -0.7223421335220337,
      "logps/chosen": -193.0515594482422,
      "logps/rejected": -197.3740234375,
      "loss": 0.2876,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.080960988998413,
      "rewards/margins": 2.9684059619903564,
      "rewards/rejected": -6.0493669509887695,
      "step": 13860
    },
    {
      "epoch": 2.531252851537549,
      "grad_norm": 7.318562030792236,
      "learning_rate": 3.974013580473482e-05,
      "logits/chosen": -0.8967751264572144,
      "logits/rejected": -0.7108744382858276,
      "logps/chosen": -187.41659545898438,
      "logps/rejected": -188.81509399414062,
      "loss": 0.2763,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.8999388217926025,
      "rewards/margins": 2.960649251937866,
      "rewards/rejected": -5.860589027404785,
      "step": 13870
    },
    {
      "epoch": 2.533077835568939,
      "grad_norm": 6.111806392669678,
      "learning_rate": 3.971077261882915e-05,
      "logits/chosen": -0.7443453669548035,
      "logits/rejected": -0.6171083450317383,
      "logps/chosen": -181.1419219970703,
      "logps/rejected": -190.5154266357422,
      "loss": 0.3925,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -4.059016227722168,
      "rewards/margins": 2.4451191425323486,
      "rewards/rejected": -6.504136085510254,
      "step": 13880
    },
    {
      "epoch": 2.5349028196003287,
      "grad_norm": 12.225135803222656,
      "learning_rate": 3.968140943292348e-05,
      "logits/chosen": -0.8925867080688477,
      "logits/rejected": -0.5755568146705627,
      "logps/chosen": -201.46502685546875,
      "logps/rejected": -193.64419555664062,
      "loss": 0.2536,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.2380993366241455,
      "rewards/margins": 3.0341756343841553,
      "rewards/rejected": -6.272274971008301,
      "step": 13890
    },
    {
      "epoch": 2.5367278036317185,
      "grad_norm": 5.953223705291748,
      "learning_rate": 3.9652046247017804e-05,
      "logits/chosen": -0.6102794408798218,
      "logits/rejected": -0.4781588912010193,
      "logps/chosen": -195.42593383789062,
      "logps/rejected": -194.21713256835938,
      "loss": 0.3997,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.238334655761719,
      "rewards/margins": 1.9847577810287476,
      "rewards/rejected": -6.223093032836914,
      "step": 13900
    },
    {
      "epoch": 2.538552787663108,
      "grad_norm": 7.641081809997559,
      "learning_rate": 3.9622683061112136e-05,
      "logits/chosen": -0.6952555179595947,
      "logits/rejected": -0.5785689353942871,
      "logps/chosen": -191.34225463867188,
      "logps/rejected": -215.77481079101562,
      "loss": 0.2891,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.768203020095825,
      "rewards/margins": 2.8837006092071533,
      "rewards/rejected": -6.6519036293029785,
      "step": 13910
    },
    {
      "epoch": 2.5403777716944975,
      "grad_norm": 9.466443061828613,
      "learning_rate": 3.959331987520646e-05,
      "logits/chosen": -0.7176553010940552,
      "logits/rejected": -0.4002450406551361,
      "logps/chosen": -193.4816131591797,
      "logps/rejected": -177.2118377685547,
      "loss": 0.3863,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -4.242842674255371,
      "rewards/margins": 2.2131757736206055,
      "rewards/rejected": -6.456018924713135,
      "step": 13920
    },
    {
      "epoch": 2.5422027557258873,
      "grad_norm": 5.3290839195251465,
      "learning_rate": 3.956395668930079e-05,
      "logits/chosen": -0.6755055785179138,
      "logits/rejected": -0.4885333478450775,
      "logps/chosen": -185.71768188476562,
      "logps/rejected": -190.3256072998047,
      "loss": 0.2312,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.8664309978485107,
      "rewards/margins": 2.754429340362549,
      "rewards/rejected": -6.6208600997924805,
      "step": 13930
    },
    {
      "epoch": 2.544027739757277,
      "grad_norm": 2.6903188228607178,
      "learning_rate": 3.953459350339512e-05,
      "logits/chosen": -0.6884382963180542,
      "logits/rejected": -0.3951728045940399,
      "logps/chosen": -172.67318725585938,
      "logps/rejected": -177.16293334960938,
      "loss": 0.1604,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.2604012489318848,
      "rewards/margins": 3.3395209312438965,
      "rewards/rejected": -6.599922180175781,
      "step": 13940
    },
    {
      "epoch": 2.545852723788667,
      "grad_norm": 12.201681137084961,
      "learning_rate": 3.9505230317489454e-05,
      "logits/chosen": -0.6093766093254089,
      "logits/rejected": -0.4490070939064026,
      "logps/chosen": -191.0059051513672,
      "logps/rejected": -197.6503448486328,
      "loss": 0.3968,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.863058090209961,
      "rewards/margins": 2.310286045074463,
      "rewards/rejected": -6.173344612121582,
      "step": 13950
    },
    {
      "epoch": 2.5476777078200565,
      "grad_norm": 9.918058395385742,
      "learning_rate": 3.947586713158378e-05,
      "logits/chosen": -0.5760123133659363,
      "logits/rejected": -0.32362812757492065,
      "logps/chosen": -184.6263885498047,
      "logps/rejected": -198.027099609375,
      "loss": 0.3002,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -4.31427526473999,
      "rewards/margins": 2.930720567703247,
      "rewards/rejected": -7.244996070861816,
      "step": 13960
    },
    {
      "epoch": 2.5495026918514463,
      "grad_norm": 5.5522260665893555,
      "learning_rate": 3.944650394567811e-05,
      "logits/chosen": -0.6711137890815735,
      "logits/rejected": -0.5121495127677917,
      "logps/chosen": -170.07040405273438,
      "logps/rejected": -188.37283325195312,
      "loss": 0.264,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.8123881816864014,
      "rewards/margins": 2.769918203353882,
      "rewards/rejected": -6.5823073387146,
      "step": 13970
    },
    {
      "epoch": 2.551327675882836,
      "grad_norm": 9.923771858215332,
      "learning_rate": 3.9417140759772435e-05,
      "logits/chosen": -0.7373780012130737,
      "logits/rejected": -0.46125268936157227,
      "logps/chosen": -191.0815887451172,
      "logps/rejected": -186.90286254882812,
      "loss": 0.4265,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.75597882270813,
      "rewards/margins": 2.571438789367676,
      "rewards/rejected": -6.327417850494385,
      "step": 13980
    },
    {
      "epoch": 2.553152659914226,
      "grad_norm": 13.141478538513184,
      "learning_rate": 3.9387777573866766e-05,
      "logits/chosen": -0.8584542274475098,
      "logits/rejected": -0.654381275177002,
      "logps/chosen": -187.8313751220703,
      "logps/rejected": -193.41049194335938,
      "loss": 0.391,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.4263789653778076,
      "rewards/margins": 2.645308017730713,
      "rewards/rejected": -6.0716872215271,
      "step": 13990
    },
    {
      "epoch": 2.5549776439456156,
      "grad_norm": 1.3118246793746948,
      "learning_rate": 3.93584143879611e-05,
      "logits/chosen": -0.8332217931747437,
      "logits/rejected": -0.6266047954559326,
      "logps/chosen": -188.109375,
      "logps/rejected": -204.89578247070312,
      "loss": 0.2277,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.531315326690674,
      "rewards/margins": 3.2663321495056152,
      "rewards/rejected": -6.797647953033447,
      "step": 14000
    },
    {
      "epoch": 2.5568026279770053,
      "grad_norm": 8.837515830993652,
      "learning_rate": 3.932905120205543e-05,
      "logits/chosen": -0.8648897409439087,
      "logits/rejected": -0.6035063862800598,
      "logps/chosen": -186.2024383544922,
      "logps/rejected": -189.24832153320312,
      "loss": 0.2411,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.8844687938690186,
      "rewards/margins": 3.062086582183838,
      "rewards/rejected": -6.946555137634277,
      "step": 14010
    },
    {
      "epoch": 2.558627612008395,
      "grad_norm": 4.896420955657959,
      "learning_rate": 3.929968801614976e-05,
      "logits/chosen": -0.8467076420783997,
      "logits/rejected": -0.6175379753112793,
      "logps/chosen": -192.95974731445312,
      "logps/rejected": -192.29605102539062,
      "loss": 0.2701,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.92305064201355,
      "rewards/margins": 2.840404987335205,
      "rewards/rejected": -6.763455867767334,
      "step": 14020
    },
    {
      "epoch": 2.560452596039785,
      "grad_norm": 2.8216583728790283,
      "learning_rate": 3.9270324830244085e-05,
      "logits/chosen": -0.8468965291976929,
      "logits/rejected": -0.6113588213920593,
      "logps/chosen": -180.01174926757812,
      "logps/rejected": -190.72674560546875,
      "loss": 0.1753,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.6522598266601562,
      "rewards/margins": 3.5881056785583496,
      "rewards/rejected": -7.240365505218506,
      "step": 14030
    },
    {
      "epoch": 2.562277580071174,
      "grad_norm": 6.499327182769775,
      "learning_rate": 3.9240961644338416e-05,
      "logits/chosen": -0.6404334306716919,
      "logits/rejected": -0.363457053899765,
      "logps/chosen": -197.33261108398438,
      "logps/rejected": -208.98617553710938,
      "loss": 0.236,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.961865186691284,
      "rewards/margins": 3.504373550415039,
      "rewards/rejected": -7.466238498687744,
      "step": 14040
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 8.882332801818848,
      "learning_rate": 3.921159845843274e-05,
      "logits/chosen": -0.5549451112747192,
      "logits/rejected": -0.399967759847641,
      "logps/chosen": -174.61618041992188,
      "logps/rejected": -198.54127502441406,
      "loss": 0.3469,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.434134006500244,
      "rewards/margins": 3.2949135303497314,
      "rewards/rejected": -7.7290472984313965,
      "step": 14050
    },
    {
      "epoch": 2.5659275481339536,
      "grad_norm": 5.216674327850342,
      "learning_rate": 3.918223527252707e-05,
      "logits/chosen": -0.6528903245925903,
      "logits/rejected": -0.3567756116390228,
      "logps/chosen": -178.80479431152344,
      "logps/rejected": -191.72586059570312,
      "loss": 0.2894,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -4.328056335449219,
      "rewards/margins": 3.0459084510803223,
      "rewards/rejected": -7.373964786529541,
      "step": 14060
    },
    {
      "epoch": 2.5677525321653434,
      "grad_norm": 9.311878204345703,
      "learning_rate": 3.9152872086621403e-05,
      "logits/chosen": -0.6855667233467102,
      "logits/rejected": -0.511783242225647,
      "logps/chosen": -175.50714111328125,
      "logps/rejected": -191.9368896484375,
      "loss": 0.3352,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -4.203051567077637,
      "rewards/margins": 2.9060044288635254,
      "rewards/rejected": -7.109055519104004,
      "step": 14070
    },
    {
      "epoch": 2.569577516196733,
      "grad_norm": 4.876266956329346,
      "learning_rate": 3.9123508900715735e-05,
      "logits/chosen": -0.653866171836853,
      "logits/rejected": -0.4704506993293762,
      "logps/chosen": -169.3186798095703,
      "logps/rejected": -190.83273315429688,
      "loss": 0.2519,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -4.05330753326416,
      "rewards/margins": 3.220898151397705,
      "rewards/rejected": -7.274205684661865,
      "step": 14080
    },
    {
      "epoch": 2.571402500228123,
      "grad_norm": 2.325505256652832,
      "learning_rate": 3.909414571481006e-05,
      "logits/chosen": -0.741661787033081,
      "logits/rejected": -0.4773017466068268,
      "logps/chosen": -191.4327850341797,
      "logps/rejected": -190.21214294433594,
      "loss": 0.2334,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.6768641471862793,
      "rewards/margins": 3.1960461139678955,
      "rewards/rejected": -6.872910499572754,
      "step": 14090
    },
    {
      "epoch": 2.5732274842595126,
      "grad_norm": 8.699475288391113,
      "learning_rate": 3.906478252890439e-05,
      "logits/chosen": -0.7717363238334656,
      "logits/rejected": -0.5585054755210876,
      "logps/chosen": -164.82473754882812,
      "logps/rejected": -180.66561889648438,
      "loss": 0.2995,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.576319456100464,
      "rewards/margins": 3.246978759765625,
      "rewards/rejected": -6.823298454284668,
      "step": 14100
    },
    {
      "epoch": 2.5750524682909024,
      "grad_norm": 2.5534331798553467,
      "learning_rate": 3.9035419342998715e-05,
      "logits/chosen": -0.7716079354286194,
      "logits/rejected": -0.658706545829773,
      "logps/chosen": -165.3429718017578,
      "logps/rejected": -187.70724487304688,
      "loss": 0.3725,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.4709575176239014,
      "rewards/margins": 2.33225154876709,
      "rewards/rejected": -5.8032097816467285,
      "step": 14110
    },
    {
      "epoch": 2.576877452322292,
      "grad_norm": 11.765105247497559,
      "learning_rate": 3.900605615709305e-05,
      "logits/chosen": -0.8542844653129578,
      "logits/rejected": -0.6619239449501038,
      "logps/chosen": -177.05831909179688,
      "logps/rejected": -198.32974243164062,
      "loss": 0.2039,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.386507034301758,
      "rewards/margins": 3.5199973583221436,
      "rewards/rejected": -5.906504154205322,
      "step": 14120
    },
    {
      "epoch": 2.578702436353682,
      "grad_norm": 14.713820457458496,
      "learning_rate": 3.897669297118738e-05,
      "logits/chosen": -0.6279340982437134,
      "logits/rejected": -0.536549985408783,
      "logps/chosen": -170.9328155517578,
      "logps/rejected": -196.91416931152344,
      "loss": 0.5928,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -4.096750736236572,
      "rewards/margins": 2.2217817306518555,
      "rewards/rejected": -6.3185319900512695,
      "step": 14130
    },
    {
      "epoch": 2.5805274203850717,
      "grad_norm": 4.83259391784668,
      "learning_rate": 3.894732978528171e-05,
      "logits/chosen": -0.8172950744628906,
      "logits/rejected": -0.641845166683197,
      "logps/chosen": -180.8771514892578,
      "logps/rejected": -189.9923858642578,
      "loss": 0.2372,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.027404308319092,
      "rewards/margins": 2.60001277923584,
      "rewards/rejected": -5.627417087554932,
      "step": 14140
    },
    {
      "epoch": 2.5823524044164614,
      "grad_norm": 0.23186296224594116,
      "learning_rate": 3.8917966599376034e-05,
      "logits/chosen": -0.761320948600769,
      "logits/rejected": -0.5758054256439209,
      "logps/chosen": -169.12841796875,
      "logps/rejected": -179.8636016845703,
      "loss": 0.2816,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.97517728805542,
      "rewards/margins": 2.8528971672058105,
      "rewards/rejected": -5.8280744552612305,
      "step": 14150
    },
    {
      "epoch": 2.584177388447851,
      "grad_norm": 2.363131046295166,
      "learning_rate": 3.8888603413470365e-05,
      "logits/chosen": -0.8076880574226379,
      "logits/rejected": -0.6094791293144226,
      "logps/chosen": -207.2749786376953,
      "logps/rejected": -201.63937377929688,
      "loss": 0.3095,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.4669766426086426,
      "rewards/margins": 2.7640089988708496,
      "rewards/rejected": -6.230985641479492,
      "step": 14160
    },
    {
      "epoch": 2.586002372479241,
      "grad_norm": 11.014144897460938,
      "learning_rate": 3.885924022756469e-05,
      "logits/chosen": -0.6863524913787842,
      "logits/rejected": -0.48545846343040466,
      "logps/chosen": -205.37442016601562,
      "logps/rejected": -226.22195434570312,
      "loss": 0.3399,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -4.325095176696777,
      "rewards/margins": 2.786318302154541,
      "rewards/rejected": -7.111413478851318,
      "step": 14170
    },
    {
      "epoch": 2.5878273565106307,
      "grad_norm": 8.672329902648926,
      "learning_rate": 3.882987704165902e-05,
      "logits/chosen": -0.7429891228675842,
      "logits/rejected": -0.4121538996696472,
      "logps/chosen": -192.4571990966797,
      "logps/rejected": -201.2044219970703,
      "loss": 0.2123,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.064199924468994,
      "rewards/margins": 3.2305874824523926,
      "rewards/rejected": -6.2947869300842285,
      "step": 14180
    },
    {
      "epoch": 2.5896523405420204,
      "grad_norm": 1.8207873106002808,
      "learning_rate": 3.880051385575335e-05,
      "logits/chosen": -0.7117685675621033,
      "logits/rejected": -0.5470979809761047,
      "logps/chosen": -169.06198120117188,
      "logps/rejected": -190.99310302734375,
      "loss": 0.3248,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.1151065826416016,
      "rewards/margins": 3.0926012992858887,
      "rewards/rejected": -6.20770788192749,
      "step": 14190
    },
    {
      "epoch": 2.59147732457341,
      "grad_norm": 11.842730522155762,
      "learning_rate": 3.8771150669847684e-05,
      "logits/chosen": -0.7786102294921875,
      "logits/rejected": -0.672164797782898,
      "logps/chosen": -169.75088500976562,
      "logps/rejected": -194.5380401611328,
      "loss": 0.2337,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.8144919872283936,
      "rewards/margins": 3.107095241546631,
      "rewards/rejected": -5.9215874671936035,
      "step": 14200
    },
    {
      "epoch": 2.5933023086048,
      "grad_norm": 1.3103522062301636,
      "learning_rate": 3.8741787483942015e-05,
      "logits/chosen": -0.6786373853683472,
      "logits/rejected": -0.39741119742393494,
      "logps/chosen": -164.5177459716797,
      "logps/rejected": -178.23196411132812,
      "loss": 0.2261,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.9594926834106445,
      "rewards/margins": 3.1565403938293457,
      "rewards/rejected": -6.116032600402832,
      "step": 14210
    },
    {
      "epoch": 2.5951272926361897,
      "grad_norm": 4.599952220916748,
      "learning_rate": 3.871242429803634e-05,
      "logits/chosen": -0.7192917466163635,
      "logits/rejected": -0.5351258516311646,
      "logps/chosen": -179.18624877929688,
      "logps/rejected": -190.27040100097656,
      "loss": 0.2147,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.7440109252929688,
      "rewards/margins": 3.2195448875427246,
      "rewards/rejected": -6.963555335998535,
      "step": 14220
    },
    {
      "epoch": 2.596952276667579,
      "grad_norm": 7.115242004394531,
      "learning_rate": 3.868306111213067e-05,
      "logits/chosen": -0.6011606454849243,
      "logits/rejected": -0.3949091136455536,
      "logps/chosen": -191.13230895996094,
      "logps/rejected": -178.4480438232422,
      "loss": 0.5064,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -4.074820518493652,
      "rewards/margins": 2.758833646774292,
      "rewards/rejected": -6.833654880523682,
      "step": 14230
    },
    {
      "epoch": 2.5987772606989687,
      "grad_norm": 8.209612846374512,
      "learning_rate": 3.8653697926224996e-05,
      "logits/chosen": -0.6227826476097107,
      "logits/rejected": -0.45174774527549744,
      "logps/chosen": -175.0929718017578,
      "logps/rejected": -199.62705993652344,
      "loss": 0.3792,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.7551090717315674,
      "rewards/margins": 3.4083423614501953,
      "rewards/rejected": -7.163450717926025,
      "step": 14240
    },
    {
      "epoch": 2.6006022447303585,
      "grad_norm": 4.954439640045166,
      "learning_rate": 3.862433474031933e-05,
      "logits/chosen": -0.687606930732727,
      "logits/rejected": -0.4710339903831482,
      "logps/chosen": -176.9888458251953,
      "logps/rejected": -174.36819458007812,
      "loss": 0.2303,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.408034563064575,
      "rewards/margins": 3.0544211864471436,
      "rewards/rejected": -6.462455749511719,
      "step": 14250
    },
    {
      "epoch": 2.6024272287617483,
      "grad_norm": 4.904475212097168,
      "learning_rate": 3.859497155441366e-05,
      "logits/chosen": -0.6172007918357849,
      "logits/rejected": -0.5486526489257812,
      "logps/chosen": -168.70945739746094,
      "logps/rejected": -194.7093505859375,
      "loss": 0.28,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.9145381450653076,
      "rewards/margins": 2.8258588314056396,
      "rewards/rejected": -6.740396976470947,
      "step": 14260
    },
    {
      "epoch": 2.604252212793138,
      "grad_norm": 2.6193959712982178,
      "learning_rate": 3.856560836850799e-05,
      "logits/chosen": -0.6069568395614624,
      "logits/rejected": -0.576367974281311,
      "logps/chosen": -160.73178100585938,
      "logps/rejected": -201.0598907470703,
      "loss": 0.2487,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.8691279888153076,
      "rewards/margins": 3.3868911266326904,
      "rewards/rejected": -7.25601863861084,
      "step": 14270
    },
    {
      "epoch": 2.6060771968245278,
      "grad_norm": 8.063333511352539,
      "learning_rate": 3.8536245182602314e-05,
      "logits/chosen": -0.756095826625824,
      "logits/rejected": -0.6433446407318115,
      "logps/chosen": -175.40921020507812,
      "logps/rejected": -217.50741577148438,
      "loss": 0.2434,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.3658223152160645,
      "rewards/margins": 3.5147907733917236,
      "rewards/rejected": -6.880612373352051,
      "step": 14280
    },
    {
      "epoch": 2.6079021808559175,
      "grad_norm": 5.44606351852417,
      "learning_rate": 3.8506881996696646e-05,
      "logits/chosen": -0.736075758934021,
      "logits/rejected": -0.44089022278785706,
      "logps/chosen": -187.9101104736328,
      "logps/rejected": -198.5970001220703,
      "loss": 0.2709,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.736624240875244,
      "rewards/margins": 3.5608773231506348,
      "rewards/rejected": -7.297502040863037,
      "step": 14290
    },
    {
      "epoch": 2.6097271648873073,
      "grad_norm": 11.768445014953613,
      "learning_rate": 3.847751881079097e-05,
      "logits/chosen": -0.7113994359970093,
      "logits/rejected": -0.5895963907241821,
      "logps/chosen": -176.3441162109375,
      "logps/rejected": -195.85977172851562,
      "loss": 0.4804,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.708535671234131,
      "rewards/margins": 2.374220371246338,
      "rewards/rejected": -6.0827555656433105,
      "step": 14300
    },
    {
      "epoch": 2.611552148918697,
      "grad_norm": 0.7083013653755188,
      "learning_rate": 3.84481556248853e-05,
      "logits/chosen": -0.7464589476585388,
      "logits/rejected": -0.657691478729248,
      "logps/chosen": -182.00424194335938,
      "logps/rejected": -193.74790954589844,
      "loss": 0.3364,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.1615989208221436,
      "rewards/margins": 2.5016286373138428,
      "rewards/rejected": -5.663227081298828,
      "step": 14310
    },
    {
      "epoch": 2.613377132950087,
      "grad_norm": 10.292710304260254,
      "learning_rate": 3.841879243897963e-05,
      "logits/chosen": -0.7589419484138489,
      "logits/rejected": -0.6031690835952759,
      "logps/chosen": -191.12353515625,
      "logps/rejected": -198.20315551757812,
      "loss": 0.4488,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.9547855854034424,
      "rewards/margins": 2.425043821334839,
      "rewards/rejected": -6.379829406738281,
      "step": 14320
    },
    {
      "epoch": 2.6152021169814765,
      "grad_norm": 1.9504458904266357,
      "learning_rate": 3.8389429253073964e-05,
      "logits/chosen": -0.8408747911453247,
      "logits/rejected": -0.6005784869194031,
      "logps/chosen": -194.2251434326172,
      "logps/rejected": -188.41616821289062,
      "loss": 0.2696,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.207371473312378,
      "rewards/margins": 2.854383945465088,
      "rewards/rejected": -6.061755657196045,
      "step": 14330
    },
    {
      "epoch": 2.6170271010128663,
      "grad_norm": 7.896478176116943,
      "learning_rate": 3.836006606716829e-05,
      "logits/chosen": -0.745193600654602,
      "logits/rejected": -0.5987831354141235,
      "logps/chosen": -172.18959045410156,
      "logps/rejected": -198.5762939453125,
      "loss": 0.2617,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.341980457305908,
      "rewards/margins": 3.1207973957061768,
      "rewards/rejected": -6.462777614593506,
      "step": 14340
    },
    {
      "epoch": 2.6188520850442556,
      "grad_norm": 7.483943939208984,
      "learning_rate": 3.833070288126262e-05,
      "logits/chosen": -0.7709447741508484,
      "logits/rejected": -0.575282096862793,
      "logps/chosen": -173.25303649902344,
      "logps/rejected": -183.89910888671875,
      "loss": 0.2897,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.9753448963165283,
      "rewards/margins": 2.79354190826416,
      "rewards/rejected": -5.768887042999268,
      "step": 14350
    },
    {
      "epoch": 2.6206770690756453,
      "grad_norm": 6.523454666137695,
      "learning_rate": 3.8301339695356945e-05,
      "logits/chosen": -0.7951127290725708,
      "logits/rejected": -0.6739349365234375,
      "logps/chosen": -183.087158203125,
      "logps/rejected": -186.30984497070312,
      "loss": 0.3221,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.079993486404419,
      "rewards/margins": 2.3225085735321045,
      "rewards/rejected": -5.402502059936523,
      "step": 14360
    },
    {
      "epoch": 2.622502053107035,
      "grad_norm": 5.02913236618042,
      "learning_rate": 3.8271976509451276e-05,
      "logits/chosen": -0.9412071108818054,
      "logits/rejected": -0.7108238339424133,
      "logps/chosen": -194.8143310546875,
      "logps/rejected": -182.4156036376953,
      "loss": 0.2858,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.5597145557403564,
      "rewards/margins": 2.917661666870117,
      "rewards/rejected": -5.4773759841918945,
      "step": 14370
    },
    {
      "epoch": 2.624327037138425,
      "grad_norm": 6.802626609802246,
      "learning_rate": 3.824261332354561e-05,
      "logits/chosen": -0.7882993817329407,
      "logits/rejected": -0.5943001508712769,
      "logps/chosen": -186.00662231445312,
      "logps/rejected": -184.45556640625,
      "loss": 0.3439,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.5486361980438232,
      "rewards/margins": 2.501734495162964,
      "rewards/rejected": -6.050370216369629,
      "step": 14380
    },
    {
      "epoch": 2.6261520211698146,
      "grad_norm": 5.403294563293457,
      "learning_rate": 3.821325013763994e-05,
      "logits/chosen": -0.8557515144348145,
      "logits/rejected": -0.7452095150947571,
      "logps/chosen": -190.9574432373047,
      "logps/rejected": -198.65869140625,
      "loss": 0.326,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.6269004344940186,
      "rewards/margins": 2.398725748062134,
      "rewards/rejected": -6.025626182556152,
      "step": 14390
    },
    {
      "epoch": 2.6279770052012044,
      "grad_norm": 1.7082858085632324,
      "learning_rate": 3.818388695173427e-05,
      "logits/chosen": -0.7155052423477173,
      "logits/rejected": -0.6091577410697937,
      "logps/chosen": -180.67205810546875,
      "logps/rejected": -180.89956665039062,
      "loss": 0.2301,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.0273051261901855,
      "rewards/margins": 2.550332546234131,
      "rewards/rejected": -5.577637672424316,
      "step": 14400
    },
    {
      "epoch": 2.629801989232594,
      "grad_norm": 3.078566789627075,
      "learning_rate": 3.8154523765828595e-05,
      "logits/chosen": -0.7514052987098694,
      "logits/rejected": -0.5347379446029663,
      "logps/chosen": -182.67120361328125,
      "logps/rejected": -185.63446044921875,
      "loss": 0.3301,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.307699680328369,
      "rewards/margins": 2.5067152976989746,
      "rewards/rejected": -5.81441593170166,
      "step": 14410
    },
    {
      "epoch": 2.631626973263984,
      "grad_norm": 5.139407157897949,
      "learning_rate": 3.8125160579922926e-05,
      "logits/chosen": -0.7956588864326477,
      "logits/rejected": -0.4974822998046875,
      "logps/chosen": -206.25289916992188,
      "logps/rejected": -187.5833740234375,
      "loss": 0.3385,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.0680394172668457,
      "rewards/margins": 2.497985363006592,
      "rewards/rejected": -5.566024303436279,
      "step": 14420
    },
    {
      "epoch": 2.6334519572953736,
      "grad_norm": 3.095646381378174,
      "learning_rate": 3.809579739401725e-05,
      "logits/chosen": -0.7394663095474243,
      "logits/rejected": -0.5825804471969604,
      "logps/chosen": -171.84677124023438,
      "logps/rejected": -186.84158325195312,
      "loss": 0.2411,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.9182450771331787,
      "rewards/margins": 2.624699115753174,
      "rewards/rejected": -5.542943954467773,
      "step": 14430
    },
    {
      "epoch": 2.6352769413267634,
      "grad_norm": 7.897119045257568,
      "learning_rate": 3.806643420811158e-05,
      "logits/chosen": -0.8229060173034668,
      "logits/rejected": -0.47859740257263184,
      "logps/chosen": -189.73953247070312,
      "logps/rejected": -175.8780517578125,
      "loss": 0.2856,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.906768321990967,
      "rewards/margins": 2.9586966037750244,
      "rewards/rejected": -5.86546516418457,
      "step": 14440
    },
    {
      "epoch": 2.637101925358153,
      "grad_norm": 3.9577949047088623,
      "learning_rate": 3.8037071022205913e-05,
      "logits/chosen": -0.7770196795463562,
      "logits/rejected": -0.5572531223297119,
      "logps/chosen": -171.139404296875,
      "logps/rejected": -186.12271118164062,
      "loss": 0.2696,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.6502065658569336,
      "rewards/margins": 2.8927865028381348,
      "rewards/rejected": -5.542993545532227,
      "step": 14450
    },
    {
      "epoch": 2.638926909389543,
      "grad_norm": 4.161536693572998,
      "learning_rate": 3.8007707836300245e-05,
      "logits/chosen": -0.8005057573318481,
      "logits/rejected": -0.6708806157112122,
      "logps/chosen": -178.1040496826172,
      "logps/rejected": -189.1970672607422,
      "loss": 0.3116,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.756929874420166,
      "rewards/margins": 2.6432666778564453,
      "rewards/rejected": -5.400196552276611,
      "step": 14460
    },
    {
      "epoch": 2.6407518934209326,
      "grad_norm": 3.2073631286621094,
      "learning_rate": 3.797834465039457e-05,
      "logits/chosen": -0.8987277150154114,
      "logits/rejected": -0.7201042771339417,
      "logps/chosen": -177.84201049804688,
      "logps/rejected": -186.4832305908203,
      "loss": 0.3365,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.752535343170166,
      "rewards/margins": 2.924750328063965,
      "rewards/rejected": -5.677285194396973,
      "step": 14470
    },
    {
      "epoch": 2.6425768774523224,
      "grad_norm": 3.859066963195801,
      "learning_rate": 3.79489814644889e-05,
      "logits/chosen": -0.8497544527053833,
      "logits/rejected": -0.6568385362625122,
      "logps/chosen": -169.7566680908203,
      "logps/rejected": -179.2683563232422,
      "loss": 0.2036,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.757493495941162,
      "rewards/margins": 3.214700222015381,
      "rewards/rejected": -5.972193717956543,
      "step": 14480
    },
    {
      "epoch": 2.644401861483712,
      "grad_norm": 4.319334506988525,
      "learning_rate": 3.7919618278583225e-05,
      "logits/chosen": -0.8589984774589539,
      "logits/rejected": -0.5812785029411316,
      "logps/chosen": -188.59793090820312,
      "logps/rejected": -184.4880828857422,
      "loss": 0.2669,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.815295696258545,
      "rewards/margins": 3.1627120971679688,
      "rewards/rejected": -5.978007793426514,
      "step": 14490
    },
    {
      "epoch": 2.646226845515102,
      "grad_norm": 3.6442079544067383,
      "learning_rate": 3.789025509267756e-05,
      "logits/chosen": -0.687140166759491,
      "logits/rejected": -0.49387454986572266,
      "logps/chosen": -176.7392120361328,
      "logps/rejected": -181.49392700195312,
      "loss": 0.3467,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.0060997009277344,
      "rewards/margins": 2.3444981575012207,
      "rewards/rejected": -5.350598335266113,
      "step": 14500
    },
    {
      "epoch": 2.6480518295464917,
      "grad_norm": 5.966629981994629,
      "learning_rate": 3.786089190677189e-05,
      "logits/chosen": -0.7345994114875793,
      "logits/rejected": -0.45182281732559204,
      "logps/chosen": -169.2715301513672,
      "logps/rejected": -177.1349639892578,
      "loss": 0.2502,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.6693167686462402,
      "rewards/margins": 3.079129457473755,
      "rewards/rejected": -5.748446941375732,
      "step": 14510
    },
    {
      "epoch": 2.6498768135778814,
      "grad_norm": 9.998749732971191,
      "learning_rate": 3.783152872086622e-05,
      "logits/chosen": -0.6144987940788269,
      "logits/rejected": -0.3823527693748474,
      "logps/chosen": -180.1390380859375,
      "logps/rejected": -185.00051879882812,
      "loss": 0.3337,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.133948802947998,
      "rewards/margins": 2.304899215698242,
      "rewards/rejected": -5.43884801864624,
      "step": 14520
    },
    {
      "epoch": 2.651701797609271,
      "grad_norm": 1.805725336074829,
      "learning_rate": 3.7802165534960544e-05,
      "logits/chosen": -0.6947911381721497,
      "logits/rejected": -0.5457803606987,
      "logps/chosen": -176.7123260498047,
      "logps/rejected": -184.90269470214844,
      "loss": 0.3877,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.5414316654205322,
      "rewards/margins": 2.4230706691741943,
      "rewards/rejected": -4.96450138092041,
      "step": 14530
    },
    {
      "epoch": 2.653526781640661,
      "grad_norm": 6.074096202850342,
      "learning_rate": 3.7772802349054875e-05,
      "logits/chosen": -0.7959185838699341,
      "logits/rejected": -0.6259148716926575,
      "logps/chosen": -176.12767028808594,
      "logps/rejected": -173.41128540039062,
      "loss": 0.3537,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.533189058303833,
      "rewards/margins": 2.342134952545166,
      "rewards/rejected": -4.875324726104736,
      "step": 14540
    },
    {
      "epoch": 2.6553517656720502,
      "grad_norm": 9.236230850219727,
      "learning_rate": 3.7743439163149207e-05,
      "logits/chosen": -0.7682754993438721,
      "logits/rejected": -0.6666334271430969,
      "logps/chosen": -161.8331298828125,
      "logps/rejected": -174.68643188476562,
      "loss": 0.3443,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.430712938308716,
      "rewards/margins": 2.102271318435669,
      "rewards/rejected": -4.532984256744385,
      "step": 14550
    },
    {
      "epoch": 2.65717674970344,
      "grad_norm": 7.091592311859131,
      "learning_rate": 3.771407597724353e-05,
      "logits/chosen": -0.8348175287246704,
      "logits/rejected": -0.6936386823654175,
      "logps/chosen": -164.21490478515625,
      "logps/rejected": -170.72500610351562,
      "loss": 0.2902,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.8627920150756836,
      "rewards/margins": 2.2876203060150146,
      "rewards/rejected": -5.150412559509277,
      "step": 14560
    },
    {
      "epoch": 2.6590017337348297,
      "grad_norm": 5.394489288330078,
      "learning_rate": 3.768471279133786e-05,
      "logits/chosen": -0.8070130348205566,
      "logits/rejected": -0.6864080429077148,
      "logps/chosen": -164.24195861816406,
      "logps/rejected": -173.18099975585938,
      "loss": 0.2486,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.6685292720794678,
      "rewards/margins": 2.6381137371063232,
      "rewards/rejected": -5.306643009185791,
      "step": 14570
    },
    {
      "epoch": 2.6608267177662195,
      "grad_norm": 8.990069389343262,
      "learning_rate": 3.7655349605432194e-05,
      "logits/chosen": -0.8143330812454224,
      "logits/rejected": -0.6518437266349792,
      "logps/chosen": -182.59414672851562,
      "logps/rejected": -178.3271942138672,
      "loss": 0.3638,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.659369945526123,
      "rewards/margins": 2.142690658569336,
      "rewards/rejected": -4.802060127258301,
      "step": 14580
    },
    {
      "epoch": 2.6626517017976092,
      "grad_norm": 2.5533084869384766,
      "learning_rate": 3.7625986419526525e-05,
      "logits/chosen": -0.8474525213241577,
      "logits/rejected": -0.6070930361747742,
      "logps/chosen": -176.30191040039062,
      "logps/rejected": -171.5856170654297,
      "loss": 0.3176,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.3764073848724365,
      "rewards/margins": 2.24741530418396,
      "rewards/rejected": -4.6238226890563965,
      "step": 14590
    },
    {
      "epoch": 2.664476685828999,
      "grad_norm": 10.0399751663208,
      "learning_rate": 3.759662323362085e-05,
      "logits/chosen": -0.8721545934677124,
      "logits/rejected": -0.7660040259361267,
      "logps/chosen": -155.67559814453125,
      "logps/rejected": -169.2147674560547,
      "loss": 0.2815,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.347526788711548,
      "rewards/margins": 2.445249080657959,
      "rewards/rejected": -4.792775630950928,
      "step": 14600
    },
    {
      "epoch": 2.6663016698603887,
      "grad_norm": 2.5504558086395264,
      "learning_rate": 3.756726004771518e-05,
      "logits/chosen": -0.9500864744186401,
      "logits/rejected": -0.7115411162376404,
      "logps/chosen": -176.24118041992188,
      "logps/rejected": -165.9665985107422,
      "loss": 0.2243,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.9135370254516602,
      "rewards/margins": 2.7475671768188477,
      "rewards/rejected": -4.661104679107666,
      "step": 14610
    },
    {
      "epoch": 2.6681266538917785,
      "grad_norm": 7.871036052703857,
      "learning_rate": 3.7537896861809506e-05,
      "logits/chosen": -0.7777462601661682,
      "logits/rejected": -0.6935117840766907,
      "logps/chosen": -181.53903198242188,
      "logps/rejected": -197.20730590820312,
      "loss": 0.2758,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.0675528049468994,
      "rewards/margins": 2.846869945526123,
      "rewards/rejected": -5.914422512054443,
      "step": 14620
    },
    {
      "epoch": 2.6699516379231683,
      "grad_norm": 1.1487188339233398,
      "learning_rate": 3.750853367590384e-05,
      "logits/chosen": -0.7936108112335205,
      "logits/rejected": -0.6114257574081421,
      "logps/chosen": -190.7271728515625,
      "logps/rejected": -193.4011688232422,
      "loss": 0.3371,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.4922680854797363,
      "rewards/margins": 3.045483112335205,
      "rewards/rejected": -6.537751197814941,
      "step": 14630
    },
    {
      "epoch": 2.671776621954558,
      "grad_norm": 7.004426002502441,
      "learning_rate": 3.747917048999817e-05,
      "logits/chosen": -0.7279701232910156,
      "logits/rejected": -0.5041394233703613,
      "logps/chosen": -167.28622436523438,
      "logps/rejected": -184.652587890625,
      "loss": 0.3296,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.2753467559814453,
      "rewards/margins": 2.7975566387176514,
      "rewards/rejected": -6.072903633117676,
      "step": 14640
    },
    {
      "epoch": 2.6736016059859478,
      "grad_norm": 3.273630142211914,
      "learning_rate": 3.74498073040925e-05,
      "logits/chosen": -0.9050962328910828,
      "logits/rejected": -0.69972825050354,
      "logps/chosen": -183.4556121826172,
      "logps/rejected": -186.46897888183594,
      "loss": 0.3427,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.186025619506836,
      "rewards/margins": 2.7432634830474854,
      "rewards/rejected": -5.929288864135742,
      "step": 14650
    },
    {
      "epoch": 2.6754265900173375,
      "grad_norm": 3.486316442489624,
      "learning_rate": 3.7420444118186824e-05,
      "logits/chosen": -0.8497081995010376,
      "logits/rejected": -0.7786896824836731,
      "logps/chosen": -159.5980987548828,
      "logps/rejected": -183.30752563476562,
      "loss": 0.2258,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.091128349304199,
      "rewards/margins": 3.00459623336792,
      "rewards/rejected": -6.095724582672119,
      "step": 14660
    },
    {
      "epoch": 2.677251574048727,
      "grad_norm": 6.2345733642578125,
      "learning_rate": 3.7391080932281156e-05,
      "logits/chosen": -0.8843741416931152,
      "logits/rejected": -0.6552290916442871,
      "logps/chosen": -187.9818572998047,
      "logps/rejected": -178.16915893554688,
      "loss": 0.4339,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.450437068939209,
      "rewards/margins": 2.461010456085205,
      "rewards/rejected": -5.911447048187256,
      "step": 14670
    },
    {
      "epoch": 2.6790765580801166,
      "grad_norm": 5.5574774742126465,
      "learning_rate": 3.736171774637548e-05,
      "logits/chosen": -0.8756341934204102,
      "logits/rejected": -0.6994034051895142,
      "logps/chosen": -177.1092071533203,
      "logps/rejected": -192.381591796875,
      "loss": 0.2978,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.7158045768737793,
      "rewards/margins": 2.8326213359832764,
      "rewards/rejected": -5.548426151275635,
      "step": 14680
    },
    {
      "epoch": 2.6809015421115063,
      "grad_norm": 3.0457139015197754,
      "learning_rate": 3.733235456046981e-05,
      "logits/chosen": -0.8557866215705872,
      "logits/rejected": -0.729724109172821,
      "logps/chosen": -177.22940063476562,
      "logps/rejected": -181.41973876953125,
      "loss": 0.2223,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.9703421592712402,
      "rewards/margins": 2.6871440410614014,
      "rewards/rejected": -5.657485485076904,
      "step": 14690
    },
    {
      "epoch": 2.682726526142896,
      "grad_norm": 6.276783466339111,
      "learning_rate": 3.730299137456414e-05,
      "logits/chosen": -0.8630736470222473,
      "logits/rejected": -0.7767769694328308,
      "logps/chosen": -162.23016357421875,
      "logps/rejected": -183.25057983398438,
      "loss": 0.3235,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.862687349319458,
      "rewards/margins": 2.8586602210998535,
      "rewards/rejected": -5.721347808837891,
      "step": 14700
    },
    {
      "epoch": 2.684551510174286,
      "grad_norm": 2.8667843341827393,
      "learning_rate": 3.7273628188658474e-05,
      "logits/chosen": -0.9639051556587219,
      "logits/rejected": -0.8381133079528809,
      "logps/chosen": -200.56082153320312,
      "logps/rejected": -210.65982055664062,
      "loss": 0.2806,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.0273890495300293,
      "rewards/margins": 2.826690673828125,
      "rewards/rejected": -5.854079246520996,
      "step": 14710
    },
    {
      "epoch": 2.6863764942056756,
      "grad_norm": 6.855044364929199,
      "learning_rate": 3.72442650027528e-05,
      "logits/chosen": -0.8389402627944946,
      "logits/rejected": -0.7279723882675171,
      "logps/chosen": -159.18545532226562,
      "logps/rejected": -174.7175750732422,
      "loss": 0.2501,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.233914852142334,
      "rewards/margins": 2.514446258544922,
      "rewards/rejected": -5.748361110687256,
      "step": 14720
    },
    {
      "epoch": 2.6882014782370653,
      "grad_norm": 3.497697114944458,
      "learning_rate": 3.721490181684713e-05,
      "logits/chosen": -0.828738808631897,
      "logits/rejected": -0.5820136666297913,
      "logps/chosen": -182.9156494140625,
      "logps/rejected": -182.8651123046875,
      "loss": 0.1791,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -3.001616954803467,
      "rewards/margins": 3.117495536804199,
      "rewards/rejected": -6.119112968444824,
      "step": 14730
    },
    {
      "epoch": 2.690026462268455,
      "grad_norm": 6.362539768218994,
      "learning_rate": 3.718553863094146e-05,
      "logits/chosen": -0.869890570640564,
      "logits/rejected": -0.7042620778083801,
      "logps/chosen": -174.6474151611328,
      "logps/rejected": -184.73638916015625,
      "loss": 0.3238,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.164827823638916,
      "rewards/margins": 2.7935824394226074,
      "rewards/rejected": -5.958410263061523,
      "step": 14740
    },
    {
      "epoch": 2.691851446299845,
      "grad_norm": 1.5383628606796265,
      "learning_rate": 3.7156175445035786e-05,
      "logits/chosen": -0.8478130102157593,
      "logits/rejected": -0.6565017700195312,
      "logps/chosen": -167.4313507080078,
      "logps/rejected": -174.40042114257812,
      "loss": 0.3623,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.6709189414978027,
      "rewards/margins": 2.6880550384521484,
      "rewards/rejected": -6.358973503112793,
      "step": 14750
    },
    {
      "epoch": 2.6936764303312346,
      "grad_norm": 4.64229679107666,
      "learning_rate": 3.712681225913012e-05,
      "logits/chosen": -0.7344604730606079,
      "logits/rejected": -0.5522813200950623,
      "logps/chosen": -193.81863403320312,
      "logps/rejected": -193.06185913085938,
      "loss": 0.2313,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.3555901050567627,
      "rewards/margins": 3.380896806716919,
      "rewards/rejected": -6.736486911773682,
      "step": 14760
    },
    {
      "epoch": 2.6955014143626244,
      "grad_norm": 10.706609725952148,
      "learning_rate": 3.709744907322445e-05,
      "logits/chosen": -0.7822739481925964,
      "logits/rejected": -0.6077380180358887,
      "logps/chosen": -165.366943359375,
      "logps/rejected": -175.50894165039062,
      "loss": 0.336,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.0034000873565674,
      "rewards/margins": 2.6252920627593994,
      "rewards/rejected": -5.628691673278809,
      "step": 14770
    },
    {
      "epoch": 2.697326398394014,
      "grad_norm": 7.355463981628418,
      "learning_rate": 3.706808588731878e-05,
      "logits/chosen": -0.7844526767730713,
      "logits/rejected": -0.6335620284080505,
      "logps/chosen": -163.58448791503906,
      "logps/rejected": -184.3085479736328,
      "loss": 0.2469,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.3610153198242188,
      "rewards/margins": 2.937612533569336,
      "rewards/rejected": -6.2986273765563965,
      "step": 14780
    },
    {
      "epoch": 2.699151382425404,
      "grad_norm": 6.661355972290039,
      "learning_rate": 3.7038722701413105e-05,
      "logits/chosen": -0.813318133354187,
      "logits/rejected": -0.7754908800125122,
      "logps/chosen": -166.21815490722656,
      "logps/rejected": -197.77658081054688,
      "loss": 0.3437,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.9796290397644043,
      "rewards/margins": 2.7972731590270996,
      "rewards/rejected": -5.776902198791504,
      "step": 14790
    },
    {
      "epoch": 2.7009763664567936,
      "grad_norm": 2.638230323791504,
      "learning_rate": 3.7009359515507436e-05,
      "logits/chosen": -0.9083601832389832,
      "logits/rejected": -0.7237213850021362,
      "logps/chosen": -176.64869689941406,
      "logps/rejected": -196.70904541015625,
      "loss": 0.2886,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.5673670768737793,
      "rewards/margins": 3.122265577316284,
      "rewards/rejected": -6.689633369445801,
      "step": 14800
    },
    {
      "epoch": 2.7028013504881834,
      "grad_norm": 8.883910179138184,
      "learning_rate": 3.697999632960176e-05,
      "logits/chosen": -0.7926587462425232,
      "logits/rejected": -0.7134206891059875,
      "logps/chosen": -169.30104064941406,
      "logps/rejected": -197.56109619140625,
      "loss": 0.1972,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.1124348640441895,
      "rewards/margins": 3.2804508209228516,
      "rewards/rejected": -6.392885684967041,
      "step": 14810
    },
    {
      "epoch": 2.704626334519573,
      "grad_norm": 4.145802974700928,
      "learning_rate": 3.695063314369609e-05,
      "logits/chosen": -0.9328020215034485,
      "logits/rejected": -0.7270364165306091,
      "logps/chosen": -177.5730743408203,
      "logps/rejected": -178.203857421875,
      "loss": 0.2759,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.051851272583008,
      "rewards/margins": 3.0212459564208984,
      "rewards/rejected": -6.073097229003906,
      "step": 14820
    },
    {
      "epoch": 2.706451318550963,
      "grad_norm": 6.964405536651611,
      "learning_rate": 3.6921269957790423e-05,
      "logits/chosen": -0.800618052482605,
      "logits/rejected": -0.6605321168899536,
      "logps/chosen": -187.9517364501953,
      "logps/rejected": -202.18270874023438,
      "loss": 0.2658,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.500032901763916,
      "rewards/margins": 2.771120309829712,
      "rewards/rejected": -6.271153450012207,
      "step": 14830
    },
    {
      "epoch": 2.7082763025823526,
      "grad_norm": 7.932828426361084,
      "learning_rate": 3.6891906771884755e-05,
      "logits/chosen": -0.8167387247085571,
      "logits/rejected": -0.7023965716362,
      "logps/chosen": -167.94451904296875,
      "logps/rejected": -185.8038330078125,
      "loss": 0.3456,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.3805365562438965,
      "rewards/margins": 2.609523296356201,
      "rewards/rejected": -5.990059852600098,
      "step": 14840
    },
    {
      "epoch": 2.7101012866137424,
      "grad_norm": 7.145177841186523,
      "learning_rate": 3.686254358597908e-05,
      "logits/chosen": -0.7980549335479736,
      "logits/rejected": -0.6623034477233887,
      "logps/chosen": -179.61477661132812,
      "logps/rejected": -193.71234130859375,
      "loss": 0.2719,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.3001632690429688,
      "rewards/margins": 2.96509051322937,
      "rewards/rejected": -6.265254020690918,
      "step": 14850
    },
    {
      "epoch": 2.7119262706451317,
      "grad_norm": 8.041650772094727,
      "learning_rate": 3.683318040007341e-05,
      "logits/chosen": -0.7914022207260132,
      "logits/rejected": -0.7133642435073853,
      "logps/chosen": -184.50860595703125,
      "logps/rejected": -213.4342498779297,
      "loss": 0.2276,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.563917875289917,
      "rewards/margins": 3.137497663497925,
      "rewards/rejected": -6.701416015625,
      "step": 14860
    },
    {
      "epoch": 2.7137512546765215,
      "grad_norm": 3.5368430614471436,
      "learning_rate": 3.6803817214167735e-05,
      "logits/chosen": -0.8950109481811523,
      "logits/rejected": -0.7317004203796387,
      "logps/chosen": -199.80357360839844,
      "logps/rejected": -210.154052734375,
      "loss": 0.2366,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.5866713523864746,
      "rewards/margins": 3.0917656421661377,
      "rewards/rejected": -6.678436279296875,
      "step": 14870
    },
    {
      "epoch": 2.715576238707911,
      "grad_norm": 7.204657554626465,
      "learning_rate": 3.6774454028262067e-05,
      "logits/chosen": -0.851962685585022,
      "logits/rejected": -0.6795967817306519,
      "logps/chosen": -182.05361938476562,
      "logps/rejected": -193.34864807128906,
      "loss": 0.2454,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.426999568939209,
      "rewards/margins": 2.897970676422119,
      "rewards/rejected": -6.324970245361328,
      "step": 14880
    },
    {
      "epoch": 2.717401222739301,
      "grad_norm": 5.383434295654297,
      "learning_rate": 3.67450908423564e-05,
      "logits/chosen": -0.7951643466949463,
      "logits/rejected": -0.5295844674110413,
      "logps/chosen": -197.67991638183594,
      "logps/rejected": -169.908447265625,
      "loss": 0.4916,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.668203353881836,
      "rewards/margins": 1.9359111785888672,
      "rewards/rejected": -5.604114532470703,
      "step": 14890
    },
    {
      "epoch": 2.7192262067706907,
      "grad_norm": 11.497944831848145,
      "learning_rate": 3.671572765645073e-05,
      "logits/chosen": -0.895632266998291,
      "logits/rejected": -0.6559931039810181,
      "logps/chosen": -189.02139282226562,
      "logps/rejected": -183.20553588867188,
      "loss": 0.2824,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.923347234725952,
      "rewards/margins": 2.7832741737365723,
      "rewards/rejected": -5.7066216468811035,
      "step": 14900
    },
    {
      "epoch": 2.7210511908020805,
      "grad_norm": 4.685726165771484,
      "learning_rate": 3.6686364470545054e-05,
      "logits/chosen": -0.9807319641113281,
      "logits/rejected": -0.7737419009208679,
      "logps/chosen": -184.97686767578125,
      "logps/rejected": -198.14503479003906,
      "loss": 0.2088,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.6707348823547363,
      "rewards/margins": 3.4883522987365723,
      "rewards/rejected": -6.159087181091309,
      "step": 14910
    },
    {
      "epoch": 2.72287617483347,
      "grad_norm": 9.923583030700684,
      "learning_rate": 3.6657001284639385e-05,
      "logits/chosen": -0.9971728324890137,
      "logits/rejected": -0.7816584706306458,
      "logps/chosen": -173.84739685058594,
      "logps/rejected": -176.9408721923828,
      "loss": 0.406,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.646707057952881,
      "rewards/margins": 2.305208921432495,
      "rewards/rejected": -4.951915740966797,
      "step": 14920
    },
    {
      "epoch": 2.72470115886486,
      "grad_norm": 4.660953044891357,
      "learning_rate": 3.6627638098733717e-05,
      "logits/chosen": -0.835162341594696,
      "logits/rejected": -0.7954039573669434,
      "logps/chosen": -153.53427124023438,
      "logps/rejected": -177.67201232910156,
      "loss": 0.2786,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.8209941387176514,
      "rewards/margins": 2.7452478408813477,
      "rewards/rejected": -5.566242218017578,
      "step": 14930
    },
    {
      "epoch": 2.7265261428962497,
      "grad_norm": 7.557379245758057,
      "learning_rate": 3.659827491282805e-05,
      "logits/chosen": -0.832405686378479,
      "logits/rejected": -0.6960372924804688,
      "logps/chosen": -166.2767333984375,
      "logps/rejected": -194.1705780029297,
      "loss": 0.2508,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.158113718032837,
      "rewards/margins": 3.0241763591766357,
      "rewards/rejected": -6.182290077209473,
      "step": 14940
    },
    {
      "epoch": 2.7283511269276395,
      "grad_norm": 3.364102363586426,
      "learning_rate": 3.656891172692238e-05,
      "logits/chosen": -0.907085120677948,
      "logits/rejected": -0.5479372143745422,
      "logps/chosen": -191.82493591308594,
      "logps/rejected": -177.33346557617188,
      "loss": 0.2242,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.096557378768921,
      "rewards/margins": 3.0370547771453857,
      "rewards/rejected": -6.133612155914307,
      "step": 14950
    },
    {
      "epoch": 2.7301761109590292,
      "grad_norm": 3.5702245235443115,
      "learning_rate": 3.6539548541016704e-05,
      "logits/chosen": -0.7857440710067749,
      "logits/rejected": -0.6329749226570129,
      "logps/chosen": -176.3921661376953,
      "logps/rejected": -183.76345825195312,
      "loss": 0.272,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.573925495147705,
      "rewards/margins": 2.697530746459961,
      "rewards/rejected": -6.271455764770508,
      "step": 14960
    },
    {
      "epoch": 2.732001094990419,
      "grad_norm": 2.1585519313812256,
      "learning_rate": 3.6510185355111035e-05,
      "logits/chosen": -0.7011271119117737,
      "logits/rejected": -0.4950138032436371,
      "logps/chosen": -177.52064514160156,
      "logps/rejected": -193.9433135986328,
      "loss": 0.2534,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.5097217559814453,
      "rewards/margins": 3.1344876289367676,
      "rewards/rejected": -6.644209384918213,
      "step": 14970
    },
    {
      "epoch": 2.7338260790218083,
      "grad_norm": 2.107095241546631,
      "learning_rate": 3.648082216920536e-05,
      "logits/chosen": -0.650390625,
      "logits/rejected": -0.4703623354434967,
      "logps/chosen": -195.18336486816406,
      "logps/rejected": -199.33493041992188,
      "loss": 0.2411,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.4381816387176514,
      "rewards/margins": 2.8992934226989746,
      "rewards/rejected": -6.337474822998047,
      "step": 14980
    },
    {
      "epoch": 2.735651063053198,
      "grad_norm": 6.853755474090576,
      "learning_rate": 3.645145898329969e-05,
      "logits/chosen": -0.4371338486671448,
      "logits/rejected": -0.3976084887981415,
      "logps/chosen": -181.70578002929688,
      "logps/rejected": -210.43112182617188,
      "loss": 0.3761,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -5.256541728973389,
      "rewards/margins": 2.348385810852051,
      "rewards/rejected": -7.604928016662598,
      "step": 14990
    },
    {
      "epoch": 2.737476047084588,
      "grad_norm": 6.547688961029053,
      "learning_rate": 3.642209579739402e-05,
      "logits/chosen": -0.7699087858200073,
      "logits/rejected": -0.522635281085968,
      "logps/chosen": -203.7289276123047,
      "logps/rejected": -208.31802368164062,
      "loss": 0.3018,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.9173660278320312,
      "rewards/margins": 2.5227465629577637,
      "rewards/rejected": -6.440112113952637,
      "step": 15000
    },
    {
      "epoch": 2.7393010311159776,
      "grad_norm": 10.352616310119629,
      "learning_rate": 3.6392732611488354e-05,
      "logits/chosen": -0.6836923360824585,
      "logits/rejected": -0.32527703046798706,
      "logps/chosen": -195.6300048828125,
      "logps/rejected": -184.436279296875,
      "loss": 0.357,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.9563846588134766,
      "rewards/margins": 2.649160861968994,
      "rewards/rejected": -6.6055450439453125,
      "step": 15010
    },
    {
      "epoch": 2.7411260151473673,
      "grad_norm": 5.939677715301514,
      "learning_rate": 3.636336942558268e-05,
      "logits/chosen": -0.684780478477478,
      "logits/rejected": -0.547264575958252,
      "logps/chosen": -172.66513061523438,
      "logps/rejected": -200.9604949951172,
      "loss": 0.2532,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.986175060272217,
      "rewards/margins": 2.8526647090911865,
      "rewards/rejected": -6.838840484619141,
      "step": 15020
    },
    {
      "epoch": 2.742950999178757,
      "grad_norm": 11.2234468460083,
      "learning_rate": 3.633400623967701e-05,
      "logits/chosen": -0.616101861000061,
      "logits/rejected": -0.35308563709259033,
      "logps/chosen": -186.25607299804688,
      "logps/rejected": -199.62738037109375,
      "loss": 0.2253,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.249608039855957,
      "rewards/margins": 3.104623317718506,
      "rewards/rejected": -7.354231834411621,
      "step": 15030
    },
    {
      "epoch": 2.744775983210147,
      "grad_norm": 18.16982078552246,
      "learning_rate": 3.6304643053771334e-05,
      "logits/chosen": -0.7914429903030396,
      "logits/rejected": -0.5191563963890076,
      "logps/chosen": -194.5189208984375,
      "logps/rejected": -183.87899780273438,
      "loss": 0.2573,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.8782074451446533,
      "rewards/margins": 3.211261749267578,
      "rewards/rejected": -7.089468955993652,
      "step": 15040
    },
    {
      "epoch": 2.7466009672415366,
      "grad_norm": 7.035409927368164,
      "learning_rate": 3.6275279867865666e-05,
      "logits/chosen": -0.695347249507904,
      "logits/rejected": -0.4789447784423828,
      "logps/chosen": -187.48887634277344,
      "logps/rejected": -189.9559326171875,
      "loss": 0.2533,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.541347026824951,
      "rewards/margins": 3.0324435234069824,
      "rewards/rejected": -6.573790550231934,
      "step": 15050
    },
    {
      "epoch": 2.7484259512729263,
      "grad_norm": 6.368076801300049,
      "learning_rate": 3.624591668196e-05,
      "logits/chosen": -0.6995037794113159,
      "logits/rejected": -0.5031846165657043,
      "logps/chosen": -179.4481964111328,
      "logps/rejected": -186.23434448242188,
      "loss": 0.2288,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.7638487815856934,
      "rewards/margins": 3.205934524536133,
      "rewards/rejected": -6.969783782958984,
      "step": 15060
    },
    {
      "epoch": 2.750250935304316,
      "grad_norm": 16.24543571472168,
      "learning_rate": 3.621655349605433e-05,
      "logits/chosen": -0.6614688038825989,
      "logits/rejected": -0.5052237510681152,
      "logps/chosen": -173.2662353515625,
      "logps/rejected": -203.33087158203125,
      "loss": 0.2687,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.925924777984619,
      "rewards/margins": 3.484577178955078,
      "rewards/rejected": -7.410501003265381,
      "step": 15070
    },
    {
      "epoch": 2.752075919335706,
      "grad_norm": 6.631443023681641,
      "learning_rate": 3.618719031014865e-05,
      "logits/chosen": -0.7494603395462036,
      "logits/rejected": -0.5153684616088867,
      "logps/chosen": -186.3660125732422,
      "logps/rejected": -182.3700714111328,
      "loss": 0.2396,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.6865291595458984,
      "rewards/margins": 3.094432830810547,
      "rewards/rejected": -6.7809624671936035,
      "step": 15080
    },
    {
      "epoch": 2.7539009033670956,
      "grad_norm": 4.917546272277832,
      "learning_rate": 3.6157827124242984e-05,
      "logits/chosen": -0.7152889966964722,
      "logits/rejected": -0.5230101346969604,
      "logps/chosen": -185.44480895996094,
      "logps/rejected": -201.9127197265625,
      "loss": 0.3253,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.8513877391815186,
      "rewards/margins": 2.904815673828125,
      "rewards/rejected": -6.756204128265381,
      "step": 15090
    },
    {
      "epoch": 2.7557258873984853,
      "grad_norm": 8.429165840148926,
      "learning_rate": 3.612846393833731e-05,
      "logits/chosen": -0.634231686592102,
      "logits/rejected": -0.5342589020729065,
      "logps/chosen": -166.46011352539062,
      "logps/rejected": -201.27635192871094,
      "loss": 0.3396,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -4.175014495849609,
      "rewards/margins": 2.8083674907684326,
      "rewards/rejected": -6.983382225036621,
      "step": 15100
    },
    {
      "epoch": 2.757550871429875,
      "grad_norm": 5.880619525909424,
      "learning_rate": 3.609910075243164e-05,
      "logits/chosen": -0.6460603475570679,
      "logits/rejected": -0.44998469948768616,
      "logps/chosen": -188.65811157226562,
      "logps/rejected": -200.77371215820312,
      "loss": 0.3351,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -4.352369785308838,
      "rewards/margins": 2.8829269409179688,
      "rewards/rejected": -7.23529577255249,
      "step": 15110
    },
    {
      "epoch": 2.759375855461265,
      "grad_norm": 8.317323684692383,
      "learning_rate": 3.606973756652597e-05,
      "logits/chosen": -0.6685341596603394,
      "logits/rejected": -0.555890679359436,
      "logps/chosen": -171.28103637695312,
      "logps/rejected": -203.18377685546875,
      "loss": 0.2818,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.103752613067627,
      "rewards/margins": 3.2650558948516846,
      "rewards/rejected": -7.368809700012207,
      "step": 15120
    },
    {
      "epoch": 2.7612008394926546,
      "grad_norm": 4.2107038497924805,
      "learning_rate": 3.60403743806203e-05,
      "logits/chosen": -0.7578221559524536,
      "logits/rejected": -0.5752698183059692,
      "logps/chosen": -196.00509643554688,
      "logps/rejected": -206.1482391357422,
      "loss": 0.2203,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.9018454551696777,
      "rewards/margins": 3.1353797912597656,
      "rewards/rejected": -7.037225246429443,
      "step": 15130
    },
    {
      "epoch": 2.7630258235240444,
      "grad_norm": 3.8480048179626465,
      "learning_rate": 3.6011011194714634e-05,
      "logits/chosen": -0.7589915990829468,
      "logits/rejected": -0.4595470428466797,
      "logps/chosen": -203.83926391601562,
      "logps/rejected": -194.755126953125,
      "loss": 0.2649,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.999525785446167,
      "rewards/margins": 3.1421878337860107,
      "rewards/rejected": -7.1417131423950195,
      "step": 15140
    },
    {
      "epoch": 2.764850807555434,
      "grad_norm": 7.260847568511963,
      "learning_rate": 3.598164800880896e-05,
      "logits/chosen": -0.8609592318534851,
      "logits/rejected": -0.6237218379974365,
      "logps/chosen": -180.50682067871094,
      "logps/rejected": -185.73590087890625,
      "loss": 0.3419,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.00797700881958,
      "rewards/margins": 2.8179240226745605,
      "rewards/rejected": -5.825901031494141,
      "step": 15150
    },
    {
      "epoch": 2.766675791586824,
      "grad_norm": 2.514737129211426,
      "learning_rate": 3.595228482290329e-05,
      "logits/chosen": -0.7770320773124695,
      "logits/rejected": -0.6155731678009033,
      "logps/chosen": -185.7744903564453,
      "logps/rejected": -200.8455352783203,
      "loss": 0.369,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.5350069999694824,
      "rewards/margins": 2.9002184867858887,
      "rewards/rejected": -6.435225486755371,
      "step": 15160
    },
    {
      "epoch": 2.7685007756182136,
      "grad_norm": 10.140793800354004,
      "learning_rate": 3.5922921636997615e-05,
      "logits/chosen": -0.7371872663497925,
      "logits/rejected": -0.6123770475387573,
      "logps/chosen": -200.95774841308594,
      "logps/rejected": -206.7280731201172,
      "loss": 0.2893,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.8846421241760254,
      "rewards/margins": 3.0321106910705566,
      "rewards/rejected": -6.916752815246582,
      "step": 15170
    },
    {
      "epoch": 2.770325759649603,
      "grad_norm": 9.200636863708496,
      "learning_rate": 3.5893558451091946e-05,
      "logits/chosen": -0.8718069791793823,
      "logits/rejected": -0.6492288708686829,
      "logps/chosen": -186.3932342529297,
      "logps/rejected": -191.4571075439453,
      "loss": 0.2515,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.1694397926330566,
      "rewards/margins": 2.7240471839904785,
      "rewards/rejected": -5.893486976623535,
      "step": 15180
    },
    {
      "epoch": 2.7721507436809927,
      "grad_norm": 6.081760406494141,
      "learning_rate": 3.586419526518628e-05,
      "logits/chosen": -0.8851171731948853,
      "logits/rejected": -0.6698845028877258,
      "logps/chosen": -177.37728881835938,
      "logps/rejected": -187.46578979492188,
      "loss": 0.2599,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.3587069511413574,
      "rewards/margins": 2.7096261978149414,
      "rewards/rejected": -6.068333625793457,
      "step": 15190
    },
    {
      "epoch": 2.7739757277123824,
      "grad_norm": 9.13878059387207,
      "learning_rate": 3.583483207928061e-05,
      "logits/chosen": -0.8507512807846069,
      "logits/rejected": -0.5811196565628052,
      "logps/chosen": -191.94473266601562,
      "logps/rejected": -191.64492797851562,
      "loss": 0.318,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.283834457397461,
      "rewards/margins": 2.9831690788269043,
      "rewards/rejected": -6.267004013061523,
      "step": 15200
    },
    {
      "epoch": 2.775800711743772,
      "grad_norm": 8.132448196411133,
      "learning_rate": 3.5805468893374933e-05,
      "logits/chosen": -0.907016932964325,
      "logits/rejected": -0.6678110361099243,
      "logps/chosen": -191.2755126953125,
      "logps/rejected": -193.82907104492188,
      "loss": 0.3904,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.5341296195983887,
      "rewards/margins": 3.0536134243011475,
      "rewards/rejected": -6.587742805480957,
      "step": 15210
    },
    {
      "epoch": 2.777625695775162,
      "grad_norm": 3.7158241271972656,
      "learning_rate": 3.5776105707469265e-05,
      "logits/chosen": -0.787829577922821,
      "logits/rejected": -0.6556006669998169,
      "logps/chosen": -157.52481079101562,
      "logps/rejected": -184.47421264648438,
      "loss": 0.3089,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.1590256690979004,
      "rewards/margins": 2.7666475772857666,
      "rewards/rejected": -5.925673484802246,
      "step": 15220
    },
    {
      "epoch": 2.7794506798065517,
      "grad_norm": 2.6560075283050537,
      "learning_rate": 3.574674252156359e-05,
      "logits/chosen": -0.8810185194015503,
      "logits/rejected": -0.7164894342422485,
      "logps/chosen": -178.0935821533203,
      "logps/rejected": -189.611328125,
      "loss": 0.2479,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.6587963104248047,
      "rewards/margins": 2.716096878051758,
      "rewards/rejected": -6.374893665313721,
      "step": 15230
    },
    {
      "epoch": 2.7812756638379414,
      "grad_norm": 5.930729389190674,
      "learning_rate": 3.571737933565792e-05,
      "logits/chosen": -0.8157905340194702,
      "logits/rejected": -0.6627378463745117,
      "logps/chosen": -160.90333557128906,
      "logps/rejected": -180.5686492919922,
      "loss": 0.3105,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.4820480346679688,
      "rewards/margins": 2.834589719772339,
      "rewards/rejected": -6.3166375160217285,
      "step": 15240
    },
    {
      "epoch": 2.783100647869331,
      "grad_norm": 5.897087574005127,
      "learning_rate": 3.568801614975225e-05,
      "logits/chosen": -0.8997437357902527,
      "logits/rejected": -0.7523947358131409,
      "logps/chosen": -184.66539001464844,
      "logps/rejected": -207.05960083007812,
      "loss": 0.2564,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.2929255962371826,
      "rewards/margins": 2.922734498977661,
      "rewards/rejected": -6.215660572052002,
      "step": 15250
    },
    {
      "epoch": 2.784925631900721,
      "grad_norm": 6.269813060760498,
      "learning_rate": 3.565865296384658e-05,
      "logits/chosen": -0.898750901222229,
      "logits/rejected": -0.7180601954460144,
      "logps/chosen": -201.5499267578125,
      "logps/rejected": -194.04446411132812,
      "loss": 0.4592,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.60497784614563,
      "rewards/margins": 1.9909454584121704,
      "rewards/rejected": -5.59592342376709,
      "step": 15260
    },
    {
      "epoch": 2.7867506159321107,
      "grad_norm": 5.528018951416016,
      "learning_rate": 3.562928977794091e-05,
      "logits/chosen": -0.965248703956604,
      "logits/rejected": -0.7998018264770508,
      "logps/chosen": -184.45474243164062,
      "logps/rejected": -185.37986755371094,
      "loss": 0.4525,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.449387311935425,
      "rewards/margins": 1.9916770458221436,
      "rewards/rejected": -5.441065311431885,
      "step": 15270
    },
    {
      "epoch": 2.7885755999635005,
      "grad_norm": 5.777127742767334,
      "learning_rate": 3.559992659203524e-05,
      "logits/chosen": -0.8689562678337097,
      "logits/rejected": -0.7369626760482788,
      "logps/chosen": -175.14474487304688,
      "logps/rejected": -184.90350341796875,
      "loss": 0.3445,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.547409772872925,
      "rewards/margins": 2.2365221977233887,
      "rewards/rejected": -5.783931732177734,
      "step": 15280
    },
    {
      "epoch": 2.7904005839948898,
      "grad_norm": 5.834402084350586,
      "learning_rate": 3.557056340612957e-05,
      "logits/chosen": -0.7529076337814331,
      "logits/rejected": -0.5915876626968384,
      "logps/chosen": -179.8830108642578,
      "logps/rejected": -195.5404815673828,
      "loss": 0.2272,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.577052593231201,
      "rewards/margins": 3.071613311767578,
      "rewards/rejected": -6.648665428161621,
      "step": 15290
    },
    {
      "epoch": 2.7922255680262795,
      "grad_norm": 4.010066509246826,
      "learning_rate": 3.5541200220223895e-05,
      "logits/chosen": -0.8187209963798523,
      "logits/rejected": -0.6264398097991943,
      "logps/chosen": -192.2524871826172,
      "logps/rejected": -198.16250610351562,
      "loss": 0.2626,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.9323818683624268,
      "rewards/margins": 2.7408103942871094,
      "rewards/rejected": -6.673192024230957,
      "step": 15300
    },
    {
      "epoch": 2.7940505520576693,
      "grad_norm": 11.499743461608887,
      "learning_rate": 3.5511837034318227e-05,
      "logits/chosen": -0.6908611059188843,
      "logits/rejected": -0.4501069188117981,
      "logps/chosen": -191.0598907470703,
      "logps/rejected": -173.64462280273438,
      "loss": 0.3497,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.9286277294158936,
      "rewards/margins": 2.3944976329803467,
      "rewards/rejected": -6.323125839233398,
      "step": 15310
    },
    {
      "epoch": 2.795875536089059,
      "grad_norm": 0.9858825206756592,
      "learning_rate": 3.548247384841256e-05,
      "logits/chosen": -0.8024246096611023,
      "logits/rejected": -0.5834397077560425,
      "logps/chosen": -203.2317657470703,
      "logps/rejected": -192.97872924804688,
      "loss": 0.2558,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.6002037525177,
      "rewards/margins": 2.8195765018463135,
      "rewards/rejected": -6.4197797775268555,
      "step": 15320
    },
    {
      "epoch": 2.797700520120449,
      "grad_norm": 4.914129257202148,
      "learning_rate": 3.545311066250689e-05,
      "logits/chosen": -0.7837081551551819,
      "logits/rejected": -0.556017279624939,
      "logps/chosen": -183.43040466308594,
      "logps/rejected": -194.5972137451172,
      "loss": 0.2746,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.871105194091797,
      "rewards/margins": 2.8014609813690186,
      "rewards/rejected": -6.6725664138793945,
      "step": 15330
    },
    {
      "epoch": 2.7995255041518385,
      "grad_norm": 9.56387710571289,
      "learning_rate": 3.5423747476601214e-05,
      "logits/chosen": -0.7879904508590698,
      "logits/rejected": -0.6332736611366272,
      "logps/chosen": -200.5818328857422,
      "logps/rejected": -218.0546112060547,
      "loss": 0.2847,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.8096816539764404,
      "rewards/margins": 2.8861634731292725,
      "rewards/rejected": -6.695845603942871,
      "step": 15340
    },
    {
      "epoch": 2.8013504881832283,
      "grad_norm": 8.687337875366211,
      "learning_rate": 3.5394384290695545e-05,
      "logits/chosen": -0.56389981508255,
      "logits/rejected": -0.5027559995651245,
      "logps/chosen": -178.84933471679688,
      "logps/rejected": -212.90182495117188,
      "loss": 0.3573,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -4.822844982147217,
      "rewards/margins": 2.407115936279297,
      "rewards/rejected": -7.2299604415893555,
      "step": 15350
    },
    {
      "epoch": 2.803175472214618,
      "grad_norm": 5.129732608795166,
      "learning_rate": 3.536502110478987e-05,
      "logits/chosen": -0.7561319470405579,
      "logits/rejected": -0.5067469477653503,
      "logps/chosen": -183.9415283203125,
      "logps/rejected": -190.7412109375,
      "loss": 0.1885,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.001197338104248,
      "rewards/margins": 3.097608804702759,
      "rewards/rejected": -7.098805904388428,
      "step": 15360
    },
    {
      "epoch": 2.805000456246008,
      "grad_norm": 7.13339900970459,
      "learning_rate": 3.53356579188842e-05,
      "logits/chosen": -0.690324068069458,
      "logits/rejected": -0.5436011552810669,
      "logps/chosen": -185.8627166748047,
      "logps/rejected": -186.03395080566406,
      "loss": 0.3616,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.8849258422851562,
      "rewards/margins": 2.3105833530426025,
      "rewards/rejected": -6.195509433746338,
      "step": 15370
    },
    {
      "epoch": 2.8068254402773976,
      "grad_norm": 2.536324977874756,
      "learning_rate": 3.530629473297853e-05,
      "logits/chosen": -0.7556186318397522,
      "logits/rejected": -0.46718230843544006,
      "logps/chosen": -178.8177032470703,
      "logps/rejected": -180.12673950195312,
      "loss": 0.3129,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.954967498779297,
      "rewards/margins": 2.7067067623138428,
      "rewards/rejected": -6.661673545837402,
      "step": 15380
    },
    {
      "epoch": 2.8086504243087873,
      "grad_norm": 4.826351642608643,
      "learning_rate": 3.5276931547072864e-05,
      "logits/chosen": -0.747070848941803,
      "logits/rejected": -0.611015260219574,
      "logps/chosen": -181.77670288085938,
      "logps/rejected": -189.59518432617188,
      "loss": 0.3138,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.8092212677001953,
      "rewards/margins": 2.4854393005371094,
      "rewards/rejected": -6.2946600914001465,
      "step": 15390
    },
    {
      "epoch": 2.810475408340177,
      "grad_norm": 9.168551445007324,
      "learning_rate": 3.524756836116719e-05,
      "logits/chosen": -0.6706014275550842,
      "logits/rejected": -0.4334658682346344,
      "logps/chosen": -172.60128784179688,
      "logps/rejected": -201.9534912109375,
      "loss": 0.1948,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.7706291675567627,
      "rewards/margins": 3.203723907470703,
      "rewards/rejected": -6.974352836608887,
      "step": 15400
    },
    {
      "epoch": 2.812300392371567,
      "grad_norm": 10.49738597869873,
      "learning_rate": 3.521820517526152e-05,
      "logits/chosen": -0.6369202733039856,
      "logits/rejected": -0.47050318121910095,
      "logps/chosen": -175.31338500976562,
      "logps/rejected": -198.37088012695312,
      "loss": 0.2523,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.9712135791778564,
      "rewards/margins": 2.9714407920837402,
      "rewards/rejected": -6.942655086517334,
      "step": 15410
    },
    {
      "epoch": 2.8141253764029566,
      "grad_norm": 5.8107991218566895,
      "learning_rate": 3.5188841989355844e-05,
      "logits/chosen": -0.7656741738319397,
      "logits/rejected": -0.5696135759353638,
      "logps/chosen": -174.37716674804688,
      "logps/rejected": -180.39529418945312,
      "loss": 0.2497,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.2883427143096924,
      "rewards/margins": 2.83319091796875,
      "rewards/rejected": -6.121533393859863,
      "step": 15420
    },
    {
      "epoch": 2.8159503604343463,
      "grad_norm": 8.155450820922852,
      "learning_rate": 3.5159478803450176e-05,
      "logits/chosen": -0.6210613250732422,
      "logits/rejected": -0.37898576259613037,
      "logps/chosen": -183.05831909179688,
      "logps/rejected": -195.39016723632812,
      "loss": 0.3132,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.8890953063964844,
      "rewards/margins": 2.781191825866699,
      "rewards/rejected": -6.670287132263184,
      "step": 15430
    },
    {
      "epoch": 2.817775344465736,
      "grad_norm": 5.240665435791016,
      "learning_rate": 3.513011561754451e-05,
      "logits/chosen": -0.7150031924247742,
      "logits/rejected": -0.5270401239395142,
      "logps/chosen": -178.21353149414062,
      "logps/rejected": -198.19534301757812,
      "loss": 0.4059,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -4.073864459991455,
      "rewards/margins": 2.496652126312256,
      "rewards/rejected": -6.570517063140869,
      "step": 15440
    },
    {
      "epoch": 2.819600328497126,
      "grad_norm": 1.601364254951477,
      "learning_rate": 3.510075243163884e-05,
      "logits/chosen": -0.7008719444274902,
      "logits/rejected": -0.41290774941444397,
      "logps/chosen": -201.37088012695312,
      "logps/rejected": -195.19850158691406,
      "loss": 0.2045,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.4852001667022705,
      "rewards/margins": 3.102787494659424,
      "rewards/rejected": -6.587987422943115,
      "step": 15450
    },
    {
      "epoch": 2.8214253125285156,
      "grad_norm": 12.847062110900879,
      "learning_rate": 3.507138924573316e-05,
      "logits/chosen": -0.6499906778335571,
      "logits/rejected": -0.4536689817905426,
      "logps/chosen": -201.61260986328125,
      "logps/rejected": -195.7825927734375,
      "loss": 0.3189,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -4.309309482574463,
      "rewards/margins": 2.3241209983825684,
      "rewards/rejected": -6.633429527282715,
      "step": 15460
    },
    {
      "epoch": 2.8232502965599053,
      "grad_norm": 8.880233764648438,
      "learning_rate": 3.5042026059827494e-05,
      "logits/chosen": -0.7633196115493774,
      "logits/rejected": -0.4160321354866028,
      "logps/chosen": -196.5976104736328,
      "logps/rejected": -196.72976684570312,
      "loss": 0.2636,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.7533066272735596,
      "rewards/margins": 2.991732120513916,
      "rewards/rejected": -6.745039463043213,
      "step": 15470
    },
    {
      "epoch": 2.825075280591295,
      "grad_norm": 12.13598918914795,
      "learning_rate": 3.5012662873921826e-05,
      "logits/chosen": -0.7405375838279724,
      "logits/rejected": -0.5544840097427368,
      "logps/chosen": -174.9082794189453,
      "logps/rejected": -192.49562072753906,
      "loss": 0.2816,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.787837505340576,
      "rewards/margins": 2.728532075881958,
      "rewards/rejected": -6.516369819641113,
      "step": 15480
    },
    {
      "epoch": 2.8269002646226844,
      "grad_norm": 6.622777938842773,
      "learning_rate": 3.498329968801615e-05,
      "logits/chosen": -0.8395339846611023,
      "logits/rejected": -0.5704618692398071,
      "logps/chosen": -187.07843017578125,
      "logps/rejected": -208.178466796875,
      "loss": 0.2205,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.6004714965820312,
      "rewards/margins": 3.0445520877838135,
      "rewards/rejected": -6.645024299621582,
      "step": 15490
    },
    {
      "epoch": 2.828725248654074,
      "grad_norm": 1.940863013267517,
      "learning_rate": 3.495393650211048e-05,
      "logits/chosen": -0.7100485563278198,
      "logits/rejected": -0.47311925888061523,
      "logps/chosen": -183.22596740722656,
      "logps/rejected": -195.18472290039062,
      "loss": 0.2046,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.475905418395996,
      "rewards/margins": 3.2829222679138184,
      "rewards/rejected": -7.758828163146973,
      "step": 15500
    },
    {
      "epoch": 2.830550232685464,
      "grad_norm": 7.11558198928833,
      "learning_rate": 3.492457331620481e-05,
      "logits/chosen": -0.6763132214546204,
      "logits/rejected": -0.4349209666252136,
      "logps/chosen": -184.43014526367188,
      "logps/rejected": -190.2235107421875,
      "loss": 0.272,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.8415093421936035,
      "rewards/margins": 2.9998779296875,
      "rewards/rejected": -6.841386318206787,
      "step": 15510
    },
    {
      "epoch": 2.8323752167168537,
      "grad_norm": 7.064217567443848,
      "learning_rate": 3.4895210130299144e-05,
      "logits/chosen": -0.6838161945343018,
      "logits/rejected": -0.502055287361145,
      "logps/chosen": -175.50291442871094,
      "logps/rejected": -173.2074432373047,
      "loss": 0.3807,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.494417667388916,
      "rewards/margins": 2.1785683631896973,
      "rewards/rejected": -5.672986030578613,
      "step": 15520
    },
    {
      "epoch": 2.8342002007482434,
      "grad_norm": 8.329331398010254,
      "learning_rate": 3.486584694439347e-05,
      "logits/chosen": -0.6366431713104248,
      "logits/rejected": -0.5269623398780823,
      "logps/chosen": -162.9123992919922,
      "logps/rejected": -186.2232208251953,
      "loss": 0.3366,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -4.075781345367432,
      "rewards/margins": 2.6224915981292725,
      "rewards/rejected": -6.698271751403809,
      "step": 15530
    },
    {
      "epoch": 2.836025184779633,
      "grad_norm": 5.017236232757568,
      "learning_rate": 3.48364837584878e-05,
      "logits/chosen": -0.8243195414543152,
      "logits/rejected": -0.5898681879043579,
      "logps/chosen": -183.9113006591797,
      "logps/rejected": -183.50999450683594,
      "loss": 0.2824,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.7901902198791504,
      "rewards/margins": 2.4580514430999756,
      "rewards/rejected": -6.248241901397705,
      "step": 15540
    },
    {
      "epoch": 2.837850168811023,
      "grad_norm": 2.5107953548431396,
      "learning_rate": 3.4807120572582125e-05,
      "logits/chosen": -0.7645323872566223,
      "logits/rejected": -0.47195976972579956,
      "logps/chosen": -168.00906372070312,
      "logps/rejected": -178.54818725585938,
      "loss": 0.2233,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.2222084999084473,
      "rewards/margins": 3.3796133995056152,
      "rewards/rejected": -6.6018218994140625,
      "step": 15550
    },
    {
      "epoch": 2.8396751528424127,
      "grad_norm": 3.9332334995269775,
      "learning_rate": 3.4777757386676456e-05,
      "logits/chosen": -0.8603020906448364,
      "logits/rejected": -0.46285462379455566,
      "logps/chosen": -202.6700897216797,
      "logps/rejected": -187.53067016601562,
      "loss": 0.3107,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.153242349624634,
      "rewards/margins": 3.0527358055114746,
      "rewards/rejected": -6.2059783935546875,
      "step": 15560
    },
    {
      "epoch": 2.8415001368738024,
      "grad_norm": 8.50202751159668,
      "learning_rate": 3.474839420077079e-05,
      "logits/chosen": -0.7232282161712646,
      "logits/rejected": -0.49277153611183167,
      "logps/chosen": -178.81539916992188,
      "logps/rejected": -200.54469299316406,
      "loss": 0.2576,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.2830913066864014,
      "rewards/margins": 3.214322328567505,
      "rewards/rejected": -6.497413635253906,
      "step": 15570
    },
    {
      "epoch": 2.843325120905192,
      "grad_norm": 11.68200397491455,
      "learning_rate": 3.471903101486512e-05,
      "logits/chosen": -0.8792389631271362,
      "logits/rejected": -0.7397651076316833,
      "logps/chosen": -172.47488403320312,
      "logps/rejected": -200.0640869140625,
      "loss": 0.4678,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.4993622303009033,
      "rewards/margins": 3.0981900691986084,
      "rewards/rejected": -5.597552299499512,
      "step": 15580
    },
    {
      "epoch": 2.845150104936582,
      "grad_norm": 6.956634998321533,
      "learning_rate": 3.4689667828959443e-05,
      "logits/chosen": -0.9558795690536499,
      "logits/rejected": -0.7693101763725281,
      "logps/chosen": -180.18936157226562,
      "logps/rejected": -183.22946166992188,
      "loss": 0.3295,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.5217490196228027,
      "rewards/margins": 3.1556789875030518,
      "rewards/rejected": -5.677428245544434,
      "step": 15590
    },
    {
      "epoch": 2.8469750889679717,
      "grad_norm": 2.606938600540161,
      "learning_rate": 3.4660304643053775e-05,
      "logits/chosen": -0.9500054121017456,
      "logits/rejected": -0.6334267258644104,
      "logps/chosen": -179.0120391845703,
      "logps/rejected": -168.36863708496094,
      "loss": 0.4045,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.5986084938049316,
      "rewards/margins": 2.4863202571868896,
      "rewards/rejected": -5.0849289894104,
      "step": 15600
    },
    {
      "epoch": 2.848800072999361,
      "grad_norm": 5.881366729736328,
      "learning_rate": 3.46309414571481e-05,
      "logits/chosen": -0.9542217254638672,
      "logits/rejected": -0.8149551153182983,
      "logps/chosen": -179.67630004882812,
      "logps/rejected": -202.3387451171875,
      "loss": 0.2615,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.3576903343200684,
      "rewards/margins": 2.984604835510254,
      "rewards/rejected": -5.342295169830322,
      "step": 15610
    },
    {
      "epoch": 2.8506250570307508,
      "grad_norm": 2.1199636459350586,
      "learning_rate": 3.460157827124243e-05,
      "logits/chosen": -0.8693954348564148,
      "logits/rejected": -0.8008328676223755,
      "logps/chosen": -157.2074432373047,
      "logps/rejected": -176.38455200195312,
      "loss": 0.3258,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.7329554557800293,
      "rewards/margins": 2.359410524368286,
      "rewards/rejected": -5.092365741729736,
      "step": 15620
    },
    {
      "epoch": 2.8524500410621405,
      "grad_norm": 3.0450940132141113,
      "learning_rate": 3.457221508533676e-05,
      "logits/chosen": -0.8101390600204468,
      "logits/rejected": -0.6121702194213867,
      "logps/chosen": -185.82894897460938,
      "logps/rejected": -189.797607421875,
      "loss": 0.2642,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.0245273113250732,
      "rewards/margins": 2.7976393699645996,
      "rewards/rejected": -5.822166442871094,
      "step": 15630
    },
    {
      "epoch": 2.8542750250935303,
      "grad_norm": 7.361804485321045,
      "learning_rate": 3.454285189943109e-05,
      "logits/chosen": -0.7831317186355591,
      "logits/rejected": -0.6470075249671936,
      "logps/chosen": -163.00045776367188,
      "logps/rejected": -171.84689331054688,
      "loss": 0.3372,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.0158092975616455,
      "rewards/margins": 2.3916640281677246,
      "rewards/rejected": -5.407473564147949,
      "step": 15640
    },
    {
      "epoch": 2.85610000912492,
      "grad_norm": 3.2272942066192627,
      "learning_rate": 3.451348871352542e-05,
      "logits/chosen": -0.8498529195785522,
      "logits/rejected": -0.6150471568107605,
      "logps/chosen": -173.68785095214844,
      "logps/rejected": -179.231689453125,
      "loss": 0.1807,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.99821138381958,
      "rewards/margins": 3.0545260906219482,
      "rewards/rejected": -6.052737236022949,
      "step": 15650
    },
    {
      "epoch": 2.8579249931563098,
      "grad_norm": 1.305198073387146,
      "learning_rate": 3.448412552761975e-05,
      "logits/chosen": -0.8166290521621704,
      "logits/rejected": -0.6131647825241089,
      "logps/chosen": -174.77639770507812,
      "logps/rejected": -180.1177215576172,
      "loss": 0.325,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.5729899406433105,
      "rewards/margins": 2.761640787124634,
      "rewards/rejected": -6.334630489349365,
      "step": 15660
    },
    {
      "epoch": 2.8597499771876995,
      "grad_norm": 3.044327735900879,
      "learning_rate": 3.445476234171408e-05,
      "logits/chosen": -0.8231064677238464,
      "logits/rejected": -0.5474256277084351,
      "logps/chosen": -211.4408721923828,
      "logps/rejected": -204.46798706054688,
      "loss": 0.2889,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.7221617698669434,
      "rewards/margins": 2.6732842922210693,
      "rewards/rejected": -6.395446300506592,
      "step": 15670
    },
    {
      "epoch": 2.8615749612190893,
      "grad_norm": 3.510578155517578,
      "learning_rate": 3.4425399155808405e-05,
      "logits/chosen": -0.7443144917488098,
      "logits/rejected": -0.6023823022842407,
      "logps/chosen": -193.20449829101562,
      "logps/rejected": -200.5972442626953,
      "loss": 0.2489,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.342911958694458,
      "rewards/margins": 2.68540096282959,
      "rewards/rejected": -6.028312683105469,
      "step": 15680
    },
    {
      "epoch": 2.863399945250479,
      "grad_norm": 14.39344596862793,
      "learning_rate": 3.4396035969902737e-05,
      "logits/chosen": -0.7982540726661682,
      "logits/rejected": -0.732060432434082,
      "logps/chosen": -159.90438842773438,
      "logps/rejected": -198.9464111328125,
      "loss": 0.3454,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.339104413986206,
      "rewards/margins": 3.0015869140625,
      "rewards/rejected": -6.340691089630127,
      "step": 15690
    },
    {
      "epoch": 2.865224929281869,
      "grad_norm": 8.215916633605957,
      "learning_rate": 3.436667278399707e-05,
      "logits/chosen": -0.844403862953186,
      "logits/rejected": -0.767229437828064,
      "logps/chosen": -170.58071899414062,
      "logps/rejected": -193.17660522460938,
      "loss": 0.3169,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.914795160293579,
      "rewards/margins": 2.9651927947998047,
      "rewards/rejected": -5.879987716674805,
      "step": 15700
    },
    {
      "epoch": 2.8670499133132585,
      "grad_norm": 8.522520065307617,
      "learning_rate": 3.43373095980914e-05,
      "logits/chosen": -0.9270095825195312,
      "logits/rejected": -0.6493569612503052,
      "logps/chosen": -181.0235595703125,
      "logps/rejected": -179.15956115722656,
      "loss": 0.3239,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.5540881156921387,
      "rewards/margins": 2.7482285499572754,
      "rewards/rejected": -5.302316665649414,
      "step": 15710
    },
    {
      "epoch": 2.8688748973446483,
      "grad_norm": 1.2869789600372314,
      "learning_rate": 3.4307946412185724e-05,
      "logits/chosen": -0.8245395421981812,
      "logits/rejected": -0.7047981023788452,
      "logps/chosen": -143.2804718017578,
      "logps/rejected": -176.6845245361328,
      "loss": 0.2467,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.637040376663208,
      "rewards/margins": 2.993736743927002,
      "rewards/rejected": -5.630777359008789,
      "step": 15720
    },
    {
      "epoch": 2.870699881376038,
      "grad_norm": 6.339873313903809,
      "learning_rate": 3.4278583226280055e-05,
      "logits/chosen": -1.0121705532073975,
      "logits/rejected": -0.8035787343978882,
      "logps/chosen": -167.2598114013672,
      "logps/rejected": -179.09542846679688,
      "loss": 0.4181,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.39791202545166,
      "rewards/margins": 2.558023691177368,
      "rewards/rejected": -4.955935478210449,
      "step": 15730
    },
    {
      "epoch": 2.872524865407428,
      "grad_norm": 7.276726722717285,
      "learning_rate": 3.424922004037438e-05,
      "logits/chosen": -0.9624869227409363,
      "logits/rejected": -0.8034032583236694,
      "logps/chosen": -179.9842071533203,
      "logps/rejected": -179.53262329101562,
      "loss": 0.3546,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.7180511951446533,
      "rewards/margins": 2.5022571086883545,
      "rewards/rejected": -5.220309257507324,
      "step": 15740
    },
    {
      "epoch": 2.8743498494388176,
      "grad_norm": 5.474194049835205,
      "learning_rate": 3.421985685446871e-05,
      "logits/chosen": -0.8765239715576172,
      "logits/rejected": -0.7263040542602539,
      "logps/chosen": -186.86317443847656,
      "logps/rejected": -192.28982543945312,
      "loss": 0.2338,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.2151989936828613,
      "rewards/margins": 2.6237926483154297,
      "rewards/rejected": -5.838991641998291,
      "step": 15750
    },
    {
      "epoch": 2.8761748334702073,
      "grad_norm": 5.538544178009033,
      "learning_rate": 3.419049366856304e-05,
      "logits/chosen": -0.955226719379425,
      "logits/rejected": -0.736304521560669,
      "logps/chosen": -198.8317413330078,
      "logps/rejected": -199.1973876953125,
      "loss": 0.2312,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.3245863914489746,
      "rewards/margins": 2.7984864711761475,
      "rewards/rejected": -6.123073577880859,
      "step": 15760
    },
    {
      "epoch": 2.877999817501597,
      "grad_norm": 5.348082065582275,
      "learning_rate": 3.4161130482657374e-05,
      "logits/chosen": -0.8423565030097961,
      "logits/rejected": -0.7656568288803101,
      "logps/chosen": -165.79283142089844,
      "logps/rejected": -190.89328002929688,
      "loss": 0.2922,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.9828193187713623,
      "rewards/margins": 2.594398021697998,
      "rewards/rejected": -5.577217102050781,
      "step": 15770
    },
    {
      "epoch": 2.879824801532987,
      "grad_norm": 6.5399489402771,
      "learning_rate": 3.41317672967517e-05,
      "logits/chosen": -0.8110131025314331,
      "logits/rejected": -0.7118774652481079,
      "logps/chosen": -177.28802490234375,
      "logps/rejected": -193.815185546875,
      "loss": 0.2428,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.4686241149902344,
      "rewards/margins": 2.544696807861328,
      "rewards/rejected": -6.0133209228515625,
      "step": 15780
    },
    {
      "epoch": 2.8816497855643766,
      "grad_norm": 2.861923933029175,
      "learning_rate": 3.410240411084603e-05,
      "logits/chosen": -0.8302164077758789,
      "logits/rejected": -0.5630320310592651,
      "logps/chosen": -193.506103515625,
      "logps/rejected": -170.7793731689453,
      "loss": 0.3932,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.650313138961792,
      "rewards/margins": 2.297536611557007,
      "rewards/rejected": -5.947850227355957,
      "step": 15790
    },
    {
      "epoch": 2.883474769595766,
      "grad_norm": 5.98375940322876,
      "learning_rate": 3.4073040924940354e-05,
      "logits/chosen": -0.7510172128677368,
      "logits/rejected": -0.5983937382698059,
      "logps/chosen": -180.2595977783203,
      "logps/rejected": -193.871337890625,
      "loss": 0.2302,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.6336193084716797,
      "rewards/margins": 2.913346529006958,
      "rewards/rejected": -6.546966552734375,
      "step": 15800
    },
    {
      "epoch": 2.8852997536271556,
      "grad_norm": 10.125214576721191,
      "learning_rate": 3.4043677739034686e-05,
      "logits/chosen": -0.8264538645744324,
      "logits/rejected": -0.6590233445167542,
      "logps/chosen": -177.80032348632812,
      "logps/rejected": -191.36575317382812,
      "loss": 0.3114,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.052236080169678,
      "rewards/margins": 2.498103618621826,
      "rewards/rejected": -6.550340175628662,
      "step": 15810
    },
    {
      "epoch": 2.8871247376585454,
      "grad_norm": 6.177280426025391,
      "learning_rate": 3.401431455312902e-05,
      "logits/chosen": -0.7894808053970337,
      "logits/rejected": -0.6700326204299927,
      "logps/chosen": -179.83670043945312,
      "logps/rejected": -210.6494140625,
      "loss": 0.2021,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.375479698181152,
      "rewards/margins": 3.1036839485168457,
      "rewards/rejected": -7.47916316986084,
      "step": 15820
    },
    {
      "epoch": 2.888949721689935,
      "grad_norm": 6.808470726013184,
      "learning_rate": 3.398495136722335e-05,
      "logits/chosen": -0.9363372921943665,
      "logits/rejected": -0.7629777193069458,
      "logps/chosen": -198.97152709960938,
      "logps/rejected": -191.1333770751953,
      "loss": 0.3413,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.540343761444092,
      "rewards/margins": 2.827141284942627,
      "rewards/rejected": -6.367485046386719,
      "step": 15830
    },
    {
      "epoch": 2.890774705721325,
      "grad_norm": 6.203037738800049,
      "learning_rate": 3.395558818131767e-05,
      "logits/chosen": -0.9260837435722351,
      "logits/rejected": -0.8084285855293274,
      "logps/chosen": -175.3169403076172,
      "logps/rejected": -198.5017547607422,
      "loss": 0.3343,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.8923676013946533,
      "rewards/margins": 2.725928783416748,
      "rewards/rejected": -6.618296146392822,
      "step": 15840
    },
    {
      "epoch": 2.8925996897527146,
      "grad_norm": 8.038623809814453,
      "learning_rate": 3.3926224995412004e-05,
      "logits/chosen": -0.8792742490768433,
      "logits/rejected": -0.6751354336738586,
      "logps/chosen": -185.63710021972656,
      "logps/rejected": -197.83648681640625,
      "loss": 0.301,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -4.056225776672363,
      "rewards/margins": 2.8848586082458496,
      "rewards/rejected": -6.941084384918213,
      "step": 15850
    },
    {
      "epoch": 2.8944246737841044,
      "grad_norm": 8.031983375549316,
      "learning_rate": 3.3896861809506336e-05,
      "logits/chosen": -0.8654862642288208,
      "logits/rejected": -0.790618896484375,
      "logps/chosen": -164.71041870117188,
      "logps/rejected": -193.51512145996094,
      "loss": 0.2675,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -4.054812431335449,
      "rewards/margins": 2.9006075859069824,
      "rewards/rejected": -6.95542049407959,
      "step": 15860
    },
    {
      "epoch": 2.896249657815494,
      "grad_norm": 4.642748832702637,
      "learning_rate": 3.386749862360066e-05,
      "logits/chosen": -0.8658088445663452,
      "logits/rejected": -0.6825828552246094,
      "logps/chosen": -192.28968811035156,
      "logps/rejected": -183.80075073242188,
      "loss": 0.298,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.8640975952148438,
      "rewards/margins": 2.6804580688476562,
      "rewards/rejected": -6.5445556640625,
      "step": 15870
    },
    {
      "epoch": 2.898074641846884,
      "grad_norm": 3.9427883625030518,
      "learning_rate": 3.383813543769499e-05,
      "logits/chosen": -0.9586267471313477,
      "logits/rejected": -0.7546417117118835,
      "logps/chosen": -195.79624938964844,
      "logps/rejected": -191.51242065429688,
      "loss": 0.2585,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.5992438793182373,
      "rewards/margins": 2.996436357498169,
      "rewards/rejected": -6.595680236816406,
      "step": 15880
    },
    {
      "epoch": 2.8998996258782737,
      "grad_norm": 6.738217353820801,
      "learning_rate": 3.380877225178932e-05,
      "logits/chosen": -0.8682184219360352,
      "logits/rejected": -0.8075771331787109,
      "logps/chosen": -159.6265106201172,
      "logps/rejected": -194.10641479492188,
      "loss": 0.2807,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.81347918510437,
      "rewards/margins": 2.862264633178711,
      "rewards/rejected": -6.675744533538818,
      "step": 15890
    },
    {
      "epoch": 2.9017246099096634,
      "grad_norm": 12.799835205078125,
      "learning_rate": 3.3779409065883654e-05,
      "logits/chosen": -0.9559923410415649,
      "logits/rejected": -0.829626202583313,
      "logps/chosen": -182.78944396972656,
      "logps/rejected": -194.69773864746094,
      "loss": 0.2611,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.3542752265930176,
      "rewards/margins": 3.0183348655700684,
      "rewards/rejected": -6.372610092163086,
      "step": 15900
    },
    {
      "epoch": 2.903549593941053,
      "grad_norm": 2.196819305419922,
      "learning_rate": 3.375004587997798e-05,
      "logits/chosen": -0.8857604265213013,
      "logits/rejected": -0.7467576265335083,
      "logps/chosen": -183.9404296875,
      "logps/rejected": -194.3275909423828,
      "loss": 0.2207,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.4824471473693848,
      "rewards/margins": 2.980466842651367,
      "rewards/rejected": -6.46291446685791,
      "step": 15910
    },
    {
      "epoch": 2.9053745779724425,
      "grad_norm": 7.791995525360107,
      "learning_rate": 3.372068269407231e-05,
      "logits/chosen": -0.8743686676025391,
      "logits/rejected": -0.7702349424362183,
      "logps/chosen": -179.45181274414062,
      "logps/rejected": -204.2292022705078,
      "loss": 0.2368,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.3342700004577637,
      "rewards/margins": 3.2923858165740967,
      "rewards/rejected": -6.626655578613281,
      "step": 15920
    },
    {
      "epoch": 2.9071995620038322,
      "grad_norm": 3.995249032974243,
      "learning_rate": 3.3691319508166635e-05,
      "logits/chosen": -0.9695343971252441,
      "logits/rejected": -0.8321863412857056,
      "logps/chosen": -196.73175048828125,
      "logps/rejected": -210.7051239013672,
      "loss": 0.3428,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.424520492553711,
      "rewards/margins": 3.0717499256134033,
      "rewards/rejected": -6.496270656585693,
      "step": 15930
    },
    {
      "epoch": 2.909024546035222,
      "grad_norm": 9.108802795410156,
      "learning_rate": 3.3661956322260966e-05,
      "logits/chosen": -0.8362504839897156,
      "logits/rejected": -0.6321852207183838,
      "logps/chosen": -184.8583526611328,
      "logps/rejected": -190.84033203125,
      "loss": 0.315,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.6676952838897705,
      "rewards/margins": 2.7768983840942383,
      "rewards/rejected": -6.444593906402588,
      "step": 15940
    },
    {
      "epoch": 2.9108495300666117,
      "grad_norm": 8.061097145080566,
      "learning_rate": 3.36325931363553e-05,
      "logits/chosen": -0.9154660105705261,
      "logits/rejected": -0.6782476902008057,
      "logps/chosen": -206.83023071289062,
      "logps/rejected": -207.1986083984375,
      "loss": 0.2703,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -4.028937816619873,
      "rewards/margins": 2.919833183288574,
      "rewards/rejected": -6.9487714767456055,
      "step": 15950
    },
    {
      "epoch": 2.9126745140980015,
      "grad_norm": 1.7363924980163574,
      "learning_rate": 3.360322995044963e-05,
      "logits/chosen": -0.9034655690193176,
      "logits/rejected": -0.7117483615875244,
      "logps/chosen": -182.84500122070312,
      "logps/rejected": -191.83206176757812,
      "loss": 0.3703,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.9698569774627686,
      "rewards/margins": 2.623136520385742,
      "rewards/rejected": -6.592993259429932,
      "step": 15960
    },
    {
      "epoch": 2.9144994981293912,
      "grad_norm": 5.477570533752441,
      "learning_rate": 3.357386676454395e-05,
      "logits/chosen": -0.8805812001228333,
      "logits/rejected": -0.7170838117599487,
      "logps/chosen": -185.3199920654297,
      "logps/rejected": -183.3013916015625,
      "loss": 0.3614,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.800063371658325,
      "rewards/margins": 2.4316964149475098,
      "rewards/rejected": -6.231759548187256,
      "step": 15970
    },
    {
      "epoch": 2.916324482160781,
      "grad_norm": 5.068547248840332,
      "learning_rate": 3.3544503578638285e-05,
      "logits/chosen": -0.818791389465332,
      "logits/rejected": -0.7055498361587524,
      "logps/chosen": -170.8563995361328,
      "logps/rejected": -187.13671875,
      "loss": 0.3396,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.6160972118377686,
      "rewards/margins": 2.709379196166992,
      "rewards/rejected": -6.325475692749023,
      "step": 15980
    },
    {
      "epoch": 2.9181494661921707,
      "grad_norm": 6.688931941986084,
      "learning_rate": 3.351514039273261e-05,
      "logits/chosen": -0.8205925226211548,
      "logits/rejected": -0.6634078025817871,
      "logps/chosen": -181.87405395507812,
      "logps/rejected": -197.7468719482422,
      "loss": 0.3195,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.519713878631592,
      "rewards/margins": 2.6227965354919434,
      "rewards/rejected": -6.142510890960693,
      "step": 15990
    },
    {
      "epoch": 2.9199744502235605,
      "grad_norm": 4.7565436363220215,
      "learning_rate": 3.348577720682694e-05,
      "logits/chosen": -0.9618483781814575,
      "logits/rejected": -0.7952273488044739,
      "logps/chosen": -183.78147888183594,
      "logps/rejected": -198.12339782714844,
      "loss": 0.2518,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.046901226043701,
      "rewards/margins": 2.979206085205078,
      "rewards/rejected": -6.026106834411621,
      "step": 16000
    },
    {
      "epoch": 2.9217994342549503,
      "grad_norm": 3.5134477615356445,
      "learning_rate": 3.345641402092127e-05,
      "logits/chosen": -0.9745885729789734,
      "logits/rejected": -0.8105290532112122,
      "logps/chosen": -153.5032501220703,
      "logps/rejected": -154.89566040039062,
      "loss": 0.2783,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.2228481769561768,
      "rewards/margins": 2.5036911964416504,
      "rewards/rejected": -5.72653865814209,
      "step": 16010
    },
    {
      "epoch": 2.92362441828634,
      "grad_norm": 4.182589530944824,
      "learning_rate": 3.34270508350156e-05,
      "logits/chosen": -0.9384360313415527,
      "logits/rejected": -0.7682368755340576,
      "logps/chosen": -178.27328491210938,
      "logps/rejected": -181.58128356933594,
      "loss": 0.268,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.4451236724853516,
      "rewards/margins": 3.019632339477539,
      "rewards/rejected": -6.464756011962891,
      "step": 16020
    },
    {
      "epoch": 2.9254494023177298,
      "grad_norm": 9.781015396118164,
      "learning_rate": 3.3397687649109935e-05,
      "logits/chosen": -0.8973197937011719,
      "logits/rejected": -0.6868169903755188,
      "logps/chosen": -187.42662048339844,
      "logps/rejected": -187.9181671142578,
      "loss": 0.321,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -4.024440288543701,
      "rewards/margins": 2.7078001499176025,
      "rewards/rejected": -6.732240200042725,
      "step": 16030
    },
    {
      "epoch": 2.9272743863491195,
      "grad_norm": 6.603303909301758,
      "learning_rate": 3.336832446320426e-05,
      "logits/chosen": -0.8832277059555054,
      "logits/rejected": -0.6850612163543701,
      "logps/chosen": -176.24838256835938,
      "logps/rejected": -187.26620483398438,
      "loss": 0.2933,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.741635799407959,
      "rewards/margins": 2.686126232147217,
      "rewards/rejected": -6.427762508392334,
      "step": 16040
    },
    {
      "epoch": 2.9290993703805093,
      "grad_norm": 3.1220126152038574,
      "learning_rate": 3.333896127729859e-05,
      "logits/chosen": -0.9021316766738892,
      "logits/rejected": -0.7430796027183533,
      "logps/chosen": -197.05355834960938,
      "logps/rejected": -210.3173370361328,
      "loss": 0.266,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.909914016723633,
      "rewards/margins": 2.630756139755249,
      "rewards/rejected": -6.540669918060303,
      "step": 16050
    },
    {
      "epoch": 2.930924354411899,
      "grad_norm": 6.815158843994141,
      "learning_rate": 3.3309598091392915e-05,
      "logits/chosen": -0.80647212266922,
      "logits/rejected": -0.6931518316268921,
      "logps/chosen": -191.45303344726562,
      "logps/rejected": -193.50537109375,
      "loss": 0.3267,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.7878212928771973,
      "rewards/margins": 2.4809250831604004,
      "rewards/rejected": -6.268746376037598,
      "step": 16060
    },
    {
      "epoch": 2.932749338443289,
      "grad_norm": 7.548769474029541,
      "learning_rate": 3.3280234905487247e-05,
      "logits/chosen": -0.9039677381515503,
      "logits/rejected": -0.7260549664497375,
      "logps/chosen": -188.23046875,
      "logps/rejected": -186.75149536132812,
      "loss": 0.317,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.7196426391601562,
      "rewards/margins": 2.422316551208496,
      "rewards/rejected": -6.141959190368652,
      "step": 16070
    },
    {
      "epoch": 2.9345743224746785,
      "grad_norm": 6.755756855010986,
      "learning_rate": 3.325087171958158e-05,
      "logits/chosen": -0.8809409141540527,
      "logits/rejected": -0.6246660947799683,
      "logps/chosen": -192.84304809570312,
      "logps/rejected": -180.8744659423828,
      "loss": 0.2839,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.834747791290283,
      "rewards/margins": 2.751476764678955,
      "rewards/rejected": -6.586224555969238,
      "step": 16080
    },
    {
      "epoch": 2.9363993065060683,
      "grad_norm": 2.7811543941497803,
      "learning_rate": 3.322150853367591e-05,
      "logits/chosen": -0.9373674392700195,
      "logits/rejected": -0.771114706993103,
      "logps/chosen": -174.58851623535156,
      "logps/rejected": -185.0403594970703,
      "loss": 0.3256,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.665541887283325,
      "rewards/margins": 2.631373167037964,
      "rewards/rejected": -6.296915054321289,
      "step": 16090
    },
    {
      "epoch": 2.938224290537458,
      "grad_norm": 3.0209176540374756,
      "learning_rate": 3.3192145347770234e-05,
      "logits/chosen": -0.9454313516616821,
      "logits/rejected": -0.7260714769363403,
      "logps/chosen": -186.16571044921875,
      "logps/rejected": -180.4090118408203,
      "loss": 0.2843,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.926168918609619,
      "rewards/margins": 2.6158902645111084,
      "rewards/rejected": -6.542059421539307,
      "step": 16100
    },
    {
      "epoch": 2.940049274568848,
      "grad_norm": 8.947799682617188,
      "learning_rate": 3.3162782161864565e-05,
      "logits/chosen": -0.9756163358688354,
      "logits/rejected": -0.7436751127243042,
      "logps/chosen": -188.0794219970703,
      "logps/rejected": -193.56533813476562,
      "loss": 0.2781,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.189603805541992,
      "rewards/margins": 3.1945013999938965,
      "rewards/rejected": -6.384106159210205,
      "step": 16110
    },
    {
      "epoch": 2.941874258600237,
      "grad_norm": 3.126361131668091,
      "learning_rate": 3.313341897595889e-05,
      "logits/chosen": -0.9063498377799988,
      "logits/rejected": -0.7622094750404358,
      "logps/chosen": -197.02505493164062,
      "logps/rejected": -198.66566467285156,
      "loss": 0.3135,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.6496119499206543,
      "rewards/margins": 2.5797057151794434,
      "rewards/rejected": -6.229318141937256,
      "step": 16120
    },
    {
      "epoch": 2.943699242631627,
      "grad_norm": 4.0005717277526855,
      "learning_rate": 3.310405579005322e-05,
      "logits/chosen": -0.9746068716049194,
      "logits/rejected": -0.8225790858268738,
      "logps/chosen": -177.43756103515625,
      "logps/rejected": -179.26153564453125,
      "loss": 0.3282,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.1554923057556152,
      "rewards/margins": 2.416430950164795,
      "rewards/rejected": -5.571923732757568,
      "step": 16130
    },
    {
      "epoch": 2.9455242266630166,
      "grad_norm": 6.839958667755127,
      "learning_rate": 3.307469260414755e-05,
      "logits/chosen": -1.0265392065048218,
      "logits/rejected": -0.7950626611709595,
      "logps/chosen": -208.5450897216797,
      "logps/rejected": -186.41685485839844,
      "loss": 0.2804,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.14707612991333,
      "rewards/margins": 2.761061906814575,
      "rewards/rejected": -5.908137321472168,
      "step": 16140
    },
    {
      "epoch": 2.9473492106944064,
      "grad_norm": 7.189349174499512,
      "learning_rate": 3.3045329418241884e-05,
      "logits/chosen": -1.0295308828353882,
      "logits/rejected": -0.8899052739143372,
      "logps/chosen": -178.5113525390625,
      "logps/rejected": -179.74208068847656,
      "loss": 0.3586,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.7897541522979736,
      "rewards/margins": 2.464250087738037,
      "rewards/rejected": -6.254004001617432,
      "step": 16150
    },
    {
      "epoch": 2.949174194725796,
      "grad_norm": 4.389627456665039,
      "learning_rate": 3.301596623233621e-05,
      "logits/chosen": -0.9414209127426147,
      "logits/rejected": -0.8005523681640625,
      "logps/chosen": -173.1923828125,
      "logps/rejected": -174.84613037109375,
      "loss": 0.2256,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.2603180408477783,
      "rewards/margins": 2.491828203201294,
      "rewards/rejected": -5.7521467208862305,
      "step": 16160
    },
    {
      "epoch": 2.950999178757186,
      "grad_norm": 8.872215270996094,
      "learning_rate": 3.298660304643054e-05,
      "logits/chosen": -0.9380933046340942,
      "logits/rejected": -0.7583833932876587,
      "logps/chosen": -192.3111572265625,
      "logps/rejected": -191.2383270263672,
      "loss": 0.4218,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.3787684440612793,
      "rewards/margins": 2.6017329692840576,
      "rewards/rejected": -5.980501651763916,
      "step": 16170
    },
    {
      "epoch": 2.9528241627885756,
      "grad_norm": 8.534614562988281,
      "learning_rate": 3.295723986052487e-05,
      "logits/chosen": -1.0524508953094482,
      "logits/rejected": -0.8474160432815552,
      "logps/chosen": -178.43360900878906,
      "logps/rejected": -186.21664428710938,
      "loss": 0.2583,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.708139181137085,
      "rewards/margins": 2.9186251163482666,
      "rewards/rejected": -5.626764297485352,
      "step": 16180
    },
    {
      "epoch": 2.9546491468199654,
      "grad_norm": 7.816081523895264,
      "learning_rate": 3.29278766746192e-05,
      "logits/chosen": -0.9101988077163696,
      "logits/rejected": -0.7889603972434998,
      "logps/chosen": -184.65914916992188,
      "logps/rejected": -193.76962280273438,
      "loss": 0.2784,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.2342212200164795,
      "rewards/margins": 2.8789737224578857,
      "rewards/rejected": -6.113195419311523,
      "step": 16190
    },
    {
      "epoch": 2.956474130851355,
      "grad_norm": 7.441671371459961,
      "learning_rate": 3.289851348871353e-05,
      "logits/chosen": -0.8866612315177917,
      "logits/rejected": -0.8020628690719604,
      "logps/chosen": -181.82749938964844,
      "logps/rejected": -202.8970489501953,
      "loss": 0.3127,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.71943998336792,
      "rewards/margins": 2.8199048042297363,
      "rewards/rejected": -6.539344787597656,
      "step": 16200
    },
    {
      "epoch": 2.958299114882745,
      "grad_norm": 10.746339797973633,
      "learning_rate": 3.286915030280786e-05,
      "logits/chosen": -0.9917442202568054,
      "logits/rejected": -0.8423665165901184,
      "logps/chosen": -177.82827758789062,
      "logps/rejected": -189.68067932128906,
      "loss": 0.3829,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.431119441986084,
      "rewards/margins": 2.381153106689453,
      "rewards/rejected": -5.812272548675537,
      "step": 16210
    },
    {
      "epoch": 2.9601240989141346,
      "grad_norm": 18.219776153564453,
      "learning_rate": 3.283978711690219e-05,
      "logits/chosen": -1.0298190116882324,
      "logits/rejected": -0.9500671625137329,
      "logps/chosen": -170.96072387695312,
      "logps/rejected": -187.1711883544922,
      "loss": 0.2848,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.8155081272125244,
      "rewards/margins": 2.4866156578063965,
      "rewards/rejected": -5.302123069763184,
      "step": 16220
    },
    {
      "epoch": 2.9619490829455244,
      "grad_norm": 9.4862642288208,
      "learning_rate": 3.2810423930996514e-05,
      "logits/chosen": -1.0258420705795288,
      "logits/rejected": -0.8762337565422058,
      "logps/chosen": -173.68698120117188,
      "logps/rejected": -182.2221221923828,
      "loss": 0.3625,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.534865140914917,
      "rewards/margins": 2.721442699432373,
      "rewards/rejected": -5.256308078765869,
      "step": 16230
    },
    {
      "epoch": 2.9637740669769137,
      "grad_norm": 2.4100136756896973,
      "learning_rate": 3.2781060745090846e-05,
      "logits/chosen": -1.0064650774002075,
      "logits/rejected": -0.9318812489509583,
      "logps/chosen": -186.92617797851562,
      "logps/rejected": -199.7006378173828,
      "loss": 0.3174,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.480700731277466,
      "rewards/margins": 2.3528034687042236,
      "rewards/rejected": -5.833503246307373,
      "step": 16240
    },
    {
      "epoch": 2.9655990510083035,
      "grad_norm": 5.815427780151367,
      "learning_rate": 3.275169755918518e-05,
      "logits/chosen": -0.9874639511108398,
      "logits/rejected": -0.8662883639335632,
      "logps/chosen": -170.6025848388672,
      "logps/rejected": -177.36007690429688,
      "loss": 0.3011,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.1878349781036377,
      "rewards/margins": 2.1289238929748535,
      "rewards/rejected": -5.316758155822754,
      "step": 16250
    },
    {
      "epoch": 2.967424035039693,
      "grad_norm": 2.8237359523773193,
      "learning_rate": 3.272233437327951e-05,
      "logits/chosen": -0.990125834941864,
      "logits/rejected": -0.8659526705741882,
      "logps/chosen": -176.45443725585938,
      "logps/rejected": -180.49142456054688,
      "loss": 0.3555,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.600187301635742,
      "rewards/margins": 2.159029483795166,
      "rewards/rejected": -5.759217262268066,
      "step": 16260
    },
    {
      "epoch": 2.969249019071083,
      "grad_norm": 5.087466716766357,
      "learning_rate": 3.269297118737383e-05,
      "logits/chosen": -1.0200965404510498,
      "logits/rejected": -0.8375242948532104,
      "logps/chosen": -170.78749084472656,
      "logps/rejected": -180.42807006835938,
      "loss": 0.2324,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.667419195175171,
      "rewards/margins": 2.6910080909729004,
      "rewards/rejected": -5.358426570892334,
      "step": 16270
    },
    {
      "epoch": 2.9710740031024727,
      "grad_norm": 7.49751615524292,
      "learning_rate": 3.2663608001468164e-05,
      "logits/chosen": -0.8922214508056641,
      "logits/rejected": -0.8674615025520325,
      "logps/chosen": -165.73471069335938,
      "logps/rejected": -193.7484893798828,
      "loss": 0.3936,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.5015311241149902,
      "rewards/margins": 2.1452298164367676,
      "rewards/rejected": -5.6467604637146,
      "step": 16280
    },
    {
      "epoch": 2.9728989871338625,
      "grad_norm": 4.8416619300842285,
      "learning_rate": 3.263424481556249e-05,
      "logits/chosen": -0.9048047065734863,
      "logits/rejected": -0.7871445417404175,
      "logps/chosen": -170.30548095703125,
      "logps/rejected": -184.71795654296875,
      "loss": 0.37,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.400177001953125,
      "rewards/margins": 2.504014730453491,
      "rewards/rejected": -5.9041924476623535,
      "step": 16290
    },
    {
      "epoch": 2.9747239711652522,
      "grad_norm": 1.8008185625076294,
      "learning_rate": 3.260488162965682e-05,
      "logits/chosen": -0.959374725818634,
      "logits/rejected": -0.728002667427063,
      "logps/chosen": -183.6751251220703,
      "logps/rejected": -186.90170288085938,
      "loss": 0.2511,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.2906689643859863,
      "rewards/margins": 2.8922324180603027,
      "rewards/rejected": -6.182901859283447,
      "step": 16300
    },
    {
      "epoch": 2.976548955196642,
      "grad_norm": 5.396340370178223,
      "learning_rate": 3.257551844375115e-05,
      "logits/chosen": -0.9152469635009766,
      "logits/rejected": -0.7586827278137207,
      "logps/chosen": -179.30010986328125,
      "logps/rejected": -178.61138916015625,
      "loss": 0.3303,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.8322463035583496,
      "rewards/margins": 2.397169589996338,
      "rewards/rejected": -6.229416370391846,
      "step": 16310
    },
    {
      "epoch": 2.9783739392280317,
      "grad_norm": 6.300968170166016,
      "learning_rate": 3.254615525784548e-05,
      "logits/chosen": -0.8812867999076843,
      "logits/rejected": -0.7829720973968506,
      "logps/chosen": -184.4461669921875,
      "logps/rejected": -192.13409423828125,
      "loss": 0.362,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.257910966873169,
      "rewards/margins": 2.223037004470825,
      "rewards/rejected": -5.480947971343994,
      "step": 16320
    },
    {
      "epoch": 2.9801989232594215,
      "grad_norm": 2.9768381118774414,
      "learning_rate": 3.251679207193981e-05,
      "logits/chosen": -0.883471667766571,
      "logits/rejected": -0.6488584280014038,
      "logps/chosen": -186.4425506591797,
      "logps/rejected": -195.42922973632812,
      "loss": 0.1716,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.6895759105682373,
      "rewards/margins": 3.208338499069214,
      "rewards/rejected": -6.897913455963135,
      "step": 16330
    },
    {
      "epoch": 2.9820239072908112,
      "grad_norm": 2.403411865234375,
      "learning_rate": 3.248742888603414e-05,
      "logits/chosen": -0.7220054864883423,
      "logits/rejected": -0.5563230514526367,
      "logps/chosen": -180.13583374023438,
      "logps/rejected": -187.1055145263672,
      "loss": 0.2145,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.7821879386901855,
      "rewards/margins": 2.9773497581481934,
      "rewards/rejected": -6.7595367431640625,
      "step": 16340
    },
    {
      "epoch": 2.983848891322201,
      "grad_norm": 7.248176097869873,
      "learning_rate": 3.245806570012846e-05,
      "logits/chosen": -0.8197141885757446,
      "logits/rejected": -0.6572657227516174,
      "logps/chosen": -188.0402374267578,
      "logps/rejected": -188.41139221191406,
      "loss": 0.3231,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.9935543537139893,
      "rewards/margins": 2.3125500679016113,
      "rewards/rejected": -6.3061041831970215,
      "step": 16350
    },
    {
      "epoch": 2.9856738753535907,
      "grad_norm": 8.465353012084961,
      "learning_rate": 3.2428702514222795e-05,
      "logits/chosen": -0.9022465944290161,
      "logits/rejected": -0.745242714881897,
      "logps/chosen": -190.93893432617188,
      "logps/rejected": -197.48965454101562,
      "loss": 0.3234,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.9102015495300293,
      "rewards/margins": 2.2782976627349854,
      "rewards/rejected": -6.1884989738464355,
      "step": 16360
    },
    {
      "epoch": 2.9874988593849805,
      "grad_norm": 1.064430594444275,
      "learning_rate": 3.2399339328317126e-05,
      "logits/chosen": -0.84601891040802,
      "logits/rejected": -0.7326860427856445,
      "logps/chosen": -172.33924865722656,
      "logps/rejected": -183.313232421875,
      "loss": 0.3491,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.745365619659424,
      "rewards/margins": 2.393789768218994,
      "rewards/rejected": -6.139155387878418,
      "step": 16370
    },
    {
      "epoch": 2.9893238434163703,
      "grad_norm": 8.955694198608398,
      "learning_rate": 3.236997614241146e-05,
      "logits/chosen": -0.9530926942825317,
      "logits/rejected": -0.7035561800003052,
      "logps/chosen": -186.59567260742188,
      "logps/rejected": -185.9586944580078,
      "loss": 0.3422,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.544539213180542,
      "rewards/margins": 2.6231331825256348,
      "rewards/rejected": -6.167672157287598,
      "step": 16380
    },
    {
      "epoch": 2.99114882744776,
      "grad_norm": 3.4298384189605713,
      "learning_rate": 3.234061295650578e-05,
      "logits/chosen": -0.905325710773468,
      "logits/rejected": -0.6997252702713013,
      "logps/chosen": -178.1539764404297,
      "logps/rejected": -185.94215393066406,
      "loss": 0.2586,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.7643165588378906,
      "rewards/margins": 2.6058154106140137,
      "rewards/rejected": -6.370131492614746,
      "step": 16390
    },
    {
      "epoch": 2.9929738114791498,
      "grad_norm": 3.625368118286133,
      "learning_rate": 3.231124977060011e-05,
      "logits/chosen": -0.8911362886428833,
      "logits/rejected": -0.745110034942627,
      "logps/chosen": -195.81729125976562,
      "logps/rejected": -200.9803466796875,
      "loss": 0.2566,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.582939863204956,
      "rewards/margins": 2.8109185695648193,
      "rewards/rejected": -6.393858909606934,
      "step": 16400
    },
    {
      "epoch": 2.9947987955105395,
      "grad_norm": 6.058742523193359,
      "learning_rate": 3.2281886584694445e-05,
      "logits/chosen": -0.8560872077941895,
      "logits/rejected": -0.7207343578338623,
      "logps/chosen": -171.7161102294922,
      "logps/rejected": -191.15823364257812,
      "loss": 0.2132,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.616624116897583,
      "rewards/margins": 2.581970453262329,
      "rewards/rejected": -6.198594093322754,
      "step": 16410
    },
    {
      "epoch": 2.9966237795419293,
      "grad_norm": 2.2799994945526123,
      "learning_rate": 3.225252339878877e-05,
      "logits/chosen": -0.7868647575378418,
      "logits/rejected": -0.6582755446434021,
      "logps/chosen": -171.6215362548828,
      "logps/rejected": -197.43441772460938,
      "loss": 0.2786,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.871605634689331,
      "rewards/margins": 2.779419422149658,
      "rewards/rejected": -6.651025295257568,
      "step": 16420
    },
    {
      "epoch": 2.9984487635733186,
      "grad_norm": 3.182769536972046,
      "learning_rate": 3.22231602128831e-05,
      "logits/chosen": -0.7844870686531067,
      "logits/rejected": -0.6318384408950806,
      "logps/chosen": -176.3635711669922,
      "logps/rejected": -203.70069885253906,
      "loss": 0.2697,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.6193320751190186,
      "rewards/margins": 3.172870635986328,
      "rewards/rejected": -6.792202949523926,
      "step": 16430
    },
    {
      "epoch": 3.0002737476047083,
      "grad_norm": 5.51057243347168,
      "learning_rate": 3.219379702697743e-05,
      "logits/chosen": -0.8438178300857544,
      "logits/rejected": -0.6599136590957642,
      "logps/chosen": -196.41024780273438,
      "logps/rejected": -201.2333221435547,
      "loss": 0.2115,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.504470109939575,
      "rewards/margins": 2.9916064739227295,
      "rewards/rejected": -6.4960761070251465,
      "step": 16440
    },
    {
      "epoch": 3.002098731636098,
      "grad_norm": 2.2801108360290527,
      "learning_rate": 3.216443384107176e-05,
      "logits/chosen": -0.7441354393959045,
      "logits/rejected": -0.6089988946914673,
      "logps/chosen": -163.73171997070312,
      "logps/rejected": -196.2882080078125,
      "loss": 0.2407,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.668738842010498,
      "rewards/margins": 3.3612239360809326,
      "rewards/rejected": -7.029963493347168,
      "step": 16450
    },
    {
      "epoch": 3.003923715667488,
      "grad_norm": 6.160962104797363,
      "learning_rate": 3.213507065516609e-05,
      "logits/chosen": -0.7352272868156433,
      "logits/rejected": -0.497415155172348,
      "logps/chosen": -189.09854125976562,
      "logps/rejected": -192.06199645996094,
      "loss": 0.1821,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.7691102027893066,
      "rewards/margins": 3.2764904499053955,
      "rewards/rejected": -7.045599937438965,
      "step": 16460
    },
    {
      "epoch": 3.0057486996988776,
      "grad_norm": 8.12535285949707,
      "learning_rate": 3.210570746926042e-05,
      "logits/chosen": -0.85590660572052,
      "logits/rejected": -0.6272957921028137,
      "logps/chosen": -188.78724670410156,
      "logps/rejected": -202.69100952148438,
      "loss": 0.2658,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.812873363494873,
      "rewards/margins": 3.4966251850128174,
      "rewards/rejected": -7.3094987869262695,
      "step": 16470
    },
    {
      "epoch": 3.0075736837302673,
      "grad_norm": 4.580914497375488,
      "learning_rate": 3.2076344283354744e-05,
      "logits/chosen": -0.8054254651069641,
      "logits/rejected": -0.6520746350288391,
      "logps/chosen": -179.18191528320312,
      "logps/rejected": -195.2687225341797,
      "loss": 0.1706,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -3.502932071685791,
      "rewards/margins": 3.1869421005249023,
      "rewards/rejected": -6.689874172210693,
      "step": 16480
    },
    {
      "epoch": 3.009398667761657,
      "grad_norm": 7.430388450622559,
      "learning_rate": 3.2046981097449075e-05,
      "logits/chosen": -0.7783333659172058,
      "logits/rejected": -0.5691419243812561,
      "logps/chosen": -186.16824340820312,
      "logps/rejected": -201.49977111816406,
      "loss": 0.2043,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.813859224319458,
      "rewards/margins": 3.5389416217803955,
      "rewards/rejected": -7.352801322937012,
      "step": 16490
    },
    {
      "epoch": 3.011223651793047,
      "grad_norm": 2.7518999576568604,
      "learning_rate": 3.2017617911543407e-05,
      "logits/chosen": -0.7485219240188599,
      "logits/rejected": -0.5330687165260315,
      "logps/chosen": -190.90277099609375,
      "logps/rejected": -206.4079132080078,
      "loss": 0.2055,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.97214937210083,
      "rewards/margins": 3.8393497467041016,
      "rewards/rejected": -7.811499118804932,
      "step": 16500
    },
    {
      "epoch": 3.0130486358244366,
      "grad_norm": 5.919034957885742,
      "learning_rate": 3.198825472563774e-05,
      "logits/chosen": -0.6345616579055786,
      "logits/rejected": -0.37251725792884827,
      "logps/chosen": -185.58297729492188,
      "logps/rejected": -188.6981658935547,
      "loss": 0.2062,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.031599044799805,
      "rewards/margins": 3.3443832397460938,
      "rewards/rejected": -7.375982761383057,
      "step": 16510
    },
    {
      "epoch": 3.0148736198558264,
      "grad_norm": 1.718449592590332,
      "learning_rate": 3.195889153973206e-05,
      "logits/chosen": -0.7339092493057251,
      "logits/rejected": -0.607373833656311,
      "logps/chosen": -179.564453125,
      "logps/rejected": -206.586181640625,
      "loss": 0.1447,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.023707389831543,
      "rewards/margins": 3.668091297149658,
      "rewards/rejected": -7.691798210144043,
      "step": 16520
    },
    {
      "epoch": 3.016698603887216,
      "grad_norm": 2.228778123855591,
      "learning_rate": 3.1929528353826394e-05,
      "logits/chosen": -0.8190681338310242,
      "logits/rejected": -0.610047459602356,
      "logps/chosen": -200.8781280517578,
      "logps/rejected": -231.7223663330078,
      "loss": 0.1273,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -3.8955917358398438,
      "rewards/margins": 4.298529148101807,
      "rewards/rejected": -8.194120407104492,
      "step": 16530
    },
    {
      "epoch": 3.018523587918606,
      "grad_norm": 8.6111421585083,
      "learning_rate": 3.190016516792072e-05,
      "logits/chosen": -0.6769328713417053,
      "logits/rejected": -0.45343589782714844,
      "logps/chosen": -200.85226440429688,
      "logps/rejected": -227.37393188476562,
      "loss": 0.1386,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.673731327056885,
      "rewards/margins": 4.0014262199401855,
      "rewards/rejected": -8.67515754699707,
      "step": 16540
    },
    {
      "epoch": 3.0203485719499956,
      "grad_norm": 5.000792026519775,
      "learning_rate": 3.187080198201505e-05,
      "logits/chosen": -0.7215505838394165,
      "logits/rejected": -0.40427201986312866,
      "logps/chosen": -200.4340362548828,
      "logps/rejected": -214.5982666015625,
      "loss": 0.1263,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.801153659820557,
      "rewards/margins": 4.233961582183838,
      "rewards/rejected": -9.035114288330078,
      "step": 16550
    },
    {
      "epoch": 3.0221735559813854,
      "grad_norm": 5.290234088897705,
      "learning_rate": 3.184143879610938e-05,
      "logits/chosen": -0.7393416166305542,
      "logits/rejected": -0.4216887950897217,
      "logps/chosen": -190.3448028564453,
      "logps/rejected": -199.1223907470703,
      "loss": 0.14,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.24675178527832,
      "rewards/margins": 4.202938079833984,
      "rewards/rejected": -8.449689865112305,
      "step": 16560
    },
    {
      "epoch": 3.0239985400127747,
      "grad_norm": 12.001727104187012,
      "learning_rate": 3.181207561020371e-05,
      "logits/chosen": -0.6839287877082825,
      "logits/rejected": -0.4030453562736511,
      "logps/chosen": -193.232177734375,
      "logps/rejected": -211.41995239257812,
      "loss": 0.1938,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -4.588213920593262,
      "rewards/margins": 3.8074951171875,
      "rewards/rejected": -8.395709991455078,
      "step": 16570
    },
    {
      "epoch": 3.0258235240441644,
      "grad_norm": 13.2959623336792,
      "learning_rate": 3.1782712424298044e-05,
      "logits/chosen": -0.758052408695221,
      "logits/rejected": -0.5935529470443726,
      "logps/chosen": -189.99166870117188,
      "logps/rejected": -227.32760620117188,
      "loss": 0.1279,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.101871967315674,
      "rewards/margins": 4.2469892501831055,
      "rewards/rejected": -8.348860740661621,
      "step": 16580
    },
    {
      "epoch": 3.027648508075554,
      "grad_norm": 7.090160846710205,
      "learning_rate": 3.175334923839237e-05,
      "logits/chosen": -0.8593955039978027,
      "logits/rejected": -0.623813807964325,
      "logps/chosen": -191.2119140625,
      "logps/rejected": -208.48916625976562,
      "loss": 0.1371,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.2538042068481445,
      "rewards/margins": 4.1329169273376465,
      "rewards/rejected": -8.38672161102295,
      "step": 16590
    },
    {
      "epoch": 3.029473492106944,
      "grad_norm": 10.317615509033203,
      "learning_rate": 3.17239860524867e-05,
      "logits/chosen": -0.7463656663894653,
      "logits/rejected": -0.45711493492126465,
      "logps/chosen": -192.10153198242188,
      "logps/rejected": -209.4855499267578,
      "loss": 0.128,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.95227575302124,
      "rewards/margins": 4.0497541427612305,
      "rewards/rejected": -9.002030372619629,
      "step": 16600
    },
    {
      "epoch": 3.0312984761383337,
      "grad_norm": 7.779356002807617,
      "learning_rate": 3.1694622866581024e-05,
      "logits/chosen": -0.8244512677192688,
      "logits/rejected": -0.6252463459968567,
      "logps/chosen": -201.4781036376953,
      "logps/rejected": -222.80941772460938,
      "loss": 0.2307,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -4.382462978363037,
      "rewards/margins": 3.8462111949920654,
      "rewards/rejected": -8.228673934936523,
      "step": 16610
    },
    {
      "epoch": 3.0331234601697235,
      "grad_norm": 4.394906520843506,
      "learning_rate": 3.1665259680675356e-05,
      "logits/chosen": -0.7378583550453186,
      "logits/rejected": -0.5689046382904053,
      "logps/chosen": -176.50424194335938,
      "logps/rejected": -215.2951202392578,
      "loss": 0.1082,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -4.2718682289123535,
      "rewards/margins": 4.423395156860352,
      "rewards/rejected": -8.69526481628418,
      "step": 16620
    },
    {
      "epoch": 3.034948444201113,
      "grad_norm": 7.212975025177002,
      "learning_rate": 3.163589649476969e-05,
      "logits/chosen": -0.6914092898368835,
      "logits/rejected": -0.32477518916130066,
      "logps/chosen": -208.1699981689453,
      "logps/rejected": -218.8413543701172,
      "loss": 0.2019,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.325422763824463,
      "rewards/margins": 4.426302909851074,
      "rewards/rejected": -9.751726150512695,
      "step": 16630
    },
    {
      "epoch": 3.036773428232503,
      "grad_norm": 2.8900697231292725,
      "learning_rate": 3.160653330886402e-05,
      "logits/chosen": -0.6642740964889526,
      "logits/rejected": -0.529930055141449,
      "logps/chosen": -189.44537353515625,
      "logps/rejected": -210.69284057617188,
      "loss": 0.1755,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.983639717102051,
      "rewards/margins": 3.68200421333313,
      "rewards/rejected": -8.665644645690918,
      "step": 16640
    },
    {
      "epoch": 3.0385984122638927,
      "grad_norm": 4.1671857833862305,
      "learning_rate": 3.157717012295834e-05,
      "logits/chosen": -0.684931218624115,
      "logits/rejected": -0.4484046399593353,
      "logps/chosen": -208.7054901123047,
      "logps/rejected": -225.06570434570312,
      "loss": 0.0968,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.383546352386475,
      "rewards/margins": 4.426351547241211,
      "rewards/rejected": -9.809897422790527,
      "step": 16650
    },
    {
      "epoch": 3.0404233962952825,
      "grad_norm": 3.4066920280456543,
      "learning_rate": 3.1547806937052674e-05,
      "logits/chosen": -0.9024370908737183,
      "logits/rejected": -0.42824769020080566,
      "logps/chosen": -209.1272430419922,
      "logps/rejected": -199.00885009765625,
      "loss": 0.1743,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.160057067871094,
      "rewards/margins": 4.109256744384766,
      "rewards/rejected": -8.269315719604492,
      "step": 16660
    },
    {
      "epoch": 3.042248380326672,
      "grad_norm": 4.652230739593506,
      "learning_rate": 3.1518443751147e-05,
      "logits/chosen": -0.8151935338973999,
      "logits/rejected": -0.5901397466659546,
      "logps/chosen": -176.78634643554688,
      "logps/rejected": -201.95236206054688,
      "loss": 0.2546,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.717974901199341,
      "rewards/margins": 4.175983905792236,
      "rewards/rejected": -7.893959045410156,
      "step": 16670
    },
    {
      "epoch": 3.044073364358062,
      "grad_norm": 2.441272735595703,
      "learning_rate": 3.148908056524133e-05,
      "logits/chosen": -0.7971307635307312,
      "logits/rejected": -0.5827000737190247,
      "logps/chosen": -197.26766967773438,
      "logps/rejected": -222.25973510742188,
      "loss": 0.0774,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -4.204119682312012,
      "rewards/margins": 4.50936222076416,
      "rewards/rejected": -8.713480949401855,
      "step": 16680
    },
    {
      "epoch": 3.0458983483894517,
      "grad_norm": 2.566594362258911,
      "learning_rate": 3.145971737933566e-05,
      "logits/chosen": -0.8892462849617004,
      "logits/rejected": -0.5459571480751038,
      "logps/chosen": -207.45327758789062,
      "logps/rejected": -209.6247100830078,
      "loss": 0.1514,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.307436943054199,
      "rewards/margins": 4.60655403137207,
      "rewards/rejected": -8.91399097442627,
      "step": 16690
    },
    {
      "epoch": 3.0477233324208415,
      "grad_norm": 4.240650653839111,
      "learning_rate": 3.143035419342999e-05,
      "logits/chosen": -0.4738638997077942,
      "logits/rejected": -0.33065056800842285,
      "logps/chosen": -186.16989135742188,
      "logps/rejected": -219.54983520507812,
      "loss": 0.1854,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.856234550476074,
      "rewards/margins": 4.056710243225098,
      "rewards/rejected": -9.912944793701172,
      "step": 16700
    },
    {
      "epoch": 3.0495483164522312,
      "grad_norm": 1.4184194803237915,
      "learning_rate": 3.140099100752432e-05,
      "logits/chosen": -0.8092136383056641,
      "logits/rejected": -0.5673705339431763,
      "logps/chosen": -192.73292541503906,
      "logps/rejected": -231.0009765625,
      "loss": 0.0706,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -4.3921308517456055,
      "rewards/margins": 4.8613457679748535,
      "rewards/rejected": -9.253477096557617,
      "step": 16710
    },
    {
      "epoch": 3.051373300483621,
      "grad_norm": 4.89891242980957,
      "learning_rate": 3.137162782161865e-05,
      "logits/chosen": -0.6838912963867188,
      "logits/rejected": -0.4376952052116394,
      "logps/chosen": -197.5973663330078,
      "logps/rejected": -217.35791015625,
      "loss": 0.1553,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.090348720550537,
      "rewards/margins": 4.502498626708984,
      "rewards/rejected": -9.59284782409668,
      "step": 16720
    },
    {
      "epoch": 3.0531982845150103,
      "grad_norm": 0.7949318289756775,
      "learning_rate": 3.134226463571297e-05,
      "logits/chosen": -0.6875048875808716,
      "logits/rejected": -0.39877718687057495,
      "logps/chosen": -185.26791381835938,
      "logps/rejected": -228.5375213623047,
      "loss": 0.1318,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.580217361450195,
      "rewards/margins": 5.268327236175537,
      "rewards/rejected": -9.84854507446289,
      "step": 16730
    },
    {
      "epoch": 3.0550232685464,
      "grad_norm": 2.824766159057617,
      "learning_rate": 3.1312901449807305e-05,
      "logits/chosen": -0.7821208238601685,
      "logits/rejected": -0.4472696781158447,
      "logps/chosen": -201.06390380859375,
      "logps/rejected": -226.33706665039062,
      "loss": 0.1302,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.712006568908691,
      "rewards/margins": 4.619459629058838,
      "rewards/rejected": -9.331465721130371,
      "step": 16740
    },
    {
      "epoch": 3.05684825257779,
      "grad_norm": 1.9843790531158447,
      "learning_rate": 3.1283538263901636e-05,
      "logits/chosen": -0.7667155861854553,
      "logits/rejected": -0.4817010462284088,
      "logps/chosen": -187.79237365722656,
      "logps/rejected": -215.37582397460938,
      "loss": 0.162,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -4.271219730377197,
      "rewards/margins": 4.256608486175537,
      "rewards/rejected": -8.52782917022705,
      "step": 16750
    },
    {
      "epoch": 3.0586732366091796,
      "grad_norm": 0.6445779204368591,
      "learning_rate": 3.125417507799597e-05,
      "logits/chosen": -0.7018121480941772,
      "logits/rejected": -0.36511534452438354,
      "logps/chosen": -183.0442657470703,
      "logps/rejected": -204.97647094726562,
      "loss": 0.1092,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -3.78814435005188,
      "rewards/margins": 4.799388885498047,
      "rewards/rejected": -8.587533950805664,
      "step": 16760
    },
    {
      "epoch": 3.0604982206405693,
      "grad_norm": 8.326245307922363,
      "learning_rate": 3.12248118920903e-05,
      "logits/chosen": -0.803493320941925,
      "logits/rejected": -0.5430086851119995,
      "logps/chosen": -184.4523162841797,
      "logps/rejected": -214.75460815429688,
      "loss": 0.275,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.215925693511963,
      "rewards/margins": 4.5761613845825195,
      "rewards/rejected": -8.792086601257324,
      "step": 16770
    },
    {
      "epoch": 3.062323204671959,
      "grad_norm": 12.71983814239502,
      "learning_rate": 3.119544870618462e-05,
      "logits/chosen": -0.8958806991577148,
      "logits/rejected": -0.7813194394111633,
      "logps/chosen": -190.51654052734375,
      "logps/rejected": -231.31640625,
      "loss": 0.2227,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.831439256668091,
      "rewards/margins": 4.0827202796936035,
      "rewards/rejected": -7.914159297943115,
      "step": 16780
    },
    {
      "epoch": 3.064148188703349,
      "grad_norm": 4.603031158447266,
      "learning_rate": 3.1166085520278955e-05,
      "logits/chosen": -0.8515105247497559,
      "logits/rejected": -0.5508461594581604,
      "logps/chosen": -188.56521606445312,
      "logps/rejected": -212.2832489013672,
      "loss": 0.1209,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -3.6994452476501465,
      "rewards/margins": 4.12479305267334,
      "rewards/rejected": -7.8242387771606445,
      "step": 16790
    },
    {
      "epoch": 3.0659731727347386,
      "grad_norm": 15.002903938293457,
      "learning_rate": 3.113672233437328e-05,
      "logits/chosen": -0.7780869007110596,
      "logits/rejected": -0.6058385968208313,
      "logps/chosen": -188.93203735351562,
      "logps/rejected": -217.5172576904297,
      "loss": 0.1144,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.350882530212402,
      "rewards/margins": 4.7569098472595215,
      "rewards/rejected": -9.107792854309082,
      "step": 16800
    },
    {
      "epoch": 3.0677981567661283,
      "grad_norm": 3.0987937450408936,
      "learning_rate": 3.110735914846761e-05,
      "logits/chosen": -0.6181884407997131,
      "logits/rejected": -0.38195815682411194,
      "logps/chosen": -196.4166259765625,
      "logps/rejected": -232.30892944335938,
      "loss": 0.082,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -4.4009199142456055,
      "rewards/margins": 4.794949054718018,
      "rewards/rejected": -9.195869445800781,
      "step": 16810
    },
    {
      "epoch": 3.069623140797518,
      "grad_norm": 3.7604424953460693,
      "learning_rate": 3.107799596256194e-05,
      "logits/chosen": -0.641877293586731,
      "logits/rejected": -0.30558282136917114,
      "logps/chosen": -201.1165771484375,
      "logps/rejected": -228.6973114013672,
      "loss": 0.1765,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.7210869789123535,
      "rewards/margins": 4.37575626373291,
      "rewards/rejected": -10.096841812133789,
      "step": 16820
    },
    {
      "epoch": 3.071448124828908,
      "grad_norm": 12.76712703704834,
      "learning_rate": 3.104863277665627e-05,
      "logits/chosen": -0.6282030344009399,
      "logits/rejected": -0.4108152389526367,
      "logps/chosen": -193.32479858398438,
      "logps/rejected": -224.4873504638672,
      "loss": 0.1539,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.162775993347168,
      "rewards/margins": 4.1585259437561035,
      "rewards/rejected": -9.32130241394043,
      "step": 16830
    },
    {
      "epoch": 3.0732731088602976,
      "grad_norm": 2.5233824253082275,
      "learning_rate": 3.10192695907506e-05,
      "logits/chosen": -0.5039604902267456,
      "logits/rejected": -0.39082765579223633,
      "logps/chosen": -188.2789306640625,
      "logps/rejected": -234.6957244873047,
      "loss": 0.15,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.186491012573242,
      "rewards/margins": 4.236720085144043,
      "rewards/rejected": -9.423211097717285,
      "step": 16840
    },
    {
      "epoch": 3.0750980928916873,
      "grad_norm": 4.8387227058410645,
      "learning_rate": 3.098990640484493e-05,
      "logits/chosen": -0.6395778059959412,
      "logits/rejected": -0.35935789346694946,
      "logps/chosen": -181.70773315429688,
      "logps/rejected": -213.1811981201172,
      "loss": 0.1105,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.258490085601807,
      "rewards/margins": 4.794167518615723,
      "rewards/rejected": -9.052659034729004,
      "step": 16850
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 13.04659652709961,
      "learning_rate": 3.0960543218939254e-05,
      "logits/chosen": -0.682600200176239,
      "logits/rejected": -0.49961766600608826,
      "logps/chosen": -190.52777099609375,
      "logps/rejected": -225.1486053466797,
      "loss": 0.1797,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.200875282287598,
      "rewards/margins": 4.563553810119629,
      "rewards/rejected": -8.764429092407227,
      "step": 16860
    },
    {
      "epoch": 3.078748060954467,
      "grad_norm": 0.8992215991020203,
      "learning_rate": 3.0931180033033585e-05,
      "logits/chosen": -0.6542895436286926,
      "logits/rejected": -0.341815710067749,
      "logps/chosen": -191.6454315185547,
      "logps/rejected": -220.8974609375,
      "loss": 0.1164,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.8733062744140625,
      "rewards/margins": 4.896378517150879,
      "rewards/rejected": -9.769685745239258,
      "step": 16870
    },
    {
      "epoch": 3.080573044985856,
      "grad_norm": 5.993251323699951,
      "learning_rate": 3.0901816847127917e-05,
      "logits/chosen": -0.5493906736373901,
      "logits/rejected": -0.1450745165348053,
      "logps/chosen": -203.4571990966797,
      "logps/rejected": -210.703125,
      "loss": 0.0786,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.171026229858398,
      "rewards/margins": 4.435170650482178,
      "rewards/rejected": -9.606196403503418,
      "step": 16880
    },
    {
      "epoch": 3.082398029017246,
      "grad_norm": 3.616011381149292,
      "learning_rate": 3.087245366122225e-05,
      "logits/chosen": -0.5579159259796143,
      "logits/rejected": -0.2767331600189209,
      "logps/chosen": -201.38922119140625,
      "logps/rejected": -219.30477905273438,
      "loss": 0.179,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.714031219482422,
      "rewards/margins": 4.674755096435547,
      "rewards/rejected": -9.388785362243652,
      "step": 16890
    },
    {
      "epoch": 3.0842230130486357,
      "grad_norm": 4.717988014221191,
      "learning_rate": 3.084309047531657e-05,
      "logits/chosen": -0.463494211435318,
      "logits/rejected": -0.22645418345928192,
      "logps/chosen": -197.3418426513672,
      "logps/rejected": -222.5861358642578,
      "loss": 0.1655,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.130505084991455,
      "rewards/margins": 4.226542949676514,
      "rewards/rejected": -9.357048988342285,
      "step": 16900
    },
    {
      "epoch": 3.0860479970800254,
      "grad_norm": 6.535206317901611,
      "learning_rate": 3.0813727289410904e-05,
      "logits/chosen": -0.49025970697402954,
      "logits/rejected": -0.2612709105014801,
      "logps/chosen": -171.44650268554688,
      "logps/rejected": -207.7174072265625,
      "loss": 0.2579,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -4.929903984069824,
      "rewards/margins": 3.9461569786071777,
      "rewards/rejected": -8.87606143951416,
      "step": 16910
    },
    {
      "epoch": 3.087872981111415,
      "grad_norm": 4.16818380355835,
      "learning_rate": 3.078436410350523e-05,
      "logits/chosen": -0.6453794836997986,
      "logits/rejected": -0.37326186895370483,
      "logps/chosen": -174.82884216308594,
      "logps/rejected": -204.41012573242188,
      "loss": 0.1728,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -3.6910624504089355,
      "rewards/margins": 4.764712333679199,
      "rewards/rejected": -8.455774307250977,
      "step": 16920
    },
    {
      "epoch": 3.089697965142805,
      "grad_norm": 1.3995248079299927,
      "learning_rate": 3.075500091759956e-05,
      "logits/chosen": -0.49792733788490295,
      "logits/rejected": -0.2275431901216507,
      "logps/chosen": -173.64146423339844,
      "logps/rejected": -217.3262939453125,
      "loss": 0.1529,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.359032154083252,
      "rewards/margins": 4.850050449371338,
      "rewards/rejected": -9.209081649780273,
      "step": 16930
    },
    {
      "epoch": 3.0915229491741947,
      "grad_norm": 7.006243705749512,
      "learning_rate": 3.072563773169389e-05,
      "logits/chosen": -0.5184756517410278,
      "logits/rejected": -0.14429064095020294,
      "logps/chosen": -185.55679321289062,
      "logps/rejected": -212.9180450439453,
      "loss": 0.1359,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -4.91335391998291,
      "rewards/margins": 4.831743240356445,
      "rewards/rejected": -9.745096206665039,
      "step": 16940
    },
    {
      "epoch": 3.0933479332055844,
      "grad_norm": 10.243049621582031,
      "learning_rate": 3.069627454578822e-05,
      "logits/chosen": -0.47059687972068787,
      "logits/rejected": -0.18799814581871033,
      "logps/chosen": -186.1943817138672,
      "logps/rejected": -223.2530517578125,
      "loss": 0.1389,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.836302757263184,
      "rewards/margins": 4.644197940826416,
      "rewards/rejected": -9.480500221252441,
      "step": 16950
    },
    {
      "epoch": 3.095172917236974,
      "grad_norm": 17.465072631835938,
      "learning_rate": 3.0666911359882554e-05,
      "logits/chosen": -0.552623987197876,
      "logits/rejected": -0.19891081750392914,
      "logps/chosen": -190.68038940429688,
      "logps/rejected": -206.3488006591797,
      "loss": 0.1136,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.533749580383301,
      "rewards/margins": 4.340307712554932,
      "rewards/rejected": -8.874056816101074,
      "step": 16960
    },
    {
      "epoch": 3.096997901268364,
      "grad_norm": 1.3830593824386597,
      "learning_rate": 3.063754817397688e-05,
      "logits/chosen": -0.29921260476112366,
      "logits/rejected": 0.0085141621530056,
      "logps/chosen": -186.4562530517578,
      "logps/rejected": -217.3415069580078,
      "loss": 0.2172,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -4.976127624511719,
      "rewards/margins": 4.513818264007568,
      "rewards/rejected": -9.489945411682129,
      "step": 16970
    },
    {
      "epoch": 3.0988228852997537,
      "grad_norm": 2.0907533168792725,
      "learning_rate": 3.060818498807121e-05,
      "logits/chosen": -0.5944700837135315,
      "logits/rejected": -0.14577502012252808,
      "logps/chosen": -211.5796661376953,
      "logps/rejected": -216.51254272460938,
      "loss": 0.1191,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.9556355476379395,
      "rewards/margins": 4.512423992156982,
      "rewards/rejected": -9.468058586120605,
      "step": 16980
    },
    {
      "epoch": 3.1006478693311434,
      "grad_norm": 3.4103848934173584,
      "learning_rate": 3.0578821802165534e-05,
      "logits/chosen": -0.5383251309394836,
      "logits/rejected": -0.2877541184425354,
      "logps/chosen": -181.27886962890625,
      "logps/rejected": -214.8009033203125,
      "loss": 0.1801,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.859182834625244,
      "rewards/margins": 4.201876163482666,
      "rewards/rejected": -8.06105899810791,
      "step": 16990
    },
    {
      "epoch": 3.102472853362533,
      "grad_norm": 3.036856174468994,
      "learning_rate": 3.0549458616259866e-05,
      "logits/chosen": -0.6531162261962891,
      "logits/rejected": -0.3866141438484192,
      "logps/chosen": -177.2893524169922,
      "logps/rejected": -214.962890625,
      "loss": 0.1022,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -3.8125243186950684,
      "rewards/margins": 4.853907585144043,
      "rewards/rejected": -8.666430473327637,
      "step": 17000
    },
    {
      "epoch": 3.104297837393923,
      "grad_norm": 4.685115814208984,
      "learning_rate": 3.05200954303542e-05,
      "logits/chosen": -0.6375446319580078,
      "logits/rejected": -0.32180967926979065,
      "logps/chosen": -214.5108184814453,
      "logps/rejected": -221.49630737304688,
      "loss": 0.1169,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.073761940002441,
      "rewards/margins": 4.097988605499268,
      "rewards/rejected": -8.171751022338867,
      "step": 17010
    },
    {
      "epoch": 3.1061228214253127,
      "grad_norm": 13.331581115722656,
      "learning_rate": 3.0490732244448525e-05,
      "logits/chosen": -0.3749110996723175,
      "logits/rejected": -0.03572282940149307,
      "logps/chosen": -197.9077606201172,
      "logps/rejected": -206.8297119140625,
      "loss": 0.1451,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.84518575668335,
      "rewards/margins": 4.547714710235596,
      "rewards/rejected": -9.392900466918945,
      "step": 17020
    },
    {
      "epoch": 3.1079478054567025,
      "grad_norm": 12.430644989013672,
      "learning_rate": 3.0461369058542853e-05,
      "logits/chosen": -0.6123588681221008,
      "logits/rejected": -0.39763370156288147,
      "logps/chosen": -187.23504638671875,
      "logps/rejected": -219.4388885498047,
      "loss": 0.1192,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.8134307861328125,
      "rewards/margins": 4.249372959136963,
      "rewards/rejected": -9.062803268432617,
      "step": 17030
    },
    {
      "epoch": 3.1097727894880918,
      "grad_norm": 4.421428203582764,
      "learning_rate": 3.0432005872637184e-05,
      "logits/chosen": -0.4323264956474304,
      "logits/rejected": -0.18875519931316376,
      "logps/chosen": -176.9969940185547,
      "logps/rejected": -230.76626586914062,
      "loss": 0.1217,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.022987365722656,
      "rewards/margins": 5.411101341247559,
      "rewards/rejected": -10.434088706970215,
      "step": 17040
    },
    {
      "epoch": 3.1115977735194815,
      "grad_norm": 1.3096100091934204,
      "learning_rate": 3.0402642686731512e-05,
      "logits/chosen": -0.4392961859703064,
      "logits/rejected": -0.13288606703281403,
      "logps/chosen": -196.25418090820312,
      "logps/rejected": -216.5753173828125,
      "loss": 0.1285,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.394285678863525,
      "rewards/margins": 4.828225612640381,
      "rewards/rejected": -9.22251033782959,
      "step": 17050
    },
    {
      "epoch": 3.1134227575508713,
      "grad_norm": 6.4346466064453125,
      "learning_rate": 3.0373279500825844e-05,
      "logits/chosen": -0.3050474524497986,
      "logits/rejected": 0.14307516813278198,
      "logps/chosen": -200.1657257080078,
      "logps/rejected": -222.51022338867188,
      "loss": 0.1841,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.863945960998535,
      "rewards/margins": 4.664065361022949,
      "rewards/rejected": -10.528009414672852,
      "step": 17060
    },
    {
      "epoch": 3.115247741582261,
      "grad_norm": 2.896226644515991,
      "learning_rate": 3.034391631492017e-05,
      "logits/chosen": -0.3101200461387634,
      "logits/rejected": 0.07745984941720963,
      "logps/chosen": -205.90292358398438,
      "logps/rejected": -233.21902465820312,
      "loss": 0.1903,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.7256903648376465,
      "rewards/margins": 4.741822719573975,
      "rewards/rejected": -10.467512130737305,
      "step": 17070
    },
    {
      "epoch": 3.117072725613651,
      "grad_norm": 25.30845069885254,
      "learning_rate": 3.0314553129014503e-05,
      "logits/chosen": -0.212181955575943,
      "logits/rejected": -0.1364286094903946,
      "logps/chosen": -183.8348388671875,
      "logps/rejected": -243.13455200195312,
      "loss": 0.1745,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.229340553283691,
      "rewards/margins": 4.65707540512085,
      "rewards/rejected": -9.886415481567383,
      "step": 17080
    },
    {
      "epoch": 3.1188977096450405,
      "grad_norm": 2.075713634490967,
      "learning_rate": 3.0285189943108827e-05,
      "logits/chosen": -0.23439288139343262,
      "logits/rejected": 0.05428101867437363,
      "logps/chosen": -180.765625,
      "logps/rejected": -224.77798461914062,
      "loss": 0.194,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.582310199737549,
      "rewards/margins": 4.608449935913086,
      "rewards/rejected": -9.190759658813477,
      "step": 17090
    },
    {
      "epoch": 3.1207226936764303,
      "grad_norm": 7.46145486831665,
      "learning_rate": 3.025582675720316e-05,
      "logits/chosen": -0.5817470550537109,
      "logits/rejected": -0.18433302640914917,
      "logps/chosen": -213.21511840820312,
      "logps/rejected": -238.1669158935547,
      "loss": 0.0931,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -4.96713924407959,
      "rewards/margins": 4.902472496032715,
      "rewards/rejected": -9.869612693786621,
      "step": 17100
    },
    {
      "epoch": 3.12254767770782,
      "grad_norm": 1.5294499397277832,
      "learning_rate": 3.0226463571297487e-05,
      "logits/chosen": -0.42102041840553284,
      "logits/rejected": -0.0317549929022789,
      "logps/chosen": -199.0827178955078,
      "logps/rejected": -221.94662475585938,
      "loss": 0.1332,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.040373802185059,
      "rewards/margins": 4.773798942565918,
      "rewards/rejected": -9.814172744750977,
      "step": 17110
    },
    {
      "epoch": 3.12437266173921,
      "grad_norm": 9.710935592651367,
      "learning_rate": 3.0197100385391818e-05,
      "logits/chosen": -0.31221553683280945,
      "logits/rejected": -0.08397485315799713,
      "logps/chosen": -204.0142059326172,
      "logps/rejected": -233.7981414794922,
      "loss": 0.1673,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.771180152893066,
      "rewards/margins": 4.553144931793213,
      "rewards/rejected": -10.324323654174805,
      "step": 17120
    },
    {
      "epoch": 3.1261976457705996,
      "grad_norm": 1.490918755531311,
      "learning_rate": 3.0167737199486146e-05,
      "logits/chosen": -0.4700245261192322,
      "logits/rejected": -0.09398851543664932,
      "logps/chosen": -214.0439910888672,
      "logps/rejected": -225.791259765625,
      "loss": 0.1664,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.4498701095581055,
      "rewards/margins": 4.046616554260254,
      "rewards/rejected": -9.496485710144043,
      "step": 17130
    },
    {
      "epoch": 3.1280226298019893,
      "grad_norm": 16.568307876586914,
      "learning_rate": 3.0138374013580477e-05,
      "logits/chosen": -0.40852802991867065,
      "logits/rejected": -0.021035226061940193,
      "logps/chosen": -215.9951629638672,
      "logps/rejected": -237.6914520263672,
      "loss": 0.1821,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.527625560760498,
      "rewards/margins": 4.907545566558838,
      "rewards/rejected": -10.43517017364502,
      "step": 17140
    },
    {
      "epoch": 3.129847613833379,
      "grad_norm": 1.3550972938537598,
      "learning_rate": 3.010901082767481e-05,
      "logits/chosen": -0.30491259694099426,
      "logits/rejected": 0.14078499376773834,
      "logps/chosen": -207.86648559570312,
      "logps/rejected": -218.4933624267578,
      "loss": 0.1784,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.4445695877075195,
      "rewards/margins": 4.741472244262695,
      "rewards/rejected": -10.186040878295898,
      "step": 17150
    },
    {
      "epoch": 3.131672597864769,
      "grad_norm": 4.800439834594727,
      "learning_rate": 3.0079647641769133e-05,
      "logits/chosen": -0.3289267420768738,
      "logits/rejected": 0.008767420426011086,
      "logps/chosen": -188.58509826660156,
      "logps/rejected": -216.3157501220703,
      "loss": 0.1114,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.3769025802612305,
      "rewards/margins": 4.1858320236206055,
      "rewards/rejected": -9.562734603881836,
      "step": 17160
    },
    {
      "epoch": 3.1334975818961586,
      "grad_norm": 0.929840087890625,
      "learning_rate": 3.0050284455863465e-05,
      "logits/chosen": -0.166152685880661,
      "logits/rejected": 0.12906032800674438,
      "logps/chosen": -191.1592559814453,
      "logps/rejected": -221.6429901123047,
      "loss": 0.1764,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.179952144622803,
      "rewards/margins": 4.131739616394043,
      "rewards/rejected": -9.31169319152832,
      "step": 17170
    },
    {
      "epoch": 3.1353225659275483,
      "grad_norm": 1.254522442817688,
      "learning_rate": 3.0020921269957793e-05,
      "logits/chosen": -0.2553321123123169,
      "logits/rejected": 0.17165058851242065,
      "logps/chosen": -186.72433471679688,
      "logps/rejected": -225.4809112548828,
      "loss": 0.1423,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.245960235595703,
      "rewards/margins": 4.494535446166992,
      "rewards/rejected": -9.740495681762695,
      "step": 17180
    },
    {
      "epoch": 3.1371475499589376,
      "grad_norm": 1.7392429113388062,
      "learning_rate": 2.9991558084052124e-05,
      "logits/chosen": -0.2617655098438263,
      "logits/rejected": -0.06587264686822891,
      "logps/chosen": -207.72628784179688,
      "logps/rejected": -230.94406127929688,
      "loss": 0.2208,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.940337181091309,
      "rewards/margins": 4.458927631378174,
      "rewards/rejected": -9.399264335632324,
      "step": 17190
    },
    {
      "epoch": 3.1389725339903274,
      "grad_norm": 1.6192213296890259,
      "learning_rate": 2.9962194898146452e-05,
      "logits/chosen": -0.06943046301603317,
      "logits/rejected": 0.24887053668498993,
      "logps/chosen": -191.21456909179688,
      "logps/rejected": -220.4254608154297,
      "loss": 0.196,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.298534393310547,
      "rewards/margins": 4.236048221588135,
      "rewards/rejected": -9.534582138061523,
      "step": 17200
    },
    {
      "epoch": 3.140797518021717,
      "grad_norm": 15.392295837402344,
      "learning_rate": 2.9932831712240783e-05,
      "logits/chosen": -0.26213401556015015,
      "logits/rejected": 0.05561230704188347,
      "logps/chosen": -199.89215087890625,
      "logps/rejected": -219.5740509033203,
      "loss": 0.2413,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -4.895089149475098,
      "rewards/margins": 4.1711249351501465,
      "rewards/rejected": -9.066214561462402,
      "step": 17210
    },
    {
      "epoch": 3.142622502053107,
      "grad_norm": 7.951484203338623,
      "learning_rate": 2.9903468526335108e-05,
      "logits/chosen": -0.20625922083854675,
      "logits/rejected": 0.11229046434164047,
      "logps/chosen": -203.54139709472656,
      "logps/rejected": -222.97396850585938,
      "loss": 0.1563,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.434985160827637,
      "rewards/margins": 4.406315803527832,
      "rewards/rejected": -9.841300010681152,
      "step": 17220
    },
    {
      "epoch": 3.1444474860844966,
      "grad_norm": 7.889857292175293,
      "learning_rate": 2.987410534042944e-05,
      "logits/chosen": -0.3857404589653015,
      "logits/rejected": -0.05354757234454155,
      "logps/chosen": -214.9792938232422,
      "logps/rejected": -218.7296905517578,
      "loss": 0.2615,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.243719100952148,
      "rewards/margins": 3.682330369949341,
      "rewards/rejected": -8.92604923248291,
      "step": 17230
    },
    {
      "epoch": 3.1462724701158864,
      "grad_norm": 3.3882882595062256,
      "learning_rate": 2.9844742154523767e-05,
      "logits/chosen": -0.18321493268013,
      "logits/rejected": 0.05713190510869026,
      "logps/chosen": -197.15451049804688,
      "logps/rejected": -229.2232208251953,
      "loss": 0.1506,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.289522647857666,
      "rewards/margins": 4.3113579750061035,
      "rewards/rejected": -9.60088062286377,
      "step": 17240
    },
    {
      "epoch": 3.148097454147276,
      "grad_norm": 7.673327922821045,
      "learning_rate": 2.98153789686181e-05,
      "logits/chosen": -0.19114461541175842,
      "logits/rejected": 0.15742750465869904,
      "logps/chosen": -205.77438354492188,
      "logps/rejected": -221.26828002929688,
      "loss": 0.1693,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.038023471832275,
      "rewards/margins": 4.028273105621338,
      "rewards/rejected": -10.066296577453613,
      "step": 17250
    },
    {
      "epoch": 3.149922438178666,
      "grad_norm": 6.898613452911377,
      "learning_rate": 2.9786015782712426e-05,
      "logits/chosen": -0.3857347071170807,
      "logits/rejected": 0.016828591004014015,
      "logps/chosen": -195.0769500732422,
      "logps/rejected": -227.90249633789062,
      "loss": 0.1373,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.115242958068848,
      "rewards/margins": 4.634536266326904,
      "rewards/rejected": -9.74977970123291,
      "step": 17260
    },
    {
      "epoch": 3.1517474222100557,
      "grad_norm": 12.095157623291016,
      "learning_rate": 2.9756652596806758e-05,
      "logits/chosen": -0.31904932856559753,
      "logits/rejected": -0.11557050794363022,
      "logps/chosen": -191.98854064941406,
      "logps/rejected": -212.8745574951172,
      "loss": 0.2844,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.09487771987915,
      "rewards/margins": 3.5067527294158936,
      "rewards/rejected": -8.601630210876465,
      "step": 17270
    },
    {
      "epoch": 3.1535724062414454,
      "grad_norm": 0.584804117679596,
      "learning_rate": 2.9727289410901082e-05,
      "logits/chosen": -0.42049869894981384,
      "logits/rejected": -0.022000575438141823,
      "logps/chosen": -198.49923706054688,
      "logps/rejected": -231.6421661376953,
      "loss": 0.0847,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -4.788404941558838,
      "rewards/margins": 4.855305194854736,
      "rewards/rejected": -9.643710136413574,
      "step": 17280
    },
    {
      "epoch": 3.155397390272835,
      "grad_norm": 3.9903573989868164,
      "learning_rate": 2.9697926224995414e-05,
      "logits/chosen": -0.3914095461368561,
      "logits/rejected": 0.04580625146627426,
      "logps/chosen": -204.25961303710938,
      "logps/rejected": -224.3662109375,
      "loss": 0.1023,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.154187202453613,
      "rewards/margins": 4.427520751953125,
      "rewards/rejected": -9.581707954406738,
      "step": 17290
    },
    {
      "epoch": 3.157222374304225,
      "grad_norm": 7.702049732208252,
      "learning_rate": 2.9668563039089742e-05,
      "logits/chosen": -0.4020003378391266,
      "logits/rejected": 0.05549636483192444,
      "logps/chosen": -211.33547973632812,
      "logps/rejected": -221.6735076904297,
      "loss": 0.0878,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.834347724914551,
      "rewards/margins": 4.818581581115723,
      "rewards/rejected": -9.652929306030273,
      "step": 17300
    },
    {
      "epoch": 3.1590473583356147,
      "grad_norm": 6.247766017913818,
      "learning_rate": 2.9639199853184073e-05,
      "logits/chosen": -0.32120904326438904,
      "logits/rejected": 0.20849700272083282,
      "logps/chosen": -199.1928253173828,
      "logps/rejected": -219.772705078125,
      "loss": 0.1123,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.781520366668701,
      "rewards/margins": 5.3025336265563965,
      "rewards/rejected": -10.084053993225098,
      "step": 17310
    },
    {
      "epoch": 3.1608723423670044,
      "grad_norm": 6.45815896987915,
      "learning_rate": 2.9609836667278404e-05,
      "logits/chosen": -0.37045207619667053,
      "logits/rejected": -0.17836478352546692,
      "logps/chosen": -196.79159545898438,
      "logps/rejected": -228.0633087158203,
      "loss": 0.2676,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.791650295257568,
      "rewards/margins": 4.115764141082764,
      "rewards/rejected": -8.907414436340332,
      "step": 17320
    },
    {
      "epoch": 3.162697326398394,
      "grad_norm": 2.758801221847534,
      "learning_rate": 2.9580473481372732e-05,
      "logits/chosen": -0.35917678475379944,
      "logits/rejected": 0.08503707498311996,
      "logps/chosen": -190.64004516601562,
      "logps/rejected": -204.71359252929688,
      "loss": 0.0959,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.110012531280518,
      "rewards/margins": 4.859368324279785,
      "rewards/rejected": -8.969381332397461,
      "step": 17330
    },
    {
      "epoch": 3.164522310429784,
      "grad_norm": 7.107012748718262,
      "learning_rate": 2.955404661405763e-05,
      "logits/chosen": -0.3808742165565491,
      "logits/rejected": -0.07777740061283112,
      "logps/chosen": -199.46926879882812,
      "logps/rejected": -215.8406524658203,
      "loss": 0.1475,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.7600836753845215,
      "rewards/margins": 4.562743186950684,
      "rewards/rejected": -8.322826385498047,
      "step": 17340
    },
    {
      "epoch": 3.1663472944611737,
      "grad_norm": 0.6250472068786621,
      "learning_rate": 2.9524683428151955e-05,
      "logits/chosen": -0.4011909067630768,
      "logits/rejected": -0.2852408289909363,
      "logps/chosen": -181.38510131835938,
      "logps/rejected": -222.6818389892578,
      "loss": 0.1732,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.2570695877075195,
      "rewards/margins": 4.7242431640625,
      "rewards/rejected": -8.98131275177002,
      "step": 17350
    },
    {
      "epoch": 3.168172278492563,
      "grad_norm": 13.80447769165039,
      "learning_rate": 2.9495320242246287e-05,
      "logits/chosen": -0.2990894019603729,
      "logits/rejected": -0.010831005871295929,
      "logps/chosen": -178.3885955810547,
      "logps/rejected": -208.4792022705078,
      "loss": 0.1549,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.263853549957275,
      "rewards/margins": 4.783544540405273,
      "rewards/rejected": -9.047399520874023,
      "step": 17360
    },
    {
      "epoch": 3.1699972625239528,
      "grad_norm": 3.7988955974578857,
      "learning_rate": 2.9465957056340614e-05,
      "logits/chosen": -0.49275436997413635,
      "logits/rejected": -0.2575361728668213,
      "logps/chosen": -187.63009643554688,
      "logps/rejected": -222.8142852783203,
      "loss": 0.2088,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -4.232905864715576,
      "rewards/margins": 4.685410976409912,
      "rewards/rejected": -8.918316841125488,
      "step": 17370
    },
    {
      "epoch": 3.1718222465553425,
      "grad_norm": 11.173262596130371,
      "learning_rate": 2.9436593870434946e-05,
      "logits/chosen": -0.5084381103515625,
      "logits/rejected": -0.30069953203201294,
      "logps/chosen": -175.20790100097656,
      "logps/rejected": -199.8577117919922,
      "loss": 0.2513,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.819826602935791,
      "rewards/margins": 4.529599189758301,
      "rewards/rejected": -7.349425315856934,
      "step": 17380
    },
    {
      "epoch": 3.1736472305867323,
      "grad_norm": 4.360289573669434,
      "learning_rate": 2.9407230684529274e-05,
      "logits/chosen": -0.540627121925354,
      "logits/rejected": -0.14300446212291718,
      "logps/chosen": -195.3014373779297,
      "logps/rejected": -208.2875213623047,
      "loss": 0.0794,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.578582286834717,
      "rewards/margins": 4.489656448364258,
      "rewards/rejected": -8.068239212036133,
      "step": 17390
    },
    {
      "epoch": 3.175472214618122,
      "grad_norm": 4.8927812576293945,
      "learning_rate": 2.9377867498623605e-05,
      "logits/chosen": -0.20088143646717072,
      "logits/rejected": 0.06624472141265869,
      "logps/chosen": -182.2626190185547,
      "logps/rejected": -209.21200561523438,
      "loss": 0.1567,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.769842147827148,
      "rewards/margins": 4.2727437019348145,
      "rewards/rejected": -9.042585372924805,
      "step": 17400
    },
    {
      "epoch": 3.1772971986495118,
      "grad_norm": 20.70404052734375,
      "learning_rate": 2.9348504312717933e-05,
      "logits/chosen": -0.20103256404399872,
      "logits/rejected": 0.2435626983642578,
      "logps/chosen": -203.06973266601562,
      "logps/rejected": -223.1708221435547,
      "loss": 0.1151,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.770716190338135,
      "rewards/margins": 5.168862342834473,
      "rewards/rejected": -9.939577102661133,
      "step": 17410
    },
    {
      "epoch": 3.1791221826809015,
      "grad_norm": 18.027484893798828,
      "learning_rate": 2.931914112681226e-05,
      "logits/chosen": -0.2806362211704254,
      "logits/rejected": 0.061372388154268265,
      "logps/chosen": -181.9567108154297,
      "logps/rejected": -209.6289520263672,
      "loss": 0.3714,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.549521446228027,
      "rewards/margins": 4.053936958312988,
      "rewards/rejected": -8.603458404541016,
      "step": 17420
    },
    {
      "epoch": 3.1809471667122913,
      "grad_norm": 4.294229984283447,
      "learning_rate": 2.928977794090659e-05,
      "logits/chosen": -0.1574377417564392,
      "logits/rejected": 0.13358551263809204,
      "logps/chosen": -189.1767120361328,
      "logps/rejected": -226.5652313232422,
      "loss": 0.1736,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.882107734680176,
      "rewards/margins": 4.171420097351074,
      "rewards/rejected": -9.05352783203125,
      "step": 17430
    },
    {
      "epoch": 3.182772150743681,
      "grad_norm": 11.059577941894531,
      "learning_rate": 2.926041475500092e-05,
      "logits/chosen": -0.25031188130378723,
      "logits/rejected": 0.13862869143486023,
      "logps/chosen": -195.6614227294922,
      "logps/rejected": -221.8040771484375,
      "loss": 0.1398,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.960352420806885,
      "rewards/margins": 4.21765661239624,
      "rewards/rejected": -9.178009033203125,
      "step": 17440
    },
    {
      "epoch": 3.184597134775071,
      "grad_norm": 1.9371271133422852,
      "learning_rate": 2.923105156909525e-05,
      "logits/chosen": -0.13633319735527039,
      "logits/rejected": 0.30064257979393005,
      "logps/chosen": -211.9171142578125,
      "logps/rejected": -229.27603149414062,
      "loss": 0.1628,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.203578948974609,
      "rewards/margins": 3.9381661415100098,
      "rewards/rejected": -10.141745567321777,
      "step": 17450
    },
    {
      "epoch": 3.1864221188064605,
      "grad_norm": 3.6687190532684326,
      "learning_rate": 2.920168838318958e-05,
      "logits/chosen": 0.05222328379750252,
      "logits/rejected": 0.46604758501052856,
      "logps/chosen": -197.89315795898438,
      "logps/rejected": -231.3361358642578,
      "loss": 0.0654,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.561991214752197,
      "rewards/margins": 4.8017897605896,
      "rewards/rejected": -10.363779067993164,
      "step": 17460
    },
    {
      "epoch": 3.1882471028378503,
      "grad_norm": 8.860572814941406,
      "learning_rate": 2.9172325197283908e-05,
      "logits/chosen": 0.18985091149806976,
      "logits/rejected": 0.42647799849510193,
      "logps/chosen": -193.3820343017578,
      "logps/rejected": -243.6956787109375,
      "loss": 0.1019,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.182126522064209,
      "rewards/margins": 5.337407112121582,
      "rewards/rejected": -11.51953411102295,
      "step": 17470
    },
    {
      "epoch": 3.19007208686924,
      "grad_norm": 19.412336349487305,
      "learning_rate": 2.914296201137824e-05,
      "logits/chosen": 0.01034003496170044,
      "logits/rejected": 0.3197009265422821,
      "logps/chosen": -202.65213012695312,
      "logps/rejected": -237.8175506591797,
      "loss": 0.2436,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.4452667236328125,
      "rewards/margins": 4.445229530334473,
      "rewards/rejected": -10.890497207641602,
      "step": 17480
    },
    {
      "epoch": 3.19189707090063,
      "grad_norm": 7.1251702308654785,
      "learning_rate": 2.9113598825472564e-05,
      "logits/chosen": -0.2420540601015091,
      "logits/rejected": 0.22829362750053406,
      "logps/chosen": -203.12722778320312,
      "logps/rejected": -227.90274047851562,
      "loss": 0.1442,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.073742866516113,
      "rewards/margins": 4.610641956329346,
      "rewards/rejected": -10.6843843460083,
      "step": 17490
    },
    {
      "epoch": 3.1937220549320195,
      "grad_norm": 6.131341934204102,
      "learning_rate": 2.9084235639566895e-05,
      "logits/chosen": -0.18964800238609314,
      "logits/rejected": 0.21709425747394562,
      "logps/chosen": -203.20791625976562,
      "logps/rejected": -213.47512817382812,
      "loss": 0.1653,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.486058712005615,
      "rewards/margins": 4.199940204620361,
      "rewards/rejected": -9.685998916625977,
      "step": 17500
    },
    {
      "epoch": 3.195547038963409,
      "grad_norm": 11.239267349243164,
      "learning_rate": 2.9054872453661223e-05,
      "logits/chosen": -0.23033523559570312,
      "logits/rejected": 0.08868966996669769,
      "logps/chosen": -179.71157836914062,
      "logps/rejected": -212.7174072265625,
      "loss": 0.1266,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.785763740539551,
      "rewards/margins": 4.591080665588379,
      "rewards/rejected": -9.376843452453613,
      "step": 17510
    },
    {
      "epoch": 3.1973720229947986,
      "grad_norm": 3.353663206100464,
      "learning_rate": 2.9025509267755554e-05,
      "logits/chosen": -0.27549952268600464,
      "logits/rejected": -0.05143950134515762,
      "logps/chosen": -196.3672332763672,
      "logps/rejected": -223.099365234375,
      "loss": 0.2152,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.426083087921143,
      "rewards/margins": 3.9382987022399902,
      "rewards/rejected": -9.364381790161133,
      "step": 17520
    },
    {
      "epoch": 3.1991970070261884,
      "grad_norm": 0.9946047067642212,
      "learning_rate": 2.8996146081849886e-05,
      "logits/chosen": -0.3722569942474365,
      "logits/rejected": -0.06882298737764359,
      "logps/chosen": -192.11380004882812,
      "logps/rejected": -214.9836883544922,
      "loss": 0.1363,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.872286796569824,
      "rewards/margins": 4.275186538696289,
      "rewards/rejected": -9.147473335266113,
      "step": 17530
    },
    {
      "epoch": 3.201021991057578,
      "grad_norm": 8.601444244384766,
      "learning_rate": 2.8966782895944214e-05,
      "logits/chosen": -0.2566802501678467,
      "logits/rejected": -0.04056983441114426,
      "logps/chosen": -204.63333129882812,
      "logps/rejected": -233.6370849609375,
      "loss": 0.143,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.4194769859313965,
      "rewards/margins": 4.293736457824707,
      "rewards/rejected": -9.713213920593262,
      "step": 17540
    },
    {
      "epoch": 3.202846975088968,
      "grad_norm": 4.335456371307373,
      "learning_rate": 2.8937419710038545e-05,
      "logits/chosen": -0.11677245050668716,
      "logits/rejected": -0.09309393912553787,
      "logps/chosen": -188.59329223632812,
      "logps/rejected": -241.59512329101562,
      "loss": 0.2093,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.1717047691345215,
      "rewards/margins": 4.666599750518799,
      "rewards/rejected": -9.83830451965332,
      "step": 17550
    },
    {
      "epoch": 3.2046719591203576,
      "grad_norm": 22.566089630126953,
      "learning_rate": 2.890805652413287e-05,
      "logits/chosen": -0.2940768897533417,
      "logits/rejected": 0.003387969685718417,
      "logps/chosen": -197.4901885986328,
      "logps/rejected": -228.76815795898438,
      "loss": 0.1504,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.088931560516357,
      "rewards/margins": 4.425667762756348,
      "rewards/rejected": -9.514598846435547,
      "step": 17560
    },
    {
      "epoch": 3.2064969431517474,
      "grad_norm": 0.36737385392189026,
      "learning_rate": 2.88786933382272e-05,
      "logits/chosen": -0.3395700752735138,
      "logits/rejected": -0.06341488659381866,
      "logps/chosen": -198.04287719726562,
      "logps/rejected": -230.4314727783203,
      "loss": 0.0821,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.087527275085449,
      "rewards/margins": 5.0995283126831055,
      "rewards/rejected": -10.187054634094238,
      "step": 17570
    },
    {
      "epoch": 3.208321927183137,
      "grad_norm": 8.31319522857666,
      "learning_rate": 2.884933015232153e-05,
      "logits/chosen": -0.14334987103939056,
      "logits/rejected": 0.20041632652282715,
      "logps/chosen": -189.09909057617188,
      "logps/rejected": -217.48873901367188,
      "loss": 0.1942,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.43781852722168,
      "rewards/margins": 4.50506067276001,
      "rewards/rejected": -8.942879676818848,
      "step": 17580
    },
    {
      "epoch": 3.210146911214527,
      "grad_norm": 7.636106014251709,
      "learning_rate": 2.881996696641586e-05,
      "logits/chosen": -0.23869343101978302,
      "logits/rejected": -0.006555111147463322,
      "logps/chosen": -200.21456909179688,
      "logps/rejected": -249.64987182617188,
      "loss": 0.1007,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.102110862731934,
      "rewards/margins": 4.791538238525391,
      "rewards/rejected": -10.893649101257324,
      "step": 17590
    },
    {
      "epoch": 3.2119718952459166,
      "grad_norm": 6.9217658042907715,
      "learning_rate": 2.8790603780510188e-05,
      "logits/chosen": -0.5589741468429565,
      "logits/rejected": -0.19325438141822815,
      "logps/chosen": -200.8470458984375,
      "logps/rejected": -221.00015258789062,
      "loss": 0.1375,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.564389228820801,
      "rewards/margins": 4.5236334800720215,
      "rewards/rejected": -9.088022232055664,
      "step": 17600
    },
    {
      "epoch": 3.2137968792773064,
      "grad_norm": 6.364036560058594,
      "learning_rate": 2.876124059460452e-05,
      "logits/chosen": -0.1358056515455246,
      "logits/rejected": 0.14080758392810822,
      "logps/chosen": -188.73448181152344,
      "logps/rejected": -232.49716186523438,
      "loss": 0.1007,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.09916353225708,
      "rewards/margins": 5.217564105987549,
      "rewards/rejected": -10.316726684570312,
      "step": 17610
    },
    {
      "epoch": 3.215621863308696,
      "grad_norm": 11.313512802124023,
      "learning_rate": 2.8731877408698844e-05,
      "logits/chosen": -0.21899065375328064,
      "logits/rejected": 0.0955624207854271,
      "logps/chosen": -200.42909240722656,
      "logps/rejected": -233.82864379882812,
      "loss": 0.1647,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.772177219390869,
      "rewards/margins": 4.299635887145996,
      "rewards/rejected": -10.071813583374023,
      "step": 17620
    },
    {
      "epoch": 3.217446847340086,
      "grad_norm": 2.733915328979492,
      "learning_rate": 2.8702514222793175e-05,
      "logits/chosen": -0.1907842457294464,
      "logits/rejected": -0.13276329636573792,
      "logps/chosen": -187.4790802001953,
      "logps/rejected": -241.7869873046875,
      "loss": 0.0982,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.805734634399414,
      "rewards/margins": 4.886903762817383,
      "rewards/rejected": -9.692638397216797,
      "step": 17630
    },
    {
      "epoch": 3.2192718313714757,
      "grad_norm": 3.8141374588012695,
      "learning_rate": 2.8673151036887503e-05,
      "logits/chosen": -0.34306830167770386,
      "logits/rejected": 0.018015244975686073,
      "logps/chosen": -202.3992462158203,
      "logps/rejected": -231.379150390625,
      "loss": 0.0994,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.161454677581787,
      "rewards/margins": 4.753650188446045,
      "rewards/rejected": -9.915104866027832,
      "step": 17640
    },
    {
      "epoch": 3.2210968154028654,
      "grad_norm": 0.6263854503631592,
      "learning_rate": 2.8643787850981835e-05,
      "logits/chosen": -0.1886436641216278,
      "logits/rejected": 0.2432776391506195,
      "logps/chosen": -204.57431030273438,
      "logps/rejected": -230.5129852294922,
      "loss": 0.1526,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.188533306121826,
      "rewards/margins": 4.824555397033691,
      "rewards/rejected": -10.013087272644043,
      "step": 17650
    },
    {
      "epoch": 3.222921799434255,
      "grad_norm": 6.0030670166015625,
      "learning_rate": 2.8614424665076163e-05,
      "logits/chosen": -0.20865169167518616,
      "logits/rejected": 0.16363708674907684,
      "logps/chosen": -205.31314086914062,
      "logps/rejected": -220.2073516845703,
      "loss": 0.1579,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.633061408996582,
      "rewards/margins": 4.496151924133301,
      "rewards/rejected": -10.129213333129883,
      "step": 17660
    },
    {
      "epoch": 3.2247467834656445,
      "grad_norm": 0.6723540425300598,
      "learning_rate": 2.8585061479170494e-05,
      "logits/chosen": -0.37717723846435547,
      "logits/rejected": 8.3328784967307e-05,
      "logps/chosen": -198.62989807128906,
      "logps/rejected": -213.79776000976562,
      "loss": 0.2278,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.272810459136963,
      "rewards/margins": 4.508022308349609,
      "rewards/rejected": -8.78083324432373,
      "step": 17670
    },
    {
      "epoch": 3.2265717674970342,
      "grad_norm": 3.286961317062378,
      "learning_rate": 2.855569829326482e-05,
      "logits/chosen": -0.3956035077571869,
      "logits/rejected": 0.2298908233642578,
      "logps/chosen": -203.60171508789062,
      "logps/rejected": -216.3964080810547,
      "loss": 0.069,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -4.430029392242432,
      "rewards/margins": 5.219485759735107,
      "rewards/rejected": -9.649514198303223,
      "step": 17680
    },
    {
      "epoch": 3.228396751528424,
      "grad_norm": 3.8585195541381836,
      "learning_rate": 2.852633510735915e-05,
      "logits/chosen": -0.11199130117893219,
      "logits/rejected": 0.12138732522726059,
      "logps/chosen": -186.51577758789062,
      "logps/rejected": -224.27597045898438,
      "loss": 0.2275,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.015532493591309,
      "rewards/margins": 4.509946823120117,
      "rewards/rejected": -9.525479316711426,
      "step": 17690
    },
    {
      "epoch": 3.2302217355598137,
      "grad_norm": 2.7136566638946533,
      "learning_rate": 2.8496971921453478e-05,
      "logits/chosen": -0.4313198924064636,
      "logits/rejected": -0.020561467856168747,
      "logps/chosen": -179.9338836669922,
      "logps/rejected": -216.6324920654297,
      "loss": 0.1334,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.648297309875488,
      "rewards/margins": 5.106412887573242,
      "rewards/rejected": -9.75471019744873,
      "step": 17700
    },
    {
      "epoch": 3.2320467195912035,
      "grad_norm": 2.2211155891418457,
      "learning_rate": 2.846760873554781e-05,
      "logits/chosen": -0.2897382378578186,
      "logits/rejected": -0.053694505244493484,
      "logps/chosen": -194.6748809814453,
      "logps/rejected": -218.09774780273438,
      "loss": 0.2242,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.061459064483643,
      "rewards/margins": 4.4201979637146,
      "rewards/rejected": -9.481657028198242,
      "step": 17710
    },
    {
      "epoch": 3.2338717036225932,
      "grad_norm": 3.991133451461792,
      "learning_rate": 2.843824554964214e-05,
      "logits/chosen": -0.3963882625102997,
      "logits/rejected": -0.21837778389453888,
      "logps/chosen": -221.9407501220703,
      "logps/rejected": -254.6539764404297,
      "loss": 0.1931,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.494736671447754,
      "rewards/margins": 5.2840142250061035,
      "rewards/rejected": -10.7787504196167,
      "step": 17720
    },
    {
      "epoch": 3.235696687653983,
      "grad_norm": 1.6413289308547974,
      "learning_rate": 2.840888236373647e-05,
      "logits/chosen": -0.3467410206794739,
      "logits/rejected": -0.05043929070234299,
      "logps/chosen": -186.35763549804688,
      "logps/rejected": -228.8469696044922,
      "loss": 0.1713,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.726661205291748,
      "rewards/margins": 4.950305461883545,
      "rewards/rejected": -9.676965713500977,
      "step": 17730
    },
    {
      "epoch": 3.2375216716853727,
      "grad_norm": 8.788470268249512,
      "learning_rate": 2.83795191778308e-05,
      "logits/chosen": -0.3726089894771576,
      "logits/rejected": -0.21955712139606476,
      "logps/chosen": -181.62979125976562,
      "logps/rejected": -230.30908203125,
      "loss": 0.21,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.754690170288086,
      "rewards/margins": 4.467474937438965,
      "rewards/rejected": -9.22216510772705,
      "step": 17740
    },
    {
      "epoch": 3.2393466557167625,
      "grad_norm": 1.7865742444992065,
      "learning_rate": 2.8350155991925124e-05,
      "logits/chosen": -0.29336270689964294,
      "logits/rejected": 0.11295153945684433,
      "logps/chosen": -183.57785034179688,
      "logps/rejected": -207.79336547851562,
      "loss": 0.1257,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.412213325500488,
      "rewards/margins": 4.547045707702637,
      "rewards/rejected": -8.959259033203125,
      "step": 17750
    },
    {
      "epoch": 3.2411716397481523,
      "grad_norm": 3.8543059825897217,
      "learning_rate": 2.8320792806019456e-05,
      "logits/chosen": -0.4290432333946228,
      "logits/rejected": -0.023311829194426537,
      "logps/chosen": -195.07241821289062,
      "logps/rejected": -219.9406280517578,
      "loss": 0.0998,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.69268798828125,
      "rewards/margins": 4.902728080749512,
      "rewards/rejected": -9.595415115356445,
      "step": 17760
    },
    {
      "epoch": 3.242996623779542,
      "grad_norm": 2.336041212081909,
      "learning_rate": 2.8291429620113784e-05,
      "logits/chosen": -0.3565174639225006,
      "logits/rejected": 0.04335176199674606,
      "logps/chosen": -195.73260498046875,
      "logps/rejected": -214.61502075195312,
      "loss": 0.1573,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.355758190155029,
      "rewards/margins": 4.574843883514404,
      "rewards/rejected": -8.930603981018066,
      "step": 17770
    },
    {
      "epoch": 3.2448216078109318,
      "grad_norm": 11.697905540466309,
      "learning_rate": 2.8262066434208115e-05,
      "logits/chosen": -0.15031583607196808,
      "logits/rejected": 0.15128375589847565,
      "logps/chosen": -199.82321166992188,
      "logps/rejected": -218.64651489257812,
      "loss": 0.1399,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.562685966491699,
      "rewards/margins": 4.917702674865723,
      "rewards/rejected": -9.480388641357422,
      "step": 17780
    },
    {
      "epoch": 3.2466465918423215,
      "grad_norm": 13.980406761169434,
      "learning_rate": 2.8232703248302443e-05,
      "logits/chosen": -0.46414780616760254,
      "logits/rejected": -0.11100135743618011,
      "logps/chosen": -206.59317016601562,
      "logps/rejected": -214.90658569335938,
      "loss": 0.2351,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.6888837814331055,
      "rewards/margins": 3.9728050231933594,
      "rewards/rejected": -8.661687850952148,
      "step": 17790
    },
    {
      "epoch": 3.2484715758737113,
      "grad_norm": 2.1465282440185547,
      "learning_rate": 2.8203340062396774e-05,
      "logits/chosen": -0.29005303978919983,
      "logits/rejected": 0.11985554546117783,
      "logps/chosen": -181.53115844726562,
      "logps/rejected": -225.6255645751953,
      "loss": 0.133,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.31873893737793,
      "rewards/margins": 5.198455333709717,
      "rewards/rejected": -9.517194747924805,
      "step": 17800
    },
    {
      "epoch": 3.250296559905101,
      "grad_norm": 9.772448539733887,
      "learning_rate": 2.81739768764911e-05,
      "logits/chosen": -0.21582667529582977,
      "logits/rejected": 0.11703269183635712,
      "logps/chosen": -183.1253204345703,
      "logps/rejected": -221.1048126220703,
      "loss": 0.1052,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.928339958190918,
      "rewards/margins": 5.267941474914551,
      "rewards/rejected": -10.196281433105469,
      "step": 17810
    },
    {
      "epoch": 3.2521215439364903,
      "grad_norm": 1.1996655464172363,
      "learning_rate": 2.814461369058543e-05,
      "logits/chosen": -0.3035730719566345,
      "logits/rejected": 0.04769587144255638,
      "logps/chosen": -188.84310913085938,
      "logps/rejected": -226.37014770507812,
      "loss": 0.1409,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.623482704162598,
      "rewards/margins": 4.942653656005859,
      "rewards/rejected": -9.566137313842773,
      "step": 17820
    },
    {
      "epoch": 3.25394652796788,
      "grad_norm": 0.43146273493766785,
      "learning_rate": 2.811525050467976e-05,
      "logits/chosen": -0.2663508653640747,
      "logits/rejected": 0.17083048820495605,
      "logps/chosen": -190.04891967773438,
      "logps/rejected": -226.17236328125,
      "loss": 0.1886,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.116103172302246,
      "rewards/margins": 4.89007568359375,
      "rewards/rejected": -10.006179809570312,
      "step": 17830
    },
    {
      "epoch": 3.25577151199927,
      "grad_norm": 6.217171669006348,
      "learning_rate": 2.808588731877409e-05,
      "logits/chosen": -0.33290165662765503,
      "logits/rejected": 0.1682622730731964,
      "logps/chosen": -205.4818115234375,
      "logps/rejected": -223.29891967773438,
      "loss": 0.0906,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.082562446594238,
      "rewards/margins": 5.278047561645508,
      "rewards/rejected": -10.36060905456543,
      "step": 17840
    },
    {
      "epoch": 3.2575964960306596,
      "grad_norm": 1.451476812362671,
      "learning_rate": 2.8056524132868418e-05,
      "logits/chosen": -0.27811381220817566,
      "logits/rejected": 0.020653244107961655,
      "logps/chosen": -202.1435546875,
      "logps/rejected": -231.6807861328125,
      "loss": 0.1596,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.622801780700684,
      "rewards/margins": 4.759331703186035,
      "rewards/rejected": -9.382132530212402,
      "step": 17850
    },
    {
      "epoch": 3.2594214800620493,
      "grad_norm": 12.460649490356445,
      "learning_rate": 2.802716094696275e-05,
      "logits/chosen": -0.16002975404262543,
      "logits/rejected": 0.06133699417114258,
      "logps/chosen": -190.2987060546875,
      "logps/rejected": -225.5911102294922,
      "loss": 0.1742,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.227476119995117,
      "rewards/margins": 4.681879997253418,
      "rewards/rejected": -9.909357070922852,
      "step": 17860
    },
    {
      "epoch": 3.261246464093439,
      "grad_norm": 1.8365052938461304,
      "learning_rate": 2.7997797761057074e-05,
      "logits/chosen": -0.2361050546169281,
      "logits/rejected": 0.12073972076177597,
      "logps/chosen": -179.76223754882812,
      "logps/rejected": -208.8555145263672,
      "loss": 0.0975,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.165355205535889,
      "rewards/margins": 4.870304107666016,
      "rewards/rejected": -9.035658836364746,
      "step": 17870
    },
    {
      "epoch": 3.263071448124829,
      "grad_norm": 2.0781733989715576,
      "learning_rate": 2.7968434575151405e-05,
      "logits/chosen": -0.24350233376026154,
      "logits/rejected": 0.13609111309051514,
      "logps/chosen": -190.0922393798828,
      "logps/rejected": -199.92054748535156,
      "loss": 0.2979,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.0751543045043945,
      "rewards/margins": 4.004542350769043,
      "rewards/rejected": -9.079697608947754,
      "step": 17880
    },
    {
      "epoch": 3.2648964321562186,
      "grad_norm": 1.3760607242584229,
      "learning_rate": 2.7939071389245733e-05,
      "logits/chosen": -0.3240891695022583,
      "logits/rejected": 0.15837985277175903,
      "logps/chosen": -206.1828155517578,
      "logps/rejected": -204.50393676757812,
      "loss": 0.1133,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.5966391563415527,
      "rewards/margins": 4.69669771194458,
      "rewards/rejected": -8.293336868286133,
      "step": 17890
    },
    {
      "epoch": 3.2667214161876084,
      "grad_norm": 5.742384910583496,
      "learning_rate": 2.7909708203340064e-05,
      "logits/chosen": -0.5442826747894287,
      "logits/rejected": -0.26750829815864563,
      "logps/chosen": -172.98924255371094,
      "logps/rejected": -208.44601440429688,
      "loss": 0.226,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.078303575515747,
      "rewards/margins": 4.430241584777832,
      "rewards/rejected": -7.508544921875,
      "step": 17900
    },
    {
      "epoch": 3.268546400218998,
      "grad_norm": 5.94273567199707,
      "learning_rate": 2.7880345017434396e-05,
      "logits/chosen": -0.3422999978065491,
      "logits/rejected": -0.08860962837934494,
      "logps/chosen": -181.47821044921875,
      "logps/rejected": -223.15914916992188,
      "loss": 0.2802,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.7651360034942627,
      "rewards/margins": 4.712494850158691,
      "rewards/rejected": -8.477629661560059,
      "step": 17910
    },
    {
      "epoch": 3.270371384250388,
      "grad_norm": 10.746306419372559,
      "learning_rate": 2.7850981831528724e-05,
      "logits/chosen": -0.4205092787742615,
      "logits/rejected": -0.018975146114826202,
      "logps/chosen": -196.30575561523438,
      "logps/rejected": -221.8681182861328,
      "loss": 0.115,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -3.7718071937561035,
      "rewards/margins": 5.249622344970703,
      "rewards/rejected": -9.021429061889648,
      "step": 17920
    },
    {
      "epoch": 3.2721963682817776,
      "grad_norm": 4.176839351654053,
      "learning_rate": 2.7821618645623055e-05,
      "logits/chosen": -0.3331668972969055,
      "logits/rejected": -0.050850044935941696,
      "logps/chosen": -174.17605590820312,
      "logps/rejected": -202.622314453125,
      "loss": 0.1278,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.177294731140137,
      "rewards/margins": 4.596312046051025,
      "rewards/rejected": -8.77360725402832,
      "step": 17930
    },
    {
      "epoch": 3.2740213523131674,
      "grad_norm": 3.493378162384033,
      "learning_rate": 2.779225545971738e-05,
      "logits/chosen": -0.34725117683410645,
      "logits/rejected": -0.032126862555742264,
      "logps/chosen": -205.37966918945312,
      "logps/rejected": -219.76986694335938,
      "loss": 0.2164,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.39669132232666,
      "rewards/margins": 4.355802059173584,
      "rewards/rejected": -8.752492904663086,
      "step": 17940
    },
    {
      "epoch": 3.275846336344557,
      "grad_norm": 10.756390571594238,
      "learning_rate": 2.776289227381171e-05,
      "logits/chosen": -0.48625168204307556,
      "logits/rejected": -0.017052391543984413,
      "logps/chosen": -194.53793334960938,
      "logps/rejected": -200.5782928466797,
      "loss": 0.1684,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -3.6961750984191895,
      "rewards/margins": 4.282902240753174,
      "rewards/rejected": -7.9790778160095215,
      "step": 17950
    },
    {
      "epoch": 3.277671320375947,
      "grad_norm": 3.518651008605957,
      "learning_rate": 2.773352908790604e-05,
      "logits/chosen": -0.23459351062774658,
      "logits/rejected": 0.19839662313461304,
      "logps/chosen": -199.20376586914062,
      "logps/rejected": -213.77102661132812,
      "loss": 0.1364,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.699950218200684,
      "rewards/margins": 4.806583404541016,
      "rewards/rejected": -9.5065336227417,
      "step": 17960
    },
    {
      "epoch": 3.2794963044073366,
      "grad_norm": 5.575232028961182,
      "learning_rate": 2.770416590200037e-05,
      "logits/chosen": -0.49043646454811096,
      "logits/rejected": 0.046974703669548035,
      "logps/chosen": -209.66268920898438,
      "logps/rejected": -202.45516967773438,
      "loss": 0.143,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.109959602355957,
      "rewards/margins": 4.757253646850586,
      "rewards/rejected": -9.867213249206543,
      "step": 17970
    },
    {
      "epoch": 3.2813212884387264,
      "grad_norm": 7.379603385925293,
      "learning_rate": 2.7674802716094698e-05,
      "logits/chosen": -0.30910664796829224,
      "logits/rejected": 0.13447462022304535,
      "logps/chosen": -187.73902893066406,
      "logps/rejected": -217.4239959716797,
      "loss": 0.0867,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.345671653747559,
      "rewards/margins": 5.256914138793945,
      "rewards/rejected": -9.602585792541504,
      "step": 17980
    },
    {
      "epoch": 3.2831462724701157,
      "grad_norm": 2.072258234024048,
      "learning_rate": 2.764543953018903e-05,
      "logits/chosen": -0.2604027986526489,
      "logits/rejected": 0.04936390370130539,
      "logps/chosen": -203.37722778320312,
      "logps/rejected": -221.38290405273438,
      "loss": 0.2149,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.025177955627441,
      "rewards/margins": 4.064570903778076,
      "rewards/rejected": -9.089750289916992,
      "step": 17990
    },
    {
      "epoch": 3.2849712565015055,
      "grad_norm": 1.644516110420227,
      "learning_rate": 2.7616076344283354e-05,
      "logits/chosen": -0.22964639961719513,
      "logits/rejected": 0.013931477442383766,
      "logps/chosen": -199.05650329589844,
      "logps/rejected": -231.0626220703125,
      "loss": 0.191,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.334036827087402,
      "rewards/margins": 3.7731242179870605,
      "rewards/rejected": -9.107160568237305,
      "step": 18000
    },
    {
      "epoch": 3.286796240532895,
      "grad_norm": 6.689085006713867,
      "learning_rate": 2.7586713158377685e-05,
      "logits/chosen": -0.24033255875110626,
      "logits/rejected": 0.10832084715366364,
      "logps/chosen": -207.7715301513672,
      "logps/rejected": -234.35739135742188,
      "loss": 0.1297,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.013711452484131,
      "rewards/margins": 4.624650478363037,
      "rewards/rejected": -9.638360977172852,
      "step": 18010
    },
    {
      "epoch": 3.288621224564285,
      "grad_norm": 3.8951938152313232,
      "learning_rate": 2.7557349972472013e-05,
      "logits/chosen": -0.161973774433136,
      "logits/rejected": 0.04859588295221329,
      "logps/chosen": -206.13217163085938,
      "logps/rejected": -242.08621215820312,
      "loss": 0.1644,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.383314609527588,
      "rewards/margins": 4.509949207305908,
      "rewards/rejected": -9.89326286315918,
      "step": 18020
    },
    {
      "epoch": 3.2904462085956747,
      "grad_norm": 1.2678859233856201,
      "learning_rate": 2.7527986786566345e-05,
      "logits/chosen": -0.23687689006328583,
      "logits/rejected": 0.1173773780465126,
      "logps/chosen": -186.41433715820312,
      "logps/rejected": -218.96768188476562,
      "loss": 0.1096,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.399970531463623,
      "rewards/margins": 4.646449565887451,
      "rewards/rejected": -9.04642105102539,
      "step": 18030
    },
    {
      "epoch": 3.2922711926270645,
      "grad_norm": 1.9747499227523804,
      "learning_rate": 2.7498623600660673e-05,
      "logits/chosen": -0.24751980602741241,
      "logits/rejected": 0.1096876859664917,
      "logps/chosen": -192.3007354736328,
      "logps/rejected": -225.49655151367188,
      "loss": 0.0973,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.910797119140625,
      "rewards/margins": 4.817084312438965,
      "rewards/rejected": -9.727880477905273,
      "step": 18040
    },
    {
      "epoch": 3.2940961766584542,
      "grad_norm": 2.2709245681762695,
      "learning_rate": 2.7469260414755004e-05,
      "logits/chosen": -0.02965412475168705,
      "logits/rejected": 0.36765044927597046,
      "logps/chosen": -196.30982971191406,
      "logps/rejected": -229.156982421875,
      "loss": 0.0936,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.606966495513916,
      "rewards/margins": 4.900245189666748,
      "rewards/rejected": -10.507211685180664,
      "step": 18050
    },
    {
      "epoch": 3.295921160689844,
      "grad_norm": 5.65810489654541,
      "learning_rate": 2.7439897228849332e-05,
      "logits/chosen": -0.21325233578681946,
      "logits/rejected": 0.3098856806755066,
      "logps/chosen": -215.716796875,
      "logps/rejected": -225.17349243164062,
      "loss": 0.1062,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.354433059692383,
      "rewards/margins": 5.119579315185547,
      "rewards/rejected": -10.47401237487793,
      "step": 18060
    },
    {
      "epoch": 3.2977461447212337,
      "grad_norm": 14.266599655151367,
      "learning_rate": 2.7410534042943663e-05,
      "logits/chosen": -0.20948991179466248,
      "logits/rejected": 0.08689651638269424,
      "logps/chosen": -197.64608764648438,
      "logps/rejected": -222.2347869873047,
      "loss": 0.2336,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.344055652618408,
      "rewards/margins": 4.370613098144531,
      "rewards/rejected": -9.714669227600098,
      "step": 18070
    },
    {
      "epoch": 3.2995711287526235,
      "grad_norm": 9.192571640014648,
      "learning_rate": 2.7381170857037995e-05,
      "logits/chosen": -0.18695999681949615,
      "logits/rejected": 0.15680035948753357,
      "logps/chosen": -176.28768920898438,
      "logps/rejected": -214.75314331054688,
      "loss": 0.1248,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.593883514404297,
      "rewards/margins": 5.067168235778809,
      "rewards/rejected": -9.661050796508789,
      "step": 18080
    },
    {
      "epoch": 3.3013961127840132,
      "grad_norm": 9.411127090454102,
      "learning_rate": 2.735180767113232e-05,
      "logits/chosen": -0.3748262822628021,
      "logits/rejected": 0.15864908695220947,
      "logps/chosen": -198.00987243652344,
      "logps/rejected": -215.31689453125,
      "loss": 0.1543,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.66949462890625,
      "rewards/margins": 5.019346714019775,
      "rewards/rejected": -9.688840866088867,
      "step": 18090
    },
    {
      "epoch": 3.303221096815403,
      "grad_norm": 0.7878209352493286,
      "learning_rate": 2.732244448522665e-05,
      "logits/chosen": -0.31355518102645874,
      "logits/rejected": 0.06522510945796967,
      "logps/chosen": -192.6770477294922,
      "logps/rejected": -218.801513671875,
      "loss": 0.1275,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.2621355056762695,
      "rewards/margins": 4.887657642364502,
      "rewards/rejected": -10.149792671203613,
      "step": 18100
    },
    {
      "epoch": 3.3050460808467927,
      "grad_norm": 0.3160426616668701,
      "learning_rate": 2.729308129932098e-05,
      "logits/chosen": -0.19701877236366272,
      "logits/rejected": 0.08711551129817963,
      "logps/chosen": -193.5371551513672,
      "logps/rejected": -229.98580932617188,
      "loss": 0.134,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.297213077545166,
      "rewards/margins": 5.101579189300537,
      "rewards/rejected": -10.39879322052002,
      "step": 18110
    },
    {
      "epoch": 3.3068710648781825,
      "grad_norm": 4.419203758239746,
      "learning_rate": 2.726371811341531e-05,
      "logits/chosen": -0.22437448799610138,
      "logits/rejected": 0.16254690289497375,
      "logps/chosen": -208.7065887451172,
      "logps/rejected": -216.57809448242188,
      "loss": 0.2579,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.073215484619141,
      "rewards/margins": 4.113327980041504,
      "rewards/rejected": -10.186543464660645,
      "step": 18120
    },
    {
      "epoch": 3.308696048909572,
      "grad_norm": 1.0723953247070312,
      "learning_rate": 2.7234354927509638e-05,
      "logits/chosen": -0.37015828490257263,
      "logits/rejected": -0.09910465776920319,
      "logps/chosen": -217.59765625,
      "logps/rejected": -222.001953125,
      "loss": 0.2764,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.9909210205078125,
      "rewards/margins": 3.4515929222106934,
      "rewards/rejected": -9.442514419555664,
      "step": 18130
    },
    {
      "epoch": 3.3105210329409616,
      "grad_norm": 1.2464749813079834,
      "learning_rate": 2.720499174160397e-05,
      "logits/chosen": -0.34448909759521484,
      "logits/rejected": 0.11430753767490387,
      "logps/chosen": -227.2197723388672,
      "logps/rejected": -237.64260864257812,
      "loss": 0.1247,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.603131294250488,
      "rewards/margins": 4.937798023223877,
      "rewards/rejected": -10.540929794311523,
      "step": 18140
    },
    {
      "epoch": 3.3123460169723513,
      "grad_norm": 14.382315635681152,
      "learning_rate": 2.7175628555698294e-05,
      "logits/chosen": -0.25040942430496216,
      "logits/rejected": -0.006613872945308685,
      "logps/chosen": -197.8278045654297,
      "logps/rejected": -233.1990203857422,
      "loss": 0.2475,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.688944339752197,
      "rewards/margins": 3.8843321800231934,
      "rewards/rejected": -9.573275566101074,
      "step": 18150
    },
    {
      "epoch": 3.314171001003741,
      "grad_norm": 3.4978368282318115,
      "learning_rate": 2.7146265369792625e-05,
      "logits/chosen": -0.28819864988327026,
      "logits/rejected": 0.037651967257261276,
      "logps/chosen": -200.9893798828125,
      "logps/rejected": -218.1195831298828,
      "loss": 0.2051,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.018858909606934,
      "rewards/margins": 4.027354717254639,
      "rewards/rejected": -9.046213150024414,
      "step": 18160
    },
    {
      "epoch": 3.315995985035131,
      "grad_norm": 10.3760986328125,
      "learning_rate": 2.7116902183886953e-05,
      "logits/chosen": -0.2994315028190613,
      "logits/rejected": -0.03967008739709854,
      "logps/chosen": -196.46737670898438,
      "logps/rejected": -225.04812622070312,
      "loss": 0.1782,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.729517936706543,
      "rewards/margins": 4.221096992492676,
      "rewards/rejected": -9.950614929199219,
      "step": 18170
    },
    {
      "epoch": 3.3178209690665206,
      "grad_norm": 10.705713272094727,
      "learning_rate": 2.7087538997981284e-05,
      "logits/chosen": -0.2095223218202591,
      "logits/rejected": 0.14191628992557526,
      "logps/chosen": -197.05538940429688,
      "logps/rejected": -238.13134765625,
      "loss": 0.2098,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.468838214874268,
      "rewards/margins": 4.305757999420166,
      "rewards/rejected": -9.774595260620117,
      "step": 18180
    },
    {
      "epoch": 3.3196459530979103,
      "grad_norm": 9.634819984436035,
      "learning_rate": 2.7058175812075612e-05,
      "logits/chosen": -0.21393939852714539,
      "logits/rejected": 0.11389486491680145,
      "logps/chosen": -195.8983154296875,
      "logps/rejected": -228.50741577148438,
      "loss": 0.0835,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.784214973449707,
      "rewards/margins": 4.721846103668213,
      "rewards/rejected": -10.506061553955078,
      "step": 18190
    },
    {
      "epoch": 3.3214709371293,
      "grad_norm": 5.831434726715088,
      "learning_rate": 2.7028812626169944e-05,
      "logits/chosen": -0.18757817149162292,
      "logits/rejected": 0.1676524579524994,
      "logps/chosen": -209.1540069580078,
      "logps/rejected": -229.54257202148438,
      "loss": 0.2035,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.7954230308532715,
      "rewards/margins": 4.220944404602051,
      "rewards/rejected": -10.016366958618164,
      "step": 18200
    },
    {
      "epoch": 3.32329592116069,
      "grad_norm": 6.13037633895874,
      "learning_rate": 2.699944944026427e-05,
      "logits/chosen": -0.2590728998184204,
      "logits/rejected": 0.022956054657697678,
      "logps/chosen": -201.66256713867188,
      "logps/rejected": -233.9060821533203,
      "loss": 0.127,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.224170684814453,
      "rewards/margins": 4.647562026977539,
      "rewards/rejected": -9.871732711791992,
      "step": 18210
    },
    {
      "epoch": 3.3251209051920796,
      "grad_norm": 2.9384219646453857,
      "learning_rate": 2.69700862543586e-05,
      "logits/chosen": -0.2632952332496643,
      "logits/rejected": 0.2992715835571289,
      "logps/chosen": -217.5994110107422,
      "logps/rejected": -216.4093780517578,
      "loss": 0.088,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.298964977264404,
      "rewards/margins": 4.521082401275635,
      "rewards/rejected": -9.820047378540039,
      "step": 18220
    },
    {
      "epoch": 3.3269458892234693,
      "grad_norm": 3.0178580284118652,
      "learning_rate": 2.6940723068452928e-05,
      "logits/chosen": -0.23228482902050018,
      "logits/rejected": -0.02106592431664467,
      "logps/chosen": -203.58741760253906,
      "logps/rejected": -230.17434692382812,
      "loss": 0.2018,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.591954231262207,
      "rewards/margins": 4.380598545074463,
      "rewards/rejected": -9.972554206848145,
      "step": 18230
    },
    {
      "epoch": 3.328770873254859,
      "grad_norm": 10.485793113708496,
      "learning_rate": 2.691135988254726e-05,
      "logits/chosen": -0.3053207993507385,
      "logits/rejected": -0.0964193195104599,
      "logps/chosen": -199.2025909423828,
      "logps/rejected": -242.75479125976562,
      "loss": 0.1235,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.060733795166016,
      "rewards/margins": 4.954799652099609,
      "rewards/rejected": -11.015534400939941,
      "step": 18240
    },
    {
      "epoch": 3.330595857286249,
      "grad_norm": 5.752676010131836,
      "learning_rate": 2.6881996696641587e-05,
      "logits/chosen": -0.21099932491779327,
      "logits/rejected": 0.25087472796440125,
      "logps/chosen": -214.9550323486328,
      "logps/rejected": -221.74551391601562,
      "loss": 0.2046,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.3481526374816895,
      "rewards/margins": 4.189056396484375,
      "rewards/rejected": -10.537208557128906,
      "step": 18250
    },
    {
      "epoch": 3.3324208413176386,
      "grad_norm": 8.880556106567383,
      "learning_rate": 2.685263351073592e-05,
      "logits/chosen": -0.25482362508773804,
      "logits/rejected": -0.08491478115320206,
      "logps/chosen": -196.45950317382812,
      "logps/rejected": -224.15298461914062,
      "loss": 0.3186,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.232846260070801,
      "rewards/margins": 3.8097286224365234,
      "rewards/rejected": -10.042573928833008,
      "step": 18260
    },
    {
      "epoch": 3.3342458253490284,
      "grad_norm": 3.4727704524993896,
      "learning_rate": 2.682327032483025e-05,
      "logits/chosen": -0.14479704201221466,
      "logits/rejected": -0.04757501929998398,
      "logps/chosen": -196.79049682617188,
      "logps/rejected": -240.7642364501953,
      "loss": 0.1729,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.414684295654297,
      "rewards/margins": 4.196911811828613,
      "rewards/rejected": -9.611597061157227,
      "step": 18270
    },
    {
      "epoch": 3.336070809380418,
      "grad_norm": 3.0819339752197266,
      "learning_rate": 2.6793907138924574e-05,
      "logits/chosen": -0.48874130845069885,
      "logits/rejected": -0.19779936969280243,
      "logps/chosen": -226.0748291015625,
      "logps/rejected": -245.05892944335938,
      "loss": 0.1445,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.300478458404541,
      "rewards/margins": 4.078299045562744,
      "rewards/rejected": -9.378778457641602,
      "step": 18280
    },
    {
      "epoch": 3.337895793411808,
      "grad_norm": 4.160247802734375,
      "learning_rate": 2.6764543953018906e-05,
      "logits/chosen": -0.36890894174575806,
      "logits/rejected": -0.2502816617488861,
      "logps/chosen": -191.01394653320312,
      "logps/rejected": -246.950439453125,
      "loss": 0.1428,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.182438850402832,
      "rewards/margins": 4.415740489959717,
      "rewards/rejected": -9.598179817199707,
      "step": 18290
    },
    {
      "epoch": 3.3397207774431976,
      "grad_norm": 2.780698299407959,
      "learning_rate": 2.6735180767113234e-05,
      "logits/chosen": -0.18080025911331177,
      "logits/rejected": 0.1529245227575302,
      "logps/chosen": -220.5438995361328,
      "logps/rejected": -252.05239868164062,
      "loss": 0.1426,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.89206075668335,
      "rewards/margins": 4.641819000244141,
      "rewards/rejected": -11.533879280090332,
      "step": 18300
    },
    {
      "epoch": 3.341545761474587,
      "grad_norm": 14.81955337524414,
      "learning_rate": 2.6705817581207565e-05,
      "logits/chosen": -0.3445987105369568,
      "logits/rejected": 0.01020651776343584,
      "logps/chosen": -203.39585876464844,
      "logps/rejected": -241.46884155273438,
      "loss": 0.1696,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.6375532150268555,
      "rewards/margins": 4.4220991134643555,
      "rewards/rejected": -10.059653282165527,
      "step": 18310
    },
    {
      "epoch": 3.3433707455059767,
      "grad_norm": 3.9746334552764893,
      "learning_rate": 2.6676454395301893e-05,
      "logits/chosen": -0.16750171780586243,
      "logits/rejected": 0.028307974338531494,
      "logps/chosen": -205.9248046875,
      "logps/rejected": -252.91152954101562,
      "loss": 0.1245,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.817464828491211,
      "rewards/margins": 4.596914291381836,
      "rewards/rejected": -10.414377212524414,
      "step": 18320
    },
    {
      "epoch": 3.3451957295373664,
      "grad_norm": 3.171661615371704,
      "learning_rate": 2.6647091209396224e-05,
      "logits/chosen": -0.3734087646007538,
      "logits/rejected": 0.005766517017036676,
      "logps/chosen": -216.28713989257812,
      "logps/rejected": -241.88363647460938,
      "loss": 0.0856,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.3365983963012695,
      "rewards/margins": 5.094917297363281,
      "rewards/rejected": -10.431513786315918,
      "step": 18330
    },
    {
      "epoch": 3.347020713568756,
      "grad_norm": 7.635168552398682,
      "learning_rate": 2.661772802349055e-05,
      "logits/chosen": -0.30764463543891907,
      "logits/rejected": 0.08295412361621857,
      "logps/chosen": -191.87115478515625,
      "logps/rejected": -208.4895782470703,
      "loss": 0.193,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.295788764953613,
      "rewards/margins": 3.855527877807617,
      "rewards/rejected": -9.151315689086914,
      "step": 18340
    },
    {
      "epoch": 3.348845697600146,
      "grad_norm": 2.268608808517456,
      "learning_rate": 2.658836483758488e-05,
      "logits/chosen": -0.10691076517105103,
      "logits/rejected": 0.049872271716594696,
      "logps/chosen": -187.66140747070312,
      "logps/rejected": -249.43798828125,
      "loss": 0.0881,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.032362461090088,
      "rewards/margins": 5.114175319671631,
      "rewards/rejected": -11.146536827087402,
      "step": 18350
    },
    {
      "epoch": 3.3506706816315357,
      "grad_norm": 4.734445571899414,
      "learning_rate": 2.6559001651679208e-05,
      "logits/chosen": -0.37121468782424927,
      "logits/rejected": -0.17380522191524506,
      "logps/chosen": -197.83364868164062,
      "logps/rejected": -250.8355712890625,
      "loss": 0.1198,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.3447651863098145,
      "rewards/margins": 5.092531681060791,
      "rewards/rejected": -10.437296867370605,
      "step": 18360
    },
    {
      "epoch": 3.3524956656629255,
      "grad_norm": 11.41100788116455,
      "learning_rate": 2.652963846577354e-05,
      "logits/chosen": -0.2601291537284851,
      "logits/rejected": -0.1445450335741043,
      "logps/chosen": -212.437255859375,
      "logps/rejected": -252.5198516845703,
      "loss": 0.1645,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.002435207366943,
      "rewards/margins": 4.666018486022949,
      "rewards/rejected": -10.66845417022705,
      "step": 18370
    },
    {
      "epoch": 3.354320649694315,
      "grad_norm": 8.703425407409668,
      "learning_rate": 2.6500275279867867e-05,
      "logits/chosen": -0.3616052269935608,
      "logits/rejected": 0.023681217804551125,
      "logps/chosen": -186.0607452392578,
      "logps/rejected": -220.59231567382812,
      "loss": 0.2446,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.408411979675293,
      "rewards/margins": 4.104325771331787,
      "rewards/rejected": -9.512738227844238,
      "step": 18380
    },
    {
      "epoch": 3.356145633725705,
      "grad_norm": 11.257662773132324,
      "learning_rate": 2.64709120939622e-05,
      "logits/chosen": -0.5470036864280701,
      "logits/rejected": -0.14311818778514862,
      "logps/chosen": -207.2289276123047,
      "logps/rejected": -226.6562042236328,
      "loss": 0.1608,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -4.993571758270264,
      "rewards/margins": 4.713431358337402,
      "rewards/rejected": -9.70700454711914,
      "step": 18390
    },
    {
      "epoch": 3.3579706177570947,
      "grad_norm": 7.688070297241211,
      "learning_rate": 2.6441548908056523e-05,
      "logits/chosen": -0.2623137831687927,
      "logits/rejected": 0.11556322872638702,
      "logps/chosen": -189.44131469726562,
      "logps/rejected": -218.8630828857422,
      "loss": 0.1442,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.321970462799072,
      "rewards/margins": 4.633908271789551,
      "rewards/rejected": -9.955879211425781,
      "step": 18400
    },
    {
      "epoch": 3.3597956017884845,
      "grad_norm": 5.558289527893066,
      "learning_rate": 2.6412185722150855e-05,
      "logits/chosen": -0.36900219321250916,
      "logits/rejected": -0.24713483452796936,
      "logps/chosen": -202.1149139404297,
      "logps/rejected": -230.46414184570312,
      "loss": 0.212,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.120434284210205,
      "rewards/margins": 4.007502555847168,
      "rewards/rejected": -9.127936363220215,
      "step": 18410
    },
    {
      "epoch": 3.361620585819874,
      "grad_norm": 10.817024230957031,
      "learning_rate": 2.6382822536245183e-05,
      "logits/chosen": -0.4956236779689789,
      "logits/rejected": -0.27203625440597534,
      "logps/chosen": -190.19020080566406,
      "logps/rejected": -221.0110321044922,
      "loss": 0.1397,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.8452653884887695,
      "rewards/margins": 4.235116004943848,
      "rewards/rejected": -9.080381393432617,
      "step": 18420
    },
    {
      "epoch": 3.363445569851264,
      "grad_norm": 9.027347564697266,
      "learning_rate": 2.6353459350339514e-05,
      "logits/chosen": -0.49109959602355957,
      "logits/rejected": -0.08322769403457642,
      "logps/chosen": -207.4551544189453,
      "logps/rejected": -237.06442260742188,
      "loss": 0.1159,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.856085300445557,
      "rewards/margins": 5.645368576049805,
      "rewards/rejected": -10.501453399658203,
      "step": 18430
    },
    {
      "epoch": 3.3652705538826533,
      "grad_norm": 1.3769667148590088,
      "learning_rate": 2.6324096164433842e-05,
      "logits/chosen": -0.4461696147918701,
      "logits/rejected": -0.13826777040958405,
      "logps/chosen": -206.3072509765625,
      "logps/rejected": -240.57113647460938,
      "loss": 0.1341,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.235527992248535,
      "rewards/margins": 4.45892858505249,
      "rewards/rejected": -9.694456100463867,
      "step": 18440
    },
    {
      "epoch": 3.367095537914043,
      "grad_norm": 1.9471131563186646,
      "learning_rate": 2.6294732978528173e-05,
      "logits/chosen": -0.18230733275413513,
      "logits/rejected": 0.09355667978525162,
      "logps/chosen": -204.52334594726562,
      "logps/rejected": -234.11813354492188,
      "loss": 0.1522,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.106895923614502,
      "rewards/margins": 4.627724647521973,
      "rewards/rejected": -10.734621047973633,
      "step": 18450
    },
    {
      "epoch": 3.368920521945433,
      "grad_norm": 3.6841299533843994,
      "learning_rate": 2.6265369792622505e-05,
      "logits/chosen": -0.26489877700805664,
      "logits/rejected": -0.09507251530885696,
      "logps/chosen": -199.9400634765625,
      "logps/rejected": -255.93411254882812,
      "loss": 0.0988,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.980818748474121,
      "rewards/margins": 4.732921600341797,
      "rewards/rejected": -9.713740348815918,
      "step": 18460
    },
    {
      "epoch": 3.3707455059768225,
      "grad_norm": 7.426214218139648,
      "learning_rate": 2.623600660671683e-05,
      "logits/chosen": -0.4045148491859436,
      "logits/rejected": -0.04798832908272743,
      "logps/chosen": -213.913818359375,
      "logps/rejected": -245.63772583007812,
      "loss": 0.1293,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -4.712491035461426,
      "rewards/margins": 4.680881500244141,
      "rewards/rejected": -9.39337158203125,
      "step": 18470
    },
    {
      "epoch": 3.3725704900082123,
      "grad_norm": 4.618546009063721,
      "learning_rate": 2.620664342081116e-05,
      "logits/chosen": -0.25793758034706116,
      "logits/rejected": 0.2045849859714508,
      "logps/chosen": -188.80911254882812,
      "logps/rejected": -211.3731231689453,
      "loss": 0.1668,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.106600284576416,
      "rewards/margins": 4.767862319946289,
      "rewards/rejected": -9.874463081359863,
      "step": 18480
    },
    {
      "epoch": 3.374395474039602,
      "grad_norm": 2.954040288925171,
      "learning_rate": 2.617728023490549e-05,
      "logits/chosen": -0.29841887950897217,
      "logits/rejected": -0.0033234283328056335,
      "logps/chosen": -192.8325958251953,
      "logps/rejected": -231.39871215820312,
      "loss": 0.1351,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.474103927612305,
      "rewards/margins": 4.821938514709473,
      "rewards/rejected": -10.296042442321777,
      "step": 18490
    },
    {
      "epoch": 3.376220458070992,
      "grad_norm": 4.628234386444092,
      "learning_rate": 2.614791704899982e-05,
      "logits/chosen": -0.1813221424818039,
      "logits/rejected": 0.1365083009004593,
      "logps/chosen": -200.53372192382812,
      "logps/rejected": -238.9785919189453,
      "loss": 0.1317,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.614991188049316,
      "rewards/margins": 5.283316612243652,
      "rewards/rejected": -11.898307800292969,
      "step": 18500
    },
    {
      "epoch": 3.3780454421023816,
      "grad_norm": 10.296134948730469,
      "learning_rate": 2.6118553863094148e-05,
      "logits/chosen": -0.12844400107860565,
      "logits/rejected": 0.15135952830314636,
      "logps/chosen": -210.40774536132812,
      "logps/rejected": -245.4494171142578,
      "loss": 0.2331,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.389667987823486,
      "rewards/margins": 4.809445858001709,
      "rewards/rejected": -11.199113845825195,
      "step": 18510
    },
    {
      "epoch": 3.3798704261337713,
      "grad_norm": 11.005034446716309,
      "learning_rate": 2.608919067718848e-05,
      "logits/chosen": -0.23565705120563507,
      "logits/rejected": 0.2805858552455902,
      "logps/chosen": -196.8468780517578,
      "logps/rejected": -213.910888671875,
      "loss": 0.1708,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.6551127433776855,
      "rewards/margins": 4.496262550354004,
      "rewards/rejected": -10.151374816894531,
      "step": 18520
    },
    {
      "epoch": 3.381695410165161,
      "grad_norm": 1.247990369796753,
      "learning_rate": 2.6059827491282804e-05,
      "logits/chosen": -0.4171737730503082,
      "logits/rejected": -0.15480217337608337,
      "logps/chosen": -188.2981414794922,
      "logps/rejected": -252.33212280273438,
      "loss": 0.1434,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.289734840393066,
      "rewards/margins": 5.542029857635498,
      "rewards/rejected": -9.831766128540039,
      "step": 18530
    },
    {
      "epoch": 3.383520394196551,
      "grad_norm": 13.020685195922852,
      "learning_rate": 2.6030464305377135e-05,
      "logits/chosen": -0.3309411108493805,
      "logits/rejected": -0.03387615457177162,
      "logps/chosen": -194.58755493164062,
      "logps/rejected": -237.7170867919922,
      "loss": 0.1385,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.742077827453613,
      "rewards/margins": 5.497839450836182,
      "rewards/rejected": -10.239917755126953,
      "step": 18540
    },
    {
      "epoch": 3.3853453782279406,
      "grad_norm": 16.518964767456055,
      "learning_rate": 2.6001101119471463e-05,
      "logits/chosen": -0.41848692297935486,
      "logits/rejected": -0.13498637080192566,
      "logps/chosen": -187.3280029296875,
      "logps/rejected": -220.05520629882812,
      "loss": 0.2415,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -4.351031303405762,
      "rewards/margins": 4.87296199798584,
      "rewards/rejected": -9.223992347717285,
      "step": 18550
    },
    {
      "epoch": 3.3871703622593303,
      "grad_norm": 2.814758777618408,
      "learning_rate": 2.5971737933565794e-05,
      "logits/chosen": -0.36453062295913696,
      "logits/rejected": -0.18747155368328094,
      "logps/chosen": -181.64222717285156,
      "logps/rejected": -216.95046997070312,
      "loss": 0.2022,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -4.838587760925293,
      "rewards/margins": 4.1495490074157715,
      "rewards/rejected": -8.988136291503906,
      "step": 18560
    },
    {
      "epoch": 3.38899534629072,
      "grad_norm": 5.54841947555542,
      "learning_rate": 2.5942374747660122e-05,
      "logits/chosen": -0.47296181321144104,
      "logits/rejected": -0.16669677197933197,
      "logps/chosen": -208.54248046875,
      "logps/rejected": -255.2173309326172,
      "loss": 0.1239,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.998941421508789,
      "rewards/margins": 5.433502197265625,
      "rewards/rejected": -10.43244457244873,
      "step": 18570
    },
    {
      "epoch": 3.39082033032211,
      "grad_norm": 0.9911127090454102,
      "learning_rate": 2.5913011561754454e-05,
      "logits/chosen": -0.42786622047424316,
      "logits/rejected": -0.05575539916753769,
      "logps/chosen": -187.3806610107422,
      "logps/rejected": -231.85824584960938,
      "loss": 0.0822,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.854485988616943,
      "rewards/margins": 5.410926818847656,
      "rewards/rejected": -10.265412330627441,
      "step": 18580
    },
    {
      "epoch": 3.3926453143534996,
      "grad_norm": 4.453425884246826,
      "learning_rate": 2.588364837584878e-05,
      "logits/chosen": -0.22622165083885193,
      "logits/rejected": 0.23051507771015167,
      "logps/chosen": -195.0414276123047,
      "logps/rejected": -219.45407104492188,
      "loss": 0.1807,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.479657173156738,
      "rewards/margins": 4.730981349945068,
      "rewards/rejected": -10.210638046264648,
      "step": 18590
    },
    {
      "epoch": 3.3944702983848893,
      "grad_norm": 14.001998901367188,
      "learning_rate": 2.585428518994311e-05,
      "logits/chosen": -0.0725456178188324,
      "logits/rejected": 0.1861577332019806,
      "logps/chosen": -195.40023803710938,
      "logps/rejected": -229.55105590820312,
      "loss": 0.1517,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.473351001739502,
      "rewards/margins": 4.758222579956055,
      "rewards/rejected": -10.231573104858398,
      "step": 18600
    },
    {
      "epoch": 3.396295282416279,
      "grad_norm": 3.6237921714782715,
      "learning_rate": 2.5824922004037438e-05,
      "logits/chosen": -0.19394835829734802,
      "logits/rejected": 0.13946717977523804,
      "logps/chosen": -195.93496704101562,
      "logps/rejected": -258.0356140136719,
      "loss": 0.0796,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.177950859069824,
      "rewards/margins": 5.794983386993408,
      "rewards/rejected": -10.972933769226074,
      "step": 18610
    },
    {
      "epoch": 3.3981202664476684,
      "grad_norm": 4.972268581390381,
      "learning_rate": 2.579555881813177e-05,
      "logits/chosen": -0.30261555314064026,
      "logits/rejected": 0.02482747659087181,
      "logps/chosen": -198.27188110351562,
      "logps/rejected": -235.4521942138672,
      "loss": 0.1642,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -4.878981590270996,
      "rewards/margins": 4.777071952819824,
      "rewards/rejected": -9.656054496765137,
      "step": 18620
    },
    {
      "epoch": 3.399945250479058,
      "grad_norm": 7.563327789306641,
      "learning_rate": 2.5766195632226097e-05,
      "logits/chosen": -0.1814756691455841,
      "logits/rejected": 0.11154923588037491,
      "logps/chosen": -165.5818328857422,
      "logps/rejected": -219.3782501220703,
      "loss": 0.3444,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -5.000959873199463,
      "rewards/margins": 4.80533504486084,
      "rewards/rejected": -9.806296348571777,
      "step": 18630
    },
    {
      "epoch": 3.401770234510448,
      "grad_norm": 6.7417097091674805,
      "learning_rate": 2.5736832446320428e-05,
      "logits/chosen": -0.5062961578369141,
      "logits/rejected": 0.0628327801823616,
      "logps/chosen": -214.307373046875,
      "logps/rejected": -206.5249481201172,
      "loss": 0.1297,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.9748382568359375,
      "rewards/margins": 4.820581436157227,
      "rewards/rejected": -8.795418739318848,
      "step": 18640
    },
    {
      "epoch": 3.4035952185418377,
      "grad_norm": 5.944303035736084,
      "learning_rate": 2.570746926041476e-05,
      "logits/chosen": -0.36890897154808044,
      "logits/rejected": -0.02892172895371914,
      "logps/chosen": -189.9696044921875,
      "logps/rejected": -201.2467803955078,
      "loss": 0.1887,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.678709983825684,
      "rewards/margins": 3.8498122692108154,
      "rewards/rejected": -8.528522491455078,
      "step": 18650
    },
    {
      "epoch": 3.4054202025732274,
      "grad_norm": 9.988215446472168,
      "learning_rate": 2.5678106074509088e-05,
      "logits/chosen": -0.3630778193473816,
      "logits/rejected": 0.09514699131250381,
      "logps/chosen": -182.86074829101562,
      "logps/rejected": -193.14178466796875,
      "loss": 0.1491,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -4.219992637634277,
      "rewards/margins": 4.345419406890869,
      "rewards/rejected": -8.565412521362305,
      "step": 18660
    },
    {
      "epoch": 3.407245186604617,
      "grad_norm": 12.675410270690918,
      "learning_rate": 2.564874288860342e-05,
      "logits/chosen": -0.4047066271305084,
      "logits/rejected": 0.025149548426270485,
      "logps/chosen": -211.5872344970703,
      "logps/rejected": -227.7197723388672,
      "loss": 0.0666,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.44547176361084,
      "rewards/margins": 4.934594631195068,
      "rewards/rejected": -10.380066871643066,
      "step": 18670
    },
    {
      "epoch": 3.409070170636007,
      "grad_norm": 2.6282753944396973,
      "learning_rate": 2.5619379702697744e-05,
      "logits/chosen": -0.07182055711746216,
      "logits/rejected": 0.06873389333486557,
      "logps/chosen": -187.16653442382812,
      "logps/rejected": -226.1603546142578,
      "loss": 0.1515,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.319311618804932,
      "rewards/margins": 4.8037285804748535,
      "rewards/rejected": -10.123039245605469,
      "step": 18680
    },
    {
      "epoch": 3.4108951546673967,
      "grad_norm": 14.019414901733398,
      "learning_rate": 2.5590016516792075e-05,
      "logits/chosen": -0.2483077049255371,
      "logits/rejected": 0.01042416412383318,
      "logps/chosen": -172.70065307617188,
      "logps/rejected": -218.5377960205078,
      "loss": 0.1432,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.556254863739014,
      "rewards/margins": 5.073244571685791,
      "rewards/rejected": -9.629499435424805,
      "step": 18690
    },
    {
      "epoch": 3.4127201386987864,
      "grad_norm": 7.199507713317871,
      "learning_rate": 2.5560653330886403e-05,
      "logits/chosen": -0.4655064046382904,
      "logits/rejected": -0.08622894436120987,
      "logps/chosen": -191.84898376464844,
      "logps/rejected": -218.9050750732422,
      "loss": 0.1839,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -4.5379462242126465,
      "rewards/margins": 4.557913780212402,
      "rewards/rejected": -9.09585952758789,
      "step": 18700
    },
    {
      "epoch": 3.414545122730176,
      "grad_norm": 7.152276992797852,
      "learning_rate": 2.5531290144980734e-05,
      "logits/chosen": -0.5109624266624451,
      "logits/rejected": -0.13803385198116302,
      "logps/chosen": -184.04470825195312,
      "logps/rejected": -205.16744995117188,
      "loss": 0.1822,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.5859405994415283,
      "rewards/margins": 4.045892715454102,
      "rewards/rejected": -7.631833076477051,
      "step": 18710
    },
    {
      "epoch": 3.416370106761566,
      "grad_norm": 2.398118734359741,
      "learning_rate": 2.5501926959075062e-05,
      "logits/chosen": -0.4225867688655853,
      "logits/rejected": -0.034503787755966187,
      "logps/chosen": -192.55970764160156,
      "logps/rejected": -220.2158660888672,
      "loss": 0.0869,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -3.95782732963562,
      "rewards/margins": 4.757650852203369,
      "rewards/rejected": -8.71547794342041,
      "step": 18720
    },
    {
      "epoch": 3.4181950907929557,
      "grad_norm": 7.655025959014893,
      "learning_rate": 2.5472563773169394e-05,
      "logits/chosen": -0.5441446304321289,
      "logits/rejected": -0.14085423946380615,
      "logps/chosen": -181.8837432861328,
      "logps/rejected": -219.2116241455078,
      "loss": 0.1025,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -3.9285731315612793,
      "rewards/margins": 5.6206583976745605,
      "rewards/rejected": -9.54923152923584,
      "step": 18730
    },
    {
      "epoch": 3.4200200748243454,
      "grad_norm": 3.2474796772003174,
      "learning_rate": 2.5443200587263718e-05,
      "logits/chosen": -0.5258117318153381,
      "logits/rejected": -0.35726478695869446,
      "logps/chosen": -197.02528381347656,
      "logps/rejected": -246.00125122070312,
      "loss": 0.1582,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.179276466369629,
      "rewards/margins": 4.552276611328125,
      "rewards/rejected": -8.731552124023438,
      "step": 18740
    },
    {
      "epoch": 3.421845058855735,
      "grad_norm": 12.917291641235352,
      "learning_rate": 2.541383740135805e-05,
      "logits/chosen": -0.2817930281162262,
      "logits/rejected": -0.013438759371638298,
      "logps/chosen": -175.09107971191406,
      "logps/rejected": -205.2704620361328,
      "loss": 0.1441,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.0677900314331055,
      "rewards/margins": 4.144891738891602,
      "rewards/rejected": -9.212681770324707,
      "step": 18750
    },
    {
      "epoch": 3.4236700428871245,
      "grad_norm": 0.2561386823654175,
      "learning_rate": 2.5384474215452377e-05,
      "logits/chosen": -0.5139130353927612,
      "logits/rejected": -0.31057748198509216,
      "logps/chosen": -210.116943359375,
      "logps/rejected": -234.8867950439453,
      "loss": 0.2181,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.367051601409912,
      "rewards/margins": 4.210026741027832,
      "rewards/rejected": -9.577077865600586,
      "step": 18760
    },
    {
      "epoch": 3.4254950269185143,
      "grad_norm": 7.107346534729004,
      "learning_rate": 2.535511102954671e-05,
      "logits/chosen": -0.511928379535675,
      "logits/rejected": -0.2867715656757355,
      "logps/chosen": -183.27452087402344,
      "logps/rejected": -223.35067749023438,
      "loss": 0.1382,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.508009433746338,
      "rewards/margins": 5.171618461608887,
      "rewards/rejected": -9.679628372192383,
      "step": 18770
    },
    {
      "epoch": 3.427320010949904,
      "grad_norm": 9.436905860900879,
      "learning_rate": 2.5325747843641037e-05,
      "logits/chosen": -0.6748543977737427,
      "logits/rejected": -0.3827642500400543,
      "logps/chosen": -207.1026153564453,
      "logps/rejected": -218.22024536132812,
      "loss": 0.2471,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.817349910736084,
      "rewards/margins": 4.461944580078125,
      "rewards/rejected": -8.27929401397705,
      "step": 18780
    },
    {
      "epoch": 3.4291449949812938,
      "grad_norm": 6.290414333343506,
      "learning_rate": 2.5296384657735368e-05,
      "logits/chosen": -0.6606006026268005,
      "logits/rejected": -0.43747425079345703,
      "logps/chosen": -185.35894775390625,
      "logps/rejected": -227.1947021484375,
      "loss": 0.1258,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.050456523895264,
      "rewards/margins": 4.66632604598999,
      "rewards/rejected": -8.71678352355957,
      "step": 18790
    },
    {
      "epoch": 3.4309699790126835,
      "grad_norm": 4.296899795532227,
      "learning_rate": 2.5267021471829693e-05,
      "logits/chosen": -0.5372977256774902,
      "logits/rejected": -0.3974069058895111,
      "logps/chosen": -170.6824493408203,
      "logps/rejected": -227.809326171875,
      "loss": 0.1611,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.330941200256348,
      "rewards/margins": 4.516638278961182,
      "rewards/rejected": -8.847579002380371,
      "step": 18800
    },
    {
      "epoch": 3.4327949630440733,
      "grad_norm": 5.597928047180176,
      "learning_rate": 2.5237658285924024e-05,
      "logits/chosen": -0.7386729121208191,
      "logits/rejected": -0.3386151194572449,
      "logps/chosen": -213.2501220703125,
      "logps/rejected": -211.4759979248047,
      "loss": 0.136,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.992542266845703,
      "rewards/margins": 4.237351417541504,
      "rewards/rejected": -9.229893684387207,
      "step": 18810
    },
    {
      "epoch": 3.434619947075463,
      "grad_norm": 5.330315589904785,
      "learning_rate": 2.5208295100018355e-05,
      "logits/chosen": -0.7510262727737427,
      "logits/rejected": -0.35610076785087585,
      "logps/chosen": -191.20339965820312,
      "logps/rejected": -205.2677764892578,
      "loss": 0.1762,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.297665596008301,
      "rewards/margins": 4.635312080383301,
      "rewards/rejected": -8.932976722717285,
      "step": 18820
    },
    {
      "epoch": 3.436444931106853,
      "grad_norm": 15.202775955200195,
      "learning_rate": 2.5178931914112683e-05,
      "logits/chosen": -0.660047709941864,
      "logits/rejected": -0.3579912483692169,
      "logps/chosen": -189.40957641601562,
      "logps/rejected": -219.25247192382812,
      "loss": 0.1674,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.9045650959014893,
      "rewards/margins": 4.7120184898376465,
      "rewards/rejected": -8.616583824157715,
      "step": 18830
    },
    {
      "epoch": 3.4382699151382425,
      "grad_norm": 4.383419036865234,
      "learning_rate": 2.5149568728207015e-05,
      "logits/chosen": -0.3632359206676483,
      "logits/rejected": -0.14023034274578094,
      "logps/chosen": -195.986083984375,
      "logps/rejected": -244.2068634033203,
      "loss": 0.1257,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.9340009689331055,
      "rewards/margins": 5.0343828201293945,
      "rewards/rejected": -9.9683837890625,
      "step": 18840
    },
    {
      "epoch": 3.4400948991696323,
      "grad_norm": 10.871172904968262,
      "learning_rate": 2.5120205542301343e-05,
      "logits/chosen": -0.26370173692703247,
      "logits/rejected": -0.14556346833705902,
      "logps/chosen": -190.5086212158203,
      "logps/rejected": -240.6441192626953,
      "loss": 0.2102,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.6382646560668945,
      "rewards/margins": 4.402565002441406,
      "rewards/rejected": -10.040830612182617,
      "step": 18850
    },
    {
      "epoch": 3.441919883201022,
      "grad_norm": 7.84061336517334,
      "learning_rate": 2.5090842356395674e-05,
      "logits/chosen": -0.5376927852630615,
      "logits/rejected": -0.1786242425441742,
      "logps/chosen": -186.72430419921875,
      "logps/rejected": -203.70132446289062,
      "loss": 0.1588,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.057082653045654,
      "rewards/margins": 4.414467811584473,
      "rewards/rejected": -9.471549987792969,
      "step": 18860
    },
    {
      "epoch": 3.443744867232412,
      "grad_norm": 4.081326484680176,
      "learning_rate": 2.506147917049e-05,
      "logits/chosen": -0.3886972665786743,
      "logits/rejected": -0.133207768201828,
      "logps/chosen": -190.9803466796875,
      "logps/rejected": -223.263671875,
      "loss": 0.1532,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.96569299697876,
      "rewards/margins": 4.257355690002441,
      "rewards/rejected": -9.223048210144043,
      "step": 18870
    },
    {
      "epoch": 3.4455698512638016,
      "grad_norm": 9.866146087646484,
      "learning_rate": 2.503211598458433e-05,
      "logits/chosen": -0.4265511631965637,
      "logits/rejected": -0.12384594976902008,
      "logps/chosen": -193.66580200195312,
      "logps/rejected": -223.62100219726562,
      "loss": 0.2435,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.495406627655029,
      "rewards/margins": 4.008963584899902,
      "rewards/rejected": -9.504369735717773,
      "step": 18880
    },
    {
      "epoch": 3.4473948352951913,
      "grad_norm": 25.611724853515625,
      "learning_rate": 2.5002752798678658e-05,
      "logits/chosen": -0.35999029874801636,
      "logits/rejected": -0.0884585976600647,
      "logps/chosen": -185.05130004882812,
      "logps/rejected": -210.32138061523438,
      "loss": 0.1901,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.132603168487549,
      "rewards/margins": 4.594718933105469,
      "rewards/rejected": -9.727323532104492,
      "step": 18890
    },
    {
      "epoch": 3.449219819326581,
      "grad_norm": 6.8966851234436035,
      "learning_rate": 2.497338961277299e-05,
      "logits/chosen": -0.5826647281646729,
      "logits/rejected": -0.324836790561676,
      "logps/chosen": -195.4247589111328,
      "logps/rejected": -231.92318725585938,
      "loss": 0.1245,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.697308540344238,
      "rewards/margins": 4.56657075881958,
      "rewards/rejected": -9.263879776000977,
      "step": 18900
    },
    {
      "epoch": 3.451044803357971,
      "grad_norm": 1.8367019891738892,
      "learning_rate": 2.4944026426867317e-05,
      "logits/chosen": -0.39385291934013367,
      "logits/rejected": 0.039796799421310425,
      "logps/chosen": -211.36642456054688,
      "logps/rejected": -228.10775756835938,
      "loss": 0.0565,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.199278831481934,
      "rewards/margins": 4.957646369934082,
      "rewards/rejected": -10.1569242477417,
      "step": 18910
    },
    {
      "epoch": 3.4528697873893606,
      "grad_norm": 8.020214080810547,
      "learning_rate": 2.4917599559552215e-05,
      "logits/chosen": -0.34643253684043884,
      "logits/rejected": 0.01626107096672058,
      "logps/chosen": -207.82632446289062,
      "logps/rejected": -239.7595977783203,
      "loss": 0.2293,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.209958076477051,
      "rewards/margins": 4.580564498901367,
      "rewards/rejected": -9.790522575378418,
      "step": 18920
    },
    {
      "epoch": 3.45469477142075,
      "grad_norm": 4.807972431182861,
      "learning_rate": 2.488823637364654e-05,
      "logits/chosen": -0.37378379702568054,
      "logits/rejected": 0.16079001128673553,
      "logps/chosen": -208.07138061523438,
      "logps/rejected": -237.64926147460938,
      "loss": 0.1239,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.773825645446777,
      "rewards/margins": 5.0670576095581055,
      "rewards/rejected": -10.840883255004883,
      "step": 18930
    },
    {
      "epoch": 3.4565197554521396,
      "grad_norm": 6.841171741485596,
      "learning_rate": 2.485887318774087e-05,
      "logits/chosen": -0.5710465312004089,
      "logits/rejected": -0.2644607126712799,
      "logps/chosen": -180.23731994628906,
      "logps/rejected": -234.20559692382812,
      "loss": 0.1836,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.257482051849365,
      "rewards/margins": 5.530343055725098,
      "rewards/rejected": -9.787824630737305,
      "step": 18940
    },
    {
      "epoch": 3.4583447394835294,
      "grad_norm": 2.1086385250091553,
      "learning_rate": 2.48295100018352e-05,
      "logits/chosen": -0.46352142095565796,
      "logits/rejected": -0.1773180514574051,
      "logps/chosen": -202.45938110351562,
      "logps/rejected": -227.30691528320312,
      "loss": 0.2061,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.594399452209473,
      "rewards/margins": 4.475245952606201,
      "rewards/rejected": -10.069644927978516,
      "step": 18950
    },
    {
      "epoch": 3.460169723514919,
      "grad_norm": 8.513592720031738,
      "learning_rate": 2.480014681592953e-05,
      "logits/chosen": -0.5833041071891785,
      "logits/rejected": -0.3596358597278595,
      "logps/chosen": -184.13088989257812,
      "logps/rejected": -230.21774291992188,
      "loss": 0.1677,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.515241622924805,
      "rewards/margins": 4.425704479217529,
      "rewards/rejected": -8.940946578979492,
      "step": 18960
    },
    {
      "epoch": 3.461994707546309,
      "grad_norm": 1.7715953588485718,
      "learning_rate": 2.477078363002386e-05,
      "logits/chosen": -0.4630265235900879,
      "logits/rejected": -0.15616793930530548,
      "logps/chosen": -180.01516723632812,
      "logps/rejected": -209.1829071044922,
      "loss": 0.0995,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -4.005532741546631,
      "rewards/margins": 5.45697021484375,
      "rewards/rejected": -9.462503433227539,
      "step": 18970
    },
    {
      "epoch": 3.4638196915776986,
      "grad_norm": 6.513146877288818,
      "learning_rate": 2.474142044411819e-05,
      "logits/chosen": -0.3706006705760956,
      "logits/rejected": -0.006179189775139093,
      "logps/chosen": -201.2764129638672,
      "logps/rejected": -219.3508758544922,
      "loss": 0.1863,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.547272205352783,
      "rewards/margins": 4.942631244659424,
      "rewards/rejected": -10.489903450012207,
      "step": 18980
    },
    {
      "epoch": 3.4656446756090884,
      "grad_norm": 11.90420150756836,
      "learning_rate": 2.4712057258212518e-05,
      "logits/chosen": -0.4410865306854248,
      "logits/rejected": 0.1881342977285385,
      "logps/chosen": -221.55905151367188,
      "logps/rejected": -221.97994995117188,
      "loss": 0.1676,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.696301460266113,
      "rewards/margins": 5.0228190422058105,
      "rewards/rejected": -10.719120025634766,
      "step": 18990
    },
    {
      "epoch": 3.467469659640478,
      "grad_norm": 8.889901161193848,
      "learning_rate": 2.468269407230685e-05,
      "logits/chosen": -0.2675737738609314,
      "logits/rejected": 0.03323281556367874,
      "logps/chosen": -186.02963256835938,
      "logps/rejected": -215.8730926513672,
      "loss": 0.1807,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.458357810974121,
      "rewards/margins": 4.325662136077881,
      "rewards/rejected": -9.784019470214844,
      "step": 19000
    },
    {
      "epoch": 3.469294643671868,
      "grad_norm": 8.864402770996094,
      "learning_rate": 2.4653330886401174e-05,
      "logits/chosen": -0.3455054759979248,
      "logits/rejected": -0.05507425218820572,
      "logps/chosen": -174.36972045898438,
      "logps/rejected": -227.43557739257812,
      "loss": 0.2156,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.412897109985352,
      "rewards/margins": 5.5482635498046875,
      "rewards/rejected": -10.961160659790039,
      "step": 19010
    },
    {
      "epoch": 3.4711196277032577,
      "grad_norm": 0.7260721921920776,
      "learning_rate": 2.4623967700495505e-05,
      "logits/chosen": -0.5686089396476746,
      "logits/rejected": -0.07820876687765121,
      "logps/chosen": -193.10452270507812,
      "logps/rejected": -220.5029754638672,
      "loss": 0.1735,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.425344467163086,
      "rewards/margins": 5.136212348937988,
      "rewards/rejected": -9.561556816101074,
      "step": 19020
    },
    {
      "epoch": 3.4729446117346474,
      "grad_norm": 10.375364303588867,
      "learning_rate": 2.4594604514589837e-05,
      "logits/chosen": -0.3284849524497986,
      "logits/rejected": -0.10288427025079727,
      "logps/chosen": -189.5199432373047,
      "logps/rejected": -230.3091278076172,
      "loss": 0.1202,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.5947675704956055,
      "rewards/margins": 5.187594413757324,
      "rewards/rejected": -9.78236198425293,
      "step": 19030
    },
    {
      "epoch": 3.474769595766037,
      "grad_norm": 13.991777420043945,
      "learning_rate": 2.4565241328684164e-05,
      "logits/chosen": -0.3406531512737274,
      "logits/rejected": -0.07637107372283936,
      "logps/chosen": -208.61196899414062,
      "logps/rejected": -233.24472045898438,
      "loss": 0.1423,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.074746608734131,
      "rewards/margins": 5.06299352645874,
      "rewards/rejected": -10.137740135192871,
      "step": 19040
    },
    {
      "epoch": 3.476594579797427,
      "grad_norm": 13.257033348083496,
      "learning_rate": 2.4535878142778496e-05,
      "logits/chosen": -0.32281941175460815,
      "logits/rejected": 0.01631859503686428,
      "logps/chosen": -213.08523559570312,
      "logps/rejected": -217.7484893798828,
      "loss": 0.3131,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.767792701721191,
      "rewards/margins": 4.283392429351807,
      "rewards/rejected": -10.051183700561523,
      "step": 19050
    },
    {
      "epoch": 3.4784195638288167,
      "grad_norm": 0.2838582992553711,
      "learning_rate": 2.4506514956872824e-05,
      "logits/chosen": -0.40616145730018616,
      "logits/rejected": 0.30497828125953674,
      "logps/chosen": -207.320556640625,
      "logps/rejected": -230.03250122070312,
      "loss": 0.119,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.709206581115723,
      "rewards/margins": 5.704836845397949,
      "rewards/rejected": -11.414043426513672,
      "step": 19060
    },
    {
      "epoch": 3.480244547860206,
      "grad_norm": 17.342937469482422,
      "learning_rate": 2.4477151770967155e-05,
      "logits/chosen": -0.3874731659889221,
      "logits/rejected": -0.05977008491754532,
      "logps/chosen": -200.18963623046875,
      "logps/rejected": -230.29788208007812,
      "loss": 0.1503,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.422126293182373,
      "rewards/margins": 4.926488876342773,
      "rewards/rejected": -10.348614692687988,
      "step": 19070
    },
    {
      "epoch": 3.4820695318915957,
      "grad_norm": 1.5522160530090332,
      "learning_rate": 2.444778858506148e-05,
      "logits/chosen": -0.444312185049057,
      "logits/rejected": 0.1528482437133789,
      "logps/chosen": -219.7100372314453,
      "logps/rejected": -235.8323516845703,
      "loss": 0.0942,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.267032146453857,
      "rewards/margins": 5.593564033508301,
      "rewards/rejected": -11.860596656799316,
      "step": 19080
    },
    {
      "epoch": 3.4838945159229855,
      "grad_norm": 1.9125398397445679,
      "learning_rate": 2.441842539915581e-05,
      "logits/chosen": -0.0683799535036087,
      "logits/rejected": 0.15664994716644287,
      "logps/chosen": -183.4423370361328,
      "logps/rejected": -238.46774291992188,
      "loss": 0.1212,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.460949897766113,
      "rewards/margins": 5.007386207580566,
      "rewards/rejected": -11.46833610534668,
      "step": 19090
    },
    {
      "epoch": 3.4857194999543752,
      "grad_norm": 0.9408531188964844,
      "learning_rate": 2.438906221325014e-05,
      "logits/chosen": -0.3691334128379822,
      "logits/rejected": -0.07878049463033676,
      "logps/chosen": -203.1125030517578,
      "logps/rejected": -231.60330200195312,
      "loss": 0.352,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.849113464355469,
      "rewards/margins": 4.753029823303223,
      "rewards/rejected": -10.602144241333008,
      "step": 19100
    },
    {
      "epoch": 3.487544483985765,
      "grad_norm": 14.471656799316406,
      "learning_rate": 2.435969902734447e-05,
      "logits/chosen": -0.33303019404411316,
      "logits/rejected": 0.03288687393069267,
      "logps/chosen": -200.81674194335938,
      "logps/rejected": -238.979248046875,
      "loss": 0.163,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.182908058166504,
      "rewards/margins": 4.874759674072266,
      "rewards/rejected": -11.05766773223877,
      "step": 19110
    },
    {
      "epoch": 3.4893694680171548,
      "grad_norm": 5.414536476135254,
      "learning_rate": 2.43303358414388e-05,
      "logits/chosen": -0.4711328148841858,
      "logits/rejected": -0.17540675401687622,
      "logps/chosen": -213.140625,
      "logps/rejected": -235.4857940673828,
      "loss": 0.177,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.447651386260986,
      "rewards/margins": 4.882891654968262,
      "rewards/rejected": -10.330543518066406,
      "step": 19120
    },
    {
      "epoch": 3.4911944520485445,
      "grad_norm": 3.3189830780029297,
      "learning_rate": 2.430097265553313e-05,
      "logits/chosen": -0.23927195370197296,
      "logits/rejected": 0.08226090669631958,
      "logps/chosen": -190.89271545410156,
      "logps/rejected": -223.28421020507812,
      "loss": 0.1584,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.8629655838012695,
      "rewards/margins": 5.057257652282715,
      "rewards/rejected": -9.920222282409668,
      "step": 19130
    },
    {
      "epoch": 3.4930194360799343,
      "grad_norm": 10.819971084594727,
      "learning_rate": 2.4271609469627454e-05,
      "logits/chosen": -0.06765260547399521,
      "logits/rejected": 0.37529149651527405,
      "logps/chosen": -210.978271484375,
      "logps/rejected": -239.4716339111328,
      "loss": 0.1322,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.3649210929870605,
      "rewards/margins": 4.972052097320557,
      "rewards/rejected": -11.336974143981934,
      "step": 19140
    },
    {
      "epoch": 3.494844420111324,
      "grad_norm": 10.33198070526123,
      "learning_rate": 2.4242246283721786e-05,
      "logits/chosen": 0.06592841446399689,
      "logits/rejected": 0.18415209650993347,
      "logps/chosen": -202.44644165039062,
      "logps/rejected": -255.51889038085938,
      "loss": 0.2587,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.878846168518066,
      "rewards/margins": 4.588447570800781,
      "rewards/rejected": -11.467294692993164,
      "step": 19150
    },
    {
      "epoch": 3.4966694041427138,
      "grad_norm": 4.355463981628418,
      "learning_rate": 2.4212883097816114e-05,
      "logits/chosen": -0.109166719019413,
      "logits/rejected": 0.2159971445798874,
      "logps/chosen": -223.58517456054688,
      "logps/rejected": -264.5716857910156,
      "loss": 0.2186,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -7.069127559661865,
      "rewards/margins": 4.5216875076293945,
      "rewards/rejected": -11.590815544128418,
      "step": 19160
    },
    {
      "epoch": 3.4984943881741035,
      "grad_norm": 6.0769429206848145,
      "learning_rate": 2.4183519911910445e-05,
      "logits/chosen": -0.24841146171092987,
      "logits/rejected": 0.42248114943504333,
      "logps/chosen": -206.0118408203125,
      "logps/rejected": -213.6381378173828,
      "loss": 0.1104,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.517265319824219,
      "rewards/margins": 5.319474220275879,
      "rewards/rejected": -10.836739540100098,
      "step": 19170
    },
    {
      "epoch": 3.5003193722054933,
      "grad_norm": 9.140349388122559,
      "learning_rate": 2.4154156726004773e-05,
      "logits/chosen": -0.042871661484241486,
      "logits/rejected": 0.28182435035705566,
      "logps/chosen": -205.82876586914062,
      "logps/rejected": -238.8246612548828,
      "loss": 0.1704,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.8051042556762695,
      "rewards/margins": 5.1193037033081055,
      "rewards/rejected": -11.924408912658691,
      "step": 19180
    },
    {
      "epoch": 3.502144356236883,
      "grad_norm": 7.930717945098877,
      "learning_rate": 2.4124793540099104e-05,
      "logits/chosen": -0.2025895118713379,
      "logits/rejected": 0.05057680606842041,
      "logps/chosen": -197.45199584960938,
      "logps/rejected": -235.9553680419922,
      "loss": 0.1944,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.856953144073486,
      "rewards/margins": 5.095874786376953,
      "rewards/rejected": -10.952825546264648,
      "step": 19190
    },
    {
      "epoch": 3.503969340268273,
      "grad_norm": 5.4678874015808105,
      "learning_rate": 2.409543035419343e-05,
      "logits/chosen": -0.37334147095680237,
      "logits/rejected": 0.1720365732908249,
      "logps/chosen": -217.5826416015625,
      "logps/rejected": -218.25244140625,
      "loss": 0.2339,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.920970916748047,
      "rewards/margins": 4.694258689880371,
      "rewards/rejected": -10.615229606628418,
      "step": 19200
    },
    {
      "epoch": 3.5057943242996625,
      "grad_norm": 3.6916966438293457,
      "learning_rate": 2.406606716828776e-05,
      "logits/chosen": -0.45861878991127014,
      "logits/rejected": -0.014305336400866508,
      "logps/chosen": -213.28079223632812,
      "logps/rejected": -220.6539306640625,
      "loss": 0.1672,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.99361515045166,
      "rewards/margins": 4.954391002655029,
      "rewards/rejected": -10.948005676269531,
      "step": 19210
    },
    {
      "epoch": 3.5076193083310523,
      "grad_norm": 3.420642614364624,
      "learning_rate": 2.403670398238209e-05,
      "logits/chosen": -0.2691895067691803,
      "logits/rejected": 0.11413197219371796,
      "logps/chosen": -206.53085327148438,
      "logps/rejected": -238.2537078857422,
      "loss": 0.0994,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.229721546173096,
      "rewards/margins": 5.2351884841918945,
      "rewards/rejected": -11.464910507202148,
      "step": 19220
    },
    {
      "epoch": 3.509444292362442,
      "grad_norm": 2.2621920108795166,
      "learning_rate": 2.400734079647642e-05,
      "logits/chosen": -0.24867796897888184,
      "logits/rejected": 0.029649779200553894,
      "logps/chosen": -195.8268585205078,
      "logps/rejected": -228.07919311523438,
      "loss": 0.2069,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.670402526855469,
      "rewards/margins": 4.598112106323242,
      "rewards/rejected": -11.268515586853027,
      "step": 19230
    },
    {
      "epoch": 3.511269276393832,
      "grad_norm": 6.29203462600708,
      "learning_rate": 2.397797761057075e-05,
      "logits/chosen": -0.537165641784668,
      "logits/rejected": -0.0679955929517746,
      "logps/chosen": -203.79782104492188,
      "logps/rejected": -220.0174102783203,
      "loss": 0.1211,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.44869327545166,
      "rewards/margins": 5.396728992462158,
      "rewards/rejected": -9.845422744750977,
      "step": 19240
    },
    {
      "epoch": 3.5130942604252215,
      "grad_norm": 13.008445739746094,
      "learning_rate": 2.394861442466508e-05,
      "logits/chosen": -0.6080762147903442,
      "logits/rejected": -0.4392562806606293,
      "logps/chosen": -193.2774200439453,
      "logps/rejected": -228.7845458984375,
      "loss": 0.1484,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.483660697937012,
      "rewards/margins": 4.555491924285889,
      "rewards/rejected": -9.039152145385742,
      "step": 19250
    },
    {
      "epoch": 3.514919244456611,
      "grad_norm": 18.5578670501709,
      "learning_rate": 2.391925123875941e-05,
      "logits/chosen": -0.2770236134529114,
      "logits/rejected": -0.01006691437214613,
      "logps/chosen": -199.71371459960938,
      "logps/rejected": -231.13131713867188,
      "loss": 0.1693,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.692944526672363,
      "rewards/margins": 4.732009410858154,
      "rewards/rejected": -10.424954414367676,
      "step": 19260
    },
    {
      "epoch": 3.5167442284880006,
      "grad_norm": 4.8955464363098145,
      "learning_rate": 2.3889888052853735e-05,
      "logits/chosen": -0.11345891654491425,
      "logits/rejected": 0.31335872411727905,
      "logps/chosen": -198.74044799804688,
      "logps/rejected": -253.81436157226562,
      "loss": 0.0563,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.089509963989258,
      "rewards/margins": 5.832293510437012,
      "rewards/rejected": -11.921804428100586,
      "step": 19270
    },
    {
      "epoch": 3.5185692125193904,
      "grad_norm": 5.150409698486328,
      "learning_rate": 2.3860524866948066e-05,
      "logits/chosen": -0.5118681192398071,
      "logits/rejected": -0.055665113031864166,
      "logps/chosen": -235.89501953125,
      "logps/rejected": -253.84176635742188,
      "loss": 0.0867,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.359078407287598,
      "rewards/margins": 5.637609958648682,
      "rewards/rejected": -10.996686935424805,
      "step": 19280
    },
    {
      "epoch": 3.52039419655078,
      "grad_norm": 5.740964889526367,
      "learning_rate": 2.3831161681042394e-05,
      "logits/chosen": -0.5100599527359009,
      "logits/rejected": 0.015653612092137337,
      "logps/chosen": -201.32762145996094,
      "logps/rejected": -233.38076782226562,
      "loss": 0.1432,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.081865310668945,
      "rewards/margins": 5.524590492248535,
      "rewards/rejected": -10.606454849243164,
      "step": 19290
    },
    {
      "epoch": 3.52221918058217,
      "grad_norm": 0.6778745651245117,
      "learning_rate": 2.3801798495136725e-05,
      "logits/chosen": -0.6069955825805664,
      "logits/rejected": -0.3431270122528076,
      "logps/chosen": -210.9186553955078,
      "logps/rejected": -239.6623077392578,
      "loss": 0.1664,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.246875286102295,
      "rewards/margins": 4.84998083114624,
      "rewards/rejected": -10.096857070922852,
      "step": 19300
    },
    {
      "epoch": 3.5240441646135596,
      "grad_norm": 0.9517102837562561,
      "learning_rate": 2.3772435309231053e-05,
      "logits/chosen": -0.5378642082214355,
      "logits/rejected": -0.04967811703681946,
      "logps/chosen": -224.79562377929688,
      "logps/rejected": -248.81417846679688,
      "loss": 0.0986,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.958123207092285,
      "rewards/margins": 5.520704746246338,
      "rewards/rejected": -11.478827476501465,
      "step": 19310
    },
    {
      "epoch": 3.5258691486449494,
      "grad_norm": 8.175856590270996,
      "learning_rate": 2.3743072123325385e-05,
      "logits/chosen": -0.5630191564559937,
      "logits/rejected": 0.041894108057022095,
      "logps/chosen": -202.53880310058594,
      "logps/rejected": -207.03384399414062,
      "loss": 0.1739,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.868998050689697,
      "rewards/margins": 4.913980007171631,
      "rewards/rejected": -9.782978057861328,
      "step": 19320
    },
    {
      "epoch": 3.527694132676339,
      "grad_norm": 3.207726240158081,
      "learning_rate": 2.371370893741971e-05,
      "logits/chosen": -0.6372038125991821,
      "logits/rejected": -0.19796836376190186,
      "logps/chosen": -198.16546630859375,
      "logps/rejected": -225.72262573242188,
      "loss": 0.1274,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.6506853103637695,
      "rewards/margins": 5.589156627655029,
      "rewards/rejected": -10.239842414855957,
      "step": 19330
    },
    {
      "epoch": 3.529519116707729,
      "grad_norm": 11.967330932617188,
      "learning_rate": 2.368434575151404e-05,
      "logits/chosen": -0.27718257904052734,
      "logits/rejected": 0.03659152239561081,
      "logps/chosen": -212.80068969726562,
      "logps/rejected": -246.18203735351562,
      "loss": 0.1811,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.773209571838379,
      "rewards/margins": 5.228105545043945,
      "rewards/rejected": -11.001314163208008,
      "step": 19340
    },
    {
      "epoch": 3.5313441007391186,
      "grad_norm": 7.789709568023682,
      "learning_rate": 2.365498256560837e-05,
      "logits/chosen": -0.4956184923648834,
      "logits/rejected": 0.2224937379360199,
      "logps/chosen": -235.5169677734375,
      "logps/rejected": -232.3238983154297,
      "loss": 0.2118,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.979604244232178,
      "rewards/margins": 4.8864898681640625,
      "rewards/rejected": -10.866093635559082,
      "step": 19350
    },
    {
      "epoch": 3.5331690847705084,
      "grad_norm": 11.889321327209473,
      "learning_rate": 2.36256193797027e-05,
      "logits/chosen": -0.21100100874900818,
      "logits/rejected": 0.08664746582508087,
      "logps/chosen": -197.01553344726562,
      "logps/rejected": -236.0814666748047,
      "loss": 0.1453,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.73239803314209,
      "rewards/margins": 5.004111289978027,
      "rewards/rejected": -10.736510276794434,
      "step": 19360
    },
    {
      "epoch": 3.534994068801898,
      "grad_norm": 5.973931312561035,
      "learning_rate": 2.3596256193797028e-05,
      "logits/chosen": -0.3132878839969635,
      "logits/rejected": 0.12355732917785645,
      "logps/chosen": -205.5322265625,
      "logps/rejected": -236.4722137451172,
      "loss": 0.1241,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.52740478515625,
      "rewards/margins": 5.020554542541504,
      "rewards/rejected": -10.54796028137207,
      "step": 19370
    },
    {
      "epoch": 3.5368190528332875,
      "grad_norm": 2.613823413848877,
      "learning_rate": 2.356689300789136e-05,
      "logits/chosen": -0.24778051674365997,
      "logits/rejected": 0.07249046862125397,
      "logps/chosen": -211.477294921875,
      "logps/rejected": -225.0596466064453,
      "loss": 0.1618,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.577243804931641,
      "rewards/margins": 4.1958537101745605,
      "rewards/rejected": -9.773097038269043,
      "step": 19380
    },
    {
      "epoch": 3.538644036864677,
      "grad_norm": 13.863811492919922,
      "learning_rate": 2.353752982198569e-05,
      "logits/chosen": -0.08341360837221146,
      "logits/rejected": 0.21055416762828827,
      "logps/chosen": -197.45321655273438,
      "logps/rejected": -245.6386260986328,
      "loss": 0.2351,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.235653877258301,
      "rewards/margins": 4.822176933288574,
      "rewards/rejected": -11.057830810546875,
      "step": 19390
    },
    {
      "epoch": 3.540469020896067,
      "grad_norm": 4.275744915008545,
      "learning_rate": 2.3508166636080015e-05,
      "logits/chosen": -0.17815861105918884,
      "logits/rejected": 0.13269451260566711,
      "logps/chosen": -227.8500518798828,
      "logps/rejected": -237.71548461914062,
      "loss": 0.2046,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.1620259284973145,
      "rewards/margins": 4.955002784729004,
      "rewards/rejected": -11.11702823638916,
      "step": 19400
    },
    {
      "epoch": 3.5422940049274567,
      "grad_norm": 2.3864405155181885,
      "learning_rate": 2.3478803450174346e-05,
      "logits/chosen": -0.37390652298927307,
      "logits/rejected": -0.016061175614595413,
      "logps/chosen": -200.63009643554688,
      "logps/rejected": -247.53231811523438,
      "loss": 0.0619,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.192334175109863,
      "rewards/margins": 5.55004358291626,
      "rewards/rejected": -11.742379188537598,
      "step": 19410
    },
    {
      "epoch": 3.5441189889588465,
      "grad_norm": 3.2710320949554443,
      "learning_rate": 2.3449440264268674e-05,
      "logits/chosen": -0.1684395968914032,
      "logits/rejected": 0.19977127015590668,
      "logps/chosen": -203.96206665039062,
      "logps/rejected": -238.7169189453125,
      "loss": 0.196,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.543630123138428,
      "rewards/margins": 5.311761379241943,
      "rewards/rejected": -11.855391502380371,
      "step": 19420
    },
    {
      "epoch": 3.5459439729902362,
      "grad_norm": 0.8065267205238342,
      "learning_rate": 2.3420077078363006e-05,
      "logits/chosen": -0.3618459105491638,
      "logits/rejected": -0.045732282102108,
      "logps/chosen": -186.11361694335938,
      "logps/rejected": -231.14114379882812,
      "loss": 0.1939,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.883915901184082,
      "rewards/margins": 4.844977378845215,
      "rewards/rejected": -9.72889232635498,
      "step": 19430
    },
    {
      "epoch": 3.547768957021626,
      "grad_norm": 5.35443115234375,
      "learning_rate": 2.3390713892457334e-05,
      "logits/chosen": -0.6290476322174072,
      "logits/rejected": -0.022627392783761024,
      "logps/chosen": -212.37496948242188,
      "logps/rejected": -219.8084716796875,
      "loss": 0.1287,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.350709915161133,
      "rewards/margins": 5.3299174308776855,
      "rewards/rejected": -10.680627822875977,
      "step": 19440
    },
    {
      "epoch": 3.5495939410530157,
      "grad_norm": 17.83741569519043,
      "learning_rate": 2.3361350706551665e-05,
      "logits/chosen": -0.49410462379455566,
      "logits/rejected": -0.23495309054851532,
      "logps/chosen": -194.63623046875,
      "logps/rejected": -222.45053100585938,
      "loss": 0.3239,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -4.923791885375977,
      "rewards/margins": 4.595822334289551,
      "rewards/rejected": -9.519614219665527,
      "step": 19450
    },
    {
      "epoch": 3.5514189250844055,
      "grad_norm": 16.264719009399414,
      "learning_rate": 2.333198752064599e-05,
      "logits/chosen": -0.37943485379219055,
      "logits/rejected": -0.1704452931880951,
      "logps/chosen": -191.10763549804688,
      "logps/rejected": -237.74655151367188,
      "loss": 0.2882,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.625397682189941,
      "rewards/margins": 3.996830463409424,
      "rewards/rejected": -9.622228622436523,
      "step": 19460
    },
    {
      "epoch": 3.5532439091157952,
      "grad_norm": 7.898274898529053,
      "learning_rate": 2.330262433474032e-05,
      "logits/chosen": -0.5340371131896973,
      "logits/rejected": -0.25612711906433105,
      "logps/chosen": -185.42898559570312,
      "logps/rejected": -219.78076171875,
      "loss": 0.1486,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.973868370056152,
      "rewards/margins": 4.5581278800964355,
      "rewards/rejected": -9.53199577331543,
      "step": 19470
    },
    {
      "epoch": 3.555068893147185,
      "grad_norm": 8.14328384399414,
      "learning_rate": 2.327326114883465e-05,
      "logits/chosen": -0.47281861305236816,
      "logits/rejected": -0.16192160546779633,
      "logps/chosen": -209.4956512451172,
      "logps/rejected": -241.0320281982422,
      "loss": 0.1278,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.2382707595825195,
      "rewards/margins": 4.659532070159912,
      "rewards/rejected": -9.89780330657959,
      "step": 19480
    },
    {
      "epoch": 3.5568938771785747,
      "grad_norm": 7.009483814239502,
      "learning_rate": 2.324389796292898e-05,
      "logits/chosen": -0.4247635304927826,
      "logits/rejected": -0.2185739278793335,
      "logps/chosen": -193.44564819335938,
      "logps/rejected": -239.0178985595703,
      "loss": 0.1725,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.882720470428467,
      "rewards/margins": 4.600683689117432,
      "rewards/rejected": -10.483404159545898,
      "step": 19490
    },
    {
      "epoch": 3.5587188612099645,
      "grad_norm": 5.813604354858398,
      "learning_rate": 2.321453477702331e-05,
      "logits/chosen": -0.4380408227443695,
      "logits/rejected": -0.017651524394750595,
      "logps/chosen": -193.76031494140625,
      "logps/rejected": -219.6543426513672,
      "loss": 0.1079,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.391102313995361,
      "rewards/margins": 4.690086364746094,
      "rewards/rejected": -10.081189155578613,
      "step": 19500
    },
    {
      "epoch": 3.5605438452413543,
      "grad_norm": 2.6362216472625732,
      "learning_rate": 2.318517159111764e-05,
      "logits/chosen": -0.24531328678131104,
      "logits/rejected": 0.1206427812576294,
      "logps/chosen": -214.86361694335938,
      "logps/rejected": -247.8037109375,
      "loss": 0.1035,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.583226680755615,
      "rewards/margins": 5.152787685394287,
      "rewards/rejected": -11.736013412475586,
      "step": 19510
    },
    {
      "epoch": 3.562368829272744,
      "grad_norm": 19.291894912719727,
      "learning_rate": 2.3155808405211964e-05,
      "logits/chosen": -0.3884003758430481,
      "logits/rejected": -0.0541134849190712,
      "logps/chosen": -228.3722381591797,
      "logps/rejected": -243.4806365966797,
      "loss": 0.2505,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -7.1177191734313965,
      "rewards/margins": 4.1672868728637695,
      "rewards/rejected": -11.285005569458008,
      "step": 19520
    },
    {
      "epoch": 3.5641938133041338,
      "grad_norm": 0.3095041513442993,
      "learning_rate": 2.3126445219306296e-05,
      "logits/chosen": -0.2827332615852356,
      "logits/rejected": -0.02795073390007019,
      "logps/chosen": -194.00167846679688,
      "logps/rejected": -249.40927124023438,
      "loss": 0.0868,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.524374961853027,
      "rewards/margins": 5.819449424743652,
      "rewards/rejected": -11.34382438659668,
      "step": 19530
    },
    {
      "epoch": 3.5660187973355235,
      "grad_norm": 10.950148582458496,
      "learning_rate": 2.3097082033400624e-05,
      "logits/chosen": -0.2613307237625122,
      "logits/rejected": 0.03671606630086899,
      "logps/chosen": -196.3225860595703,
      "logps/rejected": -238.8125457763672,
      "loss": 0.1059,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.1435770988464355,
      "rewards/margins": 4.769492149353027,
      "rewards/rejected": -10.913068771362305,
      "step": 19540
    },
    {
      "epoch": 3.5678437813669133,
      "grad_norm": 9.284439086914062,
      "learning_rate": 2.3067718847494955e-05,
      "logits/chosen": -0.293182909488678,
      "logits/rejected": 0.029488850384950638,
      "logps/chosen": -206.7245635986328,
      "logps/rejected": -234.79891967773438,
      "loss": 0.1613,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.293122291564941,
      "rewards/margins": 4.78544807434082,
      "rewards/rejected": -11.078570365905762,
      "step": 19550
    },
    {
      "epoch": 3.569668765398303,
      "grad_norm": 10.979438781738281,
      "learning_rate": 2.3038355661589283e-05,
      "logits/chosen": -0.15599194169044495,
      "logits/rejected": 0.26566529273986816,
      "logps/chosen": -224.4225311279297,
      "logps/rejected": -237.46585083007812,
      "loss": 0.2423,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.452033042907715,
      "rewards/margins": 4.435214042663574,
      "rewards/rejected": -10.887247085571289,
      "step": 19560
    },
    {
      "epoch": 3.5714937494296923,
      "grad_norm": 1.7830168008804321,
      "learning_rate": 2.3008992475683614e-05,
      "logits/chosen": -0.4306625425815582,
      "logits/rejected": -0.1898852288722992,
      "logps/chosen": -201.0067596435547,
      "logps/rejected": -247.7838134765625,
      "loss": 0.1033,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.270115375518799,
      "rewards/margins": 4.449341773986816,
      "rewards/rejected": -10.719457626342773,
      "step": 19570
    },
    {
      "epoch": 3.573318733461082,
      "grad_norm": 8.8353910446167,
      "learning_rate": 2.2979629289777946e-05,
      "logits/chosen": -0.18933595716953278,
      "logits/rejected": 0.1812957227230072,
      "logps/chosen": -202.20394897460938,
      "logps/rejected": -248.30947875976562,
      "loss": 0.1671,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.217392921447754,
      "rewards/margins": 5.453682899475098,
      "rewards/rejected": -11.671075820922852,
      "step": 19580
    },
    {
      "epoch": 3.575143717492472,
      "grad_norm": 0.277782142162323,
      "learning_rate": 2.295026610387227e-05,
      "logits/chosen": -0.32594621181488037,
      "logits/rejected": 0.28572916984558105,
      "logps/chosen": -232.512451171875,
      "logps/rejected": -242.71286010742188,
      "loss": 0.103,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.590693473815918,
      "rewards/margins": 5.173306941986084,
      "rewards/rejected": -11.763999938964844,
      "step": 19590
    },
    {
      "epoch": 3.5769687015238616,
      "grad_norm": 9.48940372467041,
      "learning_rate": 2.29209029179666e-05,
      "logits/chosen": -0.15440134704113007,
      "logits/rejected": 0.04883263632655144,
      "logps/chosen": -212.3140106201172,
      "logps/rejected": -244.7986602783203,
      "loss": 0.17,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.222771644592285,
      "rewards/margins": 4.528928756713867,
      "rewards/rejected": -10.751700401306152,
      "step": 19600
    },
    {
      "epoch": 3.5787936855552513,
      "grad_norm": 4.348690032958984,
      "learning_rate": 2.289153973206093e-05,
      "logits/chosen": -0.24301941692829132,
      "logits/rejected": 0.2463555634021759,
      "logps/chosen": -221.15463256835938,
      "logps/rejected": -258.24053955078125,
      "loss": 0.0817,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.397071838378906,
      "rewards/margins": 5.307000637054443,
      "rewards/rejected": -11.704071998596191,
      "step": 19610
    },
    {
      "epoch": 3.580618669586641,
      "grad_norm": 10.96483325958252,
      "learning_rate": 2.286217654615526e-05,
      "logits/chosen": -0.34065550565719604,
      "logits/rejected": 0.07859985530376434,
      "logps/chosen": -218.6492462158203,
      "logps/rejected": -241.30184936523438,
      "loss": 0.227,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.06776762008667,
      "rewards/margins": 4.808900356292725,
      "rewards/rejected": -10.876668930053711,
      "step": 19620
    },
    {
      "epoch": 3.582443653618031,
      "grad_norm": 13.399405479431152,
      "learning_rate": 2.283281336024959e-05,
      "logits/chosen": -0.4109748899936676,
      "logits/rejected": 0.1787700653076172,
      "logps/chosen": -219.650146484375,
      "logps/rejected": -240.41586303710938,
      "loss": 0.1053,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.547397613525391,
      "rewards/margins": 5.338284492492676,
      "rewards/rejected": -10.885682106018066,
      "step": 19630
    },
    {
      "epoch": 3.5842686376494206,
      "grad_norm": 0.7063053846359253,
      "learning_rate": 2.280345017434392e-05,
      "logits/chosen": -0.24374142289161682,
      "logits/rejected": 0.01872200146317482,
      "logps/chosen": -197.28903198242188,
      "logps/rejected": -237.76168823242188,
      "loss": 0.1078,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.1848249435424805,
      "rewards/margins": 5.018913745880127,
      "rewards/rejected": -11.203737258911133,
      "step": 19640
    },
    {
      "epoch": 3.5860936216808104,
      "grad_norm": 5.692749500274658,
      "learning_rate": 2.2774086988438248e-05,
      "logits/chosen": -0.3918835520744324,
      "logits/rejected": -0.026699265465140343,
      "logps/chosen": -223.28689575195312,
      "logps/rejected": -247.5523681640625,
      "loss": 0.1125,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.976042747497559,
      "rewards/margins": 5.113711357116699,
      "rewards/rejected": -11.089754104614258,
      "step": 19650
    },
    {
      "epoch": 3.5879186057122,
      "grad_norm": 5.216938018798828,
      "learning_rate": 2.274472380253258e-05,
      "logits/chosen": -0.4131682515144348,
      "logits/rejected": 0.004517597146332264,
      "logps/chosen": -196.1771240234375,
      "logps/rejected": -230.0522918701172,
      "loss": 0.1787,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.397220611572266,
      "rewards/margins": 4.5966386795043945,
      "rewards/rejected": -9.993860244750977,
      "step": 19660
    },
    {
      "epoch": 3.58974358974359,
      "grad_norm": 7.51249361038208,
      "learning_rate": 2.2715360616626904e-05,
      "logits/chosen": -0.054904449731111526,
      "logits/rejected": 0.21168534457683563,
      "logps/chosen": -200.3172149658203,
      "logps/rejected": -240.3563232421875,
      "loss": 0.1987,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.277606010437012,
      "rewards/margins": 5.026730060577393,
      "rewards/rejected": -11.304335594177246,
      "step": 19670
    },
    {
      "epoch": 3.5915685737749796,
      "grad_norm": 0.49571260809898376,
      "learning_rate": 2.2685997430721235e-05,
      "logits/chosen": -0.5660709142684937,
      "logits/rejected": -0.17439530789852142,
      "logps/chosen": -208.5300750732422,
      "logps/rejected": -231.2234649658203,
      "loss": 0.1939,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.292618751525879,
      "rewards/margins": 4.659537315368652,
      "rewards/rejected": -9.952156066894531,
      "step": 19680
    },
    {
      "epoch": 3.593393557806369,
      "grad_norm": 6.503738880157471,
      "learning_rate": 2.2656634244815563e-05,
      "logits/chosen": -0.20165285468101501,
      "logits/rejected": -0.012435750104486942,
      "logps/chosen": -189.88644409179688,
      "logps/rejected": -229.101806640625,
      "loss": 0.0882,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.829747676849365,
      "rewards/margins": 4.669564723968506,
      "rewards/rejected": -10.499311447143555,
      "step": 19690
    },
    {
      "epoch": 3.5952185418377587,
      "grad_norm": 13.266921043395996,
      "learning_rate": 2.2627271058909895e-05,
      "logits/chosen": -0.39499300718307495,
      "logits/rejected": 0.013039779849350452,
      "logps/chosen": -208.4927520751953,
      "logps/rejected": -232.0061492919922,
      "loss": 0.1617,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.247852802276611,
      "rewards/margins": 4.766884803771973,
      "rewards/rejected": -11.014738082885742,
      "step": 19700
    },
    {
      "epoch": 3.5970435258691484,
      "grad_norm": 16.02116584777832,
      "learning_rate": 2.2597907873004223e-05,
      "logits/chosen": -0.32157570123672485,
      "logits/rejected": 0.10937266051769257,
      "logps/chosen": -208.8837127685547,
      "logps/rejected": -221.29296875,
      "loss": 0.2204,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.044255256652832,
      "rewards/margins": 4.421994209289551,
      "rewards/rejected": -10.466249465942383,
      "step": 19710
    },
    {
      "epoch": 3.598868509900538,
      "grad_norm": 21.325664520263672,
      "learning_rate": 2.2568544687098554e-05,
      "logits/chosen": -0.4318007826805115,
      "logits/rejected": 0.016214903444051743,
      "logps/chosen": -211.9539031982422,
      "logps/rejected": -232.0919189453125,
      "loss": 0.1884,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.630815029144287,
      "rewards/margins": 5.204476356506348,
      "rewards/rejected": -10.835290908813477,
      "step": 19720
    },
    {
      "epoch": 3.600693493931928,
      "grad_norm": 10.058967590332031,
      "learning_rate": 2.253918150119288e-05,
      "logits/chosen": -0.1703965961933136,
      "logits/rejected": 0.14812855422496796,
      "logps/chosen": -200.60154724121094,
      "logps/rejected": -227.21011352539062,
      "loss": 0.0855,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.513484477996826,
      "rewards/margins": 4.545275688171387,
      "rewards/rejected": -10.058761596679688,
      "step": 19730
    },
    {
      "epoch": 3.6025184779633177,
      "grad_norm": 1.3313634395599365,
      "learning_rate": 2.250981831528721e-05,
      "logits/chosen": -0.24304747581481934,
      "logits/rejected": -0.0194847472012043,
      "logps/chosen": -206.1868438720703,
      "logps/rejected": -239.73709106445312,
      "loss": 0.1495,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.880553245544434,
      "rewards/margins": 4.388602256774902,
      "rewards/rejected": -10.269155502319336,
      "step": 19740
    },
    {
      "epoch": 3.6043434619947075,
      "grad_norm": 3.185210704803467,
      "learning_rate": 2.2480455129381538e-05,
      "logits/chosen": -0.4247972071170807,
      "logits/rejected": 0.05065030977129936,
      "logps/chosen": -204.97830200195312,
      "logps/rejected": -222.85903930664062,
      "loss": 0.1286,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.101446628570557,
      "rewards/margins": 4.358457088470459,
      "rewards/rejected": -10.459904670715332,
      "step": 19750
    },
    {
      "epoch": 3.606168446026097,
      "grad_norm": 2.9409894943237305,
      "learning_rate": 2.245109194347587e-05,
      "logits/chosen": -0.4891382157802582,
      "logits/rejected": 0.05382595211267471,
      "logps/chosen": -222.2027130126953,
      "logps/rejected": -224.93209838867188,
      "loss": 0.1143,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.147305488586426,
      "rewards/margins": 4.465733528137207,
      "rewards/rejected": -9.613039016723633,
      "step": 19760
    },
    {
      "epoch": 3.607993430057487,
      "grad_norm": 4.588563442230225,
      "learning_rate": 2.24217287575702e-05,
      "logits/chosen": -0.3289775252342224,
      "logits/rejected": 0.06903154402971268,
      "logps/chosen": -189.57211303710938,
      "logps/rejected": -209.1709442138672,
      "loss": 0.2071,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.8387837409973145,
      "rewards/margins": 5.022784233093262,
      "rewards/rejected": -9.861568450927734,
      "step": 19770
    },
    {
      "epoch": 3.6098184140888767,
      "grad_norm": 22.242971420288086,
      "learning_rate": 2.239236557166453e-05,
      "logits/chosen": -0.42656072974205017,
      "logits/rejected": -0.0978960171341896,
      "logps/chosen": -210.390625,
      "logps/rejected": -223.0041046142578,
      "loss": 0.1775,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.9205322265625,
      "rewards/margins": 4.511378288269043,
      "rewards/rejected": -9.43191146850586,
      "step": 19780
    },
    {
      "epoch": 3.6116433981202665,
      "grad_norm": 4.3810224533081055,
      "learning_rate": 2.236300238575886e-05,
      "logits/chosen": -0.15415723621845245,
      "logits/rejected": 0.11262524127960205,
      "logps/chosen": -195.13717651367188,
      "logps/rejected": -246.65255737304688,
      "loss": 0.1579,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.671952247619629,
      "rewards/margins": 4.440774917602539,
      "rewards/rejected": -10.112728118896484,
      "step": 19790
    },
    {
      "epoch": 3.613468382151656,
      "grad_norm": 5.024835586547852,
      "learning_rate": 2.2333639199853184e-05,
      "logits/chosen": -0.08889725059270859,
      "logits/rejected": 0.1990709751844406,
      "logps/chosen": -207.63229370117188,
      "logps/rejected": -248.14645385742188,
      "loss": 0.1333,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.36551570892334,
      "rewards/margins": 4.336506366729736,
      "rewards/rejected": -10.702021598815918,
      "step": 19800
    },
    {
      "epoch": 3.615293366183046,
      "grad_norm": 3.3616554737091064,
      "learning_rate": 2.2304276013947516e-05,
      "logits/chosen": -0.14300335943698883,
      "logits/rejected": 0.20287172496318817,
      "logps/chosen": -201.6768341064453,
      "logps/rejected": -235.94271850585938,
      "loss": 0.1133,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.800662994384766,
      "rewards/margins": 5.226913928985596,
      "rewards/rejected": -11.027576446533203,
      "step": 19810
    },
    {
      "epoch": 3.6171183502144357,
      "grad_norm": 9.681896209716797,
      "learning_rate": 2.2274912828041844e-05,
      "logits/chosen": -0.2300964891910553,
      "logits/rejected": 0.11093239486217499,
      "logps/chosen": -215.10110473632812,
      "logps/rejected": -241.06192016601562,
      "loss": 0.1924,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.4628119468688965,
      "rewards/margins": 4.739691257476807,
      "rewards/rejected": -11.202503204345703,
      "step": 19820
    },
    {
      "epoch": 3.6189433342458255,
      "grad_norm": 9.665728569030762,
      "learning_rate": 2.2245549642136175e-05,
      "logits/chosen": -0.3037993013858795,
      "logits/rejected": 0.35763707756996155,
      "logps/chosen": -212.67208862304688,
      "logps/rejected": -223.08053588867188,
      "loss": 0.232,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.757445335388184,
      "rewards/margins": 4.32390022277832,
      "rewards/rejected": -11.08134651184082,
      "step": 19830
    },
    {
      "epoch": 3.6207683182772152,
      "grad_norm": 20.0786190032959,
      "learning_rate": 2.2216186456230503e-05,
      "logits/chosen": -0.12853333353996277,
      "logits/rejected": 0.18301117420196533,
      "logps/chosen": -211.6452178955078,
      "logps/rejected": -244.9899444580078,
      "loss": 0.1951,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.265626907348633,
      "rewards/margins": 5.190882682800293,
      "rewards/rejected": -11.456509590148926,
      "step": 19840
    },
    {
      "epoch": 3.622593302308605,
      "grad_norm": 4.276346683502197,
      "learning_rate": 2.2186823270324834e-05,
      "logits/chosen": -0.3236863613128662,
      "logits/rejected": -0.03414461016654968,
      "logps/chosen": -216.8509979248047,
      "logps/rejected": -248.1688690185547,
      "loss": 0.1408,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.437339782714844,
      "rewards/margins": 4.7571282386779785,
      "rewards/rejected": -11.19446849822998,
      "step": 19850
    },
    {
      "epoch": 3.6244182863399947,
      "grad_norm": 43.15800476074219,
      "learning_rate": 2.215746008441916e-05,
      "logits/chosen": -0.08789078146219254,
      "logits/rejected": 0.3526287376880646,
      "logps/chosen": -199.09877014160156,
      "logps/rejected": -228.6330108642578,
      "loss": 0.197,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.478758811950684,
      "rewards/margins": 5.221219062805176,
      "rewards/rejected": -11.699976921081543,
      "step": 19860
    },
    {
      "epoch": 3.6262432703713845,
      "grad_norm": 0.7282103300094604,
      "learning_rate": 2.212809689851349e-05,
      "logits/chosen": -0.39228135347366333,
      "logits/rejected": -0.0971415713429451,
      "logps/chosen": -209.82373046875,
      "logps/rejected": -253.04019165039062,
      "loss": 0.2254,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.1962103843688965,
      "rewards/margins": 4.6516947746276855,
      "rewards/rejected": -10.847905158996582,
      "step": 19870
    },
    {
      "epoch": 3.6280682544027743,
      "grad_norm": 4.066987037658691,
      "learning_rate": 2.209873371260782e-05,
      "logits/chosen": -0.2875557839870453,
      "logits/rejected": -0.1306181699037552,
      "logps/chosen": -193.25326538085938,
      "logps/rejected": -230.39993286132812,
      "loss": 0.1884,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.674044609069824,
      "rewards/margins": 4.181687355041504,
      "rewards/rejected": -9.855731964111328,
      "step": 19880
    },
    {
      "epoch": 3.6298932384341636,
      "grad_norm": 10.681675910949707,
      "learning_rate": 2.206937052670215e-05,
      "logits/chosen": -0.39752429723739624,
      "logits/rejected": 0.03149551898241043,
      "logps/chosen": -208.38748168945312,
      "logps/rejected": -230.6691131591797,
      "loss": 0.2297,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.0470871925354,
      "rewards/margins": 4.687322616577148,
      "rewards/rejected": -9.734410285949707,
      "step": 19890
    },
    {
      "epoch": 3.6317182224655533,
      "grad_norm": 9.919791221618652,
      "learning_rate": 2.2040007340796478e-05,
      "logits/chosen": -0.5627135038375854,
      "logits/rejected": -0.17104847729206085,
      "logps/chosen": -199.59463500976562,
      "logps/rejected": -233.1503448486328,
      "loss": 0.0955,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.322207450866699,
      "rewards/margins": 5.419264316558838,
      "rewards/rejected": -9.741472244262695,
      "step": 19900
    },
    {
      "epoch": 3.633543206496943,
      "grad_norm": 2.445711612701416,
      "learning_rate": 2.201064415489081e-05,
      "logits/chosen": -0.31434494256973267,
      "logits/rejected": 0.005524820182472467,
      "logps/chosen": -192.2557373046875,
      "logps/rejected": -231.73861694335938,
      "loss": 0.1505,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.157754898071289,
      "rewards/margins": 5.083645820617676,
      "rewards/rejected": -10.241401672363281,
      "step": 19910
    },
    {
      "epoch": 3.635368190528333,
      "grad_norm": 7.294609546661377,
      "learning_rate": 2.1981280968985134e-05,
      "logits/chosen": -0.36542972922325134,
      "logits/rejected": -0.08571212738752365,
      "logps/chosen": -197.4077911376953,
      "logps/rejected": -216.2214813232422,
      "loss": 0.1834,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.681379795074463,
      "rewards/margins": 4.66517972946167,
      "rewards/rejected": -9.34656047821045,
      "step": 19920
    },
    {
      "epoch": 3.6371931745597226,
      "grad_norm": 11.836240768432617,
      "learning_rate": 2.1951917783079465e-05,
      "logits/chosen": -0.26614078879356384,
      "logits/rejected": 0.09737934172153473,
      "logps/chosen": -183.91415405273438,
      "logps/rejected": -226.3409423828125,
      "loss": 0.1891,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.742665767669678,
      "rewards/margins": 5.415278911590576,
      "rewards/rejected": -10.157943725585938,
      "step": 19930
    },
    {
      "epoch": 3.6390181585911123,
      "grad_norm": 14.47315502166748,
      "learning_rate": 2.1922554597173793e-05,
      "logits/chosen": -0.32304760813713074,
      "logits/rejected": 0.17809289693832397,
      "logps/chosen": -213.30557250976562,
      "logps/rejected": -224.34213256835938,
      "loss": 0.124,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.5299787521362305,
      "rewards/margins": 4.981076240539551,
      "rewards/rejected": -10.511055946350098,
      "step": 19940
    },
    {
      "epoch": 3.640843142622502,
      "grad_norm": 5.646552562713623,
      "learning_rate": 2.1893191411268124e-05,
      "logits/chosen": -0.27554818987846375,
      "logits/rejected": 0.09084565937519073,
      "logps/chosen": -200.02346801757812,
      "logps/rejected": -251.2515411376953,
      "loss": 0.0946,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.639111518859863,
      "rewards/margins": 5.725972652435303,
      "rewards/rejected": -11.365083694458008,
      "step": 19950
    },
    {
      "epoch": 3.642668126653892,
      "grad_norm": 16.316560745239258,
      "learning_rate": 2.1863828225362456e-05,
      "logits/chosen": -0.10689528286457062,
      "logits/rejected": 0.17127805948257446,
      "logps/chosen": -213.09890747070312,
      "logps/rejected": -242.55551147460938,
      "loss": 0.1844,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.732609748840332,
      "rewards/margins": 4.682229042053223,
      "rewards/rejected": -11.414838790893555,
      "step": 19960
    },
    {
      "epoch": 3.6444931106852816,
      "grad_norm": 0.9136042594909668,
      "learning_rate": 2.1834465039456784e-05,
      "logits/chosen": 0.005375404842197895,
      "logits/rejected": 0.19020548462867737,
      "logps/chosen": -202.02281188964844,
      "logps/rejected": -260.94268798828125,
      "loss": 0.1819,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.669097900390625,
      "rewards/margins": 4.828711986541748,
      "rewards/rejected": -11.497810363769531,
      "step": 19970
    },
    {
      "epoch": 3.6463180947166713,
      "grad_norm": 1.957575798034668,
      "learning_rate": 2.1805101853551115e-05,
      "logits/chosen": -0.38403671979904175,
      "logits/rejected": 0.0869007259607315,
      "logps/chosen": -215.29092407226562,
      "logps/rejected": -239.65072631835938,
      "loss": 0.1985,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.882224082946777,
      "rewards/margins": 4.890091896057129,
      "rewards/rejected": -10.772315979003906,
      "step": 19980
    },
    {
      "epoch": 3.648143078748061,
      "grad_norm": 9.396288871765137,
      "learning_rate": 2.177573866764544e-05,
      "logits/chosen": -0.22597388923168182,
      "logits/rejected": 0.5186832547187805,
      "logps/chosen": -206.9179229736328,
      "logps/rejected": -217.3363800048828,
      "loss": 0.1006,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.0849833488464355,
      "rewards/margins": 5.687514305114746,
      "rewards/rejected": -10.772497177124023,
      "step": 19990
    },
    {
      "epoch": 3.6499680627794504,
      "grad_norm": 7.463967800140381,
      "learning_rate": 2.174637548173977e-05,
      "logits/chosen": -0.10663845390081406,
      "logits/rejected": -0.008715188130736351,
      "logps/chosen": -187.58157348632812,
      "logps/rejected": -271.2937316894531,
      "loss": 0.0612,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.4928483963012695,
      "rewards/margins": 6.189913749694824,
      "rewards/rejected": -11.682762145996094,
      "step": 20000
    },
    {
      "epoch": 3.65179304681084,
      "grad_norm": 5.577211856842041,
      "learning_rate": 2.17170122958341e-05,
      "logits/chosen": -0.179365873336792,
      "logits/rejected": 0.22739708423614502,
      "logps/chosen": -191.05169677734375,
      "logps/rejected": -230.5449676513672,
      "loss": 0.1478,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.039002418518066,
      "rewards/margins": 6.0489606857299805,
      "rewards/rejected": -11.087964057922363,
      "step": 20010
    },
    {
      "epoch": 3.65361803084223,
      "grad_norm": 3.461130380630493,
      "learning_rate": 2.168764910992843e-05,
      "logits/chosen": -0.39502769708633423,
      "logits/rejected": -0.16756144165992737,
      "logps/chosen": -195.813232421875,
      "logps/rejected": -259.603271484375,
      "loss": 0.1127,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.203522682189941,
      "rewards/margins": 5.014162540435791,
      "rewards/rejected": -11.217683792114258,
      "step": 20020
    },
    {
      "epoch": 3.6554430148736197,
      "grad_norm": 10.456491470336914,
      "learning_rate": 2.1658285924022758e-05,
      "logits/chosen": -0.18531686067581177,
      "logits/rejected": 0.2646704614162445,
      "logps/chosen": -212.0189971923828,
      "logps/rejected": -245.5181427001953,
      "loss": 0.1983,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.461917877197266,
      "rewards/margins": 4.683105945587158,
      "rewards/rejected": -11.145023345947266,
      "step": 20030
    },
    {
      "epoch": 3.6572679989050094,
      "grad_norm": 10.603374481201172,
      "learning_rate": 2.162892273811709e-05,
      "logits/chosen": -0.30474328994750977,
      "logits/rejected": 0.041311562061309814,
      "logps/chosen": -190.1645050048828,
      "logps/rejected": -218.1453094482422,
      "loss": 0.2415,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -4.95644474029541,
      "rewards/margins": 4.418576717376709,
      "rewards/rejected": -9.375020980834961,
      "step": 20040
    },
    {
      "epoch": 3.659092982936399,
      "grad_norm": 0.8275936245918274,
      "learning_rate": 2.1599559552211414e-05,
      "logits/chosen": -0.45667997002601624,
      "logits/rejected": 0.08717761933803558,
      "logps/chosen": -203.81968688964844,
      "logps/rejected": -209.15426635742188,
      "loss": 0.2648,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.460562705993652,
      "rewards/margins": 4.597231864929199,
      "rewards/rejected": -10.057794570922852,
      "step": 20050
    },
    {
      "epoch": 3.660917966967789,
      "grad_norm": 11.472249031066895,
      "learning_rate": 2.1570196366305745e-05,
      "logits/chosen": -0.45242148637771606,
      "logits/rejected": -0.11062844097614288,
      "logps/chosen": -194.7095947265625,
      "logps/rejected": -228.300048828125,
      "loss": 0.1135,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.402978420257568,
      "rewards/margins": 5.008396625518799,
      "rewards/rejected": -10.41137409210205,
      "step": 20060
    },
    {
      "epoch": 3.6627429509991787,
      "grad_norm": 4.086773872375488,
      "learning_rate": 2.1540833180400073e-05,
      "logits/chosen": -0.3060400187969208,
      "logits/rejected": 0.13152986764907837,
      "logps/chosen": -211.40036010742188,
      "logps/rejected": -229.32119750976562,
      "loss": 0.115,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.852159023284912,
      "rewards/margins": 4.549454212188721,
      "rewards/rejected": -10.40161418914795,
      "step": 20070
    },
    {
      "epoch": 3.6645679350305684,
      "grad_norm": 14.181442260742188,
      "learning_rate": 2.1511469994494405e-05,
      "logits/chosen": -0.029224464669823647,
      "logits/rejected": 0.346901535987854,
      "logps/chosen": -194.9747772216797,
      "logps/rejected": -218.1226348876953,
      "loss": 0.158,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.558509826660156,
      "rewards/margins": 5.017396450042725,
      "rewards/rejected": -10.575906753540039,
      "step": 20080
    },
    {
      "epoch": 3.666392919061958,
      "grad_norm": 10.263330459594727,
      "learning_rate": 2.1482106808588733e-05,
      "logits/chosen": -0.3998807668685913,
      "logits/rejected": -0.03740745037794113,
      "logps/chosen": -196.22412109375,
      "logps/rejected": -237.20248413085938,
      "loss": 0.1779,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.599747180938721,
      "rewards/margins": 5.2525715827941895,
      "rewards/rejected": -10.85231876373291,
      "step": 20090
    },
    {
      "epoch": 3.668217903093348,
      "grad_norm": 10.783116340637207,
      "learning_rate": 2.1452743622683064e-05,
      "logits/chosen": -0.3455238938331604,
      "logits/rejected": -0.05495106056332588,
      "logps/chosen": -186.30978393554688,
      "logps/rejected": -221.54458618164062,
      "loss": 0.3596,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.485051155090332,
      "rewards/margins": 4.365883827209473,
      "rewards/rejected": -9.850934982299805,
      "step": 20100
    },
    {
      "epoch": 3.6700428871247377,
      "grad_norm": 18.42565155029297,
      "learning_rate": 2.142338043677739e-05,
      "logits/chosen": -0.17437265813350677,
      "logits/rejected": 0.1786336749792099,
      "logps/chosen": -210.58407592773438,
      "logps/rejected": -246.1519012451172,
      "loss": 0.2391,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.099382400512695,
      "rewards/margins": 4.9876389503479,
      "rewards/rejected": -11.087021827697754,
      "step": 20110
    },
    {
      "epoch": 3.6718678711561274,
      "grad_norm": 13.76180362701416,
      "learning_rate": 2.139401725087172e-05,
      "logits/chosen": -0.4781944751739502,
      "logits/rejected": 0.14986303448677063,
      "logps/chosen": -203.8458251953125,
      "logps/rejected": -214.58987426757812,
      "loss": 0.1278,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.3631792068481445,
      "rewards/margins": 4.848050117492676,
      "rewards/rejected": -10.21122932434082,
      "step": 20120
    },
    {
      "epoch": 3.673692855187517,
      "grad_norm": 4.508126258850098,
      "learning_rate": 2.136465406496605e-05,
      "logits/chosen": -0.2905319333076477,
      "logits/rejected": -0.02751885913312435,
      "logps/chosen": -220.1179656982422,
      "logps/rejected": -264.486328125,
      "loss": 0.1589,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.42779541015625,
      "rewards/margins": 4.681761741638184,
      "rewards/rejected": -11.109557151794434,
      "step": 20130
    },
    {
      "epoch": 3.675517839218907,
      "grad_norm": 9.867302894592285,
      "learning_rate": 2.133529087906038e-05,
      "logits/chosen": -0.5147207379341125,
      "logits/rejected": -0.11032149940729141,
      "logps/chosen": -211.40811157226562,
      "logps/rejected": -239.2358856201172,
      "loss": 0.1411,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.135315418243408,
      "rewards/margins": 4.803788185119629,
      "rewards/rejected": -9.939104080200195,
      "step": 20140
    },
    {
      "epoch": 3.6773428232502967,
      "grad_norm": 2.3866541385650635,
      "learning_rate": 2.130592769315471e-05,
      "logits/chosen": -0.5212651491165161,
      "logits/rejected": -0.11849071085453033,
      "logps/chosen": -218.84130859375,
      "logps/rejected": -234.2369384765625,
      "loss": 0.1767,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.473645210266113,
      "rewards/margins": 5.021707534790039,
      "rewards/rejected": -10.495351791381836,
      "step": 20150
    },
    {
      "epoch": 3.6791678072816865,
      "grad_norm": 0.2807341516017914,
      "learning_rate": 2.127656450724904e-05,
      "logits/chosen": -0.2097194492816925,
      "logits/rejected": 0.08930035680532455,
      "logps/chosen": -188.2649383544922,
      "logps/rejected": -226.27603149414062,
      "loss": 0.079,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.631136417388916,
      "rewards/margins": 5.1507439613342285,
      "rewards/rejected": -10.781881332397461,
      "step": 20160
    },
    {
      "epoch": 3.680992791313076,
      "grad_norm": 3.676133871078491,
      "learning_rate": 2.124720132134337e-05,
      "logits/chosen": -0.4821654260158539,
      "logits/rejected": -0.07946370542049408,
      "logps/chosen": -200.0638885498047,
      "logps/rejected": -225.1011199951172,
      "loss": 0.1831,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.547169208526611,
      "rewards/margins": 4.683684825897217,
      "rewards/rejected": -10.230854034423828,
      "step": 20170
    },
    {
      "epoch": 3.682817775344466,
      "grad_norm": 6.0834503173828125,
      "learning_rate": 2.1217838135437694e-05,
      "logits/chosen": -0.3447025716304779,
      "logits/rejected": -0.17658671736717224,
      "logps/chosen": -207.87503051757812,
      "logps/rejected": -220.5484619140625,
      "loss": 0.331,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.697537422180176,
      "rewards/margins": 3.316053867340088,
      "rewards/rejected": -9.013591766357422,
      "step": 20180
    },
    {
      "epoch": 3.6846427593758557,
      "grad_norm": 3.3836936950683594,
      "learning_rate": 2.1188474949532026e-05,
      "logits/chosen": -0.340774804353714,
      "logits/rejected": 0.016454044729471207,
      "logps/chosen": -199.24267578125,
      "logps/rejected": -234.0032196044922,
      "loss": 0.167,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.727819919586182,
      "rewards/margins": 4.646789073944092,
      "rewards/rejected": -10.374608993530273,
      "step": 20190
    },
    {
      "epoch": 3.686467743407245,
      "grad_norm": 1.458777666091919,
      "learning_rate": 2.1159111763626354e-05,
      "logits/chosen": -0.18102994561195374,
      "logits/rejected": 0.10379116237163544,
      "logps/chosen": -205.69384765625,
      "logps/rejected": -230.2811737060547,
      "loss": 0.1087,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.56020450592041,
      "rewards/margins": 4.59980583190918,
      "rewards/rejected": -10.160009384155273,
      "step": 20200
    },
    {
      "epoch": 3.688292727438635,
      "grad_norm": 2.3086979389190674,
      "learning_rate": 2.1129748577720685e-05,
      "logits/chosen": -0.41321712732315063,
      "logits/rejected": -0.015121015720069408,
      "logps/chosen": -232.73641967773438,
      "logps/rejected": -259.26019287109375,
      "loss": 0.2157,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.990182876586914,
      "rewards/margins": 5.2610368728637695,
      "rewards/rejected": -11.251218795776367,
      "step": 20210
    },
    {
      "epoch": 3.6901177114700245,
      "grad_norm": 0.5749094486236572,
      "learning_rate": 2.1100385391815013e-05,
      "logits/chosen": -0.391213983297348,
      "logits/rejected": 0.12850257754325867,
      "logps/chosen": -214.83828735351562,
      "logps/rejected": -240.1630401611328,
      "loss": 0.0375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.0531325340271,
      "rewards/margins": 5.843599796295166,
      "rewards/rejected": -10.896730422973633,
      "step": 20220
    },
    {
      "epoch": 3.6919426955014143,
      "grad_norm": 12.34217357635498,
      "learning_rate": 2.1071022205909344e-05,
      "logits/chosen": -0.05070225149393082,
      "logits/rejected": 0.2762569785118103,
      "logps/chosen": -200.53334045410156,
      "logps/rejected": -233.07595825195312,
      "loss": 0.2423,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.2278547286987305,
      "rewards/margins": 5.270366668701172,
      "rewards/rejected": -11.498222351074219,
      "step": 20230
    },
    {
      "epoch": 3.693767679532804,
      "grad_norm": 6.250603199005127,
      "learning_rate": 2.1041659020003672e-05,
      "logits/chosen": -0.17840895056724548,
      "logits/rejected": 0.30339741706848145,
      "logps/chosen": -221.70974731445312,
      "logps/rejected": -229.07254028320312,
      "loss": 0.1634,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.798674583435059,
      "rewards/margins": 4.551340579986572,
      "rewards/rejected": -11.350015640258789,
      "step": 20240
    },
    {
      "epoch": 3.695592663564194,
      "grad_norm": 9.170239448547363,
      "learning_rate": 2.1012295834098004e-05,
      "logits/chosen": -0.3940487802028656,
      "logits/rejected": -0.16349896788597107,
      "logps/chosen": -213.49777221679688,
      "logps/rejected": -240.32254028320312,
      "loss": 0.1775,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.690163612365723,
      "rewards/margins": 4.231520175933838,
      "rewards/rejected": -9.921684265136719,
      "step": 20250
    },
    {
      "epoch": 3.6974176475955836,
      "grad_norm": 6.773292541503906,
      "learning_rate": 2.0982932648192328e-05,
      "logits/chosen": -0.3225131630897522,
      "logits/rejected": -0.06375284492969513,
      "logps/chosen": -199.39720153808594,
      "logps/rejected": -220.5615692138672,
      "loss": 0.211,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.87876033782959,
      "rewards/margins": 3.6769256591796875,
      "rewards/rejected": -9.555685043334961,
      "step": 20260
    },
    {
      "epoch": 3.6992426316269733,
      "grad_norm": 16.52617835998535,
      "learning_rate": 2.095356946228666e-05,
      "logits/chosen": -0.44991350173950195,
      "logits/rejected": 0.06405383348464966,
      "logps/chosen": -208.4691925048828,
      "logps/rejected": -215.5625,
      "loss": 0.1521,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.143435478210449,
      "rewards/margins": 4.944659233093262,
      "rewards/rejected": -10.088095664978027,
      "step": 20270
    },
    {
      "epoch": 3.701067615658363,
      "grad_norm": 0.5954967737197876,
      "learning_rate": 2.0924206276380988e-05,
      "logits/chosen": -0.06222160905599594,
      "logits/rejected": 0.2556588649749756,
      "logps/chosen": -200.3325958251953,
      "logps/rejected": -222.71875,
      "loss": 0.1258,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.419025421142578,
      "rewards/margins": 5.031100749969482,
      "rewards/rejected": -10.450125694274902,
      "step": 20280
    },
    {
      "epoch": 3.702892599689753,
      "grad_norm": 8.689505577087402,
      "learning_rate": 2.089484309047532e-05,
      "logits/chosen": -0.1734168827533722,
      "logits/rejected": 0.45563364028930664,
      "logps/chosen": -212.2084197998047,
      "logps/rejected": -218.28842163085938,
      "loss": 0.1947,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.810675621032715,
      "rewards/margins": 4.690037727355957,
      "rewards/rejected": -10.500712394714355,
      "step": 20290
    },
    {
      "epoch": 3.7047175837211426,
      "grad_norm": 4.595244407653809,
      "learning_rate": 2.0865479904569647e-05,
      "logits/chosen": -0.15077051520347595,
      "logits/rejected": 0.20453254878520966,
      "logps/chosen": -197.87730407714844,
      "logps/rejected": -224.19384765625,
      "loss": 0.1496,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.417637348175049,
      "rewards/margins": 4.622647285461426,
      "rewards/rejected": -10.040285110473633,
      "step": 20300
    },
    {
      "epoch": 3.7065425677525323,
      "grad_norm": 16.750505447387695,
      "learning_rate": 2.0836116718663978e-05,
      "logits/chosen": -0.24262337386608124,
      "logits/rejected": 0.027685929089784622,
      "logps/chosen": -218.0181121826172,
      "logps/rejected": -258.40875244140625,
      "loss": 0.1335,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.751221179962158,
      "rewards/margins": 4.896190643310547,
      "rewards/rejected": -10.647412300109863,
      "step": 20310
    },
    {
      "epoch": 3.7083675517839216,
      "grad_norm": 2.312326669692993,
      "learning_rate": 2.080675353275831e-05,
      "logits/chosen": -0.27719128131866455,
      "logits/rejected": 0.06046103686094284,
      "logps/chosen": -197.95535278320312,
      "logps/rejected": -241.2734832763672,
      "loss": 0.0861,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.300893783569336,
      "rewards/margins": 5.402577877044678,
      "rewards/rejected": -10.703473091125488,
      "step": 20320
    },
    {
      "epoch": 3.7101925358153114,
      "grad_norm": 5.918826580047607,
      "learning_rate": 2.0777390346852634e-05,
      "logits/chosen": -0.3279799818992615,
      "logits/rejected": 0.04769355058670044,
      "logps/chosen": -195.33143615722656,
      "logps/rejected": -218.347412109375,
      "loss": 0.1137,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -4.978485584259033,
      "rewards/margins": 4.781887531280518,
      "rewards/rejected": -9.76037311553955,
      "step": 20330
    },
    {
      "epoch": 3.712017519846701,
      "grad_norm": 4.794979095458984,
      "learning_rate": 2.0748027160946966e-05,
      "logits/chosen": -0.18869322538375854,
      "logits/rejected": 0.15620148181915283,
      "logps/chosen": -194.62852478027344,
      "logps/rejected": -223.06216430664062,
      "loss": 0.1352,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.634853839874268,
      "rewards/margins": 4.993139266967773,
      "rewards/rejected": -10.627992630004883,
      "step": 20340
    },
    {
      "epoch": 3.713842503878091,
      "grad_norm": 3.4471275806427,
      "learning_rate": 2.0718663975041294e-05,
      "logits/chosen": -0.3742779791355133,
      "logits/rejected": -0.0884600430727005,
      "logps/chosen": -213.2102508544922,
      "logps/rejected": -237.68148803710938,
      "loss": 0.2885,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.128881454467773,
      "rewards/margins": 4.4048566818237305,
      "rewards/rejected": -9.53373908996582,
      "step": 20350
    },
    {
      "epoch": 3.7156674879094806,
      "grad_norm": 0.7468079924583435,
      "learning_rate": 2.0689300789135625e-05,
      "logits/chosen": -0.4087825417518616,
      "logits/rejected": 0.021570634096860886,
      "logps/chosen": -208.44384765625,
      "logps/rejected": -231.84915161132812,
      "loss": 0.1814,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.543380260467529,
      "rewards/margins": 4.5487775802612305,
      "rewards/rejected": -10.092158317565918,
      "step": 20360
    },
    {
      "epoch": 3.7174924719408704,
      "grad_norm": 12.710326194763184,
      "learning_rate": 2.0659937603229953e-05,
      "logits/chosen": -0.37758535146713257,
      "logits/rejected": -0.08326666057109833,
      "logps/chosen": -194.7724151611328,
      "logps/rejected": -234.6237030029297,
      "loss": 0.1711,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.801638603210449,
      "rewards/margins": 4.970829963684082,
      "rewards/rejected": -9.772469520568848,
      "step": 20370
    },
    {
      "epoch": 3.71931745597226,
      "grad_norm": 0.9602029323577881,
      "learning_rate": 2.0630574417324284e-05,
      "logits/chosen": -0.3930171728134155,
      "logits/rejected": -0.15382876992225647,
      "logps/chosen": -173.64895629882812,
      "logps/rejected": -217.4027099609375,
      "loss": 0.1555,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.276125431060791,
      "rewards/margins": 4.7717180252075195,
      "rewards/rejected": -9.047843933105469,
      "step": 20380
    },
    {
      "epoch": 3.72114244000365,
      "grad_norm": 1.4087501764297485,
      "learning_rate": 2.060121123141861e-05,
      "logits/chosen": -0.4266459345817566,
      "logits/rejected": -0.17349819839000702,
      "logps/chosen": -178.42263793945312,
      "logps/rejected": -211.76089477539062,
      "loss": 0.1298,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -3.7609729766845703,
      "rewards/margins": 5.13707971572876,
      "rewards/rejected": -8.898053169250488,
      "step": 20390
    },
    {
      "epoch": 3.7229674240350397,
      "grad_norm": 5.634687900543213,
      "learning_rate": 2.057184804551294e-05,
      "logits/chosen": -0.4549392759799957,
      "logits/rejected": -0.142817884683609,
      "logps/chosen": -199.0472412109375,
      "logps/rejected": -220.05648803710938,
      "loss": 0.1801,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.232430458068848,
      "rewards/margins": 4.604489326477051,
      "rewards/rejected": -9.836921691894531,
      "step": 20400
    },
    {
      "epoch": 3.7247924080664294,
      "grad_norm": 1.4860740900039673,
      "learning_rate": 2.0542484859607268e-05,
      "logits/chosen": -0.2729237675666809,
      "logits/rejected": 0.008478832431137562,
      "logps/chosen": -199.00112915039062,
      "logps/rejected": -230.23336791992188,
      "loss": 0.1504,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.584125518798828,
      "rewards/margins": 4.576176166534424,
      "rewards/rejected": -10.160301208496094,
      "step": 20410
    },
    {
      "epoch": 3.726617392097819,
      "grad_norm": 14.361119270324707,
      "learning_rate": 2.05131216737016e-05,
      "logits/chosen": -0.29788458347320557,
      "logits/rejected": 0.12966029345989227,
      "logps/chosen": -209.14089965820312,
      "logps/rejected": -220.434814453125,
      "loss": 0.1706,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.493569374084473,
      "rewards/margins": 4.696117401123047,
      "rewards/rejected": -10.189687728881836,
      "step": 20420
    },
    {
      "epoch": 3.728442376129209,
      "grad_norm": 4.358851432800293,
      "learning_rate": 2.0483758487795927e-05,
      "logits/chosen": -0.258555144071579,
      "logits/rejected": -0.018878478556871414,
      "logps/chosen": -197.7114715576172,
      "logps/rejected": -235.45120239257812,
      "loss": 0.2085,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.688094139099121,
      "rewards/margins": 4.616574764251709,
      "rewards/rejected": -10.304669380187988,
      "step": 20430
    },
    {
      "epoch": 3.7302673601605987,
      "grad_norm": 7.7378106117248535,
      "learning_rate": 2.045439530189026e-05,
      "logits/chosen": -0.34919998049736023,
      "logits/rejected": 0.08182941377162933,
      "logps/chosen": -195.1129913330078,
      "logps/rejected": -204.37525939941406,
      "loss": 0.1716,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.013943672180176,
      "rewards/margins": 4.258815765380859,
      "rewards/rejected": -9.272758483886719,
      "step": 20440
    },
    {
      "epoch": 3.7320923441919884,
      "grad_norm": 12.722740173339844,
      "learning_rate": 2.0425032115984583e-05,
      "logits/chosen": -0.33549314737319946,
      "logits/rejected": 0.0963444709777832,
      "logps/chosen": -217.3592987060547,
      "logps/rejected": -228.57931518554688,
      "loss": 0.1285,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.761601448059082,
      "rewards/margins": 4.810817241668701,
      "rewards/rejected": -9.572418212890625,
      "step": 20450
    },
    {
      "epoch": 3.733917328223378,
      "grad_norm": 2.896730899810791,
      "learning_rate": 2.0395668930078915e-05,
      "logits/chosen": -0.11078319698572159,
      "logits/rejected": 0.23622122406959534,
      "logps/chosen": -197.62942504882812,
      "logps/rejected": -230.39566040039062,
      "loss": 0.1461,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.181241035461426,
      "rewards/margins": 4.46977424621582,
      "rewards/rejected": -10.651015281677246,
      "step": 20460
    },
    {
      "epoch": 3.735742312254768,
      "grad_norm": 2.0311896800994873,
      "learning_rate": 2.0366305744173243e-05,
      "logits/chosen": -0.24705128371715546,
      "logits/rejected": -0.0733066201210022,
      "logps/chosen": -187.55860900878906,
      "logps/rejected": -226.5014190673828,
      "loss": 0.2298,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.5778350830078125,
      "rewards/margins": 4.067904472351074,
      "rewards/rejected": -9.64573860168457,
      "step": 20470
    },
    {
      "epoch": 3.7375672962861577,
      "grad_norm": 3.264033079147339,
      "learning_rate": 2.0336942558267574e-05,
      "logits/chosen": -0.2149849832057953,
      "logits/rejected": 0.11985807120800018,
      "logps/chosen": -186.6958465576172,
      "logps/rejected": -219.83926391601562,
      "loss": 0.1564,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.141091346740723,
      "rewards/margins": 5.135375022888184,
      "rewards/rejected": -10.276466369628906,
      "step": 20480
    },
    {
      "epoch": 3.7393922803175474,
      "grad_norm": 7.964838027954102,
      "learning_rate": 2.0307579372361902e-05,
      "logits/chosen": -0.1853659301996231,
      "logits/rejected": 0.1238325834274292,
      "logps/chosen": -231.49319458007812,
      "logps/rejected": -241.6972198486328,
      "loss": 0.2463,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.723847389221191,
      "rewards/margins": 4.403448581695557,
      "rewards/rejected": -10.12729549407959,
      "step": 20490
    },
    {
      "epoch": 3.741217264348937,
      "grad_norm": 17.041229248046875,
      "learning_rate": 2.0278216186456233e-05,
      "logits/chosen": -0.17599087953567505,
      "logits/rejected": 0.09282226860523224,
      "logps/chosen": -190.48373413085938,
      "logps/rejected": -227.80148315429688,
      "loss": 0.2011,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.998381614685059,
      "rewards/margins": 4.449347019195557,
      "rewards/rejected": -10.447728157043457,
      "step": 20500
    },
    {
      "epoch": 3.7430422483803265,
      "grad_norm": 5.923329830169678,
      "learning_rate": 2.0248853000550565e-05,
      "logits/chosen": -0.362452894449234,
      "logits/rejected": -0.0998699888586998,
      "logps/chosen": -217.66799926757812,
      "logps/rejected": -245.76205444335938,
      "loss": 0.0785,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.7211456298828125,
      "rewards/margins": 5.189102649688721,
      "rewards/rejected": -10.910248756408691,
      "step": 20510
    },
    {
      "epoch": 3.7448672324117163,
      "grad_norm": 3.6606533527374268,
      "learning_rate": 2.021948981464489e-05,
      "logits/chosen": -0.037460196763277054,
      "logits/rejected": 0.28589677810668945,
      "logps/chosen": -213.0791015625,
      "logps/rejected": -241.64163208007812,
      "loss": 0.1172,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.4929680824279785,
      "rewards/margins": 4.886390209197998,
      "rewards/rejected": -11.379358291625977,
      "step": 20520
    },
    {
      "epoch": 3.746692216443106,
      "grad_norm": 1.3330731391906738,
      "learning_rate": 2.019012662873922e-05,
      "logits/chosen": -0.2660778760910034,
      "logits/rejected": 0.0496794730424881,
      "logps/chosen": -212.0994873046875,
      "logps/rejected": -249.00149536132812,
      "loss": 0.1537,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.963122844696045,
      "rewards/margins": 4.731767654418945,
      "rewards/rejected": -10.694890975952148,
      "step": 20530
    },
    {
      "epoch": 3.7485172004744958,
      "grad_norm": 1.08696711063385,
      "learning_rate": 2.016076344283355e-05,
      "logits/chosen": -0.2947445809841156,
      "logits/rejected": 0.10274873673915863,
      "logps/chosen": -202.56515502929688,
      "logps/rejected": -224.8219757080078,
      "loss": 0.1502,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.860180854797363,
      "rewards/margins": 4.986213684082031,
      "rewards/rejected": -10.846395492553711,
      "step": 20540
    },
    {
      "epoch": 3.7503421845058855,
      "grad_norm": 13.01296329498291,
      "learning_rate": 2.013140025692788e-05,
      "logits/chosen": -0.1692729890346527,
      "logits/rejected": 0.1188565343618393,
      "logps/chosen": -213.9340362548828,
      "logps/rejected": -240.8028106689453,
      "loss": 0.165,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.793237209320068,
      "rewards/margins": 4.513066291809082,
      "rewards/rejected": -11.306304931640625,
      "step": 20550
    },
    {
      "epoch": 3.7521671685372753,
      "grad_norm": 17.877456665039062,
      "learning_rate": 2.0102037071022208e-05,
      "logits/chosen": -0.04003338888287544,
      "logits/rejected": 0.29573696851730347,
      "logps/chosen": -213.2057647705078,
      "logps/rejected": -250.4038848876953,
      "loss": 0.203,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.918126583099365,
      "rewards/margins": 5.546109676361084,
      "rewards/rejected": -12.464237213134766,
      "step": 20560
    },
    {
      "epoch": 3.753992152568665,
      "grad_norm": 8.759281158447266,
      "learning_rate": 2.007267388511654e-05,
      "logits/chosen": -0.14138059318065643,
      "logits/rejected": 0.3007529377937317,
      "logps/chosen": -224.6900177001953,
      "logps/rejected": -232.5575408935547,
      "loss": 0.2331,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -7.608463287353516,
      "rewards/margins": 4.069792747497559,
      "rewards/rejected": -11.678255081176758,
      "step": 20570
    },
    {
      "epoch": 3.755817136600055,
      "grad_norm": 16.54096794128418,
      "learning_rate": 2.0043310699210864e-05,
      "logits/chosen": -0.2893576920032501,
      "logits/rejected": -0.002320659114047885,
      "logps/chosen": -196.23265075683594,
      "logps/rejected": -236.1488800048828,
      "loss": 0.1606,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.537011623382568,
      "rewards/margins": 4.932218074798584,
      "rewards/rejected": -10.469230651855469,
      "step": 20580
    },
    {
      "epoch": 3.7576421206314445,
      "grad_norm": 2.0325019359588623,
      "learning_rate": 2.0013947513305195e-05,
      "logits/chosen": -0.1185399517416954,
      "logits/rejected": 0.24844351410865784,
      "logps/chosen": -194.43911743164062,
      "logps/rejected": -224.3314971923828,
      "loss": 0.1161,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.923749923706055,
      "rewards/margins": 5.147815227508545,
      "rewards/rejected": -11.071565628051758,
      "step": 20590
    },
    {
      "epoch": 3.7594671046628343,
      "grad_norm": 16.92293930053711,
      "learning_rate": 1.9984584327399526e-05,
      "logits/chosen": -0.1804371029138565,
      "logits/rejected": 0.17717154324054718,
      "logps/chosen": -233.0578155517578,
      "logps/rejected": -251.7834014892578,
      "loss": 0.1523,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.8513078689575195,
      "rewards/margins": 4.351564884185791,
      "rewards/rejected": -11.202872276306152,
      "step": 20600
    },
    {
      "epoch": 3.761292088694224,
      "grad_norm": 2.028010845184326,
      "learning_rate": 1.9955221141493854e-05,
      "logits/chosen": -0.23548921942710876,
      "logits/rejected": 0.11592354625463486,
      "logps/chosen": -198.23867797851562,
      "logps/rejected": -228.8428955078125,
      "loss": 0.1626,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.877519607543945,
      "rewards/margins": 5.2823638916015625,
      "rewards/rejected": -11.159884452819824,
      "step": 20610
    },
    {
      "epoch": 3.763117072725614,
      "grad_norm": 6.082368850708008,
      "learning_rate": 1.9925857955588182e-05,
      "logits/chosen": -0.26229339838027954,
      "logits/rejected": 0.2497033178806305,
      "logps/chosen": -220.4530029296875,
      "logps/rejected": -233.2301788330078,
      "loss": 0.1402,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.37251091003418,
      "rewards/margins": 4.947221755981445,
      "rewards/rejected": -11.319732666015625,
      "step": 20620
    },
    {
      "epoch": 3.764942056757003,
      "grad_norm": 11.035544395446777,
      "learning_rate": 1.9896494769682514e-05,
      "logits/chosen": -0.2905901074409485,
      "logits/rejected": -0.056934572756290436,
      "logps/chosen": -195.75082397460938,
      "logps/rejected": -240.03781127929688,
      "loss": 0.134,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.8875956535339355,
      "rewards/margins": 4.78812313079834,
      "rewards/rejected": -10.67572021484375,
      "step": 20630
    },
    {
      "epoch": 3.766767040788393,
      "grad_norm": 1.5277798175811768,
      "learning_rate": 1.986713158377684e-05,
      "logits/chosen": -0.09818092733621597,
      "logits/rejected": 0.24856793880462646,
      "logps/chosen": -218.8185272216797,
      "logps/rejected": -243.61257934570312,
      "loss": 0.0989,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.338360786437988,
      "rewards/margins": 4.889060974121094,
      "rewards/rejected": -11.227422714233398,
      "step": 20640
    },
    {
      "epoch": 3.7685920248197826,
      "grad_norm": 4.776888370513916,
      "learning_rate": 1.983776839787117e-05,
      "logits/chosen": -0.25923290848731995,
      "logits/rejected": 0.31809356808662415,
      "logps/chosen": -223.5565643310547,
      "logps/rejected": -224.03555297851562,
      "loss": 0.1392,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.653111934661865,
      "rewards/margins": 4.798089504241943,
      "rewards/rejected": -11.451202392578125,
      "step": 20650
    },
    {
      "epoch": 3.7704170088511724,
      "grad_norm": 23.943500518798828,
      "learning_rate": 1.98084052119655e-05,
      "logits/chosen": -0.3257799446582794,
      "logits/rejected": 0.11794380843639374,
      "logps/chosen": -227.27597045898438,
      "logps/rejected": -233.2250518798828,
      "loss": 0.1753,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.885286808013916,
      "rewards/margins": 4.513805866241455,
      "rewards/rejected": -11.399091720581055,
      "step": 20660
    },
    {
      "epoch": 3.772241992882562,
      "grad_norm": 6.653346538543701,
      "learning_rate": 1.977904202605983e-05,
      "logits/chosen": -0.3577457368373871,
      "logits/rejected": 0.09275712817907333,
      "logps/chosen": -223.11679077148438,
      "logps/rejected": -238.3928985595703,
      "loss": 0.128,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.4667840003967285,
      "rewards/margins": 4.909836292266846,
      "rewards/rejected": -11.376620292663574,
      "step": 20670
    },
    {
      "epoch": 3.774066976913952,
      "grad_norm": 16.67474937438965,
      "learning_rate": 1.9749678840154157e-05,
      "logits/chosen": -0.5115094184875488,
      "logits/rejected": -0.14927740395069122,
      "logps/chosen": -222.6528778076172,
      "logps/rejected": -247.3179931640625,
      "loss": 0.1859,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.034020900726318,
      "rewards/margins": 4.689672946929932,
      "rewards/rejected": -10.723694801330566,
      "step": 20680
    },
    {
      "epoch": 3.7758919609453416,
      "grad_norm": 2.2331995964050293,
      "learning_rate": 1.9720315654248488e-05,
      "logits/chosen": -0.5070516467094421,
      "logits/rejected": -0.11898033320903778,
      "logps/chosen": -217.2941436767578,
      "logps/rejected": -235.9320526123047,
      "loss": 0.2777,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.708150863647461,
      "rewards/margins": 4.402667999267578,
      "rewards/rejected": -10.110818862915039,
      "step": 20690
    },
    {
      "epoch": 3.7777169449767314,
      "grad_norm": 15.140334129333496,
      "learning_rate": 1.9690952468342816e-05,
      "logits/chosen": -0.17140451073646545,
      "logits/rejected": 0.11534224450588226,
      "logps/chosen": -191.15277099609375,
      "logps/rejected": -216.52587890625,
      "loss": 0.2919,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.389565467834473,
      "rewards/margins": 3.9472320079803467,
      "rewards/rejected": -10.336797714233398,
      "step": 20700
    },
    {
      "epoch": 3.779541929008121,
      "grad_norm": 4.164243698120117,
      "learning_rate": 1.9661589282437144e-05,
      "logits/chosen": -0.16988039016723633,
      "logits/rejected": 0.15922603011131287,
      "logps/chosen": -199.2113037109375,
      "logps/rejected": -246.7738494873047,
      "loss": 0.0707,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.483121395111084,
      "rewards/margins": 5.1727094650268555,
      "rewards/rejected": -11.655832290649414,
      "step": 20710
    },
    {
      "epoch": 3.781366913039511,
      "grad_norm": 6.187032699584961,
      "learning_rate": 1.9632226096531476e-05,
      "logits/chosen": -0.28157156705856323,
      "logits/rejected": 0.21754908561706543,
      "logps/chosen": -206.17990112304688,
      "logps/rejected": -219.638916015625,
      "loss": 0.2087,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.393568515777588,
      "rewards/margins": 4.022711753845215,
      "rewards/rejected": -10.416279792785645,
      "step": 20720
    },
    {
      "epoch": 3.7831918970709006,
      "grad_norm": 2.535844087600708,
      "learning_rate": 1.9602862910625804e-05,
      "logits/chosen": -0.12230795621871948,
      "logits/rejected": 0.059643544256687164,
      "logps/chosen": -209.814208984375,
      "logps/rejected": -232.86929321289062,
      "loss": 0.1255,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.518927574157715,
      "rewards/margins": 4.021591663360596,
      "rewards/rejected": -10.540517807006836,
      "step": 20730
    },
    {
      "epoch": 3.7850168811022904,
      "grad_norm": 6.448303699493408,
      "learning_rate": 1.957349972472013e-05,
      "logits/chosen": -0.29300346970558167,
      "logits/rejected": -0.03820822760462761,
      "logps/chosen": -197.86672973632812,
      "logps/rejected": -217.0086669921875,
      "loss": 0.2604,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.088580131530762,
      "rewards/margins": 3.8256092071533203,
      "rewards/rejected": -8.914189338684082,
      "step": 20740
    },
    {
      "epoch": 3.78684186513368,
      "grad_norm": 13.685519218444824,
      "learning_rate": 1.9544136538814463e-05,
      "logits/chosen": -0.36369678378105164,
      "logits/rejected": -0.10071983188390732,
      "logps/chosen": -214.9125213623047,
      "logps/rejected": -226.16226196289062,
      "loss": 0.1371,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.235605239868164,
      "rewards/margins": 4.58173942565918,
      "rewards/rejected": -9.81734561920166,
      "step": 20750
    },
    {
      "epoch": 3.78866684916507,
      "grad_norm": 4.936016082763672,
      "learning_rate": 1.951477335290879e-05,
      "logits/chosen": -0.30937460064888,
      "logits/rejected": -0.000544068228919059,
      "logps/chosen": -201.4539794921875,
      "logps/rejected": -245.54287719726562,
      "loss": 0.084,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.629600524902344,
      "rewards/margins": 5.025689601898193,
      "rewards/rejected": -10.655290603637695,
      "step": 20760
    },
    {
      "epoch": 3.7904918331964597,
      "grad_norm": 14.62889575958252,
      "learning_rate": 1.948541016700312e-05,
      "logits/chosen": -0.2620924115180969,
      "logits/rejected": -0.03688553720712662,
      "logps/chosen": -218.4113006591797,
      "logps/rejected": -241.37734985351562,
      "loss": 0.1986,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.367737770080566,
      "rewards/margins": 4.5718889236450195,
      "rewards/rejected": -9.939626693725586,
      "step": 20770
    },
    {
      "epoch": 3.7923168172278494,
      "grad_norm": 5.544239044189453,
      "learning_rate": 1.945604698109745e-05,
      "logits/chosen": -0.5134559273719788,
      "logits/rejected": 0.08325205743312836,
      "logps/chosen": -203.14588928222656,
      "logps/rejected": -224.49679565429688,
      "loss": 0.1501,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.542008399963379,
      "rewards/margins": 5.158017158508301,
      "rewards/rejected": -9.70002555847168,
      "step": 20780
    },
    {
      "epoch": 3.794141801259239,
      "grad_norm": 1.4514144659042358,
      "learning_rate": 1.942668379519178e-05,
      "logits/chosen": -0.31276386976242065,
      "logits/rejected": 0.13208487629890442,
      "logps/chosen": -192.1678009033203,
      "logps/rejected": -215.36392211914062,
      "loss": 0.1588,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.699625015258789,
      "rewards/margins": 5.078084945678711,
      "rewards/rejected": -10.7777099609375,
      "step": 20790
    },
    {
      "epoch": 3.795966785290629,
      "grad_norm": 23.171245574951172,
      "learning_rate": 1.939732060928611e-05,
      "logits/chosen": -0.1360616236925125,
      "logits/rejected": 0.2140108346939087,
      "logps/chosen": -210.91958618164062,
      "logps/rejected": -230.23880004882812,
      "loss": 0.231,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.13156795501709,
      "rewards/margins": 4.861747741699219,
      "rewards/rejected": -10.993316650390625,
      "step": 20800
    },
    {
      "epoch": 3.7977917693220187,
      "grad_norm": 2.96907901763916,
      "learning_rate": 1.9367957423380437e-05,
      "logits/chosen": -0.12205398082733154,
      "logits/rejected": 0.10498960316181183,
      "logps/chosen": -202.66551208496094,
      "logps/rejected": -245.2681884765625,
      "loss": 0.0986,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.114645957946777,
      "rewards/margins": 4.5510573387146,
      "rewards/rejected": -10.665702819824219,
      "step": 20810
    },
    {
      "epoch": 3.7996167533534084,
      "grad_norm": 17.612430572509766,
      "learning_rate": 1.933859423747477e-05,
      "logits/chosen": -0.2006339728832245,
      "logits/rejected": 0.17630188167095184,
      "logps/chosen": -197.34515380859375,
      "logps/rejected": -234.8614044189453,
      "loss": 0.1775,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.719983100891113,
      "rewards/margins": 4.658917427062988,
      "rewards/rejected": -10.378900527954102,
      "step": 20820
    },
    {
      "epoch": 3.8014417373847977,
      "grad_norm": 4.04381799697876,
      "learning_rate": 1.9309231051569097e-05,
      "logits/chosen": -0.24807362258434296,
      "logits/rejected": 0.07947736978530884,
      "logps/chosen": -208.2839813232422,
      "logps/rejected": -235.5660400390625,
      "loss": 0.1899,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.601938724517822,
      "rewards/margins": 5.0100998878479,
      "rewards/rejected": -10.612039566040039,
      "step": 20830
    },
    {
      "epoch": 3.8032667214161875,
      "grad_norm": 18.057220458984375,
      "learning_rate": 1.9279867865663428e-05,
      "logits/chosen": -0.11012585461139679,
      "logits/rejected": 0.21050044894218445,
      "logps/chosen": -199.0047149658203,
      "logps/rejected": -240.2443389892578,
      "loss": 0.2382,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.050637722015381,
      "rewards/margins": 4.952608585357666,
      "rewards/rejected": -11.00324535369873,
      "step": 20840
    },
    {
      "epoch": 3.8050917054475772,
      "grad_norm": 14.314498901367188,
      "learning_rate": 1.9250504679757756e-05,
      "logits/chosen": -0.14922182261943817,
      "logits/rejected": 0.21774521470069885,
      "logps/chosen": -198.12142944335938,
      "logps/rejected": -243.7257843017578,
      "loss": 0.1294,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.252799034118652,
      "rewards/margins": 5.1435041427612305,
      "rewards/rejected": -10.396303176879883,
      "step": 20850
    },
    {
      "epoch": 3.806916689478967,
      "grad_norm": 4.798198699951172,
      "learning_rate": 1.9221141493852084e-05,
      "logits/chosen": -0.3068506717681885,
      "logits/rejected": 0.027292151004076004,
      "logps/chosen": -195.2288055419922,
      "logps/rejected": -225.02035522460938,
      "loss": 0.0855,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.328459739685059,
      "rewards/margins": 5.1004509925842285,
      "rewards/rejected": -10.428911209106445,
      "step": 20860
    },
    {
      "epoch": 3.8087416735103568,
      "grad_norm": 6.641557693481445,
      "learning_rate": 1.9191778307946415e-05,
      "logits/chosen": -0.07230351865291595,
      "logits/rejected": 0.10474224388599396,
      "logps/chosen": -191.00718688964844,
      "logps/rejected": -247.25265502929688,
      "loss": 0.1306,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.842952251434326,
      "rewards/margins": 4.776751518249512,
      "rewards/rejected": -9.61970329284668,
      "step": 20870
    },
    {
      "epoch": 3.8105666575417465,
      "grad_norm": 8.310053825378418,
      "learning_rate": 1.9162415122040743e-05,
      "logits/chosen": -0.34474143385887146,
      "logits/rejected": 0.08362241089344025,
      "logps/chosen": -198.93087768554688,
      "logps/rejected": -226.2826690673828,
      "loss": 0.1252,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.322920799255371,
      "rewards/margins": 5.7237677574157715,
      "rewards/rejected": -11.0466890335083,
      "step": 20880
    },
    {
      "epoch": 3.8123916415731363,
      "grad_norm": 3.946146249771118,
      "learning_rate": 1.913305193613507e-05,
      "logits/chosen": -0.06810881942510605,
      "logits/rejected": 0.21832895278930664,
      "logps/chosen": -193.73126220703125,
      "logps/rejected": -241.7230682373047,
      "loss": 0.1207,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.017949104309082,
      "rewards/margins": 4.9529852867126465,
      "rewards/rejected": -10.97093391418457,
      "step": 20890
    },
    {
      "epoch": 3.814216625604526,
      "grad_norm": 5.50649881362915,
      "learning_rate": 1.9103688750229403e-05,
      "logits/chosen": -0.08288218080997467,
      "logits/rejected": 0.2682880461215973,
      "logps/chosen": -212.75668334960938,
      "logps/rejected": -245.6486358642578,
      "loss": 0.3135,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.94924259185791,
      "rewards/margins": 4.714911937713623,
      "rewards/rejected": -11.664154052734375,
      "step": 20900
    },
    {
      "epoch": 3.8160416096359158,
      "grad_norm": 6.432985782623291,
      "learning_rate": 1.907432556432373e-05,
      "logits/chosen": -0.2685914933681488,
      "logits/rejected": 0.30413371324539185,
      "logps/chosen": -221.90109252929688,
      "logps/rejected": -238.490478515625,
      "loss": 0.1359,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.746640682220459,
      "rewards/margins": 5.876784324645996,
      "rewards/rejected": -11.62342643737793,
      "step": 20910
    },
    {
      "epoch": 3.8178665936673055,
      "grad_norm": 8.040210723876953,
      "learning_rate": 1.904496237841806e-05,
      "logits/chosen": -0.2165428102016449,
      "logits/rejected": 0.3123527765274048,
      "logps/chosen": -210.0263671875,
      "logps/rejected": -257.9744873046875,
      "loss": 0.1137,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.142899513244629,
      "rewards/margins": 6.0998215675354,
      "rewards/rejected": -12.242720603942871,
      "step": 20920
    },
    {
      "epoch": 3.8196915776986953,
      "grad_norm": 6.4127116203308105,
      "learning_rate": 1.901559919251239e-05,
      "logits/chosen": -0.24944813549518585,
      "logits/rejected": -0.0549137182533741,
      "logps/chosen": -188.9907684326172,
      "logps/rejected": -224.0041046142578,
      "loss": 0.2146,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.861598014831543,
      "rewards/margins": 4.446541786193848,
      "rewards/rejected": -10.30813980102539,
      "step": 20930
    },
    {
      "epoch": 3.821516561730085,
      "grad_norm": 4.890439510345459,
      "learning_rate": 1.8986236006606718e-05,
      "logits/chosen": -0.09145637601613998,
      "logits/rejected": 0.38024646043777466,
      "logps/chosen": -220.9830322265625,
      "logps/rejected": -250.1885223388672,
      "loss": 0.2165,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.7599592208862305,
      "rewards/margins": 5.137285232543945,
      "rewards/rejected": -11.897244453430176,
      "step": 20940
    },
    {
      "epoch": 3.8233415457614743,
      "grad_norm": 1.6262049674987793,
      "learning_rate": 1.8956872820701046e-05,
      "logits/chosen": -0.10888712108135223,
      "logits/rejected": 0.21289923787117004,
      "logps/chosen": -210.375244140625,
      "logps/rejected": -237.47616577148438,
      "loss": 0.2407,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.197927951812744,
      "rewards/margins": 4.977551460266113,
      "rewards/rejected": -11.1754789352417,
      "step": 20950
    },
    {
      "epoch": 3.825166529792864,
      "grad_norm": 0.651548445224762,
      "learning_rate": 1.8927509634795377e-05,
      "logits/chosen": -0.26206904649734497,
      "logits/rejected": 0.12397966533899307,
      "logps/chosen": -213.9256134033203,
      "logps/rejected": -235.2215118408203,
      "loss": 0.2131,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.9026970863342285,
      "rewards/margins": 4.850037574768066,
      "rewards/rejected": -10.752734184265137,
      "step": 20960
    },
    {
      "epoch": 3.826991513824254,
      "grad_norm": 4.206081867218018,
      "learning_rate": 1.889814644888971e-05,
      "logits/chosen": -0.20952284336090088,
      "logits/rejected": 0.3021922707557678,
      "logps/chosen": -201.7179718017578,
      "logps/rejected": -234.0318145751953,
      "loss": 0.1013,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.698474884033203,
      "rewards/margins": 5.570221424102783,
      "rewards/rejected": -11.268696784973145,
      "step": 20970
    },
    {
      "epoch": 3.8288164978556436,
      "grad_norm": 3.7503740787506104,
      "learning_rate": 1.8868783262984036e-05,
      "logits/chosen": -0.1743634194135666,
      "logits/rejected": 0.37276798486709595,
      "logps/chosen": -214.7346649169922,
      "logps/rejected": -232.5673828125,
      "loss": 0.1331,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.601131916046143,
      "rewards/margins": 5.430638790130615,
      "rewards/rejected": -11.031770706176758,
      "step": 20980
    },
    {
      "epoch": 3.8306414818870334,
      "grad_norm": 17.24786376953125,
      "learning_rate": 1.8839420077078364e-05,
      "logits/chosen": -0.28779441118240356,
      "logits/rejected": 0.1469980925321579,
      "logps/chosen": -221.5282440185547,
      "logps/rejected": -224.7270965576172,
      "loss": 0.1961,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.741221904754639,
      "rewards/margins": 4.44816780090332,
      "rewards/rejected": -10.189390182495117,
      "step": 20990
    },
    {
      "epoch": 3.832466465918423,
      "grad_norm": 5.573099613189697,
      "learning_rate": 1.8810056891172696e-05,
      "logits/chosen": -0.1783652901649475,
      "logits/rejected": 0.38942140340805054,
      "logps/chosen": -211.0322723388672,
      "logps/rejected": -225.30471801757812,
      "loss": 0.1438,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.709140777587891,
      "rewards/margins": 5.110915184020996,
      "rewards/rejected": -10.82005500793457,
      "step": 21000
    },
    {
      "epoch": 3.834291449949813,
      "grad_norm": 2.891629457473755,
      "learning_rate": 1.8780693705267024e-05,
      "logits/chosen": -0.3379373550415039,
      "logits/rejected": 0.04442504048347473,
      "logps/chosen": -207.848388671875,
      "logps/rejected": -234.2995147705078,
      "loss": 0.1258,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -4.700839519500732,
      "rewards/margins": 5.1454315185546875,
      "rewards/rejected": -9.846270561218262,
      "step": 21010
    },
    {
      "epoch": 3.8361164339812026,
      "grad_norm": 1.1832817792892456,
      "learning_rate": 1.875133051936135e-05,
      "logits/chosen": -0.22841456532478333,
      "logits/rejected": 0.24219052493572235,
      "logps/chosen": -217.53402709960938,
      "logps/rejected": -232.9622344970703,
      "loss": 0.1542,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.30631685256958,
      "rewards/margins": 4.768200874328613,
      "rewards/rejected": -10.074518203735352,
      "step": 21020
    },
    {
      "epoch": 3.8379414180125924,
      "grad_norm": 8.83786678314209,
      "learning_rate": 1.8721967333455683e-05,
      "logits/chosen": -0.2896295487880707,
      "logits/rejected": 0.24098220467567444,
      "logps/chosen": -203.97164916992188,
      "logps/rejected": -233.192138671875,
      "loss": 0.0903,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.954219341278076,
      "rewards/margins": 5.52647590637207,
      "rewards/rejected": -11.480695724487305,
      "step": 21030
    },
    {
      "epoch": 3.839766402043982,
      "grad_norm": 6.679503440856934,
      "learning_rate": 1.869260414755001e-05,
      "logits/chosen": -0.1096145287156105,
      "logits/rejected": 0.18204984068870544,
      "logps/chosen": -205.804443359375,
      "logps/rejected": -246.2478790283203,
      "loss": 0.1783,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.590273857116699,
      "rewards/margins": 4.568296432495117,
      "rewards/rejected": -10.158571243286133,
      "step": 21040
    },
    {
      "epoch": 3.841591386075372,
      "grad_norm": 11.107858657836914,
      "learning_rate": 1.866324096164434e-05,
      "logits/chosen": -0.049739859998226166,
      "logits/rejected": 0.37725967168807983,
      "logps/chosen": -196.35360717773438,
      "logps/rejected": -224.66317749023438,
      "loss": 0.1715,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.657996654510498,
      "rewards/margins": 4.503584861755371,
      "rewards/rejected": -10.161581039428711,
      "step": 21050
    },
    {
      "epoch": 3.8434163701067616,
      "grad_norm": 3.5482237339019775,
      "learning_rate": 1.863387777573867e-05,
      "logits/chosen": -0.2822340130805969,
      "logits/rejected": 0.16229799389839172,
      "logps/chosen": -209.7290802001953,
      "logps/rejected": -241.851318359375,
      "loss": 0.1668,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.494162082672119,
      "rewards/margins": 5.2318220138549805,
      "rewards/rejected": -10.725984573364258,
      "step": 21060
    },
    {
      "epoch": 3.8452413541381514,
      "grad_norm": 4.17334508895874,
      "learning_rate": 1.8604514589832998e-05,
      "logits/chosen": -0.07023020088672638,
      "logits/rejected": 0.26605433225631714,
      "logps/chosen": -229.04202270507812,
      "logps/rejected": -253.8245086669922,
      "loss": 0.2601,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.45953893661499,
      "rewards/margins": 4.456477165222168,
      "rewards/rejected": -10.916017532348633,
      "step": 21070
    },
    {
      "epoch": 3.847066338169541,
      "grad_norm": 3.517179489135742,
      "learning_rate": 1.8575151403927326e-05,
      "logits/chosen": -0.29855769872665405,
      "logits/rejected": -0.11880826950073242,
      "logps/chosen": -190.55136108398438,
      "logps/rejected": -235.72677612304688,
      "loss": 0.1617,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.617991924285889,
      "rewards/margins": 4.682692527770996,
      "rewards/rejected": -10.300684928894043,
      "step": 21080
    },
    {
      "epoch": 3.848891322200931,
      "grad_norm": 2.389664649963379,
      "learning_rate": 1.8545788218021658e-05,
      "logits/chosen": -0.34680506587028503,
      "logits/rejected": 0.13068737089633942,
      "logps/chosen": -213.21133422851562,
      "logps/rejected": -229.188720703125,
      "loss": 0.129,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -4.814642906188965,
      "rewards/margins": 5.04291296005249,
      "rewards/rejected": -9.857556343078613,
      "step": 21090
    },
    {
      "epoch": 3.8507163062323206,
      "grad_norm": 14.13180160522461,
      "learning_rate": 1.8516425032115986e-05,
      "logits/chosen": -0.30245745182037354,
      "logits/rejected": 0.12798702716827393,
      "logps/chosen": -211.15219116210938,
      "logps/rejected": -229.09133911132812,
      "loss": 0.1753,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.967141151428223,
      "rewards/margins": 5.06003999710083,
      "rewards/rejected": -10.027180671691895,
      "step": 21100
    },
    {
      "epoch": 3.8525412902637104,
      "grad_norm": 9.153404235839844,
      "learning_rate": 1.8487061846210313e-05,
      "logits/chosen": -0.1843634396791458,
      "logits/rejected": 0.1784311830997467,
      "logps/chosen": -199.6073455810547,
      "logps/rejected": -233.7070770263672,
      "loss": 0.1839,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.122932434082031,
      "rewards/margins": 4.976217746734619,
      "rewards/rejected": -10.099150657653809,
      "step": 21110
    },
    {
      "epoch": 3.8543662742951,
      "grad_norm": 1.2668777704238892,
      "learning_rate": 1.8457698660304645e-05,
      "logits/chosen": -0.2464129477739334,
      "logits/rejected": 0.13157698512077332,
      "logps/chosen": -200.1978759765625,
      "logps/rejected": -225.80850219726562,
      "loss": 0.2454,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.355163097381592,
      "rewards/margins": 4.461789131164551,
      "rewards/rejected": -9.8169527053833,
      "step": 21120
    },
    {
      "epoch": 3.85619125832649,
      "grad_norm": 5.041848182678223,
      "learning_rate": 1.8428335474398973e-05,
      "logits/chosen": -0.030282363295555115,
      "logits/rejected": 0.3246629238128662,
      "logps/chosen": -195.7393035888672,
      "logps/rejected": -230.21517944335938,
      "loss": 0.1224,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.806763648986816,
      "rewards/margins": 4.699967384338379,
      "rewards/rejected": -10.506730079650879,
      "step": 21130
    },
    {
      "epoch": 3.858016242357879,
      "grad_norm": 10.171676635742188,
      "learning_rate": 1.83989722884933e-05,
      "logits/chosen": -0.058686524629592896,
      "logits/rejected": 0.1773557960987091,
      "logps/chosen": -181.2342529296875,
      "logps/rejected": -223.91452026367188,
      "loss": 0.135,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.8578314781188965,
      "rewards/margins": 4.7619452476501465,
      "rewards/rejected": -10.619775772094727,
      "step": 21140
    },
    {
      "epoch": 3.859841226389269,
      "grad_norm": 0.4768878221511841,
      "learning_rate": 1.8369609102587632e-05,
      "logits/chosen": -0.18463341891765594,
      "logits/rejected": 0.37115567922592163,
      "logps/chosen": -206.2893524169922,
      "logps/rejected": -227.70968627929688,
      "loss": 0.129,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.982019424438477,
      "rewards/margins": 5.630265235900879,
      "rewards/rejected": -10.612284660339355,
      "step": 21150
    },
    {
      "epoch": 3.8616662104206587,
      "grad_norm": 3.5140011310577393,
      "learning_rate": 1.8340245916681963e-05,
      "logits/chosen": -0.17086632549762726,
      "logits/rejected": 0.25142064690589905,
      "logps/chosen": -205.5762939453125,
      "logps/rejected": -230.14468383789062,
      "loss": 0.1485,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.3456830978393555,
      "rewards/margins": 4.836813926696777,
      "rewards/rejected": -10.182496070861816,
      "step": 21160
    },
    {
      "epoch": 3.8634911944520485,
      "grad_norm": 10.193273544311523,
      "learning_rate": 1.831088273077629e-05,
      "logits/chosen": -0.08502313494682312,
      "logits/rejected": 0.34369510412216187,
      "logps/chosen": -200.0399627685547,
      "logps/rejected": -231.11984252929688,
      "loss": 0.1617,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.112270832061768,
      "rewards/margins": 5.150209426879883,
      "rewards/rejected": -10.262479782104492,
      "step": 21170
    },
    {
      "epoch": 3.8653161784834382,
      "grad_norm": 10.450052261352539,
      "learning_rate": 1.828151954487062e-05,
      "logits/chosen": -0.11005362123250961,
      "logits/rejected": 0.3819761872291565,
      "logps/chosen": -199.98117065429688,
      "logps/rejected": -234.3393096923828,
      "loss": 0.1391,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.581162452697754,
      "rewards/margins": 5.09346342086792,
      "rewards/rejected": -10.674625396728516,
      "step": 21180
    },
    {
      "epoch": 3.867141162514828,
      "grad_norm": 2.8167872428894043,
      "learning_rate": 1.825215635896495e-05,
      "logits/chosen": -0.030198518186807632,
      "logits/rejected": 0.15102799236774445,
      "logps/chosen": -183.15440368652344,
      "logps/rejected": -242.419921875,
      "loss": 0.2359,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.339792728424072,
      "rewards/margins": 4.803204536437988,
      "rewards/rejected": -10.142996788024902,
      "step": 21190
    },
    {
      "epoch": 3.8689661465462177,
      "grad_norm": 4.910560131072998,
      "learning_rate": 1.822279317305928e-05,
      "logits/chosen": -0.21048268675804138,
      "logits/rejected": 0.3016868233680725,
      "logps/chosen": -201.3016815185547,
      "logps/rejected": -231.13107299804688,
      "loss": 0.1363,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.179638385772705,
      "rewards/margins": 5.225826263427734,
      "rewards/rejected": -11.405464172363281,
      "step": 21200
    },
    {
      "epoch": 3.8707911305776075,
      "grad_norm": 13.695038795471191,
      "learning_rate": 1.8193429987153607e-05,
      "logits/chosen": 0.03384660929441452,
      "logits/rejected": 0.35675811767578125,
      "logps/chosen": -217.8200225830078,
      "logps/rejected": -238.09408569335938,
      "loss": 0.2645,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.003920078277588,
      "rewards/margins": 4.120461463928223,
      "rewards/rejected": -11.124380111694336,
      "step": 21210
    },
    {
      "epoch": 3.8726161146089972,
      "grad_norm": 3.8802292346954346,
      "learning_rate": 1.8164066801247938e-05,
      "logits/chosen": -0.10444822162389755,
      "logits/rejected": 0.20948739349842072,
      "logps/chosen": -203.25418090820312,
      "logps/rejected": -247.556640625,
      "loss": 0.1227,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.673803329467773,
      "rewards/margins": 4.9268598556518555,
      "rewards/rejected": -10.600663185119629,
      "step": 21220
    },
    {
      "epoch": 3.874441098640387,
      "grad_norm": 6.089618682861328,
      "learning_rate": 1.8134703615342266e-05,
      "logits/chosen": -0.1582328826189041,
      "logits/rejected": 0.2655501067638397,
      "logps/chosen": -211.2853240966797,
      "logps/rejected": -220.26412963867188,
      "loss": 0.2314,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.860288619995117,
      "rewards/margins": 4.663197994232178,
      "rewards/rejected": -10.523486137390137,
      "step": 21230
    },
    {
      "epoch": 3.8762660826717767,
      "grad_norm": 0.37604036927223206,
      "learning_rate": 1.8105340429436594e-05,
      "logits/chosen": -0.09197084605693817,
      "logits/rejected": 0.21141310036182404,
      "logps/chosen": -204.4008331298828,
      "logps/rejected": -252.21536254882812,
      "loss": 0.0898,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.334554672241211,
      "rewards/margins": 5.725529670715332,
      "rewards/rejected": -12.060083389282227,
      "step": 21240
    },
    {
      "epoch": 3.8780910667031665,
      "grad_norm": 3.426114797592163,
      "learning_rate": 1.8075977243530925e-05,
      "logits/chosen": -0.17062821984291077,
      "logits/rejected": 0.27297407388687134,
      "logps/chosen": -229.08981323242188,
      "logps/rejected": -242.21487426757812,
      "loss": 0.1574,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.855274200439453,
      "rewards/margins": 4.845105171203613,
      "rewards/rejected": -11.700380325317383,
      "step": 21250
    },
    {
      "epoch": 3.879916050734556,
      "grad_norm": 3.63118052482605,
      "learning_rate": 1.8046614057625253e-05,
      "logits/chosen": -0.15473541617393494,
      "logits/rejected": 0.40471020340919495,
      "logps/chosen": -219.8870849609375,
      "logps/rejected": -246.52487182617188,
      "loss": 0.1084,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.768223762512207,
      "rewards/margins": 5.3735198974609375,
      "rewards/rejected": -12.141743659973145,
      "step": 21260
    },
    {
      "epoch": 3.8817410347659456,
      "grad_norm": 7.130282878875732,
      "learning_rate": 1.801725087171958e-05,
      "logits/chosen": -0.1715819537639618,
      "logits/rejected": 0.41322383284568787,
      "logps/chosen": -202.91925048828125,
      "logps/rejected": -216.12258911132812,
      "loss": 0.1508,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.2960205078125,
      "rewards/margins": 4.519761085510254,
      "rewards/rejected": -10.815781593322754,
      "step": 21270
    },
    {
      "epoch": 3.8835660187973353,
      "grad_norm": 11.015494346618652,
      "learning_rate": 1.7987887685813913e-05,
      "logits/chosen": -0.11785624921321869,
      "logits/rejected": 0.2847677171230316,
      "logps/chosen": -199.52320861816406,
      "logps/rejected": -223.19747924804688,
      "loss": 0.1761,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.715456962585449,
      "rewards/margins": 5.025013446807861,
      "rewards/rejected": -10.740470886230469,
      "step": 21280
    },
    {
      "epoch": 3.885391002828725,
      "grad_norm": 12.943824768066406,
      "learning_rate": 1.795852449990824e-05,
      "logits/chosen": -0.2929851710796356,
      "logits/rejected": -0.02256377786397934,
      "logps/chosen": -184.5908203125,
      "logps/rejected": -212.42562866210938,
      "loss": 0.2095,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.053882598876953,
      "rewards/margins": 4.757935047149658,
      "rewards/rejected": -9.811817169189453,
      "step": 21290
    },
    {
      "epoch": 3.887215986860115,
      "grad_norm": 1.968557596206665,
      "learning_rate": 1.792916131400257e-05,
      "logits/chosen": -0.04483494535088539,
      "logits/rejected": 0.21535436809062958,
      "logps/chosen": -205.1338653564453,
      "logps/rejected": -253.3893280029297,
      "loss": 0.1517,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.606321811676025,
      "rewards/margins": 4.7277703285217285,
      "rewards/rejected": -11.334092140197754,
      "step": 21300
    },
    {
      "epoch": 3.8890409708915046,
      "grad_norm": 14.854785919189453,
      "learning_rate": 1.78997981280969e-05,
      "logits/chosen": -0.17865276336669922,
      "logits/rejected": 0.30016130208969116,
      "logps/chosen": -219.36257934570312,
      "logps/rejected": -240.8897705078125,
      "loss": 0.2056,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.557607173919678,
      "rewards/margins": 4.4215779304504395,
      "rewards/rejected": -10.979185104370117,
      "step": 21310
    },
    {
      "epoch": 3.8908659549228943,
      "grad_norm": 12.590656280517578,
      "learning_rate": 1.7870434942191228e-05,
      "logits/chosen": -0.3445882201194763,
      "logits/rejected": 0.034196384251117706,
      "logps/chosen": -204.63848876953125,
      "logps/rejected": -227.67446899414062,
      "loss": 0.153,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -4.982307434082031,
      "rewards/margins": 4.603135108947754,
      "rewards/rejected": -9.585443496704102,
      "step": 21320
    },
    {
      "epoch": 3.892690938954284,
      "grad_norm": 11.105701446533203,
      "learning_rate": 1.784107175628556e-05,
      "logits/chosen": -0.33451223373413086,
      "logits/rejected": 0.010153326205909252,
      "logps/chosen": -212.50448608398438,
      "logps/rejected": -237.3072509765625,
      "loss": 0.1922,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.783450126647949,
      "rewards/margins": 5.021048069000244,
      "rewards/rejected": -10.804498672485352,
      "step": 21330
    },
    {
      "epoch": 3.894515922985674,
      "grad_norm": 19.404600143432617,
      "learning_rate": 1.7811708570379887e-05,
      "logits/chosen": -0.2089087963104248,
      "logits/rejected": 0.1564515233039856,
      "logps/chosen": -218.7584686279297,
      "logps/rejected": -266.82977294921875,
      "loss": 0.2369,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.309943199157715,
      "rewards/margins": 5.007424831390381,
      "rewards/rejected": -11.317367553710938,
      "step": 21340
    },
    {
      "epoch": 3.8963409070170636,
      "grad_norm": 1.6952013969421387,
      "learning_rate": 1.778234538447422e-05,
      "logits/chosen": -0.199506014585495,
      "logits/rejected": 0.26714012026786804,
      "logps/chosen": -228.6350555419922,
      "logps/rejected": -233.459716796875,
      "loss": 0.1813,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.231532096862793,
      "rewards/margins": 3.8861069679260254,
      "rewards/rejected": -10.117639541625977,
      "step": 21350
    },
    {
      "epoch": 3.8981658910484533,
      "grad_norm": 6.036298751831055,
      "learning_rate": 1.7752982198568546e-05,
      "logits/chosen": -0.2157473862171173,
      "logits/rejected": 0.23988433182239532,
      "logps/chosen": -214.5326690673828,
      "logps/rejected": -222.7227020263672,
      "loss": 0.2203,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.209263801574707,
      "rewards/margins": 4.53048038482666,
      "rewards/rejected": -9.739744186401367,
      "step": 21360
    },
    {
      "epoch": 3.899990875079843,
      "grad_norm": 3.7617218494415283,
      "learning_rate": 1.7723619012662874e-05,
      "logits/chosen": -0.24967221915721893,
      "logits/rejected": 0.15905557572841644,
      "logps/chosen": -209.5613555908203,
      "logps/rejected": -233.30081176757812,
      "loss": 0.1116,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.5172882080078125,
      "rewards/margins": 5.101487159729004,
      "rewards/rejected": -10.618775367736816,
      "step": 21370
    },
    {
      "epoch": 3.901815859111233,
      "grad_norm": 8.139277458190918,
      "learning_rate": 1.7694255826757206e-05,
      "logits/chosen": -0.147470623254776,
      "logits/rejected": 0.04851560667157173,
      "logps/chosen": -191.0484619140625,
      "logps/rejected": -249.59896850585938,
      "loss": 0.2325,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.0370612144470215,
      "rewards/margins": 5.2914509773254395,
      "rewards/rejected": -11.328511238098145,
      "step": 21380
    },
    {
      "epoch": 3.9036408431426226,
      "grad_norm": 6.012620449066162,
      "learning_rate": 1.7664892640851534e-05,
      "logits/chosen": -0.1480318009853363,
      "logits/rejected": 0.26961496472358704,
      "logps/chosen": -219.09976196289062,
      "logps/rejected": -226.4307403564453,
      "loss": 0.0852,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.1161394119262695,
      "rewards/margins": 4.289836883544922,
      "rewards/rejected": -10.405975341796875,
      "step": 21390
    },
    {
      "epoch": 3.9054658271740124,
      "grad_norm": 3.436842918395996,
      "learning_rate": 1.763552945494586e-05,
      "logits/chosen": -0.2950342893600464,
      "logits/rejected": -0.037157852202653885,
      "logps/chosen": -195.70811462402344,
      "logps/rejected": -218.457763671875,
      "loss": 0.2115,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.925010681152344,
      "rewards/margins": 3.933267593383789,
      "rewards/rejected": -9.858278274536133,
      "step": 21400
    },
    {
      "epoch": 3.907290811205402,
      "grad_norm": 1.1125929355621338,
      "learning_rate": 1.7606166269040193e-05,
      "logits/chosen": -0.12821385264396667,
      "logits/rejected": 0.20390868186950684,
      "logps/chosen": -183.46969604492188,
      "logps/rejected": -214.4918670654297,
      "loss": 0.2071,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -4.867156028747559,
      "rewards/margins": 4.663811683654785,
      "rewards/rejected": -9.530967712402344,
      "step": 21410
    },
    {
      "epoch": 3.909115795236792,
      "grad_norm": 25.335023880004883,
      "learning_rate": 1.757680308313452e-05,
      "logits/chosen": -0.2713422179222107,
      "logits/rejected": 0.26076430082321167,
      "logps/chosen": -212.617431640625,
      "logps/rejected": -225.05941772460938,
      "loss": 0.1903,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.750035762786865,
      "rewards/margins": 5.190985679626465,
      "rewards/rejected": -10.941021919250488,
      "step": 21420
    },
    {
      "epoch": 3.9109407792681816,
      "grad_norm": 24.41592788696289,
      "learning_rate": 1.7547439897228852e-05,
      "logits/chosen": -0.2554836869239807,
      "logits/rejected": 0.19986596703529358,
      "logps/chosen": -225.20211791992188,
      "logps/rejected": -253.14089965820312,
      "loss": 0.139,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.929540157318115,
      "rewards/margins": 5.145386695861816,
      "rewards/rejected": -11.074926376342773,
      "step": 21430
    },
    {
      "epoch": 3.9127657632995714,
      "grad_norm": 7.732424259185791,
      "learning_rate": 1.751807671132318e-05,
      "logits/chosen": -0.23831939697265625,
      "logits/rejected": 0.06149981543421745,
      "logps/chosen": -199.44879150390625,
      "logps/rejected": -237.88967895507812,
      "loss": 0.1204,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.747982978820801,
      "rewards/margins": 5.002770900726318,
      "rewards/rejected": -10.750753402709961,
      "step": 21440
    },
    {
      "epoch": 3.914590747330961,
      "grad_norm": 10.217574119567871,
      "learning_rate": 1.7488713525417508e-05,
      "logits/chosen": -0.18707270920276642,
      "logits/rejected": 0.28630492091178894,
      "logps/chosen": -212.9282684326172,
      "logps/rejected": -229.0161590576172,
      "loss": 0.1038,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.813318729400635,
      "rewards/margins": 4.839515686035156,
      "rewards/rejected": -10.65283489227295,
      "step": 21450
    },
    {
      "epoch": 3.9164157313623504,
      "grad_norm": 2.0988826751708984,
      "learning_rate": 1.745935033951184e-05,
      "logits/chosen": -0.10634203255176544,
      "logits/rejected": 0.08005490154027939,
      "logps/chosen": -210.71255493164062,
      "logps/rejected": -238.4651336669922,
      "loss": 0.126,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.390124797821045,
      "rewards/margins": 4.471808433532715,
      "rewards/rejected": -10.861932754516602,
      "step": 21460
    },
    {
      "epoch": 3.91824071539374,
      "grad_norm": 3.7610256671905518,
      "learning_rate": 1.7429987153606168e-05,
      "logits/chosen": -0.07423070073127747,
      "logits/rejected": 0.3161391019821167,
      "logps/chosen": -220.9121856689453,
      "logps/rejected": -243.0548858642578,
      "loss": 0.2899,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.226088523864746,
      "rewards/margins": 4.447562217712402,
      "rewards/rejected": -10.673650741577148,
      "step": 21470
    },
    {
      "epoch": 3.92006569942513,
      "grad_norm": 10.129521369934082,
      "learning_rate": 1.7400623967700496e-05,
      "logits/chosen": -0.32102930545806885,
      "logits/rejected": -0.06031282618641853,
      "logps/chosen": -195.32327270507812,
      "logps/rejected": -231.73623657226562,
      "loss": 0.1602,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.005090236663818,
      "rewards/margins": 4.526012420654297,
      "rewards/rejected": -10.531103134155273,
      "step": 21480
    },
    {
      "epoch": 3.9218906834565197,
      "grad_norm": 2.3828816413879395,
      "learning_rate": 1.7371260781794827e-05,
      "logits/chosen": -0.1287609189748764,
      "logits/rejected": 0.25162893533706665,
      "logps/chosen": -194.7599639892578,
      "logps/rejected": -230.3760223388672,
      "loss": 0.1021,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.487299919128418,
      "rewards/margins": 4.884297847747803,
      "rewards/rejected": -10.371598243713379,
      "step": 21490
    },
    {
      "epoch": 3.9237156674879095,
      "grad_norm": 4.44356632232666,
      "learning_rate": 1.7341897595889155e-05,
      "logits/chosen": -0.1593867540359497,
      "logits/rejected": 0.16725225746631622,
      "logps/chosen": -212.13864135742188,
      "logps/rejected": -229.60256958007812,
      "loss": 0.1531,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.296988010406494,
      "rewards/margins": 4.454524040222168,
      "rewards/rejected": -9.751511573791504,
      "step": 21500
    },
    {
      "epoch": 3.925540651519299,
      "grad_norm": 2.6057209968566895,
      "learning_rate": 1.7312534409983483e-05,
      "logits/chosen": -0.1876661777496338,
      "logits/rejected": 0.0786852240562439,
      "logps/chosen": -214.56668090820312,
      "logps/rejected": -243.6118927001953,
      "loss": 0.0826,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.561326503753662,
      "rewards/margins": 5.010213375091553,
      "rewards/rejected": -11.571538925170898,
      "step": 21510
    },
    {
      "epoch": 3.927365635550689,
      "grad_norm": 16.84560203552246,
      "learning_rate": 1.7283171224077814e-05,
      "logits/chosen": -0.12962128221988678,
      "logits/rejected": 0.30959466099739075,
      "logps/chosen": -201.12301635742188,
      "logps/rejected": -236.1434783935547,
      "loss": 0.0953,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.652931213378906,
      "rewards/margins": 5.200878143310547,
      "rewards/rejected": -11.85381031036377,
      "step": 21520
    },
    {
      "epoch": 3.9291906195820787,
      "grad_norm": 8.0435209274292,
      "learning_rate": 1.7253808038172145e-05,
      "logits/chosen": -0.25257161259651184,
      "logits/rejected": 0.32014235854148865,
      "logps/chosen": -237.44497680664062,
      "logps/rejected": -250.9741668701172,
      "loss": 0.1078,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.846919059753418,
      "rewards/margins": 5.132601737976074,
      "rewards/rejected": -11.979521751403809,
      "step": 21530
    },
    {
      "epoch": 3.9310156036134685,
      "grad_norm": 7.460342884063721,
      "learning_rate": 1.7224444852266473e-05,
      "logits/chosen": -0.034945957362651825,
      "logits/rejected": 0.3214368224143982,
      "logps/chosen": -195.5765380859375,
      "logps/rejected": -229.90512084960938,
      "loss": 0.1415,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.326235294342041,
      "rewards/margins": 5.3017354011535645,
      "rewards/rejected": -11.627969741821289,
      "step": 21540
    },
    {
      "epoch": 3.932840587644858,
      "grad_norm": 10.152983665466309,
      "learning_rate": 1.71950816663608e-05,
      "logits/chosen": 0.12687155604362488,
      "logits/rejected": 0.5631969571113586,
      "logps/chosen": -203.74539184570312,
      "logps/rejected": -257.0681457519531,
      "loss": 0.0828,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.911129951477051,
      "rewards/margins": 5.761373043060303,
      "rewards/rejected": -11.672503471374512,
      "step": 21550
    },
    {
      "epoch": 3.934665571676248,
      "grad_norm": 17.85186004638672,
      "learning_rate": 1.7165718480455133e-05,
      "logits/chosen": 0.026445899158716202,
      "logits/rejected": 0.5016211271286011,
      "logps/chosen": -203.31375122070312,
      "logps/rejected": -244.79550170898438,
      "loss": 0.1666,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.978548526763916,
      "rewards/margins": 5.6385698318481445,
      "rewards/rejected": -11.617117881774902,
      "step": 21560
    },
    {
      "epoch": 3.9364905557076373,
      "grad_norm": 3.794358015060425,
      "learning_rate": 1.713635529454946e-05,
      "logits/chosen": -0.04850030690431595,
      "logits/rejected": 0.44264164566993713,
      "logps/chosen": -225.77523803710938,
      "logps/rejected": -234.5367431640625,
      "loss": 0.1911,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.146142482757568,
      "rewards/margins": 5.090031623840332,
      "rewards/rejected": -11.236173629760742,
      "step": 21570
    },
    {
      "epoch": 3.938315539739027,
      "grad_norm": 5.190387725830078,
      "learning_rate": 1.710699210864379e-05,
      "logits/chosen": 0.07167120277881622,
      "logits/rejected": 0.4625643193721771,
      "logps/chosen": -208.7776336669922,
      "logps/rejected": -260.17742919921875,
      "loss": 0.1324,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.190654277801514,
      "rewards/margins": 5.699512004852295,
      "rewards/rejected": -11.890165328979492,
      "step": 21580
    },
    {
      "epoch": 3.940140523770417,
      "grad_norm": 1.2765204906463623,
      "learning_rate": 1.707762892273812e-05,
      "logits/chosen": -0.15883228182792664,
      "logits/rejected": 0.2280171811580658,
      "logps/chosen": -196.56069946289062,
      "logps/rejected": -242.4629364013672,
      "loss": 0.1759,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.797177314758301,
      "rewards/margins": 5.556267261505127,
      "rewards/rejected": -11.353445053100586,
      "step": 21590
    },
    {
      "epoch": 3.9419655078018065,
      "grad_norm": 4.957032203674316,
      "learning_rate": 1.7048265736832448e-05,
      "logits/chosen": -0.060988835990428925,
      "logits/rejected": 0.3923550844192505,
      "logps/chosen": -214.0656280517578,
      "logps/rejected": -246.5006866455078,
      "loss": 0.2459,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.312217712402344,
      "rewards/margins": 5.43013334274292,
      "rewards/rejected": -11.742351531982422,
      "step": 21600
    },
    {
      "epoch": 3.9437904918331963,
      "grad_norm": 3.794877290725708,
      "learning_rate": 1.7018902550926776e-05,
      "logits/chosen": -0.2229917049407959,
      "logits/rejected": 0.15950386226177216,
      "logps/chosen": -204.80239868164062,
      "logps/rejected": -239.96896362304688,
      "loss": 0.1933,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.027148723602295,
      "rewards/margins": 5.0370354652404785,
      "rewards/rejected": -11.064184188842773,
      "step": 21610
    },
    {
      "epoch": 3.945615475864586,
      "grad_norm": 3.3043651580810547,
      "learning_rate": 1.6989539365021107e-05,
      "logits/chosen": -0.08771149814128876,
      "logits/rejected": 0.3583248555660248,
      "logps/chosen": -228.6752471923828,
      "logps/rejected": -247.4745635986328,
      "loss": 0.1113,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.94378662109375,
      "rewards/margins": 5.4805498123168945,
      "rewards/rejected": -11.424336433410645,
      "step": 21620
    },
    {
      "epoch": 3.947440459895976,
      "grad_norm": 0.20442399382591248,
      "learning_rate": 1.6960176179115435e-05,
      "logits/chosen": -0.1246916800737381,
      "logits/rejected": 0.33491018414497375,
      "logps/chosen": -201.3275146484375,
      "logps/rejected": -242.69894409179688,
      "loss": 0.1935,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.764685153961182,
      "rewards/margins": 5.81489372253418,
      "rewards/rejected": -11.579577445983887,
      "step": 21630
    },
    {
      "epoch": 3.9492654439273656,
      "grad_norm": 0.8251091837882996,
      "learning_rate": 1.6930812993209763e-05,
      "logits/chosen": 0.01502738893032074,
      "logits/rejected": 0.28535303473472595,
      "logps/chosen": -218.90859985351562,
      "logps/rejected": -266.65850830078125,
      "loss": 0.0638,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.554593086242676,
      "rewards/margins": 5.656774997711182,
      "rewards/rejected": -12.2113676071167,
      "step": 21640
    },
    {
      "epoch": 3.9510904279587553,
      "grad_norm": 17.123149871826172,
      "learning_rate": 1.6901449807304095e-05,
      "logits/chosen": 0.07909401506185532,
      "logits/rejected": 0.48420315980911255,
      "logps/chosen": -197.18789672851562,
      "logps/rejected": -242.6936798095703,
      "loss": 0.2572,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -7.1747331619262695,
      "rewards/margins": 4.994277000427246,
      "rewards/rejected": -12.1690092086792,
      "step": 21650
    },
    {
      "epoch": 3.952915411990145,
      "grad_norm": 1.5276683568954468,
      "learning_rate": 1.6872086621398423e-05,
      "logits/chosen": -0.00979558564722538,
      "logits/rejected": 0.38230112195014954,
      "logps/chosen": -205.6623077392578,
      "logps/rejected": -254.2231903076172,
      "loss": 0.2355,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.860114097595215,
      "rewards/margins": 5.1915411949157715,
      "rewards/rejected": -12.051654815673828,
      "step": 21660
    },
    {
      "epoch": 3.954740396021535,
      "grad_norm": 7.503791332244873,
      "learning_rate": 1.684272343549275e-05,
      "logits/chosen": 0.21603581309318542,
      "logits/rejected": 0.7429732084274292,
      "logps/chosen": -211.0503692626953,
      "logps/rejected": -238.6599578857422,
      "loss": 0.2039,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.898048400878906,
      "rewards/margins": 5.2295331954956055,
      "rewards/rejected": -12.127582550048828,
      "step": 21670
    },
    {
      "epoch": 3.9565653800529246,
      "grad_norm": 14.958525657653809,
      "learning_rate": 1.681629656817765e-05,
      "logits/chosen": 0.025518495589494705,
      "logits/rejected": 0.4332013726234436,
      "logps/chosen": -223.40585327148438,
      "logps/rejected": -260.5440673828125,
      "loss": 0.2031,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.138009071350098,
      "rewards/margins": 5.185628890991211,
      "rewards/rejected": -12.323637962341309,
      "step": 21680
    },
    {
      "epoch": 3.9583903640843143,
      "grad_norm": 5.028975486755371,
      "learning_rate": 1.6786933382271977e-05,
      "logits/chosen": 0.12257301807403564,
      "logits/rejected": 0.46369224786758423,
      "logps/chosen": -204.38333129882812,
      "logps/rejected": -252.1680145263672,
      "loss": 0.1764,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.868098258972168,
      "rewards/margins": 5.624192714691162,
      "rewards/rejected": -12.492291450500488,
      "step": 21690
    },
    {
      "epoch": 3.960215348115704,
      "grad_norm": 7.069336414337158,
      "learning_rate": 1.6757570196366305e-05,
      "logits/chosen": 0.10257656872272491,
      "logits/rejected": 0.6210923790931702,
      "logps/chosen": -229.27456665039062,
      "logps/rejected": -242.9366455078125,
      "loss": 0.1302,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.087596893310547,
      "rewards/margins": 4.875917911529541,
      "rewards/rejected": -11.96351432800293,
      "step": 21700
    },
    {
      "epoch": 3.962040332147094,
      "grad_norm": 18.276960372924805,
      "learning_rate": 1.6731143329051203e-05,
      "logits/chosen": 0.06490439921617508,
      "logits/rejected": 0.4394855499267578,
      "logps/chosen": -201.511962890625,
      "logps/rejected": -245.16622924804688,
      "loss": 0.1316,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.583530426025391,
      "rewards/margins": 5.3495869636535645,
      "rewards/rejected": -11.933117866516113,
      "step": 21710
    },
    {
      "epoch": 3.9638653161784836,
      "grad_norm": 12.524089813232422,
      "learning_rate": 1.670178014314553e-05,
      "logits/chosen": 0.3274146616458893,
      "logits/rejected": 0.6494272351264954,
      "logps/chosen": -208.4542236328125,
      "logps/rejected": -242.23703002929688,
      "loss": 0.2799,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.48388671875,
      "rewards/margins": 4.360480785369873,
      "rewards/rejected": -11.844367027282715,
      "step": 21720
    },
    {
      "epoch": 3.9656903002098733,
      "grad_norm": 12.536639213562012,
      "learning_rate": 1.6672416957239862e-05,
      "logits/chosen": 0.04239155352115631,
      "logits/rejected": 0.695311963558197,
      "logps/chosen": -219.2509765625,
      "logps/rejected": -242.83395385742188,
      "loss": 0.2022,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.097329139709473,
      "rewards/margins": 4.934074878692627,
      "rewards/rejected": -12.031404495239258,
      "step": 21730
    },
    {
      "epoch": 3.967515284241263,
      "grad_norm": 9.15008544921875,
      "learning_rate": 1.6643053771334194e-05,
      "logits/chosen": 0.019186880439519882,
      "logits/rejected": 0.4551849961280823,
      "logps/chosen": -230.9455108642578,
      "logps/rejected": -255.91995239257812,
      "loss": 0.2132,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.641866207122803,
      "rewards/margins": 4.760878086090088,
      "rewards/rejected": -12.402743339538574,
      "step": 21740
    },
    {
      "epoch": 3.969340268272653,
      "grad_norm": 11.66266918182373,
      "learning_rate": 1.661369058542852e-05,
      "logits/chosen": -0.11976277828216553,
      "logits/rejected": 0.44755393266677856,
      "logps/chosen": -245.0158233642578,
      "logps/rejected": -250.3144989013672,
      "loss": 0.2033,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.545004844665527,
      "rewards/margins": 4.592608451843262,
      "rewards/rejected": -11.137613296508789,
      "step": 21750
    },
    {
      "epoch": 3.9711652523040426,
      "grad_norm": 16.34845542907715,
      "learning_rate": 1.658432739952285e-05,
      "logits/chosen": -0.13090646266937256,
      "logits/rejected": 0.17810404300689697,
      "logps/chosen": -220.18258666992188,
      "logps/rejected": -261.0569152832031,
      "loss": 0.1676,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.942171573638916,
      "rewards/margins": 5.030336856842041,
      "rewards/rejected": -11.97250747680664,
      "step": 21760
    },
    {
      "epoch": 3.972990236335432,
      "grad_norm": 4.5569987297058105,
      "learning_rate": 1.655496421361718e-05,
      "logits/chosen": -0.15351885557174683,
      "logits/rejected": 0.40278783440589905,
      "logps/chosen": -220.39404296875,
      "logps/rejected": -240.009765625,
      "loss": 0.2355,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.73345947265625,
      "rewards/margins": 5.063830375671387,
      "rewards/rejected": -11.797289848327637,
      "step": 21770
    },
    {
      "epoch": 3.9748152203668217,
      "grad_norm": 8.095519065856934,
      "learning_rate": 1.652560102771151e-05,
      "logits/chosen": 0.08100156486034393,
      "logits/rejected": 0.41774195432662964,
      "logps/chosen": -203.58291625976562,
      "logps/rejected": -226.05703735351562,
      "loss": 0.2115,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.438124656677246,
      "rewards/margins": 4.5691328048706055,
      "rewards/rejected": -11.007257461547852,
      "step": 21780
    },
    {
      "epoch": 3.9766402043982114,
      "grad_norm": 14.717473983764648,
      "learning_rate": 1.6496237841805837e-05,
      "logits/chosen": -0.06502697616815567,
      "logits/rejected": 0.4085058271884918,
      "logps/chosen": -204.7086944580078,
      "logps/rejected": -244.2292022705078,
      "loss": 0.1557,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.904744625091553,
      "rewards/margins": 5.188117504119873,
      "rewards/rejected": -12.092864036560059,
      "step": 21790
    },
    {
      "epoch": 3.978465188429601,
      "grad_norm": 8.561269760131836,
      "learning_rate": 1.6466874655900168e-05,
      "logits/chosen": 0.0317053385078907,
      "logits/rejected": 0.797883927822113,
      "logps/chosen": -221.81436157226562,
      "logps/rejected": -238.3441162109375,
      "loss": 0.1014,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.160304069519043,
      "rewards/margins": 5.01961612701416,
      "rewards/rejected": -12.179919242858887,
      "step": 21800
    },
    {
      "epoch": 3.980290172460991,
      "grad_norm": 13.702595710754395,
      "learning_rate": 1.6437511469994496e-05,
      "logits/chosen": 0.39265233278274536,
      "logits/rejected": 0.5894697308540344,
      "logps/chosen": -230.45077514648438,
      "logps/rejected": -277.1379089355469,
      "loss": 0.2158,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -8.210630416870117,
      "rewards/margins": 4.962288856506348,
      "rewards/rejected": -13.172920227050781,
      "step": 21810
    },
    {
      "epoch": 3.9821151564923807,
      "grad_norm": 20.163156509399414,
      "learning_rate": 1.6408148284088824e-05,
      "logits/chosen": 0.35709577798843384,
      "logits/rejected": 0.8659025430679321,
      "logps/chosen": -222.2764892578125,
      "logps/rejected": -252.55307006835938,
      "loss": 0.1804,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -8.420969009399414,
      "rewards/margins": 5.022266864776611,
      "rewards/rejected": -13.443235397338867,
      "step": 21820
    },
    {
      "epoch": 3.9839401405237704,
      "grad_norm": 15.623615264892578,
      "learning_rate": 1.6378785098183155e-05,
      "logits/chosen": -0.006555879022926092,
      "logits/rejected": 0.37153512239456177,
      "logps/chosen": -203.34872436523438,
      "logps/rejected": -254.51901245117188,
      "loss": 0.1843,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.579066276550293,
      "rewards/margins": 5.305759429931641,
      "rewards/rejected": -11.884825706481934,
      "step": 21830
    },
    {
      "epoch": 3.98576512455516,
      "grad_norm": 8.30611515045166,
      "learning_rate": 1.6349421912277483e-05,
      "logits/chosen": 0.08385597169399261,
      "logits/rejected": 0.48550987243652344,
      "logps/chosen": -213.04702758789062,
      "logps/rejected": -240.0065460205078,
      "loss": 0.2166,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.851153373718262,
      "rewards/margins": 4.813027381896973,
      "rewards/rejected": -11.664180755615234,
      "step": 21840
    },
    {
      "epoch": 3.98759010858655,
      "grad_norm": 9.14689826965332,
      "learning_rate": 1.632005872637181e-05,
      "logits/chosen": 0.17993071675300598,
      "logits/rejected": 0.5689439177513123,
      "logps/chosen": -208.8246307373047,
      "logps/rejected": -261.45111083984375,
      "loss": 0.0647,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.864962100982666,
      "rewards/margins": 5.695563316345215,
      "rewards/rejected": -12.560525894165039,
      "step": 21850
    },
    {
      "epoch": 3.9894150926179397,
      "grad_norm": 1.8452690839767456,
      "learning_rate": 1.6290695540466143e-05,
      "logits/chosen": -0.07179205119609833,
      "logits/rejected": 0.3596957325935364,
      "logps/chosen": -211.29776000976562,
      "logps/rejected": -241.12747192382812,
      "loss": 0.2076,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.348873138427734,
      "rewards/margins": 5.167054176330566,
      "rewards/rejected": -11.5159273147583,
      "step": 21860
    },
    {
      "epoch": 3.9912400766493294,
      "grad_norm": 6.376572132110596,
      "learning_rate": 1.626133235456047e-05,
      "logits/chosen": -0.2161063402891159,
      "logits/rejected": 0.25475820899009705,
      "logps/chosen": -227.4114227294922,
      "logps/rejected": -251.953369140625,
      "loss": 0.1257,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.166990280151367,
      "rewards/margins": 5.181110382080078,
      "rewards/rejected": -11.348100662231445,
      "step": 21870
    },
    {
      "epoch": 3.993065060680719,
      "grad_norm": 14.619941711425781,
      "learning_rate": 1.62319691686548e-05,
      "logits/chosen": -0.1730366200208664,
      "logits/rejected": 0.36156535148620605,
      "logps/chosen": -227.14285278320312,
      "logps/rejected": -248.1470184326172,
      "loss": 0.1871,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.738736152648926,
      "rewards/margins": 4.915166854858398,
      "rewards/rejected": -11.653901100158691,
      "step": 21880
    },
    {
      "epoch": 3.9948900447121085,
      "grad_norm": 8.411712646484375,
      "learning_rate": 1.620260598274913e-05,
      "logits/chosen": -0.1828518807888031,
      "logits/rejected": 0.13980849087238312,
      "logps/chosen": -195.46609497070312,
      "logps/rejected": -241.78622436523438,
      "loss": 0.0917,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.8375244140625,
      "rewards/margins": 5.6039276123046875,
      "rewards/rejected": -11.441452026367188,
      "step": 21890
    },
    {
      "epoch": 3.9967150287434983,
      "grad_norm": 1.4582523107528687,
      "learning_rate": 1.6173242796843458e-05,
      "logits/chosen": 0.016084151342511177,
      "logits/rejected": 0.24037238955497742,
      "logps/chosen": -204.30136108398438,
      "logps/rejected": -258.6812744140625,
      "loss": 0.1322,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.109078884124756,
      "rewards/margins": 5.536402702331543,
      "rewards/rejected": -12.645482063293457,
      "step": 21900
    },
    {
      "epoch": 3.998540012774888,
      "grad_norm": 1.9095842838287354,
      "learning_rate": 1.6143879610937786e-05,
      "logits/chosen": -0.009211179800331593,
      "logits/rejected": 0.29635292291641235,
      "logps/chosen": -197.38478088378906,
      "logps/rejected": -237.5612335205078,
      "loss": 0.1655,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.069554328918457,
      "rewards/margins": 4.728018283843994,
      "rewards/rejected": -11.797572135925293,
      "step": 21910
    },
    {
      "epoch": 4.000364996806278,
      "grad_norm": 5.946271896362305,
      "learning_rate": 1.6114516425032117e-05,
      "logits/chosen": -0.2543758749961853,
      "logits/rejected": 0.3514690101146698,
      "logps/chosen": -212.449951171875,
      "logps/rejected": -228.41513061523438,
      "loss": 0.1127,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.814979553222656,
      "rewards/margins": 4.9274678230285645,
      "rewards/rejected": -10.742446899414062,
      "step": 21920
    },
    {
      "epoch": 4.0021899808376675,
      "grad_norm": 1.4928480386734009,
      "learning_rate": 1.608515323912645e-05,
      "logits/chosen": -0.05891333892941475,
      "logits/rejected": 0.26558738946914673,
      "logps/chosen": -193.36087036132812,
      "logps/rejected": -244.1234893798828,
      "loss": 0.0392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.797313213348389,
      "rewards/margins": 5.724733352661133,
      "rewards/rejected": -11.52204704284668,
      "step": 21930
    },
    {
      "epoch": 4.004014964869057,
      "grad_norm": 1.2966816425323486,
      "learning_rate": 1.6055790053220776e-05,
      "logits/chosen": -0.12934251129627228,
      "logits/rejected": 0.38503342866897583,
      "logps/chosen": -201.32403564453125,
      "logps/rejected": -257.4157409667969,
      "loss": 0.026,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.169991493225098,
      "rewards/margins": 6.527148246765137,
      "rewards/rejected": -12.69714069366455,
      "step": 21940
    },
    {
      "epoch": 4.005839948900447,
      "grad_norm": 8.749626159667969,
      "learning_rate": 1.6026426867315104e-05,
      "logits/chosen": -0.08553741872310638,
      "logits/rejected": 0.49092739820480347,
      "logps/chosen": -226.6314239501953,
      "logps/rejected": -256.0852355957031,
      "loss": 0.036,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.509433746337891,
      "rewards/margins": 6.180764198303223,
      "rewards/rejected": -12.69019889831543,
      "step": 21950
    },
    {
      "epoch": 4.007664932931837,
      "grad_norm": 19.592731475830078,
      "learning_rate": 1.5997063681409436e-05,
      "logits/chosen": 0.16571716964244843,
      "logits/rejected": 0.5667738318443298,
      "logps/chosen": -190.65335083007812,
      "logps/rejected": -230.212158203125,
      "loss": 0.1524,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.064698219299316,
      "rewards/margins": 5.418581962585449,
      "rewards/rejected": -11.48327922821045,
      "step": 21960
    },
    {
      "epoch": 4.0094899169632265,
      "grad_norm": 1.9619555473327637,
      "learning_rate": 1.5967700495503764e-05,
      "logits/chosen": -0.0889306515455246,
      "logits/rejected": 0.25688499212265015,
      "logps/chosen": -227.44143676757812,
      "logps/rejected": -279.8922424316406,
      "loss": 0.0282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.096303462982178,
      "rewards/margins": 6.204151630401611,
      "rewards/rejected": -13.300455093383789,
      "step": 21970
    },
    {
      "epoch": 4.011314900994616,
      "grad_norm": 15.689210891723633,
      "learning_rate": 1.5938337309598092e-05,
      "logits/chosen": -0.16760249435901642,
      "logits/rejected": 0.2240263968706131,
      "logps/chosen": -217.50967407226562,
      "logps/rejected": -264.7353210449219,
      "loss": 0.0554,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.3826093673706055,
      "rewards/margins": 6.202588081359863,
      "rewards/rejected": -12.585197448730469,
      "step": 21980
    },
    {
      "epoch": 4.013139885026006,
      "grad_norm": 1.4448444843292236,
      "learning_rate": 1.5908974123692423e-05,
      "logits/chosen": 0.0052444813773036,
      "logits/rejected": 0.4402858316898346,
      "logps/chosen": -241.11141967773438,
      "logps/rejected": -261.9235534667969,
      "loss": 0.1345,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.357113838195801,
      "rewards/margins": 5.899572849273682,
      "rewards/rejected": -13.256686210632324,
      "step": 21990
    },
    {
      "epoch": 4.014964869057396,
      "grad_norm": 0.41978582739830017,
      "learning_rate": 1.587961093778675e-05,
      "logits/chosen": -0.12107739597558975,
      "logits/rejected": 0.4494626522064209,
      "logps/chosen": -216.45510864257812,
      "logps/rejected": -247.14404296875,
      "loss": 0.0457,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.534554958343506,
      "rewards/margins": 6.2923126220703125,
      "rewards/rejected": -12.826868057250977,
      "step": 22000
    },
    {
      "epoch": 4.0167898530887856,
      "grad_norm": 9.886252403259277,
      "learning_rate": 1.585024775188108e-05,
      "logits/chosen": 0.0864703580737114,
      "logits/rejected": 0.45230618119239807,
      "logps/chosen": -193.90037536621094,
      "logps/rejected": -258.02801513671875,
      "loss": 0.081,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.392672538757324,
      "rewards/margins": 6.477025032043457,
      "rewards/rejected": -12.869699478149414,
      "step": 22010
    },
    {
      "epoch": 4.018614837120175,
      "grad_norm": 0.8538004755973816,
      "learning_rate": 1.582088456597541e-05,
      "logits/chosen": 0.06841035187244415,
      "logits/rejected": 0.5010660290718079,
      "logps/chosen": -208.81103515625,
      "logps/rejected": -261.04937744140625,
      "loss": 0.0674,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.148845672607422,
      "rewards/margins": 5.912662506103516,
      "rewards/rejected": -12.061507225036621,
      "step": 22020
    },
    {
      "epoch": 4.020439821151565,
      "grad_norm": 0.5950330495834351,
      "learning_rate": 1.579152138006974e-05,
      "logits/chosen": -0.2290571928024292,
      "logits/rejected": 0.6245321035385132,
      "logps/chosen": -223.6171112060547,
      "logps/rejected": -259.08154296875,
      "loss": 0.062,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.627295017242432,
      "rewards/margins": 6.264500617980957,
      "rewards/rejected": -12.891797065734863,
      "step": 22030
    },
    {
      "epoch": 4.022264805182955,
      "grad_norm": 11.029129981994629,
      "learning_rate": 1.5762158194164066e-05,
      "logits/chosen": -0.031408581882715225,
      "logits/rejected": 0.41249769926071167,
      "logps/chosen": -200.57223510742188,
      "logps/rejected": -249.8292694091797,
      "loss": 0.1438,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.4349565505981445,
      "rewards/margins": 6.03111457824707,
      "rewards/rejected": -12.466070175170898,
      "step": 22040
    },
    {
      "epoch": 4.024089789214345,
      "grad_norm": 36.68435287475586,
      "learning_rate": 1.5732795008258398e-05,
      "logits/chosen": 0.03339898958802223,
      "logits/rejected": 0.6650558710098267,
      "logps/chosen": -211.2251434326172,
      "logps/rejected": -247.54037475585938,
      "loss": 0.094,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.85590124130249,
      "rewards/margins": 5.894949913024902,
      "rewards/rejected": -12.75085163116455,
      "step": 22050
    },
    {
      "epoch": 4.025914773245734,
      "grad_norm": 2.8120288848876953,
      "learning_rate": 1.5703431822352726e-05,
      "logits/chosen": 0.40631818771362305,
      "logits/rejected": 1.157058835029602,
      "logps/chosen": -210.4835662841797,
      "logps/rejected": -240.9357452392578,
      "loss": 0.0394,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.912171363830566,
      "rewards/margins": 6.288017749786377,
      "rewards/rejected": -13.200187683105469,
      "step": 22060
    },
    {
      "epoch": 4.027739757277124,
      "grad_norm": 2.1963906288146973,
      "learning_rate": 1.5674068636447054e-05,
      "logits/chosen": 0.03876354545354843,
      "logits/rejected": 0.4981512129306793,
      "logps/chosen": -218.5269775390625,
      "logps/rejected": -256.14642333984375,
      "loss": 0.0398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.746859073638916,
      "rewards/margins": 5.877056121826172,
      "rewards/rejected": -12.623915672302246,
      "step": 22070
    },
    {
      "epoch": 4.029564741308514,
      "grad_norm": 8.079331398010254,
      "learning_rate": 1.5644705450541385e-05,
      "logits/chosen": 0.3147958815097809,
      "logits/rejected": 0.8225787878036499,
      "logps/chosen": -201.52001953125,
      "logps/rejected": -247.8320770263672,
      "loss": 0.0603,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.4705376625061035,
      "rewards/margins": 5.444853782653809,
      "rewards/rejected": -11.915390968322754,
      "step": 22080
    },
    {
      "epoch": 4.031389725339904,
      "grad_norm": 11.259969711303711,
      "learning_rate": 1.5615342264635713e-05,
      "logits/chosen": 0.021299295127391815,
      "logits/rejected": 0.4279225468635559,
      "logps/chosen": -222.96810913085938,
      "logps/rejected": -257.51470947265625,
      "loss": 0.0636,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.185994625091553,
      "rewards/margins": 5.385727405548096,
      "rewards/rejected": -12.571722030639648,
      "step": 22090
    },
    {
      "epoch": 4.033214709371293,
      "grad_norm": 3.7554495334625244,
      "learning_rate": 1.558597907873004e-05,
      "logits/chosen": 0.23393802344799042,
      "logits/rejected": 0.7210684418678284,
      "logps/chosen": -226.45382690429688,
      "logps/rejected": -263.1003112792969,
      "loss": 0.09,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.024098873138428,
      "rewards/margins": 5.649502754211426,
      "rewards/rejected": -12.673602104187012,
      "step": 22100
    },
    {
      "epoch": 4.035039693402683,
      "grad_norm": 2.4405288696289062,
      "learning_rate": 1.5556615892824372e-05,
      "logits/chosen": 0.036045901477336884,
      "logits/rejected": 0.37655988335609436,
      "logps/chosen": -185.9302520751953,
      "logps/rejected": -240.88858032226562,
      "loss": 0.0296,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.234602928161621,
      "rewards/margins": 5.8441619873046875,
      "rewards/rejected": -12.078763961791992,
      "step": 22110
    },
    {
      "epoch": 4.036864677434073,
      "grad_norm": 1.7354497909545898,
      "learning_rate": 1.5527252706918704e-05,
      "logits/chosen": 0.07923731207847595,
      "logits/rejected": 0.6929971575737,
      "logps/chosen": -225.9618377685547,
      "logps/rejected": -238.1522674560547,
      "loss": 0.0951,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.576420783996582,
      "rewards/margins": 5.6397881507873535,
      "rewards/rejected": -12.216207504272461,
      "step": 22120
    },
    {
      "epoch": 4.038689661465463,
      "grad_norm": 0.9878931045532227,
      "learning_rate": 1.549788952101303e-05,
      "logits/chosen": 0.13496540486812592,
      "logits/rejected": 0.6377394795417786,
      "logps/chosen": -197.11048889160156,
      "logps/rejected": -250.0301971435547,
      "loss": 0.0302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.212679862976074,
      "rewards/margins": 6.174264907836914,
      "rewards/rejected": -12.386944770812988,
      "step": 22130
    },
    {
      "epoch": 4.0405146454968515,
      "grad_norm": 1.0484912395477295,
      "learning_rate": 1.546852633510736e-05,
      "logits/chosen": 0.10134287923574448,
      "logits/rejected": 0.6937239766120911,
      "logps/chosen": -213.1062469482422,
      "logps/rejected": -257.81280517578125,
      "loss": 0.1054,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.733483791351318,
      "rewards/margins": 6.1041107177734375,
      "rewards/rejected": -12.837594985961914,
      "step": 22140
    },
    {
      "epoch": 4.042339629528241,
      "grad_norm": 13.109088897705078,
      "learning_rate": 1.543916314920169e-05,
      "logits/chosen": 0.02998533472418785,
      "logits/rejected": 0.47147274017333984,
      "logps/chosen": -213.6947021484375,
      "logps/rejected": -251.54959106445312,
      "loss": 0.0967,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.095371246337891,
      "rewards/margins": 6.217618942260742,
      "rewards/rejected": -13.312990188598633,
      "step": 22150
    },
    {
      "epoch": 4.044164613559631,
      "grad_norm": 1.061160683631897,
      "learning_rate": 1.540979996329602e-05,
      "logits/chosen": -0.09977944195270538,
      "logits/rejected": 0.5207332372665405,
      "logps/chosen": -209.3557586669922,
      "logps/rejected": -245.57754516601562,
      "loss": 0.0544,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.800418853759766,
      "rewards/margins": 6.360596656799316,
      "rewards/rejected": -12.161016464233398,
      "step": 22160
    },
    {
      "epoch": 4.045989597591021,
      "grad_norm": 2.5310826301574707,
      "learning_rate": 1.538043677739035e-05,
      "logits/chosen": 0.1852707415819168,
      "logits/rejected": 0.4410654604434967,
      "logps/chosen": -225.4508056640625,
      "logps/rejected": -279.298828125,
      "loss": 0.0525,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.886282920837402,
      "rewards/margins": 6.411881923675537,
      "rewards/rejected": -14.298162460327148,
      "step": 22170
    },
    {
      "epoch": 4.0478145816224105,
      "grad_norm": 0.505466878414154,
      "learning_rate": 1.5351073591484678e-05,
      "logits/chosen": 0.1663343906402588,
      "logits/rejected": 0.467386394739151,
      "logps/chosen": -205.62118530273438,
      "logps/rejected": -271.427734375,
      "loss": 0.0688,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.669405460357666,
      "rewards/margins": 7.162331581115723,
      "rewards/rejected": -13.83173656463623,
      "step": 22180
    },
    {
      "epoch": 4.0496395656538,
      "grad_norm": 12.228811264038086,
      "learning_rate": 1.5321710405579006e-05,
      "logits/chosen": -0.008757039904594421,
      "logits/rejected": 0.3171837329864502,
      "logps/chosen": -215.20687866210938,
      "logps/rejected": -285.5466003417969,
      "loss": 0.0305,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.641496181488037,
      "rewards/margins": 7.287772178649902,
      "rewards/rejected": -13.929269790649414,
      "step": 22190
    },
    {
      "epoch": 4.05146454968519,
      "grad_norm": 0.8444608449935913,
      "learning_rate": 1.5292347219673337e-05,
      "logits/chosen": 0.12634174525737762,
      "logits/rejected": 0.5696048736572266,
      "logps/chosen": -221.5801544189453,
      "logps/rejected": -252.68545532226562,
      "loss": 0.0774,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.166690826416016,
      "rewards/margins": 6.002293586730957,
      "rewards/rejected": -13.168986320495605,
      "step": 22200
    },
    {
      "epoch": 4.05328953371658,
      "grad_norm": 10.018072128295898,
      "learning_rate": 1.5262984033767665e-05,
      "logits/chosen": 0.2970772385597229,
      "logits/rejected": 0.765235960483551,
      "logps/chosen": -199.7095489501953,
      "logps/rejected": -252.5604248046875,
      "loss": 0.0991,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.116776943206787,
      "rewards/margins": 5.942617893218994,
      "rewards/rejected": -13.059392929077148,
      "step": 22210
    },
    {
      "epoch": 4.0551145177479695,
      "grad_norm": 4.249797821044922,
      "learning_rate": 1.5233620847861993e-05,
      "logits/chosen": -0.016466720029711723,
      "logits/rejected": 0.4635395109653473,
      "logps/chosen": -214.0216827392578,
      "logps/rejected": -261.5600891113281,
      "loss": 0.1061,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.1947221755981445,
      "rewards/margins": 6.467874050140381,
      "rewards/rejected": -12.662595748901367,
      "step": 22220
    },
    {
      "epoch": 4.056939501779359,
      "grad_norm": 1.468469262123108,
      "learning_rate": 1.5204257661956323e-05,
      "logits/chosen": 0.24030891060829163,
      "logits/rejected": 0.7554832696914673,
      "logps/chosen": -212.6936492919922,
      "logps/rejected": -236.1830596923828,
      "loss": 0.0871,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.039801120758057,
      "rewards/margins": 5.441484451293945,
      "rewards/rejected": -12.481287002563477,
      "step": 22230
    },
    {
      "epoch": 4.058764485810749,
      "grad_norm": 2.2467854022979736,
      "learning_rate": 1.5174894476050653e-05,
      "logits/chosen": 0.22042317688465118,
      "logits/rejected": 0.5427383780479431,
      "logps/chosen": -218.6835479736328,
      "logps/rejected": -271.0447692871094,
      "loss": 0.1204,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.790595054626465,
      "rewards/margins": 6.107353210449219,
      "rewards/rejected": -12.89794921875,
      "step": 22240
    },
    {
      "epoch": 4.060589469842139,
      "grad_norm": 6.202486991882324,
      "learning_rate": 1.514553129014498e-05,
      "logits/chosen": 0.073263019323349,
      "logits/rejected": 0.7101711630821228,
      "logps/chosen": -214.962646484375,
      "logps/rejected": -252.29373168945312,
      "loss": 0.0576,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.4335455894470215,
      "rewards/margins": 6.160789489746094,
      "rewards/rejected": -13.594337463378906,
      "step": 22250
    },
    {
      "epoch": 4.0624144538735285,
      "grad_norm": 2.331953287124634,
      "learning_rate": 1.511616810423931e-05,
      "logits/chosen": 0.2556248605251312,
      "logits/rejected": 0.6277721524238586,
      "logps/chosen": -207.46401977539062,
      "logps/rejected": -260.2222595214844,
      "loss": 0.0449,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.700120449066162,
      "rewards/margins": 6.18692684173584,
      "rewards/rejected": -13.887046813964844,
      "step": 22260
    },
    {
      "epoch": 4.064239437904918,
      "grad_norm": 2.6916072368621826,
      "learning_rate": 1.508680491833364e-05,
      "logits/chosen": 0.1021750420331955,
      "logits/rejected": 0.425208181142807,
      "logps/chosen": -210.89559936523438,
      "logps/rejected": -271.3525390625,
      "loss": 0.0866,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.919602870941162,
      "rewards/margins": 6.260424613952637,
      "rewards/rejected": -13.180028915405273,
      "step": 22270
    },
    {
      "epoch": 4.066064421936308,
      "grad_norm": 1.1529756784439087,
      "learning_rate": 1.5057441732427968e-05,
      "logits/chosen": 0.3994421362876892,
      "logits/rejected": 0.8774269223213196,
      "logps/chosen": -197.5858154296875,
      "logps/rejected": -259.96533203125,
      "loss": 0.0492,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.396330833435059,
      "rewards/margins": 6.60933780670166,
      "rewards/rejected": -14.005668640136719,
      "step": 22280
    },
    {
      "epoch": 4.067889405967698,
      "grad_norm": 0.9423540234565735,
      "learning_rate": 1.5028078546522298e-05,
      "logits/chosen": 0.08650074899196625,
      "logits/rejected": 0.49542236328125,
      "logps/chosen": -206.3448028564453,
      "logps/rejected": -269.10308837890625,
      "loss": 0.0556,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.5734686851501465,
      "rewards/margins": 6.815870761871338,
      "rewards/rejected": -13.389341354370117,
      "step": 22290
    },
    {
      "epoch": 4.0697143899990875,
      "grad_norm": 1.1355561017990112,
      "learning_rate": 1.4998715360616629e-05,
      "logits/chosen": 0.212836354970932,
      "logits/rejected": 0.5754011869430542,
      "logps/chosen": -202.2312469482422,
      "logps/rejected": -273.1017761230469,
      "loss": 0.0766,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.923394680023193,
      "rewards/margins": 6.745059013366699,
      "rewards/rejected": -13.66845417022705,
      "step": 22300
    },
    {
      "epoch": 4.071539374030477,
      "grad_norm": 2.7270147800445557,
      "learning_rate": 1.4969352174710959e-05,
      "logits/chosen": 0.021571028977632523,
      "logits/rejected": 0.6054419875144958,
      "logps/chosen": -223.37173461914062,
      "logps/rejected": -267.65484619140625,
      "loss": 0.1169,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.246645450592041,
      "rewards/margins": 6.8624162673950195,
      "rewards/rejected": -14.109062194824219,
      "step": 22310
    },
    {
      "epoch": 4.073364358061867,
      "grad_norm": 28.607959747314453,
      "learning_rate": 1.4939988988805288e-05,
      "logits/chosen": -0.03589958697557449,
      "logits/rejected": 0.6439022421836853,
      "logps/chosen": -227.3406219482422,
      "logps/rejected": -267.1306457519531,
      "loss": 0.1733,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.847878932952881,
      "rewards/margins": 6.703336238861084,
      "rewards/rejected": -13.551216125488281,
      "step": 22320
    },
    {
      "epoch": 4.075189342093257,
      "grad_norm": 3.170295238494873,
      "learning_rate": 1.4910625802899616e-05,
      "logits/chosen": 0.2001308649778366,
      "logits/rejected": 0.5567713975906372,
      "logps/chosen": -204.8317108154297,
      "logps/rejected": -251.74172973632812,
      "loss": 0.0883,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.170507907867432,
      "rewards/margins": 5.5424089431762695,
      "rewards/rejected": -12.712918281555176,
      "step": 22330
    },
    {
      "epoch": 4.0770143261246465,
      "grad_norm": 15.185805320739746,
      "learning_rate": 1.4881262616993946e-05,
      "logits/chosen": 0.1251843273639679,
      "logits/rejected": 0.5139592885971069,
      "logps/chosen": -210.023193359375,
      "logps/rejected": -266.90911865234375,
      "loss": 0.0836,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.59175968170166,
      "rewards/margins": 6.806832790374756,
      "rewards/rejected": -13.398592948913574,
      "step": 22340
    },
    {
      "epoch": 4.078839310156036,
      "grad_norm": 1.386231541633606,
      "learning_rate": 1.4851899431088275e-05,
      "logits/chosen": 0.11544579267501831,
      "logits/rejected": 0.8367396593093872,
      "logps/chosen": -226.2423095703125,
      "logps/rejected": -249.98049926757812,
      "loss": 0.0412,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.1190571784973145,
      "rewards/margins": 6.874453067779541,
      "rewards/rejected": -12.993510246276855,
      "step": 22350
    },
    {
      "epoch": 4.080664294187426,
      "grad_norm": 8.760393142700195,
      "learning_rate": 1.4822536245182603e-05,
      "logits/chosen": 0.023990854620933533,
      "logits/rejected": 0.7100853323936462,
      "logps/chosen": -214.33737182617188,
      "logps/rejected": -244.44140625,
      "loss": 0.1154,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.483942985534668,
      "rewards/margins": 5.965720176696777,
      "rewards/rejected": -12.449663162231445,
      "step": 22360
    },
    {
      "epoch": 4.082489278218816,
      "grad_norm": 2.8829240798950195,
      "learning_rate": 1.4793173059276933e-05,
      "logits/chosen": 0.3649147152900696,
      "logits/rejected": 0.6998797655105591,
      "logps/chosen": -203.16983032226562,
      "logps/rejected": -264.8599853515625,
      "loss": 0.0539,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.048503875732422,
      "rewards/margins": 6.083374500274658,
      "rewards/rejected": -13.131876945495605,
      "step": 22370
    },
    {
      "epoch": 4.0843142622502056,
      "grad_norm": 0.8006681799888611,
      "learning_rate": 1.4763809873371263e-05,
      "logits/chosen": 0.1648373156785965,
      "logits/rejected": 0.7879206538200378,
      "logps/chosen": -216.2245635986328,
      "logps/rejected": -253.978271484375,
      "loss": 0.1786,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.42569637298584,
      "rewards/margins": 5.822190284729004,
      "rewards/rejected": -13.247888565063477,
      "step": 22380
    },
    {
      "epoch": 4.086139246281595,
      "grad_norm": 1.6441335678100586,
      "learning_rate": 1.473444668746559e-05,
      "logits/chosen": 0.047797370702028275,
      "logits/rejected": 0.4679277837276459,
      "logps/chosen": -222.82498168945312,
      "logps/rejected": -256.254638671875,
      "loss": 0.2059,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.342867374420166,
      "rewards/margins": 5.769861221313477,
      "rewards/rejected": -13.1127290725708,
      "step": 22390
    },
    {
      "epoch": 4.087964230312985,
      "grad_norm": 0.2526360750198364,
      "learning_rate": 1.470508350155992e-05,
      "logits/chosen": -0.09595441818237305,
      "logits/rejected": 0.4679364562034607,
      "logps/chosen": -217.35421752929688,
      "logps/rejected": -246.1739044189453,
      "loss": 0.0574,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.401747226715088,
      "rewards/margins": 5.639398097991943,
      "rewards/rejected": -12.041145324707031,
      "step": 22400
    },
    {
      "epoch": 4.089789214344375,
      "grad_norm": 1.8441118001937866,
      "learning_rate": 1.467572031565425e-05,
      "logits/chosen": 0.19499853253364563,
      "logits/rejected": 0.509490966796875,
      "logps/chosen": -215.9313201904297,
      "logps/rejected": -268.05316162109375,
      "loss": 0.1467,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.75503396987915,
      "rewards/margins": 6.076785564422607,
      "rewards/rejected": -13.831819534301758,
      "step": 22410
    },
    {
      "epoch": 4.091614198375765,
      "grad_norm": 0.522333025932312,
      "learning_rate": 1.4646357129748578e-05,
      "logits/chosen": 0.338517963886261,
      "logits/rejected": 0.686003565788269,
      "logps/chosen": -214.61416625976562,
      "logps/rejected": -258.1509704589844,
      "loss": 0.0695,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.551092624664307,
      "rewards/margins": 5.547325611114502,
      "rewards/rejected": -13.098419189453125,
      "step": 22420
    },
    {
      "epoch": 4.093439182407154,
      "grad_norm": 14.927011489868164,
      "learning_rate": 1.4616993943842908e-05,
      "logits/chosen": -0.11130638420581818,
      "logits/rejected": 0.5782227516174316,
      "logps/chosen": -221.9939727783203,
      "logps/rejected": -242.58071899414062,
      "loss": 0.0794,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.238785266876221,
      "rewards/margins": 5.7629218101501465,
      "rewards/rejected": -12.001707077026367,
      "step": 22430
    },
    {
      "epoch": 4.095264166438544,
      "grad_norm": 5.407474517822266,
      "learning_rate": 1.4587630757937237e-05,
      "logits/chosen": -0.03628081828355789,
      "logits/rejected": 0.2745990753173828,
      "logps/chosen": -208.54183959960938,
      "logps/rejected": -249.41152954101562,
      "loss": 0.0714,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.096814155578613,
      "rewards/margins": 5.412608623504639,
      "rewards/rejected": -12.509420394897461,
      "step": 22440
    },
    {
      "epoch": 4.097089150469934,
      "grad_norm": 6.793804168701172,
      "learning_rate": 1.4558267572031565e-05,
      "logits/chosen": -0.015693798661231995,
      "logits/rejected": 0.43246251344680786,
      "logps/chosen": -227.553466796875,
      "logps/rejected": -248.8150634765625,
      "loss": 0.0986,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.8502702713012695,
      "rewards/margins": 5.635046005249023,
      "rewards/rejected": -12.485316276550293,
      "step": 22450
    },
    {
      "epoch": 4.098914134501323,
      "grad_norm": 0.49263983964920044,
      "learning_rate": 1.4528904386125895e-05,
      "logits/chosen": 0.1034085601568222,
      "logits/rejected": 0.6010359525680542,
      "logps/chosen": -206.9665069580078,
      "logps/rejected": -240.9465789794922,
      "loss": 0.0283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.6596503257751465,
      "rewards/margins": 6.11837100982666,
      "rewards/rejected": -12.778020858764648,
      "step": 22460
    },
    {
      "epoch": 4.1007391185327124,
      "grad_norm": 1.5499123334884644,
      "learning_rate": 1.4499541200220225e-05,
      "logits/chosen": 0.06184149906039238,
      "logits/rejected": 0.6453127264976501,
      "logps/chosen": -224.11514282226562,
      "logps/rejected": -250.61782836914062,
      "loss": 0.1153,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.923776149749756,
      "rewards/margins": 5.763730525970459,
      "rewards/rejected": -12.687505722045898,
      "step": 22470
    },
    {
      "epoch": 4.102564102564102,
      "grad_norm": 2.4498372077941895,
      "learning_rate": 1.4470178014314556e-05,
      "logits/chosen": 0.021574294194579124,
      "logits/rejected": 0.5974013209342957,
      "logps/chosen": -216.1605682373047,
      "logps/rejected": -254.8246612548828,
      "loss": 0.0602,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.981978416442871,
      "rewards/margins": 6.679364204406738,
      "rewards/rejected": -12.66134262084961,
      "step": 22480
    },
    {
      "epoch": 4.104389086595492,
      "grad_norm": 2.547328472137451,
      "learning_rate": 1.4440814828408884e-05,
      "logits/chosen": 0.018930703401565552,
      "logits/rejected": 0.5493398904800415,
      "logps/chosen": -216.7677764892578,
      "logps/rejected": -239.4508514404297,
      "loss": 0.0421,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.609151363372803,
      "rewards/margins": 5.790864944458008,
      "rewards/rejected": -12.400015830993652,
      "step": 22490
    },
    {
      "epoch": 4.106214070626882,
      "grad_norm": 2.9304792881011963,
      "learning_rate": 1.4411451642503214e-05,
      "logits/chosen": 0.05419214814901352,
      "logits/rejected": 0.4536428451538086,
      "logps/chosen": -218.2374267578125,
      "logps/rejected": -266.85308837890625,
      "loss": 0.025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.9148125648498535,
      "rewards/margins": 6.673791408538818,
      "rewards/rejected": -13.588604927062988,
      "step": 22500
    },
    {
      "epoch": 4.1080390546582715,
      "grad_norm": 2.0220961570739746,
      "learning_rate": 1.4382088456597543e-05,
      "logits/chosen": 0.3245174288749695,
      "logits/rejected": 0.8432000279426575,
      "logps/chosen": -243.02963256835938,
      "logps/rejected": -274.8283996582031,
      "loss": 0.0783,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.561238765716553,
      "rewards/margins": 6.664403438568115,
      "rewards/rejected": -14.225642204284668,
      "step": 22510
    },
    {
      "epoch": 4.109864038689661,
      "grad_norm": 2.347090244293213,
      "learning_rate": 1.4352725270691871e-05,
      "logits/chosen": 0.11478382349014282,
      "logits/rejected": 0.737472414970398,
      "logps/chosen": -226.3954620361328,
      "logps/rejected": -274.4278869628906,
      "loss": 0.0517,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.258660793304443,
      "rewards/margins": 7.010629177093506,
      "rewards/rejected": -14.269291877746582,
      "step": 22520
    },
    {
      "epoch": 4.111689022721051,
      "grad_norm": 2.86203670501709,
      "learning_rate": 1.43233620847862e-05,
      "logits/chosen": 0.22630958259105682,
      "logits/rejected": 0.6257716417312622,
      "logps/chosen": -212.22396850585938,
      "logps/rejected": -268.7156677246094,
      "loss": 0.0229,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.913219451904297,
      "rewards/margins": 6.663977146148682,
      "rewards/rejected": -13.57719612121582,
      "step": 22530
    },
    {
      "epoch": 4.113514006752441,
      "grad_norm": 1.5338712930679321,
      "learning_rate": 1.429399889888053e-05,
      "logits/chosen": 0.24648840725421906,
      "logits/rejected": 1.1028468608856201,
      "logps/chosen": -235.1593475341797,
      "logps/rejected": -273.896484375,
      "loss": 0.0163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.884118556976318,
      "rewards/margins": 7.201547145843506,
      "rewards/rejected": -14.085667610168457,
      "step": 22540
    },
    {
      "epoch": 4.1153389907838305,
      "grad_norm": 19.186477661132812,
      "learning_rate": 1.4264635712974858e-05,
      "logits/chosen": 0.08344676345586777,
      "logits/rejected": 0.3851236402988434,
      "logps/chosen": -201.80856323242188,
      "logps/rejected": -259.8778076171875,
      "loss": 0.0718,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.321099758148193,
      "rewards/margins": 6.643775939941406,
      "rewards/rejected": -13.964876174926758,
      "step": 22550
    },
    {
      "epoch": 4.11716397481522,
      "grad_norm": 1.9874399900436401,
      "learning_rate": 1.4235272527069188e-05,
      "logits/chosen": 0.47058191895484924,
      "logits/rejected": 0.5868455767631531,
      "logps/chosen": -216.78805541992188,
      "logps/rejected": -304.21600341796875,
      "loss": 0.1019,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.237783432006836,
      "rewards/margins": 6.321465492248535,
      "rewards/rejected": -14.559247970581055,
      "step": 22560
    },
    {
      "epoch": 4.11898895884661,
      "grad_norm": 0.6961532235145569,
      "learning_rate": 1.4205909341163518e-05,
      "logits/chosen": 0.3522156774997711,
      "logits/rejected": 0.6122195720672607,
      "logps/chosen": -210.6146240234375,
      "logps/rejected": -287.17510986328125,
      "loss": 0.0372,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.002279758453369,
      "rewards/margins": 7.060053825378418,
      "rewards/rejected": -14.062335014343262,
      "step": 22570
    },
    {
      "epoch": 4.120813942878,
      "grad_norm": 18.99716567993164,
      "learning_rate": 1.4176546155257846e-05,
      "logits/chosen": 0.28604328632354736,
      "logits/rejected": 0.5489313006401062,
      "logps/chosen": -223.2345428466797,
      "logps/rejected": -270.82586669921875,
      "loss": 0.1179,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -7.254186153411865,
      "rewards/margins": 5.726538181304932,
      "rewards/rejected": -12.980725288391113,
      "step": 22580
    },
    {
      "epoch": 4.1226389269093895,
      "grad_norm": 3.387582302093506,
      "learning_rate": 1.4147182969352175e-05,
      "logits/chosen": 0.2171751707792282,
      "logits/rejected": 0.7275309562683105,
      "logps/chosen": -208.7662811279297,
      "logps/rejected": -254.7720947265625,
      "loss": 0.0562,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.418341159820557,
      "rewards/margins": 6.525606632232666,
      "rewards/rejected": -12.943946838378906,
      "step": 22590
    },
    {
      "epoch": 4.124463910940779,
      "grad_norm": 0.8283702731132507,
      "learning_rate": 1.4117819783446505e-05,
      "logits/chosen": 0.3012039065361023,
      "logits/rejected": 0.7012538909912109,
      "logps/chosen": -225.49526977539062,
      "logps/rejected": -270.3668212890625,
      "loss": 0.0825,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.576698303222656,
      "rewards/margins": 6.434650421142578,
      "rewards/rejected": -14.01134967803955,
      "step": 22600
    },
    {
      "epoch": 4.126288894972169,
      "grad_norm": 8.935127258300781,
      "learning_rate": 1.4088456597540835e-05,
      "logits/chosen": 0.10419269651174545,
      "logits/rejected": 0.6576839089393616,
      "logps/chosen": -215.76925659179688,
      "logps/rejected": -242.60153198242188,
      "loss": 0.1073,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.282243728637695,
      "rewards/margins": 5.7960357666015625,
      "rewards/rejected": -12.078280448913574,
      "step": 22610
    },
    {
      "epoch": 4.128113879003559,
      "grad_norm": 0.6040970087051392,
      "learning_rate": 1.4059093411635163e-05,
      "logits/chosen": 0.20401370525360107,
      "logits/rejected": 0.8124922513961792,
      "logps/chosen": -205.4593048095703,
      "logps/rejected": -258.6054382324219,
      "loss": 0.023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.4410552978515625,
      "rewards/margins": 7.209275245666504,
      "rewards/rejected": -13.65032958984375,
      "step": 22620
    },
    {
      "epoch": 4.1299388630349485,
      "grad_norm": 0.7282588481903076,
      "learning_rate": 1.4029730225729492e-05,
      "logits/chosen": 0.17869052290916443,
      "logits/rejected": 0.8230961561203003,
      "logps/chosen": -217.23974609375,
      "logps/rejected": -254.2186279296875,
      "loss": 0.0719,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.393328666687012,
      "rewards/margins": 6.5089311599731445,
      "rewards/rejected": -12.902259826660156,
      "step": 22630
    },
    {
      "epoch": 4.131763847066338,
      "grad_norm": 1.1130343675613403,
      "learning_rate": 1.4000367039823822e-05,
      "logits/chosen": 0.36803123354911804,
      "logits/rejected": 0.6966625452041626,
      "logps/chosen": -233.7610626220703,
      "logps/rejected": -288.26483154296875,
      "loss": 0.0251,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.991854667663574,
      "rewards/margins": 6.6265106201171875,
      "rewards/rejected": -14.618367195129395,
      "step": 22640
    },
    {
      "epoch": 4.133588831097728,
      "grad_norm": 2.0196497440338135,
      "learning_rate": 1.397100385391815e-05,
      "logits/chosen": 0.4763045310974121,
      "logits/rejected": 1.012852668762207,
      "logps/chosen": -250.1702880859375,
      "logps/rejected": -277.65594482421875,
      "loss": 0.0926,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.798102378845215,
      "rewards/margins": 5.383100986480713,
      "rewards/rejected": -14.18120288848877,
      "step": 22650
    },
    {
      "epoch": 4.135413815129118,
      "grad_norm": 2.7429254055023193,
      "learning_rate": 1.394164066801248e-05,
      "logits/chosen": 0.2805783450603485,
      "logits/rejected": 0.7575787305831909,
      "logps/chosen": -223.43057250976562,
      "logps/rejected": -257.87261962890625,
      "loss": 0.0585,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.509082794189453,
      "rewards/margins": 5.426705360412598,
      "rewards/rejected": -12.93578815460205,
      "step": 22660
    },
    {
      "epoch": 4.1372387991605075,
      "grad_norm": 0.3812777101993561,
      "learning_rate": 1.3912277482106811e-05,
      "logits/chosen": 0.34572580456733704,
      "logits/rejected": 0.911065399646759,
      "logps/chosen": -234.9574432373047,
      "logps/rejected": -284.47418212890625,
      "loss": 0.0193,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.073787689208984,
      "rewards/margins": 6.4777021408081055,
      "rewards/rejected": -13.551488876342773,
      "step": 22670
    },
    {
      "epoch": 4.139063783191897,
      "grad_norm": 14.215241432189941,
      "learning_rate": 1.388291429620114e-05,
      "logits/chosen": 0.22506539523601532,
      "logits/rejected": 0.8165802955627441,
      "logps/chosen": -215.3947296142578,
      "logps/rejected": -263.69354248046875,
      "loss": 0.0394,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.085838317871094,
      "rewards/margins": 7.164845943450928,
      "rewards/rejected": -14.25068473815918,
      "step": 22680
    },
    {
      "epoch": 4.140888767223287,
      "grad_norm": 4.558383941650391,
      "learning_rate": 1.3853551110295469e-05,
      "logits/chosen": 0.34066861867904663,
      "logits/rejected": 0.8523117899894714,
      "logps/chosen": -217.275634765625,
      "logps/rejected": -254.66543579101562,
      "loss": 0.0884,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.621425628662109,
      "rewards/margins": 6.319695472717285,
      "rewards/rejected": -13.941119194030762,
      "step": 22690
    },
    {
      "epoch": 4.142713751254677,
      "grad_norm": 0.520296573638916,
      "learning_rate": 1.3824187924389798e-05,
      "logits/chosen": 0.48289790749549866,
      "logits/rejected": 0.7855256795883179,
      "logps/chosen": -207.14810180664062,
      "logps/rejected": -266.7810974121094,
      "loss": 0.0884,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.254601955413818,
      "rewards/margins": 6.287974834442139,
      "rewards/rejected": -13.542577743530273,
      "step": 22700
    },
    {
      "epoch": 4.1445387352860665,
      "grad_norm": 8.491079330444336,
      "learning_rate": 1.3794824738484128e-05,
      "logits/chosen": 0.2646789848804474,
      "logits/rejected": 0.7406998872756958,
      "logps/chosen": -211.16842651367188,
      "logps/rejected": -258.27947998046875,
      "loss": 0.0554,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.347352027893066,
      "rewards/margins": 5.8409199714660645,
      "rewards/rejected": -13.188272476196289,
      "step": 22710
    },
    {
      "epoch": 4.146363719317456,
      "grad_norm": 4.295498371124268,
      "learning_rate": 1.3765461552578456e-05,
      "logits/chosen": 0.14248065650463104,
      "logits/rejected": 0.7144723534584045,
      "logps/chosen": -229.18057250976562,
      "logps/rejected": -262.8642272949219,
      "loss": 0.1636,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -8.311962127685547,
      "rewards/margins": 5.308269023895264,
      "rewards/rejected": -13.620231628417969,
      "step": 22720
    },
    {
      "epoch": 4.148188703348846,
      "grad_norm": 8.655646324157715,
      "learning_rate": 1.3736098366672785e-05,
      "logits/chosen": 0.20210309326648712,
      "logits/rejected": 0.8848806619644165,
      "logps/chosen": -207.659423828125,
      "logps/rejected": -252.53762817382812,
      "loss": 0.0236,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.354165554046631,
      "rewards/margins": 6.692380428314209,
      "rewards/rejected": -14.046545028686523,
      "step": 22730
    },
    {
      "epoch": 4.150013687380236,
      "grad_norm": 11.738202095031738,
      "learning_rate": 1.3706735180767115e-05,
      "logits/chosen": 0.018654193729162216,
      "logits/rejected": 0.5510485768318176,
      "logps/chosen": -217.85549926757812,
      "logps/rejected": -254.9976043701172,
      "loss": 0.0443,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.8726654052734375,
      "rewards/margins": 6.430356502532959,
      "rewards/rejected": -12.303022384643555,
      "step": 22740
    },
    {
      "epoch": 4.1518386714116255,
      "grad_norm": 0.6057745814323425,
      "learning_rate": 1.3677371994861443e-05,
      "logits/chosen": 0.18328557908535004,
      "logits/rejected": 0.6952099800109863,
      "logps/chosen": -193.2699432373047,
      "logps/rejected": -252.23898315429688,
      "loss": 0.0417,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.053770542144775,
      "rewards/margins": 7.2978363037109375,
      "rewards/rejected": -13.351606369018555,
      "step": 22750
    },
    {
      "epoch": 4.153663655443015,
      "grad_norm": 0.4771101772785187,
      "learning_rate": 1.3648008808955773e-05,
      "logits/chosen": 0.20304259657859802,
      "logits/rejected": 0.6810135841369629,
      "logps/chosen": -231.41650390625,
      "logps/rejected": -274.3645324707031,
      "loss": 0.0469,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.998651027679443,
      "rewards/margins": 6.6682538986206055,
      "rewards/rejected": -14.666905403137207,
      "step": 22760
    },
    {
      "epoch": 4.155488639474404,
      "grad_norm": 0.974681556224823,
      "learning_rate": 1.3618645623050102e-05,
      "logits/chosen": 0.17704086005687714,
      "logits/rejected": 0.6962398886680603,
      "logps/chosen": -225.180908203125,
      "logps/rejected": -274.52862548828125,
      "loss": 0.0227,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.108392238616943,
      "rewards/margins": 6.570220947265625,
      "rewards/rejected": -13.678614616394043,
      "step": 22770
    },
    {
      "epoch": 4.157313623505794,
      "grad_norm": 18.771671295166016,
      "learning_rate": 1.358928243714443e-05,
      "logits/chosen": 0.3041064143180847,
      "logits/rejected": 1.0321471691131592,
      "logps/chosen": -239.3358612060547,
      "logps/rejected": -269.2509460449219,
      "loss": 0.0849,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.064806938171387,
      "rewards/margins": 6.6693220138549805,
      "rewards/rejected": -13.73412799835205,
      "step": 22780
    },
    {
      "epoch": 4.159138607537184,
      "grad_norm": 0.8446043729782104,
      "learning_rate": 1.355991925123876e-05,
      "logits/chosen": 0.5061150789260864,
      "logits/rejected": 1.1548080444335938,
      "logps/chosen": -215.0611114501953,
      "logps/rejected": -271.483154296875,
      "loss": 0.0888,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.954160213470459,
      "rewards/margins": 6.686199188232422,
      "rewards/rejected": -14.640357971191406,
      "step": 22790
    },
    {
      "epoch": 4.160963591568573,
      "grad_norm": 0.3173794448375702,
      "learning_rate": 1.353055606533309e-05,
      "logits/chosen": 0.47618943452835083,
      "logits/rejected": 1.050759196281433,
      "logps/chosen": -221.68197631835938,
      "logps/rejected": -269.4107971191406,
      "loss": 0.101,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.370926856994629,
      "rewards/margins": 7.052786827087402,
      "rewards/rejected": -14.423715591430664,
      "step": 22800
    },
    {
      "epoch": 4.162788575599963,
      "grad_norm": 1.6653434038162231,
      "learning_rate": 1.3501192879427418e-05,
      "logits/chosen": 0.15799151360988617,
      "logits/rejected": 0.7655454874038696,
      "logps/chosen": -209.88888549804688,
      "logps/rejected": -243.17422485351562,
      "loss": 0.0941,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.608587741851807,
      "rewards/margins": 6.407642364501953,
      "rewards/rejected": -13.016230583190918,
      "step": 22810
    },
    {
      "epoch": 4.164613559631353,
      "grad_norm": 6.5301289558410645,
      "learning_rate": 1.3471829693521747e-05,
      "logits/chosen": 0.2470104992389679,
      "logits/rejected": 0.7465195655822754,
      "logps/chosen": -221.19100952148438,
      "logps/rejected": -251.4856414794922,
      "loss": 0.0979,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.962704658508301,
      "rewards/margins": 5.983217716217041,
      "rewards/rejected": -12.945920944213867,
      "step": 22820
    },
    {
      "epoch": 4.166438543662743,
      "grad_norm": 3.0324487686157227,
      "learning_rate": 1.3442466507616077e-05,
      "logits/chosen": 0.1511904001235962,
      "logits/rejected": 0.8294987678527832,
      "logps/chosen": -223.8286590576172,
      "logps/rejected": -270.08282470703125,
      "loss": 0.1116,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.943171501159668,
      "rewards/margins": 7.242463111877441,
      "rewards/rejected": -14.185635566711426,
      "step": 22830
    },
    {
      "epoch": 4.168263527694132,
      "grad_norm": 9.109484672546387,
      "learning_rate": 1.3413103321710405e-05,
      "logits/chosen": 0.11184795945882797,
      "logits/rejected": 0.7272548675537109,
      "logps/chosen": -213.65713500976562,
      "logps/rejected": -248.65908813476562,
      "loss": 0.1111,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.681052207946777,
      "rewards/margins": 5.969583988189697,
      "rewards/rejected": -12.650635719299316,
      "step": 22840
    },
    {
      "epoch": 4.170088511725522,
      "grad_norm": 6.623809814453125,
      "learning_rate": 1.3383740135804736e-05,
      "logits/chosen": 0.3155798316001892,
      "logits/rejected": 0.9812721014022827,
      "logps/chosen": -217.8671875,
      "logps/rejected": -264.3023376464844,
      "loss": 0.0404,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.347863674163818,
      "rewards/margins": 7.412433624267578,
      "rewards/rejected": -14.760297775268555,
      "step": 22850
    },
    {
      "epoch": 4.171913495756912,
      "grad_norm": 12.086394309997559,
      "learning_rate": 1.3354376949899066e-05,
      "logits/chosen": 0.22622962296009064,
      "logits/rejected": 0.784839928150177,
      "logps/chosen": -229.25390625,
      "logps/rejected": -277.6275329589844,
      "loss": 0.0983,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.987301826477051,
      "rewards/margins": 6.346982002258301,
      "rewards/rejected": -14.334284782409668,
      "step": 22860
    },
    {
      "epoch": 4.173738479788302,
      "grad_norm": 9.631407737731934,
      "learning_rate": 1.3325013763993396e-05,
      "logits/chosen": 0.16963493824005127,
      "logits/rejected": 0.5786465406417847,
      "logps/chosen": -227.29373168945312,
      "logps/rejected": -279.218017578125,
      "loss": 0.0418,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.230560302734375,
      "rewards/margins": 6.956355094909668,
      "rewards/rejected": -15.186915397644043,
      "step": 22870
    },
    {
      "epoch": 4.1755634638196915,
      "grad_norm": 12.79338264465332,
      "learning_rate": 1.3295650578087723e-05,
      "logits/chosen": 0.12078440189361572,
      "logits/rejected": 0.5158094167709351,
      "logps/chosen": -230.78396606445312,
      "logps/rejected": -275.9017028808594,
      "loss": 0.0451,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.007466316223145,
      "rewards/margins": 6.262646675109863,
      "rewards/rejected": -14.270112991333008,
      "step": 22880
    },
    {
      "epoch": 4.177388447851081,
      "grad_norm": 6.73845911026001,
      "learning_rate": 1.3266287392182053e-05,
      "logits/chosen": 0.06575695425271988,
      "logits/rejected": 0.48127618432044983,
      "logps/chosen": -214.8727569580078,
      "logps/rejected": -273.75469970703125,
      "loss": 0.1056,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.156468868255615,
      "rewards/margins": 7.031237602233887,
      "rewards/rejected": -14.187705993652344,
      "step": 22890
    },
    {
      "epoch": 4.179213431882471,
      "grad_norm": 0.32972684502601624,
      "learning_rate": 1.3236924206276383e-05,
      "logits/chosen": 0.06064283847808838,
      "logits/rejected": 0.4441224932670593,
      "logps/chosen": -226.679443359375,
      "logps/rejected": -282.0902404785156,
      "loss": 0.0983,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.562986850738525,
      "rewards/margins": 6.720096588134766,
      "rewards/rejected": -14.28308391571045,
      "step": 22900
    },
    {
      "epoch": 4.181038415913861,
      "grad_norm": 0.057527974247932434,
      "learning_rate": 1.3207561020370712e-05,
      "logits/chosen": 0.2611596882343292,
      "logits/rejected": 0.5093169808387756,
      "logps/chosen": -233.5336151123047,
      "logps/rejected": -306.1932373046875,
      "loss": 0.0683,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.524065017700195,
      "rewards/margins": 6.80393123626709,
      "rewards/rejected": -15.327997207641602,
      "step": 22910
    },
    {
      "epoch": 4.1828633999452505,
      "grad_norm": 25.846336364746094,
      "learning_rate": 1.317819783446504e-05,
      "logits/chosen": 0.30080705881118774,
      "logits/rejected": 0.5684589743614197,
      "logps/chosen": -195.99209594726562,
      "logps/rejected": -268.19891357421875,
      "loss": 0.1442,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.960911750793457,
      "rewards/margins": 6.5182366371154785,
      "rewards/rejected": -14.479148864746094,
      "step": 22920
    },
    {
      "epoch": 4.18468838397664,
      "grad_norm": 2.1874353885650635,
      "learning_rate": 1.314883464855937e-05,
      "logits/chosen": 0.11041168868541718,
      "logits/rejected": 0.7267743349075317,
      "logps/chosen": -211.9750518798828,
      "logps/rejected": -266.0809326171875,
      "loss": 0.061,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.220412254333496,
      "rewards/margins": 7.240843296051025,
      "rewards/rejected": -14.46125602722168,
      "step": 22930
    },
    {
      "epoch": 4.18651336800803,
      "grad_norm": 7.2294111251831055,
      "learning_rate": 1.31194714626537e-05,
      "logits/chosen": 0.1425844430923462,
      "logits/rejected": 0.4524369239807129,
      "logps/chosen": -194.3944549560547,
      "logps/rejected": -244.8073272705078,
      "loss": 0.0471,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.410706520080566,
      "rewards/margins": 6.233489036560059,
      "rewards/rejected": -12.644195556640625,
      "step": 22940
    },
    {
      "epoch": 4.18833835203942,
      "grad_norm": 1.9782514572143555,
      "learning_rate": 1.3090108276748028e-05,
      "logits/chosen": 0.2393939197063446,
      "logits/rejected": 0.5581311583518982,
      "logps/chosen": -233.05020141601562,
      "logps/rejected": -281.19708251953125,
      "loss": 0.0715,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.672841548919678,
      "rewards/margins": 6.783603668212891,
      "rewards/rejected": -14.456445693969727,
      "step": 22950
    },
    {
      "epoch": 4.1901633360708095,
      "grad_norm": 20.39524269104004,
      "learning_rate": 1.3060745090842357e-05,
      "logits/chosen": 0.20189563930034637,
      "logits/rejected": 0.6014536023139954,
      "logps/chosen": -230.59475708007812,
      "logps/rejected": -279.9866943359375,
      "loss": 0.1355,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.152013778686523,
      "rewards/margins": 6.240667819976807,
      "rewards/rejected": -14.392682075500488,
      "step": 22960
    },
    {
      "epoch": 4.191988320102199,
      "grad_norm": 6.2255144119262695,
      "learning_rate": 1.3031381904936687e-05,
      "logits/chosen": -0.009062444791197777,
      "logits/rejected": 0.40873223543167114,
      "logps/chosen": -224.79751586914062,
      "logps/rejected": -270.5604248046875,
      "loss": 0.059,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.8372602462768555,
      "rewards/margins": 6.631204128265381,
      "rewards/rejected": -13.468464851379395,
      "step": 22970
    },
    {
      "epoch": 4.193813304133589,
      "grad_norm": 18.449878692626953,
      "learning_rate": 1.3002018719031015e-05,
      "logits/chosen": 0.10327959060668945,
      "logits/rejected": 0.5098507404327393,
      "logps/chosen": -208.1610107421875,
      "logps/rejected": -271.1224670410156,
      "loss": 0.077,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.729062080383301,
      "rewards/margins": 6.904707431793213,
      "rewards/rejected": -13.633770942687988,
      "step": 22980
    },
    {
      "epoch": 4.195638288164979,
      "grad_norm": 21.464832305908203,
      "learning_rate": 1.2972655533125345e-05,
      "logits/chosen": 0.14701983332633972,
      "logits/rejected": 0.6928312182426453,
      "logps/chosen": -228.6212158203125,
      "logps/rejected": -269.97613525390625,
      "loss": 0.0481,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.560632228851318,
      "rewards/margins": 7.2403059005737305,
      "rewards/rejected": -14.800938606262207,
      "step": 22990
    },
    {
      "epoch": 4.1974632721963685,
      "grad_norm": 8.138946533203125,
      "learning_rate": 1.2943292347219674e-05,
      "logits/chosen": 0.041404373943805695,
      "logits/rejected": 0.7121263742446899,
      "logps/chosen": -241.42532348632812,
      "logps/rejected": -249.0042724609375,
      "loss": 0.0905,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.757197380065918,
      "rewards/margins": 6.148293495178223,
      "rewards/rejected": -12.905491828918457,
      "step": 23000
    },
    {
      "epoch": 4.199288256227758,
      "grad_norm": 5.740495681762695,
      "learning_rate": 1.2913929161314002e-05,
      "logits/chosen": -0.0952025055885315,
      "logits/rejected": 0.3222988247871399,
      "logps/chosen": -222.9875946044922,
      "logps/rejected": -276.86810302734375,
      "loss": 0.0676,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.7654218673706055,
      "rewards/margins": 7.151821136474609,
      "rewards/rejected": -13.917243957519531,
      "step": 23010
    },
    {
      "epoch": 4.201113240259148,
      "grad_norm": 1.3530975580215454,
      "learning_rate": 1.2884565975408332e-05,
      "logits/chosen": 0.10145237296819687,
      "logits/rejected": 0.6915379762649536,
      "logps/chosen": -225.8423309326172,
      "logps/rejected": -265.41229248046875,
      "loss": 0.0494,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.186100006103516,
      "rewards/margins": 6.896227836608887,
      "rewards/rejected": -14.082326889038086,
      "step": 23020
    },
    {
      "epoch": 4.202938224290538,
      "grad_norm": 17.777366638183594,
      "learning_rate": 1.2855202789502662e-05,
      "logits/chosen": 0.1386808454990387,
      "logits/rejected": 0.4923897683620453,
      "logps/chosen": -212.34622192382812,
      "logps/rejected": -283.14642333984375,
      "loss": 0.0767,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.694586277008057,
      "rewards/margins": 7.0982842445373535,
      "rewards/rejected": -13.792869567871094,
      "step": 23030
    },
    {
      "epoch": 4.2047632083219275,
      "grad_norm": 1.9534856081008911,
      "learning_rate": 1.2825839603596993e-05,
      "logits/chosen": 0.08530732244253159,
      "logits/rejected": 0.7755469083786011,
      "logps/chosen": -223.68310546875,
      "logps/rejected": -266.935546875,
      "loss": 0.042,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.714931488037109,
      "rewards/margins": 6.648590087890625,
      "rewards/rejected": -13.363520622253418,
      "step": 23040
    },
    {
      "epoch": 4.206588192353317,
      "grad_norm": 5.2901482582092285,
      "learning_rate": 1.2796476417691321e-05,
      "logits/chosen": 0.231955885887146,
      "logits/rejected": 0.7094770073890686,
      "logps/chosen": -214.72879028320312,
      "logps/rejected": -268.39447021484375,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.257359981536865,
      "rewards/margins": 7.259664058685303,
      "rewards/rejected": -14.517024040222168,
      "step": 23050
    },
    {
      "epoch": 4.208413176384707,
      "grad_norm": 7.068502426147461,
      "learning_rate": 1.276711323178565e-05,
      "logits/chosen": 0.06138532608747482,
      "logits/rejected": 0.3474094867706299,
      "logps/chosen": -202.17904663085938,
      "logps/rejected": -260.0638732910156,
      "loss": 0.0724,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.931510925292969,
      "rewards/margins": 6.499311923980713,
      "rewards/rejected": -13.430822372436523,
      "step": 23060
    },
    {
      "epoch": 4.210238160416097,
      "grad_norm": 13.690520286560059,
      "learning_rate": 1.273775004587998e-05,
      "logits/chosen": 0.1376834213733673,
      "logits/rejected": 0.31634464859962463,
      "logps/chosen": -198.9093780517578,
      "logps/rejected": -283.0867919921875,
      "loss": 0.0444,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.162336826324463,
      "rewards/margins": 6.7797956466674805,
      "rewards/rejected": -12.942133903503418,
      "step": 23070
    },
    {
      "epoch": 4.212063144447486,
      "grad_norm": 5.397012710571289,
      "learning_rate": 1.2708386859974308e-05,
      "logits/chosen": 0.20069953799247742,
      "logits/rejected": 1.125159502029419,
      "logps/chosen": -219.04257202148438,
      "logps/rejected": -256.5985412597656,
      "loss": 0.0972,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.883854866027832,
      "rewards/margins": 7.113023281097412,
      "rewards/rejected": -13.996879577636719,
      "step": 23080
    },
    {
      "epoch": 4.213888128478875,
      "grad_norm": 2.2905967235565186,
      "learning_rate": 1.2679023674068638e-05,
      "logits/chosen": 0.13365153968334198,
      "logits/rejected": 0.7899008989334106,
      "logps/chosen": -215.05471801757812,
      "logps/rejected": -257.6631774902344,
      "loss": 0.0573,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.580965995788574,
      "rewards/margins": 6.589098930358887,
      "rewards/rejected": -13.170063972473145,
      "step": 23090
    },
    {
      "epoch": 4.215713112510265,
      "grad_norm": 15.256196975708008,
      "learning_rate": 1.2649660488162967e-05,
      "logits/chosen": 0.18989072740077972,
      "logits/rejected": 0.5251055955886841,
      "logps/chosen": -203.51625061035156,
      "logps/rejected": -261.9461669921875,
      "loss": 0.0353,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.906818389892578,
      "rewards/margins": 6.567147254943848,
      "rewards/rejected": -13.473965644836426,
      "step": 23100
    },
    {
      "epoch": 4.217538096541655,
      "grad_norm": 22.961240768432617,
      "learning_rate": 1.2620297302257295e-05,
      "logits/chosen": 0.1972673386335373,
      "logits/rejected": 0.8024570345878601,
      "logps/chosen": -224.9376678466797,
      "logps/rejected": -259.48284912109375,
      "loss": 0.0813,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.927064418792725,
      "rewards/margins": 6.484382629394531,
      "rewards/rejected": -14.411447525024414,
      "step": 23110
    },
    {
      "epoch": 4.219363080573045,
      "grad_norm": 7.6050262451171875,
      "learning_rate": 1.2590934116351625e-05,
      "logits/chosen": 0.09831119328737259,
      "logits/rejected": 0.5898984670639038,
      "logps/chosen": -216.98507690429688,
      "logps/rejected": -290.69512939453125,
      "loss": 0.0769,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.717940330505371,
      "rewards/margins": 7.80483865737915,
      "rewards/rejected": -14.52277946472168,
      "step": 23120
    },
    {
      "epoch": 4.221188064604434,
      "grad_norm": 1.5001899003982544,
      "learning_rate": 1.2561570930445955e-05,
      "logits/chosen": 0.3596034646034241,
      "logits/rejected": 0.7964348196983337,
      "logps/chosen": -204.16217041015625,
      "logps/rejected": -266.2449035644531,
      "loss": 0.0988,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.072700500488281,
      "rewards/margins": 6.674659729003906,
      "rewards/rejected": -13.747360229492188,
      "step": 23130
    },
    {
      "epoch": 4.223013048635824,
      "grad_norm": 4.865628719329834,
      "learning_rate": 1.2532207744540283e-05,
      "logits/chosen": 0.2815503478050232,
      "logits/rejected": 0.6651015281677246,
      "logps/chosen": -207.989990234375,
      "logps/rejected": -251.8880615234375,
      "loss": 0.1294,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.052870273590088,
      "rewards/margins": 6.040867805480957,
      "rewards/rejected": -13.093737602233887,
      "step": 23140
    },
    {
      "epoch": 4.224838032667214,
      "grad_norm": 6.200061798095703,
      "learning_rate": 1.2502844558634612e-05,
      "logits/chosen": -0.030672337859869003,
      "logits/rejected": 0.4539467692375183,
      "logps/chosen": -214.5674591064453,
      "logps/rejected": -253.2456817626953,
      "loss": 0.0795,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.513646602630615,
      "rewards/margins": 6.329140663146973,
      "rewards/rejected": -12.84278678894043,
      "step": 23150
    },
    {
      "epoch": 4.226663016698604,
      "grad_norm": 4.133955955505371,
      "learning_rate": 1.2473481372728942e-05,
      "logits/chosen": 0.32365942001342773,
      "logits/rejected": 0.8815814852714539,
      "logps/chosen": -224.0125732421875,
      "logps/rejected": -271.2524719238281,
      "loss": 0.0395,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.542830467224121,
      "rewards/margins": 6.85666036605835,
      "rewards/rejected": -14.399492263793945,
      "step": 23160
    },
    {
      "epoch": 4.228488000729993,
      "grad_norm": 4.2265119552612305,
      "learning_rate": 1.244411818682327e-05,
      "logits/chosen": 0.5517678260803223,
      "logits/rejected": 0.7836112976074219,
      "logps/chosen": -209.91799926757812,
      "logps/rejected": -277.31683349609375,
      "loss": 0.1221,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -8.334172248840332,
      "rewards/margins": 6.340936183929443,
      "rewards/rejected": -14.67510986328125,
      "step": 23170
    },
    {
      "epoch": 4.230312984761383,
      "grad_norm": 15.78337574005127,
      "learning_rate": 1.24147550009176e-05,
      "logits/chosen": 0.15047243237495422,
      "logits/rejected": 0.5301379561424255,
      "logps/chosen": -234.03744506835938,
      "logps/rejected": -259.4140930175781,
      "loss": 0.0737,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.237232208251953,
      "rewards/margins": 6.214084148406982,
      "rewards/rejected": -13.451316833496094,
      "step": 23180
    },
    {
      "epoch": 4.232137968792773,
      "grad_norm": 17.8280086517334,
      "learning_rate": 1.238539181501193e-05,
      "logits/chosen": 0.22558096051216125,
      "logits/rejected": 0.923585057258606,
      "logps/chosen": -234.9811553955078,
      "logps/rejected": -278.8851623535156,
      "loss": 0.062,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.408514499664307,
      "rewards/margins": 7.2689313888549805,
      "rewards/rejected": -14.677444458007812,
      "step": 23190
    },
    {
      "epoch": 4.233962952824163,
      "grad_norm": 1.8717988729476929,
      "learning_rate": 1.2356028629106259e-05,
      "logits/chosen": 0.3637096881866455,
      "logits/rejected": 0.728099524974823,
      "logps/chosen": -204.2034912109375,
      "logps/rejected": -269.3585510253906,
      "loss": 0.0892,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.688269138336182,
      "rewards/margins": 6.922820091247559,
      "rewards/rejected": -14.611088752746582,
      "step": 23200
    },
    {
      "epoch": 4.235787936855552,
      "grad_norm": 3.800238609313965,
      "learning_rate": 1.2326665443200587e-05,
      "logits/chosen": 0.34526532888412476,
      "logits/rejected": 0.8344553112983704,
      "logps/chosen": -202.60963439941406,
      "logps/rejected": -262.24530029296875,
      "loss": 0.1329,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.926222324371338,
      "rewards/margins": 6.735984802246094,
      "rewards/rejected": -13.662206649780273,
      "step": 23210
    },
    {
      "epoch": 4.237612920886942,
      "grad_norm": 21.174556732177734,
      "learning_rate": 1.2297302257294918e-05,
      "logits/chosen": 0.3262706398963928,
      "logits/rejected": 0.9095795750617981,
      "logps/chosen": -241.15625,
      "logps/rejected": -271.0003967285156,
      "loss": 0.1861,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.94147253036499,
      "rewards/margins": 6.422623634338379,
      "rewards/rejected": -14.364095687866211,
      "step": 23220
    },
    {
      "epoch": 4.239437904918332,
      "grad_norm": 5.765829086303711,
      "learning_rate": 1.2267939071389248e-05,
      "logits/chosen": 0.2371405065059662,
      "logits/rejected": 0.5383106470108032,
      "logps/chosen": -216.21627807617188,
      "logps/rejected": -280.0848083496094,
      "loss": 0.0959,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.62673807144165,
      "rewards/margins": 5.49204158782959,
      "rewards/rejected": -13.118780136108398,
      "step": 23230
    },
    {
      "epoch": 4.241262888949722,
      "grad_norm": 18.378620147705078,
      "learning_rate": 1.2238575885483578e-05,
      "logits/chosen": 0.34723979234695435,
      "logits/rejected": 0.5901530385017395,
      "logps/chosen": -232.02230834960938,
      "logps/rejected": -290.81414794921875,
      "loss": 0.0903,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.219266891479492,
      "rewards/margins": 6.521676540374756,
      "rewards/rejected": -14.740943908691406,
      "step": 23240
    },
    {
      "epoch": 4.2430878729811115,
      "grad_norm": 19.733753204345703,
      "learning_rate": 1.2209212699577906e-05,
      "logits/chosen": 0.24768495559692383,
      "logits/rejected": 0.6638988852500916,
      "logps/chosen": -202.18182373046875,
      "logps/rejected": -265.99481201171875,
      "loss": 0.1424,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.520157814025879,
      "rewards/margins": 7.382136344909668,
      "rewards/rejected": -13.902295112609863,
      "step": 23250
    },
    {
      "epoch": 4.244912857012501,
      "grad_norm": 11.42759895324707,
      "learning_rate": 1.2179849513672235e-05,
      "logits/chosen": -0.036894869059324265,
      "logits/rejected": 0.7523146867752075,
      "logps/chosen": -234.0899200439453,
      "logps/rejected": -257.01416015625,
      "loss": 0.0398,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.712078094482422,
      "rewards/margins": 6.770350456237793,
      "rewards/rejected": -13.482429504394531,
      "step": 23260
    },
    {
      "epoch": 4.246737841043891,
      "grad_norm": 0.9659306406974792,
      "learning_rate": 1.2150486327766565e-05,
      "logits/chosen": 0.48706960678100586,
      "logits/rejected": 0.9060912132263184,
      "logps/chosen": -229.2924346923828,
      "logps/rejected": -296.7941589355469,
      "loss": 0.0321,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.493467807769775,
      "rewards/margins": 7.009443759918213,
      "rewards/rejected": -14.502909660339355,
      "step": 23270
    },
    {
      "epoch": 4.248562825075281,
      "grad_norm": 2.7520511150360107,
      "learning_rate": 1.2121123141860893e-05,
      "logits/chosen": 0.6094308495521545,
      "logits/rejected": 1.0544683933258057,
      "logps/chosen": -209.39208984375,
      "logps/rejected": -278.7018127441406,
      "loss": 0.0693,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.144558906555176,
      "rewards/margins": 7.138535499572754,
      "rewards/rejected": -15.28309440612793,
      "step": 23280
    },
    {
      "epoch": 4.2503878091066705,
      "grad_norm": 0.3582174479961395,
      "learning_rate": 1.2091759955955222e-05,
      "logits/chosen": 0.2439514845609665,
      "logits/rejected": 1.1274458169937134,
      "logps/chosen": -231.25704956054688,
      "logps/rejected": -255.297119140625,
      "loss": 0.1192,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.559233665466309,
      "rewards/margins": 6.943695068359375,
      "rewards/rejected": -14.5029296875,
      "step": 23290
    },
    {
      "epoch": 4.25221279313806,
      "grad_norm": 0.5286532640457153,
      "learning_rate": 1.2062396770049552e-05,
      "logits/chosen": 0.49981188774108887,
      "logits/rejected": 1.0674902200698853,
      "logps/chosen": -223.5822296142578,
      "logps/rejected": -270.2257385253906,
      "loss": 0.0617,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -8.245735168457031,
      "rewards/margins": 6.546594142913818,
      "rewards/rejected": -14.792327880859375,
      "step": 23300
    },
    {
      "epoch": 4.25403777716945,
      "grad_norm": 14.827558517456055,
      "learning_rate": 1.203303358414388e-05,
      "logits/chosen": 0.4963216781616211,
      "logits/rejected": 0.9413200616836548,
      "logps/chosen": -202.34378051757812,
      "logps/rejected": -264.11944580078125,
      "loss": 0.072,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.313287734985352,
      "rewards/margins": 7.088087558746338,
      "rewards/rejected": -13.401374816894531,
      "step": 23310
    },
    {
      "epoch": 4.25586276120084,
      "grad_norm": 7.2278313636779785,
      "learning_rate": 1.200367039823821e-05,
      "logits/chosen": 0.6672998070716858,
      "logits/rejected": 1.0510284900665283,
      "logps/chosen": -211.9926300048828,
      "logps/rejected": -271.7963562011719,
      "loss": 0.0554,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.0420560836792,
      "rewards/margins": 7.104536533355713,
      "rewards/rejected": -15.146594047546387,
      "step": 23320
    },
    {
      "epoch": 4.2576877452322295,
      "grad_norm": 12.207199096679688,
      "learning_rate": 1.197430721233254e-05,
      "logits/chosen": 0.3636758327484131,
      "logits/rejected": 0.8397101163864136,
      "logps/chosen": -224.81704711914062,
      "logps/rejected": -254.6623077392578,
      "loss": 0.0586,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.175652980804443,
      "rewards/margins": 5.9048943519592285,
      "rewards/rejected": -13.080548286437988,
      "step": 23330
    },
    {
      "epoch": 4.259512729263619,
      "grad_norm": 5.468881130218506,
      "learning_rate": 1.1944944026426867e-05,
      "logits/chosen": 0.6204106211662292,
      "logits/rejected": 1.4460794925689697,
      "logps/chosen": -225.6585235595703,
      "logps/rejected": -260.8779602050781,
      "loss": 0.0869,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.555155277252197,
      "rewards/margins": 6.565393924713135,
      "rewards/rejected": -14.120549201965332,
      "step": 23340
    },
    {
      "epoch": 4.261337713295009,
      "grad_norm": 5.296454906463623,
      "learning_rate": 1.1915580840521197e-05,
      "logits/chosen": 0.6480129957199097,
      "logits/rejected": 1.0263798236846924,
      "logps/chosen": -184.51747131347656,
      "logps/rejected": -247.145751953125,
      "loss": 0.111,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.005402565002441,
      "rewards/margins": 6.717355251312256,
      "rewards/rejected": -13.722757339477539,
      "step": 23350
    },
    {
      "epoch": 4.263162697326399,
      "grad_norm": 0.533445417881012,
      "learning_rate": 1.1886217654615527e-05,
      "logits/chosen": 0.6043449640274048,
      "logits/rejected": 1.223963737487793,
      "logps/chosen": -216.09408569335938,
      "logps/rejected": -273.5184020996094,
      "loss": 0.1336,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.734757423400879,
      "rewards/margins": 7.2708845138549805,
      "rewards/rejected": -15.005642890930176,
      "step": 23360
    },
    {
      "epoch": 4.2649876813577885,
      "grad_norm": 13.169096946716309,
      "learning_rate": 1.1856854468709855e-05,
      "logits/chosen": 0.21548929810523987,
      "logits/rejected": 0.8053275942802429,
      "logps/chosen": -219.2861328125,
      "logps/rejected": -267.19891357421875,
      "loss": 0.1026,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.606792449951172,
      "rewards/margins": 6.633334159851074,
      "rewards/rejected": -13.240127563476562,
      "step": 23370
    },
    {
      "epoch": 4.266812665389178,
      "grad_norm": 0.06487713754177094,
      "learning_rate": 1.1827491282804184e-05,
      "logits/chosen": 0.3229920566082001,
      "logits/rejected": 0.8815679550170898,
      "logps/chosen": -199.774169921875,
      "logps/rejected": -257.99920654296875,
      "loss": 0.1167,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.097136497497559,
      "rewards/margins": 7.011601448059082,
      "rewards/rejected": -14.108736991882324,
      "step": 23380
    },
    {
      "epoch": 4.268637649420567,
      "grad_norm": 9.472248077392578,
      "learning_rate": 1.1798128096898514e-05,
      "logits/chosen": 0.1810975968837738,
      "logits/rejected": 0.7077717185020447,
      "logps/chosen": -212.38558959960938,
      "logps/rejected": -257.27593994140625,
      "loss": 0.0677,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.296662330627441,
      "rewards/margins": 6.094519138336182,
      "rewards/rejected": -13.391181945800781,
      "step": 23390
    },
    {
      "epoch": 4.270462633451958,
      "grad_norm": 6.163036346435547,
      "learning_rate": 1.1768764910992845e-05,
      "logits/chosen": 0.16369356215000153,
      "logits/rejected": 0.5710993409156799,
      "logps/chosen": -214.4248046875,
      "logps/rejected": -286.93267822265625,
      "loss": 0.0614,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.252937316894531,
      "rewards/margins": 7.268149375915527,
      "rewards/rejected": -14.521085739135742,
      "step": 23400
    },
    {
      "epoch": 4.272287617483347,
      "grad_norm": 8.066061019897461,
      "learning_rate": 1.1739401725087173e-05,
      "logits/chosen": 0.20749430358409882,
      "logits/rejected": 0.6968927979469299,
      "logps/chosen": -204.60848999023438,
      "logps/rejected": -242.8197479248047,
      "loss": 0.0869,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.9328765869140625,
      "rewards/margins": 6.31863260269165,
      "rewards/rejected": -13.251508712768555,
      "step": 23410
    },
    {
      "epoch": 4.274112601514736,
      "grad_norm": 5.085655689239502,
      "learning_rate": 1.1710038539181503e-05,
      "logits/chosen": 0.2335134744644165,
      "logits/rejected": 0.825212836265564,
      "logps/chosen": -224.8120574951172,
      "logps/rejected": -271.3414001464844,
      "loss": 0.0582,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.1706862449646,
      "rewards/margins": 6.6663408279418945,
      "rewards/rejected": -13.837028503417969,
      "step": 23420
    },
    {
      "epoch": 4.275937585546126,
      "grad_norm": 0.9146520495414734,
      "learning_rate": 1.1680675353275833e-05,
      "logits/chosen": 0.16455236077308655,
      "logits/rejected": 0.8232479095458984,
      "logps/chosen": -210.50015258789062,
      "logps/rejected": -247.60934448242188,
      "loss": 0.0403,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.251200199127197,
      "rewards/margins": 6.704843997955322,
      "rewards/rejected": -12.95604419708252,
      "step": 23430
    },
    {
      "epoch": 4.277762569577516,
      "grad_norm": 1.4836727380752563,
      "learning_rate": 1.165131216737016e-05,
      "logits/chosen": 0.09060449153184891,
      "logits/rejected": 0.25898632407188416,
      "logps/chosen": -198.72206115722656,
      "logps/rejected": -254.81173706054688,
      "loss": 0.08,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.2460737228393555,
      "rewards/margins": 6.210370063781738,
      "rewards/rejected": -12.456442832946777,
      "step": 23440
    },
    {
      "epoch": 4.279587553608906,
      "grad_norm": 9.001587867736816,
      "learning_rate": 1.162194898146449e-05,
      "logits/chosen": 0.41288208961486816,
      "logits/rejected": 0.9608710408210754,
      "logps/chosen": -226.2603759765625,
      "logps/rejected": -285.66265869140625,
      "loss": 0.0389,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.836645603179932,
      "rewards/margins": 6.601217746734619,
      "rewards/rejected": -14.43786334991455,
      "step": 23450
    },
    {
      "epoch": 4.281412537640295,
      "grad_norm": 0.332553893327713,
      "learning_rate": 1.159258579555882e-05,
      "logits/chosen": 0.18614467978477478,
      "logits/rejected": 0.4725111126899719,
      "logps/chosen": -214.27212524414062,
      "logps/rejected": -277.6872863769531,
      "loss": 0.1032,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.672982692718506,
      "rewards/margins": 6.851218223571777,
      "rewards/rejected": -13.524200439453125,
      "step": 23460
    },
    {
      "epoch": 4.283237521671685,
      "grad_norm": 6.17937707901001,
      "learning_rate": 1.1563222609653148e-05,
      "logits/chosen": -0.04602768272161484,
      "logits/rejected": 0.708379864692688,
      "logps/chosen": -236.6184539794922,
      "logps/rejected": -256.59051513671875,
      "loss": 0.0952,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.879179954528809,
      "rewards/margins": 6.623038291931152,
      "rewards/rejected": -13.502218246459961,
      "step": 23470
    },
    {
      "epoch": 4.285062505703075,
      "grad_norm": 13.590746879577637,
      "learning_rate": 1.1533859423747477e-05,
      "logits/chosen": 0.22915641963481903,
      "logits/rejected": 0.6057084798812866,
      "logps/chosen": -230.55471801757812,
      "logps/rejected": -284.5561828613281,
      "loss": 0.1136,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.351678371429443,
      "rewards/margins": 6.8206634521484375,
      "rewards/rejected": -14.172340393066406,
      "step": 23480
    },
    {
      "epoch": 4.286887489734465,
      "grad_norm": 0.11020307242870331,
      "learning_rate": 1.1504496237841807e-05,
      "logits/chosen": 0.14640645682811737,
      "logits/rejected": 0.6149944067001343,
      "logps/chosen": -222.18612670898438,
      "logps/rejected": -264.9710388183594,
      "loss": 0.0618,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.047977447509766,
      "rewards/margins": 6.440649509429932,
      "rewards/rejected": -13.488626480102539,
      "step": 23490
    },
    {
      "epoch": 4.288712473765854,
      "grad_norm": 1.3158438205718994,
      "learning_rate": 1.1475133051936135e-05,
      "logits/chosen": 0.16154301166534424,
      "logits/rejected": 0.9429291486740112,
      "logps/chosen": -225.25430297851562,
      "logps/rejected": -257.11529541015625,
      "loss": 0.0225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.127552032470703,
      "rewards/margins": 7.25716495513916,
      "rewards/rejected": -14.384716987609863,
      "step": 23500
    },
    {
      "epoch": 4.290537457797244,
      "grad_norm": 4.646181106567383,
      "learning_rate": 1.1445769866030465e-05,
      "logits/chosen": 0.09343674778938293,
      "logits/rejected": 0.6070905923843384,
      "logps/chosen": -211.1647491455078,
      "logps/rejected": -258.9552001953125,
      "loss": 0.0935,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.807481288909912,
      "rewards/margins": 6.006218910217285,
      "rewards/rejected": -12.813700675964355,
      "step": 23510
    },
    {
      "epoch": 4.292362441828634,
      "grad_norm": 4.461808204650879,
      "learning_rate": 1.1416406680124794e-05,
      "logits/chosen": -0.05411117151379585,
      "logits/rejected": 0.8031783103942871,
      "logps/chosen": -231.78567504882812,
      "logps/rejected": -243.6901397705078,
      "loss": 0.077,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.690372467041016,
      "rewards/margins": 6.254863739013672,
      "rewards/rejected": -12.945236206054688,
      "step": 23520
    },
    {
      "epoch": 4.294187425860024,
      "grad_norm": 15.617158889770508,
      "learning_rate": 1.1387043494219124e-05,
      "logits/chosen": 0.15491576492786407,
      "logits/rejected": 0.5933485627174377,
      "logps/chosen": -235.2511749267578,
      "logps/rejected": -276.66937255859375,
      "loss": 0.0601,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.37002420425415,
      "rewards/margins": 6.54665470123291,
      "rewards/rejected": -13.916677474975586,
      "step": 23530
    },
    {
      "epoch": 4.296012409891413,
      "grad_norm": 0.7274178862571716,
      "learning_rate": 1.1357680308313452e-05,
      "logits/chosen": 0.0061439769342541695,
      "logits/rejected": 0.3992370665073395,
      "logps/chosen": -213.7993927001953,
      "logps/rejected": -278.727294921875,
      "loss": 0.0509,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.821754455566406,
      "rewards/margins": 6.910966396331787,
      "rewards/rejected": -13.732721328735352,
      "step": 23540
    },
    {
      "epoch": 4.297837393922803,
      "grad_norm": 17.35728645324707,
      "learning_rate": 1.1328317122407782e-05,
      "logits/chosen": 0.4067166745662689,
      "logits/rejected": 0.5377312898635864,
      "logps/chosen": -200.38568115234375,
      "logps/rejected": -269.5708923339844,
      "loss": 0.1432,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.115329742431641,
      "rewards/margins": 5.744655132293701,
      "rewards/rejected": -12.8599853515625,
      "step": 23550
    },
    {
      "epoch": 4.299662377954193,
      "grad_norm": 2.57698130607605,
      "learning_rate": 1.1298953936502111e-05,
      "logits/chosen": 0.07428357750177383,
      "logits/rejected": 0.3081057667732239,
      "logps/chosen": -214.93417358398438,
      "logps/rejected": -287.67791748046875,
      "loss": 0.167,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.647761344909668,
      "rewards/margins": 6.556959629058838,
      "rewards/rejected": -13.204721450805664,
      "step": 23560
    },
    {
      "epoch": 4.301487361985583,
      "grad_norm": 3.3974289894104004,
      "learning_rate": 1.126959075059644e-05,
      "logits/chosen": 0.08305740356445312,
      "logits/rejected": 0.7009583711624146,
      "logps/chosen": -221.8080596923828,
      "logps/rejected": -255.08261108398438,
      "loss": 0.0704,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.200274467468262,
      "rewards/margins": 6.271747589111328,
      "rewards/rejected": -13.472021102905273,
      "step": 23570
    },
    {
      "epoch": 4.303312346016972,
      "grad_norm": 31.08176040649414,
      "learning_rate": 1.1240227564690769e-05,
      "logits/chosen": 0.27462607622146606,
      "logits/rejected": 0.6158666610717773,
      "logps/chosen": -217.85018920898438,
      "logps/rejected": -274.36334228515625,
      "loss": 0.136,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.792506217956543,
      "rewards/margins": 6.3754096031188965,
      "rewards/rejected": -14.167915344238281,
      "step": 23580
    },
    {
      "epoch": 4.305137330048362,
      "grad_norm": 10.794261932373047,
      "learning_rate": 1.12108643787851e-05,
      "logits/chosen": -0.07398329675197601,
      "logits/rejected": 0.5256789922714233,
      "logps/chosen": -226.0137481689453,
      "logps/rejected": -272.07244873046875,
      "loss": 0.0539,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.657622337341309,
      "rewards/margins": 6.157967567443848,
      "rewards/rejected": -12.815591812133789,
      "step": 23590
    },
    {
      "epoch": 4.306962314079752,
      "grad_norm": 2.4700992107391357,
      "learning_rate": 1.118150119287943e-05,
      "logits/chosen": 0.312058687210083,
      "logits/rejected": 0.6612976789474487,
      "logps/chosen": -214.20089721679688,
      "logps/rejected": -272.5482177734375,
      "loss": 0.1004,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.7119245529174805,
      "rewards/margins": 6.480795860290527,
      "rewards/rejected": -14.192720413208008,
      "step": 23600
    },
    {
      "epoch": 4.308787298111142,
      "grad_norm": 3.299175262451172,
      "learning_rate": 1.1152138006973758e-05,
      "logits/chosen": -0.01754049025475979,
      "logits/rejected": 0.49976521730422974,
      "logps/chosen": -216.78359985351562,
      "logps/rejected": -257.0128173828125,
      "loss": 0.11,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.835268974304199,
      "rewards/margins": 6.497829437255859,
      "rewards/rejected": -13.333099365234375,
      "step": 23610
    },
    {
      "epoch": 4.3106122821425314,
      "grad_norm": 13.355574607849121,
      "learning_rate": 1.1122774821068088e-05,
      "logits/chosen": -0.22650901973247528,
      "logits/rejected": 0.3019110858440399,
      "logps/chosen": -215.521240234375,
      "logps/rejected": -257.5123596191406,
      "loss": 0.0768,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.3803911209106445,
      "rewards/margins": 6.817526817321777,
      "rewards/rejected": -13.197916984558105,
      "step": 23620
    },
    {
      "epoch": 4.312437266173921,
      "grad_norm": 1.9497294425964355,
      "learning_rate": 1.1093411635162417e-05,
      "logits/chosen": 0.1737656146287918,
      "logits/rejected": 0.5434603691101074,
      "logps/chosen": -214.86630249023438,
      "logps/rejected": -254.7059783935547,
      "loss": 0.1023,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.369044303894043,
      "rewards/margins": 5.617496013641357,
      "rewards/rejected": -12.986541748046875,
      "step": 23630
    },
    {
      "epoch": 4.314262250205311,
      "grad_norm": 3.561955213546753,
      "learning_rate": 1.1064048449256745e-05,
      "logits/chosen": 0.14230747520923615,
      "logits/rejected": 0.4542618691921234,
      "logps/chosen": -180.9335174560547,
      "logps/rejected": -252.49398803710938,
      "loss": 0.0305,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.1234025955200195,
      "rewards/margins": 6.837061405181885,
      "rewards/rejected": -12.960464477539062,
      "step": 23640
    },
    {
      "epoch": 4.316087234236701,
      "grad_norm": 12.561074256896973,
      "learning_rate": 1.1034685263351075e-05,
      "logits/chosen": -0.07632670551538467,
      "logits/rejected": 0.4545731544494629,
      "logps/chosen": -220.72341918945312,
      "logps/rejected": -258.1707458496094,
      "loss": 0.0481,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.290678024291992,
      "rewards/margins": 6.3528337478637695,
      "rewards/rejected": -12.643511772155762,
      "step": 23650
    },
    {
      "epoch": 4.3179122182680905,
      "grad_norm": 0.15355965495109558,
      "learning_rate": 1.1005322077445404e-05,
      "logits/chosen": -0.23231926560401917,
      "logits/rejected": 0.2503882050514221,
      "logps/chosen": -206.555908203125,
      "logps/rejected": -240.9491424560547,
      "loss": 0.0874,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.4546966552734375,
      "rewards/margins": 6.044783592224121,
      "rewards/rejected": -11.499481201171875,
      "step": 23660
    },
    {
      "epoch": 4.31973720229948,
      "grad_norm": 13.668655395507812,
      "learning_rate": 1.0975958891539732e-05,
      "logits/chosen": 0.13670995831489563,
      "logits/rejected": 0.4662168025970459,
      "logps/chosen": -211.3793182373047,
      "logps/rejected": -266.6572570800781,
      "loss": 0.0628,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.085734844207764,
      "rewards/margins": 6.281784534454346,
      "rewards/rejected": -12.36751937866211,
      "step": 23670
    },
    {
      "epoch": 4.32156218633087,
      "grad_norm": 0.483344167470932,
      "learning_rate": 1.0946595705634062e-05,
      "logits/chosen": 0.1212233155965805,
      "logits/rejected": 0.5907338857650757,
      "logps/chosen": -205.6386260986328,
      "logps/rejected": -257.4192810058594,
      "loss": 0.0556,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.2279157638549805,
      "rewards/margins": 6.801845550537109,
      "rewards/rejected": -13.029762268066406,
      "step": 23680
    },
    {
      "epoch": 4.32338717036226,
      "grad_norm": 8.77966594696045,
      "learning_rate": 1.0917232519728392e-05,
      "logits/chosen": 0.1736716777086258,
      "logits/rejected": 0.5911260843276978,
      "logps/chosen": -209.7086944580078,
      "logps/rejected": -253.77017211914062,
      "loss": 0.0774,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.005423545837402,
      "rewards/margins": 6.284706115722656,
      "rewards/rejected": -13.290128707885742,
      "step": 23690
    },
    {
      "epoch": 4.325212154393649,
      "grad_norm": 14.384041786193848,
      "learning_rate": 1.088786933382272e-05,
      "logits/chosen": 0.04647466167807579,
      "logits/rejected": 0.8966997861862183,
      "logps/chosen": -218.1614532470703,
      "logps/rejected": -260.7372131347656,
      "loss": 0.057,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.275935173034668,
      "rewards/margins": 6.53204345703125,
      "rewards/rejected": -13.807978630065918,
      "step": 23700
    },
    {
      "epoch": 4.327037138425039,
      "grad_norm": 0.4498665928840637,
      "learning_rate": 1.085850614791705e-05,
      "logits/chosen": 0.3407668471336365,
      "logits/rejected": 0.6412405967712402,
      "logps/chosen": -195.40658569335938,
      "logps/rejected": -268.02349853515625,
      "loss": 0.0411,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.978044033050537,
      "rewards/margins": 7.711491584777832,
      "rewards/rejected": -14.689535140991211,
      "step": 23710
    },
    {
      "epoch": 4.328862122456428,
      "grad_norm": 3.7152066230773926,
      "learning_rate": 1.0829142962011379e-05,
      "logits/chosen": 0.14643533527851105,
      "logits/rejected": 0.3697272539138794,
      "logps/chosen": -202.9602813720703,
      "logps/rejected": -264.970703125,
      "loss": 0.0509,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.929227352142334,
      "rewards/margins": 7.144349575042725,
      "rewards/rejected": -14.073577880859375,
      "step": 23720
    },
    {
      "epoch": 4.330687106487818,
      "grad_norm": 2.1293070316314697,
      "learning_rate": 1.0799779776105707e-05,
      "logits/chosen": 0.2407328188419342,
      "logits/rejected": 0.49069857597351074,
      "logps/chosen": -221.7943115234375,
      "logps/rejected": -266.4068298339844,
      "loss": 0.0723,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.330999374389648,
      "rewards/margins": 5.917899131774902,
      "rewards/rejected": -14.248899459838867,
      "step": 23730
    },
    {
      "epoch": 4.332512090519208,
      "grad_norm": 9.170597076416016,
      "learning_rate": 1.0770416590200037e-05,
      "logits/chosen": 0.1437676101922989,
      "logits/rejected": 0.5851216316223145,
      "logps/chosen": -213.0303955078125,
      "logps/rejected": -273.9579772949219,
      "loss": 0.0816,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.587807655334473,
      "rewards/margins": 7.193762302398682,
      "rewards/rejected": -13.78156852722168,
      "step": 23740
    },
    {
      "epoch": 4.334337074550597,
      "grad_norm": 9.494301795959473,
      "learning_rate": 1.0741053404294366e-05,
      "logits/chosen": 0.22866418957710266,
      "logits/rejected": 0.5318545699119568,
      "logps/chosen": -213.98464965820312,
      "logps/rejected": -270.3168029785156,
      "loss": 0.0949,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.947690486907959,
      "rewards/margins": 6.374248027801514,
      "rewards/rejected": -14.321937561035156,
      "step": 23750
    },
    {
      "epoch": 4.336162058581987,
      "grad_norm": 27.780805587768555,
      "learning_rate": 1.0711690218388694e-05,
      "logits/chosen": 0.29846563935279846,
      "logits/rejected": 0.9172293543815613,
      "logps/chosen": -220.44088745117188,
      "logps/rejected": -252.7497100830078,
      "loss": 0.1693,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.028961181640625,
      "rewards/margins": 6.10420036315918,
      "rewards/rejected": -13.133161544799805,
      "step": 23760
    },
    {
      "epoch": 4.337987042613377,
      "grad_norm": 3.2105138301849365,
      "learning_rate": 1.0682327032483026e-05,
      "logits/chosen": 0.1273539811372757,
      "logits/rejected": 0.6880571842193604,
      "logps/chosen": -210.26754760742188,
      "logps/rejected": -244.26419067382812,
      "loss": 0.1235,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.5446977615356445,
      "rewards/margins": 5.996098041534424,
      "rewards/rejected": -13.540796279907227,
      "step": 23770
    },
    {
      "epoch": 4.339812026644767,
      "grad_norm": 0.7361486554145813,
      "learning_rate": 1.0652963846577355e-05,
      "logits/chosen": 0.23154500126838684,
      "logits/rejected": 0.6992257833480835,
      "logps/chosen": -212.7615509033203,
      "logps/rejected": -257.1230773925781,
      "loss": 0.0458,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.811717987060547,
      "rewards/margins": 6.562878608703613,
      "rewards/rejected": -13.374595642089844,
      "step": 23780
    },
    {
      "epoch": 4.341637010676156,
      "grad_norm": 1.0582406520843506,
      "learning_rate": 1.0623600660671685e-05,
      "logits/chosen": 0.13676568865776062,
      "logits/rejected": 0.6199557781219482,
      "logps/chosen": -225.24398803710938,
      "logps/rejected": -272.7793273925781,
      "loss": 0.1307,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.495609283447266,
      "rewards/margins": 6.5297393798828125,
      "rewards/rejected": -14.025347709655762,
      "step": 23790
    },
    {
      "epoch": 4.343461994707546,
      "grad_norm": 19.227569580078125,
      "learning_rate": 1.0594237474766013e-05,
      "logits/chosen": 0.1533932387828827,
      "logits/rejected": 0.5880868434906006,
      "logps/chosen": -223.25637817382812,
      "logps/rejected": -257.72491455078125,
      "loss": 0.1348,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.863259315490723,
      "rewards/margins": 6.003918647766113,
      "rewards/rejected": -13.867177963256836,
      "step": 23800
    },
    {
      "epoch": 4.345286978738936,
      "grad_norm": 0.5206845998764038,
      "learning_rate": 1.0564874288860343e-05,
      "logits/chosen": 0.11841344833374023,
      "logits/rejected": 0.5718191862106323,
      "logps/chosen": -209.92068481445312,
      "logps/rejected": -265.3580017089844,
      "loss": 0.0368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.558257102966309,
      "rewards/margins": 7.129303932189941,
      "rewards/rejected": -13.687559127807617,
      "step": 23810
    },
    {
      "epoch": 4.347111962770326,
      "grad_norm": 4.793516159057617,
      "learning_rate": 1.0535511102954672e-05,
      "logits/chosen": 0.2223464548587799,
      "logits/rejected": 0.7099050879478455,
      "logps/chosen": -209.40478515625,
      "logps/rejected": -257.28314208984375,
      "loss": 0.1127,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.6389946937561035,
      "rewards/margins": 6.282947063446045,
      "rewards/rejected": -12.921941757202148,
      "step": 23820
    },
    {
      "epoch": 4.348936946801715,
      "grad_norm": 1.1453863382339478,
      "learning_rate": 1.0506147917049002e-05,
      "logits/chosen": 0.27020227909088135,
      "logits/rejected": 0.7395723462104797,
      "logps/chosen": -226.3496856689453,
      "logps/rejected": -261.36309814453125,
      "loss": 0.164,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.290865898132324,
      "rewards/margins": 6.290533065795898,
      "rewards/rejected": -13.581400871276855,
      "step": 23830
    },
    {
      "epoch": 4.350761930833105,
      "grad_norm": 2.0026535987854004,
      "learning_rate": 1.047678473114333e-05,
      "logits/chosen": 0.5311256051063538,
      "logits/rejected": 1.1505253314971924,
      "logps/chosen": -232.50732421875,
      "logps/rejected": -281.0868225097656,
      "loss": 0.0386,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.120664596557617,
      "rewards/margins": 7.416652679443359,
      "rewards/rejected": -15.537317276000977,
      "step": 23840
    },
    {
      "epoch": 4.352586914864495,
      "grad_norm": 1.2325963973999023,
      "learning_rate": 1.044742154523766e-05,
      "logits/chosen": 0.19403977692127228,
      "logits/rejected": 0.6878340244293213,
      "logps/chosen": -254.10281372070312,
      "logps/rejected": -313.4324645996094,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -8.359050750732422,
      "rewards/margins": 7.125146389007568,
      "rewards/rejected": -15.4841947555542,
      "step": 23850
    },
    {
      "epoch": 4.354411898895885,
      "grad_norm": 8.647671699523926,
      "learning_rate": 1.0418058359331989e-05,
      "logits/chosen": 0.48855701088905334,
      "logits/rejected": 1.1529426574707031,
      "logps/chosen": -229.2102813720703,
      "logps/rejected": -262.1116943359375,
      "loss": 0.0661,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.766589164733887,
      "rewards/margins": 6.800392150878906,
      "rewards/rejected": -14.566981315612793,
      "step": 23860
    },
    {
      "epoch": 4.356236882927274,
      "grad_norm": 0.5084505081176758,
      "learning_rate": 1.0388695173426317e-05,
      "logits/chosen": 0.24757759273052216,
      "logits/rejected": 0.7979131937026978,
      "logps/chosen": -216.38272094726562,
      "logps/rejected": -259.9616394042969,
      "loss": 0.1188,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -7.546418190002441,
      "rewards/margins": 6.723088264465332,
      "rewards/rejected": -14.269506454467773,
      "step": 23870
    },
    {
      "epoch": 4.358061866958664,
      "grad_norm": 5.344277381896973,
      "learning_rate": 1.0359331987520647e-05,
      "logits/chosen": 0.29641926288604736,
      "logits/rejected": 0.8158496618270874,
      "logps/chosen": -220.88760375976562,
      "logps/rejected": -261.77740478515625,
      "loss": 0.0459,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.02764892578125,
      "rewards/margins": 6.401069641113281,
      "rewards/rejected": -13.428716659545898,
      "step": 23880
    },
    {
      "epoch": 4.359886850990054,
      "grad_norm": 1.2798346281051636,
      "learning_rate": 1.0329968801614976e-05,
      "logits/chosen": 0.1678977608680725,
      "logits/rejected": 0.6942914724349976,
      "logps/chosen": -230.39883422851562,
      "logps/rejected": -286.34515380859375,
      "loss": 0.0521,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.423960208892822,
      "rewards/margins": 7.102843284606934,
      "rewards/rejected": -14.526803970336914,
      "step": 23890
    },
    {
      "epoch": 4.361711835021444,
      "grad_norm": 2.532681941986084,
      "learning_rate": 1.0300605615709304e-05,
      "logits/chosen": 0.3508046269416809,
      "logits/rejected": 1.0423866510391235,
      "logps/chosen": -223.8262939453125,
      "logps/rejected": -261.6444396972656,
      "loss": 0.034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.023133754730225,
      "rewards/margins": 6.874743461608887,
      "rewards/rejected": -13.897875785827637,
      "step": 23900
    },
    {
      "epoch": 4.363536819052833,
      "grad_norm": 0.9583846926689148,
      "learning_rate": 1.0271242429803634e-05,
      "logits/chosen": 0.3837071359157562,
      "logits/rejected": 0.734295666217804,
      "logps/chosen": -215.52847290039062,
      "logps/rejected": -276.6981201171875,
      "loss": 0.0433,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.138969421386719,
      "rewards/margins": 6.640106201171875,
      "rewards/rejected": -13.779075622558594,
      "step": 23910
    },
    {
      "epoch": 4.365361803084223,
      "grad_norm": 0.9746699333190918,
      "learning_rate": 1.0241879243897964e-05,
      "logits/chosen": 0.44033780694007874,
      "logits/rejected": 0.9905399084091187,
      "logps/chosen": -213.2209930419922,
      "logps/rejected": -253.6491241455078,
      "loss": 0.0451,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.404913902282715,
      "rewards/margins": 6.910990238189697,
      "rewards/rejected": -13.315902709960938,
      "step": 23920
    },
    {
      "epoch": 4.367186787115613,
      "grad_norm": 21.40155601501465,
      "learning_rate": 1.0212516057992292e-05,
      "logits/chosen": 0.2524901330471039,
      "logits/rejected": 0.7352281808853149,
      "logps/chosen": -218.23556518554688,
      "logps/rejected": -266.2968444824219,
      "loss": 0.0694,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.455903053283691,
      "rewards/margins": 6.580842018127441,
      "rewards/rejected": -14.036745071411133,
      "step": 23930
    },
    {
      "epoch": 4.369011771147003,
      "grad_norm": 4.183680534362793,
      "learning_rate": 1.0183152872086621e-05,
      "logits/chosen": 0.28388866782188416,
      "logits/rejected": 0.7671889662742615,
      "logps/chosen": -223.443603515625,
      "logps/rejected": -274.5140075683594,
      "loss": 0.1021,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.383364677429199,
      "rewards/margins": 5.855905055999756,
      "rewards/rejected": -13.239270210266113,
      "step": 23940
    },
    {
      "epoch": 4.370836755178392,
      "grad_norm": 0.43022751808166504,
      "learning_rate": 1.0153789686180951e-05,
      "logits/chosen": 0.1264771670103073,
      "logits/rejected": 0.8455661535263062,
      "logps/chosen": -217.97195434570312,
      "logps/rejected": -257.41339111328125,
      "loss": 0.0299,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.107429027557373,
      "rewards/margins": 7.261353969573975,
      "rewards/rejected": -13.368783950805664,
      "step": 23950
    },
    {
      "epoch": 4.372661739209782,
      "grad_norm": 2.7170982360839844,
      "learning_rate": 1.0124426500275282e-05,
      "logits/chosen": 0.7353752255439758,
      "logits/rejected": 1.1058528423309326,
      "logps/chosen": -218.9095916748047,
      "logps/rejected": -273.8453674316406,
      "loss": 0.0952,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.117289543151855,
      "rewards/margins": 6.117459297180176,
      "rewards/rejected": -14.234746932983398,
      "step": 23960
    },
    {
      "epoch": 4.374486723241172,
      "grad_norm": 3.5307023525238037,
      "learning_rate": 1.009506331436961e-05,
      "logits/chosen": 0.4582553505897522,
      "logits/rejected": 0.8565235137939453,
      "logps/chosen": -214.52340698242188,
      "logps/rejected": -267.4156494140625,
      "loss": 0.0667,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.403615474700928,
      "rewards/margins": 6.558854103088379,
      "rewards/rejected": -13.962469100952148,
      "step": 23970
    },
    {
      "epoch": 4.376311707272562,
      "grad_norm": 0.4983886778354645,
      "learning_rate": 1.006570012846394e-05,
      "logits/chosen": 0.4653981328010559,
      "logits/rejected": 0.903518795967102,
      "logps/chosen": -206.52804565429688,
      "logps/rejected": -252.57620239257812,
      "loss": 0.0827,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.095359802246094,
      "rewards/margins": 6.417411804199219,
      "rewards/rejected": -13.512771606445312,
      "step": 23980
    },
    {
      "epoch": 4.3781366913039514,
      "grad_norm": 2.098639965057373,
      "learning_rate": 1.003633694255827e-05,
      "logits/chosen": 0.5036317110061646,
      "logits/rejected": 1.003553867340088,
      "logps/chosen": -229.4957275390625,
      "logps/rejected": -278.975341796875,
      "loss": 0.0611,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.858563423156738,
      "rewards/margins": 5.957164287567139,
      "rewards/rejected": -13.815727233886719,
      "step": 23990
    },
    {
      "epoch": 4.379961675335341,
      "grad_norm": 0.8059919476509094,
      "learning_rate": 1.0006973756652598e-05,
      "logits/chosen": 0.1971178948879242,
      "logits/rejected": 0.822360634803772,
      "logps/chosen": -212.6104736328125,
      "logps/rejected": -258.14459228515625,
      "loss": 0.0368,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.833728790283203,
      "rewards/margins": 6.7039055824279785,
      "rewards/rejected": -13.537633895874023,
      "step": 24000
    },
    {
      "epoch": 4.381786659366731,
      "grad_norm": 3.9836621284484863,
      "learning_rate": 9.977610570746927e-06,
      "logits/chosen": 0.1579289436340332,
      "logits/rejected": 0.6488977670669556,
      "logps/chosen": -210.58154296875,
      "logps/rejected": -269.7646789550781,
      "loss": 0.0753,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.6784234046936035,
      "rewards/margins": 6.852852821350098,
      "rewards/rejected": -13.531277656555176,
      "step": 24010
    },
    {
      "epoch": 4.383611643398121,
      "grad_norm": 2.1362104415893555,
      "learning_rate": 9.948247384841257e-06,
      "logits/chosen": 0.29967838525772095,
      "logits/rejected": 0.6512757539749146,
      "logps/chosen": -222.6720428466797,
      "logps/rejected": -286.6155090332031,
      "loss": 0.1257,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.048526763916016,
      "rewards/margins": 7.111664772033691,
      "rewards/rejected": -14.160191535949707,
      "step": 24020
    },
    {
      "epoch": 4.38543662742951,
      "grad_norm": 1.5343031883239746,
      "learning_rate": 9.918884198935585e-06,
      "logits/chosen": 0.32837265729904175,
      "logits/rejected": 1.1156957149505615,
      "logps/chosen": -213.7929229736328,
      "logps/rejected": -253.2581024169922,
      "loss": 0.0243,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.844042778015137,
      "rewards/margins": 7.218009948730469,
      "rewards/rejected": -14.062052726745605,
      "step": 24030
    },
    {
      "epoch": 4.387261611460899,
      "grad_norm": 4.805822372436523,
      "learning_rate": 9.889521013029914e-06,
      "logits/chosen": 0.4901455044746399,
      "logits/rejected": 1.0498230457305908,
      "logps/chosen": -225.6433868408203,
      "logps/rejected": -261.4414978027344,
      "loss": 0.0848,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.8256659507751465,
      "rewards/margins": 6.000452518463135,
      "rewards/rejected": -13.826116561889648,
      "step": 24040
    },
    {
      "epoch": 4.389086595492289,
      "grad_norm": 9.590822219848633,
      "learning_rate": 9.860157827124244e-06,
      "logits/chosen": 0.04571040719747543,
      "logits/rejected": 0.8506935238838196,
      "logps/chosen": -242.9977264404297,
      "logps/rejected": -259.9482421875,
      "loss": 0.3838,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.216198921203613,
      "rewards/margins": 5.834488868713379,
      "rewards/rejected": -13.050686836242676,
      "step": 24050
    },
    {
      "epoch": 4.390911579523679,
      "grad_norm": 0.4759353697299957,
      "learning_rate": 9.830794641218572e-06,
      "logits/chosen": 0.2211027890443802,
      "logits/rejected": 0.6027644276618958,
      "logps/chosen": -227.21334838867188,
      "logps/rejected": -275.3184509277344,
      "loss": 0.0912,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.913572788238525,
      "rewards/margins": 6.606745719909668,
      "rewards/rejected": -13.520318984985352,
      "step": 24060
    },
    {
      "epoch": 4.392736563555069,
      "grad_norm": 8.590311050415039,
      "learning_rate": 9.801431455312902e-06,
      "logits/chosen": 0.3789108991622925,
      "logits/rejected": 0.8806438446044922,
      "logps/chosen": -233.1492156982422,
      "logps/rejected": -270.86444091796875,
      "loss": 0.1373,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.51906681060791,
      "rewards/margins": 5.84192419052124,
      "rewards/rejected": -13.360990524291992,
      "step": 24070
    },
    {
      "epoch": 4.394561547586458,
      "grad_norm": 15.33095645904541,
      "learning_rate": 9.772068269407231e-06,
      "logits/chosen": 0.2098265141248703,
      "logits/rejected": 0.6854285001754761,
      "logps/chosen": -210.60165405273438,
      "logps/rejected": -249.9568634033203,
      "loss": 0.0561,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.47493839263916,
      "rewards/margins": 5.780757904052734,
      "rewards/rejected": -13.255697250366211,
      "step": 24080
    },
    {
      "epoch": 4.396386531617848,
      "grad_norm": 1.2057429552078247,
      "learning_rate": 9.74270508350156e-06,
      "logits/chosen": 0.2082671821117401,
      "logits/rejected": 0.9255610704421997,
      "logps/chosen": -209.8834686279297,
      "logps/rejected": -255.2461395263672,
      "loss": 0.0388,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.8764801025390625,
      "rewards/margins": 6.7950615882873535,
      "rewards/rejected": -13.671541213989258,
      "step": 24090
    },
    {
      "epoch": 4.398211515649238,
      "grad_norm": 27.43657112121582,
      "learning_rate": 9.71334189759589e-06,
      "logits/chosen": 0.3988746404647827,
      "logits/rejected": 1.1202162504196167,
      "logps/chosen": -242.19271850585938,
      "logps/rejected": -262.0887451171875,
      "loss": 0.0713,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.007721900939941,
      "rewards/margins": 6.524507999420166,
      "rewards/rejected": -14.532228469848633,
      "step": 24100
    },
    {
      "epoch": 4.400036499680628,
      "grad_norm": 2.3759336471557617,
      "learning_rate": 9.683978711690219e-06,
      "logits/chosen": 0.13335032761096954,
      "logits/rejected": 0.6164796948432922,
      "logps/chosen": -228.1357879638672,
      "logps/rejected": -264.96368408203125,
      "loss": 0.054,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.205757141113281,
      "rewards/margins": 6.470533847808838,
      "rewards/rejected": -13.676290512084961,
      "step": 24110
    },
    {
      "epoch": 4.401861483712017,
      "grad_norm": 4.527661323547363,
      "learning_rate": 9.654615525784548e-06,
      "logits/chosen": 0.3795616924762726,
      "logits/rejected": 1.0595875978469849,
      "logps/chosen": -221.5116424560547,
      "logps/rejected": -251.7976531982422,
      "loss": 0.0417,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.150745391845703,
      "rewards/margins": 6.476815223693848,
      "rewards/rejected": -13.62756061553955,
      "step": 24120
    },
    {
      "epoch": 4.403686467743407,
      "grad_norm": 0.5492496490478516,
      "learning_rate": 9.625252339878878e-06,
      "logits/chosen": 0.2953264117240906,
      "logits/rejected": 0.5950174927711487,
      "logps/chosen": -209.69735717773438,
      "logps/rejected": -284.4559020996094,
      "loss": 0.1054,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.639143466949463,
      "rewards/margins": 6.874032497406006,
      "rewards/rejected": -14.513174057006836,
      "step": 24130
    },
    {
      "epoch": 4.405511451774797,
      "grad_norm": 10.099116325378418,
      "learning_rate": 9.595889153973208e-06,
      "logits/chosen": 0.4972558915615082,
      "logits/rejected": 0.8983300924301147,
      "logps/chosen": -201.79849243164062,
      "logps/rejected": -257.32537841796875,
      "loss": 0.1142,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.573094844818115,
      "rewards/margins": 6.139331817626953,
      "rewards/rejected": -12.712427139282227,
      "step": 24140
    },
    {
      "epoch": 4.407336435806187,
      "grad_norm": 0.7608419060707092,
      "learning_rate": 9.566525968067536e-06,
      "logits/chosen": 0.2692874073982239,
      "logits/rejected": 0.825030505657196,
      "logps/chosen": -210.57339477539062,
      "logps/rejected": -262.7324523925781,
      "loss": 0.0498,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.154197692871094,
      "rewards/margins": 6.780749320983887,
      "rewards/rejected": -12.93494701385498,
      "step": 24150
    },
    {
      "epoch": 4.409161419837576,
      "grad_norm": 20.950611114501953,
      "learning_rate": 9.537162782161865e-06,
      "logits/chosen": 0.4212212562561035,
      "logits/rejected": 0.9547122716903687,
      "logps/chosen": -229.3526611328125,
      "logps/rejected": -269.8746032714844,
      "loss": 0.1066,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.416436195373535,
      "rewards/margins": 7.21481990814209,
      "rewards/rejected": -14.631256103515625,
      "step": 24160
    },
    {
      "epoch": 4.410986403868966,
      "grad_norm": 2.753763437271118,
      "learning_rate": 9.507799596256195e-06,
      "logits/chosen": 0.3284420967102051,
      "logits/rejected": 0.88129723072052,
      "logps/chosen": -229.86721801757812,
      "logps/rejected": -277.58343505859375,
      "loss": 0.0394,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.875386714935303,
      "rewards/margins": 5.963624954223633,
      "rewards/rejected": -13.839012145996094,
      "step": 24170
    },
    {
      "epoch": 4.412811387900356,
      "grad_norm": 1.2329262495040894,
      "learning_rate": 9.478436410350523e-06,
      "logits/chosen": 0.2778094410896301,
      "logits/rejected": 0.8193262219429016,
      "logps/chosen": -227.5321502685547,
      "logps/rejected": -279.1728820800781,
      "loss": 0.0765,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.384023189544678,
      "rewards/margins": 6.623669624328613,
      "rewards/rejected": -14.007695198059082,
      "step": 24180
    },
    {
      "epoch": 4.414636371931746,
      "grad_norm": 9.375290870666504,
      "learning_rate": 9.449073224444854e-06,
      "logits/chosen": 0.42776885628700256,
      "logits/rejected": 1.0895226001739502,
      "logps/chosen": -240.9497833251953,
      "logps/rejected": -278.82940673828125,
      "loss": 0.0499,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.9361701011657715,
      "rewards/margins": 6.398442268371582,
      "rewards/rejected": -14.334612846374512,
      "step": 24190
    },
    {
      "epoch": 4.416461355963135,
      "grad_norm": 3.5438928604125977,
      "learning_rate": 9.419710038539182e-06,
      "logits/chosen": 0.5235003232955933,
      "logits/rejected": 0.759497344493866,
      "logps/chosen": -224.62313842773438,
      "logps/rejected": -285.62017822265625,
      "loss": 0.0557,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.922377586364746,
      "rewards/margins": 7.316216945648193,
      "rewards/rejected": -15.238595962524414,
      "step": 24200
    },
    {
      "epoch": 4.418286339994525,
      "grad_norm": 0.5173436403274536,
      "learning_rate": 9.390346852633512e-06,
      "logits/chosen": 0.5595041513442993,
      "logits/rejected": 1.0996854305267334,
      "logps/chosen": -230.66421508789062,
      "logps/rejected": -284.6092834472656,
      "loss": 0.0793,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.976365089416504,
      "rewards/margins": 7.316378593444824,
      "rewards/rejected": -15.292744636535645,
      "step": 24210
    },
    {
      "epoch": 4.420111324025915,
      "grad_norm": 28.01617431640625,
      "learning_rate": 9.360983666727842e-06,
      "logits/chosen": 0.1201419085264206,
      "logits/rejected": 0.849922776222229,
      "logps/chosen": -250.85958862304688,
      "logps/rejected": -284.06976318359375,
      "loss": 0.1313,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -8.623758316040039,
      "rewards/margins": 6.571955680847168,
      "rewards/rejected": -15.195712089538574,
      "step": 24220
    },
    {
      "epoch": 4.421936308057305,
      "grad_norm": 11.797540664672852,
      "learning_rate": 9.33162048082217e-06,
      "logits/chosen": 0.427689790725708,
      "logits/rejected": 1.0068038702011108,
      "logps/chosen": -226.73367309570312,
      "logps/rejected": -283.58892822265625,
      "loss": 0.0582,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.04005241394043,
      "rewards/margins": 6.873365879058838,
      "rewards/rejected": -14.913416862487793,
      "step": 24230
    },
    {
      "epoch": 4.423761292088694,
      "grad_norm": 1.4049499034881592,
      "learning_rate": 9.302257294916499e-06,
      "logits/chosen": 0.45910364389419556,
      "logits/rejected": 1.105942964553833,
      "logps/chosen": -211.73519897460938,
      "logps/rejected": -271.4656677246094,
      "loss": 0.044,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.486935615539551,
      "rewards/margins": 6.997671604156494,
      "rewards/rejected": -14.48460865020752,
      "step": 24240
    },
    {
      "epoch": 4.425586276120084,
      "grad_norm": 3.2742693424224854,
      "learning_rate": 9.272894109010829e-06,
      "logits/chosen": 0.6360118985176086,
      "logits/rejected": 0.9024978876113892,
      "logps/chosen": -207.14303588867188,
      "logps/rejected": -290.7305603027344,
      "loss": 0.044,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.703774929046631,
      "rewards/margins": 7.273723602294922,
      "rewards/rejected": -14.977499008178711,
      "step": 24250
    },
    {
      "epoch": 4.427411260151474,
      "grad_norm": 1.1170934438705444,
      "learning_rate": 9.243530923105157e-06,
      "logits/chosen": 0.30619755387306213,
      "logits/rejected": 1.1133525371551514,
      "logps/chosen": -235.5986785888672,
      "logps/rejected": -255.08090209960938,
      "loss": 0.0388,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.495940208435059,
      "rewards/margins": 6.3924336433410645,
      "rewards/rejected": -14.888374328613281,
      "step": 24260
    },
    {
      "epoch": 4.429236244182864,
      "grad_norm": 13.937142372131348,
      "learning_rate": 9.214167737199486e-06,
      "logits/chosen": 0.5245969295501709,
      "logits/rejected": 1.0321073532104492,
      "logps/chosen": -219.7551727294922,
      "logps/rejected": -275.6625061035156,
      "loss": 0.0306,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.135032653808594,
      "rewards/margins": 7.211358547210693,
      "rewards/rejected": -15.346389770507812,
      "step": 24270
    },
    {
      "epoch": 4.431061228214253,
      "grad_norm": 5.88278341293335,
      "learning_rate": 9.184804551293816e-06,
      "logits/chosen": 0.25644826889038086,
      "logits/rejected": 0.8446671366691589,
      "logps/chosen": -221.35671997070312,
      "logps/rejected": -266.18243408203125,
      "loss": 0.0529,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.111024379730225,
      "rewards/margins": 6.981349945068359,
      "rewards/rejected": -14.092374801635742,
      "step": 24280
    },
    {
      "epoch": 4.432886212245643,
      "grad_norm": 18.01053810119629,
      "learning_rate": 9.155441365388146e-06,
      "logits/chosen": 0.3322729468345642,
      "logits/rejected": 0.8944495320320129,
      "logps/chosen": -231.6472625732422,
      "logps/rejected": -289.08087158203125,
      "loss": 0.1016,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.958025932312012,
      "rewards/margins": 7.164711952209473,
      "rewards/rejected": -15.122736930847168,
      "step": 24290
    },
    {
      "epoch": 4.434711196277033,
      "grad_norm": 13.262004852294922,
      "learning_rate": 9.126078179482475e-06,
      "logits/chosen": 0.4258088171482086,
      "logits/rejected": 1.2298305034637451,
      "logps/chosen": -245.08242797851562,
      "logps/rejected": -282.4294738769531,
      "loss": 0.0507,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -9.296330451965332,
      "rewards/margins": 6.941494941711426,
      "rewards/rejected": -16.23782730102539,
      "step": 24300
    },
    {
      "epoch": 4.436536180308423,
      "grad_norm": 20.752656936645508,
      "learning_rate": 9.096714993576803e-06,
      "logits/chosen": 0.355977863073349,
      "logits/rejected": 1.0544415712356567,
      "logps/chosen": -220.6970672607422,
      "logps/rejected": -253.76199340820312,
      "loss": 0.1559,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.415029048919678,
      "rewards/margins": 6.149027347564697,
      "rewards/rejected": -13.564056396484375,
      "step": 24310
    },
    {
      "epoch": 4.438361164339812,
      "grad_norm": 0.1800336390733719,
      "learning_rate": 9.067351807671133e-06,
      "logits/chosen": 0.41225045919418335,
      "logits/rejected": 0.7779535055160522,
      "logps/chosen": -220.73806762695312,
      "logps/rejected": -286.3839416503906,
      "loss": 0.0615,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.040102005004883,
      "rewards/margins": 7.285941123962402,
      "rewards/rejected": -15.326044082641602,
      "step": 24320
    },
    {
      "epoch": 4.440186148371202,
      "grad_norm": 4.2134294509887695,
      "learning_rate": 9.037988621765463e-06,
      "logits/chosen": 0.24268794059753418,
      "logits/rejected": 0.8732892870903015,
      "logps/chosen": -223.608642578125,
      "logps/rejected": -264.6238708496094,
      "loss": 0.0402,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.130575656890869,
      "rewards/margins": 6.558780670166016,
      "rewards/rejected": -13.689355850219727,
      "step": 24330
    },
    {
      "epoch": 4.442011132402591,
      "grad_norm": 3.2858920097351074,
      "learning_rate": 9.00862543585979e-06,
      "logits/chosen": 0.48586973547935486,
      "logits/rejected": 0.961388111114502,
      "logps/chosen": -206.4474639892578,
      "logps/rejected": -271.69317626953125,
      "loss": 0.0402,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.031924247741699,
      "rewards/margins": 7.331629276275635,
      "rewards/rejected": -14.363554000854492,
      "step": 24340
    },
    {
      "epoch": 4.443836116433981,
      "grad_norm": 5.828652381896973,
      "learning_rate": 8.97926224995412e-06,
      "logits/chosen": 0.45036420226097107,
      "logits/rejected": 0.8015730977058411,
      "logps/chosen": -205.67599487304688,
      "logps/rejected": -268.4275207519531,
      "loss": 0.0512,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.9953107833862305,
      "rewards/margins": 7.091325283050537,
      "rewards/rejected": -14.086636543273926,
      "step": 24350
    },
    {
      "epoch": 4.4456611004653706,
      "grad_norm": 0.4848732054233551,
      "learning_rate": 8.94989906404845e-06,
      "logits/chosen": 0.6400901079177856,
      "logits/rejected": 0.8914889097213745,
      "logps/chosen": -217.8156280517578,
      "logps/rejected": -291.77459716796875,
      "loss": 0.0846,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -8.109831809997559,
      "rewards/margins": 6.8516082763671875,
      "rewards/rejected": -14.961442947387695,
      "step": 24360
    },
    {
      "epoch": 4.44748608449676,
      "grad_norm": 3.09975528717041,
      "learning_rate": 8.92053587814278e-06,
      "logits/chosen": 0.5540698170661926,
      "logits/rejected": 1.0769870281219482,
      "logps/chosen": -215.46023559570312,
      "logps/rejected": -280.5067443847656,
      "loss": 0.0505,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.043237686157227,
      "rewards/margins": 7.3206305503845215,
      "rewards/rejected": -15.363870620727539,
      "step": 24370
    },
    {
      "epoch": 4.44931106852815,
      "grad_norm": 1.0514016151428223,
      "learning_rate": 8.89117269223711e-06,
      "logits/chosen": 0.3891013562679291,
      "logits/rejected": 0.9120227098464966,
      "logps/chosen": -226.58273315429688,
      "logps/rejected": -265.4575500488281,
      "loss": 0.1125,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.598278999328613,
      "rewards/margins": 6.0326738357543945,
      "rewards/rejected": -13.630952835083008,
      "step": 24380
    },
    {
      "epoch": 4.45113605255954,
      "grad_norm": 2.9298884868621826,
      "learning_rate": 8.861809506331437e-06,
      "logits/chosen": 0.2117854803800583,
      "logits/rejected": 0.9162474870681763,
      "logps/chosen": -223.49649047851562,
      "logps/rejected": -254.60409545898438,
      "loss": 0.0876,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.121426582336426,
      "rewards/margins": 6.2357659339904785,
      "rewards/rejected": -13.357192993164062,
      "step": 24390
    },
    {
      "epoch": 4.45296103659093,
      "grad_norm": 2.072089910507202,
      "learning_rate": 8.832446320425767e-06,
      "logits/chosen": 0.34527772665023804,
      "logits/rejected": 1.052525281906128,
      "logps/chosen": -223.843994140625,
      "logps/rejected": -251.01742553710938,
      "loss": 0.0635,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.885581970214844,
      "rewards/margins": 6.390778064727783,
      "rewards/rejected": -13.276361465454102,
      "step": 24400
    },
    {
      "epoch": 4.454786020622319,
      "grad_norm": 1.884702205657959,
      "learning_rate": 8.803083134520097e-06,
      "logits/chosen": 0.4121394157409668,
      "logits/rejected": 0.8654705286026001,
      "logps/chosen": -204.3538818359375,
      "logps/rejected": -257.0434265136719,
      "loss": 0.1528,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.49916934967041,
      "rewards/margins": 6.6449761390686035,
      "rewards/rejected": -13.144145011901855,
      "step": 24410
    },
    {
      "epoch": 4.456611004653709,
      "grad_norm": 3.3127424716949463,
      "learning_rate": 8.773719948614426e-06,
      "logits/chosen": 0.3412902355194092,
      "logits/rejected": 0.8010770678520203,
      "logps/chosen": -222.32958984375,
      "logps/rejected": -263.5927429199219,
      "loss": 0.1695,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.608587741851807,
      "rewards/margins": 6.062380313873291,
      "rewards/rejected": -13.670969009399414,
      "step": 24420
    },
    {
      "epoch": 4.458435988685099,
      "grad_norm": 1.7634594440460205,
      "learning_rate": 8.744356762708754e-06,
      "logits/chosen": 0.3674960732460022,
      "logits/rejected": 1.2772313356399536,
      "logps/chosen": -208.9056396484375,
      "logps/rejected": -244.2537078857422,
      "loss": 0.0635,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.208486080169678,
      "rewards/margins": 6.464392185211182,
      "rewards/rejected": -13.672877311706543,
      "step": 24430
    },
    {
      "epoch": 4.460260972716489,
      "grad_norm": 5.224130153656006,
      "learning_rate": 8.714993576803084e-06,
      "logits/chosen": 0.3671286702156067,
      "logits/rejected": 0.6536937952041626,
      "logps/chosen": -220.4011688232422,
      "logps/rejected": -275.5476379394531,
      "loss": 0.0481,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.2728166580200195,
      "rewards/margins": 6.595608711242676,
      "rewards/rejected": -13.868425369262695,
      "step": 24440
    },
    {
      "epoch": 4.462085956747878,
      "grad_norm": 16.065750122070312,
      "learning_rate": 8.685630390897413e-06,
      "logits/chosen": 0.3687332570552826,
      "logits/rejected": 0.7077091932296753,
      "logps/chosen": -212.3138885498047,
      "logps/rejected": -259.76287841796875,
      "loss": 0.0834,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.306264400482178,
      "rewards/margins": 6.356553077697754,
      "rewards/rejected": -13.662816047668457,
      "step": 24450
    },
    {
      "epoch": 4.463910940779268,
      "grad_norm": 0.8280143737792969,
      "learning_rate": 8.656267204991741e-06,
      "logits/chosen": 0.6729388236999512,
      "logits/rejected": 0.8252333402633667,
      "logps/chosen": -219.7223358154297,
      "logps/rejected": -287.2899475097656,
      "loss": 0.038,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.5186448097229,
      "rewards/margins": 6.468926906585693,
      "rewards/rejected": -13.987571716308594,
      "step": 24460
    },
    {
      "epoch": 4.465735924810658,
      "grad_norm": 10.89828872680664,
      "learning_rate": 8.626904019086073e-06,
      "logits/chosen": 0.13481029868125916,
      "logits/rejected": 0.9131619334220886,
      "logps/chosen": -208.1750030517578,
      "logps/rejected": -255.916748046875,
      "loss": 0.0501,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.743544101715088,
      "rewards/margins": 7.136216163635254,
      "rewards/rejected": -13.879758834838867,
      "step": 24470
    },
    {
      "epoch": 4.467560908842048,
      "grad_norm": 1.0075805187225342,
      "learning_rate": 8.5975408331804e-06,
      "logits/chosen": 0.1483500748872757,
      "logits/rejected": 0.40860962867736816,
      "logps/chosen": -229.8804168701172,
      "logps/rejected": -279.16748046875,
      "loss": 0.1402,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.153738975524902,
      "rewards/margins": 6.1686296463012695,
      "rewards/rejected": -13.322367668151855,
      "step": 24480
    },
    {
      "epoch": 4.469385892873437,
      "grad_norm": 13.910865783691406,
      "learning_rate": 8.56817764727473e-06,
      "logits/chosen": 0.25716084241867065,
      "logits/rejected": 0.5670163631439209,
      "logps/chosen": -209.69839477539062,
      "logps/rejected": -262.99505615234375,
      "loss": 0.1154,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -7.216411590576172,
      "rewards/margins": 5.846316337585449,
      "rewards/rejected": -13.062728881835938,
      "step": 24490
    },
    {
      "epoch": 4.471210876904827,
      "grad_norm": 2.6468167304992676,
      "learning_rate": 8.53881446136906e-06,
      "logits/chosen": 0.41464200615882874,
      "logits/rejected": 0.8431563377380371,
      "logps/chosen": -205.3870849609375,
      "logps/rejected": -257.94049072265625,
      "loss": 0.0413,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.396147727966309,
      "rewards/margins": 6.312905311584473,
      "rewards/rejected": -12.709053039550781,
      "step": 24500
    },
    {
      "epoch": 4.473035860936217,
      "grad_norm": 5.71230411529541,
      "learning_rate": 8.509451275463388e-06,
      "logits/chosen": 0.3029581904411316,
      "logits/rejected": 0.658081591129303,
      "logps/chosen": -209.23043823242188,
      "logps/rejected": -263.752197265625,
      "loss": 0.0723,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.228964328765869,
      "rewards/margins": 6.3893632888793945,
      "rewards/rejected": -13.618326187133789,
      "step": 24510
    },
    {
      "epoch": 4.474860844967607,
      "grad_norm": 1.7389382123947144,
      "learning_rate": 8.480088089557718e-06,
      "logits/chosen": 0.3885132670402527,
      "logits/rejected": 0.873874306678772,
      "logps/chosen": -207.6985321044922,
      "logps/rejected": -270.1130065917969,
      "loss": 0.0521,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.043219089508057,
      "rewards/margins": 6.796732425689697,
      "rewards/rejected": -13.83995246887207,
      "step": 24520
    },
    {
      "epoch": 4.476685828998996,
      "grad_norm": 0.9624411463737488,
      "learning_rate": 8.450724903652047e-06,
      "logits/chosen": 0.36346301436424255,
      "logits/rejected": 0.8189098238945007,
      "logps/chosen": -195.10679626464844,
      "logps/rejected": -251.8464813232422,
      "loss": 0.0333,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.633709907531738,
      "rewards/margins": 7.017961025238037,
      "rewards/rejected": -13.6516695022583,
      "step": 24530
    },
    {
      "epoch": 4.478510813030386,
      "grad_norm": 5.2367048263549805,
      "learning_rate": 8.421361717746375e-06,
      "logits/chosen": 0.31136271357536316,
      "logits/rejected": 0.6753072142601013,
      "logps/chosen": -206.0051727294922,
      "logps/rejected": -272.40264892578125,
      "loss": 0.0881,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.311962127685547,
      "rewards/margins": 6.954505920410156,
      "rewards/rejected": -14.266467094421387,
      "step": 24540
    },
    {
      "epoch": 4.480335797061776,
      "grad_norm": 9.286177635192871,
      "learning_rate": 8.391998531840705e-06,
      "logits/chosen": 0.1301722228527069,
      "logits/rejected": 0.6859589219093323,
      "logps/chosen": -226.1833038330078,
      "logps/rejected": -261.9290771484375,
      "loss": 0.0383,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.40209436416626,
      "rewards/margins": 5.999668121337891,
      "rewards/rejected": -13.401763916015625,
      "step": 24550
    },
    {
      "epoch": 4.482160781093166,
      "grad_norm": 6.551796913146973,
      "learning_rate": 8.362635345935035e-06,
      "logits/chosen": 0.2285757064819336,
      "logits/rejected": 0.6717212200164795,
      "logps/chosen": -206.45596313476562,
      "logps/rejected": -248.56396484375,
      "loss": 0.037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.800110816955566,
      "rewards/margins": 5.9992499351501465,
      "rewards/rejected": -12.799361228942871,
      "step": 24560
    },
    {
      "epoch": 4.483985765124555,
      "grad_norm": 8.781254768371582,
      "learning_rate": 8.333272160029364e-06,
      "logits/chosen": 0.6462105512619019,
      "logits/rejected": 1.1224043369293213,
      "logps/chosen": -214.86154174804688,
      "logps/rejected": -261.7039794921875,
      "loss": 0.1266,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.049726486206055,
      "rewards/margins": 6.200997352600098,
      "rewards/rejected": -14.250724792480469,
      "step": 24570
    },
    {
      "epoch": 4.485810749155945,
      "grad_norm": 12.008420944213867,
      "learning_rate": 8.303908974123694e-06,
      "logits/chosen": 0.3429934084415436,
      "logits/rejected": 0.8730562925338745,
      "logps/chosen": -217.3274383544922,
      "logps/rejected": -268.0223083496094,
      "loss": 0.0579,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.457724094390869,
      "rewards/margins": 7.021245002746582,
      "rewards/rejected": -14.478968620300293,
      "step": 24580
    },
    {
      "epoch": 4.487635733187335,
      "grad_norm": 3.223759889602661,
      "learning_rate": 8.274545788218022e-06,
      "logits/chosen": 0.3200477659702301,
      "logits/rejected": 0.9700146913528442,
      "logps/chosen": -216.9317169189453,
      "logps/rejected": -267.9482727050781,
      "loss": 0.0554,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.45123815536499,
      "rewards/margins": 7.156564235687256,
      "rewards/rejected": -14.60780143737793,
      "step": 24590
    },
    {
      "epoch": 4.489460717218725,
      "grad_norm": 12.715241432189941,
      "learning_rate": 8.245182602312351e-06,
      "logits/chosen": 0.17261174321174622,
      "logits/rejected": 0.7662360072135925,
      "logps/chosen": -203.1422119140625,
      "logps/rejected": -249.9239044189453,
      "loss": 0.0381,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.282071590423584,
      "rewards/margins": 7.413252353668213,
      "rewards/rejected": -13.69532299041748,
      "step": 24600
    },
    {
      "epoch": 4.491285701250114,
      "grad_norm": 22.511320114135742,
      "learning_rate": 8.215819416406681e-06,
      "logits/chosen": 0.4130743443965912,
      "logits/rejected": 1.05194890499115,
      "logps/chosen": -230.38626098632812,
      "logps/rejected": -277.1143493652344,
      "loss": 0.0728,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.7002973556518555,
      "rewards/margins": 7.043266296386719,
      "rewards/rejected": -14.743563652038574,
      "step": 24610
    },
    {
      "epoch": 4.493110685281504,
      "grad_norm": 0.8421555161476135,
      "learning_rate": 8.186456230501009e-06,
      "logits/chosen": 0.1018444299697876,
      "logits/rejected": 0.4528350830078125,
      "logps/chosen": -225.0072784423828,
      "logps/rejected": -284.17254638671875,
      "loss": 0.1204,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.196378231048584,
      "rewards/margins": 6.9467267990112305,
      "rewards/rejected": -14.143106460571289,
      "step": 24620
    },
    {
      "epoch": 4.494935669312894,
      "grad_norm": 2.0225963592529297,
      "learning_rate": 8.157093044595339e-06,
      "logits/chosen": 0.09545406699180603,
      "logits/rejected": 0.7789446711540222,
      "logps/chosen": -236.75827026367188,
      "logps/rejected": -266.87799072265625,
      "loss": 0.1412,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.584875583648682,
      "rewards/margins": 7.044604301452637,
      "rewards/rejected": -14.629480361938477,
      "step": 24630
    },
    {
      "epoch": 4.496760653344284,
      "grad_norm": 3.1703219413757324,
      "learning_rate": 8.127729858689668e-06,
      "logits/chosen": 0.37447983026504517,
      "logits/rejected": 0.8543645739555359,
      "logps/chosen": -220.9503631591797,
      "logps/rejected": -274.5001220703125,
      "loss": 0.0631,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.6034255027771,
      "rewards/margins": 7.548104763031006,
      "rewards/rejected": -15.151530265808105,
      "step": 24640
    },
    {
      "epoch": 4.4985856373756725,
      "grad_norm": 8.439291000366211,
      "learning_rate": 8.098366672783998e-06,
      "logits/chosen": 0.25116586685180664,
      "logits/rejected": 0.8021417856216431,
      "logps/chosen": -223.1747589111328,
      "logps/rejected": -264.1236572265625,
      "loss": 0.1263,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.950531005859375,
      "rewards/margins": 6.290125846862793,
      "rewards/rejected": -14.240656852722168,
      "step": 24650
    },
    {
      "epoch": 4.500410621407063,
      "grad_norm": 1.0817245244979858,
      "learning_rate": 8.069003486878328e-06,
      "logits/chosen": 0.31295934319496155,
      "logits/rejected": 0.8658226728439331,
      "logps/chosen": -225.50424194335938,
      "logps/rejected": -259.70135498046875,
      "loss": 0.0563,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.291525840759277,
      "rewards/margins": 5.77333927154541,
      "rewards/rejected": -14.064865112304688,
      "step": 24660
    },
    {
      "epoch": 4.502235605438452,
      "grad_norm": 0.08921360969543457,
      "learning_rate": 8.039640300972656e-06,
      "logits/chosen": 0.32253918051719666,
      "logits/rejected": 0.7705884575843811,
      "logps/chosen": -227.9152374267578,
      "logps/rejected": -287.4576721191406,
      "loss": 0.0399,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.489290237426758,
      "rewards/margins": 7.1326093673706055,
      "rewards/rejected": -15.621899604797363,
      "step": 24670
    },
    {
      "epoch": 4.504060589469842,
      "grad_norm": 2.4757728576660156,
      "learning_rate": 8.010277115066985e-06,
      "logits/chosen": 0.09325794875621796,
      "logits/rejected": 0.5723244547843933,
      "logps/chosen": -220.0681915283203,
      "logps/rejected": -268.88592529296875,
      "loss": 0.0339,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.94742488861084,
      "rewards/margins": 6.548521995544434,
      "rewards/rejected": -14.495946884155273,
      "step": 24680
    },
    {
      "epoch": 4.5058855735012315,
      "grad_norm": 3.240898370742798,
      "learning_rate": 7.980913929161315e-06,
      "logits/chosen": 0.23605172336101532,
      "logits/rejected": 0.6632478833198547,
      "logps/chosen": -218.16055297851562,
      "logps/rejected": -281.34381103515625,
      "loss": 0.0485,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.072663307189941,
      "rewards/margins": 7.376951694488525,
      "rewards/rejected": -14.449615478515625,
      "step": 24690
    },
    {
      "epoch": 4.507710557532621,
      "grad_norm": 11.673462867736816,
      "learning_rate": 7.951550743255643e-06,
      "logits/chosen": 0.055142443627119064,
      "logits/rejected": 0.6132770776748657,
      "logps/chosen": -228.21945190429688,
      "logps/rejected": -276.3171691894531,
      "loss": 0.046,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.322648525238037,
      "rewards/margins": 6.635336399078369,
      "rewards/rejected": -13.957983016967773,
      "step": 24700
    },
    {
      "epoch": 4.509535541564011,
      "grad_norm": 2.939990282058716,
      "learning_rate": 7.922187557349973e-06,
      "logits/chosen": 0.27211594581604004,
      "logits/rejected": 0.9512270092964172,
      "logps/chosen": -224.3838348388672,
      "logps/rejected": -260.92547607421875,
      "loss": 0.0697,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.21317195892334,
      "rewards/margins": 6.40802001953125,
      "rewards/rejected": -13.621191024780273,
      "step": 24710
    },
    {
      "epoch": 4.511360525595401,
      "grad_norm": 4.345170497894287,
      "learning_rate": 7.892824371444302e-06,
      "logits/chosen": 0.2968440353870392,
      "logits/rejected": 0.6553655862808228,
      "logps/chosen": -213.994384765625,
      "logps/rejected": -270.92474365234375,
      "loss": 0.0399,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.39241886138916,
      "rewards/margins": 6.6136884689331055,
      "rewards/rejected": -14.00610637664795,
      "step": 24720
    },
    {
      "epoch": 4.5131855096267905,
      "grad_norm": 2.8991360664367676,
      "learning_rate": 7.863461185538632e-06,
      "logits/chosen": 0.2918306887149811,
      "logits/rejected": 0.7148860692977905,
      "logps/chosen": -223.258544921875,
      "logps/rejected": -262.02972412109375,
      "loss": 0.0486,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.941632270812988,
      "rewards/margins": 6.540762901306152,
      "rewards/rejected": -13.482396125793457,
      "step": 24730
    },
    {
      "epoch": 4.51501049365818,
      "grad_norm": 10.787259101867676,
      "learning_rate": 7.834097999632962e-06,
      "logits/chosen": 0.37904584407806396,
      "logits/rejected": 0.6816123723983765,
      "logps/chosen": -208.77908325195312,
      "logps/rejected": -267.7374572753906,
      "loss": 0.0853,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.034217834472656,
      "rewards/margins": 6.379202842712402,
      "rewards/rejected": -13.413421630859375,
      "step": 24740
    },
    {
      "epoch": 4.51683547768957,
      "grad_norm": 0.16313737630844116,
      "learning_rate": 7.804734813727291e-06,
      "logits/chosen": 0.1529451310634613,
      "logits/rejected": 0.7638779878616333,
      "logps/chosen": -224.44094848632812,
      "logps/rejected": -270.5038146972656,
      "loss": 0.0934,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.231165885925293,
      "rewards/margins": 7.018655300140381,
      "rewards/rejected": -14.249822616577148,
      "step": 24750
    },
    {
      "epoch": 4.51866046172096,
      "grad_norm": 5.064750671386719,
      "learning_rate": 7.77537162782162e-06,
      "logits/chosen": 0.1528872847557068,
      "logits/rejected": 0.7793588042259216,
      "logps/chosen": -227.0814208984375,
      "logps/rejected": -274.37457275390625,
      "loss": 0.0582,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.280708312988281,
      "rewards/margins": 7.0229644775390625,
      "rewards/rejected": -14.303672790527344,
      "step": 24760
    },
    {
      "epoch": 4.52048544575235,
      "grad_norm": 4.732076644897461,
      "learning_rate": 7.746008441915949e-06,
      "logits/chosen": 0.7201252579689026,
      "logits/rejected": 1.0116045475006104,
      "logps/chosen": -211.66207885742188,
      "logps/rejected": -294.6533508300781,
      "loss": 0.0467,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.800737380981445,
      "rewards/margins": 7.521016597747803,
      "rewards/rejected": -16.32175636291504,
      "step": 24770
    },
    {
      "epoch": 4.522310429783739,
      "grad_norm": 11.40131664276123,
      "learning_rate": 7.716645256010279e-06,
      "logits/chosen": -0.03791331127285957,
      "logits/rejected": 0.23541691899299622,
      "logps/chosen": -212.97256469726562,
      "logps/rejected": -273.5729064941406,
      "loss": 0.0563,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.111616611480713,
      "rewards/margins": 7.073456764221191,
      "rewards/rejected": -14.185073852539062,
      "step": 24780
    },
    {
      "epoch": 4.524135413815129,
      "grad_norm": 0.06367820501327515,
      "learning_rate": 7.687282070104606e-06,
      "logits/chosen": 0.33578428626060486,
      "logits/rejected": 0.8843525052070618,
      "logps/chosen": -236.3866424560547,
      "logps/rejected": -272.7378234863281,
      "loss": 0.03,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.963462829589844,
      "rewards/margins": 7.065157413482666,
      "rewards/rejected": -15.028620719909668,
      "step": 24790
    },
    {
      "epoch": 4.525960397846519,
      "grad_norm": 11.509347915649414,
      "learning_rate": 7.657918884198936e-06,
      "logits/chosen": 0.33861029148101807,
      "logits/rejected": 0.7324573993682861,
      "logps/chosen": -195.31951904296875,
      "logps/rejected": -248.8153076171875,
      "loss": 0.1406,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.780786037445068,
      "rewards/margins": 6.274723529815674,
      "rewards/rejected": -13.055508613586426,
      "step": 24800
    },
    {
      "epoch": 4.527785381877909,
      "grad_norm": 1.5208712816238403,
      "learning_rate": 7.628555698293265e-06,
      "logits/chosen": 0.1492381989955902,
      "logits/rejected": 0.4769517481327057,
      "logps/chosen": -206.4567108154297,
      "logps/rejected": -258.1372375488281,
      "loss": 0.0338,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.645504951477051,
      "rewards/margins": 7.5092291831970215,
      "rewards/rejected": -14.154733657836914,
      "step": 24810
    },
    {
      "epoch": 4.529610365909298,
      "grad_norm": 0.48896175622940063,
      "learning_rate": 7.599192512387595e-06,
      "logits/chosen": 0.4671192765235901,
      "logits/rejected": 0.738387405872345,
      "logps/chosen": -204.3243865966797,
      "logps/rejected": -277.44451904296875,
      "loss": 0.0488,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.873690605163574,
      "rewards/margins": 6.971651554107666,
      "rewards/rejected": -13.845341682434082,
      "step": 24820
    },
    {
      "epoch": 4.531435349940688,
      "grad_norm": 2.3269104957580566,
      "learning_rate": 7.5698293264819234e-06,
      "logits/chosen": 0.23926134407520294,
      "logits/rejected": 0.5701903700828552,
      "logps/chosen": -194.85353088378906,
      "logps/rejected": -255.119384765625,
      "loss": 0.077,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.355818748474121,
      "rewards/margins": 6.455404758453369,
      "rewards/rejected": -12.811223030090332,
      "step": 24830
    },
    {
      "epoch": 4.533260333972078,
      "grad_norm": 2.1805543899536133,
      "learning_rate": 7.540466140576254e-06,
      "logits/chosen": 0.49926719069480896,
      "logits/rejected": 0.863922119140625,
      "logps/chosen": -212.54931640625,
      "logps/rejected": -269.15399169921875,
      "loss": 0.085,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.171820163726807,
      "rewards/margins": 7.056182861328125,
      "rewards/rejected": -14.228004455566406,
      "step": 24840
    },
    {
      "epoch": 4.535085318003468,
      "grad_norm": 0.3740583062171936,
      "learning_rate": 7.511102954670583e-06,
      "logits/chosen": 0.532122015953064,
      "logits/rejected": 1.1219117641448975,
      "logps/chosen": -231.1624298095703,
      "logps/rejected": -265.6017150878906,
      "loss": 0.1053,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.805325508117676,
      "rewards/margins": 6.677672386169434,
      "rewards/rejected": -14.482996940612793,
      "step": 24850
    },
    {
      "epoch": 4.536910302034857,
      "grad_norm": 9.92406177520752,
      "learning_rate": 7.4817397687649115e-06,
      "logits/chosen": 0.2920023500919342,
      "logits/rejected": 0.9357962608337402,
      "logps/chosen": -210.2514190673828,
      "logps/rejected": -260.7231140136719,
      "loss": 0.0411,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.878823757171631,
      "rewards/margins": 7.508486270904541,
      "rewards/rejected": -14.387310981750488,
      "step": 24860
    },
    {
      "epoch": 4.538735286066247,
      "grad_norm": 2.4635674953460693,
      "learning_rate": 7.452376582859241e-06,
      "logits/chosen": 0.23124699294567108,
      "logits/rejected": 0.6307729482650757,
      "logps/chosen": -209.594970703125,
      "logps/rejected": -257.0281677246094,
      "loss": 0.037,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.109278678894043,
      "rewards/margins": 6.822731971740723,
      "rewards/rejected": -13.93200969696045,
      "step": 24870
    },
    {
      "epoch": 4.540560270097637,
      "grad_norm": 5.860374927520752,
      "learning_rate": 7.42301339695357e-06,
      "logits/chosen": 0.3318902254104614,
      "logits/rejected": 0.7185693979263306,
      "logps/chosen": -224.825439453125,
      "logps/rejected": -280.25628662109375,
      "loss": 0.0484,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.460008144378662,
      "rewards/margins": 7.22081995010376,
      "rewards/rejected": -14.680829048156738,
      "step": 24880
    },
    {
      "epoch": 4.542385254129027,
      "grad_norm": 0.48146674036979675,
      "learning_rate": 7.393650211047899e-06,
      "logits/chosen": 0.08637316524982452,
      "logits/rejected": 0.6488732099533081,
      "logps/chosen": -222.6970672607422,
      "logps/rejected": -263.92095947265625,
      "loss": 0.1135,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -7.058624267578125,
      "rewards/margins": 6.339425086975098,
      "rewards/rejected": -13.398046493530273,
      "step": 24890
    },
    {
      "epoch": 4.544210238160416,
      "grad_norm": 0.0949811115860939,
      "learning_rate": 7.3642870251422285e-06,
      "logits/chosen": 0.14110219478607178,
      "logits/rejected": 0.6390504240989685,
      "logps/chosen": -205.41610717773438,
      "logps/rejected": -263.6474914550781,
      "loss": 0.0486,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.534735679626465,
      "rewards/margins": 7.361349582672119,
      "rewards/rejected": -13.896084785461426,
      "step": 24900
    },
    {
      "epoch": 4.546035222191806,
      "grad_norm": 3.688770055770874,
      "learning_rate": 7.334923839236557e-06,
      "logits/chosen": 0.1285526156425476,
      "logits/rejected": 0.814139723777771,
      "logps/chosen": -224.7428741455078,
      "logps/rejected": -279.9610290527344,
      "loss": 0.0302,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.721059322357178,
      "rewards/margins": 7.488292694091797,
      "rewards/rejected": -15.20935344696045,
      "step": 24910
    },
    {
      "epoch": 4.547860206223196,
      "grad_norm": 0.7498382329940796,
      "learning_rate": 7.305560653330886e-06,
      "logits/chosen": 0.28439566493034363,
      "logits/rejected": 0.7550607919692993,
      "logps/chosen": -204.09042358398438,
      "logps/rejected": -258.6090393066406,
      "loss": 0.0323,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.109899997711182,
      "rewards/margins": 6.9291181564331055,
      "rewards/rejected": -14.039019584655762,
      "step": 24920
    },
    {
      "epoch": 4.549685190254586,
      "grad_norm": 0.8934571146965027,
      "learning_rate": 7.276197467425217e-06,
      "logits/chosen": 0.23334114253520966,
      "logits/rejected": 0.8107782602310181,
      "logps/chosen": -224.243896484375,
      "logps/rejected": -276.60455322265625,
      "loss": 0.1097,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.642475128173828,
      "rewards/margins": 6.532121181488037,
      "rewards/rejected": -13.174595832824707,
      "step": 24930
    },
    {
      "epoch": 4.551510174285975,
      "grad_norm": 0.13832074403762817,
      "learning_rate": 7.246834281519545e-06,
      "logits/chosen": 0.13414493203163147,
      "logits/rejected": 0.945044219493866,
      "logps/chosen": -231.0844268798828,
      "logps/rejected": -281.6761779785156,
      "loss": 0.0267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.4706711769104,
      "rewards/margins": 7.401269435882568,
      "rewards/rejected": -14.871942520141602,
      "step": 24940
    },
    {
      "epoch": 4.553335158317365,
      "grad_norm": 8.683043479919434,
      "learning_rate": 7.217471095613875e-06,
      "logits/chosen": 0.32283321022987366,
      "logits/rejected": 0.8937206268310547,
      "logps/chosen": -211.05514526367188,
      "logps/rejected": -261.5199890136719,
      "loss": 0.0727,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.194094181060791,
      "rewards/margins": 7.032723903656006,
      "rewards/rejected": -14.226819038391113,
      "step": 24950
    },
    {
      "epoch": 4.555160142348754,
      "grad_norm": 1.348941445350647,
      "learning_rate": 7.188107909708204e-06,
      "logits/chosen": 0.3278953731060028,
      "logits/rejected": 0.7256993651390076,
      "logps/chosen": -214.30697631835938,
      "logps/rejected": -277.24200439453125,
      "loss": 0.0635,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.709680080413818,
      "rewards/margins": 7.6742072105407715,
      "rewards/rejected": -14.383890151977539,
      "step": 24960
    },
    {
      "epoch": 4.556985126380145,
      "grad_norm": 1.2369393110275269,
      "learning_rate": 7.1587447238025335e-06,
      "logits/chosen": 0.1623559296131134,
      "logits/rejected": 0.55075603723526,
      "logps/chosen": -226.7032012939453,
      "logps/rejected": -277.83587646484375,
      "loss": 0.0397,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.8299407958984375,
      "rewards/margins": 7.015295505523682,
      "rewards/rejected": -14.845234870910645,
      "step": 24970
    },
    {
      "epoch": 4.5588101104115335,
      "grad_norm": 6.127674579620361,
      "learning_rate": 7.129381537896862e-06,
      "logits/chosen": 0.233496755361557,
      "logits/rejected": 0.7512836456298828,
      "logps/chosen": -202.25515747070312,
      "logps/rejected": -253.3534698486328,
      "loss": 0.0564,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.853814601898193,
      "rewards/margins": 6.75165319442749,
      "rewards/rejected": -13.60546875,
      "step": 24980
    },
    {
      "epoch": 4.560635094442923,
      "grad_norm": 0.7367356419563293,
      "learning_rate": 7.100018351991191e-06,
      "logits/chosen": 0.23461565375328064,
      "logits/rejected": 0.8338710069656372,
      "logps/chosen": -223.1107940673828,
      "logps/rejected": -294.73248291015625,
      "loss": 0.08,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.527626991271973,
      "rewards/margins": 8.255632400512695,
      "rewards/rejected": -14.783256530761719,
      "step": 24990
    },
    {
      "epoch": 4.562460078474313,
      "grad_norm": 0.7331973314285278,
      "learning_rate": 7.070655166085521e-06,
      "logits/chosen": 0.2842145264148712,
      "logits/rejected": 0.979026198387146,
      "logps/chosen": -232.8332977294922,
      "logps/rejected": -277.5392150878906,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.46837854385376,
      "rewards/margins": 7.870837211608887,
      "rewards/rejected": -15.339215278625488,
      "step": 25000
    },
    {
      "epoch": 4.564285062505703,
      "grad_norm": 11.759678840637207,
      "learning_rate": 7.04129198017985e-06,
      "logits/chosen": 0.3289421796798706,
      "logits/rejected": 1.0158003568649292,
      "logps/chosen": -231.58267211914062,
      "logps/rejected": -269.834716796875,
      "loss": 0.1172,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.881999969482422,
      "rewards/margins": 6.957286834716797,
      "rewards/rejected": -14.839286804199219,
      "step": 25010
    },
    {
      "epoch": 4.5661100465370925,
      "grad_norm": 29.87346839904785,
      "learning_rate": 7.01192879427418e-06,
      "logits/chosen": 0.42745375633239746,
      "logits/rejected": 0.7042922973632812,
      "logps/chosen": -215.6576690673828,
      "logps/rejected": -280.2491760253906,
      "loss": 0.1088,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.3529953956604,
      "rewards/margins": 6.944943428039551,
      "rewards/rejected": -14.297937393188477,
      "step": 25020
    },
    {
      "epoch": 4.567935030568482,
      "grad_norm": 0.5262238383293152,
      "learning_rate": 6.982565608368509e-06,
      "logits/chosen": 0.46764975786209106,
      "logits/rejected": 0.9775931239128113,
      "logps/chosen": -227.9602813720703,
      "logps/rejected": -283.6607666015625,
      "loss": 0.0385,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.514764308929443,
      "rewards/margins": 7.3209228515625,
      "rewards/rejected": -14.835687637329102,
      "step": 25030
    },
    {
      "epoch": 4.569760014599872,
      "grad_norm": 3.0550968647003174,
      "learning_rate": 6.953202422462838e-06,
      "logits/chosen": 0.09367349743843079,
      "logits/rejected": 0.866010844707489,
      "logps/chosen": -219.73208618164062,
      "logps/rejected": -253.21481323242188,
      "loss": 0.2283,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.5725417137146,
      "rewards/margins": 6.415402889251709,
      "rewards/rejected": -12.987945556640625,
      "step": 25040
    },
    {
      "epoch": 4.571584998631262,
      "grad_norm": 0.17075954377651215,
      "learning_rate": 6.923839236557167e-06,
      "logits/chosen": 0.17216403782367706,
      "logits/rejected": 0.49307259917259216,
      "logps/chosen": -217.43051147460938,
      "logps/rejected": -258.9687194824219,
      "loss": 0.1009,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.253660678863525,
      "rewards/margins": 6.311817646026611,
      "rewards/rejected": -13.565478324890137,
      "step": 25050
    },
    {
      "epoch": 4.5734099826626515,
      "grad_norm": 0.33136680722236633,
      "learning_rate": 6.894476050651496e-06,
      "logits/chosen": 0.13673456013202667,
      "logits/rejected": 0.6866196393966675,
      "logps/chosen": -226.1066131591797,
      "logps/rejected": -268.0133361816406,
      "loss": 0.1082,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.603950500488281,
      "rewards/margins": 6.7287917137146,
      "rewards/rejected": -13.332740783691406,
      "step": 25060
    },
    {
      "epoch": 4.575234966694041,
      "grad_norm": 15.394320487976074,
      "learning_rate": 6.865112864745825e-06,
      "logits/chosen": 0.44953832030296326,
      "logits/rejected": 0.7602208256721497,
      "logps/chosen": -214.96395874023438,
      "logps/rejected": -274.47149658203125,
      "loss": 0.0965,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.303290367126465,
      "rewards/margins": 7.334240913391113,
      "rewards/rejected": -14.637532234191895,
      "step": 25070
    },
    {
      "epoch": 4.577059950725431,
      "grad_norm": 7.898003101348877,
      "learning_rate": 6.835749678840155e-06,
      "logits/chosen": 0.17425835132598877,
      "logits/rejected": 0.8229891061782837,
      "logps/chosen": -220.4845733642578,
      "logps/rejected": -254.16064453125,
      "loss": 0.0335,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.986382484436035,
      "rewards/margins": 7.04901647567749,
      "rewards/rejected": -14.035398483276367,
      "step": 25080
    },
    {
      "epoch": 4.578884934756821,
      "grad_norm": 1.1346237659454346,
      "learning_rate": 6.8063864929344835e-06,
      "logits/chosen": 0.19802585244178772,
      "logits/rejected": 0.6037275195121765,
      "logps/chosen": -223.05941772460938,
      "logps/rejected": -286.1092834472656,
      "loss": 0.0576,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.05359411239624,
      "rewards/margins": 7.302586555480957,
      "rewards/rejected": -14.356180191040039,
      "step": 25090
    },
    {
      "epoch": 4.5807099187882105,
      "grad_norm": 5.530757904052734,
      "learning_rate": 6.777023307028813e-06,
      "logits/chosen": 0.306725412607193,
      "logits/rejected": 0.9923885464668274,
      "logps/chosen": -217.53500366210938,
      "logps/rejected": -250.38754272460938,
      "loss": 0.1069,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.978600978851318,
      "rewards/margins": 6.34538459777832,
      "rewards/rejected": -13.32398509979248,
      "step": 25100
    },
    {
      "epoch": 4.5825349028196,
      "grad_norm": 1.7260171175003052,
      "learning_rate": 6.747660121123143e-06,
      "logits/chosen": 0.1287028044462204,
      "logits/rejected": 0.5611634850502014,
      "logps/chosen": -234.17056274414062,
      "logps/rejected": -278.7076721191406,
      "loss": 0.1033,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.899640083312988,
      "rewards/margins": 6.4571075439453125,
      "rewards/rejected": -13.3567476272583,
      "step": 25110
    },
    {
      "epoch": 4.58435988685099,
      "grad_norm": 2.027658462524414,
      "learning_rate": 6.7182969352174724e-06,
      "logits/chosen": 0.3877241909503937,
      "logits/rejected": 0.7995752692222595,
      "logps/chosen": -222.65438842773438,
      "logps/rejected": -275.91278076171875,
      "loss": 0.0521,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.591538906097412,
      "rewards/margins": 6.826815128326416,
      "rewards/rejected": -14.418353080749512,
      "step": 25120
    },
    {
      "epoch": 4.58618487088238,
      "grad_norm": 3.4218955039978027,
      "learning_rate": 6.688933749311801e-06,
      "logits/chosen": -0.10043277591466904,
      "logits/rejected": 0.4037415087223053,
      "logps/chosen": -217.4994354248047,
      "logps/rejected": -246.42385864257812,
      "loss": 0.043,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.495728492736816,
      "rewards/margins": 6.3202385902404785,
      "rewards/rejected": -12.81596851348877,
      "step": 25130
    },
    {
      "epoch": 4.58800985491377,
      "grad_norm": 0.5004448294639587,
      "learning_rate": 6.65957056340613e-06,
      "logits/chosen": 0.48101529479026794,
      "logits/rejected": 0.9385639429092407,
      "logps/chosen": -206.85177612304688,
      "logps/rejected": -270.472900390625,
      "loss": 0.0633,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.9942193031311035,
      "rewards/margins": 6.946580410003662,
      "rewards/rejected": -14.940800666809082,
      "step": 25140
    },
    {
      "epoch": 4.589834838945159,
      "grad_norm": 0.16887922585010529,
      "learning_rate": 6.63020737750046e-06,
      "logits/chosen": 0.35278254747390747,
      "logits/rejected": 0.8079988360404968,
      "logps/chosen": -211.46884155273438,
      "logps/rejected": -273.054931640625,
      "loss": 0.0327,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.605907440185547,
      "rewards/margins": 7.0826287269592285,
      "rewards/rejected": -14.68853759765625,
      "step": 25150
    },
    {
      "epoch": 4.591659822976549,
      "grad_norm": 2.426943778991699,
      "learning_rate": 6.6008441915947885e-06,
      "logits/chosen": 0.1096263900399208,
      "logits/rejected": 0.6743184328079224,
      "logps/chosen": -250.8074493408203,
      "logps/rejected": -266.23822021484375,
      "loss": 0.1127,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.15880012512207,
      "rewards/margins": 5.845000267028809,
      "rewards/rejected": -14.003801345825195,
      "step": 25160
    },
    {
      "epoch": 4.593484807007939,
      "grad_norm": 1.0419604778289795,
      "learning_rate": 6.571481005689117e-06,
      "logits/chosen": 0.3645722270011902,
      "logits/rejected": 0.8052827715873718,
      "logps/chosen": -232.4606170654297,
      "logps/rejected": -291.47637939453125,
      "loss": 0.0443,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.038276672363281,
      "rewards/margins": 6.810023307800293,
      "rewards/rejected": -14.848299980163574,
      "step": 25170
    },
    {
      "epoch": 4.595309791039329,
      "grad_norm": 1.0900768041610718,
      "learning_rate": 6.542117819783447e-06,
      "logits/chosen": 0.28790193796157837,
      "logits/rejected": 0.5958636403083801,
      "logps/chosen": -231.04666137695312,
      "logps/rejected": -304.0787658691406,
      "loss": 0.0215,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.855641841888428,
      "rewards/margins": 7.109653472900391,
      "rewards/rejected": -14.965295791625977,
      "step": 25180
    },
    {
      "epoch": 4.597134775070718,
      "grad_norm": 0.05686735361814499,
      "learning_rate": 6.512754633877776e-06,
      "logits/chosen": 0.11734839528799057,
      "logits/rejected": 1.0063984394073486,
      "logps/chosen": -245.75537109375,
      "logps/rejected": -266.06304931640625,
      "loss": 0.3096,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.9505157470703125,
      "rewards/margins": 6.715553283691406,
      "rewards/rejected": -14.666067123413086,
      "step": 25190
    },
    {
      "epoch": 4.598959759102108,
      "grad_norm": 4.790222644805908,
      "learning_rate": 6.483391447972105e-06,
      "logits/chosen": 0.3733082413673401,
      "logits/rejected": 1.0010732412338257,
      "logps/chosen": -261.66583251953125,
      "logps/rejected": -281.30279541015625,
      "loss": 0.0289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -8.290159225463867,
      "rewards/margins": 6.330506324768066,
      "rewards/rejected": -14.62066650390625,
      "step": 25200
    },
    {
      "epoch": 4.600784743133498,
      "grad_norm": 10.526779174804688,
      "learning_rate": 6.454028262066435e-06,
      "logits/chosen": 0.3675178289413452,
      "logits/rejected": 0.8935595750808716,
      "logps/chosen": -228.2633819580078,
      "logps/rejected": -278.2083435058594,
      "loss": 0.0684,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.786122798919678,
      "rewards/margins": 6.544151306152344,
      "rewards/rejected": -14.33027458190918,
      "step": 25210
    },
    {
      "epoch": 4.602609727164888,
      "grad_norm": 7.939446449279785,
      "learning_rate": 6.424665076160764e-06,
      "logits/chosen": 0.41319674253463745,
      "logits/rejected": 1.1783404350280762,
      "logps/chosen": -240.13973999023438,
      "logps/rejected": -278.7249450683594,
      "loss": 0.0345,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.303448677062988,
      "rewards/margins": 7.1464362144470215,
      "rewards/rejected": -15.449885368347168,
      "step": 25220
    },
    {
      "epoch": 4.604434711196277,
      "grad_norm": 5.540956020355225,
      "learning_rate": 6.3953018902550936e-06,
      "logits/chosen": 0.5830398201942444,
      "logits/rejected": 0.8334306478500366,
      "logps/chosen": -220.3427276611328,
      "logps/rejected": -287.21612548828125,
      "loss": 0.0892,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.094549179077148,
      "rewards/margins": 6.790219783782959,
      "rewards/rejected": -14.884770393371582,
      "step": 25230
    },
    {
      "epoch": 4.606259695227667,
      "grad_norm": 1.6806889772415161,
      "learning_rate": 6.365938704349422e-06,
      "logits/chosen": 0.3209943175315857,
      "logits/rejected": 0.8126780390739441,
      "logps/chosen": -238.86972045898438,
      "logps/rejected": -290.2339172363281,
      "loss": 0.1107,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.407319068908691,
      "rewards/margins": 6.391834259033203,
      "rewards/rejected": -14.799154281616211,
      "step": 25240
    },
    {
      "epoch": 4.608084679259057,
      "grad_norm": 2.361501932144165,
      "learning_rate": 6.336575518443752e-06,
      "logits/chosen": 0.5284474492073059,
      "logits/rejected": 0.7697324752807617,
      "logps/chosen": -219.56838989257812,
      "logps/rejected": -272.41180419921875,
      "loss": 0.0774,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.640249729156494,
      "rewards/margins": 6.319570064544678,
      "rewards/rejected": -13.959820747375488,
      "step": 25250
    },
    {
      "epoch": 4.609909663290447,
      "grad_norm": 3.542478084564209,
      "learning_rate": 6.307212332538081e-06,
      "logits/chosen": 0.2706778943538666,
      "logits/rejected": 0.7685486674308777,
      "logps/chosen": -217.0823211669922,
      "logps/rejected": -272.63531494140625,
      "loss": 0.027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.956402778625488,
      "rewards/margins": 7.329490661621094,
      "rewards/rejected": -14.28589153289795,
      "step": 25260
    },
    {
      "epoch": 4.6117346473218355,
      "grad_norm": 0.3266901671886444,
      "learning_rate": 6.27784914663241e-06,
      "logits/chosen": 0.31278276443481445,
      "logits/rejected": 0.9988771677017212,
      "logps/chosen": -212.77792358398438,
      "logps/rejected": -249.86587524414062,
      "loss": 0.0696,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.309123992919922,
      "rewards/margins": 7.003231048583984,
      "rewards/rejected": -14.312355041503906,
      "step": 25270
    },
    {
      "epoch": 4.613559631353226,
      "grad_norm": 3.16650652885437,
      "learning_rate": 6.248485960726739e-06,
      "logits/chosen": 0.11852691322565079,
      "logits/rejected": 0.6480892896652222,
      "logps/chosen": -226.9600067138672,
      "logps/rejected": -257.298583984375,
      "loss": 0.0996,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.6269097328186035,
      "rewards/margins": 6.133528709411621,
      "rewards/rejected": -12.760438919067383,
      "step": 25280
    },
    {
      "epoch": 4.615384615384615,
      "grad_norm": 3.521012306213379,
      "learning_rate": 6.219122774821068e-06,
      "logits/chosen": 0.27747881412506104,
      "logits/rejected": 0.873092770576477,
      "logps/chosen": -223.32327270507812,
      "logps/rejected": -276.1021423339844,
      "loss": 0.046,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.50693416595459,
      "rewards/margins": 7.005374908447266,
      "rewards/rejected": -14.512309074401855,
      "step": 25290
    },
    {
      "epoch": 4.617209599416005,
      "grad_norm": 0.010819408111274242,
      "learning_rate": 6.189759588915399e-06,
      "logits/chosen": 0.5327028036117554,
      "logits/rejected": 0.96307373046875,
      "logps/chosen": -203.88162231445312,
      "logps/rejected": -279.6600341796875,
      "loss": 0.0606,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.007674217224121,
      "rewards/margins": 7.837937831878662,
      "rewards/rejected": -14.845611572265625,
      "step": 25300
    },
    {
      "epoch": 4.6190345834473945,
      "grad_norm": 3.280386209487915,
      "learning_rate": 6.1603964030097274e-06,
      "logits/chosen": 0.3964875042438507,
      "logits/rejected": 0.7971879839897156,
      "logps/chosen": -222.2478485107422,
      "logps/rejected": -279.1436767578125,
      "loss": 0.0755,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -8.227875709533691,
      "rewards/margins": 6.957087516784668,
      "rewards/rejected": -15.184964179992676,
      "step": 25310
    },
    {
      "epoch": 4.620859567478784,
      "grad_norm": 9.804272651672363,
      "learning_rate": 6.131033217104056e-06,
      "logits/chosen": 0.31503066420555115,
      "logits/rejected": 0.9476496577262878,
      "logps/chosen": -226.63671875,
      "logps/rejected": -261.39019775390625,
      "loss": 0.0563,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.69043493270874,
      "rewards/margins": 6.492297172546387,
      "rewards/rejected": -14.182731628417969,
      "step": 25320
    },
    {
      "epoch": 4.622684551510174,
      "grad_norm": 8.510164260864258,
      "learning_rate": 6.101670031198386e-06,
      "logits/chosen": 0.2241857498884201,
      "logits/rejected": 0.8040658831596375,
      "logps/chosen": -227.78762817382812,
      "logps/rejected": -268.37274169921875,
      "loss": 0.0734,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.593447208404541,
      "rewards/margins": 6.534773826599121,
      "rewards/rejected": -14.12822151184082,
      "step": 25330
    },
    {
      "epoch": 4.624509535541564,
      "grad_norm": 1.0426934957504272,
      "learning_rate": 6.072306845292715e-06,
      "logits/chosen": 0.08266285806894302,
      "logits/rejected": 0.6500716209411621,
      "logps/chosen": -215.2845001220703,
      "logps/rejected": -244.5500946044922,
      "loss": 0.0855,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.1292266845703125,
      "rewards/margins": 6.054247856140137,
      "rewards/rejected": -13.183473587036133,
      "step": 25340
    },
    {
      "epoch": 4.6263345195729535,
      "grad_norm": 3.4708306789398193,
      "learning_rate": 6.0429436593870435e-06,
      "logits/chosen": -0.0043859779834747314,
      "logits/rejected": 0.4959006905555725,
      "logps/chosen": -211.3656768798828,
      "logps/rejected": -269.8340148925781,
      "loss": 0.0461,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.29082727432251,
      "rewards/margins": 6.462104797363281,
      "rewards/rejected": -12.75293254852295,
      "step": 25350
    },
    {
      "epoch": 4.628159503604343,
      "grad_norm": 7.425980091094971,
      "learning_rate": 6.013580473481373e-06,
      "logits/chosen": 0.14340302348136902,
      "logits/rejected": 0.32303035259246826,
      "logps/chosen": -204.67465209960938,
      "logps/rejected": -272.71209716796875,
      "loss": 0.1366,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.646764278411865,
      "rewards/margins": 6.404372215270996,
      "rewards/rejected": -13.051135063171387,
      "step": 25360
    },
    {
      "epoch": 4.629984487635733,
      "grad_norm": 7.8485870361328125,
      "learning_rate": 5.984217287575702e-06,
      "logits/chosen": 0.20795956254005432,
      "logits/rejected": 0.6941884756088257,
      "logps/chosen": -220.0161590576172,
      "logps/rejected": -259.53997802734375,
      "loss": 0.0699,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.7729082107543945,
      "rewards/margins": 6.3279314041137695,
      "rewards/rejected": -13.100837707519531,
      "step": 25370
    },
    {
      "epoch": 4.631809471667123,
      "grad_norm": 12.109820365905762,
      "learning_rate": 5.954854101670031e-06,
      "logits/chosen": 0.09702404588460922,
      "logits/rejected": 0.7512017488479614,
      "logps/chosen": -199.2809600830078,
      "logps/rejected": -237.17398071289062,
      "loss": 0.0628,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.256037712097168,
      "rewards/margins": 7.056876182556152,
      "rewards/rejected": -13.31291389465332,
      "step": 25380
    },
    {
      "epoch": 4.6336344556985125,
      "grad_norm": 1.0591716766357422,
      "learning_rate": 5.925490915764361e-06,
      "logits/chosen": 0.10722961276769638,
      "logits/rejected": 0.8912729024887085,
      "logps/chosen": -234.67520141601562,
      "logps/rejected": -256.38226318359375,
      "loss": 0.0252,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.282993316650391,
      "rewards/margins": 6.724828243255615,
      "rewards/rejected": -14.007822036743164,
      "step": 25390
    },
    {
      "epoch": 4.635459439729902,
      "grad_norm": 1.3288143873214722,
      "learning_rate": 5.896127729858691e-06,
      "logits/chosen": 0.11383267492055893,
      "logits/rejected": 0.6550015807151794,
      "logps/chosen": -213.2135772705078,
      "logps/rejected": -248.177490234375,
      "loss": 0.0432,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.818412780761719,
      "rewards/margins": 7.219292640686035,
      "rewards/rejected": -14.037704467773438,
      "step": 25400
    },
    {
      "epoch": 4.637284423761292,
      "grad_norm": 17.43887710571289,
      "learning_rate": 5.86676454395302e-06,
      "logits/chosen": 0.10618381202220917,
      "logits/rejected": 0.5680475234985352,
      "logps/chosen": -219.94326782226562,
      "logps/rejected": -260.23236083984375,
      "loss": 0.0525,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.852458953857422,
      "rewards/margins": 6.4095048904418945,
      "rewards/rejected": -13.261962890625,
      "step": 25410
    },
    {
      "epoch": 4.639109407792682,
      "grad_norm": 3.8162355422973633,
      "learning_rate": 5.8374013580473486e-06,
      "logits/chosen": -0.08598903566598892,
      "logits/rejected": 0.5541332364082336,
      "logps/chosen": -212.01138305664062,
      "logps/rejected": -262.51226806640625,
      "loss": 0.0283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.894252300262451,
      "rewards/margins": 7.737174034118652,
      "rewards/rejected": -13.631425857543945,
      "step": 25420
    },
    {
      "epoch": 4.6409343918240715,
      "grad_norm": 1.8786965608596802,
      "learning_rate": 5.808038172141678e-06,
      "logits/chosen": 0.3375733494758606,
      "logits/rejected": 0.7247357368469238,
      "logps/chosen": -211.5522003173828,
      "logps/rejected": -266.92340087890625,
      "loss": 0.0471,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.5438995361328125,
      "rewards/margins": 6.4913740158081055,
      "rewards/rejected": -14.035273551940918,
      "step": 25430
    },
    {
      "epoch": 4.642759375855461,
      "grad_norm": 0.8179194331169128,
      "learning_rate": 5.778674986236007e-06,
      "logits/chosen": 0.2917778789997101,
      "logits/rejected": 0.7276871800422668,
      "logps/chosen": -202.98699951171875,
      "logps/rejected": -255.6256103515625,
      "loss": 0.1028,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.562061309814453,
      "rewards/margins": 7.1880998611450195,
      "rewards/rejected": -13.750162124633789,
      "step": 25440
    },
    {
      "epoch": 4.644584359886851,
      "grad_norm": 5.062235355377197,
      "learning_rate": 5.749311800330336e-06,
      "logits/chosen": 0.34761789441108704,
      "logits/rejected": 0.94819575548172,
      "logps/chosen": -224.3503875732422,
      "logps/rejected": -268.2629699707031,
      "loss": 0.0355,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.405237674713135,
      "rewards/margins": 7.053553104400635,
      "rewards/rejected": -14.45879077911377,
      "step": 25450
    },
    {
      "epoch": 4.646409343918241,
      "grad_norm": 24.047714233398438,
      "learning_rate": 5.7199486144246655e-06,
      "logits/chosen": 0.21609477698802948,
      "logits/rejected": 0.49901682138442993,
      "logps/chosen": -216.69778442382812,
      "logps/rejected": -276.0884704589844,
      "loss": 0.0676,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.296163082122803,
      "rewards/margins": 6.220059871673584,
      "rewards/rejected": -13.51622200012207,
      "step": 25460
    },
    {
      "epoch": 4.6482343279496305,
      "grad_norm": 1.5171924829483032,
      "learning_rate": 5.690585428518994e-06,
      "logits/chosen": 0.07296623289585114,
      "logits/rejected": 0.6112819910049438,
      "logps/chosen": -216.4551239013672,
      "logps/rejected": -269.81378173828125,
      "loss": 0.0427,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.142424583435059,
      "rewards/margins": 7.483809471130371,
      "rewards/rejected": -14.62623405456543,
      "step": 25470
    },
    {
      "epoch": 4.65005931198102,
      "grad_norm": 5.156877517700195,
      "learning_rate": 5.661222242613325e-06,
      "logits/chosen": 0.14771905541419983,
      "logits/rejected": 0.7057014107704163,
      "logps/chosen": -234.36898803710938,
      "logps/rejected": -265.2270812988281,
      "loss": 0.0448,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.984394073486328,
      "rewards/margins": 6.591300010681152,
      "rewards/rejected": -13.575693130493164,
      "step": 25480
    },
    {
      "epoch": 4.65188429601241,
      "grad_norm": 2.631300210952759,
      "learning_rate": 5.631859056707654e-06,
      "logits/chosen": 0.21816596388816833,
      "logits/rejected": 0.8170837163925171,
      "logps/chosen": -221.0769500732422,
      "logps/rejected": -255.38235473632812,
      "loss": 0.1166,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.086958885192871,
      "rewards/margins": 6.629103660583496,
      "rewards/rejected": -13.716062545776367,
      "step": 25490
    },
    {
      "epoch": 4.6537092800438,
      "grad_norm": 2.022453784942627,
      "learning_rate": 5.6024958708019824e-06,
      "logits/chosen": 0.07153927534818649,
      "logits/rejected": 0.6067787408828735,
      "logps/chosen": -221.1771240234375,
      "logps/rejected": -274.88232421875,
      "loss": 0.0386,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.4253387451171875,
      "rewards/margins": 7.01278018951416,
      "rewards/rejected": -14.438116073608398,
      "step": 25500
    },
    {
      "epoch": 4.6555342640751896,
      "grad_norm": 1.3619000911712646,
      "learning_rate": 5.573132684896312e-06,
      "logits/chosen": -0.006490617990493774,
      "logits/rejected": 0.568700909614563,
      "logps/chosen": -217.94656372070312,
      "logps/rejected": -258.9309997558594,
      "loss": 0.0255,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.216038703918457,
      "rewards/margins": 7.087827205657959,
      "rewards/rejected": -14.303865432739258,
      "step": 25510
    },
    {
      "epoch": 4.657359248106579,
      "grad_norm": 29.285993576049805,
      "learning_rate": 5.543769498990641e-06,
      "logits/chosen": -0.04100017994642258,
      "logits/rejected": 0.29771438241004944,
      "logps/chosen": -217.13510131835938,
      "logps/rejected": -261.4190368652344,
      "loss": 0.1453,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.463167667388916,
      "rewards/margins": 5.858270645141602,
      "rewards/rejected": -13.321436882019043,
      "step": 25520
    },
    {
      "epoch": 4.659184232137969,
      "grad_norm": 2.2122976779937744,
      "learning_rate": 5.51440631308497e-06,
      "logits/chosen": 0.1456126868724823,
      "logits/rejected": 0.6947351098060608,
      "logps/chosen": -209.45266723632812,
      "logps/rejected": -255.1506805419922,
      "loss": 0.0346,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.9276580810546875,
      "rewards/margins": 7.260897159576416,
      "rewards/rejected": -14.188554763793945,
      "step": 25530
    },
    {
      "epoch": 4.661009216169359,
      "grad_norm": 0.8161842823028564,
      "learning_rate": 5.485043127179299e-06,
      "logits/chosen": 0.34114640951156616,
      "logits/rejected": 0.9237734079360962,
      "logps/chosen": -217.36001586914062,
      "logps/rejected": -272.8697814941406,
      "loss": 0.0729,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.633752346038818,
      "rewards/margins": 7.303206443786621,
      "rewards/rejected": -14.936960220336914,
      "step": 25540
    },
    {
      "epoch": 4.662834200200749,
      "grad_norm": 6.219342231750488,
      "learning_rate": 5.455679941273628e-06,
      "logits/chosen": 0.1234661117196083,
      "logits/rejected": 0.5476012825965881,
      "logps/chosen": -222.3283233642578,
      "logps/rejected": -268.2471923828125,
      "loss": 0.0766,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.886397361755371,
      "rewards/margins": 6.922112464904785,
      "rewards/rejected": -13.808509826660156,
      "step": 25550
    },
    {
      "epoch": 4.664659184232138,
      "grad_norm": 4.698328971862793,
      "learning_rate": 5.426316755367958e-06,
      "logits/chosen": 0.024058517068624496,
      "logits/rejected": 0.4442305564880371,
      "logps/chosen": -212.902099609375,
      "logps/rejected": -270.2081298828125,
      "loss": 0.0521,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.096473693847656,
      "rewards/margins": 7.072129726409912,
      "rewards/rejected": -13.168603897094727,
      "step": 25560
    },
    {
      "epoch": 4.666484168263528,
      "grad_norm": 4.662186145782471,
      "learning_rate": 5.396953569462287e-06,
      "logits/chosen": 0.29415661096572876,
      "logits/rejected": 0.8073256611824036,
      "logps/chosen": -211.9039306640625,
      "logps/rejected": -265.3208312988281,
      "loss": 0.0518,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.331090450286865,
      "rewards/margins": 7.25411319732666,
      "rewards/rejected": -14.585205078125,
      "step": 25570
    },
    {
      "epoch": 4.668309152294917,
      "grad_norm": 2.8410446643829346,
      "learning_rate": 5.367590383556617e-06,
      "logits/chosen": 0.05380870774388313,
      "logits/rejected": 0.938351035118103,
      "logps/chosen": -235.8828125,
      "logps/rejected": -247.9134521484375,
      "loss": 0.0243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.649203300476074,
      "rewards/margins": 6.975546360015869,
      "rewards/rejected": -13.624750137329102,
      "step": 25580
    },
    {
      "epoch": 4.670134136326308,
      "grad_norm": 2.465074300765991,
      "learning_rate": 5.338227197650946e-06,
      "logits/chosen": 0.3093782365322113,
      "logits/rejected": 0.7365041971206665,
      "logps/chosen": -203.30227661132812,
      "logps/rejected": -286.22113037109375,
      "loss": 0.0351,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.810849666595459,
      "rewards/margins": 7.182135581970215,
      "rewards/rejected": -13.9929838180542,
      "step": 25590
    },
    {
      "epoch": 4.6719591203576964,
      "grad_norm": 3.7373580932617188,
      "learning_rate": 5.308864011745275e-06,
      "logits/chosen": 0.11815031617879868,
      "logits/rejected": 0.6681437492370605,
      "logps/chosen": -207.0532684326172,
      "logps/rejected": -248.139892578125,
      "loss": 0.0327,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.708420753479004,
      "rewards/margins": 6.579503536224365,
      "rewards/rejected": -12.287924766540527,
      "step": 25600
    },
    {
      "epoch": 4.673784104389087,
      "grad_norm": 0.3476364016532898,
      "learning_rate": 5.279500825839604e-06,
      "logits/chosen": 0.33563095331192017,
      "logits/rejected": 0.9267263412475586,
      "logps/chosen": -214.5170440673828,
      "logps/rejected": -286.61505126953125,
      "loss": 0.0391,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.214646816253662,
      "rewards/margins": 8.774187088012695,
      "rewards/rejected": -15.9888334274292,
      "step": 25610
    },
    {
      "epoch": 4.675609088420476,
      "grad_norm": 0.38732877373695374,
      "learning_rate": 5.250137639933933e-06,
      "logits/chosen": 0.15606233477592468,
      "logits/rejected": 0.7585873603820801,
      "logps/chosen": -211.7080841064453,
      "logps/rejected": -256.9640808105469,
      "loss": 0.0812,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.246607780456543,
      "rewards/margins": 7.223086357116699,
      "rewards/rejected": -13.469693183898926,
      "step": 25620
    },
    {
      "epoch": 4.677434072451866,
      "grad_norm": 0.5250146985054016,
      "learning_rate": 5.220774454028262e-06,
      "logits/chosen": 0.12127381563186646,
      "logits/rejected": 0.6476045250892639,
      "logps/chosen": -216.5109405517578,
      "logps/rejected": -258.12322998046875,
      "loss": 0.0887,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.893324851989746,
      "rewards/margins": 6.817955017089844,
      "rewards/rejected": -12.711278915405273,
      "step": 25630
    },
    {
      "epoch": 4.6792590564832555,
      "grad_norm": 1.6920193433761597,
      "learning_rate": 5.191411268122592e-06,
      "logits/chosen": 0.23244258761405945,
      "logits/rejected": 0.6216150522232056,
      "logps/chosen": -221.46630859375,
      "logps/rejected": -263.00701904296875,
      "loss": 0.0546,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.671536445617676,
      "rewards/margins": 6.159279823303223,
      "rewards/rejected": -13.830816268920898,
      "step": 25640
    },
    {
      "epoch": 4.681084040514645,
      "grad_norm": 0.4292055368423462,
      "learning_rate": 5.1620480822169205e-06,
      "logits/chosen": 0.31722986698150635,
      "logits/rejected": 0.8979962468147278,
      "logps/chosen": -219.45596313476562,
      "logps/rejected": -250.04574584960938,
      "loss": 0.1764,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.8296637535095215,
      "rewards/margins": 6.818894863128662,
      "rewards/rejected": -13.6485595703125,
      "step": 25650
    },
    {
      "epoch": 4.682909024546035,
      "grad_norm": 3.587195873260498,
      "learning_rate": 5.132684896311249e-06,
      "logits/chosen": 0.03002479113638401,
      "logits/rejected": 0.6795055866241455,
      "logps/chosen": -216.98104858398438,
      "logps/rejected": -247.3147430419922,
      "loss": 0.0421,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.945262908935547,
      "rewards/margins": 6.869039058685303,
      "rewards/rejected": -12.814302444458008,
      "step": 25660
    },
    {
      "epoch": 4.684734008577425,
      "grad_norm": 3.4653031826019287,
      "learning_rate": 5.10332171040558e-06,
      "logits/chosen": 0.040301717817783356,
      "logits/rejected": 0.5504844784736633,
      "logps/chosen": -187.6011199951172,
      "logps/rejected": -245.67236328125,
      "loss": 0.034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.680271148681641,
      "rewards/margins": 7.674337863922119,
      "rewards/rejected": -13.354608535766602,
      "step": 25670
    },
    {
      "epoch": 4.6865589926088145,
      "grad_norm": 7.538607597351074,
      "learning_rate": 5.073958524499909e-06,
      "logits/chosen": 0.1410590410232544,
      "logits/rejected": 0.9393604397773743,
      "logps/chosen": -215.011962890625,
      "logps/rejected": -251.63720703125,
      "loss": 0.0525,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.273446559906006,
      "rewards/margins": 7.000715732574463,
      "rewards/rejected": -13.274164199829102,
      "step": 25680
    },
    {
      "epoch": 4.688383976640204,
      "grad_norm": 0.4145079255104065,
      "learning_rate": 5.044595338594238e-06,
      "logits/chosen": -0.06383704394102097,
      "logits/rejected": 0.6099827289581299,
      "logps/chosen": -201.07040405273438,
      "logps/rejected": -260.537841796875,
      "loss": 0.0307,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.5874481201171875,
      "rewards/margins": 7.410580635070801,
      "rewards/rejected": -12.998028755187988,
      "step": 25690
    },
    {
      "epoch": 4.690208960671594,
      "grad_norm": 3.435295343399048,
      "learning_rate": 5.015232152688567e-06,
      "logits/chosen": 0.2711283564567566,
      "logits/rejected": 0.7118484973907471,
      "logps/chosen": -205.6837921142578,
      "logps/rejected": -242.65829467773438,
      "loss": 0.1037,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.714507102966309,
      "rewards/margins": 6.4368085861206055,
      "rewards/rejected": -13.151315689086914,
      "step": 25700
    },
    {
      "epoch": 4.692033944702984,
      "grad_norm": 25.775409698486328,
      "learning_rate": 4.985868966782897e-06,
      "logits/chosen": 0.015517485328018665,
      "logits/rejected": 0.5944110155105591,
      "logps/chosen": -221.0327606201172,
      "logps/rejected": -266.01446533203125,
      "loss": 0.1033,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.868243217468262,
      "rewards/margins": 6.949937343597412,
      "rewards/rejected": -13.818181037902832,
      "step": 25710
    },
    {
      "epoch": 4.6938589287343735,
      "grad_norm": 1.3393980264663696,
      "learning_rate": 4.9565057808772255e-06,
      "logits/chosen": -0.05155918002128601,
      "logits/rejected": 0.3704076409339905,
      "logps/chosen": -202.27279663085938,
      "logps/rejected": -279.3082275390625,
      "loss": 0.0608,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.005332946777344,
      "rewards/margins": 7.21252965927124,
      "rewards/rejected": -13.217863082885742,
      "step": 25720
    },
    {
      "epoch": 4.695683912765763,
      "grad_norm": 22.88212776184082,
      "learning_rate": 4.927142594971554e-06,
      "logits/chosen": 0.0847722664475441,
      "logits/rejected": 0.7055157423019409,
      "logps/chosen": -218.58615112304688,
      "logps/rejected": -260.251708984375,
      "loss": 0.0926,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.894820213317871,
      "rewards/margins": 7.407352447509766,
      "rewards/rejected": -14.30217456817627,
      "step": 25730
    },
    {
      "epoch": 4.697508896797153,
      "grad_norm": 1.6579097509384155,
      "learning_rate": 4.897779409065884e-06,
      "logits/chosen": 0.26677247881889343,
      "logits/rejected": 0.5420891046524048,
      "logps/chosen": -230.7293701171875,
      "logps/rejected": -283.5493469238281,
      "loss": 0.0189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.531089782714844,
      "rewards/margins": 7.0377302169799805,
      "rewards/rejected": -14.568819046020508,
      "step": 25740
    },
    {
      "epoch": 4.699333880828543,
      "grad_norm": 4.350656509399414,
      "learning_rate": 4.868416223160214e-06,
      "logits/chosen": 0.08203047513961792,
      "logits/rejected": 0.5826994776725769,
      "logps/chosen": -197.1964874267578,
      "logps/rejected": -252.1580352783203,
      "loss": 0.0376,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.082528114318848,
      "rewards/margins": 7.011137962341309,
      "rewards/rejected": -13.093666076660156,
      "step": 25750
    },
    {
      "epoch": 4.7011588648599325,
      "grad_norm": 9.559402465820312,
      "learning_rate": 4.8390530372545425e-06,
      "logits/chosen": 0.04866392910480499,
      "logits/rejected": 0.612824022769928,
      "logps/chosen": -224.09506225585938,
      "logps/rejected": -283.2300109863281,
      "loss": 0.0164,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.039887428283691,
      "rewards/margins": 7.525712013244629,
      "rewards/rejected": -14.565600395202637,
      "step": 25760
    },
    {
      "epoch": 4.702983848891322,
      "grad_norm": 2.1926450729370117,
      "learning_rate": 4.809689851348871e-06,
      "logits/chosen": 0.40434831380844116,
      "logits/rejected": 1.1665096282958984,
      "logps/chosen": -243.06661987304688,
      "logps/rejected": -276.571533203125,
      "loss": 0.0779,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.986241340637207,
      "rewards/margins": 6.72451114654541,
      "rewards/rejected": -14.710752487182617,
      "step": 25770
    },
    {
      "epoch": 4.704808832922712,
      "grad_norm": 17.465436935424805,
      "learning_rate": 4.780326665443201e-06,
      "logits/chosen": 0.09748490899801254,
      "logits/rejected": 0.7348607778549194,
      "logps/chosen": -209.5426025390625,
      "logps/rejected": -255.5619659423828,
      "loss": 0.1287,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.244134426116943,
      "rewards/margins": 6.986481666564941,
      "rewards/rejected": -14.230615615844727,
      "step": 25780
    },
    {
      "epoch": 4.706633816954102,
      "grad_norm": 4.765895366668701,
      "learning_rate": 4.750963479537531e-06,
      "logits/chosen": 0.3577965497970581,
      "logits/rejected": 0.6809513568878174,
      "logps/chosen": -209.5409698486328,
      "logps/rejected": -251.7996368408203,
      "loss": 0.1869,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.0435333251953125,
      "rewards/margins": 5.770473003387451,
      "rewards/rejected": -12.814005851745605,
      "step": 25790
    },
    {
      "epoch": 4.7084588009854915,
      "grad_norm": 3.0588457584381104,
      "learning_rate": 4.721600293631859e-06,
      "logits/chosen": 0.08317331969738007,
      "logits/rejected": 0.4676501750946045,
      "logps/chosen": -223.7971954345703,
      "logps/rejected": -283.69940185546875,
      "loss": 0.0447,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.6372199058532715,
      "rewards/margins": 7.487796783447266,
      "rewards/rejected": -14.125017166137695,
      "step": 25800
    },
    {
      "epoch": 4.710283785016881,
      "grad_norm": 1.7485517263412476,
      "learning_rate": 4.692237107726188e-06,
      "logits/chosen": 0.15967929363250732,
      "logits/rejected": 0.5872737765312195,
      "logps/chosen": -209.49539184570312,
      "logps/rejected": -257.1762390136719,
      "loss": 0.1073,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.930885314941406,
      "rewards/margins": 6.431313991546631,
      "rewards/rejected": -13.362199783325195,
      "step": 25810
    },
    {
      "epoch": 4.712108769048271,
      "grad_norm": 0.7149290442466736,
      "learning_rate": 4.662873921820518e-06,
      "logits/chosen": 0.043777208775281906,
      "logits/rejected": 0.46486061811447144,
      "logps/chosen": -224.03756713867188,
      "logps/rejected": -282.56610107421875,
      "loss": 0.0479,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.564919471740723,
      "rewards/margins": 7.241904258728027,
      "rewards/rejected": -13.80682373046875,
      "step": 25820
    },
    {
      "epoch": 4.713933753079661,
      "grad_norm": 2.3962018489837646,
      "learning_rate": 4.6335107359148475e-06,
      "logits/chosen": 0.41231995820999146,
      "logits/rejected": 0.7738419771194458,
      "logps/chosen": -211.5455322265625,
      "logps/rejected": -296.4226989746094,
      "loss": 0.0563,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.755810737609863,
      "rewards/margins": 7.447855472564697,
      "rewards/rejected": -15.203666687011719,
      "step": 25830
    },
    {
      "epoch": 4.7157587371110505,
      "grad_norm": 5.269349098205566,
      "learning_rate": 4.604147550009176e-06,
      "logits/chosen": 0.11835677921772003,
      "logits/rejected": 0.9419074058532715,
      "logps/chosen": -236.5934295654297,
      "logps/rejected": -256.53021240234375,
      "loss": 0.0543,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.8749680519104,
      "rewards/margins": 7.411065578460693,
      "rewards/rejected": -14.286035537719727,
      "step": 25840
    },
    {
      "epoch": 4.71758372114244,
      "grad_norm": 0.4202830195426941,
      "learning_rate": 4.574784364103506e-06,
      "logits/chosen": -0.11541640758514404,
      "logits/rejected": 0.5229372382164001,
      "logps/chosen": -208.40103149414062,
      "logps/rejected": -252.91531372070312,
      "loss": 0.0767,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.638359069824219,
      "rewards/margins": 7.051832675933838,
      "rewards/rejected": -12.690191268920898,
      "step": 25850
    },
    {
      "epoch": 4.71940870517383,
      "grad_norm": 5.006936550140381,
      "learning_rate": 4.545421178197835e-06,
      "logits/chosen": 0.06226865202188492,
      "logits/rejected": 0.42871007323265076,
      "logps/chosen": -221.7041473388672,
      "logps/rejected": -275.82952880859375,
      "loss": 0.07,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.405653476715088,
      "rewards/margins": 7.205418586730957,
      "rewards/rejected": -13.611071586608887,
      "step": 25860
    },
    {
      "epoch": 4.72123368920522,
      "grad_norm": 2.3457138538360596,
      "learning_rate": 4.516057992292164e-06,
      "logits/chosen": 0.043147653341293335,
      "logits/rejected": 0.6789716482162476,
      "logps/chosen": -230.37002563476562,
      "logps/rejected": -261.7311096191406,
      "loss": 0.0562,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.768773078918457,
      "rewards/margins": 6.470986843109131,
      "rewards/rejected": -13.23975944519043,
      "step": 25870
    },
    {
      "epoch": 4.7230586732366096,
      "grad_norm": 2.79591965675354,
      "learning_rate": 4.486694806386493e-06,
      "logits/chosen": 0.21639187633991241,
      "logits/rejected": 0.689930260181427,
      "logps/chosen": -210.33837890625,
      "logps/rejected": -275.5401916503906,
      "loss": 0.023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.143962860107422,
      "rewards/margins": 7.616024017333984,
      "rewards/rejected": -13.759986877441406,
      "step": 25880
    },
    {
      "epoch": 4.724883657267998,
      "grad_norm": 2.8679943084716797,
      "learning_rate": 4.457331620480823e-06,
      "logits/chosen": 0.12978264689445496,
      "logits/rejected": 0.5968801975250244,
      "logps/chosen": -216.7920379638672,
      "logps/rejected": -268.37591552734375,
      "loss": 0.0599,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.708858489990234,
      "rewards/margins": 7.128672122955322,
      "rewards/rejected": -13.837530136108398,
      "step": 25890
    },
    {
      "epoch": 4.726708641299389,
      "grad_norm": 2.181696891784668,
      "learning_rate": 4.427968434575152e-06,
      "logits/chosen": -0.026704858988523483,
      "logits/rejected": 0.6561890244483948,
      "logps/chosen": -235.0656280517578,
      "logps/rejected": -268.7101745605469,
      "loss": 0.0493,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.828761100769043,
      "rewards/margins": 7.414979457855225,
      "rewards/rejected": -14.243741035461426,
      "step": 25900
    },
    {
      "epoch": 4.728533625330778,
      "grad_norm": 2.71635103225708,
      "learning_rate": 4.3986052486694805e-06,
      "logits/chosen": 0.026869986206293106,
      "logits/rejected": 0.7051185369491577,
      "logps/chosen": -207.3323211669922,
      "logps/rejected": -258.92376708984375,
      "loss": 0.0471,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.72617244720459,
      "rewards/margins": 6.9749860763549805,
      "rewards/rejected": -13.70115852355957,
      "step": 25910
    },
    {
      "epoch": 4.730358609362169,
      "grad_norm": 6.615236759185791,
      "learning_rate": 4.36924206276381e-06,
      "logits/chosen": -0.01857508160173893,
      "logits/rejected": 0.5819836854934692,
      "logps/chosen": -218.5105438232422,
      "logps/rejected": -264.3246154785156,
      "loss": 0.0585,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.428967475891113,
      "rewards/margins": 7.010834693908691,
      "rewards/rejected": -13.439801216125488,
      "step": 25920
    },
    {
      "epoch": 4.732183593393557,
      "grad_norm": 2.506500482559204,
      "learning_rate": 4.33987887685814e-06,
      "logits/chosen": 0.1577480584383011,
      "logits/rejected": 0.47068390250205994,
      "logps/chosen": -203.47142028808594,
      "logps/rejected": -287.1591491699219,
      "loss": 0.0239,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.11773681640625,
      "rewards/margins": 7.552630424499512,
      "rewards/rejected": -13.670369148254395,
      "step": 25930
    },
    {
      "epoch": 4.734008577424947,
      "grad_norm": 11.363761901855469,
      "learning_rate": 4.310515690952469e-06,
      "logits/chosen": 0.134184792637825,
      "logits/rejected": 0.8269237279891968,
      "logps/chosen": -224.6621856689453,
      "logps/rejected": -269.42645263671875,
      "loss": 0.0696,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.05063009262085,
      "rewards/margins": 6.961517333984375,
      "rewards/rejected": -14.012147903442383,
      "step": 25940
    },
    {
      "epoch": 4.735833561456337,
      "grad_norm": 1.454879641532898,
      "learning_rate": 4.2811525050467975e-06,
      "logits/chosen": 0.07434786111116409,
      "logits/rejected": 0.6439217329025269,
      "logps/chosen": -217.9727325439453,
      "logps/rejected": -253.5260772705078,
      "loss": 0.0324,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.0380730628967285,
      "rewards/margins": 6.8333258628845215,
      "rewards/rejected": -13.87139892578125,
      "step": 25950
    },
    {
      "epoch": 4.737658545487727,
      "grad_norm": 0.4129634201526642,
      "learning_rate": 4.251789319141127e-06,
      "logits/chosen": 0.04826640337705612,
      "logits/rejected": 0.7209154367446899,
      "logps/chosen": -222.69247436523438,
      "logps/rejected": -272.06805419921875,
      "loss": 0.082,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.307077407836914,
      "rewards/margins": 7.040628910064697,
      "rewards/rejected": -13.34770679473877,
      "step": 25960
    },
    {
      "epoch": 4.7394835295191164,
      "grad_norm": 21.1359920501709,
      "learning_rate": 4.222426133235457e-06,
      "logits/chosen": 0.2936776876449585,
      "logits/rejected": 0.720261812210083,
      "logps/chosen": -209.79995727539062,
      "logps/rejected": -275.1073913574219,
      "loss": 0.1129,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.852059364318848,
      "rewards/margins": 7.158838748931885,
      "rewards/rejected": -14.010897636413574,
      "step": 25970
    },
    {
      "epoch": 4.741308513550506,
      "grad_norm": 3.6446683406829834,
      "learning_rate": 4.193062947329786e-06,
      "logits/chosen": 0.2645757496356964,
      "logits/rejected": 0.7191956639289856,
      "logps/chosen": -226.00711059570312,
      "logps/rejected": -286.19012451171875,
      "loss": 0.1305,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.602892875671387,
      "rewards/margins": 7.2925286293029785,
      "rewards/rejected": -13.895421981811523,
      "step": 25980
    },
    {
      "epoch": 4.743133497581896,
      "grad_norm": 4.19077730178833,
      "learning_rate": 4.163699761424114e-06,
      "logits/chosen": 0.28782254457473755,
      "logits/rejected": 0.7324060201644897,
      "logps/chosen": -222.4934539794922,
      "logps/rejected": -271.28009033203125,
      "loss": 0.0302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.359291076660156,
      "rewards/margins": 6.659008026123047,
      "rewards/rejected": -14.01830005645752,
      "step": 25990
    },
    {
      "epoch": 4.744958481613286,
      "grad_norm": 17.311668395996094,
      "learning_rate": 4.134336575518444e-06,
      "logits/chosen": 0.39601388573646545,
      "logits/rejected": 0.6601139903068542,
      "logps/chosen": -213.36495971679688,
      "logps/rejected": -270.8099670410156,
      "loss": 0.1372,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.748770236968994,
      "rewards/margins": 6.375572204589844,
      "rewards/rejected": -14.12434196472168,
      "step": 26000
    },
    {
      "epoch": 4.7467834656446755,
      "grad_norm": 0.44633933901786804,
      "learning_rate": 4.104973389612774e-06,
      "logits/chosen": 0.3368378281593323,
      "logits/rejected": 0.6835066080093384,
      "logps/chosen": -217.56442260742188,
      "logps/rejected": -287.1393127441406,
      "loss": 0.1121,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.211780548095703,
      "rewards/margins": 8.118349075317383,
      "rewards/rejected": -15.33012866973877,
      "step": 26010
    },
    {
      "epoch": 4.748608449676065,
      "grad_norm": 2.2822048664093018,
      "learning_rate": 4.0756102037071025e-06,
      "logits/chosen": 0.0535726323723793,
      "logits/rejected": 0.6612496972084045,
      "logps/chosen": -208.3737335205078,
      "logps/rejected": -248.03567504882812,
      "loss": 0.0422,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.174557209014893,
      "rewards/margins": 6.962745666503906,
      "rewards/rejected": -13.137303352355957,
      "step": 26020
    },
    {
      "epoch": 4.750433433707455,
      "grad_norm": 13.260915756225586,
      "learning_rate": 4.046247017801432e-06,
      "logits/chosen": 0.1877894401550293,
      "logits/rejected": 0.9182937741279602,
      "logps/chosen": -222.70663452148438,
      "logps/rejected": -263.29486083984375,
      "loss": 0.0525,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.574853420257568,
      "rewards/margins": 7.912440299987793,
      "rewards/rejected": -14.487292289733887,
      "step": 26030
    },
    {
      "epoch": 4.752258417738845,
      "grad_norm": 0.792958676815033,
      "learning_rate": 4.016883831895761e-06,
      "logits/chosen": 0.20170700550079346,
      "logits/rejected": 0.6175978779792786,
      "logps/chosen": -215.5382080078125,
      "logps/rejected": -286.6875915527344,
      "loss": 0.0245,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.138340950012207,
      "rewards/margins": 7.42470645904541,
      "rewards/rejected": -14.5630464553833,
      "step": 26040
    },
    {
      "epoch": 4.7540834017702345,
      "grad_norm": 6.365175724029541,
      "learning_rate": 3.98752064599009e-06,
      "logits/chosen": 0.20907410979270935,
      "logits/rejected": 0.6709316372871399,
      "logps/chosen": -231.68417358398438,
      "logps/rejected": -274.94854736328125,
      "loss": 0.0414,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.474148750305176,
      "rewards/margins": 7.2841644287109375,
      "rewards/rejected": -13.75831127166748,
      "step": 26050
    },
    {
      "epoch": 4.755908385801624,
      "grad_norm": 21.599462509155273,
      "learning_rate": 3.9581574600844195e-06,
      "logits/chosen": 0.3435927927494049,
      "logits/rejected": 0.6676362752914429,
      "logps/chosen": -216.2781982421875,
      "logps/rejected": -280.8062744140625,
      "loss": 0.1726,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.459253787994385,
      "rewards/margins": 6.917427062988281,
      "rewards/rejected": -14.376680374145508,
      "step": 26060
    },
    {
      "epoch": 4.757733369833014,
      "grad_norm": 19.860645294189453,
      "learning_rate": 3.928794274178749e-06,
      "logits/chosen": 0.2721010446548462,
      "logits/rejected": 1.0046864748001099,
      "logps/chosen": -216.31201171875,
      "logps/rejected": -259.69732666015625,
      "loss": 0.0583,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.204571723937988,
      "rewards/margins": 7.659619331359863,
      "rewards/rejected": -13.864191055297852,
      "step": 26070
    },
    {
      "epoch": 4.759558353864404,
      "grad_norm": 13.87917423248291,
      "learning_rate": 3.899431088273078e-06,
      "logits/chosen": 0.40071558952331543,
      "logits/rejected": 0.7941429615020752,
      "logps/chosen": -192.77951049804688,
      "logps/rejected": -247.0630340576172,
      "loss": 0.1209,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.00183629989624,
      "rewards/margins": 6.422609806060791,
      "rewards/rejected": -13.424446105957031,
      "step": 26080
    },
    {
      "epoch": 4.7613833378957935,
      "grad_norm": 4.604545593261719,
      "learning_rate": 3.870067902367407e-06,
      "logits/chosen": 0.1918092668056488,
      "logits/rejected": 0.5637086629867554,
      "logps/chosen": -213.28125,
      "logps/rejected": -265.32049560546875,
      "loss": 0.0531,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.337647914886475,
      "rewards/margins": 6.641226291656494,
      "rewards/rejected": -13.978876113891602,
      "step": 26090
    },
    {
      "epoch": 4.763208321927183,
      "grad_norm": 18.521230697631836,
      "learning_rate": 3.840704716461736e-06,
      "logits/chosen": 0.2876019775867462,
      "logits/rejected": 0.7501082420349121,
      "logps/chosen": -219.1641845703125,
      "logps/rejected": -286.8570556640625,
      "loss": 0.0602,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.6305975914001465,
      "rewards/margins": 6.817121982574463,
      "rewards/rejected": -14.447720527648926,
      "step": 26100
    },
    {
      "epoch": 4.765033305958573,
      "grad_norm": 0.30474692583084106,
      "learning_rate": 3.8113415305560656e-06,
      "logits/chosen": 0.19704407453536987,
      "logits/rejected": 0.8483301401138306,
      "logps/chosen": -225.5157928466797,
      "logps/rejected": -270.7612609863281,
      "loss": 0.016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.6573920249938965,
      "rewards/margins": 7.496522426605225,
      "rewards/rejected": -14.153913497924805,
      "step": 26110
    },
    {
      "epoch": 4.766858289989963,
      "grad_norm": 3.368819236755371,
      "learning_rate": 3.781978344650395e-06,
      "logits/chosen": 0.21151745319366455,
      "logits/rejected": 0.6423103213310242,
      "logps/chosen": -245.39462280273438,
      "logps/rejected": -281.5390930175781,
      "loss": 0.042,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.837044715881348,
      "rewards/margins": 6.635833740234375,
      "rewards/rejected": -14.472879409790039,
      "step": 26120
    },
    {
      "epoch": 4.7686832740213525,
      "grad_norm": 6.1814284324646,
      "learning_rate": 3.752615158744724e-06,
      "logits/chosen": -0.007539400365203619,
      "logits/rejected": 0.7987807989120483,
      "logps/chosen": -225.33419799804688,
      "logps/rejected": -266.6084289550781,
      "loss": 0.0253,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.864927768707275,
      "rewards/margins": 7.636375427246094,
      "rewards/rejected": -14.501302719116211,
      "step": 26130
    },
    {
      "epoch": 4.770508258052742,
      "grad_norm": 0.4495121240615845,
      "learning_rate": 3.7232519728390533e-06,
      "logits/chosen": 0.19944486021995544,
      "logits/rejected": 0.8138267397880554,
      "logps/chosen": -225.6083984375,
      "logps/rejected": -257.66082763671875,
      "loss": 0.0483,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.082681179046631,
      "rewards/margins": 7.142566680908203,
      "rewards/rejected": -14.225248336791992,
      "step": 26140
    },
    {
      "epoch": 4.772333242084132,
      "grad_norm": 14.233931541442871,
      "learning_rate": 3.693888786933383e-06,
      "logits/chosen": 0.21234485507011414,
      "logits/rejected": 0.6914260983467102,
      "logps/chosen": -211.8336639404297,
      "logps/rejected": -275.1524658203125,
      "loss": 0.1678,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.783201694488525,
      "rewards/margins": 7.311403751373291,
      "rewards/rejected": -14.0946044921875,
      "step": 26150
    },
    {
      "epoch": 4.774158226115522,
      "grad_norm": 28.060386657714844,
      "learning_rate": 3.6645256010277118e-06,
      "logits/chosen": 0.247216135263443,
      "logits/rejected": 0.5785561800003052,
      "logps/chosen": -220.8438262939453,
      "logps/rejected": -284.45452880859375,
      "loss": 0.1253,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.207569122314453,
      "rewards/margins": 7.139007568359375,
      "rewards/rejected": -14.346575736999512,
      "step": 26160
    },
    {
      "epoch": 4.7759832101469115,
      "grad_norm": 3.3680496215820312,
      "learning_rate": 3.635162415122041e-06,
      "logits/chosen": 0.38185685873031616,
      "logits/rejected": 0.9514982104301453,
      "logps/chosen": -242.61398315429688,
      "logps/rejected": -266.8583984375,
      "loss": 0.0475,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.960848808288574,
      "rewards/margins": 6.861392021179199,
      "rewards/rejected": -14.822239875793457,
      "step": 26170
    },
    {
      "epoch": 4.777808194178301,
      "grad_norm": 2.8029935359954834,
      "learning_rate": 3.6057992292163702e-06,
      "logits/chosen": 0.2557530701160431,
      "logits/rejected": 1.2391014099121094,
      "logps/chosen": -247.538818359375,
      "logps/rejected": -257.40118408203125,
      "loss": 0.0687,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.680638790130615,
      "rewards/margins": 7.115057468414307,
      "rewards/rejected": -14.795695304870605,
      "step": 26180
    },
    {
      "epoch": 4.779633178209691,
      "grad_norm": 1.1541082859039307,
      "learning_rate": 3.5764360433106995e-06,
      "logits/chosen": 0.04441208764910698,
      "logits/rejected": 0.4598725736141205,
      "logps/chosen": -203.0483856201172,
      "logps/rejected": -264.7966613769531,
      "loss": 0.1275,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.63137674331665,
      "rewards/margins": 7.103602409362793,
      "rewards/rejected": -13.734977722167969,
      "step": 26190
    },
    {
      "epoch": 4.781458162241081,
      "grad_norm": 4.963647842407227,
      "learning_rate": 3.547072857405029e-06,
      "logits/chosen": 0.14742837846279144,
      "logits/rejected": 1.0213783979415894,
      "logps/chosen": -229.0272979736328,
      "logps/rejected": -260.7527160644531,
      "loss": 0.0677,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.346893310546875,
      "rewards/margins": 7.5599565505981445,
      "rewards/rejected": -14.906847953796387,
      "step": 26200
    },
    {
      "epoch": 4.7832831462724705,
      "grad_norm": 1.3354605436325073,
      "learning_rate": 3.517709671499358e-06,
      "logits/chosen": 0.47548288106918335,
      "logits/rejected": 0.7379631996154785,
      "logps/chosen": -215.36361694335938,
      "logps/rejected": -280.3168029785156,
      "loss": 0.2586,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.623008728027344,
      "rewards/margins": 6.616752624511719,
      "rewards/rejected": -14.239761352539062,
      "step": 26210
    },
    {
      "epoch": 4.785108130303859,
      "grad_norm": 4.520999431610107,
      "learning_rate": 3.488346485593687e-06,
      "logits/chosen": 0.3770666718482971,
      "logits/rejected": 0.8674920797348022,
      "logps/chosen": -223.7498016357422,
      "logps/rejected": -270.464111328125,
      "loss": 0.0658,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.493119716644287,
      "rewards/margins": 6.823777675628662,
      "rewards/rejected": -14.31689739227295,
      "step": 26220
    },
    {
      "epoch": 4.78693311433525,
      "grad_norm": 6.097179412841797,
      "learning_rate": 3.4589832996880164e-06,
      "logits/chosen": 0.17647555470466614,
      "logits/rejected": 0.3301822245121002,
      "logps/chosen": -209.6043243408203,
      "logps/rejected": -288.42608642578125,
      "loss": 0.0305,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.712639808654785,
      "rewards/margins": 7.1795854568481445,
      "rewards/rejected": -14.892224311828613,
      "step": 26230
    },
    {
      "epoch": 4.788758098366639,
      "grad_norm": 10.83283805847168,
      "learning_rate": 3.429620113782346e-06,
      "logits/chosen": 0.25073710083961487,
      "logits/rejected": 0.621846079826355,
      "logps/chosen": -211.38735961914062,
      "logps/rejected": -260.23272705078125,
      "loss": 0.0821,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.839080810546875,
      "rewards/margins": 7.631319999694824,
      "rewards/rejected": -14.4704008102417,
      "step": 26240
    },
    {
      "epoch": 4.790583082398029,
      "grad_norm": 1.3737834692001343,
      "learning_rate": 3.400256927876675e-06,
      "logits/chosen": 0.13095583021640778,
      "logits/rejected": 0.8002312779426575,
      "logps/chosen": -217.68624877929688,
      "logps/rejected": -269.37237548828125,
      "loss": 0.1865,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.667301177978516,
      "rewards/margins": 6.876974582672119,
      "rewards/rejected": -14.544276237487793,
      "step": 26250
    },
    {
      "epoch": 4.792408066429418,
      "grad_norm": 2.0712852478027344,
      "learning_rate": 3.370893741971004e-06,
      "logits/chosen": 0.22717833518981934,
      "logits/rejected": 0.7552288770675659,
      "logps/chosen": -223.0716552734375,
      "logps/rejected": -263.3504638671875,
      "loss": 0.1344,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -8.383598327636719,
      "rewards/margins": 6.441770076751709,
      "rewards/rejected": -14.825368881225586,
      "step": 26260
    },
    {
      "epoch": 4.794233050460808,
      "grad_norm": 3.594895839691162,
      "learning_rate": 3.3415305560653333e-06,
      "logits/chosen": 0.1788964867591858,
      "logits/rejected": 0.6944678425788879,
      "logps/chosen": -238.7584228515625,
      "logps/rejected": -282.2146301269531,
      "loss": 0.0561,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.668139457702637,
      "rewards/margins": 6.188596248626709,
      "rewards/rejected": -13.85673713684082,
      "step": 26270
    },
    {
      "epoch": 4.796058034492198,
      "grad_norm": 4.239872932434082,
      "learning_rate": 3.3121673701596626e-06,
      "logits/chosen": 0.06517166644334793,
      "logits/rejected": 0.6761966943740845,
      "logps/chosen": -217.97787475585938,
      "logps/rejected": -243.2235565185547,
      "loss": 0.0481,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.793465614318848,
      "rewards/margins": 6.331374645233154,
      "rewards/rejected": -14.124841690063477,
      "step": 26280
    },
    {
      "epoch": 4.797883018523588,
      "grad_norm": 11.111471176147461,
      "learning_rate": 3.2828041842539922e-06,
      "logits/chosen": 0.05137864500284195,
      "logits/rejected": 0.760826051235199,
      "logps/chosen": -226.66183471679688,
      "logps/rejected": -261.71368408203125,
      "loss": 0.0635,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.6455583572387695,
      "rewards/margins": 7.27236795425415,
      "rewards/rejected": -13.917925834655762,
      "step": 26290
    },
    {
      "epoch": 4.799708002554977,
      "grad_norm": 2.1825859546661377,
      "learning_rate": 3.253440998348321e-06,
      "logits/chosen": 0.35198214650154114,
      "logits/rejected": 1.0823957920074463,
      "logps/chosen": -224.0044708251953,
      "logps/rejected": -246.733154296875,
      "loss": 0.0625,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.367594242095947,
      "rewards/margins": 6.982646942138672,
      "rewards/rejected": -14.350239753723145,
      "step": 26300
    },
    {
      "epoch": 4.801532986586367,
      "grad_norm": 13.747447967529297,
      "learning_rate": 3.2240778124426503e-06,
      "logits/chosen": -0.009359894320368767,
      "logits/rejected": 0.6237192749977112,
      "logps/chosen": -224.915771484375,
      "logps/rejected": -261.1046447753906,
      "loss": 0.0431,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.48915958404541,
      "rewards/margins": 7.122897148132324,
      "rewards/rejected": -13.612054824829102,
      "step": 26310
    },
    {
      "epoch": 4.803357970617757,
      "grad_norm": 2.8407480716705322,
      "learning_rate": 3.1947146265369795e-06,
      "logits/chosen": 0.14698350429534912,
      "logits/rejected": 0.5178598761558533,
      "logps/chosen": -211.0076446533203,
      "logps/rejected": -258.2312927246094,
      "loss": 0.0503,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.771659851074219,
      "rewards/margins": 5.850915908813477,
      "rewards/rejected": -12.622575759887695,
      "step": 26320
    },
    {
      "epoch": 4.805182954649147,
      "grad_norm": 2.6352734565734863,
      "learning_rate": 3.1653514406313083e-06,
      "logits/chosen": 0.23282310366630554,
      "logits/rejected": 0.7409475445747375,
      "logps/chosen": -210.73568725585938,
      "logps/rejected": -251.6040496826172,
      "loss": 0.05,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.8871259689331055,
      "rewards/margins": 6.75461483001709,
      "rewards/rejected": -13.641741752624512,
      "step": 26330
    },
    {
      "epoch": 4.807007938680536,
      "grad_norm": 17.65229606628418,
      "learning_rate": 3.135988254725638e-06,
      "logits/chosen": 0.15559187531471252,
      "logits/rejected": 0.42169028520584106,
      "logps/chosen": -218.022216796875,
      "logps/rejected": -281.11834716796875,
      "loss": 0.0394,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.569466590881348,
      "rewards/margins": 6.950949192047119,
      "rewards/rejected": -13.520416259765625,
      "step": 26340
    },
    {
      "epoch": 4.808832922711926,
      "grad_norm": 3.6328814029693604,
      "learning_rate": 3.106625068819967e-06,
      "logits/chosen": 0.12122155725955963,
      "logits/rejected": 0.575670599937439,
      "logps/chosen": -205.26956176757812,
      "logps/rejected": -265.1958923339844,
      "loss": 0.0454,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.206171989440918,
      "rewards/margins": 7.566173553466797,
      "rewards/rejected": -13.772344589233398,
      "step": 26350
    },
    {
      "epoch": 4.810657906743316,
      "grad_norm": 8.854918479919434,
      "learning_rate": 3.0772618829142964e-06,
      "logits/chosen": 0.14830371737480164,
      "logits/rejected": 0.5908326506614685,
      "logps/chosen": -211.306640625,
      "logps/rejected": -280.1374206542969,
      "loss": 0.0449,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.89833927154541,
      "rewards/margins": 8.013955116271973,
      "rewards/rejected": -14.912294387817383,
      "step": 26360
    },
    {
      "epoch": 4.812482890774706,
      "grad_norm": 0.4293157160282135,
      "learning_rate": 3.0478986970086257e-06,
      "logits/chosen": 0.1717248260974884,
      "logits/rejected": 0.7012050747871399,
      "logps/chosen": -217.40213012695312,
      "logps/rejected": -267.403564453125,
      "loss": 0.044,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.389049530029297,
      "rewards/margins": 7.2088303565979,
      "rewards/rejected": -13.597879409790039,
      "step": 26370
    },
    {
      "epoch": 4.8143078748060955,
      "grad_norm": 0.6639170050621033,
      "learning_rate": 3.0185355111029553e-06,
      "logits/chosen": 0.29935842752456665,
      "logits/rejected": 0.7480930089950562,
      "logps/chosen": -216.15383911132812,
      "logps/rejected": -289.1029968261719,
      "loss": 0.0126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.2593865394592285,
      "rewards/margins": 7.826426029205322,
      "rewards/rejected": -15.08581256866455,
      "step": 26380
    },
    {
      "epoch": 4.816132858837485,
      "grad_norm": 1.3898465633392334,
      "learning_rate": 2.989172325197284e-06,
      "logits/chosen": 0.4104078710079193,
      "logits/rejected": 0.9589558839797974,
      "logps/chosen": -221.6781005859375,
      "logps/rejected": -273.0567932128906,
      "loss": 0.0263,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.524588584899902,
      "rewards/margins": 7.027856349945068,
      "rewards/rejected": -14.552444458007812,
      "step": 26390
    },
    {
      "epoch": 4.817957842868875,
      "grad_norm": 1.405578851699829,
      "learning_rate": 2.9598091392916134e-06,
      "logits/chosen": 0.18875771760940552,
      "logits/rejected": 0.5649896264076233,
      "logps/chosen": -221.22647094726562,
      "logps/rejected": -282.39495849609375,
      "loss": 0.0272,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.799200534820557,
      "rewards/margins": 7.112462043762207,
      "rewards/rejected": -14.911662101745605,
      "step": 26400
    },
    {
      "epoch": 4.819782826900265,
      "grad_norm": 11.666876792907715,
      "learning_rate": 2.9304459533859426e-06,
      "logits/chosen": 0.25748729705810547,
      "logits/rejected": 0.7451193332672119,
      "logps/chosen": -232.5906219482422,
      "logps/rejected": -275.02789306640625,
      "loss": 0.072,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.766970634460449,
      "rewards/margins": 7.3038153648376465,
      "rewards/rejected": -14.07078742980957,
      "step": 26410
    },
    {
      "epoch": 4.8216078109316545,
      "grad_norm": 1.095572829246521,
      "learning_rate": 2.901082767480272e-06,
      "logits/chosen": 0.1359710395336151,
      "logits/rejected": 0.778661847114563,
      "logps/chosen": -226.36672973632812,
      "logps/rejected": -277.1312255859375,
      "loss": 0.0403,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.098033905029297,
      "rewards/margins": 7.174832344055176,
      "rewards/rejected": -14.272865295410156,
      "step": 26420
    },
    {
      "epoch": 4.823432794963044,
      "grad_norm": 23.33409309387207,
      "learning_rate": 2.8717195815746015e-06,
      "logits/chosen": 0.2726849913597107,
      "logits/rejected": 0.749815821647644,
      "logps/chosen": -235.8336944580078,
      "logps/rejected": -287.00689697265625,
      "loss": 0.0306,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.083271980285645,
      "rewards/margins": 7.020013332366943,
      "rewards/rejected": -15.10328483581543,
      "step": 26430
    },
    {
      "epoch": 4.825257778994434,
      "grad_norm": 2.5515010356903076,
      "learning_rate": 2.8423563956689303e-06,
      "logits/chosen": 0.4903123378753662,
      "logits/rejected": 0.6534501910209656,
      "logps/chosen": -203.21566772460938,
      "logps/rejected": -287.5036926269531,
      "loss": 0.1191,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.216395378112793,
      "rewards/margins": 6.9917497634887695,
      "rewards/rejected": -15.208145141601562,
      "step": 26440
    },
    {
      "epoch": 4.827082763025824,
      "grad_norm": 1.710852026939392,
      "learning_rate": 2.815929528353827e-06,
      "logits/chosen": 0.43219462037086487,
      "logits/rejected": 0.7459599375724792,
      "logps/chosen": -212.85458374023438,
      "logps/rejected": -278.6731262207031,
      "loss": 0.0902,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.975030422210693,
      "rewards/margins": 6.914913177490234,
      "rewards/rejected": -14.889944076538086,
      "step": 26450
    },
    {
      "epoch": 4.8289077470572135,
      "grad_norm": 1.775107502937317,
      "learning_rate": 2.786566342448156e-06,
      "logits/chosen": 0.2782849967479706,
      "logits/rejected": 0.7706107497215271,
      "logps/chosen": -229.7293701171875,
      "logps/rejected": -285.6939697265625,
      "loss": 0.0243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -8.332435607910156,
      "rewards/margins": 6.853954315185547,
      "rewards/rejected": -15.186388969421387,
      "step": 26460
    },
    {
      "epoch": 4.830732731088603,
      "grad_norm": 4.299222469329834,
      "learning_rate": 2.757203156542485e-06,
      "logits/chosen": 0.22837261855602264,
      "logits/rejected": 0.6179198026657104,
      "logps/chosen": -226.83676147460938,
      "logps/rejected": -274.03839111328125,
      "loss": 0.0758,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.5953192710876465,
      "rewards/margins": 6.172133445739746,
      "rewards/rejected": -13.76745319366455,
      "step": 26470
    },
    {
      "epoch": 4.832557715119993,
      "grad_norm": 4.852665901184082,
      "learning_rate": 2.727839970636814e-06,
      "logits/chosen": 0.2007657289505005,
      "logits/rejected": 0.6019285917282104,
      "logps/chosen": -211.7875518798828,
      "logps/rejected": -271.9064025878906,
      "loss": 0.0491,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.447384834289551,
      "rewards/margins": 7.162489414215088,
      "rewards/rejected": -14.609872817993164,
      "step": 26480
    },
    {
      "epoch": 4.834382699151383,
      "grad_norm": 17.064006805419922,
      "learning_rate": 2.6984767847311433e-06,
      "logits/chosen": 0.15449067950248718,
      "logits/rejected": 0.6389878988265991,
      "logps/chosen": -230.8681182861328,
      "logps/rejected": -264.6961975097656,
      "loss": 0.045,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.781730651855469,
      "rewards/margins": 6.662172794342041,
      "rewards/rejected": -14.443901062011719,
      "step": 26490
    },
    {
      "epoch": 4.8362076831827725,
      "grad_norm": 0.3244234621524811,
      "learning_rate": 2.669113598825473e-06,
      "logits/chosen": 0.43667730689048767,
      "logits/rejected": 0.7517081499099731,
      "logps/chosen": -218.0331268310547,
      "logps/rejected": -297.81207275390625,
      "loss": 0.0325,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.5645246505737305,
      "rewards/margins": 7.543448448181152,
      "rewards/rejected": -15.1079740524292,
      "step": 26500
    },
    {
      "epoch": 4.838032667214162,
      "grad_norm": 2.433302402496338,
      "learning_rate": 2.639750412919802e-06,
      "logits/chosen": 0.43564337491989136,
      "logits/rejected": 0.8947857618331909,
      "logps/chosen": -222.62405395507812,
      "logps/rejected": -274.89056396484375,
      "loss": 0.0233,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.9015045166015625,
      "rewards/margins": 7.337613105773926,
      "rewards/rejected": -15.239118576049805,
      "step": 26510
    },
    {
      "epoch": 4.839857651245552,
      "grad_norm": 1.5250983238220215,
      "learning_rate": 2.610387227014131e-06,
      "logits/chosen": 0.48557478189468384,
      "logits/rejected": 0.876021683216095,
      "logps/chosen": -193.17103576660156,
      "logps/rejected": -258.6826171875,
      "loss": 0.0435,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.748361110687256,
      "rewards/margins": 7.231884956359863,
      "rewards/rejected": -13.980245590209961,
      "step": 26520
    },
    {
      "epoch": 4.841682635276941,
      "grad_norm": 5.116352558135986,
      "learning_rate": 2.5810240411084602e-06,
      "logits/chosen": 0.038548000156879425,
      "logits/rejected": 0.7501815557479858,
      "logps/chosen": -245.70703125,
      "logps/rejected": -272.2068176269531,
      "loss": 0.0191,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.775110721588135,
      "rewards/margins": 7.297215461730957,
      "rewards/rejected": -15.07232666015625,
      "step": 26530
    },
    {
      "epoch": 4.8435076193083315,
      "grad_norm": 0.05127434432506561,
      "learning_rate": 2.55166085520279e-06,
      "logits/chosen": 0.0310048870742321,
      "logits/rejected": 0.37865400314331055,
      "logps/chosen": -209.70419311523438,
      "logps/rejected": -267.71527099609375,
      "loss": 0.0931,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.93630838394165,
      "rewards/margins": 6.500161647796631,
      "rewards/rejected": -13.436470031738281,
      "step": 26540
    },
    {
      "epoch": 4.84533260333972,
      "grad_norm": 2.5228066444396973,
      "learning_rate": 2.522297669297119e-06,
      "logits/chosen": 0.1305224746465683,
      "logits/rejected": 0.5256348848342896,
      "logps/chosen": -208.7146453857422,
      "logps/rejected": -272.603515625,
      "loss": 0.041,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.180647373199463,
      "rewards/margins": 7.338397026062012,
      "rewards/rejected": -14.519044876098633,
      "step": 26550
    },
    {
      "epoch": 4.84715758737111,
      "grad_norm": 1.2535886764526367,
      "learning_rate": 2.4929344833914484e-06,
      "logits/chosen": 0.05250122398138046,
      "logits/rejected": 0.6512124538421631,
      "logps/chosen": -227.37255859375,
      "logps/rejected": -277.85760498046875,
      "loss": 0.0216,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.277431488037109,
      "rewards/margins": 7.431235313415527,
      "rewards/rejected": -13.708666801452637,
      "step": 26560
    },
    {
      "epoch": 4.8489825714025,
      "grad_norm": 0.44571104645729065,
      "learning_rate": 2.463571297485777e-06,
      "logits/chosen": 0.2579095959663391,
      "logits/rejected": 0.8844870328903198,
      "logps/chosen": -221.16220092773438,
      "logps/rejected": -273.46563720703125,
      "loss": 0.0279,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.642723083496094,
      "rewards/margins": 7.219010829925537,
      "rewards/rejected": -14.861732482910156,
      "step": 26570
    },
    {
      "epoch": 4.85080755543389,
      "grad_norm": 0.2843351364135742,
      "learning_rate": 2.434208111580107e-06,
      "logits/chosen": 0.25210684537887573,
      "logits/rejected": 0.664793848991394,
      "logps/chosen": -233.65011596679688,
      "logps/rejected": -275.07110595703125,
      "loss": 0.0654,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.7907843589782715,
      "rewards/margins": 6.988725185394287,
      "rewards/rejected": -14.779508590698242,
      "step": 26580
    },
    {
      "epoch": 4.852632539465279,
      "grad_norm": 36.09318923950195,
      "learning_rate": 2.4048449256744356e-06,
      "logits/chosen": 0.21682915091514587,
      "logits/rejected": 0.8197594881057739,
      "logps/chosen": -228.36557006835938,
      "logps/rejected": -276.81414794921875,
      "loss": 0.0632,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.271430015563965,
      "rewards/margins": 7.69207763671875,
      "rewards/rejected": -14.963506698608398,
      "step": 26590
    },
    {
      "epoch": 4.854457523496669,
      "grad_norm": 18.477449417114258,
      "learning_rate": 2.3754817397687653e-06,
      "logits/chosen": 0.24286611378192902,
      "logits/rejected": 0.42797261476516724,
      "logps/chosen": -209.84130859375,
      "logps/rejected": -287.3924255371094,
      "loss": 0.0621,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.9427056312561035,
      "rewards/margins": 7.312331199645996,
      "rewards/rejected": -14.255037307739258,
      "step": 26600
    },
    {
      "epoch": 4.856282507528059,
      "grad_norm": 1.9540048837661743,
      "learning_rate": 2.346118553863094e-06,
      "logits/chosen": 0.2692382335662842,
      "logits/rejected": 0.7038857340812683,
      "logps/chosen": -210.71463012695312,
      "logps/rejected": -269.3419494628906,
      "loss": 0.039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.325448036193848,
      "rewards/margins": 7.160696506500244,
      "rewards/rejected": -14.4861421585083,
      "step": 26610
    },
    {
      "epoch": 4.858107491559449,
      "grad_norm": 4.654218673706055,
      "learning_rate": 2.3167553679574238e-06,
      "logits/chosen": 0.2755644917488098,
      "logits/rejected": 0.708479642868042,
      "logps/chosen": -229.6878204345703,
      "logps/rejected": -277.38037109375,
      "loss": 0.0429,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.356560707092285,
      "rewards/margins": 6.912164211273193,
      "rewards/rejected": -14.26872444152832,
      "step": 26620
    },
    {
      "epoch": 4.859932475590838,
      "grad_norm": 0.6980276107788086,
      "learning_rate": 2.287392182051753e-06,
      "logits/chosen": 0.04201814532279968,
      "logits/rejected": 0.8459436297416687,
      "logps/chosen": -248.0863800048828,
      "logps/rejected": -277.766357421875,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.076455593109131,
      "rewards/margins": 7.801693916320801,
      "rewards/rejected": -14.878149032592773,
      "step": 26630
    },
    {
      "epoch": 4.861757459622228,
      "grad_norm": 0.45475971698760986,
      "learning_rate": 2.258028996146082e-06,
      "logits/chosen": 0.3274448812007904,
      "logits/rejected": 0.78359055519104,
      "logps/chosen": -210.4379119873047,
      "logps/rejected": -269.36676025390625,
      "loss": 0.0433,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.6028242111206055,
      "rewards/margins": 7.738171577453613,
      "rewards/rejected": -15.340995788574219,
      "step": 26640
    },
    {
      "epoch": 4.863582443653618,
      "grad_norm": 0.7315083742141724,
      "learning_rate": 2.2286658102404115e-06,
      "logits/chosen": 0.4389421343803406,
      "logits/rejected": 0.9982622861862183,
      "logps/chosen": -216.0807342529297,
      "logps/rejected": -278.9427490234375,
      "loss": 0.0588,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.352226257324219,
      "rewards/margins": 7.136521339416504,
      "rewards/rejected": -14.488748550415039,
      "step": 26650
    },
    {
      "epoch": 4.865407427685008,
      "grad_norm": 1.8872389793395996,
      "learning_rate": 2.1993026243347403e-06,
      "logits/chosen": 0.1940573751926422,
      "logits/rejected": 0.41136226058006287,
      "logps/chosen": -228.2405242919922,
      "logps/rejected": -307.0858459472656,
      "loss": 0.0187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.372028350830078,
      "rewards/margins": 7.856179237365723,
      "rewards/rejected": -15.2282075881958,
      "step": 26660
    },
    {
      "epoch": 4.867232411716397,
      "grad_norm": 6.316529750823975,
      "learning_rate": 2.16993943842907e-06,
      "logits/chosen": 0.35071900486946106,
      "logits/rejected": 0.7670532464981079,
      "logps/chosen": -204.12838745117188,
      "logps/rejected": -255.130615234375,
      "loss": 0.0176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.193665981292725,
      "rewards/margins": 6.512640476226807,
      "rewards/rejected": -13.706306457519531,
      "step": 26670
    },
    {
      "epoch": 4.869057395747787,
      "grad_norm": 5.232802867889404,
      "learning_rate": 2.1405762525233987e-06,
      "logits/chosen": 0.05635986477136612,
      "logits/rejected": 0.7458648681640625,
      "logps/chosen": -222.33114624023438,
      "logps/rejected": -266.708251953125,
      "loss": 0.0397,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.4696173667907715,
      "rewards/margins": 7.666404724121094,
      "rewards/rejected": -14.136022567749023,
      "step": 26680
    },
    {
      "epoch": 4.870882379779177,
      "grad_norm": 12.100532531738281,
      "learning_rate": 2.1112130666177284e-06,
      "logits/chosen": 0.2653837203979492,
      "logits/rejected": 0.5698356628417969,
      "logps/chosen": -205.73208618164062,
      "logps/rejected": -283.23455810546875,
      "loss": 0.0452,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.737256050109863,
      "rewards/margins": 7.065573692321777,
      "rewards/rejected": -14.802828788757324,
      "step": 26690
    },
    {
      "epoch": 4.872707363810567,
      "grad_norm": 3.2132413387298584,
      "learning_rate": 2.081849880712057e-06,
      "logits/chosen": 0.11245059967041016,
      "logits/rejected": 0.5422840714454651,
      "logps/chosen": -206.2207794189453,
      "logps/rejected": -249.51199340820312,
      "loss": 0.1281,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -7.26328182220459,
      "rewards/margins": 6.424820899963379,
      "rewards/rejected": -13.688102722167969,
      "step": 26700
    },
    {
      "epoch": 4.874532347841956,
      "grad_norm": 0.18395256996154785,
      "learning_rate": 2.052486694806387e-06,
      "logits/chosen": 0.08805406838655472,
      "logits/rejected": 0.7051000595092773,
      "logps/chosen": -232.1992645263672,
      "logps/rejected": -283.3292236328125,
      "loss": 0.069,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.27642822265625,
      "rewards/margins": 7.586610317230225,
      "rewards/rejected": -14.863039016723633,
      "step": 26710
    },
    {
      "epoch": 4.876357331873346,
      "grad_norm": 4.057102680206299,
      "learning_rate": 2.023123508900716e-06,
      "logits/chosen": 0.39093178510665894,
      "logits/rejected": 0.9190171360969543,
      "logps/chosen": -235.0884246826172,
      "logps/rejected": -274.9615173339844,
      "loss": 0.1056,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.246199607849121,
      "rewards/margins": 6.432529449462891,
      "rewards/rejected": -14.678730964660645,
      "step": 26720
    },
    {
      "epoch": 4.878182315904736,
      "grad_norm": 0.2936931848526001,
      "learning_rate": 1.993760322995045e-06,
      "logits/chosen": 0.11091341823339462,
      "logits/rejected": 0.3405687212944031,
      "logps/chosen": -219.3456268310547,
      "logps/rejected": -304.2157287597656,
      "loss": 0.1178,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.480368137359619,
      "rewards/margins": 7.545474052429199,
      "rewards/rejected": -15.025843620300293,
      "step": 26730
    },
    {
      "epoch": 4.880007299936126,
      "grad_norm": 2.7646677494049072,
      "learning_rate": 1.9643971370893746e-06,
      "logits/chosen": 0.3525979816913605,
      "logits/rejected": 1.1429641246795654,
      "logps/chosen": -237.072509765625,
      "logps/rejected": -253.9574737548828,
      "loss": 0.1057,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.936725616455078,
      "rewards/margins": 6.067469596862793,
      "rewards/rejected": -14.004196166992188,
      "step": 26740
    },
    {
      "epoch": 4.8818322839675155,
      "grad_norm": 20.2834415435791,
      "learning_rate": 1.9350339511837034e-06,
      "logits/chosen": 0.05900716781616211,
      "logits/rejected": 0.761446475982666,
      "logps/chosen": -232.25827026367188,
      "logps/rejected": -273.697998046875,
      "loss": 0.0528,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.1234846115112305,
      "rewards/margins": 7.695504188537598,
      "rewards/rejected": -14.818987846374512,
      "step": 26750
    },
    {
      "epoch": 4.883657267998905,
      "grad_norm": 8.124133110046387,
      "learning_rate": 1.9056707652780328e-06,
      "logits/chosen": 0.2984635531902313,
      "logits/rejected": 0.6051031351089478,
      "logps/chosen": -233.07992553710938,
      "logps/rejected": -281.241455078125,
      "loss": 0.0736,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.282618045806885,
      "rewards/margins": 6.875247955322266,
      "rewards/rejected": -14.157865524291992,
      "step": 26760
    },
    {
      "epoch": 4.885482252030295,
      "grad_norm": 2.0952069759368896,
      "learning_rate": 1.876307579372362e-06,
      "logits/chosen": 0.19681331515312195,
      "logits/rejected": 0.7552820444107056,
      "logps/chosen": -232.53396606445312,
      "logps/rejected": -269.0765686035156,
      "loss": 0.0723,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.613278388977051,
      "rewards/margins": 6.673421382904053,
      "rewards/rejected": -14.286699295043945,
      "step": 26770
    },
    {
      "epoch": 4.887307236061685,
      "grad_norm": 16.606830596923828,
      "learning_rate": 1.8469443934666915e-06,
      "logits/chosen": 0.5767022371292114,
      "logits/rejected": 0.7752110958099365,
      "logps/chosen": -192.51712036132812,
      "logps/rejected": -262.63275146484375,
      "loss": 0.106,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.040003299713135,
      "rewards/margins": 6.831873893737793,
      "rewards/rejected": -13.871877670288086,
      "step": 26780
    },
    {
      "epoch": 4.8891322200930745,
      "grad_norm": 6.448288440704346,
      "learning_rate": 1.8175812075610205e-06,
      "logits/chosen": 0.06988067924976349,
      "logits/rejected": 0.668418288230896,
      "logps/chosen": -226.5548858642578,
      "logps/rejected": -263.7731018066406,
      "loss": 0.0692,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.771131992340088,
      "rewards/margins": 7.235672950744629,
      "rewards/rejected": -14.006803512573242,
      "step": 26790
    },
    {
      "epoch": 4.890957204124464,
      "grad_norm": 9.70999813079834,
      "learning_rate": 1.7882180216553497e-06,
      "logits/chosen": 0.10182256996631622,
      "logits/rejected": 0.7064694762229919,
      "logps/chosen": -231.83505249023438,
      "logps/rejected": -262.93109130859375,
      "loss": 0.0592,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.287120819091797,
      "rewards/margins": 6.058720588684082,
      "rewards/rejected": -13.345840454101562,
      "step": 26800
    },
    {
      "epoch": 4.892782188155854,
      "grad_norm": 5.265840530395508,
      "learning_rate": 1.758854835749679e-06,
      "logits/chosen": 0.17418122291564941,
      "logits/rejected": 0.7172566652297974,
      "logps/chosen": -226.59420776367188,
      "logps/rejected": -262.43487548828125,
      "loss": 0.0441,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.611584663391113,
      "rewards/margins": 6.58004093170166,
      "rewards/rejected": -14.191625595092773,
      "step": 26810
    },
    {
      "epoch": 4.894607172187244,
      "grad_norm": 1.8618190288543701,
      "learning_rate": 1.7294916498440082e-06,
      "logits/chosen": 0.4319167733192444,
      "logits/rejected": 0.6892678737640381,
      "logps/chosen": -209.7576904296875,
      "logps/rejected": -270.484375,
      "loss": 0.1202,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.704841613769531,
      "rewards/margins": 6.366509437561035,
      "rewards/rejected": -14.071352005004883,
      "step": 26820
    },
    {
      "epoch": 4.8964321562186335,
      "grad_norm": 1.714354395866394,
      "learning_rate": 1.7001284639383374e-06,
      "logits/chosen": 0.2957898676395416,
      "logits/rejected": 0.3097988963127136,
      "logps/chosen": -203.79452514648438,
      "logps/rejected": -301.49920654296875,
      "loss": 0.114,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.547827243804932,
      "rewards/margins": 7.339425086975098,
      "rewards/rejected": -14.887250900268555,
      "step": 26830
    },
    {
      "epoch": 4.898257140250022,
      "grad_norm": 10.830318450927734,
      "learning_rate": 1.6707652780326667e-06,
      "logits/chosen": 0.5515084862709045,
      "logits/rejected": 1.2385090589523315,
      "logps/chosen": -220.6792449951172,
      "logps/rejected": -272.3474426269531,
      "loss": 0.0636,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.26548957824707,
      "rewards/margins": 7.091019630432129,
      "rewards/rejected": -15.356508255004883,
      "step": 26840
    },
    {
      "epoch": 4.900082124281413,
      "grad_norm": 4.332090854644775,
      "learning_rate": 1.6414020921269961e-06,
      "logits/chosen": 0.28500404953956604,
      "logits/rejected": 0.803270697593689,
      "logps/chosen": -217.37454223632812,
      "logps/rejected": -267.35211181640625,
      "loss": 0.0477,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.695262908935547,
      "rewards/margins": 7.281811714172363,
      "rewards/rejected": -13.977073669433594,
      "step": 26850
    },
    {
      "epoch": 4.901907108312802,
      "grad_norm": 14.330452919006348,
      "learning_rate": 1.6120389062213251e-06,
      "logits/chosen": 0.025823241099715233,
      "logits/rejected": 0.9402863383293152,
      "logps/chosen": -206.6955108642578,
      "logps/rejected": -264.61444091796875,
      "loss": 0.0416,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.943732261657715,
      "rewards/margins": 7.610853672027588,
      "rewards/rejected": -14.554586410522461,
      "step": 26860
    },
    {
      "epoch": 4.903732092344192,
      "grad_norm": 0.23038601875305176,
      "learning_rate": 1.5826757203156542e-06,
      "logits/chosen": 0.11270274221897125,
      "logits/rejected": 0.6359307169914246,
      "logps/chosen": -245.5277099609375,
      "logps/rejected": -301.3525390625,
      "loss": 0.1147,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.518644332885742,
      "rewards/margins": 7.691584587097168,
      "rewards/rejected": -16.210229873657227,
      "step": 26870
    },
    {
      "epoch": 4.905557076375581,
      "grad_norm": 3.4971702098846436,
      "learning_rate": 1.5533125344099836e-06,
      "logits/chosen": 0.2227087914943695,
      "logits/rejected": 0.8044487833976746,
      "logps/chosen": -209.6027374267578,
      "logps/rejected": -263.36212158203125,
      "loss": 0.0987,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.229968070983887,
      "rewards/margins": 7.358899116516113,
      "rewards/rejected": -14.5888671875,
      "step": 26880
    },
    {
      "epoch": 4.907382060406971,
      "grad_norm": 2.4409053325653076,
      "learning_rate": 1.5239493485043128e-06,
      "logits/chosen": 0.1337219923734665,
      "logits/rejected": 0.5999840497970581,
      "logps/chosen": -220.07015991210938,
      "logps/rejected": -261.9762878417969,
      "loss": 0.045,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.41257381439209,
      "rewards/margins": 7.090954780578613,
      "rewards/rejected": -14.503527641296387,
      "step": 26890
    },
    {
      "epoch": 4.909207044438361,
      "grad_norm": 0.04959140345454216,
      "learning_rate": 1.494586162598642e-06,
      "logits/chosen": 0.29750779271125793,
      "logits/rejected": 0.47655099630355835,
      "logps/chosen": -211.7162628173828,
      "logps/rejected": -280.0325012207031,
      "loss": 0.0279,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.091134071350098,
      "rewards/margins": 7.0094475746154785,
      "rewards/rejected": -14.100581169128418,
      "step": 26900
    },
    {
      "epoch": 4.911032028469751,
      "grad_norm": 0.2242291420698166,
      "learning_rate": 1.4652229766929713e-06,
      "logits/chosen": 0.4343961775302887,
      "logits/rejected": 0.8917628526687622,
      "logps/chosen": -207.64639282226562,
      "logps/rejected": -296.4254150390625,
      "loss": 0.023,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.966184139251709,
      "rewards/margins": 7.91577672958374,
      "rewards/rejected": -15.88196086883545,
      "step": 26910
    },
    {
      "epoch": 4.91285701250114,
      "grad_norm": 6.571715831756592,
      "learning_rate": 1.4358597907873007e-06,
      "logits/chosen": 0.3618541359901428,
      "logits/rejected": 0.8561110496520996,
      "logps/chosen": -207.72705078125,
      "logps/rejected": -264.34613037109375,
      "loss": 0.0462,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.624726295471191,
      "rewards/margins": 6.6001877784729,
      "rewards/rejected": -14.224912643432617,
      "step": 26920
    },
    {
      "epoch": 4.91468199653253,
      "grad_norm": 8.505162239074707,
      "learning_rate": 1.4064966048816298e-06,
      "logits/chosen": 0.39310458302497864,
      "logits/rejected": 0.8557591438293457,
      "logps/chosen": -219.8277130126953,
      "logps/rejected": -271.8808288574219,
      "loss": 0.0586,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.1375150680542,
      "rewards/margins": 6.703395843505859,
      "rewards/rejected": -14.840909957885742,
      "step": 26930
    },
    {
      "epoch": 4.91650698056392,
      "grad_norm": 1.2673600912094116,
      "learning_rate": 1.3771334189759588e-06,
      "logits/chosen": 0.04178820922970772,
      "logits/rejected": 0.8228772878646851,
      "logps/chosen": -240.62643432617188,
      "logps/rejected": -271.6715393066406,
      "loss": 0.0118,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.928175449371338,
      "rewards/margins": 7.811821937561035,
      "rewards/rejected": -14.739997863769531,
      "step": 26940
    },
    {
      "epoch": 4.91833196459531,
      "grad_norm": 7.293420314788818,
      "learning_rate": 1.3477702330702882e-06,
      "logits/chosen": 0.221111461520195,
      "logits/rejected": 1.0061850547790527,
      "logps/chosen": -245.70352172851562,
      "logps/rejected": -272.1395568847656,
      "loss": 0.0554,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.559803009033203,
      "rewards/margins": 7.158775329589844,
      "rewards/rejected": -14.71857738494873,
      "step": 26950
    },
    {
      "epoch": 4.920156948626699,
      "grad_norm": 3.1714515686035156,
      "learning_rate": 1.3184070471646175e-06,
      "logits/chosen": 0.21022078394889832,
      "logits/rejected": 0.8715003728866577,
      "logps/chosen": -234.52859497070312,
      "logps/rejected": -259.2148742675781,
      "loss": 0.1442,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.118020534515381,
      "rewards/margins": 6.339354515075684,
      "rewards/rejected": -13.457376480102539,
      "step": 26960
    },
    {
      "epoch": 4.921981932658089,
      "grad_norm": 1.01759672164917,
      "learning_rate": 1.2890438612589467e-06,
      "logits/chosen": 0.31586137413978577,
      "logits/rejected": 0.7510517835617065,
      "logps/chosen": -209.8982696533203,
      "logps/rejected": -287.59405517578125,
      "loss": 0.048,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.827341556549072,
      "rewards/margins": 7.777007102966309,
      "rewards/rejected": -14.604349136352539,
      "step": 26970
    },
    {
      "epoch": 4.923806916689479,
      "grad_norm": 10.897756576538086,
      "learning_rate": 1.259680675353276e-06,
      "logits/chosen": 0.22351041436195374,
      "logits/rejected": 0.7394488453865051,
      "logps/chosen": -236.3861846923828,
      "logps/rejected": -272.65765380859375,
      "loss": 0.1124,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.9119391441345215,
      "rewards/margins": 6.230437278747559,
      "rewards/rejected": -14.142376899719238,
      "step": 26980
    },
    {
      "epoch": 4.925631900720869,
      "grad_norm": 3.206345558166504,
      "learning_rate": 1.2303174894476052e-06,
      "logits/chosen": 0.19136540591716766,
      "logits/rejected": 0.4966849386692047,
      "logps/chosen": -240.66049194335938,
      "logps/rejected": -303.6812744140625,
      "loss": 0.0717,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.7013444900512695,
      "rewards/margins": 6.771307468414307,
      "rewards/rejected": -14.47265338897705,
      "step": 26990
    },
    {
      "epoch": 4.927456884752258,
      "grad_norm": 8.277960777282715,
      "learning_rate": 1.2009543035419344e-06,
      "logits/chosen": 0.21710708737373352,
      "logits/rejected": 0.7276609539985657,
      "logps/chosen": -223.7244873046875,
      "logps/rejected": -263.44158935546875,
      "loss": 0.1489,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.965959072113037,
      "rewards/margins": 7.1577935218811035,
      "rewards/rejected": -14.123751640319824,
      "step": 27000
    },
    {
      "epoch": 4.929281868783648,
      "grad_norm": 2.911708116531372,
      "learning_rate": 1.1715911176362636e-06,
      "logits/chosen": 0.29132598638534546,
      "logits/rejected": 0.917702853679657,
      "logps/chosen": -215.89572143554688,
      "logps/rejected": -268.07000732421875,
      "loss": 0.0715,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.688790798187256,
      "rewards/margins": 6.8185529708862305,
      "rewards/rejected": -14.507342338562012,
      "step": 27010
    },
    {
      "epoch": 4.931106852815038,
      "grad_norm": 12.908427238464355,
      "learning_rate": 1.1422279317305929e-06,
      "logits/chosen": 0.11533486843109131,
      "logits/rejected": 0.5556730628013611,
      "logps/chosen": -223.24020385742188,
      "logps/rejected": -248.6964111328125,
      "loss": 0.0831,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.55788516998291,
      "rewards/margins": 5.809739112854004,
      "rewards/rejected": -13.367622375488281,
      "step": 27020
    },
    {
      "epoch": 4.932931836846428,
      "grad_norm": 2.7438583374023438,
      "learning_rate": 1.112864745824922e-06,
      "logits/chosen": 0.15287744998931885,
      "logits/rejected": 0.583866536617279,
      "logps/chosen": -225.75094604492188,
      "logps/rejected": -287.3192443847656,
      "loss": 0.0358,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.879049777984619,
      "rewards/margins": 7.431332588195801,
      "rewards/rejected": -14.310381889343262,
      "step": 27030
    },
    {
      "epoch": 4.934756820877817,
      "grad_norm": 11.179754257202148,
      "learning_rate": 1.0835015599192513e-06,
      "logits/chosen": 0.04426049441099167,
      "logits/rejected": 0.7766177654266357,
      "logps/chosen": -218.0730438232422,
      "logps/rejected": -266.2944641113281,
      "loss": 0.0285,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.809444427490234,
      "rewards/margins": 7.014552116394043,
      "rewards/rejected": -13.823997497558594,
      "step": 27040
    },
    {
      "epoch": 4.936581804909207,
      "grad_norm": 9.886163711547852,
      "learning_rate": 1.0541383740135806e-06,
      "logits/chosen": 0.2291557341814041,
      "logits/rejected": 1.0989352464675903,
      "logps/chosen": -236.5181427001953,
      "logps/rejected": -271.58233642578125,
      "loss": 0.0257,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.833244323730469,
      "rewards/margins": 6.97551965713501,
      "rewards/rejected": -14.80876350402832,
      "step": 27050
    },
    {
      "epoch": 4.938406788940597,
      "grad_norm": 23.27989387512207,
      "learning_rate": 1.0247751881079098e-06,
      "logits/chosen": 0.23905472457408905,
      "logits/rejected": 0.5875884294509888,
      "logps/chosen": -225.9562530517578,
      "logps/rejected": -272.7524108886719,
      "loss": 0.1218,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.332457542419434,
      "rewards/margins": 6.741945743560791,
      "rewards/rejected": -14.07440185546875,
      "step": 27060
    },
    {
      "epoch": 4.940231772971987,
      "grad_norm": 1.4400831460952759,
      "learning_rate": 9.95412002202239e-07,
      "logits/chosen": 0.13500863313674927,
      "logits/rejected": 0.7148703336715698,
      "logps/chosen": -211.92379760742188,
      "logps/rejected": -256.8348388671875,
      "loss": 0.0955,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.1083807945251465,
      "rewards/margins": 6.7982587814331055,
      "rewards/rejected": -12.906641006469727,
      "step": 27070
    },
    {
      "epoch": 4.942056757003376,
      "grad_norm": 9.515047073364258,
      "learning_rate": 9.660488162965682e-07,
      "logits/chosen": 0.2936086058616638,
      "logits/rejected": 0.8273471593856812,
      "logps/chosen": -213.54672241210938,
      "logps/rejected": -263.8561706542969,
      "loss": 0.0449,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.194485664367676,
      "rewards/margins": 7.767042636871338,
      "rewards/rejected": -14.961527824401855,
      "step": 27080
    },
    {
      "epoch": 4.943881741034766,
      "grad_norm": 18.33655548095703,
      "learning_rate": 9.366856303908975e-07,
      "logits/chosen": 0.1428007185459137,
      "logits/rejected": 0.8333619236946106,
      "logps/chosen": -220.12423706054688,
      "logps/rejected": -248.3444366455078,
      "loss": 0.0824,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.331219673156738,
      "rewards/margins": 6.181766510009766,
      "rewards/rejected": -13.512983322143555,
      "step": 27090
    },
    {
      "epoch": 4.945706725066156,
      "grad_norm": 13.940164566040039,
      "learning_rate": 9.073224444852267e-07,
      "logits/chosen": 0.1874653398990631,
      "logits/rejected": 0.4810919165611267,
      "logps/chosen": -207.58740234375,
      "logps/rejected": -263.99346923828125,
      "loss": 0.0334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.367547512054443,
      "rewards/margins": 6.67893123626709,
      "rewards/rejected": -14.046478271484375,
      "step": 27100
    },
    {
      "epoch": 4.947531709097546,
      "grad_norm": 0.4135597050189972,
      "learning_rate": 8.779592585795559e-07,
      "logits/chosen": 0.3996472954750061,
      "logits/rejected": 0.6636312007904053,
      "logps/chosen": -216.68618774414062,
      "logps/rejected": -299.77679443359375,
      "loss": 0.0267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.475966453552246,
      "rewards/margins": 7.193737030029297,
      "rewards/rejected": -14.669703483581543,
      "step": 27110
    },
    {
      "epoch": 4.9493566931289354,
      "grad_norm": 0.8599246144294739,
      "learning_rate": 8.485960726738853e-07,
      "logits/chosen": 0.3337121903896332,
      "logits/rejected": 0.9924769401550293,
      "logps/chosen": -219.3223419189453,
      "logps/rejected": -264.19757080078125,
      "loss": 0.048,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.461260795593262,
      "rewards/margins": 6.8359503746032715,
      "rewards/rejected": -14.297212600708008,
      "step": 27120
    },
    {
      "epoch": 4.951181677160325,
      "grad_norm": 2.0678231716156006,
      "learning_rate": 8.192328867682143e-07,
      "logits/chosen": 0.2199866771697998,
      "logits/rejected": 0.5521007776260376,
      "logps/chosen": -214.8740997314453,
      "logps/rejected": -273.6453857421875,
      "loss": 0.1101,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.6540327072143555,
      "rewards/margins": 7.101629734039307,
      "rewards/rejected": -13.755663871765137,
      "step": 27130
    },
    {
      "epoch": 4.953006661191715,
      "grad_norm": 0.830569326877594,
      "learning_rate": 7.898697008625436e-07,
      "logits/chosen": 0.3585522770881653,
      "logits/rejected": 0.7834235429763794,
      "logps/chosen": -202.79541015625,
      "logps/rejected": -268.68829345703125,
      "loss": 0.0501,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.862468719482422,
      "rewards/margins": 6.885984897613525,
      "rewards/rejected": -13.748454093933105,
      "step": 27140
    },
    {
      "epoch": 4.954831645223104,
      "grad_norm": 5.299994945526123,
      "learning_rate": 7.605065149568729e-07,
      "logits/chosen": 0.26818299293518066,
      "logits/rejected": 0.788063645362854,
      "logps/chosen": -219.81478881835938,
      "logps/rejected": -258.73095703125,
      "loss": 0.1101,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.1631598472595215,
      "rewards/margins": 6.382777214050293,
      "rewards/rejected": -13.545938491821289,
      "step": 27150
    },
    {
      "epoch": 4.9566566292544945,
      "grad_norm": 4.893004417419434,
      "learning_rate": 7.311433290512021e-07,
      "logits/chosen": 0.22656822204589844,
      "logits/rejected": 0.6408511400222778,
      "logps/chosen": -241.82327270507812,
      "logps/rejected": -290.11175537109375,
      "loss": 0.181,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.417721748352051,
      "rewards/margins": 6.48535680770874,
      "rewards/rejected": -13.90307903289795,
      "step": 27160
    },
    {
      "epoch": 4.958481613285883,
      "grad_norm": 0.6086099147796631,
      "learning_rate": 7.017801431455313e-07,
      "logits/chosen": 0.0820314884185791,
      "logits/rejected": 0.8677277565002441,
      "logps/chosen": -234.7372283935547,
      "logps/rejected": -271.20025634765625,
      "loss": 0.0154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.978555202484131,
      "rewards/margins": 7.646977424621582,
      "rewards/rejected": -14.625534057617188,
      "step": 27170
    },
    {
      "epoch": 4.960306597317274,
      "grad_norm": 3.1028318405151367,
      "learning_rate": 6.724169572398606e-07,
      "logits/chosen": 0.13714198768138885,
      "logits/rejected": 0.5481131672859192,
      "logps/chosen": -214.52963256835938,
      "logps/rejected": -280.7120361328125,
      "loss": 0.0497,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.241927146911621,
      "rewards/margins": 7.163402557373047,
      "rewards/rejected": -14.405329704284668,
      "step": 27180
    },
    {
      "epoch": 4.962131581348663,
      "grad_norm": 3.625180721282959,
      "learning_rate": 6.430537713341899e-07,
      "logits/chosen": 0.2922200560569763,
      "logits/rejected": 0.9666428565979004,
      "logps/chosen": -214.96743774414062,
      "logps/rejected": -260.64459228515625,
      "loss": 0.0656,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.061132907867432,
      "rewards/margins": 7.093170166015625,
      "rewards/rejected": -14.154302597045898,
      "step": 27190
    },
    {
      "epoch": 4.963956565380053,
      "grad_norm": 0.9486343860626221,
      "learning_rate": 6.13690585428519e-07,
      "logits/chosen": 0.37375926971435547,
      "logits/rejected": 0.7419144511222839,
      "logps/chosen": -221.3235321044922,
      "logps/rejected": -273.2692565917969,
      "loss": 0.0177,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.491405487060547,
      "rewards/margins": 6.744903564453125,
      "rewards/rejected": -14.236307144165039,
      "step": 27200
    },
    {
      "epoch": 4.965781549411442,
      "grad_norm": 3.3876941204071045,
      "learning_rate": 5.843273995228483e-07,
      "logits/chosen": 0.04680207744240761,
      "logits/rejected": 0.529808759689331,
      "logps/chosen": -219.13217163085938,
      "logps/rejected": -280.52667236328125,
      "loss": 0.0374,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.4808759689331055,
      "rewards/margins": 7.297377586364746,
      "rewards/rejected": -14.7782564163208,
      "step": 27210
    },
    {
      "epoch": 4.967606533442832,
      "grad_norm": 12.873234748840332,
      "learning_rate": 5.549642136171775e-07,
      "logits/chosen": 0.3394485414028168,
      "logits/rejected": 0.7263755798339844,
      "logps/chosen": -224.99624633789062,
      "logps/rejected": -270.73333740234375,
      "loss": 0.0458,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.007237434387207,
      "rewards/margins": 6.823936462402344,
      "rewards/rejected": -14.83117389678955,
      "step": 27220
    },
    {
      "epoch": 4.969431517474222,
      "grad_norm": 13.691913604736328,
      "learning_rate": 5.256010277115067e-07,
      "logits/chosen": 0.3240908980369568,
      "logits/rejected": 0.6997705101966858,
      "logps/chosen": -226.41244506835938,
      "logps/rejected": -272.2950744628906,
      "loss": 0.0581,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.484217166900635,
      "rewards/margins": 6.605214595794678,
      "rewards/rejected": -14.089433670043945,
      "step": 27230
    },
    {
      "epoch": 4.971256501505612,
      "grad_norm": 0.21451319754123688,
      "learning_rate": 4.96237841805836e-07,
      "logits/chosen": 0.45778241753578186,
      "logits/rejected": 0.9984415173530579,
      "logps/chosen": -241.2151641845703,
      "logps/rejected": -279.8736267089844,
      "loss": 0.1867,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -8.10105037689209,
      "rewards/margins": 6.380379676818848,
      "rewards/rejected": -14.48143196105957,
      "step": 27240
    },
    {
      "epoch": 4.973081485537001,
      "grad_norm": 14.783014297485352,
      "learning_rate": 4.6687465590016526e-07,
      "logits/chosen": 0.10323740541934967,
      "logits/rejected": 0.37939175963401794,
      "logps/chosen": -221.20156860351562,
      "logps/rejected": -277.3890380859375,
      "loss": 0.0932,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.427609443664551,
      "rewards/margins": 6.52892541885376,
      "rewards/rejected": -13.956533432006836,
      "step": 27250
    },
    {
      "epoch": 4.974906469568391,
      "grad_norm": 12.756345748901367,
      "learning_rate": 4.3751146999449443e-07,
      "logits/chosen": 0.2226497232913971,
      "logits/rejected": 0.9422756433486938,
      "logps/chosen": -244.1654052734375,
      "logps/rejected": -276.4306335449219,
      "loss": 0.0569,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.360284328460693,
      "rewards/margins": 7.258836269378662,
      "rewards/rejected": -14.619120597839355,
      "step": 27260
    },
    {
      "epoch": 4.976731453599781,
      "grad_norm": 0.5048885345458984,
      "learning_rate": 4.0814828408882367e-07,
      "logits/chosen": -0.009740397334098816,
      "logits/rejected": 0.6060703992843628,
      "logps/chosen": -233.3943634033203,
      "logps/rejected": -273.9800720214844,
      "loss": 0.0249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.320472717285156,
      "rewards/margins": 7.168992519378662,
      "rewards/rejected": -14.489465713500977,
      "step": 27270
    },
    {
      "epoch": 4.978556437631171,
      "grad_norm": 27.669864654541016,
      "learning_rate": 3.787850981831529e-07,
      "logits/chosen": 0.13083967566490173,
      "logits/rejected": 0.8109709024429321,
      "logps/chosen": -211.5386199951172,
      "logps/rejected": -257.2644348144531,
      "loss": 0.0358,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.546581268310547,
      "rewards/margins": 7.402968406677246,
      "rewards/rejected": -13.949549674987793,
      "step": 27280
    },
    {
      "epoch": 4.98038142166256,
      "grad_norm": 1.304395318031311,
      "learning_rate": 3.494219122774822e-07,
      "logits/chosen": 0.37553077936172485,
      "logits/rejected": 0.7497507929801941,
      "logps/chosen": -213.3828125,
      "logps/rejected": -275.9756774902344,
      "loss": 0.0593,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.6052565574646,
      "rewards/margins": 7.157078742980957,
      "rewards/rejected": -14.762334823608398,
      "step": 27290
    },
    {
      "epoch": 4.98220640569395,
      "grad_norm": 2.948521137237549,
      "learning_rate": 3.2005872637181137e-07,
      "logits/chosen": 0.2366601526737213,
      "logits/rejected": 0.7160066366195679,
      "logps/chosen": -200.28790283203125,
      "logps/rejected": -251.33724975585938,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.2175068855285645,
      "rewards/margins": 6.984679222106934,
      "rewards/rejected": -13.202186584472656,
      "step": 27300
    },
    {
      "epoch": 4.98403138972534,
      "grad_norm": 1.760548710823059,
      "learning_rate": 2.906955404661406e-07,
      "logits/chosen": 0.1758432239294052,
      "logits/rejected": 0.8818506002426147,
      "logps/chosen": -204.9741973876953,
      "logps/rejected": -258.2903137207031,
      "loss": 0.045,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -6.070961952209473,
      "rewards/margins": 7.488022804260254,
      "rewards/rejected": -13.558985710144043,
      "step": 27310
    },
    {
      "epoch": 4.98585637375673,
      "grad_norm": 18.9331111907959,
      "learning_rate": 2.6133235456046983e-07,
      "logits/chosen": 0.4566604495048523,
      "logits/rejected": 0.8835183382034302,
      "logps/chosen": -220.5006103515625,
      "logps/rejected": -259.1303405761719,
      "loss": 0.0932,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.155760288238525,
      "rewards/margins": 6.311740875244141,
      "rewards/rejected": -13.467500686645508,
      "step": 27320
    },
    {
      "epoch": 4.987681357788119,
      "grad_norm": 3.755070924758911,
      "learning_rate": 2.3196916865479906e-07,
      "logits/chosen": 0.07430395483970642,
      "logits/rejected": 0.779922604560852,
      "logps/chosen": -230.7089385986328,
      "logps/rejected": -266.5256652832031,
      "loss": 0.1085,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.727198600769043,
      "rewards/margins": 6.785805702209473,
      "rewards/rejected": -14.5130033493042,
      "step": 27330
    },
    {
      "epoch": 4.989506341819509,
      "grad_norm": 7.013920307159424,
      "learning_rate": 2.0260598274912827e-07,
      "logits/chosen": 0.06315237283706665,
      "logits/rejected": 0.7597932815551758,
      "logps/chosen": -242.55331420898438,
      "logps/rejected": -280.3608093261719,
      "loss": 0.0394,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.332980155944824,
      "rewards/margins": 7.8562469482421875,
      "rewards/rejected": -15.189227104187012,
      "step": 27340
    },
    {
      "epoch": 4.991331325850899,
      "grad_norm": 2.776839017868042,
      "learning_rate": 1.7324279684345753e-07,
      "logits/chosen": 0.47683796286582947,
      "logits/rejected": 0.8750171661376953,
      "logps/chosen": -195.2264404296875,
      "logps/rejected": -266.02349853515625,
      "loss": 0.0772,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.400259971618652,
      "rewards/margins": 6.917187690734863,
      "rewards/rejected": -14.317448616027832,
      "step": 27350
    },
    {
      "epoch": 4.993156309882289,
      "grad_norm": 0.9318731427192688,
      "learning_rate": 1.4387961093778676e-07,
      "logits/chosen": 0.2897189259529114,
      "logits/rejected": 0.5171542763710022,
      "logps/chosen": -217.93051147460938,
      "logps/rejected": -278.0631408691406,
      "loss": 0.0651,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.964312553405762,
      "rewards/margins": 6.377403736114502,
      "rewards/rejected": -13.341715812683105,
      "step": 27360
    },
    {
      "epoch": 4.994981293913678,
      "grad_norm": 3.958313465118408,
      "learning_rate": 1.1451642503211599e-07,
      "logits/chosen": 0.18074668943881989,
      "logits/rejected": 0.5729132294654846,
      "logps/chosen": -214.3279266357422,
      "logps/rejected": -272.8865661621094,
      "loss": 0.1155,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.833387851715088,
      "rewards/margins": 6.608508110046387,
      "rewards/rejected": -13.44189453125,
      "step": 27370
    },
    {
      "epoch": 4.996806277945068,
      "grad_norm": 1.059881329536438,
      "learning_rate": 8.515323912644523e-08,
      "logits/chosen": 0.3477891981601715,
      "logits/rejected": 0.9809501767158508,
      "logps/chosen": -232.5937042236328,
      "logps/rejected": -269.220947265625,
      "loss": 0.0297,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.935923099517822,
      "rewards/margins": 6.9469313621521,
      "rewards/rejected": -14.882853507995605,
      "step": 27380
    },
    {
      "epoch": 4.998631261976458,
      "grad_norm": 7.035699367523193,
      "learning_rate": 5.579005322077446e-08,
      "logits/chosen": 0.24554535746574402,
      "logits/rejected": 0.7541447877883911,
      "logps/chosen": -220.95571899414062,
      "logps/rejected": -269.0773010253906,
      "loss": 0.0301,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.273550510406494,
      "rewards/margins": 6.722817897796631,
      "rewards/rejected": -13.996368408203125,
      "step": 27390
    }
  ],
  "logging_steps": 10,
  "max_steps": 27395,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
