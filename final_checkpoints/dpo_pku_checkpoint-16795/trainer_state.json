{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.999255841643102,
  "eval_steps": 500.0,
  "global_step": 16795,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0002976633427593392,
      "grad_norm": 1.97544264793396,
      "learning_rate": 5.333333333333335e-07,
      "logits/chosen": -0.9510366320610046,
      "logits/rejected": -0.905555009841919,
      "logps/chosen": -154.7144775390625,
      "logps/rejected": -170.7728729248047,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.002976633427593392,
      "grad_norm": 1.7126435041427612,
      "learning_rate": 4.800000000000001e-06,
      "logits/chosen": -0.9835522174835205,
      "logits/rejected": -0.9712731242179871,
      "logps/chosen": -184.94203186035156,
      "logps/rejected": -188.027587890625,
      "loss": 0.6929,
      "rewards/accuracies": 0.4444444477558136,
      "rewards/chosen": 0.0032544720452278852,
      "rewards/margins": 0.00042697586468420923,
      "rewards/rejected": 0.0028274962678551674,
      "step": 10
    },
    {
      "epoch": 0.005953266855186784,
      "grad_norm": 1.6649776697158813,
      "learning_rate": 1.0133333333333335e-05,
      "logits/chosen": -0.9204214811325073,
      "logits/rejected": -0.9574615359306335,
      "logps/chosen": -189.01974487304688,
      "logps/rejected": -198.52798461914062,
      "loss": 0.6929,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.008443922735750675,
      "rewards/margins": 0.0005149078788235784,
      "rewards/rejected": 0.007929014973342419,
      "step": 20
    },
    {
      "epoch": 0.008929900282780175,
      "grad_norm": 1.3606950044631958,
      "learning_rate": 1.546666666666667e-05,
      "logits/chosen": -0.9789856672286987,
      "logits/rejected": -1.01932692527771,
      "logps/chosen": -169.69821166992188,
      "logps/rejected": -184.5213165283203,
      "loss": 0.6947,
      "rewards/accuracies": 0.42500001192092896,
      "rewards/chosen": 0.0037933923304080963,
      "rewards/margins": -0.003012128174304962,
      "rewards/rejected": 0.0068055205047130585,
      "step": 30
    },
    {
      "epoch": 0.011906533710373568,
      "grad_norm": 2.048383951187134,
      "learning_rate": 2.08e-05,
      "logits/chosen": -0.9430310130119324,
      "logits/rejected": -0.9449831247329712,
      "logps/chosen": -178.51254272460938,
      "logps/rejected": -174.51132202148438,
      "loss": 0.6942,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 0.031069252640008926,
      "rewards/margins": -0.0016968637937679887,
      "rewards/rejected": 0.03276611492037773,
      "step": 40
    },
    {
      "epoch": 0.01488316713796696,
      "grad_norm": 1.7765992879867554,
      "learning_rate": 2.6133333333333336e-05,
      "logits/chosen": -0.9742186665534973,
      "logits/rejected": -0.9925459027290344,
      "logps/chosen": -169.85745239257812,
      "logps/rejected": -180.4099884033203,
      "loss": 0.6955,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": 0.06532981246709824,
      "rewards/margins": -0.0039515020325779915,
      "rewards/rejected": 0.06928131729364395,
      "step": 50
    },
    {
      "epoch": 0.01785980056556035,
      "grad_norm": 1.7423672676086426,
      "learning_rate": 3.146666666666667e-05,
      "logits/chosen": -1.0018701553344727,
      "logits/rejected": -0.9946697354316711,
      "logps/chosen": -167.08816528320312,
      "logps/rejected": -163.4634246826172,
      "loss": 0.6947,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.03358091786503792,
      "rewards/margins": -0.0025692316703498363,
      "rewards/rejected": 0.03615015000104904,
      "step": 60
    },
    {
      "epoch": 0.020836433993153745,
      "grad_norm": 1.5860952138900757,
      "learning_rate": 3.680000000000001e-05,
      "logits/chosen": -0.9841923713684082,
      "logits/rejected": -0.9790522456169128,
      "logps/chosen": -174.56350708007812,
      "logps/rejected": -164.89637756347656,
      "loss": 0.6897,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": -0.027018612250685692,
      "rewards/margins": 0.008889751508831978,
      "rewards/rejected": -0.03590837121009827,
      "step": 70
    },
    {
      "epoch": 0.023813067420747135,
      "grad_norm": 1.7679237127304077,
      "learning_rate": 4.213333333333333e-05,
      "logits/chosen": -0.9711292386054993,
      "logits/rejected": -0.9751437306404114,
      "logps/chosen": -177.5792999267578,
      "logps/rejected": -185.33543395996094,
      "loss": 0.6983,
      "rewards/accuracies": 0.4124999940395355,
      "rewards/chosen": -0.14769287407398224,
      "rewards/margins": -0.007324377540498972,
      "rewards/rejected": -0.1403684765100479,
      "step": 80
    },
    {
      "epoch": 0.026789700848340526,
      "grad_norm": 1.5397602319717407,
      "learning_rate": 4.746666666666668e-05,
      "logits/chosen": -0.9335389137268066,
      "logits/rejected": -0.9229442477226257,
      "logps/chosen": -168.38851928710938,
      "logps/rejected": -176.44468688964844,
      "loss": 0.6955,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -0.01575528085231781,
      "rewards/margins": -0.0014349553966894746,
      "rewards/rejected": -0.014320326037704945,
      "step": 90
    },
    {
      "epoch": 0.02976633427593392,
      "grad_norm": 1.5447523593902588,
      "learning_rate": 5.280000000000001e-05,
      "logits/chosen": -1.0285013914108276,
      "logits/rejected": -0.9807041883468628,
      "logps/chosen": -167.16383361816406,
      "logps/rejected": -159.71099853515625,
      "loss": 0.6815,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.044532500207424164,
      "rewards/margins": 0.028975840657949448,
      "rewards/rejected": 0.015556665137410164,
      "step": 100
    },
    {
      "epoch": 0.03274296770352731,
      "grad_norm": 2.206000566482544,
      "learning_rate": 5.813333333333334e-05,
      "logits/chosen": -0.9630428552627563,
      "logits/rejected": -0.9944350123405457,
      "logps/chosen": -162.701904296875,
      "logps/rejected": -182.40036010742188,
      "loss": 0.6795,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.03241654112935066,
      "rewards/margins": 0.0356726348400116,
      "rewards/rejected": -0.0032560918480157852,
      "step": 110
    },
    {
      "epoch": 0.0357196011311207,
      "grad_norm": 2.146397829055786,
      "learning_rate": 6.346666666666667e-05,
      "logits/chosen": -0.956514835357666,
      "logits/rejected": -1.0266966819763184,
      "logps/chosen": -158.4449005126953,
      "logps/rejected": -193.2795867919922,
      "loss": 0.703,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -0.007884184829890728,
      "rewards/margins": -0.007425324525684118,
      "rewards/rejected": -0.00045885919826105237,
      "step": 120
    },
    {
      "epoch": 0.03869623455871409,
      "grad_norm": 2.348820686340332,
      "learning_rate": 6.88e-05,
      "logits/chosen": -0.968453049659729,
      "logits/rejected": -0.9952751398086548,
      "logps/chosen": -167.77294921875,
      "logps/rejected": -179.6993865966797,
      "loss": 0.6959,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.045824937522411346,
      "rewards/margins": 0.018688352778553963,
      "rewards/rejected": 0.027136588469147682,
      "step": 130
    },
    {
      "epoch": 0.04167286798630749,
      "grad_norm": 2.2695069313049316,
      "learning_rate": 7.413333333333334e-05,
      "logits/chosen": -0.9038416743278503,
      "logits/rejected": -0.9478672742843628,
      "logps/chosen": -169.43814086914062,
      "logps/rejected": -184.87356567382812,
      "loss": 0.6589,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.11016444861888885,
      "rewards/margins": 0.08506635576486588,
      "rewards/rejected": -0.19523079693317413,
      "step": 140
    },
    {
      "epoch": 0.04464950141390088,
      "grad_norm": 2.450434684753418,
      "learning_rate": 7.946666666666667e-05,
      "logits/chosen": -0.9438220262527466,
      "logits/rejected": -1.0125504732131958,
      "logps/chosen": -164.79946899414062,
      "logps/rejected": -193.1412811279297,
      "loss": 0.6918,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -0.21319468319416046,
      "rewards/margins": 0.01688223145902157,
      "rewards/rejected": -0.23007690906524658,
      "step": 150
    },
    {
      "epoch": 0.04762613484149427,
      "grad_norm": 2.376167058944702,
      "learning_rate": 7.995674376689697e-05,
      "logits/chosen": -0.9413480758666992,
      "logits/rejected": -0.9661027789115906,
      "logps/chosen": -172.6368408203125,
      "logps/rejected": -180.1016387939453,
      "loss": 0.6883,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -0.1795213520526886,
      "rewards/margins": 0.038217514753341675,
      "rewards/rejected": -0.21773883700370789,
      "step": 160
    },
    {
      "epoch": 0.05060276826908766,
      "grad_norm": 2.7265970706939697,
      "learning_rate": 7.990868128567137e-05,
      "logits/chosen": -0.957495391368866,
      "logits/rejected": -1.0288562774658203,
      "logps/chosen": -171.9680938720703,
      "logps/rejected": -197.48313903808594,
      "loss": 0.6434,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.20851728320121765,
      "rewards/margins": 0.14014442265033722,
      "rewards/rejected": -0.34866172075271606,
      "step": 170
    },
    {
      "epoch": 0.05357940169668105,
      "grad_norm": 2.3777472972869873,
      "learning_rate": 7.986061880444579e-05,
      "logits/chosen": -0.9913250803947449,
      "logits/rejected": -0.9880916476249695,
      "logps/chosen": -159.11944580078125,
      "logps/rejected": -169.5267333984375,
      "loss": 0.6711,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.0002770475985016674,
      "rewards/margins": 0.07388277351856232,
      "rewards/rejected": -0.07415983080863953,
      "step": 180
    },
    {
      "epoch": 0.05655603512427444,
      "grad_norm": 3.111677646636963,
      "learning_rate": 7.98125563232202e-05,
      "logits/chosen": -0.9192209243774414,
      "logits/rejected": -0.9792606234550476,
      "logps/chosen": -162.19920349121094,
      "logps/rejected": -195.2390594482422,
      "loss": 0.7031,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.05923796817660332,
      "rewards/margins": 0.029822399839758873,
      "rewards/rejected": 0.029415568336844444,
      "step": 190
    },
    {
      "epoch": 0.05953266855186784,
      "grad_norm": 2.823662281036377,
      "learning_rate": 7.97644938419946e-05,
      "logits/chosen": -0.9105769991874695,
      "logits/rejected": -0.9047324061393738,
      "logps/chosen": -179.94039916992188,
      "logps/rejected": -181.86105346679688,
      "loss": 0.689,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": 0.28920549154281616,
      "rewards/margins": 0.03771170973777771,
      "rewards/rejected": 0.25149381160736084,
      "step": 200
    },
    {
      "epoch": 0.06250930197946122,
      "grad_norm": 3.0660581588745117,
      "learning_rate": 7.971643136076901e-05,
      "logits/chosen": -0.9464628100395203,
      "logits/rejected": -0.9046727418899536,
      "logps/chosen": -180.38546752929688,
      "logps/rejected": -168.7027587890625,
      "loss": 0.7112,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 1.0506813526153564,
      "rewards/margins": 0.02564064785838127,
      "rewards/rejected": 1.025040864944458,
      "step": 210
    },
    {
      "epoch": 0.06548593540705462,
      "grad_norm": 2.766099452972412,
      "learning_rate": 7.966836887954342e-05,
      "logits/chosen": -0.9895184636116028,
      "logits/rejected": -1.0074342489242554,
      "logps/chosen": -150.1037139892578,
      "logps/rejected": -158.5993194580078,
      "loss": 0.7165,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.9981917142868042,
      "rewards/margins": 0.0182650126516819,
      "rewards/rejected": 0.9799267053604126,
      "step": 220
    },
    {
      "epoch": 0.06846256883464802,
      "grad_norm": 3.154008150100708,
      "learning_rate": 7.962030639831782e-05,
      "logits/chosen": -0.9862085580825806,
      "logits/rejected": -0.9751470685005188,
      "logps/chosen": -170.73194885253906,
      "logps/rejected": -163.298828125,
      "loss": 0.7621,
      "rewards/accuracies": 0.38749998807907104,
      "rewards/chosen": 0.9260025024414062,
      "rewards/margins": -0.08940442651510239,
      "rewards/rejected": 1.015406847000122,
      "step": 230
    },
    {
      "epoch": 0.0714392022622414,
      "grad_norm": 2.4700520038604736,
      "learning_rate": 7.957224391709222e-05,
      "logits/chosen": -0.970921516418457,
      "logits/rejected": -1.0110750198364258,
      "logps/chosen": -165.84706115722656,
      "logps/rejected": -177.6613006591797,
      "loss": 0.6531,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.4420791268348694,
      "rewards/margins": 0.1264457404613495,
      "rewards/rejected": 0.3156333565711975,
      "step": 240
    },
    {
      "epoch": 0.0744158356898348,
      "grad_norm": 2.689657688140869,
      "learning_rate": 7.952418143586664e-05,
      "logits/chosen": -1.08817458152771,
      "logits/rejected": -1.1149386167526245,
      "logps/chosen": -188.354736328125,
      "logps/rejected": -198.67684936523438,
      "loss": 0.6904,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.3288862109184265,
      "rewards/margins": 0.0854911282658577,
      "rewards/rejected": -0.414377361536026,
      "step": 250
    },
    {
      "epoch": 0.07739246911742818,
      "grad_norm": 5.787015914916992,
      "learning_rate": 7.947611895464104e-05,
      "logits/chosen": -1.0136115550994873,
      "logits/rejected": -1.0560086965560913,
      "logps/chosen": -196.80886840820312,
      "logps/rejected": -209.2880859375,
      "loss": 0.6169,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.415717750787735,
      "rewards/margins": 0.26595693826675415,
      "rewards/rejected": -0.6816747188568115,
      "step": 260
    },
    {
      "epoch": 0.08036910254502158,
      "grad_norm": 2.873713970184326,
      "learning_rate": 7.942805647341545e-05,
      "logits/chosen": -1.1192495822906494,
      "logits/rejected": -1.1335203647613525,
      "logps/chosen": -173.1127166748047,
      "logps/rejected": -181.6311492919922,
      "loss": 0.6267,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.1280936449766159,
      "rewards/margins": 0.23184438049793243,
      "rewards/rejected": -0.10375072062015533,
      "step": 270
    },
    {
      "epoch": 0.08334573597261498,
      "grad_norm": 3.365745782852173,
      "learning_rate": 7.937999399218985e-05,
      "logits/chosen": -1.0091089010238647,
      "logits/rejected": -1.049690842628479,
      "logps/chosen": -172.48867797851562,
      "logps/rejected": -182.5546875,
      "loss": 0.6559,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.002890709089115262,
      "rewards/margins": 0.20269417762756348,
      "rewards/rejected": -0.19980347156524658,
      "step": 280
    },
    {
      "epoch": 0.08632236940020836,
      "grad_norm": 3.2478559017181396,
      "learning_rate": 7.933193151096426e-05,
      "logits/chosen": -1.0128166675567627,
      "logits/rejected": -1.028148889541626,
      "logps/chosen": -169.92483520507812,
      "logps/rejected": -179.04251098632812,
      "loss": 0.6434,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.08573677390813828,
      "rewards/margins": 0.3319632112979889,
      "rewards/rejected": -0.41770005226135254,
      "step": 290
    },
    {
      "epoch": 0.08929900282780176,
      "grad_norm": 3.0728554725646973,
      "learning_rate": 7.928386902973867e-05,
      "logits/chosen": -1.0704282522201538,
      "logits/rejected": -1.0754828453063965,
      "logps/chosen": -193.08335876464844,
      "logps/rejected": -194.8098907470703,
      "loss": 0.6677,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.4289863109588623,
      "rewards/margins": 0.1558370292186737,
      "rewards/rejected": -0.5848233103752136,
      "step": 300
    },
    {
      "epoch": 0.09227563625539514,
      "grad_norm": 2.8616507053375244,
      "learning_rate": 7.923580654851307e-05,
      "logits/chosen": -1.0071215629577637,
      "logits/rejected": -1.0155824422836304,
      "logps/chosen": -190.72645568847656,
      "logps/rejected": -202.55294799804688,
      "loss": 0.6819,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.37332823872566223,
      "rewards/margins": 0.1599459946155548,
      "rewards/rejected": -0.533274233341217,
      "step": 310
    },
    {
      "epoch": 0.09525226968298854,
      "grad_norm": 2.990114450454712,
      "learning_rate": 7.918774406728748e-05,
      "logits/chosen": -0.9849323034286499,
      "logits/rejected": -1.0379326343536377,
      "logps/chosen": -171.3312530517578,
      "logps/rejected": -192.60462951660156,
      "loss": 0.7065,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.03837955370545387,
      "rewards/margins": 0.06760191172361374,
      "rewards/rejected": -0.10598146915435791,
      "step": 320
    },
    {
      "epoch": 0.09822890311058192,
      "grad_norm": 2.412771463394165,
      "learning_rate": 7.913968158606188e-05,
      "logits/chosen": -0.984440803527832,
      "logits/rejected": -0.9929409027099609,
      "logps/chosen": -171.7171173095703,
      "logps/rejected": -186.6527862548828,
      "loss": 0.7032,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.19431470334529877,
      "rewards/margins": 0.08715585619211197,
      "rewards/rejected": -0.28147056698799133,
      "step": 330
    },
    {
      "epoch": 0.10120553653817532,
      "grad_norm": 2.618248224258423,
      "learning_rate": 7.909642535295886e-05,
      "logits/chosen": -0.9575764536857605,
      "logits/rejected": -1.0031859874725342,
      "logps/chosen": -177.330810546875,
      "logps/rejected": -181.6828155517578,
      "loss": 0.6912,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -0.13773120939731598,
      "rewards/margins": 0.07663699984550476,
      "rewards/rejected": -0.21436822414398193,
      "step": 340
    },
    {
      "epoch": 0.10418216996576872,
      "grad_norm": 2.939518451690674,
      "learning_rate": 7.904836287173326e-05,
      "logits/chosen": -0.9433746337890625,
      "logits/rejected": -0.9446934461593628,
      "logps/chosen": -174.08151245117188,
      "logps/rejected": -181.84925842285156,
      "loss": 0.6295,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.08388446271419525,
      "rewards/margins": 0.17636674642562866,
      "rewards/rejected": -0.0924823060631752,
      "step": 350
    },
    {
      "epoch": 0.1071588033933621,
      "grad_norm": 2.48280668258667,
      "learning_rate": 7.900030039050767e-05,
      "logits/chosen": -0.9832180142402649,
      "logits/rejected": -0.9867054224014282,
      "logps/chosen": -174.16969299316406,
      "logps/rejected": -176.0292510986328,
      "loss": 0.7102,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.06016074866056442,
      "rewards/margins": 0.03910326957702637,
      "rewards/rejected": -0.09926404058933258,
      "step": 360
    },
    {
      "epoch": 0.1101354368209555,
      "grad_norm": 3.1915245056152344,
      "learning_rate": 7.895223790928208e-05,
      "logits/chosen": -1.0408469438552856,
      "logits/rejected": -1.0912656784057617,
      "logps/chosen": -155.93844604492188,
      "logps/rejected": -167.6665496826172,
      "loss": 0.6332,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.04771485552191734,
      "rewards/margins": 0.22228577733039856,
      "rewards/rejected": -0.17457088828086853,
      "step": 370
    },
    {
      "epoch": 0.11311207024854888,
      "grad_norm": 2.937253952026367,
      "learning_rate": 7.890417542805648e-05,
      "logits/chosen": -1.0393731594085693,
      "logits/rejected": -1.0898191928863525,
      "logps/chosen": -167.7630615234375,
      "logps/rejected": -170.76229858398438,
      "loss": 0.62,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.12750065326690674,
      "rewards/margins": 0.2573695778846741,
      "rewards/rejected": -0.3848702311515808,
      "step": 380
    },
    {
      "epoch": 0.11608870367614228,
      "grad_norm": 2.471139430999756,
      "learning_rate": 7.885611294683089e-05,
      "logits/chosen": -1.0828945636749268,
      "logits/rejected": -1.0763475894927979,
      "logps/chosen": -172.1783447265625,
      "logps/rejected": -178.06666564941406,
      "loss": 0.6354,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.4327860474586487,
      "rewards/margins": 0.24613416194915771,
      "rewards/rejected": -0.6789202094078064,
      "step": 390
    },
    {
      "epoch": 0.11906533710373568,
      "grad_norm": 2.7094128131866455,
      "learning_rate": 7.88080504656053e-05,
      "logits/chosen": -1.0004228353500366,
      "logits/rejected": -1.0098917484283447,
      "logps/chosen": -169.84475708007812,
      "logps/rejected": -176.4104766845703,
      "loss": 0.6634,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": -0.38363367319107056,
      "rewards/margins": 0.22632434964179993,
      "rewards/rejected": -0.6099580526351929,
      "step": 400
    },
    {
      "epoch": 0.12204197053132906,
      "grad_norm": 2.217038869857788,
      "learning_rate": 7.87599879843797e-05,
      "logits/chosen": -0.9203530550003052,
      "logits/rejected": -0.9727475047111511,
      "logps/chosen": -171.44802856445312,
      "logps/rejected": -193.774658203125,
      "loss": 0.6937,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": -0.45395976305007935,
      "rewards/margins": 0.1264556348323822,
      "rewards/rejected": -0.5804154276847839,
      "step": 410
    },
    {
      "epoch": 0.12501860395892245,
      "grad_norm": 3.4631705284118652,
      "learning_rate": 7.871192550315411e-05,
      "logits/chosen": -1.0087268352508545,
      "logits/rejected": -1.0261480808258057,
      "logps/chosen": -199.23716735839844,
      "logps/rejected": -200.53305053710938,
      "loss": 0.6907,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -0.79427170753479,
      "rewards/margins": 0.12730666995048523,
      "rewards/rejected": -0.9215785264968872,
      "step": 420
    },
    {
      "epoch": 0.12799523738651586,
      "grad_norm": 2.9832167625427246,
      "learning_rate": 7.866386302192851e-05,
      "logits/chosen": -1.06993567943573,
      "logits/rejected": -1.0728896856307983,
      "logps/chosen": -174.8734893798828,
      "logps/rejected": -176.91427612304688,
      "loss": 0.6467,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.4246671199798584,
      "rewards/margins": 0.19146637618541718,
      "rewards/rejected": -0.6161335110664368,
      "step": 430
    },
    {
      "epoch": 0.13097187081410924,
      "grad_norm": 2.7982845306396484,
      "learning_rate": 7.861580054070292e-05,
      "logits/chosen": -0.9216915369033813,
      "logits/rejected": -0.9821169972419739,
      "logps/chosen": -172.2592010498047,
      "logps/rejected": -200.0681610107422,
      "loss": 0.6644,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.5701925754547119,
      "rewards/margins": 0.2426951378583908,
      "rewards/rejected": -0.8128877878189087,
      "step": 440
    },
    {
      "epoch": 0.13394850424170263,
      "grad_norm": 1.7354755401611328,
      "learning_rate": 7.856773805947733e-05,
      "logits/chosen": -1.0288383960723877,
      "logits/rejected": -1.0009849071502686,
      "logps/chosen": -186.32308959960938,
      "logps/rejected": -174.6028594970703,
      "loss": 0.6661,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.5015429258346558,
      "rewards/margins": 0.2975022792816162,
      "rewards/rejected": -0.7990452647209167,
      "step": 450
    },
    {
      "epoch": 0.13692513766929604,
      "grad_norm": 2.211561441421509,
      "learning_rate": 7.851967557825173e-05,
      "logits/chosen": -1.0015113353729248,
      "logits/rejected": -1.028435230255127,
      "logps/chosen": -166.27609252929688,
      "logps/rejected": -183.45529174804688,
      "loss": 0.6488,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.26105445623397827,
      "rewards/margins": 0.3120916187763214,
      "rewards/rejected": -0.5731460452079773,
      "step": 460
    },
    {
      "epoch": 0.13990177109688942,
      "grad_norm": 2.948779344558716,
      "learning_rate": 7.847161309702614e-05,
      "logits/chosen": -0.9748035669326782,
      "logits/rejected": -1.0196163654327393,
      "logps/chosen": -188.53207397460938,
      "logps/rejected": -204.900634765625,
      "loss": 0.6386,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.5674103498458862,
      "rewards/margins": 0.32748064398765564,
      "rewards/rejected": -0.8948909044265747,
      "step": 470
    },
    {
      "epoch": 0.1428784045244828,
      "grad_norm": 3.9680116176605225,
      "learning_rate": 7.842355061580054e-05,
      "logits/chosen": -0.9629905819892883,
      "logits/rejected": -0.955121636390686,
      "logps/chosen": -170.54959106445312,
      "logps/rejected": -173.6507568359375,
      "loss": 0.6569,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.1006336435675621,
      "rewards/margins": 0.2678309977054596,
      "rewards/rejected": -0.3684645891189575,
      "step": 480
    },
    {
      "epoch": 0.1458550379520762,
      "grad_norm": 3.2354209423065186,
      "learning_rate": 7.837548813457496e-05,
      "logits/chosen": -0.914117693901062,
      "logits/rejected": -0.8972886204719543,
      "logps/chosen": -186.12319946289062,
      "logps/rejected": -179.03634643554688,
      "loss": 0.6049,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.2860427498817444,
      "rewards/margins": 0.4015331268310547,
      "rewards/rejected": -0.6875758767127991,
      "step": 490
    },
    {
      "epoch": 0.1488316713796696,
      "grad_norm": 3.5085062980651855,
      "learning_rate": 7.832742565334937e-05,
      "logits/chosen": -0.8739452362060547,
      "logits/rejected": -0.9426606893539429,
      "logps/chosen": -179.56077575683594,
      "logps/rejected": -201.5625457763672,
      "loss": 0.695,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.8771244287490845,
      "rewards/margins": 0.16346754133701324,
      "rewards/rejected": -1.0405919551849365,
      "step": 500
    },
    {
      "epoch": 0.15180830480726298,
      "grad_norm": 2.2078168392181396,
      "learning_rate": 7.827936317212376e-05,
      "logits/chosen": -0.8981624841690063,
      "logits/rejected": -0.9396253824234009,
      "logps/chosen": -176.4405517578125,
      "logps/rejected": -190.9582977294922,
      "loss": 0.5637,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6050609946250916,
      "rewards/margins": 0.47252288460731506,
      "rewards/rejected": -1.077583909034729,
      "step": 510
    },
    {
      "epoch": 0.15478493823485637,
      "grad_norm": 3.2264060974121094,
      "learning_rate": 7.823130069089817e-05,
      "logits/chosen": -0.9145453572273254,
      "logits/rejected": -0.9752427339553833,
      "logps/chosen": -184.7347412109375,
      "logps/rejected": -203.63812255859375,
      "loss": 0.6711,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -0.9872763752937317,
      "rewards/margins": 0.32961881160736084,
      "rewards/rejected": -1.3168952465057373,
      "step": 520
    },
    {
      "epoch": 0.15776157166244978,
      "grad_norm": 2.4101102352142334,
      "learning_rate": 7.818323820967258e-05,
      "logits/chosen": -0.9524434208869934,
      "logits/rejected": -1.0187350511550903,
      "logps/chosen": -176.27590942382812,
      "logps/rejected": -197.5045623779297,
      "loss": 0.6216,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.9371352195739746,
      "rewards/margins": 0.4448825716972351,
      "rewards/rejected": -1.3820176124572754,
      "step": 530
    },
    {
      "epoch": 0.16073820509004316,
      "grad_norm": 3.1777913570404053,
      "learning_rate": 7.813517572844698e-05,
      "logits/chosen": -0.9833134412765503,
      "logits/rejected": -0.9930227398872375,
      "logps/chosen": -176.34083557128906,
      "logps/rejected": -183.41830444335938,
      "loss": 0.6656,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.7712720632553101,
      "rewards/margins": 0.3436856269836426,
      "rewards/rejected": -1.114957571029663,
      "step": 540
    },
    {
      "epoch": 0.16371483851763655,
      "grad_norm": 4.872098445892334,
      "learning_rate": 7.808711324722139e-05,
      "logits/chosen": -0.9165612459182739,
      "logits/rejected": -1.0014564990997314,
      "logps/chosen": -178.061279296875,
      "logps/rejected": -205.21969604492188,
      "loss": 0.6638,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.3626219034194946,
      "rewards/margins": 0.37613800168037415,
      "rewards/rejected": -1.7387597560882568,
      "step": 550
    },
    {
      "epoch": 0.16669147194522996,
      "grad_norm": 3.231657028198242,
      "learning_rate": 7.803905076599581e-05,
      "logits/chosen": -0.9038820266723633,
      "logits/rejected": -0.936784565448761,
      "logps/chosen": -195.9209442138672,
      "logps/rejected": -208.5529022216797,
      "loss": 0.6105,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.0513226985931396,
      "rewards/margins": 0.5290032625198364,
      "rewards/rejected": -1.5803260803222656,
      "step": 560
    },
    {
      "epoch": 0.16966810537282334,
      "grad_norm": 3.3276782035827637,
      "learning_rate": 7.799098828477021e-05,
      "logits/chosen": -0.9648796319961548,
      "logits/rejected": -1.013214111328125,
      "logps/chosen": -178.2971954345703,
      "logps/rejected": -192.22442626953125,
      "loss": 0.6767,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.1632386445999146,
      "rewards/margins": 0.2957770526409149,
      "rewards/rejected": -1.4590156078338623,
      "step": 570
    },
    {
      "epoch": 0.17264473880041672,
      "grad_norm": 3.617567300796509,
      "learning_rate": 7.794292580354462e-05,
      "logits/chosen": -0.9575145840644836,
      "logits/rejected": -0.987913966178894,
      "logps/chosen": -185.99624633789062,
      "logps/rejected": -189.38919067382812,
      "loss": 0.6463,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.124761700630188,
      "rewards/margins": 0.46474489569664,
      "rewards/rejected": -1.58950674533844,
      "step": 580
    },
    {
      "epoch": 0.1756213722280101,
      "grad_norm": 4.489593505859375,
      "learning_rate": 7.789486332231903e-05,
      "logits/chosen": -0.9545099139213562,
      "logits/rejected": -0.974839985370636,
      "logps/chosen": -193.79251098632812,
      "logps/rejected": -211.62368774414062,
      "loss": 0.6173,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.467455506324768,
      "rewards/margins": 0.4920113682746887,
      "rewards/rejected": -1.9594666957855225,
      "step": 590
    },
    {
      "epoch": 0.17859800565560352,
      "grad_norm": 2.4949886798858643,
      "learning_rate": 7.784680084109343e-05,
      "logits/chosen": -0.9128108024597168,
      "logits/rejected": -0.9748374223709106,
      "logps/chosen": -183.9274139404297,
      "logps/rejected": -203.71102905273438,
      "loss": 0.6659,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -1.0770280361175537,
      "rewards/margins": 0.36856457591056824,
      "rewards/rejected": -1.4455927610397339,
      "step": 600
    },
    {
      "epoch": 0.1815746390831969,
      "grad_norm": 3.405381917953491,
      "learning_rate": 7.779873835986784e-05,
      "logits/chosen": -0.9546470642089844,
      "logits/rejected": -1.034856915473938,
      "logps/chosen": -185.84268188476562,
      "logps/rejected": -216.48623657226562,
      "loss": 0.5922,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.3685486316680908,
      "rewards/margins": 0.5676943063735962,
      "rewards/rejected": -1.9362430572509766,
      "step": 610
    },
    {
      "epoch": 0.1845512725107903,
      "grad_norm": 3.6204590797424316,
      "learning_rate": 7.775067587864224e-05,
      "logits/chosen": -0.9249541163444519,
      "logits/rejected": -1.0599762201309204,
      "logps/chosen": -197.13902282714844,
      "logps/rejected": -229.19845581054688,
      "loss": 0.5974,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.464214563369751,
      "rewards/margins": 0.5578854084014893,
      "rewards/rejected": -2.0220999717712402,
      "step": 620
    },
    {
      "epoch": 0.1875279059383837,
      "grad_norm": 2.749572277069092,
      "learning_rate": 7.770261339741665e-05,
      "logits/chosen": -0.9156280755996704,
      "logits/rejected": -1.0273187160491943,
      "logps/chosen": -169.62713623046875,
      "logps/rejected": -196.82839965820312,
      "loss": 0.5418,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.176466703414917,
      "rewards/margins": 0.6518608927726746,
      "rewards/rejected": -1.8283274173736572,
      "step": 630
    },
    {
      "epoch": 0.19050453936597708,
      "grad_norm": 2.7754878997802734,
      "learning_rate": 7.765455091619106e-05,
      "logits/chosen": -0.9026187062263489,
      "logits/rejected": -0.9560136795043945,
      "logps/chosen": -174.38351440429688,
      "logps/rejected": -194.7316131591797,
      "loss": 0.5744,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.024950623512268,
      "rewards/margins": 0.5959762930870056,
      "rewards/rejected": -1.620926856994629,
      "step": 640
    },
    {
      "epoch": 0.19348117279357047,
      "grad_norm": 5.862923622131348,
      "learning_rate": 7.760648843496546e-05,
      "logits/chosen": -0.9968021512031555,
      "logits/rejected": -0.9867892265319824,
      "logps/chosen": -190.76683044433594,
      "logps/rejected": -190.50619506835938,
      "loss": 0.7177,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.3569055795669556,
      "rewards/margins": 0.28589099645614624,
      "rewards/rejected": -1.642796516418457,
      "step": 650
    },
    {
      "epoch": 0.19645780622116385,
      "grad_norm": 4.739604473114014,
      "learning_rate": 7.755842595373987e-05,
      "logits/chosen": -0.9824625253677368,
      "logits/rejected": -0.9926202893257141,
      "logps/chosen": -190.69532775878906,
      "logps/rejected": -203.76083374023438,
      "loss": 0.6153,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0234075784683228,
      "rewards/margins": 0.5921385884284973,
      "rewards/rejected": -1.6155459880828857,
      "step": 660
    },
    {
      "epoch": 0.19943443964875726,
      "grad_norm": 2.5659801959991455,
      "learning_rate": 7.751036347251427e-05,
      "logits/chosen": -0.9309913516044617,
      "logits/rejected": -1.0206174850463867,
      "logps/chosen": -170.10433959960938,
      "logps/rejected": -190.01498413085938,
      "loss": 0.583,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.2778047323226929,
      "rewards/margins": 0.6726195812225342,
      "rewards/rejected": -1.9504241943359375,
      "step": 670
    },
    {
      "epoch": 0.20241107307635064,
      "grad_norm": 2.9615776538848877,
      "learning_rate": 7.746230099128868e-05,
      "logits/chosen": -0.9020684361457825,
      "logits/rejected": -0.936504065990448,
      "logps/chosen": -183.88522338867188,
      "logps/rejected": -202.45692443847656,
      "loss": 0.5522,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0845253467559814,
      "rewards/margins": 0.6148979067802429,
      "rewards/rejected": -1.6994235515594482,
      "step": 680
    },
    {
      "epoch": 0.20538770650394403,
      "grad_norm": 3.461806535720825,
      "learning_rate": 7.741423851006309e-05,
      "logits/chosen": -0.9485286474227905,
      "logits/rejected": -0.9702765345573425,
      "logps/chosen": -173.98675537109375,
      "logps/rejected": -191.03182983398438,
      "loss": 0.6907,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.4379831850528717,
      "rewards/margins": 0.3887297511100769,
      "rewards/rejected": -0.8267129063606262,
      "step": 690
    },
    {
      "epoch": 0.20836433993153744,
      "grad_norm": 5.9101457595825195,
      "learning_rate": 7.736617602883749e-05,
      "logits/chosen": -1.0194669961929321,
      "logits/rejected": -0.9898695945739746,
      "logps/chosen": -174.93765258789062,
      "logps/rejected": -178.48829650878906,
      "loss": 0.6817,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.22791925072669983,
      "rewards/margins": 0.308280885219574,
      "rewards/rejected": -0.5362001657485962,
      "step": 700
    },
    {
      "epoch": 0.21134097335913082,
      "grad_norm": 2.7758631706237793,
      "learning_rate": 7.73181135476119e-05,
      "logits/chosen": -1.0191901922225952,
      "logits/rejected": -1.0281362533569336,
      "logps/chosen": -168.8032684326172,
      "logps/rejected": -178.01553344726562,
      "loss": 0.6253,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.12904545664787292,
      "rewards/margins": 0.37773269414901733,
      "rewards/rejected": -0.2486872673034668,
      "step": 710
    },
    {
      "epoch": 0.2143176067867242,
      "grad_norm": 4.965396881103516,
      "learning_rate": 7.72700510663863e-05,
      "logits/chosen": -0.9406469464302063,
      "logits/rejected": -1.0277373790740967,
      "logps/chosen": -176.27676391601562,
      "logps/rejected": -216.4818115234375,
      "loss": 0.6347,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7365702390670776,
      "rewards/margins": 0.5400412678718567,
      "rewards/rejected": -1.276611328125,
      "step": 720
    },
    {
      "epoch": 0.21729424021431762,
      "grad_norm": 4.202592849731445,
      "learning_rate": 7.722198858516073e-05,
      "logits/chosen": -0.9360367655754089,
      "logits/rejected": -0.9904929399490356,
      "logps/chosen": -160.16563415527344,
      "logps/rejected": -177.6678009033203,
      "loss": 0.6116,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.16316208243370056,
      "rewards/margins": 0.37947970628738403,
      "rewards/rejected": -0.5426417589187622,
      "step": 730
    },
    {
      "epoch": 0.220270873641911,
      "grad_norm": 3.8057427406311035,
      "learning_rate": 7.717392610393513e-05,
      "logits/chosen": -0.9534093141555786,
      "logits/rejected": -1.0084757804870605,
      "logps/chosen": -175.32095336914062,
      "logps/rejected": -205.91244506835938,
      "loss": 0.5547,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.5844454169273376,
      "rewards/margins": 0.7734547853469849,
      "rewards/rejected": -1.3579002618789673,
      "step": 740
    },
    {
      "epoch": 0.2232475070695044,
      "grad_norm": 4.009725093841553,
      "learning_rate": 7.712586362270952e-05,
      "logits/chosen": -0.8652759790420532,
      "logits/rejected": -0.9774764776229858,
      "logps/chosen": -177.88250732421875,
      "logps/rejected": -217.3863525390625,
      "loss": 0.4875,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0789291858673096,
      "rewards/margins": 0.8926212191581726,
      "rewards/rejected": -1.9715503454208374,
      "step": 750
    },
    {
      "epoch": 0.22622414049709777,
      "grad_norm": 5.155054092407227,
      "learning_rate": 7.707780114148393e-05,
      "logits/chosen": -0.8716312646865845,
      "logits/rejected": -0.9841688275337219,
      "logps/chosen": -166.1128387451172,
      "logps/rejected": -205.242431640625,
      "loss": 0.612,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.8682360649108887,
      "rewards/margins": 1.1182596683502197,
      "rewards/rejected": -1.9864956140518188,
      "step": 760
    },
    {
      "epoch": 0.22920077392469118,
      "grad_norm": 6.69506311416626,
      "learning_rate": 7.702973866025834e-05,
      "logits/chosen": -0.9685319066047668,
      "logits/rejected": -1.0003162622451782,
      "logps/chosen": -180.42823791503906,
      "logps/rejected": -191.2748565673828,
      "loss": 0.7071,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.742472767829895,
      "rewards/margins": 0.33853408694267273,
      "rewards/rejected": -1.0810067653656006,
      "step": 770
    },
    {
      "epoch": 0.23217740735228456,
      "grad_norm": 3.2545454502105713,
      "learning_rate": 7.698167617903274e-05,
      "logits/chosen": -0.9827396273612976,
      "logits/rejected": -1.0264077186584473,
      "logps/chosen": -176.61436462402344,
      "logps/rejected": -197.1429443359375,
      "loss": 0.6098,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.25947436690330505,
      "rewards/margins": 0.481163889169693,
      "rewards/rejected": -0.7406383156776428,
      "step": 780
    },
    {
      "epoch": 0.23515404077987795,
      "grad_norm": 4.448049068450928,
      "learning_rate": 7.693361369780715e-05,
      "logits/chosen": -1.075849175453186,
      "logits/rejected": -1.1430418491363525,
      "logps/chosen": -172.40652465820312,
      "logps/rejected": -191.78858947753906,
      "loss": 0.6244,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7225115299224854,
      "rewards/margins": 0.649060845375061,
      "rewards/rejected": -1.3715722560882568,
      "step": 790
    },
    {
      "epoch": 0.23813067420747136,
      "grad_norm": 3.972133159637451,
      "learning_rate": 7.688555121658157e-05,
      "logits/chosen": -1.0496041774749756,
      "logits/rejected": -1.126320481300354,
      "logps/chosen": -171.5742645263672,
      "logps/rejected": -191.27493286132812,
      "loss": 0.6016,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.35491451621055603,
      "rewards/margins": 0.761376142501831,
      "rewards/rejected": -1.116290807723999,
      "step": 800
    },
    {
      "epoch": 0.24110730763506474,
      "grad_norm": 2.525092363357544,
      "learning_rate": 7.683748873535597e-05,
      "logits/chosen": -1.0696237087249756,
      "logits/rejected": -1.0778106451034546,
      "logps/chosen": -181.7892608642578,
      "logps/rejected": -173.66250610351562,
      "loss": 0.6987,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -0.6446353793144226,
      "rewards/margins": 0.3994881808757782,
      "rewards/rejected": -1.0441235303878784,
      "step": 810
    },
    {
      "epoch": 0.24408394106265813,
      "grad_norm": 5.026135444641113,
      "learning_rate": 7.678942625413038e-05,
      "logits/chosen": -1.126131534576416,
      "logits/rejected": -1.1918600797653198,
      "logps/chosen": -170.24082946777344,
      "logps/rejected": -193.00369262695312,
      "loss": 0.5885,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.5965596437454224,
      "rewards/margins": 0.6136451959609985,
      "rewards/rejected": -1.210204839706421,
      "step": 820
    },
    {
      "epoch": 0.24706057449025154,
      "grad_norm": 3.6179823875427246,
      "learning_rate": 7.674136377290479e-05,
      "logits/chosen": -1.0807244777679443,
      "logits/rejected": -1.1101840734481812,
      "logps/chosen": -183.77059936523438,
      "logps/rejected": -192.99295043945312,
      "loss": 0.5919,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.171255350112915,
      "rewards/margins": 0.5830856561660767,
      "rewards/rejected": -1.7543411254882812,
      "step": 830
    },
    {
      "epoch": 0.2500372079178449,
      "grad_norm": 4.227837085723877,
      "learning_rate": 7.669330129167919e-05,
      "logits/chosen": -0.9941794276237488,
      "logits/rejected": -1.0921494960784912,
      "logps/chosen": -183.90682983398438,
      "logps/rejected": -212.6153106689453,
      "loss": 0.5957,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.2713305950164795,
      "rewards/margins": 0.693457305431366,
      "rewards/rejected": -1.9647880792617798,
      "step": 840
    },
    {
      "epoch": 0.2530138413454383,
      "grad_norm": 6.26926851272583,
      "learning_rate": 7.66452388104536e-05,
      "logits/chosen": -0.9020012021064758,
      "logits/rejected": -1.010481595993042,
      "logps/chosen": -194.40904235839844,
      "logps/rejected": -231.79959106445312,
      "loss": 0.5515,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.1885244846343994,
      "rewards/margins": 0.8473899960517883,
      "rewards/rejected": -3.035914182662964,
      "step": 850
    },
    {
      "epoch": 0.2559904747730317,
      "grad_norm": 4.614675045013428,
      "learning_rate": 7.6597176329228e-05,
      "logits/chosen": -0.9085625410079956,
      "logits/rejected": -0.9888118505477905,
      "logps/chosen": -187.53976440429688,
      "logps/rejected": -213.1559600830078,
      "loss": 0.7088,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -2.6201725006103516,
      "rewards/margins": 0.33508530259132385,
      "rewards/rejected": -2.9552578926086426,
      "step": 860
    },
    {
      "epoch": 0.2589671082006251,
      "grad_norm": 4.202051162719727,
      "learning_rate": 7.654911384800241e-05,
      "logits/chosen": -0.9271222352981567,
      "logits/rejected": -1.0635011196136475,
      "logps/chosen": -202.75631713867188,
      "logps/rejected": -244.22494506835938,
      "loss": 0.5719,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.758282423019409,
      "rewards/margins": 0.9910567998886108,
      "rewards/rejected": -3.7493393421173096,
      "step": 870
    },
    {
      "epoch": 0.2619437416282185,
      "grad_norm": 3.8148202896118164,
      "learning_rate": 7.650105136677682e-05,
      "logits/chosen": -0.9624158143997192,
      "logits/rejected": -0.9690213203430176,
      "logps/chosen": -189.5704803466797,
      "logps/rejected": -195.2711181640625,
      "loss": 0.6302,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.764521837234497,
      "rewards/margins": 0.5437914133071899,
      "rewards/rejected": -2.3083133697509766,
      "step": 880
    },
    {
      "epoch": 0.2649203750558119,
      "grad_norm": 6.054788112640381,
      "learning_rate": 7.645298888555122e-05,
      "logits/chosen": -1.042382836341858,
      "logits/rejected": -1.0816643238067627,
      "logps/chosen": -190.08677673339844,
      "logps/rejected": -210.0525665283203,
      "loss": 0.7305,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -1.1902300119400024,
      "rewards/margins": 0.3570000231266022,
      "rewards/rejected": -1.5472300052642822,
      "step": 890
    },
    {
      "epoch": 0.26789700848340525,
      "grad_norm": 3.307563304901123,
      "learning_rate": 7.640492640432563e-05,
      "logits/chosen": -0.9779678583145142,
      "logits/rejected": -1.0120079517364502,
      "logps/chosen": -171.48025512695312,
      "logps/rejected": -186.94065856933594,
      "loss": 0.6279,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.16900749504566193,
      "rewards/margins": 0.3814757466316223,
      "rewards/rejected": -0.5504832863807678,
      "step": 900
    },
    {
      "epoch": 0.27087364191099866,
      "grad_norm": 4.568321228027344,
      "learning_rate": 7.635686392310004e-05,
      "logits/chosen": -0.9493445158004761,
      "logits/rejected": -1.0353498458862305,
      "logps/chosen": -177.86456298828125,
      "logps/rejected": -203.59207153320312,
      "loss": 0.5883,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.631862223148346,
      "rewards/margins": 0.5415720343589783,
      "rewards/rejected": -1.1734344959259033,
      "step": 910
    },
    {
      "epoch": 0.2738502753385921,
      "grad_norm": 3.9209635257720947,
      "learning_rate": 7.630880144187444e-05,
      "logits/chosen": -0.9130836725234985,
      "logits/rejected": -1.0040470361709595,
      "logps/chosen": -165.861083984375,
      "logps/rejected": -196.34738159179688,
      "loss": 0.6012,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.5952149033546448,
      "rewards/margins": 0.5098882913589478,
      "rewards/rejected": -1.1051032543182373,
      "step": 920
    },
    {
      "epoch": 0.27682690876618543,
      "grad_norm": 3.1097679138183594,
      "learning_rate": 7.626073896064885e-05,
      "logits/chosen": -0.9355657696723938,
      "logits/rejected": -0.9723478555679321,
      "logps/chosen": -200.02891540527344,
      "logps/rejected": -211.96212768554688,
      "loss": 0.6225,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.2652099132537842,
      "rewards/margins": 0.4230611324310303,
      "rewards/rejected": -1.688270926475525,
      "step": 930
    },
    {
      "epoch": 0.27980354219377884,
      "grad_norm": 6.291031837463379,
      "learning_rate": 7.621267647942325e-05,
      "logits/chosen": -0.9231613278388977,
      "logits/rejected": -0.96113520860672,
      "logps/chosen": -181.50723266601562,
      "logps/rejected": -184.72573852539062,
      "loss": 0.6758,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.0353291034698486,
      "rewards/margins": 0.40389785170555115,
      "rewards/rejected": -1.4392268657684326,
      "step": 940
    },
    {
      "epoch": 0.28278017562137225,
      "grad_norm": 4.020671844482422,
      "learning_rate": 7.616461399819766e-05,
      "logits/chosen": -1.0004262924194336,
      "logits/rejected": -1.0763617753982544,
      "logps/chosen": -175.52951049804688,
      "logps/rejected": -201.0177764892578,
      "loss": 0.5103,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.2101417779922485,
      "rewards/margins": 0.8624321222305298,
      "rewards/rejected": -2.0725741386413574,
      "step": 950
    },
    {
      "epoch": 0.2857568090489656,
      "grad_norm": 3.3928840160369873,
      "learning_rate": 7.611655151697207e-05,
      "logits/chosen": -0.8694855570793152,
      "logits/rejected": -0.931614875793457,
      "logps/chosen": -190.0725555419922,
      "logps/rejected": -216.8146209716797,
      "loss": 0.6211,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.7253303527832031,
      "rewards/margins": 0.7826688885688782,
      "rewards/rejected": -2.5079991817474365,
      "step": 960
    },
    {
      "epoch": 0.288733442476559,
      "grad_norm": 3.7982516288757324,
      "learning_rate": 7.606848903574649e-05,
      "logits/chosen": -0.7440276741981506,
      "logits/rejected": -0.8420189023017883,
      "logps/chosen": -176.9615936279297,
      "logps/rejected": -203.95840454101562,
      "loss": 0.6408,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.5810085535049438,
      "rewards/margins": 0.5892034769058228,
      "rewards/rejected": -2.1702117919921875,
      "step": 970
    },
    {
      "epoch": 0.2917100759041524,
      "grad_norm": 6.546545028686523,
      "learning_rate": 7.602042655452089e-05,
      "logits/chosen": -0.7846527099609375,
      "logits/rejected": -0.8870355486869812,
      "logps/chosen": -177.0509490966797,
      "logps/rejected": -204.2518310546875,
      "loss": 0.6819,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -1.4313762187957764,
      "rewards/margins": 0.34078818559646606,
      "rewards/rejected": -1.7721647024154663,
      "step": 980
    },
    {
      "epoch": 0.2946867093317458,
      "grad_norm": 3.223818063735962,
      "learning_rate": 7.597236407329529e-05,
      "logits/chosen": -0.8412233591079712,
      "logits/rejected": -0.8431285619735718,
      "logps/chosen": -175.39035034179688,
      "logps/rejected": -183.69888305664062,
      "loss": 0.6123,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.4541345536708832,
      "rewards/margins": 0.5619989633560181,
      "rewards/rejected": -1.0161335468292236,
      "step": 990
    },
    {
      "epoch": 0.2976633427593392,
      "grad_norm": 2.185898542404175,
      "learning_rate": 7.592430159206969e-05,
      "logits/chosen": -0.7581781148910522,
      "logits/rejected": -0.7642606496810913,
      "logps/chosen": -181.11715698242188,
      "logps/rejected": -188.76821899414062,
      "loss": 0.6504,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.48484182357788086,
      "rewards/margins": 0.623891294002533,
      "rewards/rejected": -1.108733057975769,
      "step": 1000
    },
    {
      "epoch": 0.30063997618693256,
      "grad_norm": 3.6048145294189453,
      "learning_rate": 7.58762391108441e-05,
      "logits/chosen": -0.8883882761001587,
      "logits/rejected": -0.9457236528396606,
      "logps/chosen": -174.20558166503906,
      "logps/rejected": -191.39675903320312,
      "loss": 0.6204,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.081714153289795,
      "rewards/margins": 0.4790612757205963,
      "rewards/rejected": -1.5607753992080688,
      "step": 1010
    },
    {
      "epoch": 0.30361660961452597,
      "grad_norm": 2.3335142135620117,
      "learning_rate": 7.58281766296185e-05,
      "logits/chosen": -0.8519501686096191,
      "logits/rejected": -0.8077607154846191,
      "logps/chosen": -190.76214599609375,
      "logps/rejected": -178.43421936035156,
      "loss": 0.6401,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.8817520141601562,
      "rewards/margins": 0.35254180431365967,
      "rewards/rejected": -1.234293818473816,
      "step": 1020
    },
    {
      "epoch": 0.3065932430421194,
      "grad_norm": 3.15346360206604,
      "learning_rate": 7.578011414839291e-05,
      "logits/chosen": -0.8926773071289062,
      "logits/rejected": -0.9323687553405762,
      "logps/chosen": -185.24884033203125,
      "logps/rejected": -197.39901733398438,
      "loss": 0.6988,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -0.9207305908203125,
      "rewards/margins": 0.2393931895494461,
      "rewards/rejected": -1.1601238250732422,
      "step": 1030
    },
    {
      "epoch": 0.30956987646971273,
      "grad_norm": 3.0799763202667236,
      "learning_rate": 7.573205166716733e-05,
      "logits/chosen": -0.9941034317016602,
      "logits/rejected": -0.9600178599357605,
      "logps/chosen": -183.08328247070312,
      "logps/rejected": -176.51840209960938,
      "loss": 0.6183,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.34606316685676575,
      "rewards/margins": 0.458822101354599,
      "rewards/rejected": -0.8048852682113647,
      "step": 1040
    },
    {
      "epoch": 0.31254650989730615,
      "grad_norm": 3.6824464797973633,
      "learning_rate": 7.568398918594174e-05,
      "logits/chosen": -0.964209258556366,
      "logits/rejected": -0.9365048408508301,
      "logps/chosen": -183.60498046875,
      "logps/rejected": -181.07876586914062,
      "loss": 0.6128,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.9462957382202148,
      "rewards/margins": 0.3133231997489929,
      "rewards/rejected": -1.2596189975738525,
      "step": 1050
    },
    {
      "epoch": 0.31552314332489956,
      "grad_norm": 2.4769182205200195,
      "learning_rate": 7.563592670471614e-05,
      "logits/chosen": -0.7941994667053223,
      "logits/rejected": -0.8447968363761902,
      "logps/chosen": -170.6359100341797,
      "logps/rejected": -187.8028564453125,
      "loss": 0.6649,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.6332710981369019,
      "rewards/margins": 0.3285732865333557,
      "rewards/rejected": -0.9618443250656128,
      "step": 1060
    },
    {
      "epoch": 0.3184997767524929,
      "grad_norm": 2.8488609790802,
      "learning_rate": 7.558786422349055e-05,
      "logits/chosen": -0.8424204587936401,
      "logits/rejected": -0.8205752372741699,
      "logps/chosen": -181.9245147705078,
      "logps/rejected": -173.66146850585938,
      "loss": 0.6618,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.4247216284275055,
      "rewards/margins": 0.2801990211009979,
      "rewards/rejected": -0.7049206495285034,
      "step": 1070
    },
    {
      "epoch": 0.3214764101800863,
      "grad_norm": 2.9195990562438965,
      "learning_rate": 7.553980174226495e-05,
      "logits/chosen": -0.9373773336410522,
      "logits/rejected": -0.9269492030143738,
      "logps/chosen": -163.7871856689453,
      "logps/rejected": -167.89649963378906,
      "loss": 0.6305,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.621403157711029,
      "rewards/margins": 0.35677045583724976,
      "rewards/rejected": -0.9781736135482788,
      "step": 1080
    },
    {
      "epoch": 0.32445304360767974,
      "grad_norm": 1.8969151973724365,
      "learning_rate": 7.549173926103936e-05,
      "logits/chosen": -0.9116865396499634,
      "logits/rejected": -0.9152435064315796,
      "logps/chosen": -187.34629821777344,
      "logps/rejected": -190.5868682861328,
      "loss": 0.5729,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.1407562494277954,
      "rewards/margins": 0.4348992705345154,
      "rewards/rejected": -1.5756556987762451,
      "step": 1090
    },
    {
      "epoch": 0.3274296770352731,
      "grad_norm": 3.127819538116455,
      "learning_rate": 7.544367677981377e-05,
      "logits/chosen": -0.8114253878593445,
      "logits/rejected": -0.8957219123840332,
      "logps/chosen": -188.55760192871094,
      "logps/rejected": -213.7491912841797,
      "loss": 0.7103,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -2.059659242630005,
      "rewards/margins": 0.4639342427253723,
      "rewards/rejected": -2.5235936641693115,
      "step": 1100
    },
    {
      "epoch": 0.3304063104628665,
      "grad_norm": 3.2176547050476074,
      "learning_rate": 7.539561429858817e-05,
      "logits/chosen": -0.782035231590271,
      "logits/rejected": -0.7774515748023987,
      "logps/chosen": -175.04656982421875,
      "logps/rejected": -166.43148803710938,
      "loss": 0.6684,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.7955155372619629,
      "rewards/margins": 0.2531368136405945,
      "rewards/rejected": -1.0486522912979126,
      "step": 1110
    },
    {
      "epoch": 0.3333829438904599,
      "grad_norm": 3.0796968936920166,
      "learning_rate": 7.534755181736258e-05,
      "logits/chosen": -0.9273667335510254,
      "logits/rejected": -0.993266761302948,
      "logps/chosen": -178.81163024902344,
      "logps/rejected": -194.24786376953125,
      "loss": 0.6346,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.7515257596969604,
      "rewards/margins": 0.3442385494709015,
      "rewards/rejected": -1.0957642793655396,
      "step": 1120
    },
    {
      "epoch": 0.33635957731805327,
      "grad_norm": 3.774418592453003,
      "learning_rate": 7.529948933613698e-05,
      "logits/chosen": -0.8527849316596985,
      "logits/rejected": -0.8815460205078125,
      "logps/chosen": -178.38064575195312,
      "logps/rejected": -188.30020141601562,
      "loss": 0.6595,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.710993766784668,
      "rewards/margins": 0.3178732097148895,
      "rewards/rejected": -1.0288671255111694,
      "step": 1130
    },
    {
      "epoch": 0.3393362107456467,
      "grad_norm": 3.4017131328582764,
      "learning_rate": 7.525142685491139e-05,
      "logits/chosen": -0.7399495840072632,
      "logits/rejected": -0.8168625831604004,
      "logps/chosen": -170.01730346679688,
      "logps/rejected": -189.31777954101562,
      "loss": 0.5569,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.10905428230762482,
      "rewards/margins": 0.6127211451530457,
      "rewards/rejected": -0.7217754125595093,
      "step": 1140
    },
    {
      "epoch": 0.34231284417324004,
      "grad_norm": 2.734205722808838,
      "learning_rate": 7.520817062180835e-05,
      "logits/chosen": -0.8490294218063354,
      "logits/rejected": -0.9080871343612671,
      "logps/chosen": -172.17245483398438,
      "logps/rejected": -198.08851623535156,
      "loss": 0.6592,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.31059616804122925,
      "rewards/margins": 0.456951767206192,
      "rewards/rejected": -0.7675479650497437,
      "step": 1150
    },
    {
      "epoch": 0.34528947760083345,
      "grad_norm": 4.945737361907959,
      "learning_rate": 7.516010814058276e-05,
      "logits/chosen": -0.9032249450683594,
      "logits/rejected": -0.9622125625610352,
      "logps/chosen": -163.6092987060547,
      "logps/rejected": -180.4864501953125,
      "loss": 0.6785,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.1851118505001068,
      "rewards/margins": 0.2802906930446625,
      "rewards/rejected": -0.4654025137424469,
      "step": 1160
    },
    {
      "epoch": 0.34826611102842686,
      "grad_norm": 3.899245023727417,
      "learning_rate": 7.511204565935716e-05,
      "logits/chosen": -0.8360775709152222,
      "logits/rejected": -0.9424786567687988,
      "logps/chosen": -168.26693725585938,
      "logps/rejected": -196.45138549804688,
      "loss": 0.637,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.2787458300590515,
      "rewards/margins": 0.5976814031600952,
      "rewards/rejected": -0.876427173614502,
      "step": 1170
    },
    {
      "epoch": 0.3512427444560202,
      "grad_norm": 4.590948104858398,
      "learning_rate": 7.506398317813158e-05,
      "logits/chosen": -0.8327972292900085,
      "logits/rejected": -0.8183948397636414,
      "logps/chosen": -186.97923278808594,
      "logps/rejected": -197.48834228515625,
      "loss": 0.5688,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5775927305221558,
      "rewards/margins": 0.646568238735199,
      "rewards/rejected": -1.2241610288619995,
      "step": 1180
    },
    {
      "epoch": 0.35421937788361363,
      "grad_norm": 3.955699920654297,
      "learning_rate": 7.501592069690599e-05,
      "logits/chosen": -0.7680628895759583,
      "logits/rejected": -0.7850946187973022,
      "logps/chosen": -177.66299438476562,
      "logps/rejected": -184.87496948242188,
      "loss": 0.7373,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -0.20679740607738495,
      "rewards/margins": 0.24517031013965607,
      "rewards/rejected": -0.451967716217041,
      "step": 1190
    },
    {
      "epoch": 0.35719601131120704,
      "grad_norm": 2.6467509269714355,
      "learning_rate": 7.49678582156804e-05,
      "logits/chosen": -0.8303887248039246,
      "logits/rejected": -0.8389304876327515,
      "logps/chosen": -168.60003662109375,
      "logps/rejected": -170.55322265625,
      "loss": 0.647,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.016133714467287064,
      "rewards/margins": 0.4501733183860779,
      "rewards/rejected": -0.4340395927429199,
      "step": 1200
    },
    {
      "epoch": 0.3601726447388004,
      "grad_norm": 2.540823459625244,
      "learning_rate": 7.49197957344548e-05,
      "logits/chosen": -0.806098461151123,
      "logits/rejected": -0.837099552154541,
      "logps/chosen": -189.98538208007812,
      "logps/rejected": -202.08592224121094,
      "loss": 0.563,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5400177836418152,
      "rewards/margins": 0.5279939770698547,
      "rewards/rejected": -1.0680116415023804,
      "step": 1210
    },
    {
      "epoch": 0.3631492781663938,
      "grad_norm": 2.8935458660125732,
      "learning_rate": 7.487173325322921e-05,
      "logits/chosen": -0.7273780107498169,
      "logits/rejected": -0.7832620739936829,
      "logps/chosen": -167.26614379882812,
      "logps/rejected": -180.0755157470703,
      "loss": 0.6031,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.2884457111358643,
      "rewards/margins": 0.4616585671901703,
      "rewards/rejected": -1.750104546546936,
      "step": 1220
    },
    {
      "epoch": 0.3661259115939872,
      "grad_norm": 3.565079927444458,
      "learning_rate": 7.482367077200361e-05,
      "logits/chosen": -0.670025646686554,
      "logits/rejected": -0.704534113407135,
      "logps/chosen": -192.65347290039062,
      "logps/rejected": -204.19305419921875,
      "loss": 0.6204,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.5325981378555298,
      "rewards/margins": 0.463768869638443,
      "rewards/rejected": -1.9963668584823608,
      "step": 1230
    },
    {
      "epoch": 0.3691025450215806,
      "grad_norm": 2.9782791137695312,
      "learning_rate": 7.477560829077802e-05,
      "logits/chosen": -0.7148706316947937,
      "logits/rejected": -0.6627799272537231,
      "logps/chosen": -205.8864288330078,
      "logps/rejected": -199.5586395263672,
      "loss": 0.628,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.1992309093475342,
      "rewards/margins": 0.4348903298377991,
      "rewards/rejected": -1.634121298789978,
      "step": 1240
    },
    {
      "epoch": 0.372079178449174,
      "grad_norm": 3.0261425971984863,
      "learning_rate": 7.472754580955243e-05,
      "logits/chosen": -0.6988739371299744,
      "logits/rejected": -0.8356817364692688,
      "logps/chosen": -166.07437133789062,
      "logps/rejected": -192.78797912597656,
      "loss": 0.6248,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -1.0175610780715942,
      "rewards/margins": 0.433402955532074,
      "rewards/rejected": -1.4509639739990234,
      "step": 1250
    },
    {
      "epoch": 0.3750558118767674,
      "grad_norm": 4.35824728012085,
      "learning_rate": 7.467948332832683e-05,
      "logits/chosen": -0.7716109156608582,
      "logits/rejected": -0.7192538380622864,
      "logps/chosen": -199.68374633789062,
      "logps/rejected": -186.38369750976562,
      "loss": 0.7695,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -1.0896884202957153,
      "rewards/margins": 0.1247972622513771,
      "rewards/rejected": -1.214485764503479,
      "step": 1260
    },
    {
      "epoch": 0.37803244530436075,
      "grad_norm": 2.2015633583068848,
      "learning_rate": 7.463142084710124e-05,
      "logits/chosen": -0.695650041103363,
      "logits/rejected": -0.6636807322502136,
      "logps/chosen": -184.81341552734375,
      "logps/rejected": -173.5574188232422,
      "loss": 0.5861,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.6805018782615662,
      "rewards/margins": 0.4546147286891937,
      "rewards/rejected": -1.135116696357727,
      "step": 1270
    },
    {
      "epoch": 0.38100907873195416,
      "grad_norm": 3.0013601779937744,
      "learning_rate": 7.458335836587564e-05,
      "logits/chosen": -0.6707616448402405,
      "logits/rejected": -0.8311411738395691,
      "logps/chosen": -175.06527709960938,
      "logps/rejected": -213.6944580078125,
      "loss": 0.579,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.9234448671340942,
      "rewards/margins": 0.6555954217910767,
      "rewards/rejected": -1.579040288925171,
      "step": 1280
    },
    {
      "epoch": 0.3839857121595476,
      "grad_norm": 4.909384727478027,
      "learning_rate": 7.453529588465005e-05,
      "logits/chosen": -0.6518440842628479,
      "logits/rejected": -0.7384060621261597,
      "logps/chosen": -176.27333068847656,
      "logps/rejected": -207.3907012939453,
      "loss": 0.568,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.177003026008606,
      "rewards/margins": 0.5105076432228088,
      "rewards/rejected": -1.6875108480453491,
      "step": 1290
    },
    {
      "epoch": 0.38696234558714093,
      "grad_norm": 4.352695465087891,
      "learning_rate": 7.448723340342446e-05,
      "logits/chosen": -0.7531604766845703,
      "logits/rejected": -0.7734609842300415,
      "logps/chosen": -180.21444702148438,
      "logps/rejected": -197.22406005859375,
      "loss": 0.7079,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -1.6469415426254272,
      "rewards/margins": 0.3432965576648712,
      "rewards/rejected": -1.9902381896972656,
      "step": 1300
    },
    {
      "epoch": 0.38993897901473434,
      "grad_norm": 3.6134893894195557,
      "learning_rate": 7.443917092219886e-05,
      "logits/chosen": -0.6108961701393127,
      "logits/rejected": -0.6878918409347534,
      "logps/chosen": -170.4265899658203,
      "logps/rejected": -188.6591796875,
      "loss": 0.6442,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0918501615524292,
      "rewards/margins": 0.3659556806087494,
      "rewards/rejected": -1.457805871963501,
      "step": 1310
    },
    {
      "epoch": 0.3929156124423277,
      "grad_norm": 3.3651764392852783,
      "learning_rate": 7.439110844097327e-05,
      "logits/chosen": -0.5364434719085693,
      "logits/rejected": -0.6311115622520447,
      "logps/chosen": -197.3976287841797,
      "logps/rejected": -224.4905548095703,
      "loss": 0.649,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -1.5916706323623657,
      "rewards/margins": 0.4839097857475281,
      "rewards/rejected": -2.075580596923828,
      "step": 1320
    },
    {
      "epoch": 0.3958922458699211,
      "grad_norm": 2.7008488178253174,
      "learning_rate": 7.434304595974768e-05,
      "logits/chosen": -0.6339104771614075,
      "logits/rejected": -0.6829333305358887,
      "logps/chosen": -179.65777587890625,
      "logps/rejected": -194.8877410888672,
      "loss": 0.6124,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.2896161079406738,
      "rewards/margins": 0.3977881968021393,
      "rewards/rejected": -1.6874043941497803,
      "step": 1330
    },
    {
      "epoch": 0.3988688792975145,
      "grad_norm": 3.4798874855041504,
      "learning_rate": 7.429498347852208e-05,
      "logits/chosen": -0.6668460369110107,
      "logits/rejected": -0.5952341556549072,
      "logps/chosen": -195.8775634765625,
      "logps/rejected": -191.3599853515625,
      "loss": 0.6114,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.071559190750122,
      "rewards/margins": 0.4510221481323242,
      "rewards/rejected": -1.5225813388824463,
      "step": 1340
    },
    {
      "epoch": 0.4018455127251079,
      "grad_norm": 2.8529744148254395,
      "learning_rate": 7.42469209972965e-05,
      "logits/chosen": -0.772468090057373,
      "logits/rejected": -0.8614404797554016,
      "logps/chosen": -180.84567260742188,
      "logps/rejected": -201.02676391601562,
      "loss": 0.6265,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.278451681137085,
      "rewards/margins": 0.40056219696998596,
      "rewards/rejected": -1.6790138483047485,
      "step": 1350
    },
    {
      "epoch": 0.4048221461527013,
      "grad_norm": 5.818501949310303,
      "learning_rate": 7.419885851607091e-05,
      "logits/chosen": -0.7004775404930115,
      "logits/rejected": -0.7305837869644165,
      "logps/chosen": -185.0666046142578,
      "logps/rejected": -195.36245727539062,
      "loss": 0.5955,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.34060537815094,
      "rewards/margins": 0.4057166576385498,
      "rewards/rejected": -1.7463219165802002,
      "step": 1360
    },
    {
      "epoch": 0.4077987795802947,
      "grad_norm": 2.9335782527923584,
      "learning_rate": 7.415079603484531e-05,
      "logits/chosen": -0.7437853217124939,
      "logits/rejected": -0.6221972703933716,
      "logps/chosen": -183.2805633544922,
      "logps/rejected": -172.31642150878906,
      "loss": 0.6562,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.1941423416137695,
      "rewards/margins": 0.34442251920700073,
      "rewards/rejected": -1.538564920425415,
      "step": 1370
    },
    {
      "epoch": 0.41077541300788806,
      "grad_norm": 3.5632760524749756,
      "learning_rate": 7.41027335536197e-05,
      "logits/chosen": -0.675675094127655,
      "logits/rejected": -0.7552134990692139,
      "logps/chosen": -180.89080810546875,
      "logps/rejected": -200.8624267578125,
      "loss": 0.5836,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0664188861846924,
      "rewards/margins": 0.4700976312160492,
      "rewards/rejected": -1.536516547203064,
      "step": 1380
    },
    {
      "epoch": 0.41375204643548147,
      "grad_norm": 2.3207099437713623,
      "learning_rate": 7.405467107239411e-05,
      "logits/chosen": -0.6460621953010559,
      "logits/rejected": -0.6134334802627563,
      "logps/chosen": -180.8807373046875,
      "logps/rejected": -179.68563842773438,
      "loss": 0.5944,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0735949277877808,
      "rewards/margins": 0.4988338351249695,
      "rewards/rejected": -1.5724287033081055,
      "step": 1390
    },
    {
      "epoch": 0.4167286798630749,
      "grad_norm": 3.9915475845336914,
      "learning_rate": 7.400660859116852e-05,
      "logits/chosen": -0.6959450244903564,
      "logits/rejected": -0.7270548343658447,
      "logps/chosen": -193.95089721679688,
      "logps/rejected": -205.1103057861328,
      "loss": 0.6081,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.8753246068954468,
      "rewards/margins": 0.537288248538971,
      "rewards/rejected": -2.4126131534576416,
      "step": 1400
    },
    {
      "epoch": 0.41970531329066824,
      "grad_norm": 3.301252841949463,
      "learning_rate": 7.395854610994292e-05,
      "logits/chosen": -0.5265404582023621,
      "logits/rejected": -0.5910511612892151,
      "logps/chosen": -196.55987548828125,
      "logps/rejected": -226.874755859375,
      "loss": 0.5853,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.7940994501113892,
      "rewards/margins": 0.712661862373352,
      "rewards/rejected": -2.506761074066162,
      "step": 1410
    },
    {
      "epoch": 0.42268194671826165,
      "grad_norm": 3.5536303520202637,
      "learning_rate": 7.391048362871734e-05,
      "logits/chosen": -0.6775950193405151,
      "logits/rejected": -0.684914231300354,
      "logps/chosen": -187.22039794921875,
      "logps/rejected": -200.21395874023438,
      "loss": 0.5506,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.4985231161117554,
      "rewards/margins": 0.7082122564315796,
      "rewards/rejected": -2.206735372543335,
      "step": 1420
    },
    {
      "epoch": 0.42565858014585506,
      "grad_norm": 2.988579750061035,
      "learning_rate": 7.386242114749175e-05,
      "logits/chosen": -0.6975175738334656,
      "logits/rejected": -0.7324480414390564,
      "logps/chosen": -188.0128173828125,
      "logps/rejected": -195.57717895507812,
      "loss": 0.6405,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.1416873931884766,
      "rewards/margins": 0.5081726312637329,
      "rewards/rejected": -1.6498600244522095,
      "step": 1430
    },
    {
      "epoch": 0.4286352135734484,
      "grad_norm": 4.3045654296875,
      "learning_rate": 7.381435866626616e-05,
      "logits/chosen": -0.6942250728607178,
      "logits/rejected": -0.7738581299781799,
      "logps/chosen": -190.28924560546875,
      "logps/rejected": -204.02609252929688,
      "loss": 0.6485,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.186838984489441,
      "rewards/margins": 0.4165570139884949,
      "rewards/rejected": -1.6033960580825806,
      "step": 1440
    },
    {
      "epoch": 0.4316118470010418,
      "grad_norm": 3.4405641555786133,
      "learning_rate": 7.376629618504056e-05,
      "logits/chosen": -0.8025158643722534,
      "logits/rejected": -0.8219634294509888,
      "logps/chosen": -192.8708953857422,
      "logps/rejected": -196.3754425048828,
      "loss": 0.6804,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -2.211724042892456,
      "rewards/margins": 0.32307904958724976,
      "rewards/rejected": -2.5348029136657715,
      "step": 1450
    },
    {
      "epoch": 0.43458848042863524,
      "grad_norm": 3.389559745788574,
      "learning_rate": 7.371823370381497e-05,
      "logits/chosen": -0.8688727617263794,
      "logits/rejected": -0.8078497052192688,
      "logps/chosen": -190.28402709960938,
      "logps/rejected": -182.6565399169922,
      "loss": 0.5852,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.3545535802841187,
      "rewards/margins": 0.4415208399295807,
      "rewards/rejected": -1.7960745096206665,
      "step": 1460
    },
    {
      "epoch": 0.4375651138562286,
      "grad_norm": 2.0250134468078613,
      "learning_rate": 7.367017122258937e-05,
      "logits/chosen": -0.7739856243133545,
      "logits/rejected": -0.8206751942634583,
      "logps/chosen": -179.52455139160156,
      "logps/rejected": -188.9673614501953,
      "loss": 0.6222,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5727356672286987,
      "rewards/margins": 0.43224820494651794,
      "rewards/rejected": -2.004983901977539,
      "step": 1470
    },
    {
      "epoch": 0.440541747283822,
      "grad_norm": 3.4514238834381104,
      "learning_rate": 7.362210874136378e-05,
      "logits/chosen": -0.74516361951828,
      "logits/rejected": -0.7840023040771484,
      "logps/chosen": -172.86672973632812,
      "logps/rejected": -186.72183227539062,
      "loss": 0.5984,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.6882225871086121,
      "rewards/margins": 0.5252479910850525,
      "rewards/rejected": -1.2134705781936646,
      "step": 1480
    },
    {
      "epoch": 0.4435183807114154,
      "grad_norm": 4.206452369689941,
      "learning_rate": 7.357404626013819e-05,
      "logits/chosen": -0.7893417477607727,
      "logits/rejected": -0.7802373170852661,
      "logps/chosen": -198.6871337890625,
      "logps/rejected": -198.36273193359375,
      "loss": 0.5696,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.7846976518630981,
      "rewards/margins": 0.5194244384765625,
      "rewards/rejected": -1.3041220903396606,
      "step": 1490
    },
    {
      "epoch": 0.4464950141390088,
      "grad_norm": 3.579059362411499,
      "learning_rate": 7.352598377891259e-05,
      "logits/chosen": -0.7644058465957642,
      "logits/rejected": -0.7669198513031006,
      "logps/chosen": -196.3068084716797,
      "logps/rejected": -196.84906005859375,
      "loss": 0.569,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1713556051254272,
      "rewards/margins": 0.5736747980117798,
      "rewards/rejected": -1.745030403137207,
      "step": 1500
    },
    {
      "epoch": 0.4494716475666022,
      "grad_norm": 4.8978800773620605,
      "learning_rate": 7.3477921297687e-05,
      "logits/chosen": -0.8020421266555786,
      "logits/rejected": -0.8395172357559204,
      "logps/chosen": -193.81175231933594,
      "logps/rejected": -208.5922088623047,
      "loss": 0.6066,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -2.0345723628997803,
      "rewards/margins": 0.5240772366523743,
      "rewards/rejected": -2.5586495399475098,
      "step": 1510
    },
    {
      "epoch": 0.45244828099419554,
      "grad_norm": 3.152988910675049,
      "learning_rate": 7.34298588164614e-05,
      "logits/chosen": -0.6920439600944519,
      "logits/rejected": -0.7888700366020203,
      "logps/chosen": -193.0537109375,
      "logps/rejected": -220.08291625976562,
      "loss": 0.5937,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -2.1394612789154053,
      "rewards/margins": 0.6723121404647827,
      "rewards/rejected": -2.8117733001708984,
      "step": 1520
    },
    {
      "epoch": 0.45542491442178895,
      "grad_norm": 4.214576244354248,
      "learning_rate": 7.338179633523581e-05,
      "logits/chosen": -0.7646873593330383,
      "logits/rejected": -0.8532228469848633,
      "logps/chosen": -206.2889404296875,
      "logps/rejected": -228.50778198242188,
      "loss": 0.5832,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.7986655235290527,
      "rewards/margins": 0.7756079435348511,
      "rewards/rejected": -3.5742735862731934,
      "step": 1530
    },
    {
      "epoch": 0.45840154784938236,
      "grad_norm": 3.6800143718719482,
      "learning_rate": 7.333373385401022e-05,
      "logits/chosen": -0.7936034202575684,
      "logits/rejected": -0.805004894733429,
      "logps/chosen": -190.3814239501953,
      "logps/rejected": -189.45977783203125,
      "loss": 0.6581,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -2.282724142074585,
      "rewards/margins": 0.4287613034248352,
      "rewards/rejected": -2.7114853858947754,
      "step": 1540
    },
    {
      "epoch": 0.4613781812769757,
      "grad_norm": 3.338472843170166,
      "learning_rate": 7.328567137278462e-05,
      "logits/chosen": -0.7250747680664062,
      "logits/rejected": -0.7060396671295166,
      "logps/chosen": -223.7118377685547,
      "logps/rejected": -220.0576171875,
      "loss": 0.6207,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.979845404624939,
      "rewards/margins": 0.7533287405967712,
      "rewards/rejected": -2.7331743240356445,
      "step": 1550
    },
    {
      "epoch": 0.46435481470456913,
      "grad_norm": 3.1647138595581055,
      "learning_rate": 7.323760889155903e-05,
      "logits/chosen": -0.7613006830215454,
      "logits/rejected": -0.8128318786621094,
      "logps/chosen": -186.09689331054688,
      "logps/rejected": -204.63612365722656,
      "loss": 0.6145,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.1178877353668213,
      "rewards/margins": 0.5693659782409668,
      "rewards/rejected": -2.687253952026367,
      "step": 1560
    },
    {
      "epoch": 0.46733144813216254,
      "grad_norm": 2.5431954860687256,
      "learning_rate": 7.318954641033344e-05,
      "logits/chosen": -0.7214018702507019,
      "logits/rejected": -0.7821462750434875,
      "logps/chosen": -198.10975646972656,
      "logps/rejected": -222.1988067626953,
      "loss": 0.5519,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.087772846221924,
      "rewards/margins": 0.7258394956588745,
      "rewards/rejected": -2.813612222671509,
      "step": 1570
    },
    {
      "epoch": 0.4703080815597559,
      "grad_norm": 2.0751845836639404,
      "learning_rate": 7.314148392910784e-05,
      "logits/chosen": -0.7448005080223083,
      "logits/rejected": -0.7792001962661743,
      "logps/chosen": -200.47862243652344,
      "logps/rejected": -210.215087890625,
      "loss": 0.6333,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -2.46431040763855,
      "rewards/margins": 0.3253610134124756,
      "rewards/rejected": -2.7896714210510254,
      "step": 1580
    },
    {
      "epoch": 0.4732847149873493,
      "grad_norm": 3.492793083190918,
      "learning_rate": 7.309342144788226e-05,
      "logits/chosen": -0.7041530013084412,
      "logits/rejected": -0.7235110998153687,
      "logps/chosen": -202.04391479492188,
      "logps/rejected": -218.53759765625,
      "loss": 0.594,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.9791240692138672,
      "rewards/margins": 0.5564603805541992,
      "rewards/rejected": -2.5355844497680664,
      "step": 1590
    },
    {
      "epoch": 0.4762613484149427,
      "grad_norm": 4.246933937072754,
      "learning_rate": 7.304535896665667e-05,
      "logits/chosen": -0.5786532759666443,
      "logits/rejected": -0.6531438231468201,
      "logps/chosen": -187.13221740722656,
      "logps/rejected": -212.6765899658203,
      "loss": 0.5688,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.0026867389678955,
      "rewards/margins": 0.7464555501937866,
      "rewards/rejected": -2.7491421699523926,
      "step": 1600
    },
    {
      "epoch": 0.4792379818425361,
      "grad_norm": 1.78248131275177,
      "learning_rate": 7.299729648543107e-05,
      "logits/chosen": -0.6229616403579712,
      "logits/rejected": -0.6638821363449097,
      "logps/chosen": -186.19931030273438,
      "logps/rejected": -198.42027282714844,
      "loss": 0.5833,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.6430084705352783,
      "rewards/margins": 0.6211866140365601,
      "rewards/rejected": -2.264194965362549,
      "step": 1610
    },
    {
      "epoch": 0.4822146152701295,
      "grad_norm": 2.9341485500335693,
      "learning_rate": 7.294923400420547e-05,
      "logits/chosen": -0.7974963784217834,
      "logits/rejected": -0.8516708612442017,
      "logps/chosen": -175.3806610107422,
      "logps/rejected": -191.8528594970703,
      "loss": 0.5903,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.6359916925430298,
      "rewards/margins": 0.6261876821517944,
      "rewards/rejected": -2.262179374694824,
      "step": 1620
    },
    {
      "epoch": 0.4851912486977229,
      "grad_norm": 4.123788833618164,
      "learning_rate": 7.290117152297987e-05,
      "logits/chosen": -0.7141470909118652,
      "logits/rejected": -0.7974482774734497,
      "logps/chosen": -197.95291137695312,
      "logps/rejected": -235.3839569091797,
      "loss": 0.4915,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.884070634841919,
      "rewards/margins": 0.996941864490509,
      "rewards/rejected": -2.881012439727783,
      "step": 1630
    },
    {
      "epoch": 0.48816788212531625,
      "grad_norm": 2.317295551300049,
      "learning_rate": 7.285310904175428e-05,
      "logits/chosen": -0.7238271236419678,
      "logits/rejected": -0.771206259727478,
      "logps/chosen": -193.1932830810547,
      "logps/rejected": -212.31820678710938,
      "loss": 0.5753,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7525396347045898,
      "rewards/margins": 0.6992851495742798,
      "rewards/rejected": -2.451824903488159,
      "step": 1640
    },
    {
      "epoch": 0.49114451555290967,
      "grad_norm": 3.2690415382385254,
      "learning_rate": 7.280504656052869e-05,
      "logits/chosen": -0.7030261754989624,
      "logits/rejected": -0.8788629770278931,
      "logps/chosen": -185.6872100830078,
      "logps/rejected": -232.9250030517578,
      "loss": 0.5064,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.0629637241363525,
      "rewards/margins": 1.5126367807388306,
      "rewards/rejected": -3.5756003856658936,
      "step": 1650
    },
    {
      "epoch": 0.4941211489805031,
      "grad_norm": 4.134389877319336,
      "learning_rate": 7.27569840793031e-05,
      "logits/chosen": -0.7301262617111206,
      "logits/rejected": -0.7216383814811707,
      "logps/chosen": -196.29928588867188,
      "logps/rejected": -202.17514038085938,
      "loss": 0.7831,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -1.645273208618164,
      "rewards/margins": 0.5554307103157043,
      "rewards/rejected": -2.2007038593292236,
      "step": 1660
    },
    {
      "epoch": 0.49709778240809643,
      "grad_norm": 5.013368129730225,
      "learning_rate": 7.270892159807751e-05,
      "logits/chosen": -0.578633189201355,
      "logits/rejected": -0.6898370981216431,
      "logps/chosen": -176.3950653076172,
      "logps/rejected": -212.70687866210938,
      "loss": 0.5672,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0626437664031982,
      "rewards/margins": 1.0624257326126099,
      "rewards/rejected": -2.1250696182250977,
      "step": 1670
    },
    {
      "epoch": 0.5000744158356898,
      "grad_norm": 4.808247089385986,
      "learning_rate": 7.266085911685192e-05,
      "logits/chosen": -0.7407124638557434,
      "logits/rejected": -0.7133066654205322,
      "logps/chosen": -190.00869750976562,
      "logps/rejected": -190.137939453125,
      "loss": 0.6789,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -0.9037891626358032,
      "rewards/margins": 0.40927180647850037,
      "rewards/rejected": -1.313060998916626,
      "step": 1680
    },
    {
      "epoch": 0.5030510492632833,
      "grad_norm": 4.73721981048584,
      "learning_rate": 7.261279663562632e-05,
      "logits/chosen": -0.6867583394050598,
      "logits/rejected": -0.7117101550102234,
      "logps/chosen": -193.35862731933594,
      "logps/rejected": -198.35768127441406,
      "loss": 0.7331,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.5985842943191528,
      "rewards/margins": 0.27013838291168213,
      "rewards/rejected": -0.8687226176261902,
      "step": 1690
    },
    {
      "epoch": 0.5060276826908766,
      "grad_norm": 3.349405288696289,
      "learning_rate": 7.256473415440073e-05,
      "logits/chosen": -0.638450026512146,
      "logits/rejected": -0.7279180884361267,
      "logps/chosen": -173.8144073486328,
      "logps/rejected": -197.35641479492188,
      "loss": 0.5998,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.6065539121627808,
      "rewards/margins": 0.5791957378387451,
      "rewards/rejected": -1.1857496500015259,
      "step": 1700
    },
    {
      "epoch": 0.50900431611847,
      "grad_norm": 3.395108222961426,
      "learning_rate": 7.251667167317514e-05,
      "logits/chosen": -0.785658061504364,
      "logits/rejected": -0.7898305654525757,
      "logps/chosen": -189.76675415039062,
      "logps/rejected": -195.13304138183594,
      "loss": 0.6518,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.749666154384613,
      "rewards/margins": 0.4059992730617523,
      "rewards/rejected": -1.1556655168533325,
      "step": 1710
    },
    {
      "epoch": 0.5119809495460634,
      "grad_norm": 3.243227958679199,
      "learning_rate": 7.246860919194954e-05,
      "logits/chosen": -0.8404852747917175,
      "logits/rejected": -0.8658764958381653,
      "logps/chosen": -175.05300903320312,
      "logps/rejected": -187.31350708007812,
      "loss": 0.6991,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.4480019211769104,
      "rewards/margins": 0.23028135299682617,
      "rewards/rejected": -0.6782832145690918,
      "step": 1720
    },
    {
      "epoch": 0.5149575829736568,
      "grad_norm": 4.120052814483643,
      "learning_rate": 7.242054671072395e-05,
      "logits/chosen": -0.864738941192627,
      "logits/rejected": -0.8862429857254028,
      "logps/chosen": -166.05313110351562,
      "logps/rejected": -171.92984008789062,
      "loss": 0.6726,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.927169919013977,
      "rewards/margins": 0.2659216523170471,
      "rewards/rejected": -1.1930915117263794,
      "step": 1730
    },
    {
      "epoch": 0.5179342164012501,
      "grad_norm": 3.3685734272003174,
      "learning_rate": 7.237248422949835e-05,
      "logits/chosen": -0.8688908815383911,
      "logits/rejected": -0.9371142387390137,
      "logps/chosen": -190.76809692382812,
      "logps/rejected": -214.2984161376953,
      "loss": 0.6454,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.1103936433792114,
      "rewards/margins": 0.5680106282234192,
      "rewards/rejected": -1.6784042119979858,
      "step": 1740
    },
    {
      "epoch": 0.5209108498288436,
      "grad_norm": 2.673178195953369,
      "learning_rate": 7.232442174827276e-05,
      "logits/chosen": -0.8357303738594055,
      "logits/rejected": -0.8811224102973938,
      "logps/chosen": -179.79183959960938,
      "logps/rejected": -191.9795684814453,
      "loss": 0.6831,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.9526581764221191,
      "rewards/margins": 0.30313828587532043,
      "rewards/rejected": -1.2557963132858276,
      "step": 1750
    },
    {
      "epoch": 0.523887483256437,
      "grad_norm": 3.9804675579071045,
      "learning_rate": 7.227635926704717e-05,
      "logits/chosen": -0.8154557943344116,
      "logits/rejected": -0.8430795669555664,
      "logps/chosen": -175.48141479492188,
      "logps/rejected": -187.54568481445312,
      "loss": 0.6931,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.130425214767456,
      "rewards/margins": 0.2894608974456787,
      "rewards/rejected": -1.4198863506317139,
      "step": 1760
    },
    {
      "epoch": 0.5268641166840303,
      "grad_norm": 3.746126413345337,
      "learning_rate": 7.222829678582157e-05,
      "logits/chosen": -0.8171979784965515,
      "logits/rejected": -0.8603159785270691,
      "logps/chosen": -193.27084350585938,
      "logps/rejected": -204.18099975585938,
      "loss": 0.6075,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.1062142848968506,
      "rewards/margins": 0.4522288739681244,
      "rewards/rejected": -1.558443307876587,
      "step": 1770
    },
    {
      "epoch": 0.5298407501116238,
      "grad_norm": 1.822403907775879,
      "learning_rate": 7.218023430459598e-05,
      "logits/chosen": -0.927914023399353,
      "logits/rejected": -0.8783625364303589,
      "logps/chosen": -201.52444458007812,
      "logps/rejected": -189.22935485839844,
      "loss": 0.5945,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.13124680519104,
      "rewards/margins": 0.48937273025512695,
      "rewards/rejected": -1.620619535446167,
      "step": 1780
    },
    {
      "epoch": 0.5328173835392171,
      "grad_norm": 3.9871394634246826,
      "learning_rate": 7.213217182337038e-05,
      "logits/chosen": -0.8708113431930542,
      "logits/rejected": -0.9467099905014038,
      "logps/chosen": -198.87600708007812,
      "logps/rejected": -220.197998046875,
      "loss": 0.612,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.5470874309539795,
      "rewards/margins": 0.6149423718452454,
      "rewards/rejected": -3.16202974319458,
      "step": 1790
    },
    {
      "epoch": 0.5357940169668105,
      "grad_norm": 3.8904504776000977,
      "learning_rate": 7.208410934214479e-05,
      "logits/chosen": -0.9720231294631958,
      "logits/rejected": -0.9478367567062378,
      "logps/chosen": -193.91656494140625,
      "logps/rejected": -195.8235626220703,
      "loss": 0.704,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.9774589538574219,
      "rewards/margins": 0.3288574814796448,
      "rewards/rejected": -2.3063161373138428,
      "step": 1800
    },
    {
      "epoch": 0.538770650394404,
      "grad_norm": 3.5039095878601074,
      "learning_rate": 7.20360468609192e-05,
      "logits/chosen": -0.8743468523025513,
      "logits/rejected": -0.9610827565193176,
      "logps/chosen": -185.91822814941406,
      "logps/rejected": -219.1413116455078,
      "loss": 0.5536,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7072263956069946,
      "rewards/margins": 0.8808467984199524,
      "rewards/rejected": -2.588073253631592,
      "step": 1810
    },
    {
      "epoch": 0.5417472838219973,
      "grad_norm": 3.378678798675537,
      "learning_rate": 7.19879843796936e-05,
      "logits/chosen": -0.9163988828659058,
      "logits/rejected": -0.9456316828727722,
      "logps/chosen": -171.34823608398438,
      "logps/rejected": -192.7887725830078,
      "loss": 0.5427,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.4167240858078003,
      "rewards/margins": 0.762859046459198,
      "rewards/rejected": -2.1795830726623535,
      "step": 1820
    },
    {
      "epoch": 0.5447239172495907,
      "grad_norm": 2.404367685317993,
      "learning_rate": 7.193992189846802e-05,
      "logits/chosen": -0.841174304485321,
      "logits/rejected": -0.8676074147224426,
      "logps/chosen": -194.93679809570312,
      "logps/rejected": -201.96078491210938,
      "loss": 0.5303,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.7422469854354858,
      "rewards/margins": 0.7832115888595581,
      "rewards/rejected": -2.525458812713623,
      "step": 1830
    },
    {
      "epoch": 0.5477005506771842,
      "grad_norm": 2.819387912750244,
      "learning_rate": 7.189185941724243e-05,
      "logits/chosen": -0.7473834753036499,
      "logits/rejected": -0.8550982475280762,
      "logps/chosen": -177.83164978027344,
      "logps/rejected": -217.30941772460938,
      "loss": 0.5556,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.6946697235107422,
      "rewards/margins": 0.8729019165039062,
      "rewards/rejected": -2.5675718784332275,
      "step": 1840
    },
    {
      "epoch": 0.5506771841047775,
      "grad_norm": 4.610118865966797,
      "learning_rate": 7.184379693601684e-05,
      "logits/chosen": -0.8227030634880066,
      "logits/rejected": -0.8588784337043762,
      "logps/chosen": -179.5529327392578,
      "logps/rejected": -191.06478881835938,
      "loss": 0.7459,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -1.3102734088897705,
      "rewards/margins": 0.3808271884918213,
      "rewards/rejected": -1.6911007165908813,
      "step": 1850
    },
    {
      "epoch": 0.5536538175323709,
      "grad_norm": 4.197263717651367,
      "learning_rate": 7.179573445479123e-05,
      "logits/chosen": -0.7498524188995361,
      "logits/rejected": -0.7945424318313599,
      "logps/chosen": -189.6427459716797,
      "logps/rejected": -203.78121948242188,
      "loss": 0.5875,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.2990083694458008,
      "rewards/margins": 0.6364342570304871,
      "rewards/rejected": -1.935442328453064,
      "step": 1860
    },
    {
      "epoch": 0.5566304509599643,
      "grad_norm": 3.6159534454345703,
      "learning_rate": 7.174767197356563e-05,
      "logits/chosen": -0.8079761266708374,
      "logits/rejected": -0.8337534070014954,
      "logps/chosen": -193.13629150390625,
      "logps/rejected": -205.68746948242188,
      "loss": 0.6317,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.2060647010803223,
      "rewards/margins": 0.5165966749191284,
      "rewards/rejected": -1.7226613759994507,
      "step": 1870
    },
    {
      "epoch": 0.5596070843875577,
      "grad_norm": 2.5246801376342773,
      "learning_rate": 7.169960949234004e-05,
      "logits/chosen": -0.826999306678772,
      "logits/rejected": -0.9116142392158508,
      "logps/chosen": -184.77511596679688,
      "logps/rejected": -207.3143768310547,
      "loss": 0.6113,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.8773248195648193,
      "rewards/margins": 0.5412057042121887,
      "rewards/rejected": -2.418530225753784,
      "step": 1880
    },
    {
      "epoch": 0.562583717815151,
      "grad_norm": 1.8639265298843384,
      "learning_rate": 7.165154701111445e-05,
      "logits/chosen": -0.8509751558303833,
      "logits/rejected": -0.8922152519226074,
      "logps/chosen": -179.3192596435547,
      "logps/rejected": -187.03634643554688,
      "loss": 0.5764,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3608198165893555,
      "rewards/margins": 0.6164065003395081,
      "rewards/rejected": -1.9772264957427979,
      "step": 1890
    },
    {
      "epoch": 0.5655603512427445,
      "grad_norm": 1.5607880353927612,
      "learning_rate": 7.160348452988887e-05,
      "logits/chosen": -0.7604408860206604,
      "logits/rejected": -0.8872579336166382,
      "logps/chosen": -186.07919311523438,
      "logps/rejected": -220.78945922851562,
      "loss": 0.5401,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.6916195154190063,
      "rewards/margins": 0.7302623987197876,
      "rewards/rejected": -2.421882152557373,
      "step": 1900
    },
    {
      "epoch": 0.5685369846703379,
      "grad_norm": 3.9446046352386475,
      "learning_rate": 7.155542204866327e-05,
      "logits/chosen": -0.8156787753105164,
      "logits/rejected": -0.8706666231155396,
      "logps/chosen": -189.69552612304688,
      "logps/rejected": -202.18545532226562,
      "loss": 0.678,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.6004302501678467,
      "rewards/margins": 0.5355358123779297,
      "rewards/rejected": -2.1359663009643555,
      "step": 1910
    },
    {
      "epoch": 0.5715136180979312,
      "grad_norm": 4.919641494750977,
      "learning_rate": 7.150735956743768e-05,
      "logits/chosen": -0.8084006309509277,
      "logits/rejected": -0.8178125619888306,
      "logps/chosen": -193.21446228027344,
      "logps/rejected": -204.8572540283203,
      "loss": 0.6724,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.214043378829956,
      "rewards/margins": 0.3264677822589874,
      "rewards/rejected": -1.5405113697052002,
      "step": 1920
    },
    {
      "epoch": 0.5744902515255247,
      "grad_norm": 2.387192487716675,
      "learning_rate": 7.145929708621208e-05,
      "logits/chosen": -0.8177211880683899,
      "logits/rejected": -0.9048296213150024,
      "logps/chosen": -176.4480743408203,
      "logps/rejected": -198.54360961914062,
      "loss": 0.6558,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.1325318813323975,
      "rewards/margins": 0.414360910654068,
      "rewards/rejected": -1.5468926429748535,
      "step": 1930
    },
    {
      "epoch": 0.577466884953118,
      "grad_norm": 3.9699015617370605,
      "learning_rate": 7.141123460498649e-05,
      "logits/chosen": -0.8495432138442993,
      "logits/rejected": -0.9162184000015259,
      "logps/chosen": -185.37991333007812,
      "logps/rejected": -205.2489471435547,
      "loss": 0.582,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.4571123123168945,
      "rewards/margins": 0.4727083146572113,
      "rewards/rejected": -1.9298204183578491,
      "step": 1940
    },
    {
      "epoch": 0.5804435183807114,
      "grad_norm": 8.592153549194336,
      "learning_rate": 7.13631721237609e-05,
      "logits/chosen": -0.8479089736938477,
      "logits/rejected": -0.8039817810058594,
      "logps/chosen": -194.78269958496094,
      "logps/rejected": -190.43202209472656,
      "loss": 0.5876,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.6587755680084229,
      "rewards/margins": 0.47143858671188354,
      "rewards/rejected": -2.130213975906372,
      "step": 1950
    },
    {
      "epoch": 0.5834201518083048,
      "grad_norm": 4.953104019165039,
      "learning_rate": 7.13151096425353e-05,
      "logits/chosen": -0.8106791377067566,
      "logits/rejected": -0.8238639831542969,
      "logps/chosen": -194.1484375,
      "logps/rejected": -204.41152954101562,
      "loss": 0.584,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.9537570476531982,
      "rewards/margins": 0.4904858469963074,
      "rewards/rejected": -2.4442429542541504,
      "step": 1960
    },
    {
      "epoch": 0.5863967852358982,
      "grad_norm": 4.05232572555542,
      "learning_rate": 7.126704716130971e-05,
      "logits/chosen": -0.7570921778678894,
      "logits/rejected": -0.8238348960876465,
      "logps/chosen": -193.64141845703125,
      "logps/rejected": -207.5658721923828,
      "loss": 0.6604,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.9831085205078125,
      "rewards/margins": 0.4089873731136322,
      "rewards/rejected": -2.3920960426330566,
      "step": 1970
    },
    {
      "epoch": 0.5893734186634916,
      "grad_norm": 2.725094795227051,
      "learning_rate": 7.121898468008412e-05,
      "logits/chosen": -0.81226646900177,
      "logits/rejected": -0.8188245892524719,
      "logps/chosen": -185.8225555419922,
      "logps/rejected": -196.81178283691406,
      "loss": 0.6454,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.473853349685669,
      "rewards/margins": 0.4288483262062073,
      "rewards/rejected": -1.9027013778686523,
      "step": 1980
    },
    {
      "epoch": 0.5923500520910849,
      "grad_norm": Infinity,
      "learning_rate": 7.117572844698109e-05,
      "logits/chosen": -0.7787488698959351,
      "logits/rejected": -0.8218138813972473,
      "logps/chosen": -182.76748657226562,
      "logps/rejected": -194.4145050048828,
      "loss": 0.5562,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.416934609413147,
      "rewards/margins": 0.6335715055465698,
      "rewards/rejected": -2.050506114959717,
      "step": 1990
    },
    {
      "epoch": 0.5953266855186784,
      "grad_norm": 4.013278007507324,
      "learning_rate": 7.112766596575548e-05,
      "logits/chosen": -0.8035497665405273,
      "logits/rejected": -0.8145018815994263,
      "logps/chosen": -190.0870819091797,
      "logps/rejected": -193.81863403320312,
      "loss": 0.6394,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.5550167560577393,
      "rewards/margins": 0.5644631385803223,
      "rewards/rejected": -2.1194801330566406,
      "step": 2000
    },
    {
      "epoch": 0.5983033189462718,
      "grad_norm": 2.781841516494751,
      "learning_rate": 7.107960348452989e-05,
      "logits/chosen": -0.8406835794448853,
      "logits/rejected": -0.9083505868911743,
      "logps/chosen": -172.8799591064453,
      "logps/rejected": -195.173828125,
      "loss": 0.539,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.6908824443817139,
      "rewards/margins": 0.7767914533615112,
      "rewards/rejected": -2.4676737785339355,
      "step": 2010
    },
    {
      "epoch": 0.6012799523738651,
      "grad_norm": 1.8132328987121582,
      "learning_rate": 7.10315410033043e-05,
      "logits/chosen": -0.799079418182373,
      "logits/rejected": -0.8375774621963501,
      "logps/chosen": -191.4585418701172,
      "logps/rejected": -220.1946258544922,
      "loss": 0.5427,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7688789367675781,
      "rewards/margins": 0.9470335841178894,
      "rewards/rejected": -2.715912342071533,
      "step": 2020
    },
    {
      "epoch": 0.6042565858014586,
      "grad_norm": 2.426038980484009,
      "learning_rate": 7.09834785220787e-05,
      "logits/chosen": -0.8140174746513367,
      "logits/rejected": -0.9474841952323914,
      "logps/chosen": -165.90872192382812,
      "logps/rejected": -204.61219787597656,
      "loss": 0.5171,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.3958144187927246,
      "rewards/margins": 0.9101747274398804,
      "rewards/rejected": -2.3059890270233154,
      "step": 2030
    },
    {
      "epoch": 0.6072332192290519,
      "grad_norm": 2.7128665447235107,
      "learning_rate": 7.093541604085312e-05,
      "logits/chosen": -0.9227206110954285,
      "logits/rejected": -0.9710836410522461,
      "logps/chosen": -212.39413452148438,
      "logps/rejected": -232.532958984375,
      "loss": 0.6426,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.4869742393493652,
      "rewards/margins": 0.969841480255127,
      "rewards/rejected": -3.456815719604492,
      "step": 2040
    },
    {
      "epoch": 0.6102098526566453,
      "grad_norm": 2.645390272140503,
      "learning_rate": 7.088735355962753e-05,
      "logits/chosen": -0.8735041618347168,
      "logits/rejected": -0.9381577372550964,
      "logps/chosen": -186.81959533691406,
      "logps/rejected": -213.207275390625,
      "loss": 0.6357,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -2.4975523948669434,
      "rewards/margins": 0.5709877610206604,
      "rewards/rejected": -3.068540096282959,
      "step": 2050
    },
    {
      "epoch": 0.6131864860842388,
      "grad_norm": 3.965702533721924,
      "learning_rate": 7.083929107840193e-05,
      "logits/chosen": -0.8992296457290649,
      "logits/rejected": -0.9014223217964172,
      "logps/chosen": -203.03504943847656,
      "logps/rejected": -214.8361358642578,
      "loss": 0.6635,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.2269952297210693,
      "rewards/margins": 0.5106884241104126,
      "rewards/rejected": -2.7376837730407715,
      "step": 2060
    },
    {
      "epoch": 0.6161631195118321,
      "grad_norm": 5.809253215789795,
      "learning_rate": 7.079122859717634e-05,
      "logits/chosen": -0.9349378347396851,
      "logits/rejected": -0.946928858757019,
      "logps/chosen": -185.36685180664062,
      "logps/rejected": -191.52987670898438,
      "loss": 0.628,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.6555083990097046,
      "rewards/margins": 0.6179019212722778,
      "rewards/rejected": -2.2734103202819824,
      "step": 2070
    },
    {
      "epoch": 0.6191397529394255,
      "grad_norm": 2.9749908447265625,
      "learning_rate": 7.074316611595074e-05,
      "logits/chosen": -0.7643545866012573,
      "logits/rejected": -0.8716063499450684,
      "logps/chosen": -195.26202392578125,
      "logps/rejected": -231.73544311523438,
      "loss": 0.5482,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.1662380695343018,
      "rewards/margins": 0.8149053454399109,
      "rewards/rejected": -2.9811434745788574,
      "step": 2080
    },
    {
      "epoch": 0.6221163863670189,
      "grad_norm": 3.6529057025909424,
      "learning_rate": 7.069510363472515e-05,
      "logits/chosen": -0.8404330015182495,
      "logits/rejected": -0.866291344165802,
      "logps/chosen": -195.03964233398438,
      "logps/rejected": -206.8406982421875,
      "loss": 0.6373,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.113640308380127,
      "rewards/margins": 0.5413334965705872,
      "rewards/rejected": -2.6549735069274902,
      "step": 2090
    },
    {
      "epoch": 0.6250930197946123,
      "grad_norm": 3.009639263153076,
      "learning_rate": 7.064704115349956e-05,
      "logits/chosen": -0.8719316720962524,
      "logits/rejected": -0.92259281873703,
      "logps/chosen": -196.63800048828125,
      "logps/rejected": -216.1446533203125,
      "loss": 0.574,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.149139404296875,
      "rewards/margins": 0.8854495286941528,
      "rewards/rejected": -3.0345890522003174,
      "step": 2100
    },
    {
      "epoch": 0.6280696532222056,
      "grad_norm": 4.538352012634277,
      "learning_rate": 7.059897867227396e-05,
      "logits/chosen": -0.8923214077949524,
      "logits/rejected": -0.9528707265853882,
      "logps/chosen": -202.92721557617188,
      "logps/rejected": -220.94284057617188,
      "loss": 0.7091,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -2.5779669284820557,
      "rewards/margins": 0.32582587003707886,
      "rewards/rejected": -2.9037928581237793,
      "step": 2110
    },
    {
      "epoch": 0.6310462866497991,
      "grad_norm": 3.7455055713653564,
      "learning_rate": 7.055091619104837e-05,
      "logits/chosen": -0.8864187002182007,
      "logits/rejected": -0.9369841814041138,
      "logps/chosen": -190.2439727783203,
      "logps/rejected": -209.3750762939453,
      "loss": 0.569,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.1607472896575928,
      "rewards/margins": 0.6793943047523499,
      "rewards/rejected": -2.840141534805298,
      "step": 2120
    },
    {
      "epoch": 0.6340229200773925,
      "grad_norm": 4.956562042236328,
      "learning_rate": 7.050285370982277e-05,
      "logits/chosen": -0.8748683929443359,
      "logits/rejected": -0.8757928013801575,
      "logps/chosen": -186.8656768798828,
      "logps/rejected": -196.31739807128906,
      "loss": 0.5986,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4439500570297241,
      "rewards/margins": 0.6608331799507141,
      "rewards/rejected": -2.104783296585083,
      "step": 2130
    },
    {
      "epoch": 0.6369995535049858,
      "grad_norm": 3.306110382080078,
      "learning_rate": 7.045479122859718e-05,
      "logits/chosen": -0.8384490013122559,
      "logits/rejected": -0.7886229157447815,
      "logps/chosen": -189.73614501953125,
      "logps/rejected": -192.03781127929688,
      "loss": 0.5631,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.9161168932914734,
      "rewards/margins": 0.6682487726211548,
      "rewards/rejected": -1.5843656063079834,
      "step": 2140
    },
    {
      "epoch": 0.6399761869325793,
      "grad_norm": 2.4446218013763428,
      "learning_rate": 7.040672874737159e-05,
      "logits/chosen": -0.8028393983840942,
      "logits/rejected": -0.9398038983345032,
      "logps/chosen": -167.08746337890625,
      "logps/rejected": -210.0466766357422,
      "loss": 0.5305,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.56170654296875,
      "rewards/margins": 0.8272544145584106,
      "rewards/rejected": -2.38896107673645,
      "step": 2150
    },
    {
      "epoch": 0.6429528203601726,
      "grad_norm": 4.619171619415283,
      "learning_rate": 7.0358666266146e-05,
      "logits/chosen": -0.8321369290351868,
      "logits/rejected": -0.8897380828857422,
      "logps/chosen": -174.43435668945312,
      "logps/rejected": -212.04147338867188,
      "loss": 0.5209,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.7804820537567139,
      "rewards/margins": 0.8925204277038574,
      "rewards/rejected": -2.673002243041992,
      "step": 2160
    },
    {
      "epoch": 0.645929453787766,
      "grad_norm": 2.9758529663085938,
      "learning_rate": 7.03106037849204e-05,
      "logits/chosen": -0.9057415723800659,
      "logits/rejected": -0.9921849966049194,
      "logps/chosen": -194.69406127929688,
      "logps/rejected": -233.6082763671875,
      "loss": 0.5672,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.7119076251983643,
      "rewards/margins": 1.1156339645385742,
      "rewards/rejected": -3.827540874481201,
      "step": 2170
    },
    {
      "epoch": 0.6489060872153595,
      "grad_norm": 3.356480121612549,
      "learning_rate": 7.02625413036948e-05,
      "logits/chosen": -0.9886916875839233,
      "logits/rejected": -1.0733588933944702,
      "logps/chosen": -197.85568237304688,
      "logps/rejected": -224.2259979248047,
      "loss": 0.6702,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -2.7795333862304688,
      "rewards/margins": 0.5378631949424744,
      "rewards/rejected": -3.317396640777588,
      "step": 2180
    },
    {
      "epoch": 0.6518827206429528,
      "grad_norm": 4.944113254547119,
      "learning_rate": 7.021447882246921e-05,
      "logits/chosen": -1.0105335712432861,
      "logits/rejected": -1.0764727592468262,
      "logps/chosen": -197.4431610107422,
      "logps/rejected": -226.98837280273438,
      "loss": 0.5997,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -3.5327553749084473,
      "rewards/margins": 0.6574137210845947,
      "rewards/rejected": -4.190169334411621,
      "step": 2190
    },
    {
      "epoch": 0.6548593540705462,
      "grad_norm": 5.037261962890625,
      "learning_rate": 7.016641634124362e-05,
      "logits/chosen": -1.060044527053833,
      "logits/rejected": -1.1127997636795044,
      "logps/chosen": -199.02151489257812,
      "logps/rejected": -222.55148315429688,
      "loss": 0.6037,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -3.320089340209961,
      "rewards/margins": 0.7244848608970642,
      "rewards/rejected": -4.04457426071167,
      "step": 2200
    },
    {
      "epoch": 0.6578359874981397,
      "grad_norm": 2.2991397380828857,
      "learning_rate": 7.011835386001804e-05,
      "logits/chosen": -0.9639589190483093,
      "logits/rejected": -0.9666935801506042,
      "logps/chosen": -203.32394409179688,
      "logps/rejected": -218.01358032226562,
      "loss": 0.529,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.2814278602600098,
      "rewards/margins": 0.8913923501968384,
      "rewards/rejected": -3.172820568084717,
      "step": 2210
    },
    {
      "epoch": 0.660812620925733,
      "grad_norm": 4.556965351104736,
      "learning_rate": 7.007029137879244e-05,
      "logits/chosen": -0.9728258848190308,
      "logits/rejected": -1.0158816576004028,
      "logps/chosen": -194.72128295898438,
      "logps/rejected": -216.33248901367188,
      "loss": 0.5937,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.9205493927001953,
      "rewards/margins": 0.7720879316329956,
      "rewards/rejected": -3.6926372051239014,
      "step": 2220
    },
    {
      "epoch": 0.6637892543533264,
      "grad_norm": 6.31085729598999,
      "learning_rate": 7.002222889756685e-05,
      "logits/chosen": -1.0029231309890747,
      "logits/rejected": -1.081437587738037,
      "logps/chosen": -199.10696411132812,
      "logps/rejected": -228.25588989257812,
      "loss": 0.6168,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -3.20969820022583,
      "rewards/margins": 0.6827950477600098,
      "rewards/rejected": -3.8924930095672607,
      "step": 2230
    },
    {
      "epoch": 0.6667658877809198,
      "grad_norm": 6.460172653198242,
      "learning_rate": 6.997416641634126e-05,
      "logits/chosen": -0.9519510269165039,
      "logits/rejected": -1.016565203666687,
      "logps/chosen": -192.2548065185547,
      "logps/rejected": -228.2013702392578,
      "loss": 0.5331,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.177849292755127,
      "rewards/margins": 1.0301494598388672,
      "rewards/rejected": -4.207998752593994,
      "step": 2240
    },
    {
      "epoch": 0.6697425212085132,
      "grad_norm": 4.4539008140563965,
      "learning_rate": 6.992610393511565e-05,
      "logits/chosen": -0.9010421633720398,
      "logits/rejected": -0.9259635210037231,
      "logps/chosen": -199.75955200195312,
      "logps/rejected": -207.86178588867188,
      "loss": 0.617,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.762547254562378,
      "rewards/margins": 0.7049922943115234,
      "rewards/rejected": -3.4675395488739014,
      "step": 2250
    },
    {
      "epoch": 0.6727191546361065,
      "grad_norm": 3.3561272621154785,
      "learning_rate": 6.987804145389005e-05,
      "logits/chosen": -0.7672104239463806,
      "logits/rejected": -0.798870325088501,
      "logps/chosen": -184.5234375,
      "logps/rejected": -204.8805694580078,
      "loss": 0.5625,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.1256661415100098,
      "rewards/margins": 0.6818670630455017,
      "rewards/rejected": -2.8075332641601562,
      "step": 2260
    },
    {
      "epoch": 0.6756957880637,
      "grad_norm": 2.242572784423828,
      "learning_rate": 6.982997897266446e-05,
      "logits/chosen": -0.7064734101295471,
      "logits/rejected": -0.7696767449378967,
      "logps/chosen": -188.17318725585938,
      "logps/rejected": -221.52859497070312,
      "loss": 0.578,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.3748583793640137,
      "rewards/margins": 0.7633601427078247,
      "rewards/rejected": -3.138218641281128,
      "step": 2270
    },
    {
      "epoch": 0.6786724214912934,
      "grad_norm": 4.334688663482666,
      "learning_rate": 6.978191649143888e-05,
      "logits/chosen": -0.7799808979034424,
      "logits/rejected": -0.7885816693305969,
      "logps/chosen": -202.4123992919922,
      "logps/rejected": -213.7053680419922,
      "loss": 0.7027,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -2.200498342514038,
      "rewards/margins": 0.4614063799381256,
      "rewards/rejected": -2.6619045734405518,
      "step": 2280
    },
    {
      "epoch": 0.6816490549188867,
      "grad_norm": 6.113214015960693,
      "learning_rate": 6.973385401021329e-05,
      "logits/chosen": -0.8640464544296265,
      "logits/rejected": -0.8956620097160339,
      "logps/chosen": -178.39505004882812,
      "logps/rejected": -197.27645874023438,
      "loss": 0.6332,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.0607962608337402,
      "rewards/margins": 0.5944253206253052,
      "rewards/rejected": -2.655221700668335,
      "step": 2290
    },
    {
      "epoch": 0.6846256883464801,
      "grad_norm": 4.913014888763428,
      "learning_rate": 6.968579152898769e-05,
      "logits/chosen": -0.8502591252326965,
      "logits/rejected": -0.8860637545585632,
      "logps/chosen": -188.48989868164062,
      "logps/rejected": -203.58511352539062,
      "loss": 0.5678,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.3485276699066162,
      "rewards/margins": 0.9698403477668762,
      "rewards/rejected": -2.3183679580688477,
      "step": 2300
    },
    {
      "epoch": 0.6876023217740735,
      "grad_norm": 4.517670631408691,
      "learning_rate": 6.96377290477621e-05,
      "logits/chosen": -0.8832725286483765,
      "logits/rejected": -0.8968575596809387,
      "logps/chosen": -202.2191925048828,
      "logps/rejected": -206.5677032470703,
      "loss": 0.6052,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.5575695037841797,
      "rewards/margins": 0.5582810640335083,
      "rewards/rejected": -2.1158504486083984,
      "step": 2310
    },
    {
      "epoch": 0.6905789552016669,
      "grad_norm": 3.8789000511169434,
      "learning_rate": 6.95896665665365e-05,
      "logits/chosen": -0.8762456774711609,
      "logits/rejected": -0.8617225885391235,
      "logps/chosen": -200.9715118408203,
      "logps/rejected": -198.95748901367188,
      "loss": 0.6619,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.5372788906097412,
      "rewards/margins": 0.5682910084724426,
      "rewards/rejected": -2.105569839477539,
      "step": 2320
    },
    {
      "epoch": 0.6935555886292603,
      "grad_norm": 3.598747491836548,
      "learning_rate": 6.954160408531091e-05,
      "logits/chosen": -0.8019242286682129,
      "logits/rejected": -0.7781111598014832,
      "logps/chosen": -189.95188903808594,
      "logps/rejected": -198.22145080566406,
      "loss": 0.5648,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.347509503364563,
      "rewards/margins": 0.7450476884841919,
      "rewards/rejected": -2.092557191848755,
      "step": 2330
    },
    {
      "epoch": 0.6965322220568537,
      "grad_norm": 2.7185544967651367,
      "learning_rate": 6.949354160408532e-05,
      "logits/chosen": -0.862270712852478,
      "logits/rejected": -0.9446060061454773,
      "logps/chosen": -183.97628784179688,
      "logps/rejected": -220.28695678710938,
      "loss": 0.607,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.4178001880645752,
      "rewards/margins": 0.9359077215194702,
      "rewards/rejected": -2.353708028793335,
      "step": 2340
    },
    {
      "epoch": 0.6995088554844471,
      "grad_norm": 3.654336452484131,
      "learning_rate": 6.944547912285972e-05,
      "logits/chosen": -0.8354101181030273,
      "logits/rejected": -0.820086658000946,
      "logps/chosen": -206.86734008789062,
      "logps/rejected": -213.6166229248047,
      "loss": 0.6017,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.538681983947754,
      "rewards/margins": 0.6287951469421387,
      "rewards/rejected": -2.1674771308898926,
      "step": 2350
    },
    {
      "epoch": 0.7024854889120404,
      "grad_norm": 5.50062370300293,
      "learning_rate": 6.939741664163413e-05,
      "logits/chosen": -0.8009994626045227,
      "logits/rejected": -0.7999467849731445,
      "logps/chosen": -196.4537811279297,
      "logps/rejected": -196.5510711669922,
      "loss": 0.7022,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -1.5013267993927002,
      "rewards/margins": 0.36338919401168823,
      "rewards/rejected": -1.8647159337997437,
      "step": 2360
    },
    {
      "epoch": 0.7054621223396339,
      "grad_norm": 5.658552646636963,
      "learning_rate": 6.934935416040854e-05,
      "logits/chosen": -0.8128096461296082,
      "logits/rejected": -0.922163188457489,
      "logps/chosen": -179.62071228027344,
      "logps/rejected": -205.4830322265625,
      "loss": 0.6021,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.7107261419296265,
      "rewards/margins": 0.5068203210830688,
      "rewards/rejected": -2.217546224594116,
      "step": 2370
    },
    {
      "epoch": 0.7084387557672273,
      "grad_norm": 2.3360424041748047,
      "learning_rate": 6.930129167918294e-05,
      "logits/chosen": -0.8230779767036438,
      "logits/rejected": -0.870805561542511,
      "logps/chosen": -195.75389099121094,
      "logps/rejected": -216.1524200439453,
      "loss": 0.6089,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.2441017627716064,
      "rewards/margins": 0.6420840620994568,
      "rewards/rejected": -2.886185884475708,
      "step": 2380
    },
    {
      "epoch": 0.7114153891948206,
      "grad_norm": 3.480652093887329,
      "learning_rate": 6.925322919795735e-05,
      "logits/chosen": -0.7940609455108643,
      "logits/rejected": -0.8728139996528625,
      "logps/chosen": -195.41012573242188,
      "logps/rejected": -220.0330047607422,
      "loss": 0.6391,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -2.076608180999756,
      "rewards/margins": 0.510009229183197,
      "rewards/rejected": -2.5866177082061768,
      "step": 2390
    },
    {
      "epoch": 0.7143920226224141,
      "grad_norm": 2.9067418575286865,
      "learning_rate": 6.920516671673175e-05,
      "logits/chosen": -0.8862215280532837,
      "logits/rejected": -0.9277852177619934,
      "logps/chosen": -191.42794799804688,
      "logps/rejected": -205.22958374023438,
      "loss": 0.5485,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3763056993484497,
      "rewards/margins": 0.6821569800376892,
      "rewards/rejected": -2.058462619781494,
      "step": 2400
    },
    {
      "epoch": 0.7173686560500074,
      "grad_norm": 2.152268171310425,
      "learning_rate": 6.915710423550616e-05,
      "logits/chosen": -0.8244490623474121,
      "logits/rejected": -0.9096195101737976,
      "logps/chosen": -186.56393432617188,
      "logps/rejected": -221.41696166992188,
      "loss": 0.6003,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.129755735397339,
      "rewards/margins": 0.5487379431724548,
      "rewards/rejected": -2.6784934997558594,
      "step": 2410
    },
    {
      "epoch": 0.7203452894776008,
      "grad_norm": 3.1451103687286377,
      "learning_rate": 6.910904175428057e-05,
      "logits/chosen": -0.9775108098983765,
      "logits/rejected": -0.9868971109390259,
      "logps/chosen": -189.2052459716797,
      "logps/rejected": -193.92051696777344,
      "loss": 0.6484,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -2.0195608139038086,
      "rewards/margins": 0.3757934868335724,
      "rewards/rejected": -2.3953542709350586,
      "step": 2420
    },
    {
      "epoch": 0.7233219229051943,
      "grad_norm": 2.636077404022217,
      "learning_rate": 6.906097927305497e-05,
      "logits/chosen": -0.8758786916732788,
      "logits/rejected": -0.9460700750350952,
      "logps/chosen": -204.49224853515625,
      "logps/rejected": -229.51852416992188,
      "loss": 0.6279,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.4488346576690674,
      "rewards/margins": 0.4694032669067383,
      "rewards/rejected": -2.9182376861572266,
      "step": 2430
    },
    {
      "epoch": 0.7262985563327876,
      "grad_norm": 4.239707946777344,
      "learning_rate": 6.901291679182938e-05,
      "logits/chosen": -0.9316617250442505,
      "logits/rejected": -0.9684608578681946,
      "logps/chosen": -204.56344604492188,
      "logps/rejected": -222.19021606445312,
      "loss": 0.6207,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -2.313499927520752,
      "rewards/margins": 0.49829205870628357,
      "rewards/rejected": -2.8117918968200684,
      "step": 2440
    },
    {
      "epoch": 0.729275189760381,
      "grad_norm": 3.920154094696045,
      "learning_rate": 6.89648543106038e-05,
      "logits/chosen": -0.9898079633712769,
      "logits/rejected": -1.089538812637329,
      "logps/chosen": -176.01864624023438,
      "logps/rejected": -217.38998413085938,
      "loss": 0.5728,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.490255355834961,
      "rewards/margins": 0.6616902351379395,
      "rewards/rejected": -3.1519455909729004,
      "step": 2450
    },
    {
      "epoch": 0.7322518231879744,
      "grad_norm": 5.301992893218994,
      "learning_rate": 6.89167918293782e-05,
      "logits/chosen": -1.0613367557525635,
      "logits/rejected": -1.0948246717453003,
      "logps/chosen": -179.89584350585938,
      "logps/rejected": -196.56829833984375,
      "loss": 0.5279,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.641110897064209,
      "rewards/margins": 0.7393562197685242,
      "rewards/rejected": -3.380466938018799,
      "step": 2460
    },
    {
      "epoch": 0.7352284566155678,
      "grad_norm": 6.88953971862793,
      "learning_rate": 6.886872934815261e-05,
      "logits/chosen": -1.051489233970642,
      "logits/rejected": -1.09092378616333,
      "logps/chosen": -185.1536865234375,
      "logps/rejected": -195.44032287597656,
      "loss": 0.693,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.690396308898926,
      "rewards/margins": 0.3631100058555603,
      "rewards/rejected": -3.0535061359405518,
      "step": 2470
    },
    {
      "epoch": 0.7382050900431611,
      "grad_norm": 3.7646498680114746,
      "learning_rate": 6.882066686692702e-05,
      "logits/chosen": -1.0250732898712158,
      "logits/rejected": -1.0103213787078857,
      "logps/chosen": -209.5425567626953,
      "logps/rejected": -206.5584716796875,
      "loss": 0.7236,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -2.333961009979248,
      "rewards/margins": 0.27341675758361816,
      "rewards/rejected": -2.607377767562866,
      "step": 2480
    },
    {
      "epoch": 0.7411817234707546,
      "grad_norm": 3.783259391784668,
      "learning_rate": 6.877260438570141e-05,
      "logits/chosen": -0.9106239080429077,
      "logits/rejected": -0.9019454121589661,
      "logps/chosen": -189.0754852294922,
      "logps/rejected": -203.63101196289062,
      "loss": 0.6146,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -1.811934232711792,
      "rewards/margins": 0.6656922101974487,
      "rewards/rejected": -2.477626323699951,
      "step": 2490
    },
    {
      "epoch": 0.744158356898348,
      "grad_norm": 4.176761150360107,
      "learning_rate": 6.872454190447582e-05,
      "logits/chosen": -0.8977394104003906,
      "logits/rejected": -0.9325630068778992,
      "logps/chosen": -183.6981964111328,
      "logps/rejected": -196.3212890625,
      "loss": 0.6187,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.5012788772583008,
      "rewards/margins": 0.5798512101173401,
      "rewards/rejected": -2.081130266189575,
      "step": 2500
    },
    {
      "epoch": 0.7471349903259413,
      "grad_norm": 1.868334412574768,
      "learning_rate": 6.867647942325022e-05,
      "logits/chosen": -0.9133443832397461,
      "logits/rejected": -0.9406349062919617,
      "logps/chosen": -189.22789001464844,
      "logps/rejected": -205.2772216796875,
      "loss": 0.5794,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1812264919281006,
      "rewards/margins": 0.7347365617752075,
      "rewards/rejected": -1.9159629344940186,
      "step": 2510
    },
    {
      "epoch": 0.7501116237535348,
      "grad_norm": 2.914776563644409,
      "learning_rate": 6.862841694202464e-05,
      "logits/chosen": -0.9347526431083679,
      "logits/rejected": -0.8745311498641968,
      "logps/chosen": -186.20846557617188,
      "logps/rejected": -182.29861450195312,
      "loss": 0.616,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.2229257822036743,
      "rewards/margins": 0.39908522367477417,
      "rewards/rejected": -1.6220108270645142,
      "step": 2520
    },
    {
      "epoch": 0.7530882571811282,
      "grad_norm": 2.2015421390533447,
      "learning_rate": 6.858035446079905e-05,
      "logits/chosen": -0.8058239221572876,
      "logits/rejected": -0.8142188787460327,
      "logps/chosen": -188.16433715820312,
      "logps/rejected": -193.4334716796875,
      "loss": 0.5844,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2313346862792969,
      "rewards/margins": 0.7531031370162964,
      "rewards/rejected": -1.9844377040863037,
      "step": 2530
    },
    {
      "epoch": 0.7560648906087215,
      "grad_norm": 3.6915478706359863,
      "learning_rate": 6.853229197957345e-05,
      "logits/chosen": -0.7708162069320679,
      "logits/rejected": -0.8465433120727539,
      "logps/chosen": -193.2525634765625,
      "logps/rejected": -216.1611785888672,
      "loss": 0.5934,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.5584125518798828,
      "rewards/margins": 0.6514273881912231,
      "rewards/rejected": -2.2098400592803955,
      "step": 2540
    },
    {
      "epoch": 0.759041524036315,
      "grad_norm": 2.5907390117645264,
      "learning_rate": 6.848422949834786e-05,
      "logits/chosen": -0.8323779106140137,
      "logits/rejected": -0.8067895174026489,
      "logps/chosen": -196.62081909179688,
      "logps/rejected": -197.7082061767578,
      "loss": 0.6878,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.2796754837036133,
      "rewards/margins": 0.32524174451828003,
      "rewards/rejected": -1.6049175262451172,
      "step": 2550
    },
    {
      "epoch": 0.7620181574639083,
      "grad_norm": 4.156843662261963,
      "learning_rate": 6.843616701712227e-05,
      "logits/chosen": -0.7929641604423523,
      "logits/rejected": -0.8329683542251587,
      "logps/chosen": -187.92803955078125,
      "logps/rejected": -201.49020385742188,
      "loss": 0.5596,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.50421941280365,
      "rewards/margins": 0.6237403154373169,
      "rewards/rejected": -2.127959728240967,
      "step": 2560
    },
    {
      "epoch": 0.7649947908915017,
      "grad_norm": 2.635838508605957,
      "learning_rate": 6.838810453589667e-05,
      "logits/chosen": -0.7906769514083862,
      "logits/rejected": -0.8017072677612305,
      "logps/chosen": -178.52017211914062,
      "logps/rejected": -185.91648864746094,
      "loss": 0.5494,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.621441125869751,
      "rewards/margins": 0.7160421013832092,
      "rewards/rejected": -2.3374831676483154,
      "step": 2570
    },
    {
      "epoch": 0.7679714243190952,
      "grad_norm": 2.87979793548584,
      "learning_rate": 6.834004205467108e-05,
      "logits/chosen": -0.8443522453308105,
      "logits/rejected": -0.924353301525116,
      "logps/chosen": -214.0017852783203,
      "logps/rejected": -235.66915893554688,
      "loss": 0.5475,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.7052154541015625,
      "rewards/margins": 0.8279345631599426,
      "rewards/rejected": -3.5331501960754395,
      "step": 2580
    },
    {
      "epoch": 0.7709480577466885,
      "grad_norm": 2.9504895210266113,
      "learning_rate": 6.829197957344548e-05,
      "logits/chosen": -0.7843652963638306,
      "logits/rejected": -0.7974057197570801,
      "logps/chosen": -194.2433624267578,
      "logps/rejected": -200.22308349609375,
      "loss": 0.5901,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.7781381607055664,
      "rewards/margins": 0.5341330766677856,
      "rewards/rejected": -3.3122706413269043,
      "step": 2590
    },
    {
      "epoch": 0.7739246911742819,
      "grad_norm": 4.223634719848633,
      "learning_rate": 6.824391709221989e-05,
      "logits/chosen": -0.7943746447563171,
      "logits/rejected": -0.8248971700668335,
      "logps/chosen": -199.85995483398438,
      "logps/rejected": -215.3144073486328,
      "loss": 0.7067,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.1531143188476562,
      "rewards/margins": 0.5934410095214844,
      "rewards/rejected": -2.7465553283691406,
      "step": 2600
    },
    {
      "epoch": 0.7769013246018753,
      "grad_norm": 4.774094581604004,
      "learning_rate": 6.81958546109943e-05,
      "logits/chosen": -0.9242231249809265,
      "logits/rejected": -0.9093729853630066,
      "logps/chosen": -195.74644470214844,
      "logps/rejected": -197.26698303222656,
      "loss": 0.5837,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0647897720336914,
      "rewards/margins": 0.5863233804702759,
      "rewards/rejected": -2.651113271713257,
      "step": 2610
    },
    {
      "epoch": 0.7798779580294687,
      "grad_norm": 2.6316869258880615,
      "learning_rate": 6.81477921297687e-05,
      "logits/chosen": -0.8739868402481079,
      "logits/rejected": -0.8982722163200378,
      "logps/chosen": -184.72950744628906,
      "logps/rejected": -199.61666870117188,
      "loss": 0.4952,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9974238872528076,
      "rewards/margins": 0.858542799949646,
      "rewards/rejected": -2.855966806411743,
      "step": 2620
    },
    {
      "epoch": 0.782854591457062,
      "grad_norm": 4.017105579376221,
      "learning_rate": 6.809972964854311e-05,
      "logits/chosen": -0.9231332540512085,
      "logits/rejected": -1.020018219947815,
      "logps/chosen": -199.54368591308594,
      "logps/rejected": -222.64208984375,
      "loss": 0.5599,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.0818896293640137,
      "rewards/margins": 0.6770524978637695,
      "rewards/rejected": -2.758942127227783,
      "step": 2630
    },
    {
      "epoch": 0.7858312248846554,
      "grad_norm": 2.1565630435943604,
      "learning_rate": 6.805166716731752e-05,
      "logits/chosen": -0.806168258190155,
      "logits/rejected": -0.9003484845161438,
      "logps/chosen": -200.5784454345703,
      "logps/rejected": -222.9506072998047,
      "loss": 0.4941,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.5760550498962402,
      "rewards/margins": 0.8996587991714478,
      "rewards/rejected": -3.4757142066955566,
      "step": 2640
    },
    {
      "epoch": 0.7888078583122489,
      "grad_norm": 2.796062469482422,
      "learning_rate": 6.800360468609192e-05,
      "logits/chosen": -0.8729236721992493,
      "logits/rejected": -0.9314875602722168,
      "logps/chosen": -212.88656616210938,
      "logps/rejected": -227.76907348632812,
      "loss": 0.6414,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -3.0291614532470703,
      "rewards/margins": 0.5704482197761536,
      "rewards/rejected": -3.5996100902557373,
      "step": 2650
    },
    {
      "epoch": 0.7917844917398422,
      "grad_norm": 3.565124034881592,
      "learning_rate": 6.795554220486633e-05,
      "logits/chosen": -0.8585073351860046,
      "logits/rejected": -0.9393308758735657,
      "logps/chosen": -193.06130981445312,
      "logps/rejected": -213.66943359375,
      "loss": 0.5452,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.710272789001465,
      "rewards/margins": 0.7848669290542603,
      "rewards/rejected": -3.4951395988464355,
      "step": 2660
    },
    {
      "epoch": 0.7947611251674356,
      "grad_norm": 1.6229264736175537,
      "learning_rate": 6.790747972364073e-05,
      "logits/chosen": -0.9001126289367676,
      "logits/rejected": -0.9527347683906555,
      "logps/chosen": -213.16799926757812,
      "logps/rejected": -232.04345703125,
      "loss": 0.4134,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.1075453758239746,
      "rewards/margins": 1.587424635887146,
      "rewards/rejected": -3.694969654083252,
      "step": 2670
    },
    {
      "epoch": 0.797737758595029,
      "grad_norm": 4.111910343170166,
      "learning_rate": 6.785941724241514e-05,
      "logits/chosen": -0.8081693649291992,
      "logits/rejected": -0.8748302459716797,
      "logps/chosen": -203.8827362060547,
      "logps/rejected": -221.96829223632812,
      "loss": 0.69,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.3022701740264893,
      "rewards/margins": 0.603425145149231,
      "rewards/rejected": -2.9056954383850098,
      "step": 2680
    },
    {
      "epoch": 0.8007143920226224,
      "grad_norm": 3.1926605701446533,
      "learning_rate": 6.781135476118956e-05,
      "logits/chosen": -0.8746101260185242,
      "logits/rejected": -0.9106194376945496,
      "logps/chosen": -188.09999084472656,
      "logps/rejected": -200.0714111328125,
      "loss": 0.5587,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.2651309967041016,
      "rewards/margins": 0.9334152936935425,
      "rewards/rejected": -3.1985459327697754,
      "step": 2690
    },
    {
      "epoch": 0.8036910254502158,
      "grad_norm": 4.009433269500732,
      "learning_rate": 6.776329227996397e-05,
      "logits/chosen": -0.92292720079422,
      "logits/rejected": -0.9661901593208313,
      "logps/chosen": -189.87728881835938,
      "logps/rejected": -207.40853881835938,
      "loss": 0.5527,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.189331531524658,
      "rewards/margins": 0.7093812227249146,
      "rewards/rejected": -2.898712635040283,
      "step": 2700
    },
    {
      "epoch": 0.8066676588778092,
      "grad_norm": 4.477945804595947,
      "learning_rate": 6.771522979873837e-05,
      "logits/chosen": -1.0426868200302124,
      "logits/rejected": -1.0630146265029907,
      "logps/chosen": -189.14268493652344,
      "logps/rejected": -210.9114990234375,
      "loss": 0.6025,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.608394145965576,
      "rewards/margins": 0.8747402429580688,
      "rewards/rejected": -3.4831340312957764,
      "step": 2710
    },
    {
      "epoch": 0.8096442923054026,
      "grad_norm": 7.162075042724609,
      "learning_rate": 6.766716731751278e-05,
      "logits/chosen": -0.9775387048721313,
      "logits/rejected": -0.9712387323379517,
      "logps/chosen": -207.61361694335938,
      "logps/rejected": -213.0128631591797,
      "loss": 0.6356,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.938929319381714,
      "rewards/margins": 0.7166657447814941,
      "rewards/rejected": -3.655595064163208,
      "step": 2720
    },
    {
      "epoch": 0.8126209257329959,
      "grad_norm": 2.9854342937469482,
      "learning_rate": 6.761910483628717e-05,
      "logits/chosen": -0.9945376515388489,
      "logits/rejected": -1.048504114151001,
      "logps/chosen": -186.23989868164062,
      "logps/rejected": -208.76708984375,
      "loss": 0.5428,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.7397959232330322,
      "rewards/margins": 1.0307830572128296,
      "rewards/rejected": -3.7705790996551514,
      "step": 2730
    },
    {
      "epoch": 0.8155975591605894,
      "grad_norm": 6.034064769744873,
      "learning_rate": 6.757104235506158e-05,
      "logits/chosen": -0.9646980166435242,
      "logits/rejected": -0.9673722982406616,
      "logps/chosen": -209.5154571533203,
      "logps/rejected": -206.5411376953125,
      "loss": 0.6483,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.2587509155273438,
      "rewards/margins": 0.5356101393699646,
      "rewards/rejected": -2.794360637664795,
      "step": 2740
    },
    {
      "epoch": 0.8185741925881828,
      "grad_norm": 3.271533727645874,
      "learning_rate": 6.752297987383598e-05,
      "logits/chosen": -1.0471620559692383,
      "logits/rejected": -1.02994704246521,
      "logps/chosen": -176.23728942871094,
      "logps/rejected": -179.53500366210938,
      "loss": 0.6521,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.6196752786636353,
      "rewards/margins": 0.48323044180870056,
      "rewards/rejected": -2.102905750274658,
      "step": 2750
    },
    {
      "epoch": 0.8215508260157761,
      "grad_norm": 3.129427909851074,
      "learning_rate": 6.74749173926104e-05,
      "logits/chosen": -1.0412027835845947,
      "logits/rejected": -0.9922600984573364,
      "logps/chosen": -201.67347717285156,
      "logps/rejected": -198.78054809570312,
      "loss": 0.5113,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.9339015483856201,
      "rewards/margins": 0.7501698732376099,
      "rewards/rejected": -2.6840715408325195,
      "step": 2760
    },
    {
      "epoch": 0.8245274594433696,
      "grad_norm": 3.619501829147339,
      "learning_rate": 6.742685491138481e-05,
      "logits/chosen": -0.8721837997436523,
      "logits/rejected": -0.910038948059082,
      "logps/chosen": -189.3790283203125,
      "logps/rejected": -203.36312866210938,
      "loss": 0.5011,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6933772563934326,
      "rewards/margins": 0.9020093679428101,
      "rewards/rejected": -2.5953869819641113,
      "step": 2770
    },
    {
      "epoch": 0.8275040928709629,
      "grad_norm": 3.7114996910095215,
      "learning_rate": 6.737879243015922e-05,
      "logits/chosen": -0.8978636860847473,
      "logits/rejected": -0.9138191938400269,
      "logps/chosen": -189.81588745117188,
      "logps/rejected": -212.141845703125,
      "loss": 0.5213,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.9327285289764404,
      "rewards/margins": 1.0472782850265503,
      "rewards/rejected": -2.9800071716308594,
      "step": 2780
    },
    {
      "epoch": 0.8304807262985563,
      "grad_norm": 2.2855966091156006,
      "learning_rate": 6.733072994893362e-05,
      "logits/chosen": -0.9234901666641235,
      "logits/rejected": -0.9674445390701294,
      "logps/chosen": -197.31454467773438,
      "logps/rejected": -209.99008178710938,
      "loss": 0.6358,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.9900052547454834,
      "rewards/margins": 0.7685280442237854,
      "rewards/rejected": -2.758533239364624,
      "step": 2790
    },
    {
      "epoch": 0.8334573597261498,
      "grad_norm": 5.344142436981201,
      "learning_rate": 6.728266746770803e-05,
      "logits/chosen": -0.8393639326095581,
      "logits/rejected": -0.897735595703125,
      "logps/chosen": -198.6840057373047,
      "logps/rejected": -222.1476593017578,
      "loss": 0.6512,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.9298454523086548,
      "rewards/margins": 0.521459698677063,
      "rewards/rejected": -2.4513051509857178,
      "step": 2800
    },
    {
      "epoch": 0.8364339931537431,
      "grad_norm": 4.7366437911987305,
      "learning_rate": 6.723460498648243e-05,
      "logits/chosen": -0.8931584358215332,
      "logits/rejected": -0.9551416635513306,
      "logps/chosen": -188.6897735595703,
      "logps/rejected": -204.9369354248047,
      "loss": 0.579,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.9339059591293335,
      "rewards/margins": 0.8194364309310913,
      "rewards/rejected": -2.753342390060425,
      "step": 2810
    },
    {
      "epoch": 0.8394106265813365,
      "grad_norm": 2.1380202770233154,
      "learning_rate": 6.718654250525684e-05,
      "logits/chosen": -0.7700122594833374,
      "logits/rejected": -0.7745082378387451,
      "logps/chosen": -200.4813995361328,
      "logps/rejected": -209.433837890625,
      "loss": 0.5992,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -2.179187059402466,
      "rewards/margins": 0.870350182056427,
      "rewards/rejected": -3.049536943435669,
      "step": 2820
    },
    {
      "epoch": 0.8423872600089299,
      "grad_norm": 2.3302581310272217,
      "learning_rate": 6.713848002403125e-05,
      "logits/chosen": -0.8148499727249146,
      "logits/rejected": -0.8485671877861023,
      "logps/chosen": -193.68539428710938,
      "logps/rejected": -203.68064880371094,
      "loss": 0.5673,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.9261553287506104,
      "rewards/margins": 0.7324424982070923,
      "rewards/rejected": -2.658597946166992,
      "step": 2830
    },
    {
      "epoch": 0.8453638934365233,
      "grad_norm": 4.204676151275635,
      "learning_rate": 6.709041754280565e-05,
      "logits/chosen": -0.8861495852470398,
      "logits/rejected": -0.9307815432548523,
      "logps/chosen": -211.80618286132812,
      "logps/rejected": -221.864990234375,
      "loss": 0.6824,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.8569483757019043,
      "rewards/margins": 0.49546703696250916,
      "rewards/rejected": -3.3524155616760254,
      "step": 2840
    },
    {
      "epoch": 0.8483405268641167,
      "grad_norm": 1.962087631225586,
      "learning_rate": 6.704235506158006e-05,
      "logits/chosen": -0.6975604295730591,
      "logits/rejected": -0.7824384570121765,
      "logps/chosen": -181.6318359375,
      "logps/rejected": -212.64468383789062,
      "loss": 0.4861,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.4835829734802246,
      "rewards/margins": 1.042129397392273,
      "rewards/rejected": -3.525712251663208,
      "step": 2850
    },
    {
      "epoch": 0.8513171602917101,
      "grad_norm": 8.858142852783203,
      "learning_rate": 6.699429258035446e-05,
      "logits/chosen": -0.7444471120834351,
      "logits/rejected": -0.8011857867240906,
      "logps/chosen": -204.48391723632812,
      "logps/rejected": -232.622314453125,
      "loss": 0.6729,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.9430959224700928,
      "rewards/margins": 0.9490984082221985,
      "rewards/rejected": -3.8921940326690674,
      "step": 2860
    },
    {
      "epoch": 0.8542937937193035,
      "grad_norm": 2.550105571746826,
      "learning_rate": 6.694623009912887e-05,
      "logits/chosen": -0.7119820713996887,
      "logits/rejected": -0.7500320672988892,
      "logps/chosen": -192.01681518554688,
      "logps/rejected": -206.76821899414062,
      "loss": 0.5323,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.1548430919647217,
      "rewards/margins": 0.9377992749214172,
      "rewards/rejected": -3.092642307281494,
      "step": 2870
    },
    {
      "epoch": 0.8572704271468968,
      "grad_norm": 2.3901147842407227,
      "learning_rate": 6.689816761790328e-05,
      "logits/chosen": -0.7251447439193726,
      "logits/rejected": -0.7622807025909424,
      "logps/chosen": -206.6266326904297,
      "logps/rejected": -214.5155487060547,
      "loss": 0.5759,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.4941117763519287,
      "rewards/margins": 0.7299089431762695,
      "rewards/rejected": -3.2240207195281982,
      "step": 2880
    },
    {
      "epoch": 0.8602470605744903,
      "grad_norm": 3.8678340911865234,
      "learning_rate": 6.685010513667768e-05,
      "logits/chosen": -0.7314431071281433,
      "logits/rejected": -0.8616552352905273,
      "logps/chosen": -194.86666870117188,
      "logps/rejected": -223.61572265625,
      "loss": 0.5659,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.564767360687256,
      "rewards/margins": 0.7840480208396912,
      "rewards/rejected": -3.348815441131592,
      "step": 2890
    },
    {
      "epoch": 0.8632236940020837,
      "grad_norm": 3.883267402648926,
      "learning_rate": 6.680204265545209e-05,
      "logits/chosen": -0.8501842617988586,
      "logits/rejected": -0.8530827760696411,
      "logps/chosen": -203.38961791992188,
      "logps/rejected": -209.27120971679688,
      "loss": 0.5366,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.8376052379608154,
      "rewards/margins": 0.7825316786766052,
      "rewards/rejected": -3.6201369762420654,
      "step": 2900
    },
    {
      "epoch": 0.866200327429677,
      "grad_norm": 3.9303066730499268,
      "learning_rate": 6.67539801742265e-05,
      "logits/chosen": -0.7464410066604614,
      "logits/rejected": -0.8233236074447632,
      "logps/chosen": -194.13490295410156,
      "logps/rejected": -222.8258819580078,
      "loss": 0.6145,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.6254019737243652,
      "rewards/margins": 0.7074708342552185,
      "rewards/rejected": -3.3328731060028076,
      "step": 2910
    },
    {
      "epoch": 0.8691769608572705,
      "grad_norm": 3.3741812705993652,
      "learning_rate": 6.67059176930009e-05,
      "logits/chosen": -0.7686892747879028,
      "logits/rejected": -0.7760806679725647,
      "logps/chosen": -185.6595458984375,
      "logps/rejected": -205.00564575195312,
      "loss": 0.5456,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.68035888671875,
      "rewards/margins": 0.9156612157821655,
      "rewards/rejected": -2.596020221710205,
      "step": 2920
    },
    {
      "epoch": 0.8721535942848638,
      "grad_norm": 2.5092225074768066,
      "learning_rate": 6.665785521177532e-05,
      "logits/chosen": -0.8187748789787292,
      "logits/rejected": -0.8643869161605835,
      "logps/chosen": -186.887939453125,
      "logps/rejected": -198.99465942382812,
      "loss": 0.5887,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.4651665687561035,
      "rewards/margins": 0.9176557660102844,
      "rewards/rejected": -3.3828225135803223,
      "step": 2930
    },
    {
      "epoch": 0.8751302277124572,
      "grad_norm": 2.8046936988830566,
      "learning_rate": 6.660979273054973e-05,
      "logits/chosen": -0.7961305379867554,
      "logits/rejected": -0.8627949953079224,
      "logps/chosen": -200.25323486328125,
      "logps/rejected": -225.2218475341797,
      "loss": 0.5841,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.5014162063598633,
      "rewards/margins": 0.7134072184562683,
      "rewards/rejected": -3.2148234844207764,
      "step": 2940
    },
    {
      "epoch": 0.8781068611400507,
      "grad_norm": 2.3406407833099365,
      "learning_rate": 6.656173024932413e-05,
      "logits/chosen": -0.7410632371902466,
      "logits/rejected": -0.7476456165313721,
      "logps/chosen": -205.9498748779297,
      "logps/rejected": -212.14468383789062,
      "loss": 0.6241,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -2.539180278778076,
      "rewards/margins": 0.6160227656364441,
      "rewards/rejected": -3.155203104019165,
      "step": 2950
    },
    {
      "epoch": 0.881083494567644,
      "grad_norm": 3.148491621017456,
      "learning_rate": 6.651366776809854e-05,
      "logits/chosen": -0.8345397114753723,
      "logits/rejected": -0.8727396130561829,
      "logps/chosen": -185.84791564941406,
      "logps/rejected": -197.95664978027344,
      "loss": 0.6163,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.013293981552124,
      "rewards/margins": 0.542471170425415,
      "rewards/rejected": -2.555765390396118,
      "step": 2960
    },
    {
      "epoch": 0.8840601279952374,
      "grad_norm": 4.850064754486084,
      "learning_rate": 6.646560528687293e-05,
      "logits/chosen": -0.8215940594673157,
      "logits/rejected": -0.8749954104423523,
      "logps/chosen": -184.30111694335938,
      "logps/rejected": -202.60427856445312,
      "loss": 0.544,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.2622714042663574,
      "rewards/margins": 0.8257061243057251,
      "rewards/rejected": -3.087977170944214,
      "step": 2970
    },
    {
      "epoch": 0.8870367614228308,
      "grad_norm": 2.559643030166626,
      "learning_rate": 6.641754280564734e-05,
      "logits/chosen": -0.8148333430290222,
      "logits/rejected": -0.8603997230529785,
      "logps/chosen": -182.71133422851562,
      "logps/rejected": -200.9945526123047,
      "loss": 0.5828,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.8712406158447266,
      "rewards/margins": 0.7640877366065979,
      "rewards/rejected": -2.6353282928466797,
      "step": 2980
    },
    {
      "epoch": 0.8900133948504242,
      "grad_norm": 1.8977389335632324,
      "learning_rate": 6.636948032442176e-05,
      "logits/chosen": -0.8077163696289062,
      "logits/rejected": -0.7973501086235046,
      "logps/chosen": -191.5727996826172,
      "logps/rejected": -199.56790161132812,
      "loss": 0.579,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.009047031402588,
      "rewards/margins": 0.5895249843597412,
      "rewards/rejected": -2.598572254180908,
      "step": 2990
    },
    {
      "epoch": 0.8929900282780175,
      "grad_norm": 3.1437783241271973,
      "learning_rate": 6.632141784319616e-05,
      "logits/chosen": -0.8500359654426575,
      "logits/rejected": -0.8814091682434082,
      "logps/chosen": -185.9428253173828,
      "logps/rejected": -213.6567840576172,
      "loss": 0.5924,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.819960594177246,
      "rewards/margins": 0.973404586315155,
      "rewards/rejected": -2.793365001678467,
      "step": 3000
    },
    {
      "epoch": 0.8959666617056109,
      "grad_norm": 3.4054789543151855,
      "learning_rate": 6.627335536197057e-05,
      "logits/chosen": -0.6577621698379517,
      "logits/rejected": -0.8249263763427734,
      "logps/chosen": -182.9583282470703,
      "logps/rejected": -244.24459838867188,
      "loss": 0.5026,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.617820382118225,
      "rewards/margins": 1.3555444478988647,
      "rewards/rejected": -2.973365068435669,
      "step": 3010
    },
    {
      "epoch": 0.8989432951332044,
      "grad_norm": 3.267951726913452,
      "learning_rate": 6.622529288074498e-05,
      "logits/chosen": -0.9040484428405762,
      "logits/rejected": -0.8674526214599609,
      "logps/chosen": -176.7691192626953,
      "logps/rejected": -183.96409606933594,
      "loss": 0.5711,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.620550274848938,
      "rewards/margins": 0.8692372441291809,
      "rewards/rejected": -1.4897875785827637,
      "step": 3020
    },
    {
      "epoch": 0.9019199285607977,
      "grad_norm": 7.745297908782959,
      "learning_rate": 6.617723039951938e-05,
      "logits/chosen": -0.7617749571800232,
      "logits/rejected": -0.8287884593009949,
      "logps/chosen": -198.35409545898438,
      "logps/rejected": -222.21096801757812,
      "loss": 0.5479,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.6436080932617188,
      "rewards/margins": 0.8334104418754578,
      "rewards/rejected": -2.4770185947418213,
      "step": 3030
    },
    {
      "epoch": 0.9048965619883911,
      "grad_norm": 5.898054122924805,
      "learning_rate": 6.612916791829379e-05,
      "logits/chosen": -0.7429410219192505,
      "logits/rejected": -0.7472949028015137,
      "logps/chosen": -175.9357147216797,
      "logps/rejected": -188.65957641601562,
      "loss": 0.5468,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.131032109260559,
      "rewards/margins": 0.7747434973716736,
      "rewards/rejected": -1.905775785446167,
      "step": 3040
    },
    {
      "epoch": 0.9078731954159845,
      "grad_norm": 3.3681607246398926,
      "learning_rate": 6.60811054370682e-05,
      "logits/chosen": -0.8113505244255066,
      "logits/rejected": -0.8223028182983398,
      "logps/chosen": -188.9376220703125,
      "logps/rejected": -190.93673706054688,
      "loss": 0.6354,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.13762629032135,
      "rewards/margins": 0.6164771318435669,
      "rewards/rejected": -1.754103422164917,
      "step": 3050
    },
    {
      "epoch": 0.9108498288435779,
      "grad_norm": 3.8021321296691895,
      "learning_rate": 6.60330429558426e-05,
      "logits/chosen": -0.7642958760261536,
      "logits/rejected": -0.811357319355011,
      "logps/chosen": -182.38832092285156,
      "logps/rejected": -198.68899536132812,
      "loss": 0.6296,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.2625095844268799,
      "rewards/margins": 0.7055321931838989,
      "rewards/rejected": -1.9680416584014893,
      "step": 3060
    },
    {
      "epoch": 0.9138264622711713,
      "grad_norm": 2.7946364879608154,
      "learning_rate": 6.598498047461701e-05,
      "logits/chosen": -0.7112513184547424,
      "logits/rejected": -0.7529956698417664,
      "logps/chosen": -163.9618682861328,
      "logps/rejected": -179.57785034179688,
      "loss": 0.5661,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1840094327926636,
      "rewards/margins": 0.7713964581489563,
      "rewards/rejected": -1.9554059505462646,
      "step": 3070
    },
    {
      "epoch": 0.9168030956987647,
      "grad_norm": 3.878383159637451,
      "learning_rate": 6.593691799339141e-05,
      "logits/chosen": -0.649204432964325,
      "logits/rejected": -0.761882483959198,
      "logps/chosen": -182.0133514404297,
      "logps/rejected": -217.917236328125,
      "loss": 0.5375,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7434240579605103,
      "rewards/margins": 1.0328350067138672,
      "rewards/rejected": -2.776258945465088,
      "step": 3080
    },
    {
      "epoch": 0.9197797291263581,
      "grad_norm": 2.6279635429382324,
      "learning_rate": 6.588885551216582e-05,
      "logits/chosen": -0.7410624623298645,
      "logits/rejected": -0.7665559649467468,
      "logps/chosen": -177.21800231933594,
      "logps/rejected": -191.07870483398438,
      "loss": 0.5816,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.5905895233154297,
      "rewards/margins": 0.7796747088432312,
      "rewards/rejected": -2.3702642917633057,
      "step": 3090
    },
    {
      "epoch": 0.9227563625539514,
      "grad_norm": 4.41895055770874,
      "learning_rate": 6.584079303094023e-05,
      "logits/chosen": -0.8238494992256165,
      "logits/rejected": -0.8575658798217773,
      "logps/chosen": -197.97726440429688,
      "logps/rejected": -204.8148956298828,
      "loss": 0.7298,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.9752686023712158,
      "rewards/margins": 0.35308653116226196,
      "rewards/rejected": -2.328355073928833,
      "step": 3100
    },
    {
      "epoch": 0.9257329959815449,
      "grad_norm": 3.3393099308013916,
      "learning_rate": 6.579273054971463e-05,
      "logits/chosen": -0.7871979475021362,
      "logits/rejected": -0.8321081399917603,
      "logps/chosen": -186.7706298828125,
      "logps/rejected": -202.77603149414062,
      "loss": 0.5715,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.5306693315505981,
      "rewards/margins": 0.6333286762237549,
      "rewards/rejected": -2.1639981269836426,
      "step": 3110
    },
    {
      "epoch": 0.9287096294091383,
      "grad_norm": 3.195450782775879,
      "learning_rate": 6.574466806848904e-05,
      "logits/chosen": -0.7784937620162964,
      "logits/rejected": -0.8236656188964844,
      "logps/chosen": -184.07615661621094,
      "logps/rejected": -196.71487426757812,
      "loss": 0.5452,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.7984615564346313,
      "rewards/margins": 0.7143586874008179,
      "rewards/rejected": -2.5128204822540283,
      "step": 3120
    },
    {
      "epoch": 0.9316862628367316,
      "grad_norm": 2.751861810684204,
      "learning_rate": 6.569660558726344e-05,
      "logits/chosen": -0.7587357759475708,
      "logits/rejected": -0.7908545732498169,
      "logps/chosen": -199.18409729003906,
      "logps/rejected": -208.88803100585938,
      "loss": 0.5385,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6449044942855835,
      "rewards/margins": 0.8962351083755493,
      "rewards/rejected": -2.541140079498291,
      "step": 3130
    },
    {
      "epoch": 0.9346628962643251,
      "grad_norm": 3.575336217880249,
      "learning_rate": 6.564854310603785e-05,
      "logits/chosen": -0.8531113862991333,
      "logits/rejected": -0.8511737585067749,
      "logps/chosen": -187.09988403320312,
      "logps/rejected": -190.94776916503906,
      "loss": 0.6218,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.3808441162109375,
      "rewards/margins": 0.5955201387405396,
      "rewards/rejected": -1.9763641357421875,
      "step": 3140
    },
    {
      "epoch": 0.9376395296919184,
      "grad_norm": 3.1856234073638916,
      "learning_rate": 6.560048062481226e-05,
      "logits/chosen": -0.8651763796806335,
      "logits/rejected": -0.9280352592468262,
      "logps/chosen": -183.38607788085938,
      "logps/rejected": -208.0252227783203,
      "loss": 0.5478,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.3344143629074097,
      "rewards/margins": 0.657211184501648,
      "rewards/rejected": -1.9916257858276367,
      "step": 3150
    },
    {
      "epoch": 0.9406161631195118,
      "grad_norm": 3.0034372806549072,
      "learning_rate": 6.555241814358668e-05,
      "logits/chosen": -0.7951415181159973,
      "logits/rejected": -0.8608459234237671,
      "logps/chosen": -171.45675659179688,
      "logps/rejected": -186.6882781982422,
      "loss": 0.5822,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.839433491230011,
      "rewards/margins": 0.6793217658996582,
      "rewards/rejected": -1.5187551975250244,
      "step": 3160
    },
    {
      "epoch": 0.9435927965471053,
      "grad_norm": 4.041500091552734,
      "learning_rate": 6.550435566236108e-05,
      "logits/chosen": -0.7281309962272644,
      "logits/rejected": -0.81512051820755,
      "logps/chosen": -173.57455444335938,
      "logps/rejected": -197.4498291015625,
      "loss": 0.531,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7719841003417969,
      "rewards/margins": 0.8693034052848816,
      "rewards/rejected": -2.6412875652313232,
      "step": 3170
    },
    {
      "epoch": 0.9465694299746986,
      "grad_norm": 3.754565954208374,
      "learning_rate": 6.545629318113549e-05,
      "logits/chosen": -0.8778519630432129,
      "logits/rejected": -0.8824154138565063,
      "logps/chosen": -194.02731323242188,
      "logps/rejected": -200.68173217773438,
      "loss": 0.6467,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.5578275918960571,
      "rewards/margins": 0.5165980458259583,
      "rewards/rejected": -2.07442569732666,
      "step": 3180
    },
    {
      "epoch": 0.949546063402292,
      "grad_norm": 2.3792924880981445,
      "learning_rate": 6.54082306999099e-05,
      "logits/chosen": -0.9453357458114624,
      "logits/rejected": -0.9521898031234741,
      "logps/chosen": -181.63328552246094,
      "logps/rejected": -185.79014587402344,
      "loss": 0.6376,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.3851158618927002,
      "rewards/margins": 0.576801061630249,
      "rewards/rejected": -1.9619166851043701,
      "step": 3190
    },
    {
      "epoch": 0.9525226968298854,
      "grad_norm": 4.153547763824463,
      "learning_rate": 6.53601682186843e-05,
      "logits/chosen": -0.8934330940246582,
      "logits/rejected": -0.898002028465271,
      "logps/chosen": -185.60617065429688,
      "logps/rejected": -203.35098266601562,
      "loss": 0.6332,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -1.281640648841858,
      "rewards/margins": 0.5914865136146545,
      "rewards/rejected": -1.8731272220611572,
      "step": 3200
    },
    {
      "epoch": 0.9554993302574788,
      "grad_norm": 3.308516263961792,
      "learning_rate": 6.531210573745869e-05,
      "logits/chosen": -0.9440546035766602,
      "logits/rejected": -1.0155023336410522,
      "logps/chosen": -187.012451171875,
      "logps/rejected": -215.42385864257812,
      "loss": 0.4936,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.520794153213501,
      "rewards/margins": 0.8198097944259644,
      "rewards/rejected": -2.340603828430176,
      "step": 3210
    },
    {
      "epoch": 0.9584759636850722,
      "grad_norm": 4.12837028503418,
      "learning_rate": 6.52640432562331e-05,
      "logits/chosen": -0.8392407298088074,
      "logits/rejected": -0.9157900810241699,
      "logps/chosen": -186.7196807861328,
      "logps/rejected": -206.8565216064453,
      "loss": 0.5326,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.551105260848999,
      "rewards/margins": 0.9271756410598755,
      "rewards/rejected": -2.478281021118164,
      "step": 3220
    },
    {
      "epoch": 0.9614525971126656,
      "grad_norm": 3.7757129669189453,
      "learning_rate": 6.521598077500752e-05,
      "logits/chosen": -0.888585090637207,
      "logits/rejected": -0.9319125413894653,
      "logps/chosen": -188.6426544189453,
      "logps/rejected": -200.4862518310547,
      "loss": 0.6836,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -1.649808645248413,
      "rewards/margins": 0.3273203372955322,
      "rewards/rejected": -1.9771287441253662,
      "step": 3230
    },
    {
      "epoch": 0.964429230540259,
      "grad_norm": 3.5869805812835693,
      "learning_rate": 6.516791829378193e-05,
      "logits/chosen": -0.8976339101791382,
      "logits/rejected": -0.898944079875946,
      "logps/chosen": -192.4273681640625,
      "logps/rejected": -198.84378051757812,
      "loss": 0.5953,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.7143566608428955,
      "rewards/margins": 0.7248843312263489,
      "rewards/rejected": -2.4392409324645996,
      "step": 3240
    },
    {
      "epoch": 0.9674058639678523,
      "grad_norm": 5.374905586242676,
      "learning_rate": 6.511985581255633e-05,
      "logits/chosen": -0.9142367243766785,
      "logits/rejected": -0.9261860847473145,
      "logps/chosen": -182.32473754882812,
      "logps/rejected": -194.49668884277344,
      "loss": 0.5945,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.8827155232429504,
      "rewards/margins": 0.7372815608978271,
      "rewards/rejected": -1.6199970245361328,
      "step": 3250
    },
    {
      "epoch": 0.9703824973954458,
      "grad_norm": 5.290043830871582,
      "learning_rate": 6.507179333133074e-05,
      "logits/chosen": -0.930925190448761,
      "logits/rejected": -0.947557806968689,
      "logps/chosen": -174.72317504882812,
      "logps/rejected": -181.7444610595703,
      "loss": 0.5458,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.32662832736969,
      "rewards/margins": 0.793325662612915,
      "rewards/rejected": -2.1199541091918945,
      "step": 3260
    },
    {
      "epoch": 0.9733591308230392,
      "grad_norm": 3.758615493774414,
      "learning_rate": 6.502373085010514e-05,
      "logits/chosen": -0.836783230304718,
      "logits/rejected": -0.9201515913009644,
      "logps/chosen": -183.8164520263672,
      "logps/rejected": -222.86654663085938,
      "loss": 0.5319,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.848365068435669,
      "rewards/margins": 0.9357935190200806,
      "rewards/rejected": -2.784158706665039,
      "step": 3270
    },
    {
      "epoch": 0.9763357642506325,
      "grad_norm": 3.303809404373169,
      "learning_rate": 6.497566836887955e-05,
      "logits/chosen": -0.9136770963668823,
      "logits/rejected": -0.934775710105896,
      "logps/chosen": -196.83941650390625,
      "logps/rejected": -206.98794555664062,
      "loss": 0.5235,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9719154834747314,
      "rewards/margins": 0.8653915524482727,
      "rewards/rejected": -2.8373069763183594,
      "step": 3280
    },
    {
      "epoch": 0.979312397678226,
      "grad_norm": 4.298236846923828,
      "learning_rate": 6.492760588765396e-05,
      "logits/chosen": -0.9109317064285278,
      "logits/rejected": -0.9054409861564636,
      "logps/chosen": -203.53424072265625,
      "logps/rejected": -208.56991577148438,
      "loss": 0.5358,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.794677495956421,
      "rewards/margins": 0.786591112613678,
      "rewards/rejected": -2.581268787384033,
      "step": 3290
    },
    {
      "epoch": 0.9822890311058193,
      "grad_norm": 4.66634464263916,
      "learning_rate": 6.487954340642836e-05,
      "logits/chosen": -0.928181529045105,
      "logits/rejected": -0.9484883546829224,
      "logps/chosen": -180.48001098632812,
      "logps/rejected": -187.61685180664062,
      "loss": 0.6418,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.6857168674468994,
      "rewards/margins": 0.4263593554496765,
      "rewards/rejected": -2.1120762825012207,
      "step": 3300
    },
    {
      "epoch": 0.9852656645334127,
      "grad_norm": 4.160323619842529,
      "learning_rate": 6.483148092520277e-05,
      "logits/chosen": -0.910269558429718,
      "logits/rejected": -0.8967860341072083,
      "logps/chosen": -196.21246337890625,
      "logps/rejected": -203.93142700195312,
      "loss": 0.5309,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7210452556610107,
      "rewards/margins": 0.8024009466171265,
      "rewards/rejected": -2.5234463214874268,
      "step": 3310
    },
    {
      "epoch": 0.9882422979610062,
      "grad_norm": 3.5292325019836426,
      "learning_rate": 6.478341844397717e-05,
      "logits/chosen": -0.879368007183075,
      "logits/rejected": -0.962435245513916,
      "logps/chosen": -205.72824096679688,
      "logps/rejected": -225.61669921875,
      "loss": 0.5049,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1346850395202637,
      "rewards/margins": 0.9058841466903687,
      "rewards/rejected": -3.040569305419922,
      "step": 3320
    },
    {
      "epoch": 0.9912189313885995,
      "grad_norm": 3.23714542388916,
      "learning_rate": 6.473535596275158e-05,
      "logits/chosen": -0.8662294149398804,
      "logits/rejected": -0.8732364773750305,
      "logps/chosen": -198.3070068359375,
      "logps/rejected": -206.2274169921875,
      "loss": 0.5765,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.9395866394042969,
      "rewards/margins": 0.772649347782135,
      "rewards/rejected": -2.712236166000366,
      "step": 3330
    },
    {
      "epoch": 0.9941955648161929,
      "grad_norm": 4.039350986480713,
      "learning_rate": 6.468729348152599e-05,
      "logits/chosen": -0.8894580602645874,
      "logits/rejected": -0.8967620134353638,
      "logps/chosen": -200.0818634033203,
      "logps/rejected": -209.89871215820312,
      "loss": 0.5592,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.8928667306900024,
      "rewards/margins": 0.9318864941596985,
      "rewards/rejected": -2.8247532844543457,
      "step": 3340
    },
    {
      "epoch": 0.9971721982437862,
      "grad_norm": 4.0443434715271,
      "learning_rate": 6.463923100030039e-05,
      "logits/chosen": -0.9028267860412598,
      "logits/rejected": -0.9927003979682922,
      "logps/chosen": -196.02064514160156,
      "logps/rejected": -228.3913116455078,
      "loss": 0.5214,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.7266879081726074,
      "rewards/margins": 1.0318487882614136,
      "rewards/rejected": -3.7585365772247314,
      "step": 3350
    },
    {
      "epoch": 1.0001488316713796,
      "grad_norm": 8.846224784851074,
      "learning_rate": 6.45911685190748e-05,
      "logits/chosen": -0.9543989896774292,
      "logits/rejected": -0.9580944180488586,
      "logps/chosen": -221.9348907470703,
      "logps/rejected": -229.2919464111328,
      "loss": 0.6567,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.96828031539917,
      "rewards/margins": 0.6041281223297119,
      "rewards/rejected": -3.572408676147461,
      "step": 3360
    },
    {
      "epoch": 1.0031254650989732,
      "grad_norm": 2.7994751930236816,
      "learning_rate": 6.45431060378492e-05,
      "logits/chosen": -0.8739336133003235,
      "logits/rejected": -0.9161443710327148,
      "logps/chosen": -186.39535522460938,
      "logps/rejected": -202.50404357910156,
      "loss": 0.496,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.1677842140197754,
      "rewards/margins": 0.8873307108879089,
      "rewards/rejected": -3.055114984512329,
      "step": 3370
    },
    {
      "epoch": 1.0061020985265665,
      "grad_norm": 2.943526029586792,
      "learning_rate": 6.449504355662361e-05,
      "logits/chosen": -0.8760126233100891,
      "logits/rejected": -0.9248356819152832,
      "logps/chosen": -191.5074920654297,
      "logps/rejected": -201.38119506835938,
      "loss": 0.5141,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5250715017318726,
      "rewards/margins": 0.8729965090751648,
      "rewards/rejected": -2.3980681896209717,
      "step": 3380
    },
    {
      "epoch": 1.0090787319541599,
      "grad_norm": 2.997002124786377,
      "learning_rate": 6.444698107539802e-05,
      "logits/chosen": -0.9248110055923462,
      "logits/rejected": -0.9797259569168091,
      "logps/chosen": -179.37820434570312,
      "logps/rejected": -199.830810546875,
      "loss": 0.4415,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.9512237310409546,
      "rewards/margins": 1.0595035552978516,
      "rewards/rejected": -3.0107274055480957,
      "step": 3390
    },
    {
      "epoch": 1.0120553653817532,
      "grad_norm": 3.0557501316070557,
      "learning_rate": 6.439891859417244e-05,
      "logits/chosen": -0.8072491884231567,
      "logits/rejected": -0.8887661099433899,
      "logps/chosen": -183.681884765625,
      "logps/rejected": -227.43765258789062,
      "loss": 0.3586,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9138749837875366,
      "rewards/margins": 1.6472409963607788,
      "rewards/rejected": -3.5611159801483154,
      "step": 3400
    },
    {
      "epoch": 1.0150319988093466,
      "grad_norm": 1.696101188659668,
      "learning_rate": 6.435085611294684e-05,
      "logits/chosen": -0.8552045822143555,
      "logits/rejected": -0.950750470161438,
      "logps/chosen": -206.69137573242188,
      "logps/rejected": -247.1300506591797,
      "loss": 0.3474,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.535200834274292,
      "rewards/margins": 2.0001380443573,
      "rewards/rejected": -4.53533935546875,
      "step": 3410
    },
    {
      "epoch": 1.01800863223694,
      "grad_norm": 5.135011672973633,
      "learning_rate": 6.430279363172125e-05,
      "logits/chosen": -0.9272775650024414,
      "logits/rejected": -0.9514007568359375,
      "logps/chosen": -201.84719848632812,
      "logps/rejected": -206.89321899414062,
      "loss": 0.5367,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.3215107917785645,
      "rewards/margins": 0.9372585415840149,
      "rewards/rejected": -3.2587692737579346,
      "step": 3420
    },
    {
      "epoch": 1.0209852656645335,
      "grad_norm": 2.2945895195007324,
      "learning_rate": 6.425473115049566e-05,
      "logits/chosen": -0.9142599105834961,
      "logits/rejected": -0.9912382960319519,
      "logps/chosen": -195.98318481445312,
      "logps/rejected": -226.6366424560547,
      "loss": 0.4661,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.579803466796875,
      "rewards/margins": 1.0672216415405273,
      "rewards/rejected": -3.6470253467559814,
      "step": 3430
    },
    {
      "epoch": 1.0239618990921269,
      "grad_norm": 3.1619725227355957,
      "learning_rate": 6.420666866927006e-05,
      "logits/chosen": -0.8212305307388306,
      "logits/rejected": -0.8805948495864868,
      "logps/chosen": -195.28355407714844,
      "logps/rejected": -225.90011596679688,
      "loss": 0.4555,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.1710093021392822,
      "rewards/margins": 1.2411863803863525,
      "rewards/rejected": -3.4121956825256348,
      "step": 3440
    },
    {
      "epoch": 1.0269385325197202,
      "grad_norm": 3.3516106605529785,
      "learning_rate": 6.415860618804445e-05,
      "logits/chosen": -0.875856876373291,
      "logits/rejected": -0.8913179636001587,
      "logps/chosen": -193.94168090820312,
      "logps/rejected": -202.29586791992188,
      "loss": 0.6012,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.253699779510498,
      "rewards/margins": 0.7351999878883362,
      "rewards/rejected": -2.9888999462127686,
      "step": 3450
    },
    {
      "epoch": 1.0299151659473136,
      "grad_norm": 2.2453715801239014,
      "learning_rate": 6.411054370681886e-05,
      "logits/chosen": -0.8953107595443726,
      "logits/rejected": -0.918499767780304,
      "logps/chosen": -185.22109985351562,
      "logps/rejected": -194.40463256835938,
      "loss": 0.4456,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6988780498504639,
      "rewards/margins": 0.8804980516433716,
      "rewards/rejected": -2.579375743865967,
      "step": 3460
    },
    {
      "epoch": 1.032891799374907,
      "grad_norm": 3.2203211784362793,
      "learning_rate": 6.406248122559328e-05,
      "logits/chosen": -0.8277549743652344,
      "logits/rejected": -0.8888378143310547,
      "logps/chosen": -200.9015655517578,
      "logps/rejected": -222.7324676513672,
      "loss": 0.412,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.305213451385498,
      "rewards/margins": 1.1775280237197876,
      "rewards/rejected": -3.482741117477417,
      "step": 3470
    },
    {
      "epoch": 1.0358684328025003,
      "grad_norm": 2.521374225616455,
      "learning_rate": 6.401441874436769e-05,
      "logits/chosen": -0.7664563059806824,
      "logits/rejected": -0.8753385543823242,
      "logps/chosen": -178.23313903808594,
      "logps/rejected": -214.2522430419922,
      "loss": 0.4113,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0234262943267822,
      "rewards/margins": 1.3646600246429443,
      "rewards/rejected": -3.3880867958068848,
      "step": 3480
    },
    {
      "epoch": 1.0388450662300937,
      "grad_norm": 2.507629156112671,
      "learning_rate": 6.396635626314209e-05,
      "logits/chosen": -0.7461771368980408,
      "logits/rejected": -0.8465557098388672,
      "logps/chosen": -191.3837890625,
      "logps/rejected": -223.7218017578125,
      "loss": 0.4355,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1302895545959473,
      "rewards/margins": 1.2976597547531128,
      "rewards/rejected": -3.4279491901397705,
      "step": 3490
    },
    {
      "epoch": 1.0418216996576872,
      "grad_norm": 6.263843536376953,
      "learning_rate": 6.39182937819165e-05,
      "logits/chosen": -0.725475549697876,
      "logits/rejected": -0.7214592099189758,
      "logps/chosen": -198.05865478515625,
      "logps/rejected": -215.2097625732422,
      "loss": 0.4397,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.0877785682678223,
      "rewards/margins": 1.2285950183868408,
      "rewards/rejected": -3.316373348236084,
      "step": 3500
    },
    {
      "epoch": 1.0447983330852806,
      "grad_norm": 2.1924638748168945,
      "learning_rate": 6.38702313006909e-05,
      "logits/chosen": -0.7265986204147339,
      "logits/rejected": -0.7980517148971558,
      "logps/chosen": -184.13682556152344,
      "logps/rejected": -209.3789520263672,
      "loss": 0.4019,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.2575173377990723,
      "rewards/margins": 1.314572811126709,
      "rewards/rejected": -3.5720901489257812,
      "step": 3510
    },
    {
      "epoch": 1.047774966512874,
      "grad_norm": 2.9907233715057373,
      "learning_rate": 6.382216881946531e-05,
      "logits/chosen": -0.5512939691543579,
      "logits/rejected": -0.7126942276954651,
      "logps/chosen": -185.21780395507812,
      "logps/rejected": -229.8980255126953,
      "loss": 0.3768,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.095355749130249,
      "rewards/margins": 1.6904433965682983,
      "rewards/rejected": -4.785799980163574,
      "step": 3520
    },
    {
      "epoch": 1.0507515999404673,
      "grad_norm": 2.196075201034546,
      "learning_rate": 6.377410633823972e-05,
      "logits/chosen": -0.6515753865242004,
      "logits/rejected": -0.6962084174156189,
      "logps/chosen": -204.5228271484375,
      "logps/rejected": -230.72409057617188,
      "loss": 0.4007,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.8509302139282227,
      "rewards/margins": 1.7090351581573486,
      "rewards/rejected": -4.55996561050415,
      "step": 3530
    },
    {
      "epoch": 1.0537282333680607,
      "grad_norm": 4.827825546264648,
      "learning_rate": 6.372604385701412e-05,
      "logits/chosen": -0.734025776386261,
      "logits/rejected": -0.6766709089279175,
      "logps/chosen": -205.37796020507812,
      "logps/rejected": -209.6305694580078,
      "loss": 0.5382,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.7824137210845947,
      "rewards/margins": 1.0794909000396729,
      "rewards/rejected": -3.8619046211242676,
      "step": 3540
    },
    {
      "epoch": 1.0567048667956542,
      "grad_norm": 5.607051849365234,
      "learning_rate": 6.367798137578853e-05,
      "logits/chosen": -0.8363826870918274,
      "logits/rejected": -0.87517249584198,
      "logps/chosen": -190.845947265625,
      "logps/rejected": -216.0135498046875,
      "loss": 0.3913,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.541454792022705,
      "rewards/margins": 1.5502485036849976,
      "rewards/rejected": -4.091702938079834,
      "step": 3550
    },
    {
      "epoch": 1.0596815002232476,
      "grad_norm": 4.480737686157227,
      "learning_rate": 6.362991889456294e-05,
      "logits/chosen": -0.7184215784072876,
      "logits/rejected": -0.7272249460220337,
      "logps/chosen": -205.2199249267578,
      "logps/rejected": -224.1632080078125,
      "loss": 0.4868,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.9001753330230713,
      "rewards/margins": 1.4321000576019287,
      "rewards/rejected": -4.332274913787842,
      "step": 3560
    },
    {
      "epoch": 1.062658133650841,
      "grad_norm": 4.002510070800781,
      "learning_rate": 6.358185641333734e-05,
      "logits/chosen": -0.667870044708252,
      "logits/rejected": -0.8370159864425659,
      "logps/chosen": -185.2978973388672,
      "logps/rejected": -233.98483276367188,
      "loss": 0.4241,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.950639247894287,
      "rewards/margins": 1.7937037944793701,
      "rewards/rejected": -4.744342803955078,
      "step": 3570
    },
    {
      "epoch": 1.0656347670784343,
      "grad_norm": 2.660137176513672,
      "learning_rate": 6.353379393211175e-05,
      "logits/chosen": -0.746475338935852,
      "logits/rejected": -0.7324618101119995,
      "logps/chosen": -196.8250274658203,
      "logps/rejected": -201.92352294921875,
      "loss": 0.4733,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.6827502250671387,
      "rewards/margins": 1.1120978593826294,
      "rewards/rejected": -3.7948482036590576,
      "step": 3580
    },
    {
      "epoch": 1.0686114005060277,
      "grad_norm": 3.699723482131958,
      "learning_rate": 6.348573145088615e-05,
      "logits/chosen": -0.7977631092071533,
      "logits/rejected": -0.7787880897521973,
      "logps/chosen": -218.61489868164062,
      "logps/rejected": -231.11203002929688,
      "loss": 0.4845,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.6337857246398926,
      "rewards/margins": 1.0980418920516968,
      "rewards/rejected": -3.731827974319458,
      "step": 3590
    },
    {
      "epoch": 1.071588033933621,
      "grad_norm": 3.548145055770874,
      "learning_rate": 6.343766896966056e-05,
      "logits/chosen": -0.7083352208137512,
      "logits/rejected": -0.8319941759109497,
      "logps/chosen": -197.78152465820312,
      "logps/rejected": -234.96224975585938,
      "loss": 0.4185,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.4640541076660156,
      "rewards/margins": 1.524261474609375,
      "rewards/rejected": -3.9883155822753906,
      "step": 3600
    },
    {
      "epoch": 1.0745646673612144,
      "grad_norm": 4.987697124481201,
      "learning_rate": 6.338960648843497e-05,
      "logits/chosen": -0.7050070762634277,
      "logits/rejected": -0.7822762131690979,
      "logps/chosen": -202.8192596435547,
      "logps/rejected": -224.5171356201172,
      "loss": 0.4695,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.4115703105926514,
      "rewards/margins": 1.0199509859085083,
      "rewards/rejected": -3.43152117729187,
      "step": 3610
    },
    {
      "epoch": 1.077541300788808,
      "grad_norm": 5.849793910980225,
      "learning_rate": 6.334154400720937e-05,
      "logits/chosen": -0.6930030584335327,
      "logits/rejected": -0.7609996795654297,
      "logps/chosen": -203.6180877685547,
      "logps/rejected": -234.48458862304688,
      "loss": 0.4298,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.0546703338623047,
      "rewards/margins": 1.3151741027832031,
      "rewards/rejected": -4.369844436645508,
      "step": 3620
    },
    {
      "epoch": 1.0805179342164013,
      "grad_norm": 2.7127907276153564,
      "learning_rate": 6.329348152598378e-05,
      "logits/chosen": -0.6087427139282227,
      "logits/rejected": -0.7316496968269348,
      "logps/chosen": -185.4946746826172,
      "logps/rejected": -226.4108123779297,
      "loss": 0.3421,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.5381155014038086,
      "rewards/margins": 1.7767693996429443,
      "rewards/rejected": -4.314885139465332,
      "step": 3630
    },
    {
      "epoch": 1.0834945676439947,
      "grad_norm": 3.749032974243164,
      "learning_rate": 6.32454190447582e-05,
      "logits/chosen": -0.7032159566879272,
      "logits/rejected": -0.6799787878990173,
      "logps/chosen": -198.72311401367188,
      "logps/rejected": -218.4789276123047,
      "loss": 0.3703,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.5611555576324463,
      "rewards/margins": 1.5273188352584839,
      "rewards/rejected": -4.088474750518799,
      "step": 3640
    },
    {
      "epoch": 1.086471201071588,
      "grad_norm": 3.0798916816711426,
      "learning_rate": 6.31973565635326e-05,
      "logits/chosen": -0.6094663739204407,
      "logits/rejected": -0.63045334815979,
      "logps/chosen": -192.5386962890625,
      "logps/rejected": -201.89645385742188,
      "loss": 0.4966,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.5470588207244873,
      "rewards/margins": 0.9853734970092773,
      "rewards/rejected": -3.5324325561523438,
      "step": 3650
    },
    {
      "epoch": 1.0894478344991814,
      "grad_norm": 4.072603702545166,
      "learning_rate": 6.314929408230701e-05,
      "logits/chosen": -0.5865360498428345,
      "logits/rejected": -0.5754219889640808,
      "logps/chosen": -195.00733947753906,
      "logps/rejected": -205.17324829101562,
      "loss": 0.4658,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.2513015270233154,
      "rewards/margins": 1.0211776494979858,
      "rewards/rejected": -4.27247953414917,
      "step": 3660
    },
    {
      "epoch": 1.0924244679267747,
      "grad_norm": 4.322398662567139,
      "learning_rate": 6.310123160108142e-05,
      "logits/chosen": -0.4080687165260315,
      "logits/rejected": -0.42353564500808716,
      "logps/chosen": -209.99636840820312,
      "logps/rejected": -233.7672882080078,
      "loss": 0.3534,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.857125759124756,
      "rewards/margins": 1.4473053216934204,
      "rewards/rejected": -5.304430961608887,
      "step": 3670
    },
    {
      "epoch": 1.0954011013543683,
      "grad_norm": 2.588603973388672,
      "learning_rate": 6.305316911985582e-05,
      "logits/chosen": -0.49399107694625854,
      "logits/rejected": -0.47724246978759766,
      "logps/chosen": -200.35598754882812,
      "logps/rejected": -214.2404022216797,
      "loss": 0.4135,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.395781993865967,
      "rewards/margins": 1.2968370914459229,
      "rewards/rejected": -4.692619800567627,
      "step": 3680
    },
    {
      "epoch": 1.0983777347819617,
      "grad_norm": 4.263345718383789,
      "learning_rate": 6.300510663863022e-05,
      "logits/chosen": -0.4269663691520691,
      "logits/rejected": -0.4742148518562317,
      "logps/chosen": -192.3225555419922,
      "logps/rejected": -218.34274291992188,
      "loss": 0.4248,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.890007734298706,
      "rewards/margins": 1.6636202335357666,
      "rewards/rejected": -4.553627967834473,
      "step": 3690
    },
    {
      "epoch": 1.101354368209555,
      "grad_norm": 3.3555076122283936,
      "learning_rate": 6.295704415740462e-05,
      "logits/chosen": -0.6155514717102051,
      "logits/rejected": -0.7023353576660156,
      "logps/chosen": -197.30441284179688,
      "logps/rejected": -230.93533325195312,
      "loss": 0.3907,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.3490848541259766,
      "rewards/margins": 1.6773052215576172,
      "rewards/rejected": -5.026390552520752,
      "step": 3700
    },
    {
      "epoch": 1.1043310016371484,
      "grad_norm": 2.182941198348999,
      "learning_rate": 6.290898167617904e-05,
      "logits/chosen": -0.6306422352790833,
      "logits/rejected": -0.6763945817947388,
      "logps/chosen": -215.6849822998047,
      "logps/rejected": -241.27279663085938,
      "loss": 0.4867,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.1936967372894287,
      "rewards/margins": 1.3405667543411255,
      "rewards/rejected": -4.534263610839844,
      "step": 3710
    },
    {
      "epoch": 1.1073076350647417,
      "grad_norm": 3.2564210891723633,
      "learning_rate": 6.286091919495345e-05,
      "logits/chosen": -0.6474646925926208,
      "logits/rejected": -0.7568936944007874,
      "logps/chosen": -206.2776641845703,
      "logps/rejected": -245.7364044189453,
      "loss": 0.4659,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.8473777770996094,
      "rewards/margins": 1.2575370073318481,
      "rewards/rejected": -4.104914665222168,
      "step": 3720
    },
    {
      "epoch": 1.110284268492335,
      "grad_norm": 3.7257559299468994,
      "learning_rate": 6.281285671372785e-05,
      "logits/chosen": -0.8128930926322937,
      "logits/rejected": -0.8133898973464966,
      "logps/chosen": -200.4281005859375,
      "logps/rejected": -213.91592407226562,
      "loss": 0.5459,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.852464437484741,
      "rewards/margins": 1.1581404209136963,
      "rewards/rejected": -4.010604381561279,
      "step": 3730
    },
    {
      "epoch": 1.1132609019199287,
      "grad_norm": 5.555940628051758,
      "learning_rate": 6.276479423250226e-05,
      "logits/chosen": -0.7569796442985535,
      "logits/rejected": -0.8079754114151001,
      "logps/chosen": -206.9120635986328,
      "logps/rejected": -230.61227416992188,
      "loss": 0.4268,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.275679349899292,
      "rewards/margins": 1.2638053894042969,
      "rewards/rejected": -4.539484977722168,
      "step": 3740
    },
    {
      "epoch": 1.116237535347522,
      "grad_norm": 2.7820961475372314,
      "learning_rate": 6.271673175127667e-05,
      "logits/chosen": -0.7157383561134338,
      "logits/rejected": -0.8137361407279968,
      "logps/chosen": -198.89541625976562,
      "logps/rejected": -230.49301147460938,
      "loss": 0.3765,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.4008212089538574,
      "rewards/margins": 1.6510273218154907,
      "rewards/rejected": -5.051848411560059,
      "step": 3750
    },
    {
      "epoch": 1.1192141687751154,
      "grad_norm": 4.553107738494873,
      "learning_rate": 6.266866927005107e-05,
      "logits/chosen": -0.6782727241516113,
      "logits/rejected": -0.8087924122810364,
      "logps/chosen": -199.78382873535156,
      "logps/rejected": -242.5368194580078,
      "loss": 0.4295,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.71370005607605,
      "rewards/margins": 1.5731737613677979,
      "rewards/rejected": -5.286874294281006,
      "step": 3760
    },
    {
      "epoch": 1.1221908022027087,
      "grad_norm": 2.8249127864837646,
      "learning_rate": 6.262060678882548e-05,
      "logits/chosen": -0.7087239623069763,
      "logits/rejected": -0.7125063538551331,
      "logps/chosen": -223.3398895263672,
      "logps/rejected": -242.55276489257812,
      "loss": 0.4039,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.685595989227295,
      "rewards/margins": 1.6662523746490479,
      "rewards/rejected": -5.3518476486206055,
      "step": 3770
    },
    {
      "epoch": 1.125167435630302,
      "grad_norm": 1.9372236728668213,
      "learning_rate": 6.257254430759988e-05,
      "logits/chosen": -0.6757029294967651,
      "logits/rejected": -0.7087745070457458,
      "logps/chosen": -202.35830688476562,
      "logps/rejected": -221.017578125,
      "loss": 0.5473,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.6218204498291016,
      "rewards/margins": 1.3650307655334473,
      "rewards/rejected": -4.986851692199707,
      "step": 3780
    },
    {
      "epoch": 1.1281440690578954,
      "grad_norm": 3.775977373123169,
      "learning_rate": 6.252448182637429e-05,
      "logits/chosen": -0.7190219759941101,
      "logits/rejected": -0.7463334798812866,
      "logps/chosen": -205.54806518554688,
      "logps/rejected": -232.3034210205078,
      "loss": 0.4111,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.4848906993865967,
      "rewards/margins": 1.3484961986541748,
      "rewards/rejected": -4.833386421203613,
      "step": 3790
    },
    {
      "epoch": 1.131120702485489,
      "grad_norm": 5.778914928436279,
      "learning_rate": 6.24764193451487e-05,
      "logits/chosen": -0.6986542344093323,
      "logits/rejected": -0.7327571511268616,
      "logps/chosen": -217.38772583007812,
      "logps/rejected": -237.4423370361328,
      "loss": 0.4224,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.974362850189209,
      "rewards/margins": 1.565327525138855,
      "rewards/rejected": -4.539690971374512,
      "step": 3800
    },
    {
      "epoch": 1.1340973359130824,
      "grad_norm": 3.410125255584717,
      "learning_rate": 6.24283568639231e-05,
      "logits/chosen": -0.7508337497711182,
      "logits/rejected": -0.7633103728294373,
      "logps/chosen": -216.321044921875,
      "logps/rejected": -230.3046112060547,
      "loss": 0.4814,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -3.171814203262329,
      "rewards/margins": 1.1908295154571533,
      "rewards/rejected": -4.362643718719482,
      "step": 3810
    },
    {
      "epoch": 1.1370739693406757,
      "grad_norm": 4.980411052703857,
      "learning_rate": 6.238029438269751e-05,
      "logits/chosen": -0.7344219088554382,
      "logits/rejected": -0.7848840951919556,
      "logps/chosen": -222.8375244140625,
      "logps/rejected": -242.571044921875,
      "loss": 0.4833,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.6370177268981934,
      "rewards/margins": 1.249534010887146,
      "rewards/rejected": -4.886551856994629,
      "step": 3820
    },
    {
      "epoch": 1.140050602768269,
      "grad_norm": 2.4756956100463867,
      "learning_rate": 6.233223190147191e-05,
      "logits/chosen": -0.7917445302009583,
      "logits/rejected": -0.8102933764457703,
      "logps/chosen": -221.5624237060547,
      "logps/rejected": -231.0176239013672,
      "loss": 0.5351,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -3.346768856048584,
      "rewards/margins": 1.1096947193145752,
      "rewards/rejected": -4.456463813781738,
      "step": 3830
    },
    {
      "epoch": 1.1430272361958624,
      "grad_norm": 2.768650531768799,
      "learning_rate": 6.228416942024632e-05,
      "logits/chosen": -0.7415547966957092,
      "logits/rejected": -0.8592926263809204,
      "logps/chosen": -205.2235870361328,
      "logps/rejected": -252.73660278320312,
      "loss": 0.3332,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.631861925125122,
      "rewards/margins": 1.52927565574646,
      "rewards/rejected": -5.16113805770874,
      "step": 3840
    },
    {
      "epoch": 1.1460038696234558,
      "grad_norm": 2.8876888751983643,
      "learning_rate": 6.223610693902073e-05,
      "logits/chosen": -0.7232798337936401,
      "logits/rejected": -0.7752770185470581,
      "logps/chosen": -210.80502319335938,
      "logps/rejected": -232.4930877685547,
      "loss": 0.3518,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.068159580230713,
      "rewards/margins": 1.6666351556777954,
      "rewards/rejected": -4.734794616699219,
      "step": 3850
    },
    {
      "epoch": 1.1489805030510492,
      "grad_norm": 7.32369327545166,
      "learning_rate": 6.218804445779513e-05,
      "logits/chosen": -0.7278649210929871,
      "logits/rejected": -0.8165310621261597,
      "logps/chosen": -187.16757202148438,
      "logps/rejected": -215.5323028564453,
      "loss": 0.4859,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.188356637954712,
      "rewards/margins": 1.281797170639038,
      "rewards/rejected": -4.47015380859375,
      "step": 3860
    },
    {
      "epoch": 1.1519571364786427,
      "grad_norm": 6.689932823181152,
      "learning_rate": 6.213998197656954e-05,
      "logits/chosen": -0.8806148767471313,
      "logits/rejected": -0.9655517339706421,
      "logps/chosen": -189.8411407470703,
      "logps/rejected": -216.82577514648438,
      "loss": 0.5156,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.796832323074341,
      "rewards/margins": 1.272881031036377,
      "rewards/rejected": -4.069713115692139,
      "step": 3870
    },
    {
      "epoch": 1.154933769906236,
      "grad_norm": 6.338642120361328,
      "learning_rate": 6.209191949534396e-05,
      "logits/chosen": -0.7716227769851685,
      "logits/rejected": -0.9351493120193481,
      "logps/chosen": -193.4453582763672,
      "logps/rejected": -242.4921875,
      "loss": 0.4086,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.1995723247528076,
      "rewards/margins": 1.6627027988433838,
      "rewards/rejected": -4.86227560043335,
      "step": 3880
    },
    {
      "epoch": 1.1579104033338294,
      "grad_norm": 2.7896080017089844,
      "learning_rate": 6.204385701411837e-05,
      "logits/chosen": -0.9733819961547852,
      "logits/rejected": -0.959997296333313,
      "logps/chosen": -222.76025390625,
      "logps/rejected": -239.76467895507812,
      "loss": 0.3521,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.95754075050354,
      "rewards/margins": 1.4482790231704712,
      "rewards/rejected": -4.405819892883301,
      "step": 3890
    },
    {
      "epoch": 1.1608870367614228,
      "grad_norm": 4.061676025390625,
      "learning_rate": 6.199579453289277e-05,
      "logits/chosen": -0.8807541728019714,
      "logits/rejected": -0.9286953210830688,
      "logps/chosen": -194.23001098632812,
      "logps/rejected": -213.08261108398438,
      "loss": 0.5012,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.262716770172119,
      "rewards/margins": 1.23462975025177,
      "rewards/rejected": -3.4973464012145996,
      "step": 3900
    },
    {
      "epoch": 1.1638636701890162,
      "grad_norm": 5.233249664306641,
      "learning_rate": 6.194773205166718e-05,
      "logits/chosen": -0.9395143389701843,
      "logits/rejected": -0.9277550578117371,
      "logps/chosen": -194.51889038085938,
      "logps/rejected": -198.66976928710938,
      "loss": 0.5369,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.0917978286743164,
      "rewards/margins": 0.9727274179458618,
      "rewards/rejected": -3.0645253658294678,
      "step": 3910
    },
    {
      "epoch": 1.1668403036166097,
      "grad_norm": 2.7903833389282227,
      "learning_rate": 6.189966957044158e-05,
      "logits/chosen": -0.8508666157722473,
      "logits/rejected": -0.9106114506721497,
      "logps/chosen": -179.64407348632812,
      "logps/rejected": -210.458740234375,
      "loss": 0.4026,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0324172973632812,
      "rewards/margins": 1.5297651290893555,
      "rewards/rejected": -3.562182664871216,
      "step": 3920
    },
    {
      "epoch": 1.169816937044203,
      "grad_norm": 7.034722328186035,
      "learning_rate": 6.185160708921598e-05,
      "logits/chosen": -0.9217901229858398,
      "logits/rejected": -0.9503629803657532,
      "logps/chosen": -197.44052124023438,
      "logps/rejected": -213.93603515625,
      "loss": 0.5899,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.623375415802002,
      "rewards/margins": 0.8411153554916382,
      "rewards/rejected": -3.4644908905029297,
      "step": 3930
    },
    {
      "epoch": 1.1727935704717964,
      "grad_norm": 3.822007894515991,
      "learning_rate": 6.180354460799038e-05,
      "logits/chosen": -0.9028498530387878,
      "logits/rejected": -0.8501261472702026,
      "logps/chosen": -215.0948486328125,
      "logps/rejected": -215.4450225830078,
      "loss": 0.437,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1621668338775635,
      "rewards/margins": 0.9759165048599243,
      "rewards/rejected": -3.1380832195281982,
      "step": 3940
    },
    {
      "epoch": 1.1757702038993898,
      "grad_norm": 4.67323637008667,
      "learning_rate": 6.17554821267648e-05,
      "logits/chosen": -0.9536741375923157,
      "logits/rejected": -0.9378601312637329,
      "logps/chosen": -187.8660888671875,
      "logps/rejected": -196.62640380859375,
      "loss": 0.4825,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.846416711807251,
      "rewards/margins": 1.0415021181106567,
      "rewards/rejected": -2.8879189491271973,
      "step": 3950
    },
    {
      "epoch": 1.1787468373269832,
      "grad_norm": 4.689813613891602,
      "learning_rate": 6.170741964553921e-05,
      "logits/chosen": -0.9795457720756531,
      "logits/rejected": -1.018990397453308,
      "logps/chosen": -195.7078399658203,
      "logps/rejected": -217.0519256591797,
      "loss": 0.4813,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.6276886463165283,
      "rewards/margins": 1.1450841426849365,
      "rewards/rejected": -3.772773027420044,
      "step": 3960
    },
    {
      "epoch": 1.1817234707545765,
      "grad_norm": 5.262818813323975,
      "learning_rate": 6.165935716431361e-05,
      "logits/chosen": -0.9751002192497253,
      "logits/rejected": -1.0073413848876953,
      "logps/chosen": -193.75436401367188,
      "logps/rejected": -213.6801300048828,
      "loss": 0.5073,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.759169101715088,
      "rewards/margins": 1.056726098060608,
      "rewards/rejected": -3.8158950805664062,
      "step": 3970
    },
    {
      "epoch": 1.1847001041821699,
      "grad_norm": 3.8157081604003906,
      "learning_rate": 6.161129468308802e-05,
      "logits/chosen": -0.9285880923271179,
      "logits/rejected": -0.9551151990890503,
      "logps/chosen": -198.00465393066406,
      "logps/rejected": -233.68063354492188,
      "loss": 0.4099,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.580105781555176,
      "rewards/margins": 1.3020243644714355,
      "rewards/rejected": -3.8821303844451904,
      "step": 3980
    },
    {
      "epoch": 1.1876767376097634,
      "grad_norm": 4.380044460296631,
      "learning_rate": 6.156323220186243e-05,
      "logits/chosen": -0.8958011865615845,
      "logits/rejected": -0.9463204145431519,
      "logps/chosen": -205.9014129638672,
      "logps/rejected": -235.43429565429688,
      "loss": 0.3383,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.989719867706299,
      "rewards/margins": 1.6366227865219116,
      "rewards/rejected": -4.626343250274658,
      "step": 3990
    },
    {
      "epoch": 1.1906533710373568,
      "grad_norm": 4.682768821716309,
      "learning_rate": 6.151516972063683e-05,
      "logits/chosen": -0.9405552744865417,
      "logits/rejected": -0.9470905065536499,
      "logps/chosen": -215.556884765625,
      "logps/rejected": -231.0933074951172,
      "loss": 0.4102,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.2209174633026123,
      "rewards/margins": 1.4612218141555786,
      "rewards/rejected": -4.6821393966674805,
      "step": 4000
    },
    {
      "epoch": 1.1936300044649502,
      "grad_norm": 3.1280126571655273,
      "learning_rate": 6.146710723941124e-05,
      "logits/chosen": -0.8828452825546265,
      "logits/rejected": -0.9873319864273071,
      "logps/chosen": -193.41506958007812,
      "logps/rejected": -232.88772583007812,
      "loss": 0.4668,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.8303382396698,
      "rewards/margins": 1.5569331645965576,
      "rewards/rejected": -5.387271404266357,
      "step": 4010
    },
    {
      "epoch": 1.1966066378925435,
      "grad_norm": 4.46779203414917,
      "learning_rate": 6.141904475818565e-05,
      "logits/chosen": -0.8292118906974792,
      "logits/rejected": -0.9349692463874817,
      "logps/chosen": -193.09100341796875,
      "logps/rejected": -231.08761596679688,
      "loss": 0.4061,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.4490761756896973,
      "rewards/margins": 1.7255032062530518,
      "rewards/rejected": -5.17457914352417,
      "step": 4020
    },
    {
      "epoch": 1.1995832713201369,
      "grad_norm": 6.835309982299805,
      "learning_rate": 6.137098227696005e-05,
      "logits/chosen": -0.8415864109992981,
      "logits/rejected": -0.9104088544845581,
      "logps/chosen": -193.12246704101562,
      "logps/rejected": -220.0592803955078,
      "loss": 0.4484,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -3.1964383125305176,
      "rewards/margins": 1.4485359191894531,
      "rewards/rejected": -4.644974231719971,
      "step": 4030
    },
    {
      "epoch": 1.2025599047477302,
      "grad_norm": 7.919963836669922,
      "learning_rate": 6.132291979573446e-05,
      "logits/chosen": -0.8539859056472778,
      "logits/rejected": -0.8620290756225586,
      "logps/chosen": -211.64260864257812,
      "logps/rejected": -233.03311157226562,
      "loss": 0.5027,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.1488471031188965,
      "rewards/margins": 1.3652633428573608,
      "rewards/rejected": -4.514110565185547,
      "step": 4040
    },
    {
      "epoch": 1.2055365381753238,
      "grad_norm": 3.82525634765625,
      "learning_rate": 6.127485731450886e-05,
      "logits/chosen": -0.8090389370918274,
      "logits/rejected": -0.8212539553642273,
      "logps/chosen": -211.35617065429688,
      "logps/rejected": -234.4902801513672,
      "loss": 0.5253,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.782264232635498,
      "rewards/margins": 1.4788724184036255,
      "rewards/rejected": -5.261136531829834,
      "step": 4050
    },
    {
      "epoch": 1.2085131716029172,
      "grad_norm": 2.117197275161743,
      "learning_rate": 6.122679483328327e-05,
      "logits/chosen": -0.8219223022460938,
      "logits/rejected": -0.7485896348953247,
      "logps/chosen": -210.3601531982422,
      "logps/rejected": -226.2949676513672,
      "loss": 0.3681,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.7829301357269287,
      "rewards/margins": 2.0073189735412598,
      "rewards/rejected": -4.790248870849609,
      "step": 4060
    },
    {
      "epoch": 1.2114898050305105,
      "grad_norm": 6.588192939758301,
      "learning_rate": 6.117873235205768e-05,
      "logits/chosen": -0.6097161769866943,
      "logits/rejected": -0.6761428713798523,
      "logps/chosen": -218.3379669189453,
      "logps/rejected": -242.5160369873047,
      "loss": 0.4042,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.7672088146209717,
      "rewards/margins": 1.525537133216858,
      "rewards/rejected": -5.292746067047119,
      "step": 4070
    },
    {
      "epoch": 1.2144664384581039,
      "grad_norm": 3.5156846046447754,
      "learning_rate": 6.113066987083208e-05,
      "logits/chosen": -0.6726025342941284,
      "logits/rejected": -0.7129844427108765,
      "logps/chosen": -209.4743194580078,
      "logps/rejected": -232.840576171875,
      "loss": 0.3763,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.4873459339141846,
      "rewards/margins": 1.6400775909423828,
      "rewards/rejected": -5.127423286437988,
      "step": 4080
    },
    {
      "epoch": 1.2174430718856972,
      "grad_norm": 5.244047164916992,
      "learning_rate": 6.108260738960649e-05,
      "logits/chosen": -0.5926367044448853,
      "logits/rejected": -0.6210325360298157,
      "logps/chosen": -195.20343017578125,
      "logps/rejected": -211.7620391845703,
      "loss": 0.4694,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.685349702835083,
      "rewards/margins": 1.3213101625442505,
      "rewards/rejected": -5.006659984588623,
      "step": 4090
    },
    {
      "epoch": 1.2204197053132906,
      "grad_norm": 10.48891544342041,
      "learning_rate": 6.10345449083809e-05,
      "logits/chosen": -0.689566433429718,
      "logits/rejected": -0.7326227426528931,
      "logps/chosen": -234.4716796875,
      "logps/rejected": -258.3140563964844,
      "loss": 0.5482,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.7885749340057373,
      "rewards/margins": 1.244023084640503,
      "rewards/rejected": -5.03259801864624,
      "step": 4100
    },
    {
      "epoch": 1.223396338740884,
      "grad_norm": 7.777186870574951,
      "learning_rate": 6.098648242715531e-05,
      "logits/chosen": -0.6993013620376587,
      "logits/rejected": -0.6961819529533386,
      "logps/chosen": -231.6807403564453,
      "logps/rejected": -246.4333038330078,
      "loss": 0.4915,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.8591971397399902,
      "rewards/margins": 1.2351057529449463,
      "rewards/rejected": -5.094303131103516,
      "step": 4110
    },
    {
      "epoch": 1.2263729721684775,
      "grad_norm": 4.674156188964844,
      "learning_rate": 6.093841994592971e-05,
      "logits/chosen": -0.6517392992973328,
      "logits/rejected": -0.663364052772522,
      "logps/chosen": -206.07113647460938,
      "logps/rejected": -216.4981231689453,
      "loss": 0.4498,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.8466274738311768,
      "rewards/margins": 0.9977318048477173,
      "rewards/rejected": -4.844358921051025,
      "step": 4120
    },
    {
      "epoch": 1.2293496055960709,
      "grad_norm": 4.211210250854492,
      "learning_rate": 6.089035746470412e-05,
      "logits/chosen": -0.6806820034980774,
      "logits/rejected": -0.6580148935317993,
      "logps/chosen": -201.26821899414062,
      "logps/rejected": -209.6449432373047,
      "loss": 0.6047,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.2077572345733643,
      "rewards/margins": 0.8944199681282043,
      "rewards/rejected": -4.102177143096924,
      "step": 4130
    },
    {
      "epoch": 1.2323262390236642,
      "grad_norm": 4.4344353675842285,
      "learning_rate": 6.084229498347853e-05,
      "logits/chosen": -0.7935815453529358,
      "logits/rejected": -0.7945656180381775,
      "logps/chosen": -198.44114685058594,
      "logps/rejected": -203.71865844726562,
      "loss": 0.4827,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.810453414916992,
      "rewards/margins": 0.9968552589416504,
      "rewards/rejected": -3.8073086738586426,
      "step": 4140
    },
    {
      "epoch": 1.2353028724512576,
      "grad_norm": 6.094699382781982,
      "learning_rate": 6.079423250225294e-05,
      "logits/chosen": -0.8233476877212524,
      "logits/rejected": -0.8661494255065918,
      "logps/chosen": -199.609130859375,
      "logps/rejected": -222.877197265625,
      "loss": 0.416,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.010031223297119,
      "rewards/margins": 1.3947865962982178,
      "rewards/rejected": -4.404818058013916,
      "step": 4150
    },
    {
      "epoch": 1.238279505878851,
      "grad_norm": 2.9920644760131836,
      "learning_rate": 6.0746170021027345e-05,
      "logits/chosen": -0.7523073554039001,
      "logits/rejected": -0.8255599737167358,
      "logps/chosen": -202.91290283203125,
      "logps/rejected": -223.30905151367188,
      "loss": 0.5147,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.373546600341797,
      "rewards/margins": 1.0510920286178589,
      "rewards/rejected": -4.424638748168945,
      "step": 4160
    },
    {
      "epoch": 1.2412561393064445,
      "grad_norm": 3.672264337539673,
      "learning_rate": 6.069810753980175e-05,
      "logits/chosen": -0.803641676902771,
      "logits/rejected": -0.8212774991989136,
      "logps/chosen": -224.28366088867188,
      "logps/rejected": -241.3925323486328,
      "loss": 0.4559,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.368720531463623,
      "rewards/margins": 1.3461240530014038,
      "rewards/rejected": -4.714844703674316,
      "step": 4170
    },
    {
      "epoch": 1.2442327727340379,
      "grad_norm": 7.4823126792907715,
      "learning_rate": 6.065004505857615e-05,
      "logits/chosen": -0.9590493440628052,
      "logits/rejected": -0.8908175230026245,
      "logps/chosen": -203.25051879882812,
      "logps/rejected": -198.17977905273438,
      "loss": 0.4889,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.56298565864563,
      "rewards/margins": 1.0922366380691528,
      "rewards/rejected": -3.6552224159240723,
      "step": 4180
    },
    {
      "epoch": 1.2472094061616312,
      "grad_norm": 1.869724988937378,
      "learning_rate": 6.0601982577350556e-05,
      "logits/chosen": -0.7936528921127319,
      "logits/rejected": -0.8256213068962097,
      "logps/chosen": -189.4876251220703,
      "logps/rejected": -211.6808319091797,
      "loss": 0.3495,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.5064682960510254,
      "rewards/margins": 1.5316213369369507,
      "rewards/rejected": -4.038089752197266,
      "step": 4190
    },
    {
      "epoch": 1.2501860395892246,
      "grad_norm": 3.8743350505828857,
      "learning_rate": 6.055392009612496e-05,
      "logits/chosen": -0.759016215801239,
      "logits/rejected": -0.8158676028251648,
      "logps/chosen": -203.54043579101562,
      "logps/rejected": -236.91250610351562,
      "loss": 0.4545,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.436039686203003,
      "rewards/margins": 1.5138853788375854,
      "rewards/rejected": -4.949925422668457,
      "step": 4200
    },
    {
      "epoch": 1.253162673016818,
      "grad_norm": 3.291053056716919,
      "learning_rate": 6.0505857614899375e-05,
      "logits/chosen": -0.8221050500869751,
      "logits/rejected": -0.8288874626159668,
      "logps/chosen": -210.82632446289062,
      "logps/rejected": -228.8872528076172,
      "loss": 0.4283,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.9671974182128906,
      "rewards/margins": 1.421066403388977,
      "rewards/rejected": -4.388263702392578,
      "step": 4210
    },
    {
      "epoch": 1.2561393064444113,
      "grad_norm": 2.878354549407959,
      "learning_rate": 6.045779513367378e-05,
      "logits/chosen": -0.7135518193244934,
      "logits/rejected": -0.7535154819488525,
      "logps/chosen": -205.316650390625,
      "logps/rejected": -226.69723510742188,
      "loss": 0.463,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.2568092346191406,
      "rewards/margins": 1.2181378602981567,
      "rewards/rejected": -4.474947452545166,
      "step": 4220
    },
    {
      "epoch": 1.2591159398720047,
      "grad_norm": 3.720768928527832,
      "learning_rate": 6.040973265244819e-05,
      "logits/chosen": -0.7896732687950134,
      "logits/rejected": -0.8329477310180664,
      "logps/chosen": -188.11703491210938,
      "logps/rejected": -207.25442504882812,
      "loss": 0.5226,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.7879717350006104,
      "rewards/margins": 1.133424162864685,
      "rewards/rejected": -3.921396255493164,
      "step": 4230
    },
    {
      "epoch": 1.2620925732995982,
      "grad_norm": 3.6004319190979004,
      "learning_rate": 6.0361670171222594e-05,
      "logits/chosen": -0.7876050472259521,
      "logits/rejected": -0.8260354995727539,
      "logps/chosen": -196.81015014648438,
      "logps/rejected": -222.25424194335938,
      "loss": 0.3979,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.5224051475524902,
      "rewards/margins": 1.4325096607208252,
      "rewards/rejected": -3.9549148082733154,
      "step": 4240
    },
    {
      "epoch": 1.2650692067271916,
      "grad_norm": 7.793047904968262,
      "learning_rate": 6.0313607689997e-05,
      "logits/chosen": -0.8423212766647339,
      "logits/rejected": -0.9262076616287231,
      "logps/chosen": -204.496337890625,
      "logps/rejected": -228.0640411376953,
      "loss": 0.5138,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.0777900218963623,
      "rewards/margins": 1.1466225385665894,
      "rewards/rejected": -3.224412441253662,
      "step": 4250
    },
    {
      "epoch": 1.268045840154785,
      "grad_norm": 4.259014129638672,
      "learning_rate": 6.026554520877141e-05,
      "logits/chosen": -0.882872462272644,
      "logits/rejected": -0.932726263999939,
      "logps/chosen": -190.9003143310547,
      "logps/rejected": -224.7482452392578,
      "loss": 0.3501,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.5248160362243652,
      "rewards/margins": 1.4895280599594116,
      "rewards/rejected": -3.0143444538116455,
      "step": 4260
    },
    {
      "epoch": 1.2710224735823783,
      "grad_norm": 3.405451774597168,
      "learning_rate": 6.021748272754582e-05,
      "logits/chosen": -0.898896336555481,
      "logits/rejected": -0.9517580270767212,
      "logps/chosen": -199.31869506835938,
      "logps/rejected": -224.5087127685547,
      "loss": 0.3951,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0184831619262695,
      "rewards/margins": 1.3439794778823853,
      "rewards/rejected": -3.3624625205993652,
      "step": 4270
    },
    {
      "epoch": 1.2739991070099717,
      "grad_norm": 5.025654315948486,
      "learning_rate": 6.0169420246320225e-05,
      "logits/chosen": -0.8548073768615723,
      "logits/rejected": -0.8862999081611633,
      "logps/chosen": -203.015625,
      "logps/rejected": -222.2017364501953,
      "loss": 0.3393,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.348301410675049,
      "rewards/margins": 1.7407605648040771,
      "rewards/rejected": -4.089061737060547,
      "step": 4280
    },
    {
      "epoch": 1.2769757404375652,
      "grad_norm": 5.728916645050049,
      "learning_rate": 6.012135776509463e-05,
      "logits/chosen": -0.9030078053474426,
      "logits/rejected": -0.9555519223213196,
      "logps/chosen": -193.9320831298828,
      "logps/rejected": -216.5748291015625,
      "loss": 0.5147,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.829003095626831,
      "rewards/margins": 1.3704965114593506,
      "rewards/rejected": -3.1994996070861816,
      "step": 4290
    },
    {
      "epoch": 1.2799523738651586,
      "grad_norm": 4.842463970184326,
      "learning_rate": 6.007329528386903e-05,
      "logits/chosen": -0.9770609736442566,
      "logits/rejected": -0.9970777630805969,
      "logps/chosen": -178.85336303710938,
      "logps/rejected": -198.2813262939453,
      "loss": 0.4231,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.316892385482788,
      "rewards/margins": 1.403494119644165,
      "rewards/rejected": -2.720386505126953,
      "step": 4300
    },
    {
      "epoch": 1.282929007292752,
      "grad_norm": 2.3711631298065186,
      "learning_rate": 6.002523280264344e-05,
      "logits/chosen": -1.0340373516082764,
      "logits/rejected": -1.0683858394622803,
      "logps/chosen": -213.27426147460938,
      "logps/rejected": -249.3536376953125,
      "loss": 0.3967,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.6930675506591797,
      "rewards/margins": 1.4752819538116455,
      "rewards/rejected": -3.168349504470825,
      "step": 4310
    },
    {
      "epoch": 1.2859056407203453,
      "grad_norm": 5.651860237121582,
      "learning_rate": 5.997717032141784e-05,
      "logits/chosen": -0.9916332960128784,
      "logits/rejected": -1.051316499710083,
      "logps/chosen": -198.0973663330078,
      "logps/rejected": -229.15072631835938,
      "loss": 0.3845,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.830531597137451,
      "rewards/margins": 1.7601503133773804,
      "rewards/rejected": -4.590682029724121,
      "step": 4320
    },
    {
      "epoch": 1.2888822741479387,
      "grad_norm": 2.7717742919921875,
      "learning_rate": 5.9929107840192256e-05,
      "logits/chosen": -1.0287930965423584,
      "logits/rejected": -1.0142465829849243,
      "logps/chosen": -191.43569946289062,
      "logps/rejected": -206.1727752685547,
      "loss": 0.4692,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.2465858459472656,
      "rewards/margins": 1.253983736038208,
      "rewards/rejected": -3.5005695819854736,
      "step": 4330
    },
    {
      "epoch": 1.291858907575532,
      "grad_norm": 6.0342183113098145,
      "learning_rate": 5.988104535896666e-05,
      "logits/chosen": -1.0215741395950317,
      "logits/rejected": -1.1106226444244385,
      "logps/chosen": -195.72344970703125,
      "logps/rejected": -233.3906707763672,
      "loss": 0.4589,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.473437786102295,
      "rewards/margins": 1.4399785995483398,
      "rewards/rejected": -3.9134163856506348,
      "step": 4340
    },
    {
      "epoch": 1.2948355410031254,
      "grad_norm": 4.280180931091309,
      "learning_rate": 5.983298287774107e-05,
      "logits/chosen": -0.991396427154541,
      "logits/rejected": -1.0601609945297241,
      "logps/chosen": -196.4944305419922,
      "logps/rejected": -230.714599609375,
      "loss": 0.3938,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.532325267791748,
      "rewards/margins": 1.9049879312515259,
      "rewards/rejected": -4.437313079833984,
      "step": 4350
    },
    {
      "epoch": 1.2978121744307187,
      "grad_norm": 4.297778129577637,
      "learning_rate": 5.9784920396515474e-05,
      "logits/chosen": -0.9981575012207031,
      "logits/rejected": -1.0727711915969849,
      "logps/chosen": -183.44105529785156,
      "logps/rejected": -217.9885711669922,
      "loss": 0.3663,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.645426034927368,
      "rewards/margins": 1.7687957286834717,
      "rewards/rejected": -4.414221286773682,
      "step": 4360
    },
    {
      "epoch": 1.3007888078583123,
      "grad_norm": 2.7831931114196777,
      "learning_rate": 5.973685791528988e-05,
      "logits/chosen": -1.082175612449646,
      "logits/rejected": -1.052416443824768,
      "logps/chosen": -212.0186004638672,
      "logps/rejected": -217.45565795898438,
      "loss": 0.369,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.4509551525115967,
      "rewards/margins": 1.480132818222046,
      "rewards/rejected": -3.9310882091522217,
      "step": 4370
    },
    {
      "epoch": 1.3037654412859057,
      "grad_norm": 5.127490997314453,
      "learning_rate": 5.9688795434064294e-05,
      "logits/chosen": -1.0132739543914795,
      "logits/rejected": -1.0336741209030151,
      "logps/chosen": -207.6172332763672,
      "logps/rejected": -225.05078125,
      "loss": 0.4555,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.7040019035339355,
      "rewards/margins": 1.238531470298767,
      "rewards/rejected": -3.942533493041992,
      "step": 4380
    },
    {
      "epoch": 1.306742074713499,
      "grad_norm": 4.045278549194336,
      "learning_rate": 5.96407329528387e-05,
      "logits/chosen": -0.9543377757072449,
      "logits/rejected": -0.9869958758354187,
      "logps/chosen": -191.55914306640625,
      "logps/rejected": -218.77700805664062,
      "loss": 0.4097,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.478926181793213,
      "rewards/margins": 1.3733104467391968,
      "rewards/rejected": -3.85223650932312,
      "step": 4390
    },
    {
      "epoch": 1.3097187081410924,
      "grad_norm": 7.291454315185547,
      "learning_rate": 5.9592670471613106e-05,
      "logits/chosen": -0.9538580179214478,
      "logits/rejected": -1.0654065608978271,
      "logps/chosen": -179.6652069091797,
      "logps/rejected": -230.8815155029297,
      "loss": 0.4378,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.2981181144714355,
      "rewards/margins": 1.4672069549560547,
      "rewards/rejected": -4.76532506942749,
      "step": 4400
    },
    {
      "epoch": 1.312695341568686,
      "grad_norm": 3.6278696060180664,
      "learning_rate": 5.954460799038751e-05,
      "logits/chosen": -0.9276289939880371,
      "logits/rejected": -1.0082924365997314,
      "logps/chosen": -199.42056274414062,
      "logps/rejected": -243.5719757080078,
      "loss": 0.4552,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.15403413772583,
      "rewards/margins": 1.4912351369857788,
      "rewards/rejected": -4.645269393920898,
      "step": 4410
    },
    {
      "epoch": 1.3156719749962793,
      "grad_norm": 4.616237640380859,
      "learning_rate": 5.949654550916191e-05,
      "logits/chosen": -1.0731446743011475,
      "logits/rejected": -1.0840390920639038,
      "logps/chosen": -195.71229553222656,
      "logps/rejected": -210.20999145507812,
      "loss": 0.4014,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.719712018966675,
      "rewards/margins": 1.2827155590057373,
      "rewards/rejected": -4.002427577972412,
      "step": 4420
    },
    {
      "epoch": 1.3186486084238727,
      "grad_norm": 5.369238376617432,
      "learning_rate": 5.944848302793632e-05,
      "logits/chosen": -1.0230703353881836,
      "logits/rejected": -1.0211937427520752,
      "logps/chosen": -192.43453979492188,
      "logps/rejected": -208.5076141357422,
      "loss": 0.4309,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.394814968109131,
      "rewards/margins": 1.4410415887832642,
      "rewards/rejected": -3.8358566761016846,
      "step": 4430
    },
    {
      "epoch": 1.321625241851466,
      "grad_norm": 2.9231560230255127,
      "learning_rate": 5.9400420546710724e-05,
      "logits/chosen": -0.9686728715896606,
      "logits/rejected": -1.0562446117401123,
      "logps/chosen": -194.8743438720703,
      "logps/rejected": -235.88436889648438,
      "loss": 0.4176,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.2788946628570557,
      "rewards/margins": 1.7524044513702393,
      "rewards/rejected": -4.031298637390137,
      "step": 4440
    },
    {
      "epoch": 1.3246018752790594,
      "grad_norm": 3.4344494342803955,
      "learning_rate": 5.9352358065485137e-05,
      "logits/chosen": -1.0108952522277832,
      "logits/rejected": -1.0660407543182373,
      "logps/chosen": -191.44566345214844,
      "logps/rejected": -222.7322998046875,
      "loss": 0.3502,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.1552317142486572,
      "rewards/margins": 1.6708557605743408,
      "rewards/rejected": -3.826087236404419,
      "step": 4450
    },
    {
      "epoch": 1.3275785087066527,
      "grad_norm": 4.034864902496338,
      "learning_rate": 5.930429558425954e-05,
      "logits/chosen": -0.969436526298523,
      "logits/rejected": -1.0019407272338867,
      "logps/chosen": -208.59375,
      "logps/rejected": -231.68948364257812,
      "loss": 0.3906,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.01127290725708,
      "rewards/margins": 1.576337456703186,
      "rewards/rejected": -4.587610721588135,
      "step": 4460
    },
    {
      "epoch": 1.330555142134246,
      "grad_norm": 3.704779863357544,
      "learning_rate": 5.925623310303395e-05,
      "logits/chosen": -1.0597277879714966,
      "logits/rejected": -1.0331989526748657,
      "logps/chosen": -191.60556030273438,
      "logps/rejected": -197.6593017578125,
      "loss": 0.4251,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.2819836139678955,
      "rewards/margins": 1.2992093563079834,
      "rewards/rejected": -3.581193208694458,
      "step": 4470
    },
    {
      "epoch": 1.3335317755618394,
      "grad_norm": 14.272339820861816,
      "learning_rate": 5.9208170621808355e-05,
      "logits/chosen": -0.9550822377204895,
      "logits/rejected": -0.9725041389465332,
      "logps/chosen": -239.4604949951172,
      "logps/rejected": -248.96188354492188,
      "loss": 0.4922,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.416455030441284,
      "rewards/margins": 1.4239591360092163,
      "rewards/rejected": -4.840413570404053,
      "step": 4480
    },
    {
      "epoch": 1.336508408989433,
      "grad_norm": 2.701411247253418,
      "learning_rate": 5.916010814058276e-05,
      "logits/chosen": -0.8530169725418091,
      "logits/rejected": -0.9559119343757629,
      "logps/chosen": -194.57180786132812,
      "logps/rejected": -231.02566528320312,
      "loss": 0.4297,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.0631582736968994,
      "rewards/margins": 1.5083115100860596,
      "rewards/rejected": -4.571469783782959,
      "step": 4490
    },
    {
      "epoch": 1.3394850424170264,
      "grad_norm": 4.614861011505127,
      "learning_rate": 5.9112045659357174e-05,
      "logits/chosen": -0.8196685910224915,
      "logits/rejected": -0.91664057970047,
      "logps/chosen": -205.7014923095703,
      "logps/rejected": -250.1165771484375,
      "loss": 0.3738,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.6024374961853027,
      "rewards/margins": 2.167586088180542,
      "rewards/rejected": -5.770023345947266,
      "step": 4500
    },
    {
      "epoch": 1.3424616758446197,
      "grad_norm": 3.833310127258301,
      "learning_rate": 5.906398317813158e-05,
      "logits/chosen": -0.8955095410346985,
      "logits/rejected": -0.9292011260986328,
      "logps/chosen": -183.56912231445312,
      "logps/rejected": -210.1297149658203,
      "loss": 0.4207,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.0466299057006836,
      "rewards/margins": 1.7015308141708374,
      "rewards/rejected": -4.748160362243652,
      "step": 4510
    },
    {
      "epoch": 1.345438309272213,
      "grad_norm": 4.915456295013428,
      "learning_rate": 5.9015920696905986e-05,
      "logits/chosen": -0.9561094045639038,
      "logits/rejected": -0.9343549609184265,
      "logps/chosen": -200.2451934814453,
      "logps/rejected": -210.5509490966797,
      "loss": 0.5086,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.696932792663574,
      "rewards/margins": 1.6008901596069336,
      "rewards/rejected": -4.297823429107666,
      "step": 4520
    },
    {
      "epoch": 1.3484149426998064,
      "grad_norm": 5.396085739135742,
      "learning_rate": 5.896785821568039e-05,
      "logits/chosen": -0.946823239326477,
      "logits/rejected": -1.0027434825897217,
      "logps/chosen": -215.37362670898438,
      "logps/rejected": -244.9798126220703,
      "loss": 0.4926,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.97615122795105,
      "rewards/margins": 1.3467488288879395,
      "rewards/rejected": -4.322900295257568,
      "step": 4530
    },
    {
      "epoch": 1.3513915761274,
      "grad_norm": 7.523108959197998,
      "learning_rate": 5.891979573445479e-05,
      "logits/chosen": -0.8699695467948914,
      "logits/rejected": -0.8703676462173462,
      "logps/chosen": -192.88145446777344,
      "logps/rejected": -208.2229461669922,
      "loss": 0.4819,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.8248536586761475,
      "rewards/margins": 1.4472708702087402,
      "rewards/rejected": -4.272124290466309,
      "step": 4540
    },
    {
      "epoch": 1.3543682095549934,
      "grad_norm": 4.18428373336792,
      "learning_rate": 5.88717332532292e-05,
      "logits/chosen": -0.7758336663246155,
      "logits/rejected": -0.8916326761245728,
      "logps/chosen": -183.63812255859375,
      "logps/rejected": -216.83657836914062,
      "loss": 0.4511,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.8137998580932617,
      "rewards/margins": 1.2502009868621826,
      "rewards/rejected": -4.064000606536865,
      "step": 4550
    },
    {
      "epoch": 1.3573448429825867,
      "grad_norm": 9.853818893432617,
      "learning_rate": 5.8823670772003604e-05,
      "logits/chosen": -0.7865718603134155,
      "logits/rejected": -0.8017221689224243,
      "logps/chosen": -200.09796142578125,
      "logps/rejected": -222.98593139648438,
      "loss": 0.4297,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.5129001140594482,
      "rewards/margins": 1.3933185338974,
      "rewards/rejected": -3.9062187671661377,
      "step": 4560
    },
    {
      "epoch": 1.36032147641018,
      "grad_norm": 4.535844326019287,
      "learning_rate": 5.877560829077802e-05,
      "logits/chosen": -0.9043635129928589,
      "logits/rejected": -0.8830575942993164,
      "logps/chosen": -188.5312042236328,
      "logps/rejected": -207.3682861328125,
      "loss": 0.411,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.137516498565674,
      "rewards/margins": 1.4295583963394165,
      "rewards/rejected": -3.56707501411438,
      "step": 4570
    },
    {
      "epoch": 1.3632981098377734,
      "grad_norm": 5.63885498046875,
      "learning_rate": 5.872754580955242e-05,
      "logits/chosen": -0.8516526222229004,
      "logits/rejected": -0.8540905714035034,
      "logps/chosen": -196.01028442382812,
      "logps/rejected": -219.9153289794922,
      "loss": 0.5234,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.726527690887451,
      "rewards/margins": 1.2919776439666748,
      "rewards/rejected": -4.018505573272705,
      "step": 4580
    },
    {
      "epoch": 1.3662747432653668,
      "grad_norm": 3.762439727783203,
      "learning_rate": 5.867948332832683e-05,
      "logits/chosen": -0.8726446032524109,
      "logits/rejected": -0.9398218393325806,
      "logps/chosen": -204.70297241210938,
      "logps/rejected": -233.08486938476562,
      "loss": 0.3372,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.43141508102417,
      "rewards/margins": 1.9987752437591553,
      "rewards/rejected": -4.430190086364746,
      "step": 4590
    },
    {
      "epoch": 1.3692513766929602,
      "grad_norm": 6.452539443969727,
      "learning_rate": 5.8631420847101236e-05,
      "logits/chosen": -0.8425421714782715,
      "logits/rejected": -0.898415744304657,
      "logps/chosen": -186.05325317382812,
      "logps/rejected": -232.8426971435547,
      "loss": 0.3549,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.5431737899780273,
      "rewards/margins": 1.9205173254013062,
      "rewards/rejected": -4.463691234588623,
      "step": 4600
    },
    {
      "epoch": 1.3722280101205537,
      "grad_norm": 5.39857816696167,
      "learning_rate": 5.858335836587564e-05,
      "logits/chosen": -0.832984447479248,
      "logits/rejected": -0.9530434608459473,
      "logps/chosen": -202.00167846679688,
      "logps/rejected": -256.5856018066406,
      "loss": 0.455,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.878871440887451,
      "rewards/margins": 2.0912513732910156,
      "rewards/rejected": -4.970123291015625,
      "step": 4610
    },
    {
      "epoch": 1.375204643548147,
      "grad_norm": 12.988517761230469,
      "learning_rate": 5.8535295884650055e-05,
      "logits/chosen": -0.927655041217804,
      "logits/rejected": -0.9388788342475891,
      "logps/chosen": -210.3701171875,
      "logps/rejected": -229.2845458984375,
      "loss": 0.5507,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.9519402980804443,
      "rewards/margins": 1.4179426431655884,
      "rewards/rejected": -4.369883060455322,
      "step": 4620
    },
    {
      "epoch": 1.3781812769757404,
      "grad_norm": 8.154762268066406,
      "learning_rate": 5.848723340342446e-05,
      "logits/chosen": -0.877942681312561,
      "logits/rejected": -0.9721583127975464,
      "logps/chosen": -195.50326538085938,
      "logps/rejected": -227.61294555664062,
      "loss": 0.4522,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.096121311187744,
      "rewards/margins": 1.3978878259658813,
      "rewards/rejected": -4.494009017944336,
      "step": 4630
    },
    {
      "epoch": 1.3811579104033338,
      "grad_norm": 4.15828275680542,
      "learning_rate": 5.843917092219887e-05,
      "logits/chosen": -0.9139870405197144,
      "logits/rejected": -0.930263340473175,
      "logps/chosen": -191.49473571777344,
      "logps/rejected": -209.12655639648438,
      "loss": 0.4268,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.610314130783081,
      "rewards/margins": 1.4429707527160645,
      "rewards/rejected": -4.053284645080566,
      "step": 4640
    },
    {
      "epoch": 1.3841345438309272,
      "grad_norm": 3.4737555980682373,
      "learning_rate": 5.839110844097327e-05,
      "logits/chosen": -0.8718427419662476,
      "logits/rejected": -0.9597437977790833,
      "logps/chosen": -206.31784057617188,
      "logps/rejected": -248.2152557373047,
      "loss": 0.4435,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.319134473800659,
      "rewards/margins": 1.547438621520996,
      "rewards/rejected": -4.866572856903076,
      "step": 4650
    },
    {
      "epoch": 1.3871111772585207,
      "grad_norm": 7.136972427368164,
      "learning_rate": 5.834304595974767e-05,
      "logits/chosen": -0.8429244756698608,
      "logits/rejected": -0.8984212875366211,
      "logps/chosen": -190.67684936523438,
      "logps/rejected": -226.29556274414062,
      "loss": 0.4769,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.850083589553833,
      "rewards/margins": 1.808729887008667,
      "rewards/rejected": -4.6588134765625,
      "step": 4660
    },
    {
      "epoch": 1.390087810686114,
      "grad_norm": 3.4219796657562256,
      "learning_rate": 5.829498347852208e-05,
      "logits/chosen": -0.9906252026557922,
      "logits/rejected": -1.0057843923568726,
      "logps/chosen": -183.4100341796875,
      "logps/rejected": -201.86630249023438,
      "loss": 0.411,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.486384630203247,
      "rewards/margins": 1.6298917531967163,
      "rewards/rejected": -4.116275787353516,
      "step": 4670
    },
    {
      "epoch": 1.3930644441137074,
      "grad_norm": 6.344451904296875,
      "learning_rate": 5.8246920997296485e-05,
      "logits/chosen": -0.8565579652786255,
      "logits/rejected": -0.8905194997787476,
      "logps/chosen": -196.94940185546875,
      "logps/rejected": -216.8155059814453,
      "loss": 0.3706,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.733508586883545,
      "rewards/margins": 1.7044938802719116,
      "rewards/rejected": -4.438002586364746,
      "step": 4680
    },
    {
      "epoch": 1.3960410775413008,
      "grad_norm": 4.2238264083862305,
      "learning_rate": 5.81988585160709e-05,
      "logits/chosen": -0.9617627859115601,
      "logits/rejected": -0.981986403465271,
      "logps/chosen": -194.1963653564453,
      "logps/rejected": -213.818603515625,
      "loss": 0.3909,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.3749821186065674,
      "rewards/margins": 1.7722320556640625,
      "rewards/rejected": -4.147213935852051,
      "step": 4690
    },
    {
      "epoch": 1.3990177109688942,
      "grad_norm": 2.205273151397705,
      "learning_rate": 5.8150796034845304e-05,
      "logits/chosen": -0.9183858633041382,
      "logits/rejected": -0.9460153579711914,
      "logps/chosen": -191.0074005126953,
      "logps/rejected": -216.9703826904297,
      "loss": 0.4535,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.971630334854126,
      "rewards/margins": 1.6595184803009033,
      "rewards/rejected": -3.6311492919921875,
      "step": 4700
    },
    {
      "epoch": 1.4019943443964875,
      "grad_norm": 4.891366481781006,
      "learning_rate": 5.810273355361971e-05,
      "logits/chosen": -0.9690852165222168,
      "logits/rejected": -1.0195748805999756,
      "logps/chosen": -196.83184814453125,
      "logps/rejected": -218.01608276367188,
      "loss": 0.4548,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.798526406288147,
      "rewards/margins": 1.2195097208023071,
      "rewards/rejected": -3.018035650253296,
      "step": 4710
    },
    {
      "epoch": 1.4049709778240809,
      "grad_norm": 4.191133975982666,
      "learning_rate": 5.8054671072394116e-05,
      "logits/chosen": -0.9223171472549438,
      "logits/rejected": -0.9683669805526733,
      "logps/chosen": -186.842529296875,
      "logps/rejected": -221.5424346923828,
      "loss": 0.445,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.3003127574920654,
      "rewards/margins": 1.4935123920440674,
      "rewards/rejected": -3.7938246726989746,
      "step": 4720
    },
    {
      "epoch": 1.4079476112516742,
      "grad_norm": 5.1046600341796875,
      "learning_rate": 5.800660859116852e-05,
      "logits/chosen": -0.9346091151237488,
      "logits/rejected": -0.9250373840332031,
      "logps/chosen": -193.154541015625,
      "logps/rejected": -200.78347778320312,
      "loss": 0.4677,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.456921100616455,
      "rewards/margins": 1.7335898876190186,
      "rewards/rejected": -4.190511226654053,
      "step": 4730
    },
    {
      "epoch": 1.4109242446792678,
      "grad_norm": 2.3077304363250732,
      "learning_rate": 5.7958546109942935e-05,
      "logits/chosen": -0.8775187730789185,
      "logits/rejected": -0.9329182505607605,
      "logps/chosen": -189.66073608398438,
      "logps/rejected": -222.52096557617188,
      "loss": 0.3044,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.496289014816284,
      "rewards/margins": 2.106968402862549,
      "rewards/rejected": -4.603257179260254,
      "step": 4740
    },
    {
      "epoch": 1.4139008781068612,
      "grad_norm": 4.297039985656738,
      "learning_rate": 5.791048362871734e-05,
      "logits/chosen": -0.9107218980789185,
      "logits/rejected": -0.9030554890632629,
      "logps/chosen": -195.49118041992188,
      "logps/rejected": -208.7208709716797,
      "loss": 0.5768,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.9662153720855713,
      "rewards/margins": 1.0579332113265991,
      "rewards/rejected": -4.024148464202881,
      "step": 4750
    },
    {
      "epoch": 1.4168775115344545,
      "grad_norm": 5.312601089477539,
      "learning_rate": 5.786242114749175e-05,
      "logits/chosen": -0.807499885559082,
      "logits/rejected": -0.9001014828681946,
      "logps/chosen": -210.25192260742188,
      "logps/rejected": -242.7315673828125,
      "loss": 0.4454,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.3739993572235107,
      "rewards/margins": 1.483750581741333,
      "rewards/rejected": -4.857749938964844,
      "step": 4760
    },
    {
      "epoch": 1.4198541449620479,
      "grad_norm": 7.893896102905273,
      "learning_rate": 5.7814358666266154e-05,
      "logits/chosen": -0.9229485392570496,
      "logits/rejected": -0.9776448011398315,
      "logps/chosen": -200.09286499023438,
      "logps/rejected": -213.5045928955078,
      "loss": 0.4329,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.1216273307800293,
      "rewards/margins": 1.3848748207092285,
      "rewards/rejected": -4.5065016746521,
      "step": 4770
    },
    {
      "epoch": 1.4228307783896414,
      "grad_norm": 3.7713332176208496,
      "learning_rate": 5.776629618504055e-05,
      "logits/chosen": -0.9577873945236206,
      "logits/rejected": -0.9610961675643921,
      "logps/chosen": -194.4258270263672,
      "logps/rejected": -208.5254669189453,
      "loss": 0.458,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.1125998497009277,
      "rewards/margins": 1.1391222476959229,
      "rewards/rejected": -4.25172233581543,
      "step": 4780
    },
    {
      "epoch": 1.4258074118172348,
      "grad_norm": 5.524360656738281,
      "learning_rate": 5.771823370381496e-05,
      "logits/chosen": -0.8090450167655945,
      "logits/rejected": -0.8809741139411926,
      "logps/chosen": -200.3094482421875,
      "logps/rejected": -228.9150390625,
      "loss": 0.5015,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.611940860748291,
      "rewards/margins": 1.3332345485687256,
      "rewards/rejected": -4.9451751708984375,
      "step": 4790
    },
    {
      "epoch": 1.4287840452448282,
      "grad_norm": 2.990266799926758,
      "learning_rate": 5.7670171222589365e-05,
      "logits/chosen": -0.9309023022651672,
      "logits/rejected": -0.9630596041679382,
      "logps/chosen": -208.6964874267578,
      "logps/rejected": -234.8347625732422,
      "loss": 0.3225,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.8223328590393066,
      "rewards/margins": 1.8962618112564087,
      "rewards/rejected": -4.718594551086426,
      "step": 4800
    },
    {
      "epoch": 1.4317606786724215,
      "grad_norm": 2.1097664833068848,
      "learning_rate": 5.762210874136378e-05,
      "logits/chosen": -0.8830984234809875,
      "logits/rejected": -0.9241572618484497,
      "logps/chosen": -213.58590698242188,
      "logps/rejected": -233.57040405273438,
      "loss": 0.3967,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.220909595489502,
      "rewards/margins": 1.510704755783081,
      "rewards/rejected": -4.731614112854004,
      "step": 4810
    },
    {
      "epoch": 1.4347373121000149,
      "grad_norm": 1.798709750175476,
      "learning_rate": 5.7574046260138184e-05,
      "logits/chosen": -0.8995599746704102,
      "logits/rejected": -0.9137633442878723,
      "logps/chosen": -196.34669494628906,
      "logps/rejected": -208.1372833251953,
      "loss": 0.4199,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4240670204162598,
      "rewards/margins": 1.4876800775527954,
      "rewards/rejected": -3.9117469787597656,
      "step": 4820
    },
    {
      "epoch": 1.4377139455276082,
      "grad_norm": 9.396889686584473,
      "learning_rate": 5.752598377891259e-05,
      "logits/chosen": -0.9028457403182983,
      "logits/rejected": -0.9342072606086731,
      "logps/chosen": -209.76220703125,
      "logps/rejected": -230.13992309570312,
      "loss": 0.4218,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.679553508758545,
      "rewards/margins": 1.4846950769424438,
      "rewards/rejected": -4.164248466491699,
      "step": 4830
    },
    {
      "epoch": 1.4406905789552016,
      "grad_norm": 5.002473831176758,
      "learning_rate": 5.7477921297686997e-05,
      "logits/chosen": -0.9539322853088379,
      "logits/rejected": -0.9193570017814636,
      "logps/chosen": -188.50177001953125,
      "logps/rejected": -197.8641815185547,
      "loss": 0.5365,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.879634380340576,
      "rewards/margins": 1.3215745687484741,
      "rewards/rejected": -4.201208591461182,
      "step": 4840
    },
    {
      "epoch": 1.443667212382795,
      "grad_norm": 5.079366207122803,
      "learning_rate": 5.74298588164614e-05,
      "logits/chosen": -0.9382908940315247,
      "logits/rejected": -1.01105797290802,
      "logps/chosen": -198.2783203125,
      "logps/rejected": -230.5859375,
      "loss": 0.551,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -3.3222625255584717,
      "rewards/margins": 1.1695079803466797,
      "rewards/rejected": -4.4917707443237305,
      "step": 4850
    },
    {
      "epoch": 1.4466438458103885,
      "grad_norm": 4.373404502868652,
      "learning_rate": 5.7381796335235816e-05,
      "logits/chosen": -0.9624205827713013,
      "logits/rejected": -1.0203752517700195,
      "logps/chosen": -198.45565795898438,
      "logps/rejected": -226.93701171875,
      "loss": 0.3964,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.0561254024505615,
      "rewards/margins": 1.4440748691558838,
      "rewards/rejected": -4.500199794769287,
      "step": 4860
    },
    {
      "epoch": 1.4496204792379819,
      "grad_norm": 2.7198424339294434,
      "learning_rate": 5.733373385401022e-05,
      "logits/chosen": -0.8963267207145691,
      "logits/rejected": -0.9149236679077148,
      "logps/chosen": -210.66537475585938,
      "logps/rejected": -224.785400390625,
      "loss": 0.4387,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.185062885284424,
      "rewards/margins": 1.5868210792541504,
      "rewards/rejected": -4.771883964538574,
      "step": 4870
    },
    {
      "epoch": 1.4525971126655752,
      "grad_norm": 4.928021430969238,
      "learning_rate": 5.728567137278463e-05,
      "logits/chosen": -1.019352674484253,
      "logits/rejected": -1.0070796012878418,
      "logps/chosen": -200.16983032226562,
      "logps/rejected": -209.01791381835938,
      "loss": 0.4289,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.6851820945739746,
      "rewards/margins": 1.3230810165405273,
      "rewards/rejected": -4.00826358795166,
      "step": 4880
    },
    {
      "epoch": 1.4555737460931686,
      "grad_norm": 8.848699569702148,
      "learning_rate": 5.7237608891559034e-05,
      "logits/chosen": -1.0115236043930054,
      "logits/rejected": -1.015243411064148,
      "logps/chosen": -201.76846313476562,
      "logps/rejected": -209.64382934570312,
      "loss": 0.5145,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.186702013015747,
      "rewards/margins": 1.0820424556732178,
      "rewards/rejected": -3.268744945526123,
      "step": 4890
    },
    {
      "epoch": 1.458550379520762,
      "grad_norm": 7.900387763977051,
      "learning_rate": 5.7189546410333433e-05,
      "logits/chosen": -1.005719780921936,
      "logits/rejected": -1.0058332681655884,
      "logps/chosen": -215.78292846679688,
      "logps/rejected": -222.07040405273438,
      "loss": 0.471,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.2783637046813965,
      "rewards/margins": 1.4575669765472412,
      "rewards/rejected": -4.735930442810059,
      "step": 4900
    },
    {
      "epoch": 1.4615270129483555,
      "grad_norm": 3.032261371612549,
      "learning_rate": 5.714148392910784e-05,
      "logits/chosen": -0.9500843286514282,
      "logits/rejected": -1.0036966800689697,
      "logps/chosen": -196.99685668945312,
      "logps/rejected": -216.9801025390625,
      "loss": 0.4756,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.271395206451416,
      "rewards/margins": 1.102888822555542,
      "rewards/rejected": -4.374283790588379,
      "step": 4910
    },
    {
      "epoch": 1.4645036463759489,
      "grad_norm": 3.994478464126587,
      "learning_rate": 5.7093421447882246e-05,
      "logits/chosen": -1.0310683250427246,
      "logits/rejected": -1.0354691743850708,
      "logps/chosen": -223.4552764892578,
      "logps/rejected": -231.12814331054688,
      "loss": 0.4213,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.4365627765655518,
      "rewards/margins": 1.383922815322876,
      "rewards/rejected": -4.820486068725586,
      "step": 4920
    },
    {
      "epoch": 1.4674802798035422,
      "grad_norm": 5.740405082702637,
      "learning_rate": 5.704535896665666e-05,
      "logits/chosen": -0.9404652714729309,
      "logits/rejected": -1.0340020656585693,
      "logps/chosen": -193.5689239501953,
      "logps/rejected": -234.26766967773438,
      "loss": 0.4456,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.4203274250030518,
      "rewards/margins": 1.4600489139556885,
      "rewards/rejected": -4.880375862121582,
      "step": 4930
    },
    {
      "epoch": 1.4704569132311356,
      "grad_norm": 7.880877494812012,
      "learning_rate": 5.6997296485431065e-05,
      "logits/chosen": -0.9548699259757996,
      "logits/rejected": -0.9768792986869812,
      "logps/chosen": -191.929443359375,
      "logps/rejected": -215.73208618164062,
      "loss": 0.4608,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.942797899246216,
      "rewards/margins": 1.306934118270874,
      "rewards/rejected": -4.24973201751709,
      "step": 4940
    },
    {
      "epoch": 1.473433546658729,
      "grad_norm": 3.2363030910491943,
      "learning_rate": 5.694923400420547e-05,
      "logits/chosen": -1.0339698791503906,
      "logits/rejected": -1.0463539361953735,
      "logps/chosen": -224.9833984375,
      "logps/rejected": -238.5490264892578,
      "loss": 0.3889,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.4205894470214844,
      "rewards/margins": 1.5515336990356445,
      "rewards/rejected": -4.972122669219971,
      "step": 4950
    },
    {
      "epoch": 1.4764101800863223,
      "grad_norm": 2.337804079055786,
      "learning_rate": 5.690117152297988e-05,
      "logits/chosen": -0.9667177200317383,
      "logits/rejected": -0.9505282640457153,
      "logps/chosen": -197.33026123046875,
      "logps/rejected": -207.1222381591797,
      "loss": 0.4497,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.747840642929077,
      "rewards/margins": 1.2195110321044922,
      "rewards/rejected": -3.9673514366149902,
      "step": 4960
    },
    {
      "epoch": 1.4793868135139157,
      "grad_norm": 4.889899730682373,
      "learning_rate": 5.685310904175428e-05,
      "logits/chosen": -0.9594646692276001,
      "logits/rejected": -0.9587761163711548,
      "logps/chosen": -226.89236450195312,
      "logps/rejected": -247.84811401367188,
      "loss": 0.4361,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.026660919189453,
      "rewards/margins": 1.4423015117645264,
      "rewards/rejected": -4.468962669372559,
      "step": 4970
    },
    {
      "epoch": 1.4823634469415092,
      "grad_norm": 4.70704460144043,
      "learning_rate": 5.6805046560528696e-05,
      "logits/chosen": -0.9304086565971375,
      "logits/rejected": -0.957714855670929,
      "logps/chosen": -196.62869262695312,
      "logps/rejected": -233.4872283935547,
      "loss": 0.4374,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.69791316986084,
      "rewards/margins": 1.7208753824234009,
      "rewards/rejected": -4.418788433074951,
      "step": 4980
    },
    {
      "epoch": 1.4853400803691026,
      "grad_norm": 6.135955810546875,
      "learning_rate": 5.67569840793031e-05,
      "logits/chosen": -1.0017551183700562,
      "logits/rejected": -1.0077579021453857,
      "logps/chosen": -212.47756958007812,
      "logps/rejected": -227.33340454101562,
      "loss": 0.3811,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.0424928665161133,
      "rewards/margins": 1.6985328197479248,
      "rewards/rejected": -4.741025447845459,
      "step": 4990
    },
    {
      "epoch": 1.488316713796696,
      "grad_norm": 3.5043628215789795,
      "learning_rate": 5.670892159807751e-05,
      "logits/chosen": -0.9721168279647827,
      "logits/rejected": -1.0497957468032837,
      "logps/chosen": -193.81776428222656,
      "logps/rejected": -226.43603515625,
      "loss": 0.438,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.3732688426971436,
      "rewards/margins": 1.6750034093856812,
      "rewards/rejected": -5.048272132873535,
      "step": 5000
    },
    {
      "epoch": 1.4912933472242893,
      "grad_norm": 4.911879062652588,
      "learning_rate": 5.6660859116851915e-05,
      "logits/chosen": -0.9709256291389465,
      "logits/rejected": -1.0464409589767456,
      "logps/chosen": -193.754638671875,
      "logps/rejected": -227.7522430419922,
      "loss": 0.4528,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.5412020683288574,
      "rewards/margins": 1.5460503101348877,
      "rewards/rejected": -5.087252616882324,
      "step": 5010
    },
    {
      "epoch": 1.4942699806518827,
      "grad_norm": 5.821148872375488,
      "learning_rate": 5.6612796635626314e-05,
      "logits/chosen": -0.9797137975692749,
      "logits/rejected": -0.9859535098075867,
      "logps/chosen": -205.53439331054688,
      "logps/rejected": -226.2725067138672,
      "loss": 0.2945,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.2128822803497314,
      "rewards/margins": 2.0609207153320312,
      "rewards/rejected": -5.273803234100342,
      "step": 5020
    },
    {
      "epoch": 1.4972466140794762,
      "grad_norm": 6.671750545501709,
      "learning_rate": 5.656473415440072e-05,
      "logits/chosen": -0.9043645858764648,
      "logits/rejected": -0.9741827249526978,
      "logps/chosen": -194.54690551757812,
      "logps/rejected": -219.57339477539062,
      "loss": 0.4633,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.349910259246826,
      "rewards/margins": 1.4379510879516602,
      "rewards/rejected": -4.7878618240356445,
      "step": 5030
    },
    {
      "epoch": 1.5002232475070696,
      "grad_norm": 4.243459701538086,
      "learning_rate": 5.651667167317513e-05,
      "logits/chosen": -0.8722008466720581,
      "logits/rejected": -0.9732156991958618,
      "logps/chosen": -187.4794921875,
      "logps/rejected": -225.3052215576172,
      "loss": 0.4195,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.798820972442627,
      "rewards/margins": 1.5595571994781494,
      "rewards/rejected": -4.358377933502197,
      "step": 5040
    },
    {
      "epoch": 1.503199880934663,
      "grad_norm": 2.6234517097473145,
      "learning_rate": 5.646860919194954e-05,
      "logits/chosen": -0.9008989334106445,
      "logits/rejected": -0.9332183003425598,
      "logps/chosen": -195.8497314453125,
      "logps/rejected": -228.30221557617188,
      "loss": 0.3626,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.6345038414001465,
      "rewards/margins": 1.870618462562561,
      "rewards/rejected": -4.505122184753418,
      "step": 5050
    },
    {
      "epoch": 1.5061765143622563,
      "grad_norm": 1.883670687675476,
      "learning_rate": 5.6420546710723945e-05,
      "logits/chosen": -0.8761148452758789,
      "logits/rejected": -0.911742091178894,
      "logps/chosen": -207.63272094726562,
      "logps/rejected": -239.9979705810547,
      "loss": 0.3365,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.0582504272460938,
      "rewards/margins": 1.9206266403198242,
      "rewards/rejected": -4.978877067565918,
      "step": 5060
    },
    {
      "epoch": 1.5091531477898497,
      "grad_norm": 6.094402313232422,
      "learning_rate": 5.637248422949835e-05,
      "logits/chosen": -0.8783837556838989,
      "logits/rejected": -0.8558171987533569,
      "logps/chosen": -209.0671844482422,
      "logps/rejected": -223.6459503173828,
      "loss": 0.5808,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -3.4947593212127686,
      "rewards/margins": 1.2566430568695068,
      "rewards/rejected": -4.751402378082275,
      "step": 5070
    },
    {
      "epoch": 1.512129781217443,
      "grad_norm": 3.8614206314086914,
      "learning_rate": 5.632442174827276e-05,
      "logits/chosen": -0.8534156680107117,
      "logits/rejected": -0.8685600161552429,
      "logps/chosen": -194.89901733398438,
      "logps/rejected": -218.77035522460938,
      "loss": 0.4113,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.352185010910034,
      "rewards/margins": 1.5286155939102173,
      "rewards/rejected": -3.880800724029541,
      "step": 5080
    },
    {
      "epoch": 1.5151064146450364,
      "grad_norm": 5.846047878265381,
      "learning_rate": 5.6276359267047164e-05,
      "logits/chosen": -0.9145218133926392,
      "logits/rejected": -0.9393417239189148,
      "logps/chosen": -191.75070190429688,
      "logps/rejected": -201.42221069335938,
      "loss": 0.4967,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.6172196865081787,
      "rewards/margins": 1.1140367984771729,
      "rewards/rejected": -3.7312569618225098,
      "step": 5090
    },
    {
      "epoch": 1.5180830480726297,
      "grad_norm": 3.5059874057769775,
      "learning_rate": 5.622829678582158e-05,
      "logits/chosen": -0.9496046304702759,
      "logits/rejected": -0.9837759137153625,
      "logps/chosen": -205.3748321533203,
      "logps/rejected": -223.64077758789062,
      "loss": 0.5172,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.9893548488616943,
      "rewards/margins": 1.3031169176101685,
      "rewards/rejected": -4.292471408843994,
      "step": 5100
    },
    {
      "epoch": 1.521059681500223,
      "grad_norm": 7.008663654327393,
      "learning_rate": 5.618023430459598e-05,
      "logits/chosen": -0.9956260919570923,
      "logits/rejected": -1.0629651546478271,
      "logps/chosen": -200.6551971435547,
      "logps/rejected": -232.53872680664062,
      "loss": 0.3964,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.903406858444214,
      "rewards/margins": 1.4038002490997314,
      "rewards/rejected": -4.307207107543945,
      "step": 5110
    },
    {
      "epoch": 1.5240363149278167,
      "grad_norm": 2.0257527828216553,
      "learning_rate": 5.613217182337039e-05,
      "logits/chosen": -0.9709954261779785,
      "logits/rejected": -1.0021347999572754,
      "logps/chosen": -207.2604217529297,
      "logps/rejected": -235.70034790039062,
      "loss": 0.3862,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.6029083728790283,
      "rewards/margins": 1.4001858234405518,
      "rewards/rejected": -5.003093719482422,
      "step": 5120
    },
    {
      "epoch": 1.52701294835541,
      "grad_norm": 4.199748992919922,
      "learning_rate": 5.6084109342144795e-05,
      "logits/chosen": -0.9565631747245789,
      "logits/rejected": -1.0135843753814697,
      "logps/chosen": -191.68240356445312,
      "logps/rejected": -217.5769805908203,
      "loss": 0.4534,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.999891757965088,
      "rewards/margins": 1.3661941289901733,
      "rewards/rejected": -4.366086006164551,
      "step": 5130
    },
    {
      "epoch": 1.5299895817830034,
      "grad_norm": 6.140199661254883,
      "learning_rate": 5.6036046860919195e-05,
      "logits/chosen": -1.0390138626098633,
      "logits/rejected": -1.0524580478668213,
      "logps/chosen": -211.5072784423828,
      "logps/rejected": -229.6161346435547,
      "loss": 0.6084,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -3.694049835205078,
      "rewards/margins": 0.9461256861686707,
      "rewards/rejected": -4.6401753425598145,
      "step": 5140
    },
    {
      "epoch": 1.532966215210597,
      "grad_norm": 6.841315269470215,
      "learning_rate": 5.59879843796936e-05,
      "logits/chosen": -0.9494512677192688,
      "logits/rejected": -1.0126056671142578,
      "logps/chosen": -186.88499450683594,
      "logps/rejected": -221.4099578857422,
      "loss": 0.3792,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.7837603092193604,
      "rewards/margins": 1.8244463205337524,
      "rewards/rejected": -4.608206272125244,
      "step": 5150
    },
    {
      "epoch": 1.5359428486381903,
      "grad_norm": 10.043990135192871,
      "learning_rate": 5.5939921898468014e-05,
      "logits/chosen": -1.0098780393600464,
      "logits/rejected": -1.166503667831421,
      "logps/chosen": -191.92947387695312,
      "logps/rejected": -233.37509155273438,
      "loss": 0.4148,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.175981044769287,
      "rewards/margins": 1.5468995571136475,
      "rewards/rejected": -4.722879886627197,
      "step": 5160
    },
    {
      "epoch": 1.5389194820657837,
      "grad_norm": 7.176795959472656,
      "learning_rate": 5.589185941724242e-05,
      "logits/chosen": -1.045175313949585,
      "logits/rejected": -1.1026842594146729,
      "logps/chosen": -192.79513549804688,
      "logps/rejected": -217.98770141601562,
      "loss": 0.4209,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.0580623149871826,
      "rewards/margins": 1.55299973487854,
      "rewards/rejected": -4.611062049865723,
      "step": 5170
    },
    {
      "epoch": 1.541896115493377,
      "grad_norm": 3.8319714069366455,
      "learning_rate": 5.5843796936016826e-05,
      "logits/chosen": -1.0736761093139648,
      "logits/rejected": -1.0699822902679443,
      "logps/chosen": -217.8979949951172,
      "logps/rejected": -227.84506225585938,
      "loss": 0.4468,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.4830374717712402,
      "rewards/margins": 1.7628463506698608,
      "rewards/rejected": -4.245883464813232,
      "step": 5180
    },
    {
      "epoch": 1.5448727489209704,
      "grad_norm": 2.6051509380340576,
      "learning_rate": 5.579573445479123e-05,
      "logits/chosen": -0.9850679636001587,
      "logits/rejected": -0.9949724078178406,
      "logps/chosen": -183.2908477783203,
      "logps/rejected": -198.90794372558594,
      "loss": 0.5001,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.720701217651367,
      "rewards/margins": 1.1140518188476562,
      "rewards/rejected": -3.8347530364990234,
      "step": 5190
    },
    {
      "epoch": 1.5478493823485637,
      "grad_norm": 6.044902801513672,
      "learning_rate": 5.574767197356564e-05,
      "logits/chosen": -0.9894511103630066,
      "logits/rejected": -1.0372514724731445,
      "logps/chosen": -195.44442749023438,
      "logps/rejected": -219.22091674804688,
      "loss": 0.4422,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.256938934326172,
      "rewards/margins": 1.4131735563278198,
      "rewards/rejected": -4.6701130867004395,
      "step": 5200
    },
    {
      "epoch": 1.550826015776157,
      "grad_norm": 5.17512321472168,
      "learning_rate": 5.5699609492340044e-05,
      "logits/chosen": -1.0177332162857056,
      "logits/rejected": -1.072649359703064,
      "logps/chosen": -199.11181640625,
      "logps/rejected": -223.7585906982422,
      "loss": 0.4095,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.805271625518799,
      "rewards/margins": 1.5798726081848145,
      "rewards/rejected": -4.385144233703613,
      "step": 5210
    },
    {
      "epoch": 1.5538026492037504,
      "grad_norm": 6.593147277832031,
      "learning_rate": 5.565154701111446e-05,
      "logits/chosen": -0.9780895113945007,
      "logits/rejected": -0.945918083190918,
      "logps/chosen": -216.9557647705078,
      "logps/rejected": -218.5076904296875,
      "loss": 0.442,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.462594509124756,
      "rewards/margins": 1.2805482149124146,
      "rewards/rejected": -3.743142604827881,
      "step": 5220
    },
    {
      "epoch": 1.5567792826313438,
      "grad_norm": 6.058053016662598,
      "learning_rate": 5.5603484529888863e-05,
      "logits/chosen": -0.923748791217804,
      "logits/rejected": -1.003584623336792,
      "logps/chosen": -192.8673553466797,
      "logps/rejected": -236.26065063476562,
      "loss": 0.3584,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.071664333343506,
      "rewards/margins": 2.1405985355377197,
      "rewards/rejected": -5.212262153625488,
      "step": 5230
    },
    {
      "epoch": 1.5597559160589374,
      "grad_norm": 11.337929725646973,
      "learning_rate": 5.555542204866327e-05,
      "logits/chosen": -0.904238224029541,
      "logits/rejected": -0.9275946617126465,
      "logps/chosen": -209.64535522460938,
      "logps/rejected": -229.1185760498047,
      "loss": 0.4753,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.64977765083313,
      "rewards/margins": 1.616032600402832,
      "rewards/rejected": -5.265810489654541,
      "step": 5240
    },
    {
      "epoch": 1.5627325494865307,
      "grad_norm": 11.37490463256836,
      "learning_rate": 5.5507359567437676e-05,
      "logits/chosen": -0.9953893423080444,
      "logits/rejected": -1.0398727655410767,
      "logps/chosen": -211.97183227539062,
      "logps/rejected": -244.3013458251953,
      "loss": 0.4879,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -4.062257289886475,
      "rewards/margins": 1.5768921375274658,
      "rewards/rejected": -5.639149188995361,
      "step": 5250
    },
    {
      "epoch": 1.565709182914124,
      "grad_norm": 4.41043758392334,
      "learning_rate": 5.5459297086212075e-05,
      "logits/chosen": -0.9884011149406433,
      "logits/rejected": -1.116702914237976,
      "logps/chosen": -208.0368194580078,
      "logps/rejected": -250.9564666748047,
      "loss": 0.4191,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.8732171058654785,
      "rewards/margins": 1.6150264739990234,
      "rewards/rejected": -5.488243103027344,
      "step": 5260
    },
    {
      "epoch": 1.5686858163417177,
      "grad_norm": 4.738279342651367,
      "learning_rate": 5.541123460498648e-05,
      "logits/chosen": -1.0212799310684204,
      "logits/rejected": -1.1065995693206787,
      "logps/chosen": -196.21751403808594,
      "logps/rejected": -231.97341918945312,
      "loss": 0.467,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.8427956104278564,
      "rewards/margins": 1.4495258331298828,
      "rewards/rejected": -5.29232120513916,
      "step": 5270
    },
    {
      "epoch": 1.571662449769311,
      "grad_norm": 2.3907742500305176,
      "learning_rate": 5.5363172123760894e-05,
      "logits/chosen": -1.0190397500991821,
      "logits/rejected": -1.0062981843948364,
      "logps/chosen": -215.7598876953125,
      "logps/rejected": -232.3708038330078,
      "loss": 0.4601,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -4.132951736450195,
      "rewards/margins": 1.3140004873275757,
      "rewards/rejected": -5.4469523429870605,
      "step": 5280
    },
    {
      "epoch": 1.5746390831969044,
      "grad_norm": 3.924905300140381,
      "learning_rate": 5.53151096425353e-05,
      "logits/chosen": -1.0301024913787842,
      "logits/rejected": -1.0302258729934692,
      "logps/chosen": -216.0699005126953,
      "logps/rejected": -220.72509765625,
      "loss": 0.457,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.3618862628936768,
      "rewards/margins": 1.201361060142517,
      "rewards/rejected": -4.563247203826904,
      "step": 5290
    },
    {
      "epoch": 1.5776157166244977,
      "grad_norm": 2.226172685623169,
      "learning_rate": 5.5267047161309706e-05,
      "logits/chosen": -0.9796608090400696,
      "logits/rejected": -1.0104631185531616,
      "logps/chosen": -193.63113403320312,
      "logps/rejected": -224.62838745117188,
      "loss": 0.3976,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.329681873321533,
      "rewards/margins": 1.4432423114776611,
      "rewards/rejected": -3.7729239463806152,
      "step": 5300
    },
    {
      "epoch": 1.580592350052091,
      "grad_norm": 3.4793403148651123,
      "learning_rate": 5.521898468008411e-05,
      "logits/chosen": -1.057162880897522,
      "logits/rejected": -1.0538350343704224,
      "logps/chosen": -204.69729614257812,
      "logps/rejected": -216.7999725341797,
      "loss": 0.4668,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.1324071884155273,
      "rewards/margins": 1.2202024459838867,
      "rewards/rejected": -4.352609157562256,
      "step": 5310
    },
    {
      "epoch": 1.5835689834796844,
      "grad_norm": 4.550724029541016,
      "learning_rate": 5.517092219885852e-05,
      "logits/chosen": -0.9617779850959778,
      "logits/rejected": -1.0138715505599976,
      "logps/chosen": -205.5327911376953,
      "logps/rejected": -224.54824829101562,
      "loss": 0.5001,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.125656843185425,
      "rewards/margins": 1.2236945629119873,
      "rewards/rejected": -4.349351406097412,
      "step": 5320
    },
    {
      "epoch": 1.5865456169072778,
      "grad_norm": 8.320362091064453,
      "learning_rate": 5.512285971763293e-05,
      "logits/chosen": -1.0373210906982422,
      "logits/rejected": -1.0260610580444336,
      "logps/chosen": -230.744873046875,
      "logps/rejected": -235.5072021484375,
      "loss": 0.4947,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.949697971343994,
      "rewards/margins": 1.17195463180542,
      "rewards/rejected": -4.121653079986572,
      "step": 5330
    },
    {
      "epoch": 1.5895222503348712,
      "grad_norm": 5.8316121101379395,
      "learning_rate": 5.507479723640734e-05,
      "logits/chosen": -0.9730648994445801,
      "logits/rejected": -0.9935421943664551,
      "logps/chosen": -184.39077758789062,
      "logps/rejected": -207.54623413085938,
      "loss": 0.4033,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.1856470108032227,
      "rewards/margins": 1.3959580659866333,
      "rewards/rejected": -3.5816047191619873,
      "step": 5340
    },
    {
      "epoch": 1.5924988837624645,
      "grad_norm": 7.285313129425049,
      "learning_rate": 5.5026734755181744e-05,
      "logits/chosen": -1.0485827922821045,
      "logits/rejected": -1.0158042907714844,
      "logps/chosen": -199.7417755126953,
      "logps/rejected": -216.4994354248047,
      "loss": 0.3284,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.7782320976257324,
      "rewards/margins": 1.8140223026275635,
      "rewards/rejected": -4.592254638671875,
      "step": 5350
    },
    {
      "epoch": 1.595475517190058,
      "grad_norm": 12.725835800170898,
      "learning_rate": 5.497867227395615e-05,
      "logits/chosen": -0.9215947389602661,
      "logits/rejected": -0.9685147404670715,
      "logps/chosen": -188.46597290039062,
      "logps/rejected": -216.0271453857422,
      "loss": 0.4321,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.87819242477417,
      "rewards/margins": 1.5552418231964111,
      "rewards/rejected": -4.43343448638916,
      "step": 5360
    },
    {
      "epoch": 1.5984521506176514,
      "grad_norm": 3.6748287677764893,
      "learning_rate": 5.4930609792730556e-05,
      "logits/chosen": -0.9944755434989929,
      "logits/rejected": -1.0248310565948486,
      "logps/chosen": -197.08297729492188,
      "logps/rejected": -229.3994140625,
      "loss": 0.4463,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.092561721801758,
      "rewards/margins": 1.768694519996643,
      "rewards/rejected": -4.861256122589111,
      "step": 5370
    },
    {
      "epoch": 1.6014287840452448,
      "grad_norm": 2.747251272201538,
      "learning_rate": 5.4882547311504956e-05,
      "logits/chosen": -0.9337876439094543,
      "logits/rejected": -1.045973539352417,
      "logps/chosen": -190.56723022460938,
      "logps/rejected": -248.780517578125,
      "loss": 0.2975,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.4778366088867188,
      "rewards/margins": 2.223036766052246,
      "rewards/rejected": -5.700873374938965,
      "step": 5380
    },
    {
      "epoch": 1.6044054174728384,
      "grad_norm": 3.7514073848724365,
      "learning_rate": 5.483448483027936e-05,
      "logits/chosen": -1.0465519428253174,
      "logits/rejected": -1.1086434125900269,
      "logps/chosen": -194.05418395996094,
      "logps/rejected": -215.5829315185547,
      "loss": 0.4417,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.7335987091064453,
      "rewards/margins": 1.1869783401489258,
      "rewards/rejected": -4.920576572418213,
      "step": 5390
    },
    {
      "epoch": 1.6073820509004317,
      "grad_norm": 8.406216621398926,
      "learning_rate": 5.4786422349053775e-05,
      "logits/chosen": -0.9542183876037598,
      "logits/rejected": -0.9681878089904785,
      "logps/chosen": -212.9798583984375,
      "logps/rejected": -238.5550537109375,
      "loss": 0.4272,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.8251583576202393,
      "rewards/margins": 1.554360270500183,
      "rewards/rejected": -5.379518985748291,
      "step": 5400
    },
    {
      "epoch": 1.610358684328025,
      "grad_norm": 6.16771125793457,
      "learning_rate": 5.473835986782818e-05,
      "logits/chosen": -0.9089294672012329,
      "logits/rejected": -0.9319337010383606,
      "logps/chosen": -220.83706665039062,
      "logps/rejected": -256.79443359375,
      "loss": 0.4445,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.4668407440185547,
      "rewards/margins": 1.6580028533935547,
      "rewards/rejected": -5.124844074249268,
      "step": 5410
    },
    {
      "epoch": 1.6133353177556184,
      "grad_norm": 4.97233772277832,
      "learning_rate": 5.469029738660259e-05,
      "logits/chosen": -1.002076506614685,
      "logits/rejected": -1.1316410303115845,
      "logps/chosen": -198.37673950195312,
      "logps/rejected": -254.9080810546875,
      "loss": 0.4606,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.5831387042999268,
      "rewards/margins": 1.6463695764541626,
      "rewards/rejected": -5.229508399963379,
      "step": 5420
    },
    {
      "epoch": 1.6163119511832118,
      "grad_norm": 7.339156150817871,
      "learning_rate": 5.464223490537699e-05,
      "logits/chosen": -1.0000779628753662,
      "logits/rejected": -1.0061089992523193,
      "logps/chosen": -201.28314208984375,
      "logps/rejected": -219.78793334960938,
      "loss": 0.397,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.982511043548584,
      "rewards/margins": 1.6432183980941772,
      "rewards/rejected": -4.625729560852051,
      "step": 5430
    },
    {
      "epoch": 1.6192885846108052,
      "grad_norm": 2.4347805976867676,
      "learning_rate": 5.45941724241514e-05,
      "logits/chosen": -1.0024744272232056,
      "logits/rejected": -1.0260539054870605,
      "logps/chosen": -213.96090698242188,
      "logps/rejected": -239.5052490234375,
      "loss": 0.3985,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.8013312816619873,
      "rewards/margins": 1.8213437795639038,
      "rewards/rejected": -5.62267541885376,
      "step": 5440
    },
    {
      "epoch": 1.6222652180383985,
      "grad_norm": 6.184134006500244,
      "learning_rate": 5.454610994292581e-05,
      "logits/chosen": -1.0620360374450684,
      "logits/rejected": -1.1702615022659302,
      "logps/chosen": -193.7169189453125,
      "logps/rejected": -236.689453125,
      "loss": 0.3405,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.8368594646453857,
      "rewards/margins": 2.0325043201446533,
      "rewards/rejected": -5.869363784790039,
      "step": 5450
    },
    {
      "epoch": 1.6252418514659919,
      "grad_norm": 6.507039546966553,
      "learning_rate": 5.450285370982277e-05,
      "logits/chosen": -1.0400217771530151,
      "logits/rejected": -1.0951257944107056,
      "logps/chosen": -230.4798583984375,
      "logps/rejected": -255.2401885986328,
      "loss": 0.5719,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -5.108774662017822,
      "rewards/margins": 1.1225908994674683,
      "rewards/rejected": -6.231365203857422,
      "step": 5460
    },
    {
      "epoch": 1.6282184848935852,
      "grad_norm": 8.65950870513916,
      "learning_rate": 5.445479122859718e-05,
      "logits/chosen": -1.07323157787323,
      "logits/rejected": -1.0328730344772339,
      "logps/chosen": -229.60519409179688,
      "logps/rejected": -225.9145965576172,
      "loss": 0.4946,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.472362995147705,
      "rewards/margins": 1.4119151830673218,
      "rewards/rejected": -4.884278297424316,
      "step": 5470
    },
    {
      "epoch": 1.6311951183211786,
      "grad_norm": 7.170077323913574,
      "learning_rate": 5.440672874737159e-05,
      "logits/chosen": -1.0566126108169556,
      "logits/rejected": -1.0210535526275635,
      "logps/chosen": -229.29150390625,
      "logps/rejected": -249.99984741210938,
      "loss": 0.3819,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -4.497259140014648,
      "rewards/margins": 1.7702716588974,
      "rewards/rejected": -6.267530918121338,
      "step": 5480
    },
    {
      "epoch": 1.6341717517487722,
      "grad_norm": 8.054693222045898,
      "learning_rate": 5.4358666266146e-05,
      "logits/chosen": -1.0858192443847656,
      "logits/rejected": -1.120755910873413,
      "logps/chosen": -224.2169647216797,
      "logps/rejected": -253.81149291992188,
      "loss": 0.3684,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -4.255335807800293,
      "rewards/margins": 2.104434013366699,
      "rewards/rejected": -6.359769344329834,
      "step": 5490
    },
    {
      "epoch": 1.6371483851763655,
      "grad_norm": 5.543079376220703,
      "learning_rate": 5.4310603784920404e-05,
      "logits/chosen": -1.0365444421768188,
      "logits/rejected": -1.070999264717102,
      "logps/chosen": -220.93875122070312,
      "logps/rejected": -249.5534210205078,
      "loss": 0.5133,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -4.255246162414551,
      "rewards/margins": 1.4996881484985352,
      "rewards/rejected": -5.754934787750244,
      "step": 5500
    },
    {
      "epoch": 1.6401250186039589,
      "grad_norm": 10.662075996398926,
      "learning_rate": 5.426254130369481e-05,
      "logits/chosen": -1.099228024482727,
      "logits/rejected": -1.16695237159729,
      "logps/chosen": -210.30526733398438,
      "logps/rejected": -245.0768585205078,
      "loss": 0.4132,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -4.174276828765869,
      "rewards/margins": 1.7928855419158936,
      "rewards/rejected": -5.967162132263184,
      "step": 5510
    },
    {
      "epoch": 1.6431016520315525,
      "grad_norm": 9.965685844421387,
      "learning_rate": 5.4214478822469216e-05,
      "logits/chosen": -1.108957052230835,
      "logits/rejected": -1.1433972120285034,
      "logps/chosen": -232.1116943359375,
      "logps/rejected": -241.79177856445312,
      "loss": 0.5077,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -4.363067626953125,
      "rewards/margins": 1.3004497289657593,
      "rewards/rejected": -5.663516998291016,
      "step": 5520
    },
    {
      "epoch": 1.6460782854591458,
      "grad_norm": 4.426425457000732,
      "learning_rate": 5.4166416341243615e-05,
      "logits/chosen": -1.0163496732711792,
      "logits/rejected": -1.081878423690796,
      "logps/chosen": -199.06979370117188,
      "logps/rejected": -221.86593627929688,
      "loss": 0.4924,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -4.038823127746582,
      "rewards/margins": 1.243221640586853,
      "rewards/rejected": -5.282044410705566,
      "step": 5530
    },
    {
      "epoch": 1.6490549188867392,
      "grad_norm": 4.239009857177734,
      "learning_rate": 5.411835386001802e-05,
      "logits/chosen": -0.9919536709785461,
      "logits/rejected": -1.0670533180236816,
      "logps/chosen": -203.86917114257812,
      "logps/rejected": -230.21829223632812,
      "loss": 0.4419,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.0923361778259277,
      "rewards/margins": 1.4267200231552124,
      "rewards/rejected": -4.51905632019043,
      "step": 5540
    },
    {
      "epoch": 1.6520315523143325,
      "grad_norm": 8.768318176269531,
      "learning_rate": 5.4070291378792434e-05,
      "logits/chosen": -1.0373218059539795,
      "logits/rejected": -1.080418348312378,
      "logps/chosen": -191.7731475830078,
      "logps/rejected": -221.8361358642578,
      "loss": 0.4843,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.6600775718688965,
      "rewards/margins": 1.3991731405258179,
      "rewards/rejected": -4.059250831604004,
      "step": 5550
    },
    {
      "epoch": 1.6550081857419259,
      "grad_norm": 5.21821928024292,
      "learning_rate": 5.402222889756684e-05,
      "logits/chosen": -0.9546284675598145,
      "logits/rejected": -1.001971960067749,
      "logps/chosen": -197.5320281982422,
      "logps/rejected": -232.1413116455078,
      "loss": 0.3683,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.6137588024139404,
      "rewards/margins": 1.8285939693450928,
      "rewards/rejected": -5.44235372543335,
      "step": 5560
    },
    {
      "epoch": 1.6579848191695192,
      "grad_norm": 9.991103172302246,
      "learning_rate": 5.397416641634125e-05,
      "logits/chosen": -1.1243380308151245,
      "logits/rejected": -1.127625823020935,
      "logps/chosen": -202.75177001953125,
      "logps/rejected": -224.3834991455078,
      "loss": 0.4488,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.3355002403259277,
      "rewards/margins": 1.3330137729644775,
      "rewards/rejected": -4.668514251708984,
      "step": 5570
    },
    {
      "epoch": 1.6609614525971126,
      "grad_norm": 5.090268135070801,
      "learning_rate": 5.392610393511565e-05,
      "logits/chosen": -1.0282742977142334,
      "logits/rejected": -1.0654643774032593,
      "logps/chosen": -197.31869506835938,
      "logps/rejected": -222.1250762939453,
      "loss": 0.3996,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.828064203262329,
      "rewards/margins": 1.467038869857788,
      "rewards/rejected": -4.295103073120117,
      "step": 5580
    },
    {
      "epoch": 1.663938086024706,
      "grad_norm": 2.994206666946411,
      "learning_rate": 5.387804145389006e-05,
      "logits/chosen": -1.0690009593963623,
      "logits/rejected": -1.0794963836669922,
      "logps/chosen": -198.40164184570312,
      "logps/rejected": -214.65982055664062,
      "loss": 0.5138,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -3.4178829193115234,
      "rewards/margins": 1.1750959157943726,
      "rewards/rejected": -4.592978477478027,
      "step": 5590
    },
    {
      "epoch": 1.6669147194522993,
      "grad_norm": 4.355796813964844,
      "learning_rate": 5.382997897266447e-05,
      "logits/chosen": -1.0051286220550537,
      "logits/rejected": -1.0022557973861694,
      "logps/chosen": -207.3846435546875,
      "logps/rejected": -222.59628295898438,
      "loss": 0.4505,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.825687885284424,
      "rewards/margins": 1.4571969509124756,
      "rewards/rejected": -4.2828850746154785,
      "step": 5600
    },
    {
      "epoch": 1.6698913528798929,
      "grad_norm": 4.500482559204102,
      "learning_rate": 5.378191649143888e-05,
      "logits/chosen": -1.0311599969863892,
      "logits/rejected": -1.0487698316574097,
      "logps/chosen": -190.43690490722656,
      "logps/rejected": -211.47219848632812,
      "loss": 0.3869,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.3908095359802246,
      "rewards/margins": 1.5130078792572021,
      "rewards/rejected": -3.9038169384002686,
      "step": 5610
    },
    {
      "epoch": 1.6728679863074862,
      "grad_norm": 7.5249152183532715,
      "learning_rate": 5.3733854010213284e-05,
      "logits/chosen": -1.0044052600860596,
      "logits/rejected": -1.056073546409607,
      "logps/chosen": -205.74154663085938,
      "logps/rejected": -236.50369262695312,
      "loss": 0.4458,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.479480266571045,
      "rewards/margins": 1.8479890823364258,
      "rewards/rejected": -5.327469348907471,
      "step": 5620
    },
    {
      "epoch": 1.6758446197350796,
      "grad_norm": 6.8370232582092285,
      "learning_rate": 5.368579152898769e-05,
      "logits/chosen": -1.0158199071884155,
      "logits/rejected": -1.0346311330795288,
      "logps/chosen": -218.08847045898438,
      "logps/rejected": -227.21609497070312,
      "loss": 0.4383,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.338697910308838,
      "rewards/margins": 1.4342710971832275,
      "rewards/rejected": -4.772968769073486,
      "step": 5630
    },
    {
      "epoch": 1.6788212531626732,
      "grad_norm": 5.605362415313721,
      "learning_rate": 5.3637729047762097e-05,
      "logits/chosen": -0.8887430429458618,
      "logits/rejected": -0.9251028895378113,
      "logps/chosen": -219.91995239257812,
      "logps/rejected": -237.14981079101562,
      "loss": 0.4447,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.346134901046753,
      "rewards/margins": 1.3554563522338867,
      "rewards/rejected": -4.701590538024902,
      "step": 5640
    },
    {
      "epoch": 1.6817978865902665,
      "grad_norm": 6.1348419189453125,
      "learning_rate": 5.3589666566536496e-05,
      "logits/chosen": -0.8805974125862122,
      "logits/rejected": -0.8732854723930359,
      "logps/chosen": -203.67007446289062,
      "logps/rejected": -230.24365234375,
      "loss": 0.5081,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.407158613204956,
      "rewards/margins": 1.3852226734161377,
      "rewards/rejected": -4.792381286621094,
      "step": 5650
    },
    {
      "epoch": 1.6847745200178599,
      "grad_norm": 3.211785078048706,
      "learning_rate": 5.35416040853109e-05,
      "logits/chosen": -0.8817955255508423,
      "logits/rejected": -0.9297847747802734,
      "logps/chosen": -204.51759338378906,
      "logps/rejected": -228.2462615966797,
      "loss": 0.4178,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.7329907417297363,
      "rewards/margins": 1.3879337310791016,
      "rewards/rejected": -5.120924949645996,
      "step": 5660
    },
    {
      "epoch": 1.6877511534454532,
      "grad_norm": 1.968674898147583,
      "learning_rate": 5.3493541604085315e-05,
      "logits/chosen": -0.8578993082046509,
      "logits/rejected": -0.9055814743041992,
      "logps/chosen": -207.2769012451172,
      "logps/rejected": -236.964111328125,
      "loss": 0.4136,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.6374897956848145,
      "rewards/margins": 1.713456392288208,
      "rewards/rejected": -5.350945949554443,
      "step": 5670
    },
    {
      "epoch": 1.6907277868730466,
      "grad_norm": 5.39876127243042,
      "learning_rate": 5.344547912285972e-05,
      "logits/chosen": -0.9565936923027039,
      "logits/rejected": -0.9975290298461914,
      "logps/chosen": -218.45486450195312,
      "logps/rejected": -245.2130584716797,
      "loss": 0.3909,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.467186689376831,
      "rewards/margins": 1.6811769008636475,
      "rewards/rejected": -5.148364067077637,
      "step": 5680
    },
    {
      "epoch": 1.69370442030064,
      "grad_norm": 2.096959114074707,
      "learning_rate": 5.339741664163413e-05,
      "logits/chosen": -0.9479848146438599,
      "logits/rejected": -1.012086272239685,
      "logps/chosen": -208.97695922851562,
      "logps/rejected": -226.1244354248047,
      "loss": 0.3933,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.1887123584747314,
      "rewards/margins": 1.6212913990020752,
      "rewards/rejected": -4.810003757476807,
      "step": 5690
    },
    {
      "epoch": 1.6966810537282333,
      "grad_norm": 6.066664218902588,
      "learning_rate": 5.3349354160408533e-05,
      "logits/chosen": -0.9650271534919739,
      "logits/rejected": -1.05698561668396,
      "logps/chosen": -215.64404296875,
      "logps/rejected": -252.3437042236328,
      "loss": 0.3887,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.0622096061706543,
      "rewards/margins": 1.56038498878479,
      "rewards/rejected": -4.622594356536865,
      "step": 5700
    },
    {
      "epoch": 1.6996576871558267,
      "grad_norm": 11.855934143066406,
      "learning_rate": 5.330129167918294e-05,
      "logits/chosen": -0.9640706777572632,
      "logits/rejected": -1.049892783164978,
      "logps/chosen": -186.26986694335938,
      "logps/rejected": -210.08731079101562,
      "loss": 0.5593,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.8963634967803955,
      "rewards/margins": 1.2014210224151611,
      "rewards/rejected": -4.097784519195557,
      "step": 5710
    },
    {
      "epoch": 1.70263432058342,
      "grad_norm": 5.502655029296875,
      "learning_rate": 5.325322919795735e-05,
      "logits/chosen": -0.8542516827583313,
      "logits/rejected": -0.9216411709785461,
      "logps/chosen": -198.58609008789062,
      "logps/rejected": -232.6293182373047,
      "loss": 0.4383,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.584977626800537,
      "rewards/margins": 1.9443352222442627,
      "rewards/rejected": -4.529313087463379,
      "step": 5720
    },
    {
      "epoch": 1.7056109540110136,
      "grad_norm": 4.6021809577941895,
      "learning_rate": 5.320516671673176e-05,
      "logits/chosen": -1.0264389514923096,
      "logits/rejected": -1.011969804763794,
      "logps/chosen": -227.26022338867188,
      "logps/rejected": -237.3638458251953,
      "loss": 0.3993,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.240922451019287,
      "rewards/margins": 1.479126214981079,
      "rewards/rejected": -4.720047950744629,
      "step": 5730
    },
    {
      "epoch": 1.708587587438607,
      "grad_norm": 5.414653301239014,
      "learning_rate": 5.3157104235506165e-05,
      "logits/chosen": -0.8777672052383423,
      "logits/rejected": -0.8953043222427368,
      "logps/chosen": -213.52633666992188,
      "logps/rejected": -239.8511505126953,
      "loss": 0.329,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.168881893157959,
      "rewards/margins": 2.029552698135376,
      "rewards/rejected": -5.198434829711914,
      "step": 5740
    },
    {
      "epoch": 1.7115642208662003,
      "grad_norm": 2.7294161319732666,
      "learning_rate": 5.310904175428057e-05,
      "logits/chosen": -0.8668349385261536,
      "logits/rejected": -1.0153840780258179,
      "logps/chosen": -201.44186401367188,
      "logps/rejected": -248.1734161376953,
      "loss": 0.3734,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.563382625579834,
      "rewards/margins": 1.7704484462738037,
      "rewards/rejected": -5.3338303565979,
      "step": 5750
    },
    {
      "epoch": 1.7145408542937939,
      "grad_norm": 4.780976295471191,
      "learning_rate": 5.306097927305498e-05,
      "logits/chosen": -1.033056378364563,
      "logits/rejected": -0.9537479281425476,
      "logps/chosen": -199.69430541992188,
      "logps/rejected": -209.44326782226562,
      "loss": 0.3836,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.239374876022339,
      "rewards/margins": 1.5181702375411987,
      "rewards/rejected": -4.75754451751709,
      "step": 5760
    },
    {
      "epoch": 1.7175174877213872,
      "grad_norm": 7.5885467529296875,
      "learning_rate": 5.3012916791829376e-05,
      "logits/chosen": -0.9116741418838501,
      "logits/rejected": -0.9553664922714233,
      "logps/chosen": -223.637451171875,
      "logps/rejected": -237.17367553710938,
      "loss": 0.3931,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.408017635345459,
      "rewards/margins": 1.5655170679092407,
      "rewards/rejected": -4.97353458404541,
      "step": 5770
    },
    {
      "epoch": 1.7204941211489806,
      "grad_norm": 6.718312740325928,
      "learning_rate": 5.296485431060379e-05,
      "logits/chosen": -0.8463031649589539,
      "logits/rejected": -0.9282751083374023,
      "logps/chosen": -208.96029663085938,
      "logps/rejected": -240.9462127685547,
      "loss": 0.3929,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.9304003715515137,
      "rewards/margins": 1.8402340412139893,
      "rewards/rejected": -5.770634651184082,
      "step": 5780
    },
    {
      "epoch": 1.723470754576574,
      "grad_norm": 2.1488401889801025,
      "learning_rate": 5.2916791829378195e-05,
      "logits/chosen": -0.8828967809677124,
      "logits/rejected": -0.9269835352897644,
      "logps/chosen": -201.7342071533203,
      "logps/rejected": -225.3650665283203,
      "loss": 0.407,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.3751957416534424,
      "rewards/margins": 1.6116969585418701,
      "rewards/rejected": -4.986893177032471,
      "step": 5790
    },
    {
      "epoch": 1.7264473880041673,
      "grad_norm": 5.216937065124512,
      "learning_rate": 5.28687293481526e-05,
      "logits/chosen": -1.0046777725219727,
      "logits/rejected": -0.9671528935432434,
      "logps/chosen": -219.361572265625,
      "logps/rejected": -232.3356170654297,
      "loss": 0.4257,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.6728672981262207,
      "rewards/margins": 1.519474744796753,
      "rewards/rejected": -5.1923418045043945,
      "step": 5800
    },
    {
      "epoch": 1.7294240214317607,
      "grad_norm": 6.747747898101807,
      "learning_rate": 5.282066686692701e-05,
      "logits/chosen": -1.0244452953338623,
      "logits/rejected": -1.0557881593704224,
      "logps/chosen": -202.4022979736328,
      "logps/rejected": -228.6184539794922,
      "loss": 0.4486,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.0090153217315674,
      "rewards/margins": 1.6437046527862549,
      "rewards/rejected": -4.652719974517822,
      "step": 5810
    },
    {
      "epoch": 1.732400654859354,
      "grad_norm": 5.4851484298706055,
      "learning_rate": 5.2772604385701414e-05,
      "logits/chosen": -0.9279022216796875,
      "logits/rejected": -0.9959508180618286,
      "logps/chosen": -196.22781372070312,
      "logps/rejected": -231.1416473388672,
      "loss": 0.365,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.1485190391540527,
      "rewards/margins": 1.6622798442840576,
      "rewards/rejected": -4.8107991218566895,
      "step": 5820
    },
    {
      "epoch": 1.7353772882869474,
      "grad_norm": 5.107354640960693,
      "learning_rate": 5.272454190447582e-05,
      "logits/chosen": -0.9679665565490723,
      "logits/rejected": -1.0393599271774292,
      "logps/chosen": -202.40634155273438,
      "logps/rejected": -243.65646362304688,
      "loss": 0.5325,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -3.818413496017456,
      "rewards/margins": 1.5213812589645386,
      "rewards/rejected": -5.339794158935547,
      "step": 5830
    },
    {
      "epoch": 1.7383539217145407,
      "grad_norm": 6.079700469970703,
      "learning_rate": 5.267647942325023e-05,
      "logits/chosen": -0.9610395431518555,
      "logits/rejected": -0.9841812252998352,
      "logps/chosen": -198.47268676757812,
      "logps/rejected": -221.2429656982422,
      "loss": 0.473,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.1803078651428223,
      "rewards/margins": 1.2799417972564697,
      "rewards/rejected": -4.460249900817871,
      "step": 5840
    },
    {
      "epoch": 1.741330555142134,
      "grad_norm": 5.627341270446777,
      "learning_rate": 5.262841694202464e-05,
      "logits/chosen": -0.9243200421333313,
      "logits/rejected": -0.9252554178237915,
      "logps/chosen": -217.0103759765625,
      "logps/rejected": -230.67831420898438,
      "loss": 0.3952,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.6176209449768066,
      "rewards/margins": 1.7605810165405273,
      "rewards/rejected": -5.378202438354492,
      "step": 5850
    },
    {
      "epoch": 1.7443071885697277,
      "grad_norm": 3.360208749771118,
      "learning_rate": 5.2580354460799045e-05,
      "logits/chosen": -0.949617862701416,
      "logits/rejected": -0.954694926738739,
      "logps/chosen": -215.0952606201172,
      "logps/rejected": -223.7807159423828,
      "loss": 0.4274,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.8839333057403564,
      "rewards/margins": 1.6090812683105469,
      "rewards/rejected": -4.493014335632324,
      "step": 5860
    },
    {
      "epoch": 1.747283821997321,
      "grad_norm": 7.3997392654418945,
      "learning_rate": 5.253229197957345e-05,
      "logits/chosen": -0.9771600961685181,
      "logits/rejected": -1.0019986629486084,
      "logps/chosen": -204.3321075439453,
      "logps/rejected": -228.4190216064453,
      "loss": 0.4179,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.214979648590088,
      "rewards/margins": 1.5376174449920654,
      "rewards/rejected": -3.7525970935821533,
      "step": 5870
    },
    {
      "epoch": 1.7502604554249144,
      "grad_norm": 5.343186378479004,
      "learning_rate": 5.248422949834786e-05,
      "logits/chosen": -1.0142650604248047,
      "logits/rejected": -1.1051125526428223,
      "logps/chosen": -193.57508850097656,
      "logps/rejected": -222.87045288085938,
      "loss": 0.4371,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.7921252250671387,
      "rewards/margins": 1.3476043939590454,
      "rewards/rejected": -4.1397294998168945,
      "step": 5880
    },
    {
      "epoch": 1.753237088852508,
      "grad_norm": 3.6867687702178955,
      "learning_rate": 5.243616701712226e-05,
      "logits/chosen": -0.9592202305793762,
      "logits/rejected": -0.9933211207389832,
      "logps/chosen": -199.58230590820312,
      "logps/rejected": -227.3941650390625,
      "loss": 0.3786,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.32018780708313,
      "rewards/margins": 1.6877162456512451,
      "rewards/rejected": -5.007904052734375,
      "step": 5890
    },
    {
      "epoch": 1.7562137222801013,
      "grad_norm": 6.853147029876709,
      "learning_rate": 5.238810453589667e-05,
      "logits/chosen": -1.0501145124435425,
      "logits/rejected": -1.0782500505447388,
      "logps/chosen": -195.35562133789062,
      "logps/rejected": -222.20211791992188,
      "loss": 0.409,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.1079368591308594,
      "rewards/margins": 1.730921983718872,
      "rewards/rejected": -4.838859558105469,
      "step": 5900
    },
    {
      "epoch": 1.7591903557076947,
      "grad_norm": 3.0305867195129395,
      "learning_rate": 5.2340042054671076e-05,
      "logits/chosen": -0.8854562044143677,
      "logits/rejected": -0.9333637952804565,
      "logps/chosen": -211.8309783935547,
      "logps/rejected": -237.36325073242188,
      "loss": 0.3993,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.83294415473938,
      "rewards/margins": 1.6115543842315674,
      "rewards/rejected": -5.444498062133789,
      "step": 5910
    },
    {
      "epoch": 1.762166989135288,
      "grad_norm": 2.9894444942474365,
      "learning_rate": 5.229197957344548e-05,
      "logits/chosen": -0.9033304452896118,
      "logits/rejected": -0.8688968420028687,
      "logps/chosen": -215.0168914794922,
      "logps/rejected": -222.43276977539062,
      "loss": 0.5358,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -4.0435686111450195,
      "rewards/margins": 1.1925987005233765,
      "rewards/rejected": -5.236166954040527,
      "step": 5920
    },
    {
      "epoch": 1.7651436225628814,
      "grad_norm": 5.410542011260986,
      "learning_rate": 5.224391709221989e-05,
      "logits/chosen": -0.9975217580795288,
      "logits/rejected": -1.009803056716919,
      "logps/chosen": -203.5802764892578,
      "logps/rejected": -219.2273712158203,
      "loss": 0.3789,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.8600146770477295,
      "rewards/margins": 1.6381105184555054,
      "rewards/rejected": -4.498125076293945,
      "step": 5930
    },
    {
      "epoch": 1.7681202559904747,
      "grad_norm": 7.216063499450684,
      "learning_rate": 5.2195854610994294e-05,
      "logits/chosen": -0.9879908561706543,
      "logits/rejected": -0.9148960113525391,
      "logps/chosen": -203.20950317382812,
      "logps/rejected": -207.23709106445312,
      "loss": 0.4897,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.383007526397705,
      "rewards/margins": 1.296938180923462,
      "rewards/rejected": -4.679945468902588,
      "step": 5940
    },
    {
      "epoch": 1.771096889418068,
      "grad_norm": 4.817939758300781,
      "learning_rate": 5.21477921297687e-05,
      "logits/chosen": -0.9770383834838867,
      "logits/rejected": -0.9461797475814819,
      "logps/chosen": -201.2985382080078,
      "logps/rejected": -210.72653198242188,
      "loss": 0.3825,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.970177173614502,
      "rewards/margins": 1.4492523670196533,
      "rewards/rejected": -4.419429779052734,
      "step": 5950
    },
    {
      "epoch": 1.7740735228456614,
      "grad_norm": 4.952849864959717,
      "learning_rate": 5.2099729648543114e-05,
      "logits/chosen": -0.9424937963485718,
      "logits/rejected": -0.9196656346321106,
      "logps/chosen": -231.29537963867188,
      "logps/rejected": -243.1800079345703,
      "loss": 0.453,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.130275249481201,
      "rewards/margins": 1.3123716115951538,
      "rewards/rejected": -4.4426469802856445,
      "step": 5960
    },
    {
      "epoch": 1.7770501562732548,
      "grad_norm": 4.425256729125977,
      "learning_rate": 5.205166716731752e-05,
      "logits/chosen": -0.9736078381538391,
      "logits/rejected": -1.060621976852417,
      "logps/chosen": -183.61257934570312,
      "logps/rejected": -216.87600708007812,
      "loss": 0.4392,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.737671375274658,
      "rewards/margins": 1.2841873168945312,
      "rewards/rejected": -4.021859169006348,
      "step": 5970
    },
    {
      "epoch": 1.7800267897008484,
      "grad_norm": 6.424226760864258,
      "learning_rate": 5.2003604686091926e-05,
      "logits/chosen": -0.9901324510574341,
      "logits/rejected": -1.032339096069336,
      "logps/chosen": -203.6844482421875,
      "logps/rejected": -235.6865234375,
      "loss": 0.3861,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.1735427379608154,
      "rewards/margins": 1.7202484607696533,
      "rewards/rejected": -4.893791198730469,
      "step": 5980
    },
    {
      "epoch": 1.7830034231284417,
      "grad_norm": 1.6372524499893188,
      "learning_rate": 5.195554220486633e-05,
      "logits/chosen": -1.0540552139282227,
      "logits/rejected": -1.0643627643585205,
      "logps/chosen": -220.45388793945312,
      "logps/rejected": -244.91586303710938,
      "loss": 0.3666,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.454629898071289,
      "rewards/margins": 1.6459563970565796,
      "rewards/rejected": -5.1005859375,
      "step": 5990
    },
    {
      "epoch": 1.785980056556035,
      "grad_norm": 7.285731315612793,
      "learning_rate": 5.190747972364074e-05,
      "logits/chosen": -1.0065263509750366,
      "logits/rejected": -0.9969080686569214,
      "logps/chosen": -218.928466796875,
      "logps/rejected": -236.5420684814453,
      "loss": 0.5323,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.9941468238830566,
      "rewards/margins": 1.393420696258545,
      "rewards/rejected": -5.387567520141602,
      "step": 6000
    },
    {
      "epoch": 1.7889566899836287,
      "grad_norm": 3.734748363494873,
      "learning_rate": 5.185941724241514e-05,
      "logits/chosen": -0.9482877850532532,
      "logits/rejected": -0.9971238970756531,
      "logps/chosen": -211.29006958007812,
      "logps/rejected": -246.4809112548828,
      "loss": 0.4462,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.655181407928467,
      "rewards/margins": 1.5371872186660767,
      "rewards/rejected": -5.192368507385254,
      "step": 6010
    },
    {
      "epoch": 1.791933323411222,
      "grad_norm": 7.317465305328369,
      "learning_rate": 5.181135476118955e-05,
      "logits/chosen": -0.9473081827163696,
      "logits/rejected": -0.9667373895645142,
      "logps/chosen": -204.8305206298828,
      "logps/rejected": -216.49740600585938,
      "loss": 0.4813,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.4433789253234863,
      "rewards/margins": 1.1099741458892822,
      "rewards/rejected": -4.553353309631348,
      "step": 6020
    },
    {
      "epoch": 1.7949099568388154,
      "grad_norm": 3.582120895385742,
      "learning_rate": 5.1763292279963957e-05,
      "logits/chosen": -0.9905003309249878,
      "logits/rejected": -1.073256492614746,
      "logps/chosen": -197.7290496826172,
      "logps/rejected": -231.6002197265625,
      "loss": 0.4463,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.4143893718719482,
      "rewards/margins": 1.4845598936080933,
      "rewards/rejected": -4.898949146270752,
      "step": 6030
    },
    {
      "epoch": 1.7978865902664087,
      "grad_norm": 6.180393695831299,
      "learning_rate": 5.171522979873836e-05,
      "logits/chosen": -1.035814881324768,
      "logits/rejected": -1.0579745769500732,
      "logps/chosen": -214.24560546875,
      "logps/rejected": -240.1848907470703,
      "loss": 0.4017,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.2991206645965576,
      "rewards/margins": 1.7859398126602173,
      "rewards/rejected": -5.085060119628906,
      "step": 6040
    },
    {
      "epoch": 1.800863223694002,
      "grad_norm": 8.401456832885742,
      "learning_rate": 5.166716731751277e-05,
      "logits/chosen": -0.9774194955825806,
      "logits/rejected": -1.013746738433838,
      "logps/chosen": -200.9915008544922,
      "logps/rejected": -226.13345336914062,
      "loss": 0.4535,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -3.159406900405884,
      "rewards/margins": 1.2523481845855713,
      "rewards/rejected": -4.411755084991455,
      "step": 6050
    },
    {
      "epoch": 1.8038398571215954,
      "grad_norm": 4.833957672119141,
      "learning_rate": 5.1619104836287175e-05,
      "logits/chosen": -1.0168113708496094,
      "logits/rejected": -1.0521183013916016,
      "logps/chosen": -193.15809631347656,
      "logps/rejected": -219.87704467773438,
      "loss": 0.4931,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.0451204776763916,
      "rewards/margins": 1.2259799242019653,
      "rewards/rejected": -4.271100044250488,
      "step": 6060
    },
    {
      "epoch": 1.8068164905491888,
      "grad_norm": 3.371152400970459,
      "learning_rate": 5.157104235506159e-05,
      "logits/chosen": -0.9260169863700867,
      "logits/rejected": -0.9694845080375671,
      "logps/chosen": -208.532958984375,
      "logps/rejected": -248.3263702392578,
      "loss": 0.2972,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.0687384605407715,
      "rewards/margins": 2.0347352027893066,
      "rewards/rejected": -5.103473663330078,
      "step": 6070
    },
    {
      "epoch": 1.8097931239767822,
      "grad_norm": 3.5901830196380615,
      "learning_rate": 5.1522979873835994e-05,
      "logits/chosen": -0.9231769442558289,
      "logits/rejected": -1.0093177556991577,
      "logps/chosen": -200.32989501953125,
      "logps/rejected": -243.38546752929688,
      "loss": 0.4288,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.1061699390411377,
      "rewards/margins": 1.7400767803192139,
      "rewards/rejected": -4.846246242523193,
      "step": 6080
    },
    {
      "epoch": 1.8127697574043755,
      "grad_norm": 3.450212001800537,
      "learning_rate": 5.14749173926104e-05,
      "logits/chosen": -0.9629656672477722,
      "logits/rejected": -1.0005176067352295,
      "logps/chosen": -205.9312286376953,
      "logps/rejected": -234.34689331054688,
      "loss": 0.3966,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.9013419151306152,
      "rewards/margins": 1.4893474578857422,
      "rewards/rejected": -5.390689373016357,
      "step": 6090
    },
    {
      "epoch": 1.815746390831969,
      "grad_norm": 3.6772756576538086,
      "learning_rate": 5.1426854911384806e-05,
      "logits/chosen": -0.9504537582397461,
      "logits/rejected": -0.9111529588699341,
      "logps/chosen": -215.0176544189453,
      "logps/rejected": -233.3474578857422,
      "loss": 0.3873,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -4.056557655334473,
      "rewards/margins": 1.8140662908554077,
      "rewards/rejected": -5.870623588562012,
      "step": 6100
    },
    {
      "epoch": 1.8187230242595624,
      "grad_norm": 5.107858657836914,
      "learning_rate": 5.137879243015921e-05,
      "logits/chosen": -0.9188932180404663,
      "logits/rejected": -0.9131290316581726,
      "logps/chosen": -200.43984985351562,
      "logps/rejected": -223.72055053710938,
      "loss": 0.3861,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -4.044517993927002,
      "rewards/margins": 1.6438013315200806,
      "rewards/rejected": -5.688319206237793,
      "step": 6110
    },
    {
      "epoch": 1.8216996576871558,
      "grad_norm": 4.804128170013428,
      "learning_rate": 5.133072994893362e-05,
      "logits/chosen": -0.7530507445335388,
      "logits/rejected": -0.8859957456588745,
      "logps/chosen": -192.62367248535156,
      "logps/rejected": -233.20938110351562,
      "loss": 0.4153,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -4.511641502380371,
      "rewards/margins": 1.542922019958496,
      "rewards/rejected": -6.054563522338867,
      "step": 6120
    },
    {
      "epoch": 1.8246762911147494,
      "grad_norm": 5.91953706741333,
      "learning_rate": 5.128266746770802e-05,
      "logits/chosen": -0.9347529411315918,
      "logits/rejected": -0.9695334434509277,
      "logps/chosen": -221.2375946044922,
      "logps/rejected": -244.404052734375,
      "loss": 0.4158,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -5.289196968078613,
      "rewards/margins": 1.6090545654296875,
      "rewards/rejected": -6.898252010345459,
      "step": 6130
    },
    {
      "epoch": 1.8276529245423427,
      "grad_norm": 5.555588722229004,
      "learning_rate": 5.123460498648243e-05,
      "logits/chosen": -0.9187668561935425,
      "logits/rejected": -0.9546529650688171,
      "logps/chosen": -223.52975463867188,
      "logps/rejected": -240.92269897460938,
      "loss": 0.4541,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -4.757828235626221,
      "rewards/margins": 1.5314396619796753,
      "rewards/rejected": -6.2892680168151855,
      "step": 6140
    },
    {
      "epoch": 1.830629557969936,
      "grad_norm": 5.233101844787598,
      "learning_rate": 5.118654250525684e-05,
      "logits/chosen": -0.9722198247909546,
      "logits/rejected": -1.0283122062683105,
      "logps/chosen": -197.68954467773438,
      "logps/rejected": -217.7042999267578,
      "loss": 0.5628,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -3.7979416847229004,
      "rewards/margins": 1.0960150957107544,
      "rewards/rejected": -4.893956661224365,
      "step": 6150
    },
    {
      "epoch": 1.8336061913975295,
      "grad_norm": 3.864093780517578,
      "learning_rate": 5.113848002403124e-05,
      "logits/chosen": -0.9544383883476257,
      "logits/rejected": -0.9958959817886353,
      "logps/chosen": -204.6818084716797,
      "logps/rejected": -230.9652557373047,
      "loss": 0.4013,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.3259520530700684,
      "rewards/margins": 1.8293707370758057,
      "rewards/rejected": -5.155322551727295,
      "step": 6160
    },
    {
      "epoch": 1.8365828248251228,
      "grad_norm": 4.7137250900268555,
      "learning_rate": 5.109041754280565e-05,
      "logits/chosen": -0.9787880182266235,
      "logits/rejected": -1.0050331354141235,
      "logps/chosen": -224.30056762695312,
      "logps/rejected": -246.14453125,
      "loss": 0.4447,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -4.415628910064697,
      "rewards/margins": 1.647452712059021,
      "rewards/rejected": -6.06308126449585,
      "step": 6170
    },
    {
      "epoch": 1.8395594582527162,
      "grad_norm": 3.039458990097046,
      "learning_rate": 5.1042355061580056e-05,
      "logits/chosen": -1.034375548362732,
      "logits/rejected": -1.0748944282531738,
      "logps/chosen": -194.7064971923828,
      "logps/rejected": -220.7533416748047,
      "loss": 0.4255,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.4696362018585205,
      "rewards/margins": 1.50480055809021,
      "rewards/rejected": -4.9744367599487305,
      "step": 6180
    },
    {
      "epoch": 1.8425360916803095,
      "grad_norm": 2.811469793319702,
      "learning_rate": 5.099429258035447e-05,
      "logits/chosen": -1.078109860420227,
      "logits/rejected": -1.0545642375946045,
      "logps/chosen": -203.73257446289062,
      "logps/rejected": -221.32308959960938,
      "loss": 0.4154,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.2971789836883545,
      "rewards/margins": 1.7271610498428345,
      "rewards/rejected": -5.0243401527404785,
      "step": 6190
    },
    {
      "epoch": 1.8455127251079029,
      "grad_norm": 3.6059532165527344,
      "learning_rate": 5.0946230099128875e-05,
      "logits/chosen": -1.0857959985733032,
      "logits/rejected": -1.1408056020736694,
      "logps/chosen": -196.0033416748047,
      "logps/rejected": -226.12564086914062,
      "loss": 0.4632,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.359097719192505,
      "rewards/margins": 1.4872843027114868,
      "rewards/rejected": -4.846381187438965,
      "step": 6200
    },
    {
      "epoch": 1.8484893585354962,
      "grad_norm": 5.100882530212402,
      "learning_rate": 5.089816761790328e-05,
      "logits/chosen": -1.0826561450958252,
      "logits/rejected": -1.0816504955291748,
      "logps/chosen": -198.1914825439453,
      "logps/rejected": -227.56661987304688,
      "loss": 0.3627,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.907968044281006,
      "rewards/margins": 1.689326524734497,
      "rewards/rejected": -4.597294807434082,
      "step": 6210
    },
    {
      "epoch": 1.8514659919630896,
      "grad_norm": 4.454859733581543,
      "learning_rate": 5.085010513667769e-05,
      "logits/chosen": -1.060936689376831,
      "logits/rejected": -1.1158229112625122,
      "logps/chosen": -194.57391357421875,
      "logps/rejected": -227.55252075195312,
      "loss": 0.3882,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.0750279426574707,
      "rewards/margins": 1.6306778192520142,
      "rewards/rejected": -4.705705165863037,
      "step": 6220
    },
    {
      "epoch": 1.8544426253906832,
      "grad_norm": 4.492489337921143,
      "learning_rate": 5.080204265545209e-05,
      "logits/chosen": -1.067430853843689,
      "logits/rejected": -1.0231215953826904,
      "logps/chosen": -213.4345703125,
      "logps/rejected": -231.3037872314453,
      "loss": 0.3544,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.3629746437072754,
      "rewards/margins": 1.7541481256484985,
      "rewards/rejected": -5.117121696472168,
      "step": 6230
    },
    {
      "epoch": 1.8574192588182765,
      "grad_norm": 4.886497497558594,
      "learning_rate": 5.0753980174226506e-05,
      "logits/chosen": -1.0996614694595337,
      "logits/rejected": -1.160577654838562,
      "logps/chosen": -205.59823608398438,
      "logps/rejected": -229.7920684814453,
      "loss": 0.4358,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.204657793045044,
      "rewards/margins": 1.365299940109253,
      "rewards/rejected": -4.5699567794799805,
      "step": 6240
    },
    {
      "epoch": 1.8603958922458699,
      "grad_norm": 7.443303108215332,
      "learning_rate": 5.07059176930009e-05,
      "logits/chosen": -1.0666446685791016,
      "logits/rejected": -1.075324535369873,
      "logps/chosen": -207.0012664794922,
      "logps/rejected": -225.3226776123047,
      "loss": 0.4359,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.558920383453369,
      "rewards/margins": 1.4230613708496094,
      "rewards/rejected": -3.9819819927215576,
      "step": 6250
    },
    {
      "epoch": 1.8633725256734635,
      "grad_norm": 7.169916152954102,
      "learning_rate": 5.065785521177531e-05,
      "logits/chosen": -1.1181244850158691,
      "logits/rejected": -1.1280022859573364,
      "logps/chosen": -215.75100708007812,
      "logps/rejected": -233.0443878173828,
      "loss": 0.4063,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.756333827972412,
      "rewards/margins": 1.5735509395599365,
      "rewards/rejected": -4.329885005950928,
      "step": 6260
    },
    {
      "epoch": 1.8663491591010568,
      "grad_norm": 7.049902439117432,
      "learning_rate": 5.060979273054972e-05,
      "logits/chosen": -1.0195704698562622,
      "logits/rejected": -1.080318570137024,
      "logps/chosen": -212.65805053710938,
      "logps/rejected": -243.42312622070312,
      "loss": 0.3607,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.3107402324676514,
      "rewards/margins": 2.0033791065216064,
      "rewards/rejected": -5.314119338989258,
      "step": 6270
    },
    {
      "epoch": 1.8693257925286502,
      "grad_norm": 11.196277618408203,
      "learning_rate": 5.0561730249324124e-05,
      "logits/chosen": -1.0832858085632324,
      "logits/rejected": -1.0996283292770386,
      "logps/chosen": -203.5035400390625,
      "logps/rejected": -226.6542510986328,
      "loss": 0.4957,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.391949415206909,
      "rewards/margins": 1.2951695919036865,
      "rewards/rejected": -4.687119483947754,
      "step": 6280
    },
    {
      "epoch": 1.8723024259562435,
      "grad_norm": 4.82597017288208,
      "learning_rate": 5.051366776809853e-05,
      "logits/chosen": -1.0316306352615356,
      "logits/rejected": -1.1006138324737549,
      "logps/chosen": -220.23287963867188,
      "logps/rejected": -268.25225830078125,
      "loss": 0.45,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.716052293777466,
      "rewards/margins": 1.7208149433135986,
      "rewards/rejected": -5.436867713928223,
      "step": 6290
    },
    {
      "epoch": 1.8752790593838369,
      "grad_norm": 8.31167221069336,
      "learning_rate": 5.0465605286872936e-05,
      "logits/chosen": -1.1304107904434204,
      "logits/rejected": -1.1695486307144165,
      "logps/chosen": -202.5706329345703,
      "logps/rejected": -223.42465209960938,
      "loss": 0.5098,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -3.411912441253662,
      "rewards/margins": 1.2581570148468018,
      "rewards/rejected": -4.670069217681885,
      "step": 6300
    },
    {
      "epoch": 1.8782556928114302,
      "grad_norm": 1.9087038040161133,
      "learning_rate": 5.041754280564735e-05,
      "logits/chosen": -1.039648175239563,
      "logits/rejected": -1.1080913543701172,
      "logps/chosen": -213.32565307617188,
      "logps/rejected": -255.7526397705078,
      "loss": 0.376,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.8679137229919434,
      "rewards/margins": 1.8257465362548828,
      "rewards/rejected": -5.693660259246826,
      "step": 6310
    },
    {
      "epoch": 1.8812323262390236,
      "grad_norm": 5.369542121887207,
      "learning_rate": 5.0369480324421755e-05,
      "logits/chosen": -1.1308549642562866,
      "logits/rejected": -1.0836312770843506,
      "logps/chosen": -208.65554809570312,
      "logps/rejected": -216.6039276123047,
      "loss": 0.3993,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.8949456214904785,
      "rewards/margins": 1.3006771802902222,
      "rewards/rejected": -4.195622444152832,
      "step": 6320
    },
    {
      "epoch": 1.884208959666617,
      "grad_norm": 2.7908732891082764,
      "learning_rate": 5.032141784319616e-05,
      "logits/chosen": -1.0586498975753784,
      "logits/rejected": -1.101879596710205,
      "logps/chosen": -188.6873016357422,
      "logps/rejected": -218.99423217773438,
      "loss": 0.351,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.0042710304260254,
      "rewards/margins": 1.8726030588150024,
      "rewards/rejected": -4.876873970031738,
      "step": 6330
    },
    {
      "epoch": 1.8871855930942103,
      "grad_norm": 6.752643585205078,
      "learning_rate": 5.027335536197057e-05,
      "logits/chosen": -1.097367525100708,
      "logits/rejected": -1.1157218217849731,
      "logps/chosen": -220.4041748046875,
      "logps/rejected": -248.2626495361328,
      "loss": 0.3511,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -4.337514877319336,
      "rewards/margins": 1.84221613407135,
      "rewards/rejected": -6.179730415344238,
      "step": 6340
    },
    {
      "epoch": 1.8901622265218039,
      "grad_norm": 3.4583606719970703,
      "learning_rate": 5.0225292880744974e-05,
      "logits/chosen": -1.0076748132705688,
      "logits/rejected": -1.0981727838516235,
      "logps/chosen": -209.63986206054688,
      "logps/rejected": -249.3939971923828,
      "loss": 0.4259,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -4.551772117614746,
      "rewards/margins": 1.792353868484497,
      "rewards/rejected": -6.3441267013549805,
      "step": 6350
    },
    {
      "epoch": 1.8931388599493972,
      "grad_norm": 7.795094013214111,
      "learning_rate": 5.0177230399519387e-05,
      "logits/chosen": -1.0039541721343994,
      "logits/rejected": -1.029255986213684,
      "logps/chosen": -209.8175048828125,
      "logps/rejected": -233.55770874023438,
      "loss": 0.4514,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -4.218703269958496,
      "rewards/margins": 1.5588560104370117,
      "rewards/rejected": -5.77755880355835,
      "step": 6360
    },
    {
      "epoch": 1.8961154933769906,
      "grad_norm": 9.437128067016602,
      "learning_rate": 5.012916791829378e-05,
      "logits/chosen": -0.9742001295089722,
      "logits/rejected": -0.9557243585586548,
      "logps/chosen": -210.4265899658203,
      "logps/rejected": -218.75851440429688,
      "loss": 0.5136,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.7560806274414062,
      "rewards/margins": 1.2288893461227417,
      "rewards/rejected": -4.984970569610596,
      "step": 6370
    },
    {
      "epoch": 1.8990921268045842,
      "grad_norm": 5.94142484664917,
      "learning_rate": 5.008110543706819e-05,
      "logits/chosen": -1.0164105892181396,
      "logits/rejected": -0.9897278547286987,
      "logps/chosen": -204.30616760253906,
      "logps/rejected": -220.70156860351562,
      "loss": 0.4012,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.553818464279175,
      "rewards/margins": 1.7529197931289673,
      "rewards/rejected": -5.30673885345459,
      "step": 6380
    },
    {
      "epoch": 1.9020687602321775,
      "grad_norm": 4.556098461151123,
      "learning_rate": 5.00330429558426e-05,
      "logits/chosen": -1.0182604789733887,
      "logits/rejected": -1.0149041414260864,
      "logps/chosen": -215.4408416748047,
      "logps/rejected": -234.6375274658203,
      "loss": 0.466,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -3.450106143951416,
      "rewards/margins": 1.7005506753921509,
      "rewards/rejected": -5.150656700134277,
      "step": 6390
    },
    {
      "epoch": 1.9050453936597709,
      "grad_norm": 3.3062777519226074,
      "learning_rate": 4.9984980474617004e-05,
      "logits/chosen": -1.0713788270950317,
      "logits/rejected": -1.1024034023284912,
      "logps/chosen": -210.5243682861328,
      "logps/rejected": -242.32254028320312,
      "loss": 0.3804,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.5338828563690186,
      "rewards/margins": 1.6317602396011353,
      "rewards/rejected": -5.165642738342285,
      "step": 6400
    },
    {
      "epoch": 1.9080220270873642,
      "grad_norm": 3.1794593334198,
      "learning_rate": 4.993691799339141e-05,
      "logits/chosen": -0.9598291516304016,
      "logits/rejected": -1.023808479309082,
      "logps/chosen": -197.48416137695312,
      "logps/rejected": -242.7261505126953,
      "loss": 0.2813,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.032276630401611,
      "rewards/margins": 2.1577341556549072,
      "rewards/rejected": -6.1900105476379395,
      "step": 6410
    },
    {
      "epoch": 1.9109986605149576,
      "grad_norm": 3.8737056255340576,
      "learning_rate": 4.9888855512165817e-05,
      "logits/chosen": -1.0628302097320557,
      "logits/rejected": -1.0453622341156006,
      "logps/chosen": -224.7656707763672,
      "logps/rejected": -239.81692504882812,
      "loss": 0.4749,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -4.2706732749938965,
      "rewards/margins": 1.641593337059021,
      "rewards/rejected": -5.912267208099365,
      "step": 6420
    },
    {
      "epoch": 1.913975293942551,
      "grad_norm": 3.5647597312927246,
      "learning_rate": 4.984079303094023e-05,
      "logits/chosen": -1.0012664794921875,
      "logits/rejected": -0.9202278852462769,
      "logps/chosen": -203.46463012695312,
      "logps/rejected": -217.79367065429688,
      "loss": 0.3993,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -4.064986705780029,
      "rewards/margins": 1.6513147354125977,
      "rewards/rejected": -5.716301918029785,
      "step": 6430
    },
    {
      "epoch": 1.9169519273701443,
      "grad_norm": 5.6247334480285645,
      "learning_rate": 4.9792730549714636e-05,
      "logits/chosen": -0.8961313366889954,
      "logits/rejected": -0.922618567943573,
      "logps/chosen": -220.5117950439453,
      "logps/rejected": -259.27618408203125,
      "loss": 0.3974,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -4.483181953430176,
      "rewards/margins": 1.7033910751342773,
      "rewards/rejected": -6.186573028564453,
      "step": 6440
    },
    {
      "epoch": 1.9199285607977377,
      "grad_norm": 5.027138710021973,
      "learning_rate": 4.974466806848904e-05,
      "logits/chosen": -0.8699434399604797,
      "logits/rejected": -0.9593513607978821,
      "logps/chosen": -202.59420776367188,
      "logps/rejected": -243.5865936279297,
      "loss": 0.3376,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -4.086410045623779,
      "rewards/margins": 2.0527448654174805,
      "rewards/rejected": -6.13915491104126,
      "step": 6450
    },
    {
      "epoch": 1.922905194225331,
      "grad_norm": 7.933572292327881,
      "learning_rate": 4.969660558726345e-05,
      "logits/chosen": -0.8755135536193848,
      "logits/rejected": -0.9293915629386902,
      "logps/chosen": -234.70272827148438,
      "logps/rejected": -261.88946533203125,
      "loss": 0.4226,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -5.411403656005859,
      "rewards/margins": 2.1308043003082275,
      "rewards/rejected": -7.542208194732666,
      "step": 6460
    },
    {
      "epoch": 1.9258818276529246,
      "grad_norm": 7.080699443817139,
      "learning_rate": 4.9648543106037854e-05,
      "logits/chosen": -1.0109285116195679,
      "logits/rejected": -1.0467804670333862,
      "logps/chosen": -216.30032348632812,
      "logps/rejected": -245.882080078125,
      "loss": 0.3817,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.526785850524902,
      "rewards/margins": 1.833740234375,
      "rewards/rejected": -6.360525131225586,
      "step": 6470
    },
    {
      "epoch": 1.928858461080518,
      "grad_norm": 2.7537238597869873,
      "learning_rate": 4.960048062481227e-05,
      "logits/chosen": -1.0403480529785156,
      "logits/rejected": -1.0299382209777832,
      "logps/chosen": -211.80673217773438,
      "logps/rejected": -230.5532684326172,
      "loss": 0.4458,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.958620548248291,
      "rewards/margins": 1.4235117435455322,
      "rewards/rejected": -5.382132530212402,
      "step": 6480
    },
    {
      "epoch": 1.9318350945081113,
      "grad_norm": 4.416843891143799,
      "learning_rate": 4.955241814358666e-05,
      "logits/chosen": -0.9163812398910522,
      "logits/rejected": -1.017797827720642,
      "logps/chosen": -207.21435546875,
      "logps/rejected": -251.5215301513672,
      "loss": 0.365,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -4.367720603942871,
      "rewards/margins": 2.0311615467071533,
      "rewards/rejected": -6.398882865905762,
      "step": 6490
    },
    {
      "epoch": 1.9348117279357049,
      "grad_norm": 3.1922404766082764,
      "learning_rate": 4.950435566236107e-05,
      "logits/chosen": -1.0433075428009033,
      "logits/rejected": -1.0600244998931885,
      "logps/chosen": -222.9582977294922,
      "logps/rejected": -257.01910400390625,
      "loss": 0.3325,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -4.622690677642822,
      "rewards/margins": 2.1222777366638184,
      "rewards/rejected": -6.744968414306641,
      "step": 6500
    },
    {
      "epoch": 1.9377883613632982,
      "grad_norm": 5.774649143218994,
      "learning_rate": 4.945629318113548e-05,
      "logits/chosen": -1.0556418895721436,
      "logits/rejected": -1.0247488021850586,
      "logps/chosen": -209.15048217773438,
      "logps/rejected": -221.46762084960938,
      "loss": 0.4729,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.607548475265503,
      "rewards/margins": 1.7469717264175415,
      "rewards/rejected": -5.354520797729492,
      "step": 6510
    },
    {
      "epoch": 1.9407649947908916,
      "grad_norm": 3.483104705810547,
      "learning_rate": 4.9408230699909885e-05,
      "logits/chosen": -1.0353809595108032,
      "logits/rejected": -1.054827094078064,
      "logps/chosen": -210.58993530273438,
      "logps/rejected": -237.2012176513672,
      "loss": 0.3088,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.378488063812256,
      "rewards/margins": 1.8763850927352905,
      "rewards/rejected": -5.254873752593994,
      "step": 6520
    },
    {
      "epoch": 1.943741628218485,
      "grad_norm": 6.566394805908203,
      "learning_rate": 4.936016821868429e-05,
      "logits/chosen": -0.9924203753471375,
      "logits/rejected": -1.0954821109771729,
      "logps/chosen": -200.6496124267578,
      "logps/rejected": -246.0218505859375,
      "loss": 0.3853,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -3.726048231124878,
      "rewards/margins": 2.0127835273742676,
      "rewards/rejected": -5.738831996917725,
      "step": 6530
    },
    {
      "epoch": 1.9467182616460783,
      "grad_norm": 4.509383201599121,
      "learning_rate": 4.93121057374587e-05,
      "logits/chosen": -1.0516785383224487,
      "logits/rejected": -1.117593765258789,
      "logps/chosen": -197.06549072265625,
      "logps/rejected": -235.5010528564453,
      "loss": 0.3721,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.772324323654175,
      "rewards/margins": 1.9227378368377686,
      "rewards/rejected": -5.695062160491943,
      "step": 6540
    },
    {
      "epoch": 1.9496948950736717,
      "grad_norm": 4.024548530578613,
      "learning_rate": 4.926404325623311e-05,
      "logits/chosen": -1.078932523727417,
      "logits/rejected": -1.105881929397583,
      "logps/chosen": -222.2428436279297,
      "logps/rejected": -231.6147003173828,
      "loss": 0.6217,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -3.604344606399536,
      "rewards/margins": 1.1723220348358154,
      "rewards/rejected": -4.776666641235352,
      "step": 6550
    },
    {
      "epoch": 1.952671528501265,
      "grad_norm": 5.004919052124023,
      "learning_rate": 4.9215980775007516e-05,
      "logits/chosen": -0.8831602334976196,
      "logits/rejected": -1.0708928108215332,
      "logps/chosen": -201.46469116210938,
      "logps/rejected": -264.4839782714844,
      "loss": 0.3331,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -4.142736434936523,
      "rewards/margins": 2.3465099334716797,
      "rewards/rejected": -6.489246368408203,
      "step": 6560
    },
    {
      "epoch": 1.9556481619288584,
      "grad_norm": 5.058296203613281,
      "learning_rate": 4.916791829378192e-05,
      "logits/chosen": -0.9896553158760071,
      "logits/rejected": -1.033639907836914,
      "logps/chosen": -215.9971160888672,
      "logps/rejected": -249.61355590820312,
      "loss": 0.3692,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -4.018141269683838,
      "rewards/margins": 2.093471050262451,
      "rewards/rejected": -6.111612796783447,
      "step": 6570
    },
    {
      "epoch": 1.9586247953564517,
      "grad_norm": 5.6593217849731445,
      "learning_rate": 4.911985581255633e-05,
      "logits/chosen": -0.9661677479743958,
      "logits/rejected": -0.9421943426132202,
      "logps/chosen": -233.14566040039062,
      "logps/rejected": -244.89437866210938,
      "loss": 0.4184,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -4.168262481689453,
      "rewards/margins": 1.9259183406829834,
      "rewards/rejected": -6.094181060791016,
      "step": 6580
    },
    {
      "epoch": 1.961601428784045,
      "grad_norm": 2.3118414878845215,
      "learning_rate": 4.9071793331330735e-05,
      "logits/chosen": -1.012494683265686,
      "logits/rejected": -1.0804191827774048,
      "logps/chosen": -223.1846466064453,
      "logps/rejected": -264.02532958984375,
      "loss": 0.3088,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.113015174865723,
      "rewards/margins": 2.1950831413269043,
      "rewards/rejected": -6.308097839355469,
      "step": 6590
    },
    {
      "epoch": 1.9645780622116387,
      "grad_norm": 4.174253463745117,
      "learning_rate": 4.902373085010515e-05,
      "logits/chosen": -0.9698527455329895,
      "logits/rejected": -1.002534031867981,
      "logps/chosen": -195.85110473632812,
      "logps/rejected": -235.3517303466797,
      "loss": 0.428,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -4.177757740020752,
      "rewards/margins": 2.0963082313537598,
      "rewards/rejected": -6.274065971374512,
      "step": 6600
    },
    {
      "epoch": 1.967554695639232,
      "grad_norm": 6.349113941192627,
      "learning_rate": 4.897566836887954e-05,
      "logits/chosen": -0.8823890686035156,
      "logits/rejected": -0.9506708383560181,
      "logps/chosen": -209.58963012695312,
      "logps/rejected": -257.8300476074219,
      "loss": 0.4467,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -4.0963287353515625,
      "rewards/margins": 2.0509841442108154,
      "rewards/rejected": -6.147313117980957,
      "step": 6610
    },
    {
      "epoch": 1.9705313290668254,
      "grad_norm": 8.680018424987793,
      "learning_rate": 4.892760588765395e-05,
      "logits/chosen": -1.0105106830596924,
      "logits/rejected": -1.0532927513122559,
      "logps/chosen": -219.9153594970703,
      "logps/rejected": -250.18893432617188,
      "loss": 0.4029,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -4.702815055847168,
      "rewards/margins": 1.7463716268539429,
      "rewards/rejected": -6.449185848236084,
      "step": 6620
    },
    {
      "epoch": 1.973507962494419,
      "grad_norm": 4.796993255615234,
      "learning_rate": 4.887954340642836e-05,
      "logits/chosen": -1.055338740348816,
      "logits/rejected": -0.9726970791816711,
      "logps/chosen": -212.8876190185547,
      "logps/rejected": -204.1228790283203,
      "loss": 0.4559,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.5539162158966064,
      "rewards/margins": 1.2494817972183228,
      "rewards/rejected": -4.803398609161377,
      "step": 6630
    },
    {
      "epoch": 1.9764845959220123,
      "grad_norm": 2.9523608684539795,
      "learning_rate": 4.8831480925202765e-05,
      "logits/chosen": -0.9077655673027039,
      "logits/rejected": -0.9603633880615234,
      "logps/chosen": -203.52542114257812,
      "logps/rejected": -231.15798950195312,
      "loss": 0.4185,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.483372211456299,
      "rewards/margins": 1.7095378637313843,
      "rewards/rejected": -5.1929097175598145,
      "step": 6640
    },
    {
      "epoch": 1.9794612293496057,
      "grad_norm": 5.742208003997803,
      "learning_rate": 4.878341844397717e-05,
      "logits/chosen": -0.9810947179794312,
      "logits/rejected": -1.0487346649169922,
      "logps/chosen": -206.68783569335938,
      "logps/rejected": -231.1185760498047,
      "loss": 0.4496,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.7712302207946777,
      "rewards/margins": 1.391469955444336,
      "rewards/rejected": -5.162701606750488,
      "step": 6650
    },
    {
      "epoch": 1.982437862777199,
      "grad_norm": 3.8053340911865234,
      "learning_rate": 4.873535596275158e-05,
      "logits/chosen": -0.9622715711593628,
      "logits/rejected": -0.9862116575241089,
      "logps/chosen": -216.972412109375,
      "logps/rejected": -242.04989624023438,
      "loss": 0.3524,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.7936389446258545,
      "rewards/margins": 2.033947467803955,
      "rewards/rejected": -5.8275861740112305,
      "step": 6660
    },
    {
      "epoch": 1.9854144962047924,
      "grad_norm": 4.197648525238037,
      "learning_rate": 4.868729348152599e-05,
      "logits/chosen": -1.0872970819473267,
      "logits/rejected": -1.0739967823028564,
      "logps/chosen": -209.00167846679688,
      "logps/rejected": -222.2506866455078,
      "loss": 0.4361,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.179821491241455,
      "rewards/margins": 1.2708441019058228,
      "rewards/rejected": -4.450665473937988,
      "step": 6670
    },
    {
      "epoch": 1.9883911296323857,
      "grad_norm": 3.1763296127319336,
      "learning_rate": 4.86392310003004e-05,
      "logits/chosen": -1.0621039867401123,
      "logits/rejected": -1.1065576076507568,
      "logps/chosen": -221.55419921875,
      "logps/rejected": -245.7554168701172,
      "loss": 0.4259,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.448056697845459,
      "rewards/margins": 1.6358569860458374,
      "rewards/rejected": -5.083913326263428,
      "step": 6680
    },
    {
      "epoch": 1.991367763059979,
      "grad_norm": 3.1587417125701904,
      "learning_rate": 4.85911685190748e-05,
      "logits/chosen": -1.0736528635025024,
      "logits/rejected": -1.045122742652893,
      "logps/chosen": -219.6327362060547,
      "logps/rejected": -228.4168701171875,
      "loss": 0.5353,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.6016364097595215,
      "rewards/margins": 1.4045979976654053,
      "rewards/rejected": -5.006234645843506,
      "step": 6690
    },
    {
      "epoch": 1.9943443964875724,
      "grad_norm": 7.9834089279174805,
      "learning_rate": 4.854310603784921e-05,
      "logits/chosen": -1.0821529626846313,
      "logits/rejected": -1.0612753629684448,
      "logps/chosen": -215.8182373046875,
      "logps/rejected": -233.7727508544922,
      "loss": 0.4474,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.698875904083252,
      "rewards/margins": 1.3028786182403564,
      "rewards/rejected": -5.001753807067871,
      "step": 6700
    },
    {
      "epoch": 1.9973210299151658,
      "grad_norm": 4.942883014678955,
      "learning_rate": 4.8495043556623615e-05,
      "logits/chosen": -0.9854854345321655,
      "logits/rejected": -1.045609474182129,
      "logps/chosen": -196.4122772216797,
      "logps/rejected": -217.30953979492188,
      "loss": 0.4035,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.283236265182495,
      "rewards/margins": 1.5521867275238037,
      "rewards/rejected": -4.835422515869141,
      "step": 6710
    },
    {
      "epoch": 2.000297663342759,
      "grad_norm": 3.3930001258850098,
      "learning_rate": 4.844698107539803e-05,
      "logits/chosen": -0.9609926342964172,
      "logits/rejected": -1.1129542589187622,
      "logps/chosen": -203.33843994140625,
      "logps/rejected": -259.8106384277344,
      "loss": 0.3566,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.8548271656036377,
      "rewards/margins": 1.8893754482269287,
      "rewards/rejected": -5.744202613830566,
      "step": 6720
    },
    {
      "epoch": 2.0032742967703525,
      "grad_norm": 3.6270222663879395,
      "learning_rate": 4.839891859417242e-05,
      "logits/chosen": -1.0086547136306763,
      "logits/rejected": -1.0624668598175049,
      "logps/chosen": -209.63516235351562,
      "logps/rejected": -250.8707275390625,
      "loss": 0.2457,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -3.712146759033203,
      "rewards/margins": 2.494696855545044,
      "rewards/rejected": -6.206843376159668,
      "step": 6730
    },
    {
      "epoch": 2.0062509301979463,
      "grad_norm": 6.01954984664917,
      "learning_rate": 4.8350856112946834e-05,
      "logits/chosen": -1.0393940210342407,
      "logits/rejected": -1.0695099830627441,
      "logps/chosen": -212.3219757080078,
      "logps/rejected": -249.9033203125,
      "loss": 0.2568,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -4.69191312789917,
      "rewards/margins": 2.154660940170288,
      "rewards/rejected": -6.846573829650879,
      "step": 6740
    },
    {
      "epoch": 2.0092275636255397,
      "grad_norm": 3.4843997955322266,
      "learning_rate": 4.830279363172124e-05,
      "logits/chosen": -0.9998032450675964,
      "logits/rejected": -1.1227643489837646,
      "logps/chosen": -196.87002563476562,
      "logps/rejected": -246.9526824951172,
      "loss": 0.2424,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -4.454354286193848,
      "rewards/margins": 2.460965633392334,
      "rewards/rejected": -6.915318965911865,
      "step": 6750
    },
    {
      "epoch": 2.012204197053133,
      "grad_norm": 4.421919345855713,
      "learning_rate": 4.8254731150495646e-05,
      "logits/chosen": -1.0377132892608643,
      "logits/rejected": -1.0440946817398071,
      "logps/chosen": -228.260986328125,
      "logps/rejected": -266.38458251953125,
      "loss": 0.2323,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -4.90640926361084,
      "rewards/margins": 2.8477585315704346,
      "rewards/rejected": -7.754168510437012,
      "step": 6760
    },
    {
      "epoch": 2.0151808304807264,
      "grad_norm": 5.650359153747559,
      "learning_rate": 4.820666866927005e-05,
      "logits/chosen": -0.9981106519699097,
      "logits/rejected": -1.0047165155410767,
      "logps/chosen": -210.61740112304688,
      "logps/rejected": -250.45864868164062,
      "loss": 0.2359,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -3.8976948261260986,
      "rewards/margins": 2.612417697906494,
      "rewards/rejected": -6.5101118087768555,
      "step": 6770
    },
    {
      "epoch": 2.0181574639083197,
      "grad_norm": 1.9534168243408203,
      "learning_rate": 4.815860618804446e-05,
      "logits/chosen": -0.9055618047714233,
      "logits/rejected": -0.9710069894790649,
      "logps/chosen": -209.1455535888672,
      "logps/rejected": -254.68795776367188,
      "loss": 0.2171,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.9615702629089355,
      "rewards/margins": 3.093188524246216,
      "rewards/rejected": -7.054758548736572,
      "step": 6780
    },
    {
      "epoch": 2.021134097335913,
      "grad_norm": 2.3304526805877686,
      "learning_rate": 4.811054370681887e-05,
      "logits/chosen": -0.9273804426193237,
      "logits/rejected": -0.8720032572746277,
      "logps/chosen": -226.80123901367188,
      "logps/rejected": -240.3706817626953,
      "loss": 0.2407,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.09214448928833,
      "rewards/margins": 2.4190258979797363,
      "rewards/rejected": -6.511170387268066,
      "step": 6790
    },
    {
      "epoch": 2.0241107307635064,
      "grad_norm": 9.995476722717285,
      "learning_rate": 4.806248122559328e-05,
      "logits/chosen": -0.8768268823623657,
      "logits/rejected": -0.7746760249137878,
      "logps/chosen": -256.6694641113281,
      "logps/rejected": -266.5936279296875,
      "loss": 0.205,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.636662006378174,
      "rewards/margins": 2.5106935501098633,
      "rewards/rejected": -8.147356033325195,
      "step": 6800
    },
    {
      "epoch": 2.0270873641911,
      "grad_norm": 5.023653984069824,
      "learning_rate": 4.8014418744367683e-05,
      "logits/chosen": -0.9519774317741394,
      "logits/rejected": -0.9471400380134583,
      "logps/chosen": -224.36294555664062,
      "logps/rejected": -255.89620971679688,
      "loss": 0.3073,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -5.042962074279785,
      "rewards/margins": 2.554266929626465,
      "rewards/rejected": -7.59722900390625,
      "step": 6810
    },
    {
      "epoch": 2.030063997618693,
      "grad_norm": 4.5217671394348145,
      "learning_rate": 4.796635626314209e-05,
      "logits/chosen": -0.8284792900085449,
      "logits/rejected": -0.9161784052848816,
      "logps/chosen": -208.0080108642578,
      "logps/rejected": -242.69314575195312,
      "loss": 0.2954,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.177313804626465,
      "rewards/margins": 2.4233477115631104,
      "rewards/rejected": -7.600660800933838,
      "step": 6820
    },
    {
      "epoch": 2.0330406310462865,
      "grad_norm": 5.210659503936768,
      "learning_rate": 4.7918293781916496e-05,
      "logits/chosen": -0.7471047639846802,
      "logits/rejected": -0.7532001733779907,
      "logps/chosen": -230.826171875,
      "logps/rejected": -267.9317932128906,
      "loss": 0.2446,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.408759117126465,
      "rewards/margins": 2.9896116256713867,
      "rewards/rejected": -8.398370742797852,
      "step": 6830
    },
    {
      "epoch": 2.03601726447388,
      "grad_norm": 4.744000434875488,
      "learning_rate": 4.787023130069091e-05,
      "logits/chosen": -0.7447320222854614,
      "logits/rejected": -0.7676731944084167,
      "logps/chosen": -236.95755004882812,
      "logps/rejected": -287.4554443359375,
      "loss": 0.2006,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.526132106781006,
      "rewards/margins": 3.4856553077697754,
      "rewards/rejected": -9.011787414550781,
      "step": 6840
    },
    {
      "epoch": 2.0389938979014732,
      "grad_norm": 12.60563850402832,
      "learning_rate": 4.78221688194653e-05,
      "logits/chosen": -0.6394303441047668,
      "logits/rejected": -0.6072821617126465,
      "logps/chosen": -240.8624725341797,
      "logps/rejected": -258.2088317871094,
      "loss": 0.3088,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -6.6788330078125,
      "rewards/margins": 2.438246250152588,
      "rewards/rejected": -9.11707878112793,
      "step": 6850
    },
    {
      "epoch": 2.041970531329067,
      "grad_norm": 4.22967004776001,
      "learning_rate": 4.7774106338239714e-05,
      "logits/chosen": -0.7323123812675476,
      "logits/rejected": -0.7425022125244141,
      "logps/chosen": -227.93359375,
      "logps/rejected": -254.46963500976562,
      "loss": 0.2878,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.385415077209473,
      "rewards/margins": 2.776458263397217,
      "rewards/rejected": -8.161873817443848,
      "step": 6860
    },
    {
      "epoch": 2.0449471647566604,
      "grad_norm": 8.205995559692383,
      "learning_rate": 4.772604385701412e-05,
      "logits/chosen": -0.8287402391433716,
      "logits/rejected": -0.7934919595718384,
      "logps/chosen": -232.1124725341797,
      "logps/rejected": -264.5063171386719,
      "loss": 0.2636,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -5.6171793937683105,
      "rewards/margins": 2.8478596210479736,
      "rewards/rejected": -8.465039253234863,
      "step": 6870
    },
    {
      "epoch": 2.0479237981842537,
      "grad_norm": 4.046397686004639,
      "learning_rate": 4.7677981375788526e-05,
      "logits/chosen": -0.7836447954177856,
      "logits/rejected": -0.7926181554794312,
      "logps/chosen": -214.51953125,
      "logps/rejected": -244.3509521484375,
      "loss": 0.2431,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -4.845687389373779,
      "rewards/margins": 2.6731836795806885,
      "rewards/rejected": -7.518871307373047,
      "step": 6880
    },
    {
      "epoch": 2.050900431611847,
      "grad_norm": 2.678053855895996,
      "learning_rate": 4.762991889456293e-05,
      "logits/chosen": -0.6766976714134216,
      "logits/rejected": -0.7792876958847046,
      "logps/chosen": -208.3757781982422,
      "logps/rejected": -250.61380004882812,
      "loss": 0.1613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.475132942199707,
      "rewards/margins": 2.7595458030700684,
      "rewards/rejected": -8.234678268432617,
      "step": 6890
    },
    {
      "epoch": 2.0538770650394405,
      "grad_norm": 4.782326698303223,
      "learning_rate": 4.758185641333734e-05,
      "logits/chosen": -0.7321763634681702,
      "logits/rejected": -0.8204339742660522,
      "logps/chosen": -246.4103240966797,
      "logps/rejected": -286.0997619628906,
      "loss": 0.3073,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.705233573913574,
      "rewards/margins": 2.597515344619751,
      "rewards/rejected": -9.302748680114746,
      "step": 6900
    },
    {
      "epoch": 2.056853698467034,
      "grad_norm": 4.404498100280762,
      "learning_rate": 4.753379393211175e-05,
      "logits/chosen": -0.864951491355896,
      "logits/rejected": -0.9310558438301086,
      "logps/chosen": -242.9060516357422,
      "logps/rejected": -278.2928161621094,
      "loss": 0.1867,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.778449058532715,
      "rewards/margins": 2.7309765815734863,
      "rewards/rejected": -8.509425163269043,
      "step": 6910
    },
    {
      "epoch": 2.059830331894627,
      "grad_norm": 3.405888080596924,
      "learning_rate": 4.748573145088616e-05,
      "logits/chosen": -0.9142965078353882,
      "logits/rejected": -1.0617066621780396,
      "logps/chosen": -225.04037475585938,
      "logps/rejected": -283.1331787109375,
      "loss": 0.2824,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.630393028259277,
      "rewards/margins": 2.910628318786621,
      "rewards/rejected": -8.541021347045898,
      "step": 6920
    },
    {
      "epoch": 2.0628069653222205,
      "grad_norm": 3.644927740097046,
      "learning_rate": 4.7437668969660564e-05,
      "logits/chosen": -0.9660176038742065,
      "logits/rejected": -0.9421710968017578,
      "logps/chosen": -228.4074249267578,
      "logps/rejected": -252.13735961914062,
      "loss": 0.2339,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -4.714961528778076,
      "rewards/margins": 2.429356098175049,
      "rewards/rejected": -7.144317626953125,
      "step": 6930
    },
    {
      "epoch": 2.065783598749814,
      "grad_norm": 7.4013471603393555,
      "learning_rate": 4.738960648843497e-05,
      "logits/chosen": -0.9589084386825562,
      "logits/rejected": -1.0224398374557495,
      "logps/chosen": -223.6455841064453,
      "logps/rejected": -258.92852783203125,
      "loss": 0.288,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.171360015869141,
      "rewards/margins": 2.5770905017852783,
      "rewards/rejected": -7.74845027923584,
      "step": 6940
    },
    {
      "epoch": 2.0687602321774072,
      "grad_norm": 8.92702865600586,
      "learning_rate": 4.7341544007209376e-05,
      "logits/chosen": -1.0156127214431763,
      "logits/rejected": -1.0130459070205688,
      "logps/chosen": -233.38705444335938,
      "logps/rejected": -263.9423828125,
      "loss": 0.2023,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.342015266418457,
      "rewards/margins": 2.626427173614502,
      "rewards/rejected": -7.968441963195801,
      "step": 6950
    },
    {
      "epoch": 2.0717368656050006,
      "grad_norm": 3.618689775466919,
      "learning_rate": 4.729348152598379e-05,
      "logits/chosen": -0.8503873944282532,
      "logits/rejected": -0.943753719329834,
      "logps/chosen": -222.13525390625,
      "logps/rejected": -269.8484191894531,
      "loss": 0.1593,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.05379581451416,
      "rewards/margins": 3.307518720626831,
      "rewards/rejected": -8.36131477355957,
      "step": 6960
    },
    {
      "epoch": 2.074713499032594,
      "grad_norm": 3.8880815505981445,
      "learning_rate": 4.724541904475818e-05,
      "logits/chosen": -0.8555718660354614,
      "logits/rejected": -0.8822164535522461,
      "logps/chosen": -222.099365234375,
      "logps/rejected": -255.48544311523438,
      "loss": 0.1731,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.319037437438965,
      "rewards/margins": 3.1796000003814697,
      "rewards/rejected": -8.498637199401855,
      "step": 6970
    },
    {
      "epoch": 2.0776901324601873,
      "grad_norm": 4.896745204925537,
      "learning_rate": 4.7197356563532595e-05,
      "logits/chosen": -0.9087221026420593,
      "logits/rejected": -0.8809015154838562,
      "logps/chosen": -205.73025512695312,
      "logps/rejected": -240.61972045898438,
      "loss": 0.2563,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -4.990902423858643,
      "rewards/margins": 2.560213327407837,
      "rewards/rejected": -7.5511155128479,
      "step": 6980
    },
    {
      "epoch": 2.080666765887781,
      "grad_norm": 8.4346284866333,
      "learning_rate": 4.7149294082307e-05,
      "logits/chosen": -0.9681816101074219,
      "logits/rejected": -1.0807926654815674,
      "logps/chosen": -238.72024536132812,
      "logps/rejected": -298.1727600097656,
      "loss": 0.1808,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.245665073394775,
      "rewards/margins": 3.487046003341675,
      "rewards/rejected": -9.732711791992188,
      "step": 6990
    },
    {
      "epoch": 2.0836433993153745,
      "grad_norm": 14.750201225280762,
      "learning_rate": 4.710123160108141e-05,
      "logits/chosen": -0.873473048210144,
      "logits/rejected": -0.9249376058578491,
      "logps/chosen": -248.4402618408203,
      "logps/rejected": -292.4382019042969,
      "loss": 0.257,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.865701198577881,
      "rewards/margins": 3.3853917121887207,
      "rewards/rejected": -10.251092910766602,
      "step": 7000
    },
    {
      "epoch": 2.086620032742968,
      "grad_norm": 1.4645600318908691,
      "learning_rate": 4.705316911985581e-05,
      "logits/chosen": -0.9733689427375793,
      "logits/rejected": -0.8555242419242859,
      "logps/chosen": -226.0706329345703,
      "logps/rejected": -242.9854278564453,
      "loss": 0.1761,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -4.620716571807861,
      "rewards/margins": 2.9640698432922363,
      "rewards/rejected": -7.584786891937256,
      "step": 7010
    },
    {
      "epoch": 2.089596666170561,
      "grad_norm": 13.868948936462402,
      "learning_rate": 4.700510663863022e-05,
      "logits/chosen": -0.7921064496040344,
      "logits/rejected": -0.8269727826118469,
      "logps/chosen": -225.597900390625,
      "logps/rejected": -261.326904296875,
      "loss": 0.2947,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.175344467163086,
      "rewards/margins": 2.785618543624878,
      "rewards/rejected": -8.960962295532227,
      "step": 7020
    },
    {
      "epoch": 2.0925732995981545,
      "grad_norm": 2.926546096801758,
      "learning_rate": 4.695704415740463e-05,
      "logits/chosen": -0.8746669888496399,
      "logits/rejected": -0.8976143002510071,
      "logps/chosen": -244.37948608398438,
      "logps/rejected": -276.07574462890625,
      "loss": 0.2713,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.960302352905273,
      "rewards/margins": 2.3578457832336426,
      "rewards/rejected": -8.318148612976074,
      "step": 7030
    },
    {
      "epoch": 2.095549933025748,
      "grad_norm": 5.532979965209961,
      "learning_rate": 4.690898167617904e-05,
      "logits/chosen": -0.9411019086837769,
      "logits/rejected": -0.9334419369697571,
      "logps/chosen": -217.15072631835938,
      "logps/rejected": -247.25015258789062,
      "loss": 0.2409,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -4.738151550292969,
      "rewards/margins": 2.388721466064453,
      "rewards/rejected": -7.126873016357422,
      "step": 7040
    },
    {
      "epoch": 2.0985265664533412,
      "grad_norm": 5.393617153167725,
      "learning_rate": 4.6860919194953445e-05,
      "logits/chosen": -0.7954815626144409,
      "logits/rejected": -0.7926744222640991,
      "logps/chosen": -225.50509643554688,
      "logps/rejected": -259.4455261230469,
      "loss": 0.215,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.221548080444336,
      "rewards/margins": 3.1115543842315674,
      "rewards/rejected": -8.333102226257324,
      "step": 7050
    },
    {
      "epoch": 2.1015031998809346,
      "grad_norm": 0.8258939981460571,
      "learning_rate": 4.681285671372785e-05,
      "logits/chosen": -0.7342342138290405,
      "logits/rejected": -0.6693004369735718,
      "logps/chosen": -240.09774780273438,
      "logps/rejected": -274.1280822753906,
      "loss": 0.2159,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.862774848937988,
      "rewards/margins": 2.843726634979248,
      "rewards/rejected": -8.706502914428711,
      "step": 7060
    },
    {
      "epoch": 2.104479833308528,
      "grad_norm": 2.39616322517395,
      "learning_rate": 4.676479423250226e-05,
      "logits/chosen": -0.5533229112625122,
      "logits/rejected": -0.637627124786377,
      "logps/chosen": -227.74325561523438,
      "logps/rejected": -277.1457214355469,
      "loss": 0.2654,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.207206726074219,
      "rewards/margins": 2.8136260509490967,
      "rewards/rejected": -9.020833015441895,
      "step": 7070
    },
    {
      "epoch": 2.1074564667361213,
      "grad_norm": 2.1403660774230957,
      "learning_rate": 4.671673175127667e-05,
      "logits/chosen": -0.6128817200660706,
      "logits/rejected": -0.7775971293449402,
      "logps/chosen": -229.65176391601562,
      "logps/rejected": -287.41326904296875,
      "loss": 0.2189,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.31779146194458,
      "rewards/margins": 3.194958209991455,
      "rewards/rejected": -9.512748718261719,
      "step": 7080
    },
    {
      "epoch": 2.1104331001637147,
      "grad_norm": 3.968334913253784,
      "learning_rate": 4.6668669270051076e-05,
      "logits/chosen": -0.5670629143714905,
      "logits/rejected": -0.7136070728302002,
      "logps/chosen": -225.051513671875,
      "logps/rejected": -276.642578125,
      "loss": 0.2428,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.322340488433838,
      "rewards/margins": 3.1048176288604736,
      "rewards/rejected": -9.42715835571289,
      "step": 7090
    },
    {
      "epoch": 2.1134097335913085,
      "grad_norm": 6.77924108505249,
      "learning_rate": 4.6620606788825475e-05,
      "logits/chosen": -0.5186029672622681,
      "logits/rejected": -0.4953940510749817,
      "logps/chosen": -232.22494506835938,
      "logps/rejected": -270.8237609863281,
      "loss": 0.2291,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.920950412750244,
      "rewards/margins": 3.1229376792907715,
      "rewards/rejected": -10.043889045715332,
      "step": 7100
    },
    {
      "epoch": 2.116386367018902,
      "grad_norm": 5.344362258911133,
      "learning_rate": 4.657254430759988e-05,
      "logits/chosen": -0.6234628558158875,
      "logits/rejected": -0.6201885938644409,
      "logps/chosen": -245.93344116210938,
      "logps/rejected": -271.9517517089844,
      "loss": 0.3107,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.534054756164551,
      "rewards/margins": 2.5026321411132812,
      "rewards/rejected": -9.036687850952148,
      "step": 7110
    },
    {
      "epoch": 2.119363000446495,
      "grad_norm": 6.550627708435059,
      "learning_rate": 4.652448182637429e-05,
      "logits/chosen": -0.7903640866279602,
      "logits/rejected": -0.8268726468086243,
      "logps/chosen": -236.5895233154297,
      "logps/rejected": -269.2236328125,
      "loss": 0.2514,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.291239261627197,
      "rewards/margins": 2.669090986251831,
      "rewards/rejected": -8.960330963134766,
      "step": 7120
    },
    {
      "epoch": 2.1223396338740885,
      "grad_norm": 8.306700706481934,
      "learning_rate": 4.6476419345148694e-05,
      "logits/chosen": -0.6912389993667603,
      "logits/rejected": -0.8331298828125,
      "logps/chosen": -236.07870483398438,
      "logps/rejected": -298.7451171875,
      "loss": 0.2677,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.8083906173706055,
      "rewards/margins": 3.275635242462158,
      "rewards/rejected": -9.084024429321289,
      "step": 7130
    },
    {
      "epoch": 2.125316267301682,
      "grad_norm": 5.00970983505249,
      "learning_rate": 4.64283568639231e-05,
      "logits/chosen": -0.687637209892273,
      "logits/rejected": -0.753862738609314,
      "logps/chosen": -234.390380859375,
      "logps/rejected": -281.9366149902344,
      "loss": 0.207,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.527628421783447,
      "rewards/margins": 3.299274444580078,
      "rewards/rejected": -9.826902389526367,
      "step": 7140
    },
    {
      "epoch": 2.1282929007292752,
      "grad_norm": 3.6034133434295654,
      "learning_rate": 4.638029438269751e-05,
      "logits/chosen": -0.7365237474441528,
      "logits/rejected": -0.6635974645614624,
      "logps/chosen": -247.43814086914062,
      "logps/rejected": -278.71221923828125,
      "loss": 0.2003,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.9273786544799805,
      "rewards/margins": 3.3435261249542236,
      "rewards/rejected": -10.270905494689941,
      "step": 7150
    },
    {
      "epoch": 2.1312695341568686,
      "grad_norm": 6.793529033660889,
      "learning_rate": 4.633223190147192e-05,
      "logits/chosen": -0.8229132890701294,
      "logits/rejected": -0.8828161358833313,
      "logps/chosen": -213.82907104492188,
      "logps/rejected": -244.8444366455078,
      "loss": 0.3024,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.238215446472168,
      "rewards/margins": 2.2685303688049316,
      "rewards/rejected": -7.5067458152771,
      "step": 7160
    },
    {
      "epoch": 2.134246167584462,
      "grad_norm": 5.455910682678223,
      "learning_rate": 4.6284169420246325e-05,
      "logits/chosen": -0.9326960444450378,
      "logits/rejected": -0.885299563407898,
      "logps/chosen": -237.1294708251953,
      "logps/rejected": -260.8902893066406,
      "loss": 0.2177,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.384009838104248,
      "rewards/margins": 2.7045185565948486,
      "rewards/rejected": -8.088528633117676,
      "step": 7170
    },
    {
      "epoch": 2.1372228010120553,
      "grad_norm": 4.548612117767334,
      "learning_rate": 4.623610693902073e-05,
      "logits/chosen": -0.9013687968254089,
      "logits/rejected": -1.0072695016860962,
      "logps/chosen": -220.5884552001953,
      "logps/rejected": -261.83856201171875,
      "loss": 0.2547,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.73225212097168,
      "rewards/margins": 2.582014799118042,
      "rewards/rejected": -8.3142671585083,
      "step": 7180
    },
    {
      "epoch": 2.1401994344396487,
      "grad_norm": 5.0219011306762695,
      "learning_rate": 4.618804445779514e-05,
      "logits/chosen": -0.8653416633605957,
      "logits/rejected": -0.9699785113334656,
      "logps/chosen": -230.58004760742188,
      "logps/rejected": -274.28326416015625,
      "loss": 0.3314,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -5.63150691986084,
      "rewards/margins": 3.332319736480713,
      "rewards/rejected": -8.963827133178711,
      "step": 7190
    },
    {
      "epoch": 2.143176067867242,
      "grad_norm": 7.445830821990967,
      "learning_rate": 4.613998197656955e-05,
      "logits/chosen": -0.8697279095649719,
      "logits/rejected": -0.8241435885429382,
      "logps/chosen": -239.712646484375,
      "logps/rejected": -268.7230529785156,
      "loss": 0.216,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.043058395385742,
      "rewards/margins": 2.972769260406494,
      "rewards/rejected": -9.015828132629395,
      "step": 7200
    },
    {
      "epoch": 2.1461527012948354,
      "grad_norm": 10.273040771484375,
      "learning_rate": 4.6091919495343956e-05,
      "logits/chosen": -0.713362455368042,
      "logits/rejected": -0.8300623893737793,
      "logps/chosen": -222.0362091064453,
      "logps/rejected": -273.9424133300781,
      "loss": 0.2301,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.215035915374756,
      "rewards/margins": 2.847428560256958,
      "rewards/rejected": -9.062463760375977,
      "step": 7210
    },
    {
      "epoch": 2.1491293347224287,
      "grad_norm": 8.244292259216309,
      "learning_rate": 4.6043857014118356e-05,
      "logits/chosen": -0.6490418314933777,
      "logits/rejected": -0.7459266781806946,
      "logps/chosen": -235.4239044189453,
      "logps/rejected": -267.3975830078125,
      "loss": 0.2342,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.465517997741699,
      "rewards/margins": 2.8455567359924316,
      "rewards/rejected": -9.311075210571289,
      "step": 7220
    },
    {
      "epoch": 2.1521059681500225,
      "grad_norm": 2.6129331588745117,
      "learning_rate": 4.599579453289276e-05,
      "logits/chosen": -0.6696256399154663,
      "logits/rejected": -0.7257509231567383,
      "logps/chosen": -252.3833465576172,
      "logps/rejected": -310.27587890625,
      "loss": 0.1744,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.440488338470459,
      "rewards/margins": 3.6402690410614014,
      "rewards/rejected": -10.080758094787598,
      "step": 7230
    },
    {
      "epoch": 2.155082601577616,
      "grad_norm": 13.19599437713623,
      "learning_rate": 4.594773205166717e-05,
      "logits/chosen": -0.754361629486084,
      "logits/rejected": -0.700925350189209,
      "logps/chosen": -238.19973754882812,
      "logps/rejected": -261.91217041015625,
      "loss": 0.3797,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.31461238861084,
      "rewards/margins": 2.6565256118774414,
      "rewards/rejected": -7.971138000488281,
      "step": 7240
    },
    {
      "epoch": 2.1580592350052092,
      "grad_norm": 5.290023326873779,
      "learning_rate": 4.5899669570441574e-05,
      "logits/chosen": -0.7126718163490295,
      "logits/rejected": -0.699087381362915,
      "logps/chosen": -228.88058471679688,
      "logps/rejected": -258.0765686035156,
      "loss": 0.2878,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -5.430178642272949,
      "rewards/margins": 2.516481399536133,
      "rewards/rejected": -7.94666051864624,
      "step": 7250
    },
    {
      "epoch": 2.1610358684328026,
      "grad_norm": 6.355810165405273,
      "learning_rate": 4.585160708921598e-05,
      "logits/chosen": -0.6544567346572876,
      "logits/rejected": -0.8224486112594604,
      "logps/chosen": -239.5699920654297,
      "logps/rejected": -306.2498474121094,
      "loss": 0.2019,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.5645599365234375,
      "rewards/margins": 3.0695676803588867,
      "rewards/rejected": -9.634129524230957,
      "step": 7260
    },
    {
      "epoch": 2.164012501860396,
      "grad_norm": 3.046978712081909,
      "learning_rate": 4.580354460799039e-05,
      "logits/chosen": -0.6469134092330933,
      "logits/rejected": -0.6160798072814941,
      "logps/chosen": -243.2045135498047,
      "logps/rejected": -262.2032165527344,
      "loss": 0.2586,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.102955341339111,
      "rewards/margins": 2.7422232627868652,
      "rewards/rejected": -8.845178604125977,
      "step": 7270
    },
    {
      "epoch": 2.1669891352879893,
      "grad_norm": 2.025120496749878,
      "learning_rate": 4.57554821267648e-05,
      "logits/chosen": -0.6525744199752808,
      "logits/rejected": -0.6546115279197693,
      "logps/chosen": -241.6601104736328,
      "logps/rejected": -283.168212890625,
      "loss": 0.1965,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.866494178771973,
      "rewards/margins": 3.294116973876953,
      "rewards/rejected": -10.160611152648926,
      "step": 7280
    },
    {
      "epoch": 2.1699657687155827,
      "grad_norm": 5.073836326599121,
      "learning_rate": 4.5707419645539206e-05,
      "logits/chosen": -0.5233343839645386,
      "logits/rejected": -0.6412903070449829,
      "logps/chosen": -242.1357421875,
      "logps/rejected": -290.7659606933594,
      "loss": 0.2363,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.08944845199585,
      "rewards/margins": 3.337313175201416,
      "rewards/rejected": -10.426762580871582,
      "step": 7290
    },
    {
      "epoch": 2.172942402143176,
      "grad_norm": 3.5012125968933105,
      "learning_rate": 4.565935716431361e-05,
      "logits/chosen": -0.7249504327774048,
      "logits/rejected": -0.809585690498352,
      "logps/chosen": -237.7661895751953,
      "logps/rejected": -281.45977783203125,
      "loss": 0.3174,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.775840759277344,
      "rewards/margins": 2.6989076137542725,
      "rewards/rejected": -9.474747657775879,
      "step": 7300
    },
    {
      "epoch": 2.1759190355707694,
      "grad_norm": 3.1607658863067627,
      "learning_rate": 4.561129468308802e-05,
      "logits/chosen": -0.8483607172966003,
      "logits/rejected": -0.8035635948181152,
      "logps/chosen": -263.81207275390625,
      "logps/rejected": -284.9578552246094,
      "loss": 0.4216,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -7.329782009124756,
      "rewards/margins": 2.370744228363037,
      "rewards/rejected": -9.70052719116211,
      "step": 7310
    },
    {
      "epoch": 2.1788956689983627,
      "grad_norm": 5.575445652008057,
      "learning_rate": 4.556323220186243e-05,
      "logits/chosen": -0.9204357266426086,
      "logits/rejected": -0.9799977540969849,
      "logps/chosen": -232.5540008544922,
      "logps/rejected": -266.66265869140625,
      "loss": 0.2554,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.222077369689941,
      "rewards/margins": 2.5893826484680176,
      "rewards/rejected": -8.811460494995117,
      "step": 7320
    },
    {
      "epoch": 2.181872302425956,
      "grad_norm": 6.080098628997803,
      "learning_rate": 4.551516972063684e-05,
      "logits/chosen": -0.9863424301147461,
      "logits/rejected": -0.9316117167472839,
      "logps/chosen": -229.894287109375,
      "logps/rejected": -244.55252075195312,
      "loss": 0.3244,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.364596843719482,
      "rewards/margins": 2.213503360748291,
      "rewards/rejected": -7.578099727630615,
      "step": 7330
    },
    {
      "epoch": 2.1848489358535494,
      "grad_norm": 3.2244226932525635,
      "learning_rate": 4.5467107239411236e-05,
      "logits/chosen": -1.0044413805007935,
      "logits/rejected": -1.035518765449524,
      "logps/chosen": -206.73257446289062,
      "logps/rejected": -243.5690155029297,
      "loss": 0.2664,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.470213890075684,
      "rewards/margins": 2.3664050102233887,
      "rewards/rejected": -7.836618900299072,
      "step": 7340
    },
    {
      "epoch": 2.1878255692811432,
      "grad_norm": 3.7074620723724365,
      "learning_rate": 4.541904475818564e-05,
      "logits/chosen": -0.9141491055488586,
      "logits/rejected": -0.9887884259223938,
      "logps/chosen": -250.0056915283203,
      "logps/rejected": -299.9334411621094,
      "loss": 0.1785,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.645254611968994,
      "rewards/margins": 3.2242438793182373,
      "rewards/rejected": -9.869499206542969,
      "step": 7350
    },
    {
      "epoch": 2.1908022027087366,
      "grad_norm": 2.408392906188965,
      "learning_rate": 4.537098227696005e-05,
      "logits/chosen": -0.9456449747085571,
      "logits/rejected": -1.0242364406585693,
      "logps/chosen": -225.41024780273438,
      "logps/rejected": -283.5874328613281,
      "loss": 0.2382,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.3474440574646,
      "rewards/margins": 3.253143787384033,
      "rewards/rejected": -8.600587844848633,
      "step": 7360
    },
    {
      "epoch": 2.19377883613633,
      "grad_norm": 6.983366012573242,
      "learning_rate": 4.5322919795734455e-05,
      "logits/chosen": -0.9233323931694031,
      "logits/rejected": -0.9146817326545715,
      "logps/chosen": -240.6273956298828,
      "logps/rejected": -271.0935974121094,
      "loss": 0.2833,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -5.472516059875488,
      "rewards/margins": 2.7366697788238525,
      "rewards/rejected": -8.209184646606445,
      "step": 7370
    },
    {
      "epoch": 2.1967554695639233,
      "grad_norm": 2.775749683380127,
      "learning_rate": 4.527485731450887e-05,
      "logits/chosen": -1.0939357280731201,
      "logits/rejected": -0.8993927836418152,
      "logps/chosen": -226.9051055908203,
      "logps/rejected": -233.06826782226562,
      "loss": 0.2503,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -4.504876613616943,
      "rewards/margins": 2.427011251449585,
      "rewards/rejected": -6.931888580322266,
      "step": 7380
    },
    {
      "epoch": 2.1997321029915167,
      "grad_norm": 2.4823153018951416,
      "learning_rate": 4.5226794833283274e-05,
      "logits/chosen": -0.9621703028678894,
      "logits/rejected": -0.9455770254135132,
      "logps/chosen": -226.1719512939453,
      "logps/rejected": -249.75778198242188,
      "loss": 0.2932,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -4.203949928283691,
      "rewards/margins": 2.2157604694366455,
      "rewards/rejected": -6.4197096824646,
      "step": 7390
    },
    {
      "epoch": 2.20270873641911,
      "grad_norm": 5.1721343994140625,
      "learning_rate": 4.517873235205768e-05,
      "logits/chosen": -0.8593694567680359,
      "logits/rejected": -0.8676276206970215,
      "logps/chosen": -208.95266723632812,
      "logps/rejected": -250.8795928955078,
      "loss": 0.2047,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.129449367523193,
      "rewards/margins": 2.864882469177246,
      "rewards/rejected": -7.994331359863281,
      "step": 7400
    },
    {
      "epoch": 2.2056853698467034,
      "grad_norm": 11.524815559387207,
      "learning_rate": 4.5130669870832086e-05,
      "logits/chosen": -0.958344578742981,
      "logits/rejected": -0.9724551439285278,
      "logps/chosen": -242.53652954101562,
      "logps/rejected": -273.8931579589844,
      "loss": 0.2406,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.6820526123046875,
      "rewards/margins": 2.6269049644470215,
      "rewards/rejected": -8.308958053588867,
      "step": 7410
    },
    {
      "epoch": 2.2086620032742967,
      "grad_norm": 7.995443344116211,
      "learning_rate": 4.508260738960649e-05,
      "logits/chosen": -0.885650634765625,
      "logits/rejected": -0.8962454795837402,
      "logps/chosen": -229.06356811523438,
      "logps/rejected": -267.61090087890625,
      "loss": 0.2065,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.989915370941162,
      "rewards/margins": 2.744555950164795,
      "rewards/rejected": -8.734471321105957,
      "step": 7420
    },
    {
      "epoch": 2.21163863670189,
      "grad_norm": 6.411810398101807,
      "learning_rate": 4.50345449083809e-05,
      "logits/chosen": -0.7640453577041626,
      "logits/rejected": -0.90227872133255,
      "logps/chosen": -227.03579711914062,
      "logps/rejected": -280.49078369140625,
      "loss": 0.269,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.034468173980713,
      "rewards/margins": 3.0934441089630127,
      "rewards/rejected": -9.127912521362305,
      "step": 7430
    },
    {
      "epoch": 2.2146152701294834,
      "grad_norm": 8.311295509338379,
      "learning_rate": 4.498648242715531e-05,
      "logits/chosen": -0.8398404121398926,
      "logits/rejected": -0.8857324719429016,
      "logps/chosen": -237.56787109375,
      "logps/rejected": -269.4236145019531,
      "loss": 0.2282,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.210257530212402,
      "rewards/margins": 2.9332990646362305,
      "rewards/rejected": -8.143556594848633,
      "step": 7440
    },
    {
      "epoch": 2.217591903557077,
      "grad_norm": 1.0324175357818604,
      "learning_rate": 4.493841994592972e-05,
      "logits/chosen": -0.6932796239852905,
      "logits/rejected": -0.7831157445907593,
      "logps/chosen": -232.29171752929688,
      "logps/rejected": -283.35614013671875,
      "loss": 0.1805,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.998778820037842,
      "rewards/margins": 3.354600191116333,
      "rewards/rejected": -9.353378295898438,
      "step": 7450
    },
    {
      "epoch": 2.22056853698467,
      "grad_norm": 24.012826919555664,
      "learning_rate": 4.489035746470412e-05,
      "logits/chosen": -0.8005752563476562,
      "logits/rejected": -0.828230082988739,
      "logps/chosen": -241.2596435546875,
      "logps/rejected": -274.725830078125,
      "loss": 0.3191,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -7.061420440673828,
      "rewards/margins": 3.1486356258392334,
      "rewards/rejected": -10.210055351257324,
      "step": 7460
    },
    {
      "epoch": 2.2235451704122635,
      "grad_norm": 8.57250690460205,
      "learning_rate": 4.484229498347852e-05,
      "logits/chosen": -0.7480868101119995,
      "logits/rejected": -0.6833415031433105,
      "logps/chosen": -238.496337890625,
      "logps/rejected": -261.10662841796875,
      "loss": 0.2844,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.672466278076172,
      "rewards/margins": 2.7293434143066406,
      "rewards/rejected": -9.401809692382812,
      "step": 7470
    },
    {
      "epoch": 2.2265218038398573,
      "grad_norm": 6.584680557250977,
      "learning_rate": 4.479423250225293e-05,
      "logits/chosen": -0.6879044771194458,
      "logits/rejected": -0.7247816324234009,
      "logps/chosen": -227.06546020507812,
      "logps/rejected": -265.7701110839844,
      "loss": 0.204,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.817241191864014,
      "rewards/margins": 3.2238993644714355,
      "rewards/rejected": -9.04114055633545,
      "step": 7480
    },
    {
      "epoch": 2.2294984372674507,
      "grad_norm": 13.249794960021973,
      "learning_rate": 4.4746170021027335e-05,
      "logits/chosen": -0.8439725041389465,
      "logits/rejected": -0.8088820576667786,
      "logps/chosen": -247.9132537841797,
      "logps/rejected": -275.5690002441406,
      "loss": 0.3849,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -6.4245147705078125,
      "rewards/margins": 2.609442949295044,
      "rewards/rejected": -9.033957481384277,
      "step": 7490
    },
    {
      "epoch": 2.232475070695044,
      "grad_norm": 7.527966022491455,
      "learning_rate": 4.469810753980175e-05,
      "logits/chosen": -0.8156619071960449,
      "logits/rejected": -0.9115575551986694,
      "logps/chosen": -224.62094116210938,
      "logps/rejected": -273.96661376953125,
      "loss": 0.2296,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.870140552520752,
      "rewards/margins": 2.7683327198028564,
      "rewards/rejected": -8.638473510742188,
      "step": 7500
    },
    {
      "epoch": 2.2354517041226374,
      "grad_norm": 7.801366806030273,
      "learning_rate": 4.4650045058576154e-05,
      "logits/chosen": -0.8114508390426636,
      "logits/rejected": -0.8878215551376343,
      "logps/chosen": -215.7370147705078,
      "logps/rejected": -262.54608154296875,
      "loss": 0.232,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.689062118530273,
      "rewards/margins": 3.0944652557373047,
      "rewards/rejected": -8.783527374267578,
      "step": 7510
    },
    {
      "epoch": 2.2384283375502307,
      "grad_norm": 2.2834300994873047,
      "learning_rate": 4.460198257735056e-05,
      "logits/chosen": -0.7448588013648987,
      "logits/rejected": -0.8625596761703491,
      "logps/chosen": -230.2811737060547,
      "logps/rejected": -295.4375,
      "loss": 0.1711,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.614457607269287,
      "rewards/margins": 3.4649016857147217,
      "rewards/rejected": -10.07935905456543,
      "step": 7520
    },
    {
      "epoch": 2.241404970977824,
      "grad_norm": 5.04945182800293,
      "learning_rate": 4.455392009612497e-05,
      "logits/chosen": -0.7686911821365356,
      "logits/rejected": -0.9562965631484985,
      "logps/chosen": -240.38916015625,
      "logps/rejected": -293.2795104980469,
      "loss": 0.3257,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.139715671539307,
      "rewards/margins": 2.7260940074920654,
      "rewards/rejected": -8.865808486938477,
      "step": 7530
    },
    {
      "epoch": 2.2443816044054175,
      "grad_norm": 8.705528259277344,
      "learning_rate": 4.450585761489937e-05,
      "logits/chosen": -0.7258087396621704,
      "logits/rejected": -0.78258216381073,
      "logps/chosen": -231.1732940673828,
      "logps/rejected": -264.7855224609375,
      "loss": 0.288,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.3035359382629395,
      "rewards/margins": 2.9313530921936035,
      "rewards/rejected": -9.234889030456543,
      "step": 7540
    },
    {
      "epoch": 2.247358237833011,
      "grad_norm": 0.9376424551010132,
      "learning_rate": 4.445779513367378e-05,
      "logits/chosen": -0.9471322894096375,
      "logits/rejected": -0.8780769109725952,
      "logps/chosen": -223.28463745117188,
      "logps/rejected": -244.851806640625,
      "loss": 0.303,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -4.792492866516113,
      "rewards/margins": 2.5700185298919678,
      "rewards/rejected": -7.36251163482666,
      "step": 7550
    },
    {
      "epoch": 2.250334871260604,
      "grad_norm": 4.74177885055542,
      "learning_rate": 4.440973265244819e-05,
      "logits/chosen": -0.9580272436141968,
      "logits/rejected": -0.921512246131897,
      "logps/chosen": -235.8068084716797,
      "logps/rejected": -266.7616271972656,
      "loss": 0.2608,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.738248825073242,
      "rewards/margins": 2.8554868698120117,
      "rewards/rejected": -8.593735694885254,
      "step": 7560
    },
    {
      "epoch": 2.2533115046881975,
      "grad_norm": 4.885244369506836,
      "learning_rate": 4.43616701712226e-05,
      "logits/chosen": -0.9300775527954102,
      "logits/rejected": -0.9888219833374023,
      "logps/chosen": -227.45986938476562,
      "logps/rejected": -274.35858154296875,
      "loss": 0.2545,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.312863349914551,
      "rewards/margins": 2.937779188156128,
      "rewards/rejected": -8.250642776489258,
      "step": 7570
    },
    {
      "epoch": 2.256288138115791,
      "grad_norm": 4.950533866882324,
      "learning_rate": 4.4313607689997e-05,
      "logits/chosen": -0.9164720773696899,
      "logits/rejected": -0.9397482872009277,
      "logps/chosen": -227.47061157226562,
      "logps/rejected": -259.45220947265625,
      "loss": 0.2156,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.73286247253418,
      "rewards/margins": 2.6510796546936035,
      "rewards/rejected": -8.383941650390625,
      "step": 7580
    },
    {
      "epoch": 2.2592647715433847,
      "grad_norm": 6.483705997467041,
      "learning_rate": 4.4265545208771404e-05,
      "logits/chosen": -0.9016959071159363,
      "logits/rejected": -0.9586091041564941,
      "logps/chosen": -222.0322723388672,
      "logps/rejected": -273.37396240234375,
      "loss": 0.2266,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.085877418518066,
      "rewards/margins": 3.126014232635498,
      "rewards/rejected": -9.211891174316406,
      "step": 7590
    },
    {
      "epoch": 2.262241404970978,
      "grad_norm": 5.088005065917969,
      "learning_rate": 4.421748272754581e-05,
      "logits/chosen": -1.0080606937408447,
      "logits/rejected": -1.0160232782363892,
      "logps/chosen": -222.5441131591797,
      "logps/rejected": -251.47763061523438,
      "loss": 0.2992,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -4.8522562980651855,
      "rewards/margins": 2.40490460395813,
      "rewards/rejected": -7.2571611404418945,
      "step": 7600
    },
    {
      "epoch": 2.2652180383985714,
      "grad_norm": 8.391348838806152,
      "learning_rate": 4.4169420246320216e-05,
      "logits/chosen": -0.9445720911026001,
      "logits/rejected": -1.056018590927124,
      "logps/chosen": -236.22998046875,
      "logps/rejected": -291.76947021484375,
      "loss": 0.2706,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.999173164367676,
      "rewards/margins": 3.60188627243042,
      "rewards/rejected": -9.601058959960938,
      "step": 7610
    },
    {
      "epoch": 2.2681946718261647,
      "grad_norm": 3.2733047008514404,
      "learning_rate": 4.412135776509463e-05,
      "logits/chosen": -0.9584376215934753,
      "logits/rejected": -0.9287335276603699,
      "logps/chosen": -225.4986572265625,
      "logps/rejected": -246.1902313232422,
      "loss": 0.2398,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.492818832397461,
      "rewards/margins": 2.611978054046631,
      "rewards/rejected": -8.10479736328125,
      "step": 7620
    },
    {
      "epoch": 2.271171305253758,
      "grad_norm": 3.6396384239196777,
      "learning_rate": 4.4073295283869035e-05,
      "logits/chosen": -1.010601282119751,
      "logits/rejected": -0.930132269859314,
      "logps/chosen": -208.6885986328125,
      "logps/rejected": -235.38375854492188,
      "loss": 0.2489,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -4.910460472106934,
      "rewards/margins": 2.8019540309906006,
      "rewards/rejected": -7.712413787841797,
      "step": 7630
    },
    {
      "epoch": 2.2741479386813515,
      "grad_norm": 11.388580322265625,
      "learning_rate": 4.402523280264344e-05,
      "logits/chosen": -0.9510037302970886,
      "logits/rejected": -0.9404541850090027,
      "logps/chosen": -251.5042724609375,
      "logps/rejected": -276.49822998046875,
      "loss": 0.3923,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.667161464691162,
      "rewards/margins": 2.580157995223999,
      "rewards/rejected": -9.247319221496582,
      "step": 7640
    },
    {
      "epoch": 2.277124572108945,
      "grad_norm": 11.751092910766602,
      "learning_rate": 4.397717032141785e-05,
      "logits/chosen": -0.7858389616012573,
      "logits/rejected": -0.878775417804718,
      "logps/chosen": -244.89395141601562,
      "logps/rejected": -284.45135498046875,
      "loss": 0.1956,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -7.016746520996094,
      "rewards/margins": 3.1224799156188965,
      "rewards/rejected": -10.139226913452148,
      "step": 7650
    },
    {
      "epoch": 2.280101205536538,
      "grad_norm": 3.532202959060669,
      "learning_rate": 4.392910784019225e-05,
      "logits/chosen": -0.7761790156364441,
      "logits/rejected": -0.8206145167350769,
      "logps/chosen": -238.26187133789062,
      "logps/rejected": -278.5986022949219,
      "loss": 0.1783,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.506214141845703,
      "rewards/margins": 3.361011028289795,
      "rewards/rejected": -9.867225646972656,
      "step": 7660
    },
    {
      "epoch": 2.2830778389641315,
      "grad_norm": 8.02181625366211,
      "learning_rate": 4.3881045358966666e-05,
      "logits/chosen": -0.8313661813735962,
      "logits/rejected": -0.8941248059272766,
      "logps/chosen": -218.9334259033203,
      "logps/rejected": -269.1909484863281,
      "loss": 0.2749,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.801453590393066,
      "rewards/margins": 3.3037097454071045,
      "rewards/rejected": -9.105161666870117,
      "step": 7670
    },
    {
      "epoch": 2.286054472391725,
      "grad_norm": 3.802218198776245,
      "learning_rate": 4.383298287774107e-05,
      "logits/chosen": -0.8147395849227905,
      "logits/rejected": -0.9211446642875671,
      "logps/chosen": -215.9866180419922,
      "logps/rejected": -278.86077880859375,
      "loss": 0.2504,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.0631208419799805,
      "rewards/margins": 3.3899223804473877,
      "rewards/rejected": -8.453042984008789,
      "step": 7680
    },
    {
      "epoch": 2.2890311058193182,
      "grad_norm": 7.6512250900268555,
      "learning_rate": 4.378492039651548e-05,
      "logits/chosen": -0.6849513053894043,
      "logits/rejected": -0.7542628645896912,
      "logps/chosen": -224.27285766601562,
      "logps/rejected": -264.3360290527344,
      "loss": 0.3472,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -6.015864372253418,
      "rewards/margins": 2.466092586517334,
      "rewards/rejected": -8.48195743560791,
      "step": 7690
    },
    {
      "epoch": 2.2920077392469116,
      "grad_norm": 1.748821496963501,
      "learning_rate": 4.373685791528988e-05,
      "logits/chosen": -0.8740633130073547,
      "logits/rejected": -0.866812527179718,
      "logps/chosen": -246.5102996826172,
      "logps/rejected": -277.14239501953125,
      "loss": 0.2063,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.353091239929199,
      "rewards/margins": 3.313436985015869,
      "rewards/rejected": -9.666526794433594,
      "step": 7700
    },
    {
      "epoch": 2.294984372674505,
      "grad_norm": 5.024875164031982,
      "learning_rate": 4.3688795434064284e-05,
      "logits/chosen": -0.8813340067863464,
      "logits/rejected": -0.8739985227584839,
      "logps/chosen": -228.38156127929688,
      "logps/rejected": -263.6443176269531,
      "loss": 0.2293,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.242908000946045,
      "rewards/margins": 3.020803213119507,
      "rewards/rejected": -8.263710021972656,
      "step": 7710
    },
    {
      "epoch": 2.2979610061020983,
      "grad_norm": 3.5582611560821533,
      "learning_rate": 4.364073295283869e-05,
      "logits/chosen": -0.8272199630737305,
      "logits/rejected": -0.8660825490951538,
      "logps/chosen": -224.61917114257812,
      "logps/rejected": -268.5983581542969,
      "loss": 0.1523,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -5.618307113647461,
      "rewards/margins": 3.391127347946167,
      "rewards/rejected": -9.009434700012207,
      "step": 7720
    },
    {
      "epoch": 2.300937639529692,
      "grad_norm": 4.817763805389404,
      "learning_rate": 4.3592670471613096e-05,
      "logits/chosen": -0.779209315776825,
      "logits/rejected": -0.9612677693367004,
      "logps/chosen": -233.44485473632812,
      "logps/rejected": -285.42413330078125,
      "loss": 0.2382,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.93997049331665,
      "rewards/margins": 2.923426628112793,
      "rewards/rejected": -9.863397598266602,
      "step": 7730
    },
    {
      "epoch": 2.3039142729572855,
      "grad_norm": 3.996035099029541,
      "learning_rate": 4.354460799038751e-05,
      "logits/chosen": -0.9218137860298157,
      "logits/rejected": -0.9980878829956055,
      "logps/chosen": -217.5148468017578,
      "logps/rejected": -262.58782958984375,
      "loss": 0.1505,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -5.859803676605225,
      "rewards/margins": 3.178131341934204,
      "rewards/rejected": -9.037935256958008,
      "step": 7740
    },
    {
      "epoch": 2.306890906384879,
      "grad_norm": 3.3498358726501465,
      "learning_rate": 4.3496545509161915e-05,
      "logits/chosen": -0.9522299766540527,
      "logits/rejected": -0.9304071664810181,
      "logps/chosen": -211.5003662109375,
      "logps/rejected": -240.01712036132812,
      "loss": 0.2042,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.936086177825928,
      "rewards/margins": 2.8829843997955322,
      "rewards/rejected": -7.819069862365723,
      "step": 7750
    },
    {
      "epoch": 2.309867539812472,
      "grad_norm": 5.389584064483643,
      "learning_rate": 4.344848302793632e-05,
      "logits/chosen": -0.8627485036849976,
      "logits/rejected": -0.9643386006355286,
      "logps/chosen": -232.786376953125,
      "logps/rejected": -282.3574523925781,
      "loss": 0.3309,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.173723220825195,
      "rewards/margins": 3.120668888092041,
      "rewards/rejected": -9.294392585754395,
      "step": 7760
    },
    {
      "epoch": 2.3128441732400655,
      "grad_norm": 4.656906604766846,
      "learning_rate": 4.340042054671073e-05,
      "logits/chosen": -0.9561654925346375,
      "logits/rejected": -1.019959807395935,
      "logps/chosen": -224.2788543701172,
      "logps/rejected": -268.4458312988281,
      "loss": 0.306,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -5.067269802093506,
      "rewards/margins": 2.779982805252075,
      "rewards/rejected": -7.84725284576416,
      "step": 7770
    },
    {
      "epoch": 2.315820806667659,
      "grad_norm": 2.610658884048462,
      "learning_rate": 4.3352358065485134e-05,
      "logits/chosen": -0.8712009191513062,
      "logits/rejected": -0.9712939262390137,
      "logps/chosen": -239.0070343017578,
      "logps/rejected": -276.98687744140625,
      "loss": 0.2774,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.468043804168701,
      "rewards/margins": 2.877603769302368,
      "rewards/rejected": -8.345647811889648,
      "step": 7780
    },
    {
      "epoch": 2.3187974400952522,
      "grad_norm": 4.182241439819336,
      "learning_rate": 4.330429558425955e-05,
      "logits/chosen": -0.8351929783821106,
      "logits/rejected": -0.836805522441864,
      "logps/chosen": -225.1775360107422,
      "logps/rejected": -261.42376708984375,
      "loss": 0.2545,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.548440456390381,
      "rewards/margins": 2.899843454360962,
      "rewards/rejected": -8.448283195495605,
      "step": 7790
    },
    {
      "epoch": 2.3217740735228456,
      "grad_norm": 11.62065601348877,
      "learning_rate": 4.325623310303395e-05,
      "logits/chosen": -0.8125088810920715,
      "logits/rejected": -0.7710144519805908,
      "logps/chosen": -226.47225952148438,
      "logps/rejected": -255.4746551513672,
      "loss": 0.2309,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.6068220138549805,
      "rewards/margins": 2.993896245956421,
      "rewards/rejected": -8.600719451904297,
      "step": 7800
    },
    {
      "epoch": 2.324750706950439,
      "grad_norm": 10.06527042388916,
      "learning_rate": 4.320817062180836e-05,
      "logits/chosen": -0.7307459115982056,
      "logits/rejected": -0.7260038256645203,
      "logps/chosen": -264.01190185546875,
      "logps/rejected": -290.2310791015625,
      "loss": 0.3323,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -7.944422245025635,
      "rewards/margins": 2.8276631832122803,
      "rewards/rejected": -10.772086143493652,
      "step": 7810
    },
    {
      "epoch": 2.3277273403780323,
      "grad_norm": 4.136056423187256,
      "learning_rate": 4.316010814058276e-05,
      "logits/chosen": -0.7573527097702026,
      "logits/rejected": -0.8022686243057251,
      "logps/chosen": -251.64443969726562,
      "logps/rejected": -291.18292236328125,
      "loss": 0.2402,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -7.243317604064941,
      "rewards/margins": 3.14571475982666,
      "rewards/rejected": -10.389032363891602,
      "step": 7820
    },
    {
      "epoch": 2.3307039738056257,
      "grad_norm": 5.702212810516357,
      "learning_rate": 4.3112045659357165e-05,
      "logits/chosen": -0.7024528980255127,
      "logits/rejected": -0.7928638458251953,
      "logps/chosen": -232.47671508789062,
      "logps/rejected": -290.107177734375,
      "loss": 0.2731,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.488151550292969,
      "rewards/margins": 3.052020788192749,
      "rewards/rejected": -9.54017162322998,
      "step": 7830
    },
    {
      "epoch": 2.3336806072332195,
      "grad_norm": 3.6447691917419434,
      "learning_rate": 4.306398317813157e-05,
      "logits/chosen": -0.8531447649002075,
      "logits/rejected": -0.9088997840881348,
      "logps/chosen": -231.3711700439453,
      "logps/rejected": -263.9911193847656,
      "loss": 0.3395,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.443802833557129,
      "rewards/margins": 2.5285115242004395,
      "rewards/rejected": -8.97231388092041,
      "step": 7840
    },
    {
      "epoch": 2.336657240660813,
      "grad_norm": 8.331262588500977,
      "learning_rate": 4.301592069690598e-05,
      "logits/chosen": -0.919575572013855,
      "logits/rejected": -0.9097217321395874,
      "logps/chosen": -236.53884887695312,
      "logps/rejected": -264.97955322265625,
      "loss": 0.3117,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.874752998352051,
      "rewards/margins": 2.5460851192474365,
      "rewards/rejected": -8.420839309692383,
      "step": 7850
    },
    {
      "epoch": 2.339633874088406,
      "grad_norm": 6.988320350646973,
      "learning_rate": 4.296785821568039e-05,
      "logits/chosen": -0.9370660781860352,
      "logits/rejected": -0.9503476023674011,
      "logps/chosen": -222.0546112060547,
      "logps/rejected": -251.0723114013672,
      "loss": 0.2865,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.711459159851074,
      "rewards/margins": 2.4422571659088135,
      "rewards/rejected": -8.153717041015625,
      "step": 7860
    },
    {
      "epoch": 2.3426105075159995,
      "grad_norm": 5.1960930824279785,
      "learning_rate": 4.2919795734454796e-05,
      "logits/chosen": -0.8896418809890747,
      "logits/rejected": -0.9328458905220032,
      "logps/chosen": -230.09024047851562,
      "logps/rejected": -253.1710968017578,
      "loss": 0.2781,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -5.408946514129639,
      "rewards/margins": 2.4708945751190186,
      "rewards/rejected": -7.879840850830078,
      "step": 7870
    },
    {
      "epoch": 2.345587140943593,
      "grad_norm": 3.6458184719085693,
      "learning_rate": 4.28717332532292e-05,
      "logits/chosen": -0.9688626527786255,
      "logits/rejected": -0.9328345060348511,
      "logps/chosen": -227.056884765625,
      "logps/rejected": -247.658447265625,
      "loss": 0.2644,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -4.904150485992432,
      "rewards/margins": 2.6056413650512695,
      "rewards/rejected": -7.509791374206543,
      "step": 7880
    },
    {
      "epoch": 2.3485637743711862,
      "grad_norm": 5.396914005279541,
      "learning_rate": 4.282367077200361e-05,
      "logits/chosen": -0.9601036906242371,
      "logits/rejected": -1.0803838968276978,
      "logps/chosen": -206.46542358398438,
      "logps/rejected": -250.1533203125,
      "loss": 0.2984,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -4.68472146987915,
      "rewards/margins": 2.4056410789489746,
      "rewards/rejected": -7.090362548828125,
      "step": 7890
    },
    {
      "epoch": 2.3515404077987796,
      "grad_norm": 7.124876976013184,
      "learning_rate": 4.2775608290778014e-05,
      "logits/chosen": -0.8916034698486328,
      "logits/rejected": -0.993155837059021,
      "logps/chosen": -234.593994140625,
      "logps/rejected": -286.3519287109375,
      "loss": 0.2602,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.930922031402588,
      "rewards/margins": 2.953688144683838,
      "rewards/rejected": -8.884610176086426,
      "step": 7900
    },
    {
      "epoch": 2.354517041226373,
      "grad_norm": 9.065223693847656,
      "learning_rate": 4.272754580955243e-05,
      "logits/chosen": -0.8552120923995972,
      "logits/rejected": -0.9697238206863403,
      "logps/chosen": -197.99562072753906,
      "logps/rejected": -245.33041381835938,
      "loss": 0.2996,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.7291693687438965,
      "rewards/margins": 2.488964557647705,
      "rewards/rejected": -7.21813440322876,
      "step": 7910
    },
    {
      "epoch": 2.3574936746539663,
      "grad_norm": 4.421485900878906,
      "learning_rate": 4.2679483328326833e-05,
      "logits/chosen": -1.0004228353500366,
      "logits/rejected": -1.0768836736679077,
      "logps/chosen": -220.9223175048828,
      "logps/rejected": -256.45611572265625,
      "loss": 0.284,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -4.598596572875977,
      "rewards/margins": 2.630108118057251,
      "rewards/rejected": -7.228704929351807,
      "step": 7920
    },
    {
      "epoch": 2.3604703080815597,
      "grad_norm": 6.470273494720459,
      "learning_rate": 4.263142084710124e-05,
      "logits/chosen": -1.0492521524429321,
      "logits/rejected": -1.1036460399627686,
      "logps/chosen": -213.90133666992188,
      "logps/rejected": -246.20620727539062,
      "loss": 0.2912,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -5.063813209533691,
      "rewards/margins": 2.8232500553131104,
      "rewards/rejected": -7.887062072753906,
      "step": 7930
    },
    {
      "epoch": 2.363446941509153,
      "grad_norm": 4.864525318145752,
      "learning_rate": 4.258335836587564e-05,
      "logits/chosen": -1.0451672077178955,
      "logits/rejected": -1.1191623210906982,
      "logps/chosen": -205.228271484375,
      "logps/rejected": -244.82833862304688,
      "loss": 0.3058,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.084323406219482,
      "rewards/margins": 2.4982473850250244,
      "rewards/rejected": -7.582570552825928,
      "step": 7940
    },
    {
      "epoch": 2.3664235749367464,
      "grad_norm": 11.006146430969238,
      "learning_rate": 4.2535295884650045e-05,
      "logits/chosen": -0.9916939735412598,
      "logits/rejected": -1.0702167749404907,
      "logps/chosen": -203.14718627929688,
      "logps/rejected": -248.69168090820312,
      "loss": 0.2376,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -4.668193817138672,
      "rewards/margins": 2.938803195953369,
      "rewards/rejected": -7.606997013092041,
      "step": 7950
    },
    {
      "epoch": 2.3694002083643397,
      "grad_norm": 4.014253616333008,
      "learning_rate": 4.248723340342445e-05,
      "logits/chosen": -1.0430638790130615,
      "logits/rejected": -1.0326883792877197,
      "logps/chosen": -239.4589080810547,
      "logps/rejected": -269.65618896484375,
      "loss": 0.2591,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.353871822357178,
      "rewards/margins": 2.712775468826294,
      "rewards/rejected": -8.06664752960205,
      "step": 7960
    },
    {
      "epoch": 2.372376841791933,
      "grad_norm": 8.032983779907227,
      "learning_rate": 4.243917092219886e-05,
      "logits/chosen": -1.0225298404693604,
      "logits/rejected": -1.0012376308441162,
      "logps/chosen": -221.02926635742188,
      "logps/rejected": -241.97201538085938,
      "loss": 0.2627,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.6976423263549805,
      "rewards/margins": 2.2853760719299316,
      "rewards/rejected": -6.983018398284912,
      "step": 7970
    },
    {
      "epoch": 2.375353475219527,
      "grad_norm": 4.606788158416748,
      "learning_rate": 4.239110844097327e-05,
      "logits/chosen": -1.002979040145874,
      "logits/rejected": -0.981743335723877,
      "logps/chosen": -234.22750854492188,
      "logps/rejected": -266.30010986328125,
      "loss": 0.3019,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.164937496185303,
      "rewards/margins": 2.6765735149383545,
      "rewards/rejected": -7.841510772705078,
      "step": 7980
    },
    {
      "epoch": 2.3783301086471202,
      "grad_norm": 4.431375026702881,
      "learning_rate": 4.2343045959747677e-05,
      "logits/chosen": -0.9919317960739136,
      "logits/rejected": -1.0497304201126099,
      "logps/chosen": -228.0965576171875,
      "logps/rejected": -271.99151611328125,
      "loss": 0.2515,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.129878044128418,
      "rewards/margins": 2.8458263874053955,
      "rewards/rejected": -7.975705146789551,
      "step": 7990
    },
    {
      "epoch": 2.3813067420747136,
      "grad_norm": 8.759751319885254,
      "learning_rate": 4.229498347852208e-05,
      "logits/chosen": -1.1246585845947266,
      "logits/rejected": -1.1274114847183228,
      "logps/chosen": -224.2936248779297,
      "logps/rejected": -257.07293701171875,
      "loss": 0.3024,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.065047264099121,
      "rewards/margins": 2.5574209690093994,
      "rewards/rejected": -7.6224684715271,
      "step": 8000
    },
    {
      "epoch": 2.384283375502307,
      "grad_norm": 8.51732349395752,
      "learning_rate": 4.224692099729649e-05,
      "logits/chosen": -0.9823921322822571,
      "logits/rejected": -1.0513232946395874,
      "logps/chosen": -214.3549041748047,
      "logps/rejected": -251.98193359375,
      "loss": 0.3091,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -5.328833103179932,
      "rewards/margins": 2.3998539447784424,
      "rewards/rejected": -7.728686332702637,
      "step": 8010
    },
    {
      "epoch": 2.3872600089299003,
      "grad_norm": 7.260806083679199,
      "learning_rate": 4.2198858516070895e-05,
      "logits/chosen": -0.9230703115463257,
      "logits/rejected": -1.0362662076950073,
      "logps/chosen": -223.3293914794922,
      "logps/rejected": -296.9763488769531,
      "loss": 0.2448,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.443993091583252,
      "rewards/margins": 3.0975613594055176,
      "rewards/rejected": -8.54155445098877,
      "step": 8020
    },
    {
      "epoch": 2.3902366423574937,
      "grad_norm": 3.335822105407715,
      "learning_rate": 4.215079603484531e-05,
      "logits/chosen": -1.0039886236190796,
      "logits/rejected": -1.0721033811569214,
      "logps/chosen": -207.0228729248047,
      "logps/rejected": -261.05694580078125,
      "loss": 0.1878,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -4.740689277648926,
      "rewards/margins": 2.9996132850646973,
      "rewards/rejected": -7.740301609039307,
      "step": 8030
    },
    {
      "epoch": 2.393213275785087,
      "grad_norm": 9.297889709472656,
      "learning_rate": 4.2102733553619714e-05,
      "logits/chosen": -0.9974482655525208,
      "logits/rejected": -1.0649775266647339,
      "logps/chosen": -222.7532196044922,
      "logps/rejected": -264.9005432128906,
      "loss": 0.3662,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.326457977294922,
      "rewards/margins": 2.4294495582580566,
      "rewards/rejected": -7.755906581878662,
      "step": 8040
    },
    {
      "epoch": 2.3961899092126804,
      "grad_norm": 6.476495265960693,
      "learning_rate": 4.205467107239412e-05,
      "logits/chosen": -1.0327489376068115,
      "logits/rejected": -1.04482102394104,
      "logps/chosen": -222.84310913085938,
      "logps/rejected": -250.48861694335938,
      "loss": 0.2386,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -4.782838821411133,
      "rewards/margins": 2.7101869583129883,
      "rewards/rejected": -7.493025779724121,
      "step": 8050
    },
    {
      "epoch": 2.3991665426402737,
      "grad_norm": 7.936558723449707,
      "learning_rate": 4.200660859116852e-05,
      "logits/chosen": -1.0987436771392822,
      "logits/rejected": -1.129884123802185,
      "logps/chosen": -215.4097137451172,
      "logps/rejected": -252.52066040039062,
      "loss": 0.2482,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -4.5093865394592285,
      "rewards/margins": 2.7535619735717773,
      "rewards/rejected": -7.262948513031006,
      "step": 8060
    },
    {
      "epoch": 2.402143176067867,
      "grad_norm": 6.644890785217285,
      "learning_rate": 4.1958546109942926e-05,
      "logits/chosen": -1.0843770503997803,
      "logits/rejected": -1.0860517024993896,
      "logps/chosen": -220.53195190429688,
      "logps/rejected": -243.0409698486328,
      "loss": 0.3125,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.051302909851074,
      "rewards/margins": 2.3233237266540527,
      "rewards/rejected": -7.374627113342285,
      "step": 8070
    },
    {
      "epoch": 2.4051198094954604,
      "grad_norm": 5.847949028015137,
      "learning_rate": 4.191048362871733e-05,
      "logits/chosen": -0.9865924715995789,
      "logits/rejected": -0.9950031042098999,
      "logps/chosen": -235.088623046875,
      "logps/rejected": -259.254150390625,
      "loss": 0.2288,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.259375095367432,
      "rewards/margins": 2.83972430229187,
      "rewards/rejected": -8.099100112915039,
      "step": 8080
    },
    {
      "epoch": 2.4080964429230542,
      "grad_norm": 5.129678249359131,
      "learning_rate": 4.186242114749174e-05,
      "logits/chosen": -0.8856889009475708,
      "logits/rejected": -0.8820438385009766,
      "logps/chosen": -219.39981079101562,
      "logps/rejected": -257.917724609375,
      "loss": 0.2056,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.155298233032227,
      "rewards/margins": 3.0349204540252686,
      "rewards/rejected": -8.190218925476074,
      "step": 8090
    },
    {
      "epoch": 2.4110730763506476,
      "grad_norm": 10.307188034057617,
      "learning_rate": 4.181435866626615e-05,
      "logits/chosen": -0.9080488085746765,
      "logits/rejected": -0.9454303979873657,
      "logps/chosen": -231.01025390625,
      "logps/rejected": -273.00433349609375,
      "loss": 0.2536,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.906579494476318,
      "rewards/margins": 2.712893009185791,
      "rewards/rejected": -8.619471549987793,
      "step": 8100
    },
    {
      "epoch": 2.414049709778241,
      "grad_norm": 5.054491996765137,
      "learning_rate": 4.176629618504056e-05,
      "logits/chosen": -0.8707106709480286,
      "logits/rejected": -0.8812103271484375,
      "logps/chosen": -232.54800415039062,
      "logps/rejected": -288.7511291503906,
      "loss": 0.2335,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.854458332061768,
      "rewards/margins": 3.4878921508789062,
      "rewards/rejected": -9.342350959777832,
      "step": 8110
    },
    {
      "epoch": 2.4170263432058343,
      "grad_norm": 11.605535507202148,
      "learning_rate": 4.171823370381496e-05,
      "logits/chosen": -0.8493192791938782,
      "logits/rejected": -0.8736603856086731,
      "logps/chosen": -233.51626586914062,
      "logps/rejected": -261.3774719238281,
      "loss": 0.2583,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.1281867027282715,
      "rewards/margins": 2.789417266845703,
      "rewards/rejected": -8.917604446411133,
      "step": 8120
    },
    {
      "epoch": 2.4200029766334277,
      "grad_norm": 2.3606789112091064,
      "learning_rate": 4.167017122258937e-05,
      "logits/chosen": -0.7387124300003052,
      "logits/rejected": -0.8663609623908997,
      "logps/chosen": -234.3048858642578,
      "logps/rejected": -292.0909729003906,
      "loss": 0.239,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.737555503845215,
      "rewards/margins": 3.1163058280944824,
      "rewards/rejected": -9.853861808776855,
      "step": 8130
    },
    {
      "epoch": 2.422979610061021,
      "grad_norm": 6.640524387359619,
      "learning_rate": 4.1622108741363775e-05,
      "logits/chosen": -0.8551329374313354,
      "logits/rejected": -0.8034198880195618,
      "logps/chosen": -246.5299835205078,
      "logps/rejected": -262.7054443359375,
      "loss": 0.393,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.3039727210998535,
      "rewards/margins": 2.3697328567504883,
      "rewards/rejected": -8.673705101013184,
      "step": 8140
    },
    {
      "epoch": 2.4259562434886144,
      "grad_norm": 3.441709041595459,
      "learning_rate": 4.157404626013819e-05,
      "logits/chosen": -0.7488664388656616,
      "logits/rejected": -0.8642722964286804,
      "logps/chosen": -221.97586059570312,
      "logps/rejected": -285.92120361328125,
      "loss": 0.1781,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.345648765563965,
      "rewards/margins": 3.3342196941375732,
      "rewards/rejected": -9.679868698120117,
      "step": 8150
    },
    {
      "epoch": 2.4289328769162077,
      "grad_norm": 3.9064149856567383,
      "learning_rate": 4.1525983778912595e-05,
      "logits/chosen": -0.8154008984565735,
      "logits/rejected": -0.8218542337417603,
      "logps/chosen": -223.2000732421875,
      "logps/rejected": -261.9211730957031,
      "loss": 0.2421,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.990389823913574,
      "rewards/margins": 3.1021621227264404,
      "rewards/rejected": -9.092551231384277,
      "step": 8160
    },
    {
      "epoch": 2.431909510343801,
      "grad_norm": 7.3866729736328125,
      "learning_rate": 4.1477921297687e-05,
      "logits/chosen": -0.7375770211219788,
      "logits/rejected": -0.7613214254379272,
      "logps/chosen": -236.940673828125,
      "logps/rejected": -290.50628662109375,
      "loss": 0.2086,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.959389686584473,
      "rewards/margins": 3.464235305786133,
      "rewards/rejected": -10.423624038696289,
      "step": 8170
    },
    {
      "epoch": 2.4348861437713945,
      "grad_norm": 4.912028789520264,
      "learning_rate": 4.14298588164614e-05,
      "logits/chosen": -0.9388893246650696,
      "logits/rejected": -0.9070670008659363,
      "logps/chosen": -250.6474151611328,
      "logps/rejected": -288.1945495605469,
      "loss": 0.2937,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -7.061149597167969,
      "rewards/margins": 2.710111141204834,
      "rewards/rejected": -9.771261215209961,
      "step": 8180
    },
    {
      "epoch": 2.437862777198988,
      "grad_norm": 5.462055683135986,
      "learning_rate": 4.1381796335235806e-05,
      "logits/chosen": -0.9172617197036743,
      "logits/rejected": -0.8459122776985168,
      "logps/chosen": -229.03134155273438,
      "logps/rejected": -245.2421417236328,
      "loss": 0.2432,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.2965497970581055,
      "rewards/margins": 2.7154393196105957,
      "rewards/rejected": -8.011988639831543,
      "step": 8190
    },
    {
      "epoch": 2.440839410626581,
      "grad_norm": 2.5404632091522217,
      "learning_rate": 4.133373385401021e-05,
      "logits/chosen": -1.0171955823898315,
      "logits/rejected": -1.0036344528198242,
      "logps/chosen": -228.76608276367188,
      "logps/rejected": -261.7934875488281,
      "loss": 0.2883,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -4.976459503173828,
      "rewards/margins": 2.671177864074707,
      "rewards/rejected": -7.647637844085693,
      "step": 8200
    },
    {
      "epoch": 2.4438160440541745,
      "grad_norm": 11.372586250305176,
      "learning_rate": 4.128567137278462e-05,
      "logits/chosen": -0.9225519299507141,
      "logits/rejected": -0.97764652967453,
      "logps/chosen": -238.32339477539062,
      "logps/rejected": -292.08734130859375,
      "loss": 0.2737,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.981855869293213,
      "rewards/margins": 2.96394419670105,
      "rewards/rejected": -8.945799827575684,
      "step": 8210
    },
    {
      "epoch": 2.446792677481768,
      "grad_norm": 3.3383431434631348,
      "learning_rate": 4.123760889155903e-05,
      "logits/chosen": -1.0978604555130005,
      "logits/rejected": -1.0526043176651,
      "logps/chosen": -226.89199829101562,
      "logps/rejected": -245.99002075195312,
      "loss": 0.2702,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.270987033843994,
      "rewards/margins": 2.706699848175049,
      "rewards/rejected": -7.977685451507568,
      "step": 8220
    },
    {
      "epoch": 2.4497693109093617,
      "grad_norm": 3.5937576293945312,
      "learning_rate": 4.118954641033344e-05,
      "logits/chosen": -0.9737793207168579,
      "logits/rejected": -1.1088292598724365,
      "logps/chosen": -226.4253387451172,
      "logps/rejected": -279.7696228027344,
      "loss": 0.2954,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.831981658935547,
      "rewards/margins": 2.504460096359253,
      "rewards/rejected": -8.336441993713379,
      "step": 8230
    },
    {
      "epoch": 2.452745944336955,
      "grad_norm": 20.311203002929688,
      "learning_rate": 4.1141483929107844e-05,
      "logits/chosen": -1.0212994813919067,
      "logits/rejected": -1.0536372661590576,
      "logps/chosen": -231.14004516601562,
      "logps/rejected": -271.2859802246094,
      "loss": 0.2491,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.004591941833496,
      "rewards/margins": 2.754746913909912,
      "rewards/rejected": -8.759340286254883,
      "step": 8240
    },
    {
      "epoch": 2.4557225777645484,
      "grad_norm": 10.150224685668945,
      "learning_rate": 4.109342144788225e-05,
      "logits/chosen": -0.9254634976387024,
      "logits/rejected": -0.9970367550849915,
      "logps/chosen": -234.41763305664062,
      "logps/rejected": -273.8644104003906,
      "loss": 0.2125,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.182150840759277,
      "rewards/margins": 2.9915003776550293,
      "rewards/rejected": -9.173651695251465,
      "step": 8250
    },
    {
      "epoch": 2.4586992111921417,
      "grad_norm": 11.013839721679688,
      "learning_rate": 4.1045358966656656e-05,
      "logits/chosen": -1.0277996063232422,
      "logits/rejected": -1.0326001644134521,
      "logps/chosen": -228.0386962890625,
      "logps/rejected": -247.67428588867188,
      "loss": 0.3931,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -5.975936412811279,
      "rewards/margins": 2.2119052410125732,
      "rewards/rejected": -8.187841415405273,
      "step": 8260
    },
    {
      "epoch": 2.461675844619735,
      "grad_norm": 6.591976642608643,
      "learning_rate": 4.099729648543107e-05,
      "logits/chosen": -0.9797163009643555,
      "logits/rejected": -0.9918488264083862,
      "logps/chosen": -217.7152099609375,
      "logps/rejected": -251.8853759765625,
      "loss": 0.255,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.198803901672363,
      "rewards/margins": 2.427891731262207,
      "rewards/rejected": -7.6266961097717285,
      "step": 8270
    },
    {
      "epoch": 2.4646524780473285,
      "grad_norm": 2.0392909049987793,
      "learning_rate": 4.0949234004205475e-05,
      "logits/chosen": -1.0757960081100464,
      "logits/rejected": -1.046650767326355,
      "logps/chosen": -233.06494140625,
      "logps/rejected": -271.33245849609375,
      "loss": 0.1166,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -5.7016143798828125,
      "rewards/margins": 3.448570728302002,
      "rewards/rejected": -9.150184631347656,
      "step": 8280
    },
    {
      "epoch": 2.467629111474922,
      "grad_norm": 2.1865291595458984,
      "learning_rate": 4.090117152297988e-05,
      "logits/chosen": -1.0348397493362427,
      "logits/rejected": -1.031273603439331,
      "logps/chosen": -237.28860473632812,
      "logps/rejected": -259.14501953125,
      "loss": 0.319,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.237381458282471,
      "rewards/margins": 2.6360526084899902,
      "rewards/rejected": -7.873434543609619,
      "step": 8290
    },
    {
      "epoch": 2.470605744902515,
      "grad_norm": 6.230867862701416,
      "learning_rate": 4.085310904175428e-05,
      "logits/chosen": -0.9759520292282104,
      "logits/rejected": -0.9995438456535339,
      "logps/chosen": -221.424072265625,
      "logps/rejected": -252.322265625,
      "loss": 0.3068,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -5.805869102478027,
      "rewards/margins": 2.5081379413604736,
      "rewards/rejected": -8.314007759094238,
      "step": 8300
    },
    {
      "epoch": 2.4735823783301085,
      "grad_norm": 5.727799415588379,
      "learning_rate": 4.080504656052869e-05,
      "logits/chosen": -0.9561697840690613,
      "logits/rejected": -1.005265235900879,
      "logps/chosen": -219.2775115966797,
      "logps/rejected": -256.14263916015625,
      "loss": 0.322,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.027538776397705,
      "rewards/margins": 2.8702549934387207,
      "rewards/rejected": -8.897793769836426,
      "step": 8310
    },
    {
      "epoch": 2.476559011757702,
      "grad_norm": 10.497872352600098,
      "learning_rate": 4.075698407930309e-05,
      "logits/chosen": -0.9704276919364929,
      "logits/rejected": -0.9687343835830688,
      "logps/chosen": -238.05416870117188,
      "logps/rejected": -270.7333068847656,
      "loss": 0.2701,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.054085731506348,
      "rewards/margins": 2.5855510234832764,
      "rewards/rejected": -8.639636039733887,
      "step": 8320
    },
    {
      "epoch": 2.4795356451852957,
      "grad_norm": 10.946572303771973,
      "learning_rate": 4.07089215980775e-05,
      "logits/chosen": -0.8472846150398254,
      "logits/rejected": -0.9572522044181824,
      "logps/chosen": -233.16659545898438,
      "logps/rejected": -280.7665710449219,
      "loss": 0.2493,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.683722019195557,
      "rewards/margins": 3.063647508621216,
      "rewards/rejected": -9.747368812561035,
      "step": 8330
    },
    {
      "epoch": 2.482512278612889,
      "grad_norm": 7.678852558135986,
      "learning_rate": 4.066085911685191e-05,
      "logits/chosen": -0.8814692497253418,
      "logits/rejected": -0.9279540181159973,
      "logps/chosen": -240.4718780517578,
      "logps/rejected": -281.03118896484375,
      "loss": 0.2327,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.6389617919921875,
      "rewards/margins": 3.154240846633911,
      "rewards/rejected": -9.793203353881836,
      "step": 8340
    },
    {
      "epoch": 2.4854889120404824,
      "grad_norm": 10.34037971496582,
      "learning_rate": 4.061279663562632e-05,
      "logits/chosen": -0.9318035840988159,
      "logits/rejected": -0.9285573959350586,
      "logps/chosen": -234.13919067382812,
      "logps/rejected": -272.94586181640625,
      "loss": 0.2742,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.577677249908447,
      "rewards/margins": 2.895402431488037,
      "rewards/rejected": -9.473078727722168,
      "step": 8350
    },
    {
      "epoch": 2.4884655454680757,
      "grad_norm": 2.66593337059021,
      "learning_rate": 4.0564734154400724e-05,
      "logits/chosen": -0.8465338945388794,
      "logits/rejected": -0.8970789909362793,
      "logps/chosen": -224.119140625,
      "logps/rejected": -267.5843811035156,
      "loss": 0.2664,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.646224021911621,
      "rewards/margins": 2.6618521213531494,
      "rewards/rejected": -9.308075904846191,
      "step": 8360
    },
    {
      "epoch": 2.491442178895669,
      "grad_norm": 2.075472116470337,
      "learning_rate": 4.051667167317513e-05,
      "logits/chosen": -0.8868908882141113,
      "logits/rejected": -0.9937865138053894,
      "logps/chosen": -218.85916137695312,
      "logps/rejected": -276.12066650390625,
      "loss": 0.2596,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.0399370193481445,
      "rewards/margins": 2.9951171875,
      "rewards/rejected": -9.035055160522461,
      "step": 8370
    },
    {
      "epoch": 2.4944188123232625,
      "grad_norm": 6.236112117767334,
      "learning_rate": 4.0468609191949537e-05,
      "logits/chosen": -0.9427593946456909,
      "logits/rejected": -0.9837595820426941,
      "logps/chosen": -245.3186798095703,
      "logps/rejected": -286.1259765625,
      "loss": 0.2071,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.588754177093506,
      "rewards/margins": 3.0517020225524902,
      "rewards/rejected": -9.64045524597168,
      "step": 8380
    },
    {
      "epoch": 2.497395445750856,
      "grad_norm": 10.056583404541016,
      "learning_rate": 4.042054671072395e-05,
      "logits/chosen": -0.8424429893493652,
      "logits/rejected": -0.7794173955917358,
      "logps/chosen": -232.44711303710938,
      "logps/rejected": -251.2861785888672,
      "loss": 0.3123,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -6.532907962799072,
      "rewards/margins": 2.3041348457336426,
      "rewards/rejected": -8.837041854858398,
      "step": 8390
    },
    {
      "epoch": 2.500372079178449,
      "grad_norm": 2.781207799911499,
      "learning_rate": 4.0372484229498356e-05,
      "logits/chosen": -0.8647850155830383,
      "logits/rejected": -0.8791747093200684,
      "logps/chosen": -233.89794921875,
      "logps/rejected": -269.78302001953125,
      "loss": 0.1838,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.229115962982178,
      "rewards/margins": 2.795461416244507,
      "rewards/rejected": -9.024579048156738,
      "step": 8400
    },
    {
      "epoch": 2.5033487126060425,
      "grad_norm": 4.309731960296631,
      "learning_rate": 4.032442174827276e-05,
      "logits/chosen": -0.7249868512153625,
      "logits/rejected": -0.7880223989486694,
      "logps/chosen": -231.6582489013672,
      "logps/rejected": -274.207763671875,
      "loss": 0.2454,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.717276096343994,
      "rewards/margins": 3.092428207397461,
      "rewards/rejected": -9.809703826904297,
      "step": 8410
    },
    {
      "epoch": 2.506325346033636,
      "grad_norm": 7.227319240570068,
      "learning_rate": 4.027635926704716e-05,
      "logits/chosen": -0.7986873388290405,
      "logits/rejected": -0.8399385213851929,
      "logps/chosen": -232.46435546875,
      "logps/rejected": -268.5472106933594,
      "loss": 0.2848,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -5.934284687042236,
      "rewards/margins": 3.076528787612915,
      "rewards/rejected": -9.010812759399414,
      "step": 8420
    },
    {
      "epoch": 2.5093019794612292,
      "grad_norm": 4.793074607849121,
      "learning_rate": 4.022829678582157e-05,
      "logits/chosen": -0.7477108836174011,
      "logits/rejected": -0.8070516586303711,
      "logps/chosen": -241.97940063476562,
      "logps/rejected": -273.94635009765625,
      "loss": 0.3093,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.638369560241699,
      "rewards/margins": 2.8593668937683105,
      "rewards/rejected": -9.497735977172852,
      "step": 8430
    },
    {
      "epoch": 2.5122786128888226,
      "grad_norm": 3.0567243099212646,
      "learning_rate": 4.0180234304595973e-05,
      "logits/chosen": -0.7292605638504028,
      "logits/rejected": -0.7392595410346985,
      "logps/chosen": -243.5807342529297,
      "logps/rejected": -297.1964416503906,
      "loss": 0.1659,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.140550136566162,
      "rewards/margins": 3.7396724224090576,
      "rewards/rejected": -10.88022232055664,
      "step": 8440
    },
    {
      "epoch": 2.515255246316416,
      "grad_norm": 6.098415374755859,
      "learning_rate": 4.013217182337038e-05,
      "logits/chosen": -0.788666844367981,
      "logits/rejected": -0.9207391738891602,
      "logps/chosen": -244.54934692382812,
      "logps/rejected": -297.2980041503906,
      "loss": 0.2799,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -7.274683952331543,
      "rewards/margins": 3.1161155700683594,
      "rewards/rejected": -10.390799522399902,
      "step": 8450
    },
    {
      "epoch": 2.5182318797440093,
      "grad_norm": 6.439157962799072,
      "learning_rate": 4.008410934214479e-05,
      "logits/chosen": -0.9222485423088074,
      "logits/rejected": -0.842329204082489,
      "logps/chosen": -239.12393188476562,
      "logps/rejected": -267.56475830078125,
      "loss": 0.2024,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.575188636779785,
      "rewards/margins": 3.1550190448760986,
      "rewards/rejected": -9.730209350585938,
      "step": 8460
    },
    {
      "epoch": 2.5212085131716027,
      "grad_norm": 6.289836883544922,
      "learning_rate": 4.00360468609192e-05,
      "logits/chosen": -0.8999700546264648,
      "logits/rejected": -0.9317717552185059,
      "logps/chosen": -228.09860229492188,
      "logps/rejected": -268.7356262207031,
      "loss": 0.2371,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.961949825286865,
      "rewards/margins": 3.4734740257263184,
      "rewards/rejected": -9.4354248046875,
      "step": 8470
    },
    {
      "epoch": 2.5241851465991965,
      "grad_norm": 4.913486480712891,
      "learning_rate": 3.9987984379693605e-05,
      "logits/chosen": -0.838067352771759,
      "logits/rejected": -0.8705962300300598,
      "logps/chosen": -236.62387084960938,
      "logps/rejected": -273.52569580078125,
      "loss": 0.3318,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.9014177322387695,
      "rewards/margins": 3.0210354328155518,
      "rewards/rejected": -9.922451972961426,
      "step": 8480
    },
    {
      "epoch": 2.52716178002679,
      "grad_norm": 18.7718448638916,
      "learning_rate": 3.993992189846801e-05,
      "logits/chosen": -0.9040163159370422,
      "logits/rejected": -0.8725277781486511,
      "logps/chosen": -231.52798461914062,
      "logps/rejected": -266.5208740234375,
      "loss": 0.2711,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.291316032409668,
      "rewards/margins": 3.0900719165802,
      "rewards/rejected": -9.381387710571289,
      "step": 8490
    },
    {
      "epoch": 2.530138413454383,
      "grad_norm": 5.311214923858643,
      "learning_rate": 3.989185941724242e-05,
      "logits/chosen": -0.9446607828140259,
      "logits/rejected": -0.9321956634521484,
      "logps/chosen": -239.9952392578125,
      "logps/rejected": -270.78875732421875,
      "loss": 0.4011,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -6.189030647277832,
      "rewards/margins": 2.82271409034729,
      "rewards/rejected": -9.011744499206543,
      "step": 8500
    },
    {
      "epoch": 2.5331150468819765,
      "grad_norm": 3.698768377304077,
      "learning_rate": 3.984379693601682e-05,
      "logits/chosen": -0.9546334147453308,
      "logits/rejected": -0.9838916063308716,
      "logps/chosen": -235.98275756835938,
      "logps/rejected": -266.5221252441406,
      "loss": 0.2809,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.418295383453369,
      "rewards/margins": 2.9665067195892334,
      "rewards/rejected": -9.384801864624023,
      "step": 8510
    },
    {
      "epoch": 2.53609168030957,
      "grad_norm": 4.156732559204102,
      "learning_rate": 3.979573445479123e-05,
      "logits/chosen": -1.0320080518722534,
      "logits/rejected": -1.0377795696258545,
      "logps/chosen": -237.0278778076172,
      "logps/rejected": -270.1103515625,
      "loss": 0.1998,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -5.5274658203125,
      "rewards/margins": 2.917119026184082,
      "rewards/rejected": -8.444585800170898,
      "step": 8520
    },
    {
      "epoch": 2.5390683137371632,
      "grad_norm": 7.734607219696045,
      "learning_rate": 3.9747671973565636e-05,
      "logits/chosen": -0.9322648048400879,
      "logits/rejected": -1.0520565509796143,
      "logps/chosen": -237.0015869140625,
      "logps/rejected": -283.4466247558594,
      "loss": 0.1987,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.277347087860107,
      "rewards/margins": 3.061249017715454,
      "rewards/rejected": -9.338594436645508,
      "step": 8530
    },
    {
      "epoch": 2.5420449471647566,
      "grad_norm": 13.16397762298584,
      "learning_rate": 3.969960949234005e-05,
      "logits/chosen": -0.9787636995315552,
      "logits/rejected": -1.020282506942749,
      "logps/chosen": -256.9514465332031,
      "logps/rejected": -306.0216979980469,
      "loss": 0.3484,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.3583984375,
      "rewards/margins": 2.9928054809570312,
      "rewards/rejected": -10.351203918457031,
      "step": 8540
    },
    {
      "epoch": 2.54502158059235,
      "grad_norm": 5.206212520599365,
      "learning_rate": 3.9651547011114455e-05,
      "logits/chosen": -0.8709907531738281,
      "logits/rejected": -0.9132227897644043,
      "logps/chosen": -223.9845428466797,
      "logps/rejected": -262.2842712402344,
      "loss": 0.2481,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.690656661987305,
      "rewards/margins": 2.5479068756103516,
      "rewards/rejected": -8.238564491271973,
      "step": 8550
    },
    {
      "epoch": 2.5479982140199433,
      "grad_norm": 5.4380059242248535,
      "learning_rate": 3.960348452988886e-05,
      "logits/chosen": -0.7837192416191101,
      "logits/rejected": -0.8731056451797485,
      "logps/chosen": -246.1937255859375,
      "logps/rejected": -304.3793029785156,
      "loss": 0.3124,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -7.059002876281738,
      "rewards/margins": 2.6825408935546875,
      "rewards/rejected": -9.741544723510742,
      "step": 8560
    },
    {
      "epoch": 2.550974847447537,
      "grad_norm": 6.59340238571167,
      "learning_rate": 3.955542204866326e-05,
      "logits/chosen": -0.8403725624084473,
      "logits/rejected": -0.8499014973640442,
      "logps/chosen": -232.51416015625,
      "logps/rejected": -268.51287841796875,
      "loss": 0.2692,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.559429168701172,
      "rewards/margins": 2.7203500270843506,
      "rewards/rejected": -8.279779434204102,
      "step": 8570
    },
    {
      "epoch": 2.5539514808751305,
      "grad_norm": 11.815825462341309,
      "learning_rate": 3.950735956743767e-05,
      "logits/chosen": -0.7927743792533875,
      "logits/rejected": -0.8295382261276245,
      "logps/chosen": -240.2115478515625,
      "logps/rejected": -281.15753173828125,
      "loss": 0.2817,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.345324516296387,
      "rewards/margins": 2.7332921028137207,
      "rewards/rejected": -9.07861614227295,
      "step": 8580
    },
    {
      "epoch": 2.556928114302724,
      "grad_norm": 5.505669116973877,
      "learning_rate": 3.945929708621208e-05,
      "logits/chosen": -0.8337599635124207,
      "logits/rejected": -0.8329728245735168,
      "logps/chosen": -227.02743530273438,
      "logps/rejected": -262.1871032714844,
      "loss": 0.2653,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.674555778503418,
      "rewards/margins": 2.7995765209198,
      "rewards/rejected": -8.47413444519043,
      "step": 8590
    },
    {
      "epoch": 2.559904747730317,
      "grad_norm": 2.753835916519165,
      "learning_rate": 3.9411234604986485e-05,
      "logits/chosen": -0.9116326570510864,
      "logits/rejected": -0.9563049077987671,
      "logps/chosen": -241.99508666992188,
      "logps/rejected": -279.87152099609375,
      "loss": 0.2472,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.122591495513916,
      "rewards/margins": 3.0665650367736816,
      "rewards/rejected": -9.189155578613281,
      "step": 8600
    },
    {
      "epoch": 2.5628813811579105,
      "grad_norm": 5.651226043701172,
      "learning_rate": 3.936317212376089e-05,
      "logits/chosen": -0.9535655975341797,
      "logits/rejected": -1.0316311120986938,
      "logps/chosen": -246.2603302001953,
      "logps/rejected": -288.2639465332031,
      "loss": 0.1946,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.859213829040527,
      "rewards/margins": 3.0656790733337402,
      "rewards/rejected": -9.924894332885742,
      "step": 8610
    },
    {
      "epoch": 2.565858014585504,
      "grad_norm": 1.4642482995986938,
      "learning_rate": 3.93151096425353e-05,
      "logits/chosen": -0.8806253671646118,
      "logits/rejected": -0.7811192870140076,
      "logps/chosen": -231.4257049560547,
      "logps/rejected": -242.1392822265625,
      "loss": 0.3186,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -5.674454212188721,
      "rewards/margins": 2.415781021118164,
      "rewards/rejected": -8.090235710144043,
      "step": 8620
    },
    {
      "epoch": 2.5688346480130972,
      "grad_norm": 6.739351272583008,
      "learning_rate": 3.9267047161309704e-05,
      "logits/chosen": -0.8757163882255554,
      "logits/rejected": -0.7842500805854797,
      "logps/chosen": -241.0995635986328,
      "logps/rejected": -263.9787902832031,
      "loss": 0.2212,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.888871192932129,
      "rewards/margins": 2.8138954639434814,
      "rewards/rejected": -8.702765464782715,
      "step": 8630
    },
    {
      "epoch": 2.5718112814406906,
      "grad_norm": 8.95161247253418,
      "learning_rate": 3.921898468008411e-05,
      "logits/chosen": -0.8022803068161011,
      "logits/rejected": -0.7434584498405457,
      "logps/chosen": -221.44583129882812,
      "logps/rejected": -258.2441711425781,
      "loss": 0.2276,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.293745517730713,
      "rewards/margins": 3.054006338119507,
      "rewards/rejected": -8.34775161743164,
      "step": 8640
    },
    {
      "epoch": 2.574787914868284,
      "grad_norm": 3.7122344970703125,
      "learning_rate": 3.9170922198858516e-05,
      "logits/chosen": -0.9278427362442017,
      "logits/rejected": -0.858807384967804,
      "logps/chosen": -222.93478393554688,
      "logps/rejected": -251.09732055664062,
      "loss": 0.1776,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -4.729884624481201,
      "rewards/margins": 3.120534896850586,
      "rewards/rejected": -7.850419521331787,
      "step": 8650
    },
    {
      "epoch": 2.5777645482958773,
      "grad_norm": 4.571427822113037,
      "learning_rate": 3.912285971763293e-05,
      "logits/chosen": -0.7065585851669312,
      "logits/rejected": -0.7506067752838135,
      "logps/chosen": -230.86367797851562,
      "logps/rejected": -277.29327392578125,
      "loss": 0.2469,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.102239608764648,
      "rewards/margins": 3.1546926498413086,
      "rewards/rejected": -9.256932258605957,
      "step": 8660
    },
    {
      "epoch": 2.5807411817234707,
      "grad_norm": 4.284933090209961,
      "learning_rate": 3.9074797236407335e-05,
      "logits/chosen": -0.751086413860321,
      "logits/rejected": -0.8133456110954285,
      "logps/chosen": -235.48367309570312,
      "logps/rejected": -289.6802673339844,
      "loss": 0.2293,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.809342861175537,
      "rewards/margins": 3.6044723987579346,
      "rewards/rejected": -10.41381549835205,
      "step": 8670
    },
    {
      "epoch": 2.583717815151064,
      "grad_norm": 0.4506171941757202,
      "learning_rate": 3.902673475518174e-05,
      "logits/chosen": -0.6835060715675354,
      "logits/rejected": -0.578838050365448,
      "logps/chosen": -244.3648681640625,
      "logps/rejected": -267.0816955566406,
      "loss": 0.19,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.365556716918945,
      "rewards/margins": 3.7088425159454346,
      "rewards/rejected": -10.074399948120117,
      "step": 8680
    },
    {
      "epoch": 2.5866944485786574,
      "grad_norm": 15.098821640014648,
      "learning_rate": 3.897867227395615e-05,
      "logits/chosen": -0.7566733360290527,
      "logits/rejected": -0.6598000526428223,
      "logps/chosen": -254.53933715820312,
      "logps/rejected": -288.4368591308594,
      "loss": 0.292,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -7.171122074127197,
      "rewards/margins": 3.2775352001190186,
      "rewards/rejected": -10.448657989501953,
      "step": 8690
    },
    {
      "epoch": 2.5896710820062507,
      "grad_norm": 2.128783702850342,
      "learning_rate": 3.8930609792730554e-05,
      "logits/chosen": -0.671251118183136,
      "logits/rejected": -0.6917694211006165,
      "logps/chosen": -247.3819580078125,
      "logps/rejected": -291.67138671875,
      "loss": 0.2802,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -7.855644226074219,
      "rewards/margins": 3.3266353607177734,
      "rewards/rejected": -11.182278633117676,
      "step": 8700
    },
    {
      "epoch": 2.592647715433844,
      "grad_norm": 6.3010478019714355,
      "learning_rate": 3.888254731150496e-05,
      "logits/chosen": -0.7370989918708801,
      "logits/rejected": -0.6201602220535278,
      "logps/chosen": -242.4496307373047,
      "logps/rejected": -271.4049987792969,
      "loss": 0.1908,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.741133689880371,
      "rewards/margins": 3.2575793266296387,
      "rewards/rejected": -8.998712539672852,
      "step": 8710
    },
    {
      "epoch": 2.5956243488614374,
      "grad_norm": 6.089982986450195,
      "learning_rate": 3.8834484830279366e-05,
      "logits/chosen": -0.7402690052986145,
      "logits/rejected": -0.7495585680007935,
      "logps/chosen": -242.7307891845703,
      "logps/rejected": -274.1847229003906,
      "loss": 0.2602,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.012814998626709,
      "rewards/margins": 2.853933334350586,
      "rewards/rejected": -8.866747856140137,
      "step": 8720
    },
    {
      "epoch": 2.5986009822890312,
      "grad_norm": 7.682206630706787,
      "learning_rate": 3.878642234905377e-05,
      "logits/chosen": -0.6356184482574463,
      "logits/rejected": -0.7101471424102783,
      "logps/chosen": -239.71432495117188,
      "logps/rejected": -286.5028381347656,
      "loss": 0.2969,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -7.63690710067749,
      "rewards/margins": 2.698694944381714,
      "rewards/rejected": -10.335602760314941,
      "step": 8730
    },
    {
      "epoch": 2.6015776157166246,
      "grad_norm": 9.764383316040039,
      "learning_rate": 3.873835986782818e-05,
      "logits/chosen": -0.6553947329521179,
      "logits/rejected": -0.6802899837493896,
      "logps/chosen": -254.6399688720703,
      "logps/rejected": -273.3900451660156,
      "loss": 0.3289,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.129286766052246,
      "rewards/margins": 2.5026752948760986,
      "rewards/rejected": -9.631961822509766,
      "step": 8740
    },
    {
      "epoch": 2.604554249144218,
      "grad_norm": 4.005951881408691,
      "learning_rate": 3.8695103634725145e-05,
      "logits/chosen": -0.6511294841766357,
      "logits/rejected": -0.5335432291030884,
      "logps/chosen": -259.299072265625,
      "logps/rejected": -285.7131042480469,
      "loss": 0.3224,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -8.614564895629883,
      "rewards/margins": 2.6518189907073975,
      "rewards/rejected": -11.266386032104492,
      "step": 8750
    },
    {
      "epoch": 2.6075308825718113,
      "grad_norm": 4.437927722930908,
      "learning_rate": 3.864704115349955e-05,
      "logits/chosen": -0.5941112637519836,
      "logits/rejected": -0.561424732208252,
      "logps/chosen": -262.4676513671875,
      "logps/rejected": -302.0335388183594,
      "loss": 0.2569,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -8.24083423614502,
      "rewards/margins": 3.1293816566467285,
      "rewards/rejected": -11.370216369628906,
      "step": 8760
    },
    {
      "epoch": 2.6105075159994047,
      "grad_norm": 3.89704966545105,
      "learning_rate": 3.8598978672273964e-05,
      "logits/chosen": -0.7747606635093689,
      "logits/rejected": -0.6974378824234009,
      "logps/chosen": -239.4163818359375,
      "logps/rejected": -259.16046142578125,
      "loss": 0.3532,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.8420090675354,
      "rewards/margins": 2.7833685874938965,
      "rewards/rejected": -9.625378608703613,
      "step": 8770
    },
    {
      "epoch": 2.613484149426998,
      "grad_norm": 3.247082471847534,
      "learning_rate": 3.8550916191048364e-05,
      "logits/chosen": -0.8484641313552856,
      "logits/rejected": -0.9300491213798523,
      "logps/chosen": -236.9562225341797,
      "logps/rejected": -292.1181640625,
      "loss": 0.2341,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.860876560211182,
      "rewards/margins": 3.0552289485931396,
      "rewards/rejected": -8.916105270385742,
      "step": 8780
    },
    {
      "epoch": 2.6164607828545914,
      "grad_norm": 2.806370735168457,
      "learning_rate": 3.850285370982277e-05,
      "logits/chosen": -0.961376965045929,
      "logits/rejected": -1.0012065172195435,
      "logps/chosen": -245.6499481201172,
      "logps/rejected": -281.38104248046875,
      "loss": 0.2029,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.382718086242676,
      "rewards/margins": 3.056175947189331,
      "rewards/rejected": -9.438894271850586,
      "step": 8790
    },
    {
      "epoch": 2.6194374162821847,
      "grad_norm": 4.68651008605957,
      "learning_rate": 3.8454791228597176e-05,
      "logits/chosen": -0.8796022534370422,
      "logits/rejected": -0.8729805946350098,
      "logps/chosen": -236.87600708007812,
      "logps/rejected": -273.61871337890625,
      "loss": 0.289,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.73600435256958,
      "rewards/margins": 2.9850223064422607,
      "rewards/rejected": -8.721025466918945,
      "step": 8800
    },
    {
      "epoch": 2.622414049709778,
      "grad_norm": 5.141992568969727,
      "learning_rate": 3.840672874737159e-05,
      "logits/chosen": -0.850106418132782,
      "logits/rejected": -0.8754243850708008,
      "logps/chosen": -235.57284545898438,
      "logps/rejected": -279.08685302734375,
      "loss": 0.1775,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.012853145599365,
      "rewards/margins": 3.2334556579589844,
      "rewards/rejected": -9.246309280395508,
      "step": 8810
    },
    {
      "epoch": 2.625390683137372,
      "grad_norm": 8.512385368347168,
      "learning_rate": 3.8358666266145995e-05,
      "logits/chosen": -0.75472491979599,
      "logits/rejected": -0.8180144429206848,
      "logps/chosen": -250.4229278564453,
      "logps/rejected": -315.8304748535156,
      "loss": 0.2191,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.901525974273682,
      "rewards/margins": 3.91963267326355,
      "rewards/rejected": -10.821159362792969,
      "step": 8820
    },
    {
      "epoch": 2.6283673165649653,
      "grad_norm": 4.7937798500061035,
      "learning_rate": 3.83106037849204e-05,
      "logits/chosen": -0.7714338302612305,
      "logits/rejected": -0.7598616480827332,
      "logps/chosen": -260.52691650390625,
      "logps/rejected": -293.2237243652344,
      "loss": 0.3458,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.799437522888184,
      "rewards/margins": 2.7174649238586426,
      "rewards/rejected": -10.516902923583984,
      "step": 8830
    },
    {
      "epoch": 2.6313439499925586,
      "grad_norm": 10.111701011657715,
      "learning_rate": 3.826254130369481e-05,
      "logits/chosen": -0.8442403674125671,
      "logits/rejected": -0.8627344369888306,
      "logps/chosen": -255.32131958007812,
      "logps/rejected": -293.64239501953125,
      "loss": 0.3109,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -7.042847633361816,
      "rewards/margins": 2.731417417526245,
      "rewards/rejected": -9.774264335632324,
      "step": 8840
    },
    {
      "epoch": 2.634320583420152,
      "grad_norm": 3.8581087589263916,
      "learning_rate": 3.821447882246921e-05,
      "logits/chosen": -0.772177517414093,
      "logits/rejected": -0.8933321237564087,
      "logps/chosen": -224.19113159179688,
      "logps/rejected": -278.7377624511719,
      "loss": 0.2304,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.408657073974609,
      "rewards/margins": 3.2899043560028076,
      "rewards/rejected": -9.698561668395996,
      "step": 8850
    },
    {
      "epoch": 2.6372972168477453,
      "grad_norm": 9.330618858337402,
      "learning_rate": 3.816641634124362e-05,
      "logits/chosen": -0.7114585638046265,
      "logits/rejected": -0.7866912484169006,
      "logps/chosen": -245.2044219970703,
      "logps/rejected": -300.7183837890625,
      "loss": 0.2461,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.143463134765625,
      "rewards/margins": 3.2172293663024902,
      "rewards/rejected": -10.360692977905273,
      "step": 8860
    },
    {
      "epoch": 2.6402738502753387,
      "grad_norm": 4.558748245239258,
      "learning_rate": 3.8118353860018026e-05,
      "logits/chosen": -0.8431656956672668,
      "logits/rejected": -0.845058262348175,
      "logps/chosen": -240.69589233398438,
      "logps/rejected": -275.2950744628906,
      "loss": 0.3004,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -7.334967613220215,
      "rewards/margins": 2.749927520751953,
      "rewards/rejected": -10.084895133972168,
      "step": 8870
    },
    {
      "epoch": 2.643250483702932,
      "grad_norm": 6.638084888458252,
      "learning_rate": 3.807029137879243e-05,
      "logits/chosen": -0.8177458047866821,
      "logits/rejected": -0.7995452880859375,
      "logps/chosen": -220.6556396484375,
      "logps/rejected": -262.4344177246094,
      "loss": 0.2296,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -5.950594425201416,
      "rewards/margins": 3.296729564666748,
      "rewards/rejected": -9.247323989868164,
      "step": 8880
    },
    {
      "epoch": 2.6462271171305254,
      "grad_norm": 11.81594181060791,
      "learning_rate": 3.8022228897566845e-05,
      "logits/chosen": -0.9081304669380188,
      "logits/rejected": -0.8839127421379089,
      "logps/chosen": -224.6973876953125,
      "logps/rejected": -269.00921630859375,
      "loss": 0.2582,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.160340309143066,
      "rewards/margins": 3.147359848022461,
      "rewards/rejected": -9.307699203491211,
      "step": 8890
    },
    {
      "epoch": 2.6492037505581187,
      "grad_norm": 5.544663906097412,
      "learning_rate": 3.7974166416341244e-05,
      "logits/chosen": -0.7938756942749023,
      "logits/rejected": -0.7785305380821228,
      "logps/chosen": -238.2122802734375,
      "logps/rejected": -270.09490966796875,
      "loss": 0.1589,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.030039310455322,
      "rewards/margins": 3.3712258338928223,
      "rewards/rejected": -9.401265144348145,
      "step": 8900
    },
    {
      "epoch": 2.652180383985712,
      "grad_norm": 11.04711627960205,
      "learning_rate": 3.792610393511565e-05,
      "logits/chosen": -0.8439419865608215,
      "logits/rejected": -0.8851221799850464,
      "logps/chosen": -231.37399291992188,
      "logps/rejected": -280.1847839355469,
      "loss": 0.3047,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.733199119567871,
      "rewards/margins": 3.2419562339782715,
      "rewards/rejected": -9.975153923034668,
      "step": 8910
    },
    {
      "epoch": 2.6551570174133055,
      "grad_norm": 11.650307655334473,
      "learning_rate": 3.787804145389006e-05,
      "logits/chosen": -0.857840359210968,
      "logits/rejected": -0.7352579236030579,
      "logps/chosen": -241.751220703125,
      "logps/rejected": -260.95947265625,
      "loss": 0.2268,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.165677070617676,
      "rewards/margins": 3.3528480529785156,
      "rewards/rejected": -9.518525123596191,
      "step": 8920
    },
    {
      "epoch": 2.658133650840899,
      "grad_norm": 1.9117523431777954,
      "learning_rate": 3.782997897266447e-05,
      "logits/chosen": -0.6860749125480652,
      "logits/rejected": -0.7103971242904663,
      "logps/chosen": -221.1433563232422,
      "logps/rejected": -268.0544738769531,
      "loss": 0.2411,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.12661075592041,
      "rewards/margins": 3.4760518074035645,
      "rewards/rejected": -9.602663040161133,
      "step": 8930
    },
    {
      "epoch": 2.661110284268492,
      "grad_norm": 7.550600528717041,
      "learning_rate": 3.7781916491438875e-05,
      "logits/chosen": -0.6180399656295776,
      "logits/rejected": -0.5511460900306702,
      "logps/chosen": -240.02993774414062,
      "logps/rejected": -271.1280517578125,
      "loss": 0.264,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -7.0609002113342285,
      "rewards/margins": 3.2450225353240967,
      "rewards/rejected": -10.305923461914062,
      "step": 8940
    },
    {
      "epoch": 2.6640869176960855,
      "grad_norm": 5.419733047485352,
      "learning_rate": 3.773385401021328e-05,
      "logits/chosen": -0.603131115436554,
      "logits/rejected": -0.7150284647941589,
      "logps/chosen": -254.95852661132812,
      "logps/rejected": -303.23828125,
      "loss": 0.3195,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -8.34671401977539,
      "rewards/margins": 3.138664960861206,
      "rewards/rejected": -11.485379219055176,
      "step": 8950
    },
    {
      "epoch": 2.667063551123679,
      "grad_norm": 4.379087924957275,
      "learning_rate": 3.768579152898769e-05,
      "logits/chosen": -0.6874254941940308,
      "logits/rejected": -0.6823633909225464,
      "logps/chosen": -229.953125,
      "logps/rejected": -262.6233825683594,
      "loss": 0.2775,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -7.082724094390869,
      "rewards/margins": 2.99973464012146,
      "rewards/rejected": -10.082459449768066,
      "step": 8960
    },
    {
      "epoch": 2.6700401845512727,
      "grad_norm": 7.745228290557861,
      "learning_rate": 3.7637729047762094e-05,
      "logits/chosen": -0.7182952165603638,
      "logits/rejected": -0.8185846209526062,
      "logps/chosen": -248.8699493408203,
      "logps/rejected": -303.8511657714844,
      "loss": 0.1812,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.464402675628662,
      "rewards/margins": 3.3399734497070312,
      "rewards/rejected": -10.804377555847168,
      "step": 8970
    },
    {
      "epoch": 2.673016817978866,
      "grad_norm": 4.889357566833496,
      "learning_rate": 3.75896665665365e-05,
      "logits/chosen": -0.6552508473396301,
      "logits/rejected": -0.6954101324081421,
      "logps/chosen": -236.22738647460938,
      "logps/rejected": -272.7279968261719,
      "loss": 0.2421,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -7.018911838531494,
      "rewards/margins": 3.1304829120635986,
      "rewards/rejected": -10.149393081665039,
      "step": 8980
    },
    {
      "epoch": 2.6759934514064594,
      "grad_norm": 11.094525337219238,
      "learning_rate": 3.7541604085310906e-05,
      "logits/chosen": -0.7752541899681091,
      "logits/rejected": -0.7357305288314819,
      "logps/chosen": -240.4745635986328,
      "logps/rejected": -275.0009765625,
      "loss": 0.2998,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.9558868408203125,
      "rewards/margins": 3.6093621253967285,
      "rewards/rejected": -10.565248489379883,
      "step": 8990
    },
    {
      "epoch": 2.6789700848340527,
      "grad_norm": 3.6436386108398438,
      "learning_rate": 3.749354160408531e-05,
      "logits/chosen": -0.751929759979248,
      "logits/rejected": -0.7381362318992615,
      "logps/chosen": -244.72561645507812,
      "logps/rejected": -280.5454406738281,
      "loss": 0.2215,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.5146164894104,
      "rewards/margins": 3.3022618293762207,
      "rewards/rejected": -9.816878318786621,
      "step": 9000
    },
    {
      "epoch": 2.681946718261646,
      "grad_norm": 29.36964988708496,
      "learning_rate": 3.7445479122859725e-05,
      "logits/chosen": -0.6817713379859924,
      "logits/rejected": -0.7940207123756409,
      "logps/chosen": -239.27572631835938,
      "logps/rejected": -287.7240295410156,
      "loss": 0.4047,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -7.270246982574463,
      "rewards/margins": 2.5865085124969482,
      "rewards/rejected": -9.856755256652832,
      "step": 9010
    },
    {
      "epoch": 2.6849233516892395,
      "grad_norm": 9.267252922058105,
      "learning_rate": 3.7397416641634125e-05,
      "logits/chosen": -0.8259528875350952,
      "logits/rejected": -0.9732569456100464,
      "logps/chosen": -227.84976196289062,
      "logps/rejected": -291.1751708984375,
      "loss": 0.1675,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.266770362854004,
      "rewards/margins": 3.735525131225586,
      "rewards/rejected": -10.002294540405273,
      "step": 9020
    },
    {
      "epoch": 2.687899985116833,
      "grad_norm": 6.107118129730225,
      "learning_rate": 3.734935416040853e-05,
      "logits/chosen": -0.787874162197113,
      "logits/rejected": -0.9373620748519897,
      "logps/chosen": -259.56158447265625,
      "logps/rejected": -315.69775390625,
      "loss": 0.241,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -7.443073272705078,
      "rewards/margins": 3.5778496265411377,
      "rewards/rejected": -11.020922660827637,
      "step": 9030
    },
    {
      "epoch": 2.690876618544426,
      "grad_norm": 7.217554569244385,
      "learning_rate": 3.7301291679182944e-05,
      "logits/chosen": -0.863697350025177,
      "logits/rejected": -0.8132671117782593,
      "logps/chosen": -236.0209503173828,
      "logps/rejected": -265.3119201660156,
      "loss": 0.1832,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.076672554016113,
      "rewards/margins": 3.4610214233398438,
      "rewards/rejected": -9.537694931030273,
      "step": 9040
    },
    {
      "epoch": 2.6938532519720195,
      "grad_norm": 14.882135391235352,
      "learning_rate": 3.725322919795735e-05,
      "logits/chosen": -0.7698267698287964,
      "logits/rejected": -0.8162034749984741,
      "logps/chosen": -216.0393524169922,
      "logps/rejected": -254.12796020507812,
      "loss": 0.3711,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -5.871339797973633,
      "rewards/margins": 2.78554630279541,
      "rewards/rejected": -8.656885147094727,
      "step": 9050
    },
    {
      "epoch": 2.696829885399613,
      "grad_norm": 5.25105094909668,
      "learning_rate": 3.7205166716731756e-05,
      "logits/chosen": -0.920360267162323,
      "logits/rejected": -0.878160834312439,
      "logps/chosen": -245.5413055419922,
      "logps/rejected": -277.2933654785156,
      "loss": 0.2,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.848513126373291,
      "rewards/margins": 3.334982395172119,
      "rewards/rejected": -9.183494567871094,
      "step": 9060
    },
    {
      "epoch": 2.6998065188272067,
      "grad_norm": 10.711016654968262,
      "learning_rate": 3.715710423550616e-05,
      "logits/chosen": -0.770814061164856,
      "logits/rejected": -0.7042734622955322,
      "logps/chosen": -243.7606658935547,
      "logps/rejected": -268.19476318359375,
      "loss": 0.2433,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.4971160888671875,
      "rewards/margins": 3.2435097694396973,
      "rewards/rejected": -9.740625381469727,
      "step": 9070
    },
    {
      "epoch": 2.7027831522548,
      "grad_norm": 6.727812767028809,
      "learning_rate": 3.710904175428057e-05,
      "logits/chosen": -0.6946907043457031,
      "logits/rejected": -0.7160525918006897,
      "logps/chosen": -242.1352996826172,
      "logps/rejected": -283.4115905761719,
      "loss": 0.3112,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.4939422607421875,
      "rewards/margins": 3.1233041286468506,
      "rewards/rejected": -9.617246627807617,
      "step": 9080
    },
    {
      "epoch": 2.7057597856823934,
      "grad_norm": 4.087992191314697,
      "learning_rate": 3.7060979273054974e-05,
      "logits/chosen": -0.6403035521507263,
      "logits/rejected": -0.7033451199531555,
      "logps/chosen": -239.1611785888672,
      "logps/rejected": -278.2855529785156,
      "loss": 0.2862,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.688653469085693,
      "rewards/margins": 2.960176944732666,
      "rewards/rejected": -9.648828506469727,
      "step": 9090
    },
    {
      "epoch": 2.7087364191099867,
      "grad_norm": 12.218873977661133,
      "learning_rate": 3.701291679182938e-05,
      "logits/chosen": -0.5692034363746643,
      "logits/rejected": -0.6395061016082764,
      "logps/chosen": -244.55715942382812,
      "logps/rejected": -284.85107421875,
      "loss": 0.2717,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.986472129821777,
      "rewards/margins": 2.8478288650512695,
      "rewards/rejected": -9.834300994873047,
      "step": 9100
    },
    {
      "epoch": 2.71171305253758,
      "grad_norm": 5.646556377410889,
      "learning_rate": 3.696485431060379e-05,
      "logits/chosen": -0.6352238059043884,
      "logits/rejected": -0.7643920183181763,
      "logps/chosen": -252.107421875,
      "logps/rejected": -312.44525146484375,
      "loss": 0.2928,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.422369480133057,
      "rewards/margins": 2.839639663696289,
      "rewards/rejected": -10.26201057434082,
      "step": 9110
    },
    {
      "epoch": 2.7146896859651735,
      "grad_norm": 3.1086373329162598,
      "learning_rate": 3.691679182937819e-05,
      "logits/chosen": -0.6120437383651733,
      "logits/rejected": -0.6020321249961853,
      "logps/chosen": -244.6997528076172,
      "logps/rejected": -300.2519226074219,
      "loss": 0.227,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.073543548583984,
      "rewards/margins": 3.3126914501190186,
      "rewards/rejected": -10.386235237121582,
      "step": 9120
    },
    {
      "epoch": 2.717666319392767,
      "grad_norm": 9.826348304748535,
      "learning_rate": 3.6868729348152606e-05,
      "logits/chosen": -0.6090048551559448,
      "logits/rejected": -0.6359458565711975,
      "logps/chosen": -242.4599609375,
      "logps/rejected": -287.2182312011719,
      "loss": 0.2796,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -7.459500312805176,
      "rewards/margins": 2.8444600105285645,
      "rewards/rejected": -10.303960800170898,
      "step": 9130
    },
    {
      "epoch": 2.72064295282036,
      "grad_norm": 4.134557247161865,
      "learning_rate": 3.6820666866927005e-05,
      "logits/chosen": -0.6343504190444946,
      "logits/rejected": -0.6144732236862183,
      "logps/chosen": -239.6112060546875,
      "logps/rejected": -273.7780456542969,
      "loss": 0.2546,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.469193458557129,
      "rewards/margins": 2.868171215057373,
      "rewards/rejected": -9.337364196777344,
      "step": 9140
    },
    {
      "epoch": 2.7236195862479535,
      "grad_norm": 3.9187228679656982,
      "learning_rate": 3.677260438570141e-05,
      "logits/chosen": -0.723365843296051,
      "logits/rejected": -0.7752310633659363,
      "logps/chosen": -228.9298858642578,
      "logps/rejected": -267.8977966308594,
      "loss": 0.2228,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.133973121643066,
      "rewards/margins": 2.83864426612854,
      "rewards/rejected": -8.972616195678711,
      "step": 9150
    },
    {
      "epoch": 2.726596219675547,
      "grad_norm": 7.167730331420898,
      "learning_rate": 3.6724541904475824e-05,
      "logits/chosen": -0.5809872150421143,
      "logits/rejected": -0.6365225911140442,
      "logps/chosen": -244.0902862548828,
      "logps/rejected": -284.35479736328125,
      "loss": 0.2212,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.523562431335449,
      "rewards/margins": 3.2927231788635254,
      "rewards/rejected": -9.81628704071045,
      "step": 9160
    },
    {
      "epoch": 2.7295728531031402,
      "grad_norm": 5.973953723907471,
      "learning_rate": 3.667647942325023e-05,
      "logits/chosen": -0.652129054069519,
      "logits/rejected": -0.590320885181427,
      "logps/chosen": -250.1107635498047,
      "logps/rejected": -276.03216552734375,
      "loss": 0.2157,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.788724422454834,
      "rewards/margins": 3.076727867126465,
      "rewards/rejected": -9.86545181274414,
      "step": 9170
    },
    {
      "epoch": 2.7325494865307336,
      "grad_norm": 10.407560348510742,
      "learning_rate": 3.6628416942024636e-05,
      "logits/chosen": -0.6354435682296753,
      "logits/rejected": -0.659277081489563,
      "logps/chosen": -223.32510375976562,
      "logps/rejected": -257.74957275390625,
      "loss": 0.268,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.335597515106201,
      "rewards/margins": 2.8193440437316895,
      "rewards/rejected": -9.154942512512207,
      "step": 9180
    },
    {
      "epoch": 2.735526119958327,
      "grad_norm": 15.026000022888184,
      "learning_rate": 3.658035446079904e-05,
      "logits/chosen": -0.584568977355957,
      "logits/rejected": -0.45978108048439026,
      "logps/chosen": -240.45193481445312,
      "logps/rejected": -263.29388427734375,
      "loss": 0.2417,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.650956153869629,
      "rewards/margins": 3.0436787605285645,
      "rewards/rejected": -9.694634437561035,
      "step": 9190
    },
    {
      "epoch": 2.7385027533859203,
      "grad_norm": 5.539600372314453,
      "learning_rate": 3.653229197957345e-05,
      "logits/chosen": -0.4424467980861664,
      "logits/rejected": -0.49481672048568726,
      "logps/chosen": -231.5437469482422,
      "logps/rejected": -275.4007873535156,
      "loss": 0.1927,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -7.1920928955078125,
      "rewards/margins": 3.1610686779022217,
      "rewards/rejected": -10.35316276550293,
      "step": 9200
    },
    {
      "epoch": 2.7414793868135137,
      "grad_norm": 2.115927219390869,
      "learning_rate": 3.6484229498347855e-05,
      "logits/chosen": -0.5434015989303589,
      "logits/rejected": -0.40959566831588745,
      "logps/chosen": -249.08432006835938,
      "logps/rejected": -277.3287658691406,
      "loss": 0.2714,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -7.307949066162109,
      "rewards/margins": 3.13057017326355,
      "rewards/rejected": -10.438519477844238,
      "step": 9210
    },
    {
      "epoch": 2.7444560202411075,
      "grad_norm": 11.09974193572998,
      "learning_rate": 3.643616701712226e-05,
      "logits/chosen": -0.4841267168521881,
      "logits/rejected": -0.6781183481216431,
      "logps/chosen": -221.3123016357422,
      "logps/rejected": -289.29620361328125,
      "loss": 0.3255,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.931975364685059,
      "rewards/margins": 3.631403684616089,
      "rewards/rejected": -10.563379287719727,
      "step": 9220
    },
    {
      "epoch": 2.747432653668701,
      "grad_norm": 8.86053466796875,
      "learning_rate": 3.638810453589667e-05,
      "logits/chosen": -0.5390284061431885,
      "logits/rejected": -0.591625452041626,
      "logps/chosen": -220.76077270507812,
      "logps/rejected": -271.7389221191406,
      "loss": 0.3833,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.705834865570068,
      "rewards/margins": 3.124025821685791,
      "rewards/rejected": -9.82986068725586,
      "step": 9230
    },
    {
      "epoch": 2.750409287096294,
      "grad_norm": 8.434388160705566,
      "learning_rate": 3.634004205467107e-05,
      "logits/chosen": -0.5193055868148804,
      "logits/rejected": -0.5856386423110962,
      "logps/chosen": -220.60116577148438,
      "logps/rejected": -269.9834899902344,
      "loss": 0.2805,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.38124418258667,
      "rewards/margins": 2.8866066932678223,
      "rewards/rejected": -9.267850875854492,
      "step": 9240
    },
    {
      "epoch": 2.7533859205238875,
      "grad_norm": 2.5149738788604736,
      "learning_rate": 3.6291979573445486e-05,
      "logits/chosen": -0.5712525844573975,
      "logits/rejected": -0.5806139707565308,
      "logps/chosen": -241.89938354492188,
      "logps/rejected": -283.4790954589844,
      "loss": 0.2155,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.6053466796875,
      "rewards/margins": 2.7792229652404785,
      "rewards/rejected": -9.38456916809082,
      "step": 9250
    },
    {
      "epoch": 2.756362553951481,
      "grad_norm": 11.417177200317383,
      "learning_rate": 3.6243917092219886e-05,
      "logits/chosen": -0.5533527731895447,
      "logits/rejected": -0.4832095503807068,
      "logps/chosen": -247.3441925048828,
      "logps/rejected": -272.89044189453125,
      "loss": 0.4,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -6.722771644592285,
      "rewards/margins": 2.9720466136932373,
      "rewards/rejected": -9.694818496704102,
      "step": 9260
    },
    {
      "epoch": 2.7593391873790742,
      "grad_norm": 9.406509399414062,
      "learning_rate": 3.619585461099429e-05,
      "logits/chosen": -0.4990956783294678,
      "logits/rejected": -0.656403660774231,
      "logps/chosen": -220.66806030273438,
      "logps/rejected": -286.2841796875,
      "loss": 0.1742,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.4936699867248535,
      "rewards/margins": 3.4601426124572754,
      "rewards/rejected": -9.953812599182129,
      "step": 9270
    },
    {
      "epoch": 2.7623158208066676,
      "grad_norm": 22.089834213256836,
      "learning_rate": 3.6147792129768705e-05,
      "logits/chosen": -0.6373592615127563,
      "logits/rejected": -0.6220613121986389,
      "logps/chosen": -237.1791534423828,
      "logps/rejected": -265.29168701171875,
      "loss": 0.3255,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.435330390930176,
      "rewards/margins": 2.6593289375305176,
      "rewards/rejected": -9.094658851623535,
      "step": 9280
    },
    {
      "epoch": 2.765292454234261,
      "grad_norm": 3.7672739028930664,
      "learning_rate": 3.609972964854311e-05,
      "logits/chosen": -0.6591275334358215,
      "logits/rejected": -0.6172068119049072,
      "logps/chosen": -237.4481964111328,
      "logps/rejected": -263.8651428222656,
      "loss": 0.2687,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.0960693359375,
      "rewards/margins": 2.9531919956207275,
      "rewards/rejected": -9.049261093139648,
      "step": 9290
    },
    {
      "epoch": 2.7682690876618543,
      "grad_norm": 7.693236827850342,
      "learning_rate": 3.605166716731752e-05,
      "logits/chosen": -0.5958265662193298,
      "logits/rejected": -0.623729407787323,
      "logps/chosen": -242.93063354492188,
      "logps/rejected": -296.8364562988281,
      "loss": 0.2115,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.560183525085449,
      "rewards/margins": 3.378547191619873,
      "rewards/rejected": -9.93873119354248,
      "step": 9300
    },
    {
      "epoch": 2.771245721089448,
      "grad_norm": 7.1901631355285645,
      "learning_rate": 3.600360468609192e-05,
      "logits/chosen": -0.7006728649139404,
      "logits/rejected": -0.6687764525413513,
      "logps/chosen": -237.73483276367188,
      "logps/rejected": -280.96856689453125,
      "loss": 0.2312,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.3527326583862305,
      "rewards/margins": 3.3438801765441895,
      "rewards/rejected": -9.696612358093262,
      "step": 9310
    },
    {
      "epoch": 2.7742223545170415,
      "grad_norm": 7.705904006958008,
      "learning_rate": 3.595554220486633e-05,
      "logits/chosen": -0.6303638219833374,
      "logits/rejected": -0.6624171733856201,
      "logps/chosen": -229.0279083251953,
      "logps/rejected": -269.29522705078125,
      "loss": 0.2804,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.571185111999512,
      "rewards/margins": 3.1200509071350098,
      "rewards/rejected": -9.69123649597168,
      "step": 9320
    },
    {
      "epoch": 2.777198987944635,
      "grad_norm": 4.5862603187561035,
      "learning_rate": 3.5907479723640735e-05,
      "logits/chosen": -0.6285475492477417,
      "logits/rejected": -0.6713131666183472,
      "logps/chosen": -226.2410888671875,
      "logps/rejected": -280.8774108886719,
      "loss": 0.156,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.2776780128479,
      "rewards/margins": 3.8966968059539795,
      "rewards/rejected": -10.174375534057617,
      "step": 9330
    },
    {
      "epoch": 2.780175621372228,
      "grad_norm": 11.125887870788574,
      "learning_rate": 3.585941724241514e-05,
      "logits/chosen": -0.62334805727005,
      "logits/rejected": -0.7132053971290588,
      "logps/chosen": -229.34603881835938,
      "logps/rejected": -292.995361328125,
      "loss": 0.2335,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.97855281829834,
      "rewards/margins": 3.847034454345703,
      "rewards/rejected": -10.825587272644043,
      "step": 9340
    },
    {
      "epoch": 2.7831522547998215,
      "grad_norm": 1.004828691482544,
      "learning_rate": 3.581135476118955e-05,
      "logits/chosen": -0.684675931930542,
      "logits/rejected": -0.6407372951507568,
      "logps/chosen": -229.22604370117188,
      "logps/rejected": -263.48333740234375,
      "loss": 0.2514,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.60787296295166,
      "rewards/margins": 2.8390510082244873,
      "rewards/rejected": -9.44692325592041,
      "step": 9350
    },
    {
      "epoch": 2.786128888227415,
      "grad_norm": 3.095366954803467,
      "learning_rate": 3.5763292279963954e-05,
      "logits/chosen": -0.6211304068565369,
      "logits/rejected": -0.7155672311782837,
      "logps/chosen": -232.5103302001953,
      "logps/rejected": -286.9748229980469,
      "loss": 0.1495,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.536118507385254,
      "rewards/margins": 4.290120601654053,
      "rewards/rejected": -10.826238632202148,
      "step": 9360
    },
    {
      "epoch": 2.7891055216550082,
      "grad_norm": 37.10905075073242,
      "learning_rate": 3.571522979873837e-05,
      "logits/chosen": -0.5917450785636902,
      "logits/rejected": -0.5230382680892944,
      "logps/chosen": -256.68682861328125,
      "logps/rejected": -295.7117614746094,
      "loss": 0.3077,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -8.028700828552246,
      "rewards/margins": 3.0938210487365723,
      "rewards/rejected": -11.12252140045166,
      "step": 9370
    },
    {
      "epoch": 2.7920821550826016,
      "grad_norm": 5.780149459838867,
      "learning_rate": 3.5667167317512766e-05,
      "logits/chosen": -0.6557181477546692,
      "logits/rejected": -0.6694371700286865,
      "logps/chosen": -251.24636840820312,
      "logps/rejected": -285.96868896484375,
      "loss": 0.3603,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.7609124183654785,
      "rewards/margins": 3.1516458988189697,
      "rewards/rejected": -9.912558555603027,
      "step": 9380
    },
    {
      "epoch": 2.795058788510195,
      "grad_norm": 8.133928298950195,
      "learning_rate": 3.561910483628717e-05,
      "logits/chosen": -0.6469305753707886,
      "logits/rejected": -0.6226391792297363,
      "logps/chosen": -244.99832153320312,
      "logps/rejected": -274.64544677734375,
      "loss": 0.3266,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -7.463604927062988,
      "rewards/margins": 2.7001616954803467,
      "rewards/rejected": -10.163766860961914,
      "step": 9390
    },
    {
      "epoch": 2.7980354219377883,
      "grad_norm": 2.9302072525024414,
      "learning_rate": 3.5571042355061585e-05,
      "logits/chosen": -0.6290534138679504,
      "logits/rejected": -0.570650577545166,
      "logps/chosen": -252.38345336914062,
      "logps/rejected": -283.4775085449219,
      "loss": 0.2309,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -7.278410911560059,
      "rewards/margins": 3.253873348236084,
      "rewards/rejected": -10.5322847366333,
      "step": 9400
    },
    {
      "epoch": 2.8010120553653817,
      "grad_norm": 3.4370479583740234,
      "learning_rate": 3.552297987383599e-05,
      "logits/chosen": -0.5341969728469849,
      "logits/rejected": -0.5323593020439148,
      "logps/chosen": -240.6468963623047,
      "logps/rejected": -274.83343505859375,
      "loss": 0.2441,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -7.728579521179199,
      "rewards/margins": 2.9380903244018555,
      "rewards/rejected": -10.666669845581055,
      "step": 9410
    },
    {
      "epoch": 2.803988688792975,
      "grad_norm": 4.792204856872559,
      "learning_rate": 3.54749173926104e-05,
      "logits/chosen": -0.5459516048431396,
      "logits/rejected": -0.6719788908958435,
      "logps/chosen": -239.9792938232422,
      "logps/rejected": -283.0976867675781,
      "loss": 0.2477,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -7.0343194007873535,
      "rewards/margins": 3.2759220600128174,
      "rewards/rejected": -10.31024169921875,
      "step": 9420
    },
    {
      "epoch": 2.8069653222205684,
      "grad_norm": 2.1615374088287354,
      "learning_rate": 3.5426854911384804e-05,
      "logits/chosen": -0.7175547480583191,
      "logits/rejected": -0.6607123613357544,
      "logps/chosen": -241.44985961914062,
      "logps/rejected": -274.9308166503906,
      "loss": 0.2306,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.570408821105957,
      "rewards/margins": 3.0605759620666504,
      "rewards/rejected": -9.630985260009766,
      "step": 9430
    },
    {
      "epoch": 2.8099419556481617,
      "grad_norm": 3.2623724937438965,
      "learning_rate": 3.537879243015921e-05,
      "logits/chosen": -0.6878656148910522,
      "logits/rejected": -0.6776002645492554,
      "logps/chosen": -234.19088745117188,
      "logps/rejected": -267.66973876953125,
      "loss": 0.2205,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.433610439300537,
      "rewards/margins": 2.827618360519409,
      "rewards/rejected": -9.261229515075684,
      "step": 9440
    },
    {
      "epoch": 2.812918589075755,
      "grad_norm": 5.882075309753418,
      "learning_rate": 3.5330729948933616e-05,
      "logits/chosen": -0.657060980796814,
      "logits/rejected": -0.6449424028396606,
      "logps/chosen": -265.32501220703125,
      "logps/rejected": -296.16693115234375,
      "loss": 0.2443,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.227846622467041,
      "rewards/margins": 2.6999905109405518,
      "rewards/rejected": -9.927836418151855,
      "step": 9450
    },
    {
      "epoch": 2.8158952225033484,
      "grad_norm": 7.08521842956543,
      "learning_rate": 3.528266746770802e-05,
      "logits/chosen": -0.6774507761001587,
      "logits/rejected": -0.619316577911377,
      "logps/chosen": -222.2114715576172,
      "logps/rejected": -249.3206329345703,
      "loss": 0.2243,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.472123146057129,
      "rewards/margins": 2.990269660949707,
      "rewards/rejected": -8.462393760681152,
      "step": 9460
    },
    {
      "epoch": 2.8188718559309422,
      "grad_norm": 6.33342981338501,
      "learning_rate": 3.523460498648243e-05,
      "logits/chosen": -0.7611567378044128,
      "logits/rejected": -0.7782570123672485,
      "logps/chosen": -239.33273315429688,
      "logps/rejected": -283.7768249511719,
      "loss": 0.1895,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.293158054351807,
      "rewards/margins": 3.3131461143493652,
      "rewards/rejected": -9.606303215026855,
      "step": 9470
    },
    {
      "epoch": 2.8218484893585356,
      "grad_norm": 15.094281196594238,
      "learning_rate": 3.5186542505256834e-05,
      "logits/chosen": -0.6362541317939758,
      "logits/rejected": -0.6872098445892334,
      "logps/chosen": -234.9597625732422,
      "logps/rejected": -273.78033447265625,
      "loss": 0.285,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.1951904296875,
      "rewards/margins": 2.9298930168151855,
      "rewards/rejected": -10.125082969665527,
      "step": 9480
    },
    {
      "epoch": 2.824825122786129,
      "grad_norm": 2.744534492492676,
      "learning_rate": 3.513848002403125e-05,
      "logits/chosen": -0.6959661245346069,
      "logits/rejected": -0.7835139036178589,
      "logps/chosen": -246.8702392578125,
      "logps/rejected": -292.4069519042969,
      "loss": 0.265,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.8032073974609375,
      "rewards/margins": 2.885526418685913,
      "rewards/rejected": -9.68873405456543,
      "step": 9490
    },
    {
      "epoch": 2.8278017562137223,
      "grad_norm": 3.677704095840454,
      "learning_rate": 3.509041754280565e-05,
      "logits/chosen": -0.690802276134491,
      "logits/rejected": -0.727604329586029,
      "logps/chosen": -229.4849090576172,
      "logps/rejected": -272.0277404785156,
      "loss": 0.2452,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.1806840896606445,
      "rewards/margins": 3.375497817993164,
      "rewards/rejected": -9.556183815002441,
      "step": 9500
    },
    {
      "epoch": 2.8307783896413157,
      "grad_norm": 1.7570091485977173,
      "learning_rate": 3.504235506158005e-05,
      "logits/chosen": -0.666784942150116,
      "logits/rejected": -0.704961895942688,
      "logps/chosen": -234.7834014892578,
      "logps/rejected": -273.3443603515625,
      "loss": 0.2422,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.540312767028809,
      "rewards/margins": 2.9106271266937256,
      "rewards/rejected": -9.450940132141113,
      "step": 9510
    },
    {
      "epoch": 2.833755023068909,
      "grad_norm": 6.951675891876221,
      "learning_rate": 3.4994292580354466e-05,
      "logits/chosen": -0.738562822341919,
      "logits/rejected": -0.7513336539268494,
      "logps/chosen": -239.9913330078125,
      "logps/rejected": -272.38262939453125,
      "loss": 0.2394,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.689277648925781,
      "rewards/margins": 2.9085824489593506,
      "rewards/rejected": -9.597860336303711,
      "step": 9520
    },
    {
      "epoch": 2.8367316564965024,
      "grad_norm": 7.420191764831543,
      "learning_rate": 3.494623009912887e-05,
      "logits/chosen": -0.7435091733932495,
      "logits/rejected": -0.775858998298645,
      "logps/chosen": -224.9455108642578,
      "logps/rejected": -266.75189208984375,
      "loss": 0.2297,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.7519636154174805,
      "rewards/margins": 2.9530537128448486,
      "rewards/rejected": -8.70501708984375,
      "step": 9530
    },
    {
      "epoch": 2.8397082899240957,
      "grad_norm": 6.283024787902832,
      "learning_rate": 3.489816761790328e-05,
      "logits/chosen": -0.7256342768669128,
      "logits/rejected": -0.701454758644104,
      "logps/chosen": -230.878173828125,
      "logps/rejected": -257.11151123046875,
      "loss": 0.2752,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.558109283447266,
      "rewards/margins": 2.732177734375,
      "rewards/rejected": -9.29028606414795,
      "step": 9540
    },
    {
      "epoch": 2.842684923351689,
      "grad_norm": 9.276894569396973,
      "learning_rate": 3.4850105136677684e-05,
      "logits/chosen": -0.6831148862838745,
      "logits/rejected": -0.6404807567596436,
      "logps/chosen": -217.72998046875,
      "logps/rejected": -267.28851318359375,
      "loss": 0.2091,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.615447044372559,
      "rewards/margins": 3.3489887714385986,
      "rewards/rejected": -8.964436531066895,
      "step": 9550
    },
    {
      "epoch": 2.845661556779283,
      "grad_norm": 3.2560243606567383,
      "learning_rate": 3.480204265545209e-05,
      "logits/chosen": -0.7642744779586792,
      "logits/rejected": -0.679105818271637,
      "logps/chosen": -269.02032470703125,
      "logps/rejected": -289.43389892578125,
      "loss": 0.2316,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.843850135803223,
      "rewards/margins": 3.2427799701690674,
      "rewards/rejected": -10.086629867553711,
      "step": 9560
    },
    {
      "epoch": 2.8486381902068763,
      "grad_norm": 8.687080383300781,
      "learning_rate": 3.4753980174226497e-05,
      "logits/chosen": -0.5856231451034546,
      "logits/rejected": -0.6325315237045288,
      "logps/chosen": -243.7168426513672,
      "logps/rejected": -281.1812438964844,
      "loss": 0.3795,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -6.410011291503906,
      "rewards/margins": 2.6719322204589844,
      "rewards/rejected": -9.081944465637207,
      "step": 9570
    },
    {
      "epoch": 2.8516148236344696,
      "grad_norm": 6.202707290649414,
      "learning_rate": 3.47059176930009e-05,
      "logits/chosen": -0.679271399974823,
      "logits/rejected": -0.6725692749023438,
      "logps/chosen": -225.7039794921875,
      "logps/rejected": -263.0595397949219,
      "loss": 0.3619,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.022491455078125,
      "rewards/margins": 2.7922866344451904,
      "rewards/rejected": -8.814778327941895,
      "step": 9580
    },
    {
      "epoch": 2.854591457062063,
      "grad_norm": 4.626526832580566,
      "learning_rate": 3.465785521177531e-05,
      "logits/chosen": -0.7485120296478271,
      "logits/rejected": -0.7973724603652954,
      "logps/chosen": -230.43850708007812,
      "logps/rejected": -277.6731872558594,
      "loss": 0.2646,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.5901923179626465,
      "rewards/margins": 2.756788730621338,
      "rewards/rejected": -9.346982955932617,
      "step": 9590
    },
    {
      "epoch": 2.8575680904896563,
      "grad_norm": 3.8489527702331543,
      "learning_rate": 3.4609792730549715e-05,
      "logits/chosen": -0.6608564853668213,
      "logits/rejected": -0.7339325547218323,
      "logps/chosen": -223.00448608398438,
      "logps/rejected": -261.64593505859375,
      "loss": 0.2549,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.132604122161865,
      "rewards/margins": 2.576887369155884,
      "rewards/rejected": -8.709492683410645,
      "step": 9600
    },
    {
      "epoch": 2.8605447239172497,
      "grad_norm": 4.249612331390381,
      "learning_rate": 3.456173024932413e-05,
      "logits/chosen": -0.6079264283180237,
      "logits/rejected": -0.6748976707458496,
      "logps/chosen": -221.1101837158203,
      "logps/rejected": -266.2571105957031,
      "loss": 0.2463,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.605851650238037,
      "rewards/margins": 3.0160677433013916,
      "rewards/rejected": -8.621919631958008,
      "step": 9610
    },
    {
      "epoch": 2.863521357344843,
      "grad_norm": 3.201340436935425,
      "learning_rate": 3.451366776809853e-05,
      "logits/chosen": -0.648154616355896,
      "logits/rejected": -0.7247408628463745,
      "logps/chosen": -226.651611328125,
      "logps/rejected": -262.4049072265625,
      "loss": 0.2469,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.422171115875244,
      "rewards/margins": 2.786119222640991,
      "rewards/rejected": -9.208290100097656,
      "step": 9620
    },
    {
      "epoch": 2.8664979907724364,
      "grad_norm": 2.486966133117676,
      "learning_rate": 3.4465605286872933e-05,
      "logits/chosen": -0.7665941715240479,
      "logits/rejected": -0.6976572275161743,
      "logps/chosen": -227.82150268554688,
      "logps/rejected": -264.29559326171875,
      "loss": 0.3006,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -5.7129316329956055,
      "rewards/margins": 2.881649971008301,
      "rewards/rejected": -8.59458065032959,
      "step": 9630
    },
    {
      "epoch": 2.8694746242000297,
      "grad_norm": 15.054976463317871,
      "learning_rate": 3.4417542805647346e-05,
      "logits/chosen": -0.6796032190322876,
      "logits/rejected": -0.7167380452156067,
      "logps/chosen": -223.1351776123047,
      "logps/rejected": -254.08145141601562,
      "loss": 0.2688,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.230034828186035,
      "rewards/margins": 2.4889698028564453,
      "rewards/rejected": -7.719004154205322,
      "step": 9640
    },
    {
      "epoch": 2.872451257627623,
      "grad_norm": 10.015970230102539,
      "learning_rate": 3.436948032442175e-05,
      "logits/chosen": -0.6599870324134827,
      "logits/rejected": -0.7303685545921326,
      "logps/chosen": -233.06802368164062,
      "logps/rejected": -290.0870361328125,
      "loss": 0.2806,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.301409721374512,
      "rewards/margins": 2.970120906829834,
      "rewards/rejected": -9.271531105041504,
      "step": 9650
    },
    {
      "epoch": 2.8754278910552165,
      "grad_norm": 6.683670997619629,
      "learning_rate": 3.432141784319616e-05,
      "logits/chosen": -0.7231581807136536,
      "logits/rejected": -0.6857188940048218,
      "logps/chosen": -249.6422576904297,
      "logps/rejected": -288.0805969238281,
      "loss": 0.2112,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.308867931365967,
      "rewards/margins": 3.0461764335632324,
      "rewards/rejected": -9.355045318603516,
      "step": 9660
    },
    {
      "epoch": 2.87840452448281,
      "grad_norm": 7.754927158355713,
      "learning_rate": 3.4273355361970565e-05,
      "logits/chosen": -0.7181768417358398,
      "logits/rejected": -0.8126443028450012,
      "logps/chosen": -239.79757690429688,
      "logps/rejected": -280.95452880859375,
      "loss": 0.2749,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.903874397277832,
      "rewards/margins": 2.755654811859131,
      "rewards/rejected": -9.659528732299805,
      "step": 9670
    },
    {
      "epoch": 2.881381157910403,
      "grad_norm": 3.35491943359375,
      "learning_rate": 3.422529288074497e-05,
      "logits/chosen": -0.6857311725616455,
      "logits/rejected": -0.6204245090484619,
      "logps/chosen": -239.46920776367188,
      "logps/rejected": -257.94189453125,
      "loss": 0.3688,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.477692604064941,
      "rewards/margins": 2.618290662765503,
      "rewards/rejected": -9.095983505249023,
      "step": 9680
    },
    {
      "epoch": 2.8843577913379965,
      "grad_norm": 13.981857299804688,
      "learning_rate": 3.417723039951938e-05,
      "logits/chosen": -0.651052713394165,
      "logits/rejected": -0.7049063444137573,
      "logps/chosen": -238.6939239501953,
      "logps/rejected": -281.19091796875,
      "loss": 0.2178,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.515453338623047,
      "rewards/margins": 2.8560948371887207,
      "rewards/rejected": -9.371548652648926,
      "step": 9690
    },
    {
      "epoch": 2.88733442476559,
      "grad_norm": 6.767333984375,
      "learning_rate": 3.412916791829378e-05,
      "logits/chosen": -0.7030708193778992,
      "logits/rejected": -0.7039650678634644,
      "logps/chosen": -237.5244903564453,
      "logps/rejected": -284.3153991699219,
      "loss": 0.2112,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.6432671546936035,
      "rewards/margins": 3.170011281967163,
      "rewards/rejected": -9.813279151916504,
      "step": 9700
    },
    {
      "epoch": 2.8903110581931832,
      "grad_norm": 6.473371505737305,
      "learning_rate": 3.408110543706819e-05,
      "logits/chosen": -0.601040244102478,
      "logits/rejected": -0.5969938039779663,
      "logps/chosen": -256.1308288574219,
      "logps/rejected": -284.9250183105469,
      "loss": 0.2849,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -7.151960849761963,
      "rewards/margins": 2.6945879459381104,
      "rewards/rejected": -9.846549034118652,
      "step": 9710
    },
    {
      "epoch": 2.893287691620777,
      "grad_norm": 3.5993740558624268,
      "learning_rate": 3.40330429558426e-05,
      "logits/chosen": -0.7198466062545776,
      "logits/rejected": -0.8049508333206177,
      "logps/chosen": -237.3166961669922,
      "logps/rejected": -280.262451171875,
      "loss": 0.254,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -7.024916172027588,
      "rewards/margins": 3.081566572189331,
      "rewards/rejected": -10.10648250579834,
      "step": 9720
    },
    {
      "epoch": 2.8962643250483704,
      "grad_norm": 6.302070617675781,
      "learning_rate": 3.398498047461701e-05,
      "logits/chosen": -0.689679741859436,
      "logits/rejected": -0.7498145699501038,
      "logps/chosen": -230.54733276367188,
      "logps/rejected": -264.2926025390625,
      "loss": 0.2344,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.47824764251709,
      "rewards/margins": 2.7251200675964355,
      "rewards/rejected": -9.203367233276367,
      "step": 9730
    },
    {
      "epoch": 2.8992409584759637,
      "grad_norm": 1.6067898273468018,
      "learning_rate": 3.393691799339141e-05,
      "logits/chosen": -0.7287238836288452,
      "logits/rejected": -0.6352943181991577,
      "logps/chosen": -245.18704223632812,
      "logps/rejected": -275.3720703125,
      "loss": 0.1943,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.2292160987854,
      "rewards/margins": 3.1579642295837402,
      "rewards/rejected": -9.38718032836914,
      "step": 9740
    },
    {
      "epoch": 2.902217591903557,
      "grad_norm": 7.658848285675049,
      "learning_rate": 3.3888855512165814e-05,
      "logits/chosen": -0.591742217540741,
      "logits/rejected": -0.6405738592147827,
      "logps/chosen": -237.8938446044922,
      "logps/rejected": -294.6893310546875,
      "loss": 0.1671,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.671104431152344,
      "rewards/margins": 3.788252353668213,
      "rewards/rejected": -10.459356307983398,
      "step": 9750
    },
    {
      "epoch": 2.9051942253311505,
      "grad_norm": 16.70008087158203,
      "learning_rate": 3.384079303094023e-05,
      "logits/chosen": -0.5534436106681824,
      "logits/rejected": -0.6381027102470398,
      "logps/chosen": -260.821533203125,
      "logps/rejected": -312.552001953125,
      "loss": 0.1844,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -8.142007827758789,
      "rewards/margins": 3.950313091278076,
      "rewards/rejected": -12.092321395874023,
      "step": 9760
    },
    {
      "epoch": 2.908170858758744,
      "grad_norm": 9.09842586517334,
      "learning_rate": 3.379273054971463e-05,
      "logits/chosen": -0.6136292219161987,
      "logits/rejected": -0.6047353744506836,
      "logps/chosen": -243.9256134033203,
      "logps/rejected": -286.8564147949219,
      "loss": 0.3166,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -7.071259498596191,
      "rewards/margins": 3.3624072074890137,
      "rewards/rejected": -10.43366813659668,
      "step": 9770
    },
    {
      "epoch": 2.911147492186337,
      "grad_norm": 3.0524203777313232,
      "learning_rate": 3.374466806848904e-05,
      "logits/chosen": -0.6817499995231628,
      "logits/rejected": -0.8357593417167664,
      "logps/chosen": -226.22555541992188,
      "logps/rejected": -274.23004150390625,
      "loss": 0.2583,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.792366027832031,
      "rewards/margins": 2.549471378326416,
      "rewards/rejected": -9.341836929321289,
      "step": 9780
    },
    {
      "epoch": 2.9141241256139305,
      "grad_norm": 2.9745025634765625,
      "learning_rate": 3.3696605587263445e-05,
      "logits/chosen": -0.5517374873161316,
      "logits/rejected": -0.5729304552078247,
      "logps/chosen": -253.48086547851562,
      "logps/rejected": -313.64361572265625,
      "loss": 0.2218,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.220279693603516,
      "rewards/margins": 3.285884141921997,
      "rewards/rejected": -10.506162643432617,
      "step": 9790
    },
    {
      "epoch": 2.917100759041524,
      "grad_norm": 4.786869525909424,
      "learning_rate": 3.364854310603785e-05,
      "logits/chosen": -0.5844334959983826,
      "logits/rejected": -0.6390870809555054,
      "logps/chosen": -260.1522521972656,
      "logps/rejected": -301.8631896972656,
      "loss": 0.1996,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -8.621061325073242,
      "rewards/margins": 3.1939852237701416,
      "rewards/rejected": -11.815046310424805,
      "step": 9800
    },
    {
      "epoch": 2.9200773924691177,
      "grad_norm": 5.5408935546875,
      "learning_rate": 3.360048062481226e-05,
      "logits/chosen": -0.7831741571426392,
      "logits/rejected": -0.6740711331367493,
      "logps/chosen": -235.96847534179688,
      "logps/rejected": -257.3384094238281,
      "loss": 0.245,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.259350776672363,
      "rewards/margins": 2.938495397567749,
      "rewards/rejected": -9.197845458984375,
      "step": 9810
    },
    {
      "epoch": 2.923054025896711,
      "grad_norm": 14.930198669433594,
      "learning_rate": 3.3552418143586664e-05,
      "logits/chosen": -0.7249873280525208,
      "logits/rejected": -0.7364225387573242,
      "logps/chosen": -244.9603729248047,
      "logps/rejected": -291.7657775878906,
      "loss": 0.2496,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.580684661865234,
      "rewards/margins": 3.2251079082489014,
      "rewards/rejected": -9.805791854858398,
      "step": 9820
    },
    {
      "epoch": 2.9260306593243044,
      "grad_norm": 6.897357940673828,
      "learning_rate": 3.350435566236107e-05,
      "logits/chosen": -0.7214046716690063,
      "logits/rejected": -0.7358191609382629,
      "logps/chosen": -245.6416473388672,
      "logps/rejected": -280.1291198730469,
      "loss": 0.2631,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -7.245408535003662,
      "rewards/margins": 2.79799747467041,
      "rewards/rejected": -10.043405532836914,
      "step": 9830
    },
    {
      "epoch": 2.9290072927518978,
      "grad_norm": 7.371056079864502,
      "learning_rate": 3.345629318113548e-05,
      "logits/chosen": -0.6795329451560974,
      "logits/rejected": -0.6561486124992371,
      "logps/chosen": -241.98562622070312,
      "logps/rejected": -283.66351318359375,
      "loss": 0.2499,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -7.2029314041137695,
      "rewards/margins": 3.103900671005249,
      "rewards/rejected": -10.306831359863281,
      "step": 9840
    },
    {
      "epoch": 2.931983926179491,
      "grad_norm": 4.325817108154297,
      "learning_rate": 3.340823069990989e-05,
      "logits/chosen": -0.5022760629653931,
      "logits/rejected": -0.5143382549285889,
      "logps/chosen": -249.32373046875,
      "logps/rejected": -286.1679992675781,
      "loss": 0.2013,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -7.543936252593994,
      "rewards/margins": 3.217803955078125,
      "rewards/rejected": -10.761739730834961,
      "step": 9850
    },
    {
      "epoch": 2.9349605596070845,
      "grad_norm": 5.4567999839782715,
      "learning_rate": 3.336016821868429e-05,
      "logits/chosen": -0.6109732389450073,
      "logits/rejected": -0.5910316109657288,
      "logps/chosen": -236.4042510986328,
      "logps/rejected": -280.2582092285156,
      "loss": 0.2066,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.705239772796631,
      "rewards/margins": 3.397610902786255,
      "rewards/rejected": -10.102851867675781,
      "step": 9860
    },
    {
      "epoch": 2.937937193034678,
      "grad_norm": 5.925931453704834,
      "learning_rate": 3.3312105737458694e-05,
      "logits/chosen": -0.6937621831893921,
      "logits/rejected": -0.7017737627029419,
      "logps/chosen": -229.9920654296875,
      "logps/rejected": -275.23211669921875,
      "loss": 0.2646,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.445733070373535,
      "rewards/margins": 3.0847644805908203,
      "rewards/rejected": -9.530497550964355,
      "step": 9870
    },
    {
      "epoch": 2.940913826462271,
      "grad_norm": 14.536218643188477,
      "learning_rate": 3.326404325623311e-05,
      "logits/chosen": -0.6463802456855774,
      "logits/rejected": -0.756790041923523,
      "logps/chosen": -260.8778076171875,
      "logps/rejected": -312.2760314941406,
      "loss": 0.2118,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -7.217637538909912,
      "rewards/margins": 3.2501583099365234,
      "rewards/rejected": -10.467796325683594,
      "step": 9880
    },
    {
      "epoch": 2.9438904598898645,
      "grad_norm": 5.4745001792907715,
      "learning_rate": 3.3215980775007514e-05,
      "logits/chosen": -0.6822748780250549,
      "logits/rejected": -0.614580512046814,
      "logps/chosen": -227.72402954101562,
      "logps/rejected": -268.68475341796875,
      "loss": 0.2127,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.554958343505859,
      "rewards/margins": 3.347501039505005,
      "rewards/rejected": -9.902459144592285,
      "step": 9890
    },
    {
      "epoch": 2.946867093317458,
      "grad_norm": 3.0449864864349365,
      "learning_rate": 3.316791829378192e-05,
      "logits/chosen": -0.717546820640564,
      "logits/rejected": -0.6981933116912842,
      "logps/chosen": -242.0155487060547,
      "logps/rejected": -270.61041259765625,
      "loss": 0.2321,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.819553375244141,
      "rewards/margins": 2.835365056991577,
      "rewards/rejected": -9.654918670654297,
      "step": 9900
    },
    {
      "epoch": 2.9498437267450512,
      "grad_norm": 9.822487831115723,
      "learning_rate": 3.3119855812556326e-05,
      "logits/chosen": -0.6581277847290039,
      "logits/rejected": -0.6663563847541809,
      "logps/chosen": -229.70242309570312,
      "logps/rejected": -267.2284240722656,
      "loss": 0.2963,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.59890079498291,
      "rewards/margins": 2.96254563331604,
      "rewards/rejected": -9.561445236206055,
      "step": 9910
    },
    {
      "epoch": 2.9528203601726446,
      "grad_norm": 6.400832653045654,
      "learning_rate": 3.307179333133073e-05,
      "logits/chosen": -0.6880375146865845,
      "logits/rejected": -0.772915780544281,
      "logps/chosen": -236.7348175048828,
      "logps/rejected": -293.0433654785156,
      "loss": 0.2235,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.798188209533691,
      "rewards/margins": 3.1601150035858154,
      "rewards/rejected": -9.958303451538086,
      "step": 9920
    },
    {
      "epoch": 2.955796993600238,
      "grad_norm": 6.543014049530029,
      "learning_rate": 3.302373085010514e-05,
      "logits/chosen": -0.6511216163635254,
      "logits/rejected": -0.7509839534759521,
      "logps/chosen": -223.40939331054688,
      "logps/rejected": -262.0069885253906,
      "loss": 0.2671,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.573050022125244,
      "rewards/margins": 2.795560836791992,
      "rewards/rejected": -9.368612289428711,
      "step": 9930
    },
    {
      "epoch": 2.9587736270278313,
      "grad_norm": 6.894161701202393,
      "learning_rate": 3.2975668368879544e-05,
      "logits/chosen": -0.7242068648338318,
      "logits/rejected": -0.6926618218421936,
      "logps/chosen": -238.95046997070312,
      "logps/rejected": -270.49835205078125,
      "loss": 0.2389,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.8035078048706055,
      "rewards/margins": 3.037177324295044,
      "rewards/rejected": -9.84068489074707,
      "step": 9940
    },
    {
      "epoch": 2.9617502604554247,
      "grad_norm": 3.4565417766571045,
      "learning_rate": 3.292760588765395e-05,
      "logits/chosen": -0.6446126699447632,
      "logits/rejected": -0.7463021874427795,
      "logps/chosen": -239.0891571044922,
      "logps/rejected": -292.7305603027344,
      "loss": 0.2583,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.937779903411865,
      "rewards/margins": 2.7945199012756348,
      "rewards/rejected": -9.732300758361816,
      "step": 9950
    },
    {
      "epoch": 2.9647268938830185,
      "grad_norm": 7.713287353515625,
      "learning_rate": 3.287954340642836e-05,
      "logits/chosen": -0.7691160440444946,
      "logits/rejected": -0.7920691967010498,
      "logps/chosen": -228.7286376953125,
      "logps/rejected": -263.8736267089844,
      "loss": 0.2689,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -6.42534875869751,
      "rewards/margins": 2.7186055183410645,
      "rewards/rejected": -9.143953323364258,
      "step": 9960
    },
    {
      "epoch": 2.967703527310612,
      "grad_norm": 8.342370986938477,
      "learning_rate": 3.283148092520277e-05,
      "logits/chosen": -0.7501130104064941,
      "logits/rejected": -0.7997766733169556,
      "logps/chosen": -234.2049102783203,
      "logps/rejected": -275.17047119140625,
      "loss": 0.4077,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -6.7403740882873535,
      "rewards/margins": 2.669562578201294,
      "rewards/rejected": -9.409936904907227,
      "step": 9970
    },
    {
      "epoch": 2.970680160738205,
      "grad_norm": 4.738150119781494,
      "learning_rate": 3.2783418443977176e-05,
      "logits/chosen": -0.7723057866096497,
      "logits/rejected": -0.8536229133605957,
      "logps/chosen": -226.27383422851562,
      "logps/rejected": -279.70623779296875,
      "loss": 0.2437,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.7784600257873535,
      "rewards/margins": 3.51118540763855,
      "rewards/rejected": -10.289645195007324,
      "step": 9980
    },
    {
      "epoch": 2.9736567941657985,
      "grad_norm": 6.2900214195251465,
      "learning_rate": 3.2735355962751575e-05,
      "logits/chosen": -0.7440798282623291,
      "logits/rejected": -0.7421436309814453,
      "logps/chosen": -243.365478515625,
      "logps/rejected": -289.46807861328125,
      "loss": 0.2405,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -6.804182529449463,
      "rewards/margins": 3.4382972717285156,
      "rewards/rejected": -10.24247932434082,
      "step": 9990
    },
    {
      "epoch": 2.976633427593392,
      "grad_norm": 6.752107620239258,
      "learning_rate": 3.268729348152599e-05,
      "logits/chosen": -0.8168749809265137,
      "logits/rejected": -0.9022367596626282,
      "logps/chosen": -234.68319702148438,
      "logps/rejected": -280.830322265625,
      "loss": 0.1936,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -6.14340877532959,
      "rewards/margins": 3.5312438011169434,
      "rewards/rejected": -9.674653053283691,
      "step": 10000
    },
    {
      "epoch": 2.9796100610209852,
      "grad_norm": 2.6451728343963623,
      "learning_rate": 3.2639231000300394e-05,
      "logits/chosen": -0.7929586172103882,
      "logits/rejected": -0.843073844909668,
      "logps/chosen": -235.0001983642578,
      "logps/rejected": -282.82891845703125,
      "loss": 0.2452,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -7.170835018157959,
      "rewards/margins": 3.1041135787963867,
      "rewards/rejected": -10.274948120117188,
      "step": 10010
    },
    {
      "epoch": 2.9825866944485786,
      "grad_norm": 8.247344017028809,
      "learning_rate": 3.25911685190748e-05,
      "logits/chosen": -0.8386660814285278,
      "logits/rejected": -0.9519084692001343,
      "logps/chosen": -216.64920043945312,
      "logps/rejected": -272.75885009765625,
      "loss": 0.2944,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -6.576885223388672,
      "rewards/margins": 3.134737253189087,
      "rewards/rejected": -9.711623191833496,
      "step": 10020
    },
    {
      "epoch": 2.985563327876172,
      "grad_norm": 6.723414897918701,
      "learning_rate": 3.2543106037849206e-05,
      "logits/chosen": -0.8205930590629578,
      "logits/rejected": -0.8438116312026978,
      "logps/chosen": -238.8426513671875,
      "logps/rejected": -285.1878356933594,
      "loss": 0.2503,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.0794854164123535,
      "rewards/margins": 3.368016481399536,
      "rewards/rejected": -9.447502136230469,
      "step": 10030
    },
    {
      "epoch": 2.9885399613037653,
      "grad_norm": 9.12564468383789,
      "learning_rate": 3.249504355662361e-05,
      "logits/chosen": -0.8078948259353638,
      "logits/rejected": -0.9187692403793335,
      "logps/chosen": -220.29415893554688,
      "logps/rejected": -275.95562744140625,
      "loss": 0.2547,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -5.756201267242432,
      "rewards/margins": 3.7290427684783936,
      "rewards/rejected": -9.485244750976562,
      "step": 10040
    },
    {
      "epoch": 2.9915165947313587,
      "grad_norm": 6.228079319000244,
      "learning_rate": 3.244698107539802e-05,
      "logits/chosen": -0.8352636098861694,
      "logits/rejected": -0.8413498997688293,
      "logps/chosen": -240.55859375,
      "logps/rejected": -281.96826171875,
      "loss": 0.2155,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.488954067230225,
      "rewards/margins": 3.368619203567505,
      "rewards/rejected": -9.857575416564941,
      "step": 10050
    },
    {
      "epoch": 2.9944932281589525,
      "grad_norm": 5.210285663604736,
      "learning_rate": 3.2398918594172425e-05,
      "logits/chosen": -0.8248066902160645,
      "logits/rejected": -0.8279555439949036,
      "logps/chosen": -231.91140747070312,
      "logps/rejected": -279.3765563964844,
      "loss": 0.1959,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -5.826091766357422,
      "rewards/margins": 3.91273832321167,
      "rewards/rejected": -9.738829612731934,
      "step": 10060
    },
    {
      "epoch": 2.997469861586546,
      "grad_norm": 2.7954039573669434,
      "learning_rate": 3.235085611294683e-05,
      "logits/chosen": -0.8324111700057983,
      "logits/rejected": -0.8713104128837585,
      "logps/chosen": -258.74072265625,
      "logps/rejected": -304.1173400878906,
      "loss": 0.1947,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -6.9626665115356445,
      "rewards/margins": 3.445310115814209,
      "rewards/rejected": -10.407976150512695,
      "step": 10070
    },
    {
      "epoch": 3.000446495014139,
      "grad_norm": 3.249779224395752,
      "learning_rate": 3.2302793631721244e-05,
      "logits/chosen": -0.7352923154830933,
      "logits/rejected": -0.7684574723243713,
      "logps/chosen": -235.3817901611328,
      "logps/rejected": -267.7145690917969,
      "loss": 0.2058,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.900288105010986,
      "rewards/margins": 3.288541316986084,
      "rewards/rejected": -9.18882942199707,
      "step": 10080
    },
    {
      "epoch": 3.0034231284417325,
      "grad_norm": 2.9006311893463135,
      "learning_rate": 3.225473115049565e-05,
      "logits/chosen": -0.6522785425186157,
      "logits/rejected": -0.7735521197319031,
      "logps/chosen": -223.9835968017578,
      "logps/rejected": -279.66229248046875,
      "loss": 0.1838,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -6.395440578460693,
      "rewards/margins": 3.4954867362976074,
      "rewards/rejected": -9.890928268432617,
      "step": 10090
    },
    {
      "epoch": 3.006399761869326,
      "grad_norm": 4.475825309753418,
      "learning_rate": 3.2206668669270056e-05,
      "logits/chosen": -0.7020027041435242,
      "logits/rejected": -0.6952938437461853,
      "logps/chosen": -241.4960479736328,
      "logps/rejected": -295.5921936035156,
      "loss": 0.1211,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.98663330078125,
      "rewards/margins": 4.062692642211914,
      "rewards/rejected": -11.04932689666748,
      "step": 10100
    },
    {
      "epoch": 3.0093763952969192,
      "grad_norm": 2.627655029296875,
      "learning_rate": 3.2158606188044456e-05,
      "logits/chosen": -0.730174720287323,
      "logits/rejected": -0.6524555087089539,
      "logps/chosen": -224.4887237548828,
      "logps/rejected": -267.9323425292969,
      "loss": 0.1251,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -6.3827714920043945,
      "rewards/margins": 4.047763824462891,
      "rewards/rejected": -10.430535316467285,
      "step": 10110
    },
    {
      "epoch": 3.0123530287245126,
      "grad_norm": 4.624863624572754,
      "learning_rate": 3.211054370681887e-05,
      "logits/chosen": -0.7302500605583191,
      "logits/rejected": -0.6619678735733032,
      "logps/chosen": -239.82791137695312,
      "logps/rejected": -280.4125671386719,
      "loss": 0.1915,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -6.033398628234863,
      "rewards/margins": 3.7705459594726562,
      "rewards/rejected": -9.80394458770752,
      "step": 10120
    },
    {
      "epoch": 3.015329662152106,
      "grad_norm": 3.8087775707244873,
      "learning_rate": 3.2062481225593275e-05,
      "logits/chosen": -0.5628846287727356,
      "logits/rejected": -0.5978162884712219,
      "logps/chosen": -236.9705810546875,
      "logps/rejected": -292.7278747558594,
      "loss": 0.0845,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -6.6463422775268555,
      "rewards/margins": 4.572443962097168,
      "rewards/rejected": -11.218786239624023,
      "step": 10130
    },
    {
      "epoch": 3.0183062955796993,
      "grad_norm": 3.3321545124053955,
      "learning_rate": 3.201441874436768e-05,
      "logits/chosen": -0.5593819618225098,
      "logits/rejected": -0.6457076668739319,
      "logps/chosen": -236.7914276123047,
      "logps/rejected": -297.7909240722656,
      "loss": 0.1185,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.398255348205566,
      "rewards/margins": 4.498867988586426,
      "rewards/rejected": -11.897122383117676,
      "step": 10140
    },
    {
      "epoch": 3.0212829290072927,
      "grad_norm": 13.090418815612793,
      "learning_rate": 3.196635626314209e-05,
      "logits/chosen": -0.5772762894630432,
      "logits/rejected": -0.63294517993927,
      "logps/chosen": -218.7872314453125,
      "logps/rejected": -279.2975769042969,
      "loss": 0.1482,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -6.951085090637207,
      "rewards/margins": 4.329892158508301,
      "rewards/rejected": -11.280977249145508,
      "step": 10150
    },
    {
      "epoch": 3.024259562434886,
      "grad_norm": 2.289205312728882,
      "learning_rate": 3.191829378191649e-05,
      "logits/chosen": -0.6286271810531616,
      "logits/rejected": -0.6864795684814453,
      "logps/chosen": -244.6385955810547,
      "logps/rejected": -299.09088134765625,
      "loss": 0.1211,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.276342391967773,
      "rewards/margins": 4.190838813781738,
      "rewards/rejected": -12.467181205749512,
      "step": 10160
    },
    {
      "epoch": 3.0272361958624794,
      "grad_norm": 10.594063758850098,
      "learning_rate": 3.18702313006909e-05,
      "logits/chosen": -0.6844713091850281,
      "logits/rejected": -0.5927034020423889,
      "logps/chosen": -263.7509460449219,
      "logps/rejected": -294.03704833984375,
      "loss": 0.1234,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -7.448494911193848,
      "rewards/margins": 4.64823055267334,
      "rewards/rejected": -12.096724510192871,
      "step": 10170
    },
    {
      "epoch": 3.0302128292900727,
      "grad_norm": 4.591259002685547,
      "learning_rate": 3.1822168819465305e-05,
      "logits/chosen": -0.6102460622787476,
      "logits/rejected": -0.6829899549484253,
      "logps/chosen": -259.29815673828125,
      "logps/rejected": -321.106689453125,
      "loss": 0.1496,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.895785331726074,
      "rewards/margins": 4.521488189697266,
      "rewards/rejected": -12.417274475097656,
      "step": 10180
    },
    {
      "epoch": 3.033189462717666,
      "grad_norm": 1.7007437944412231,
      "learning_rate": 3.177410633823971e-05,
      "logits/chosen": -0.6436122059822083,
      "logits/rejected": -0.7016191482543945,
      "logps/chosen": -276.44952392578125,
      "logps/rejected": -340.7899169921875,
      "loss": 0.1088,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.746886253356934,
      "rewards/margins": 4.679891586303711,
      "rewards/rejected": -13.426777839660645,
      "step": 10190
    },
    {
      "epoch": 3.03616609614526,
      "grad_norm": 5.48043155670166,
      "learning_rate": 3.1726043857014124e-05,
      "logits/chosen": -0.7037807106971741,
      "logits/rejected": -0.6151244640350342,
      "logps/chosen": -250.6740264892578,
      "logps/rejected": -280.5391845703125,
      "loss": 0.1691,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.928323268890381,
      "rewards/margins": 3.7603328227996826,
      "rewards/rejected": -11.6886568069458,
      "step": 10200
    },
    {
      "epoch": 3.0391427295728533,
      "grad_norm": 15.823229789733887,
      "learning_rate": 3.167798137578853e-05,
      "logits/chosen": -0.5803548097610474,
      "logits/rejected": -0.6443495750427246,
      "logps/chosen": -238.83578491210938,
      "logps/rejected": -303.0572814941406,
      "loss": 0.1222,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.015386581420898,
      "rewards/margins": 4.561923027038574,
      "rewards/rejected": -12.577310562133789,
      "step": 10210
    },
    {
      "epoch": 3.0421193630004466,
      "grad_norm": 1.6714340448379517,
      "learning_rate": 3.162991889456294e-05,
      "logits/chosen": -0.627476155757904,
      "logits/rejected": -0.6369412541389465,
      "logps/chosen": -249.18429565429688,
      "logps/rejected": -307.9058532714844,
      "loss": 0.115,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.218338012695312,
      "rewards/margins": 4.6728925704956055,
      "rewards/rejected": -12.891229629516602,
      "step": 10220
    },
    {
      "epoch": 3.04509599642804,
      "grad_norm": 0.8778092861175537,
      "learning_rate": 3.158185641333734e-05,
      "logits/chosen": -0.5996997952461243,
      "logits/rejected": -0.5375468134880066,
      "logps/chosen": -250.0510711669922,
      "logps/rejected": -295.3155822753906,
      "loss": 0.1269,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.682607173919678,
      "rewards/margins": 4.530465602874756,
      "rewards/rejected": -12.213071823120117,
      "step": 10230
    },
    {
      "epoch": 3.0480726298556333,
      "grad_norm": 3.9038965702056885,
      "learning_rate": 3.153379393211175e-05,
      "logits/chosen": -0.4412127137184143,
      "logits/rejected": -0.4822081923484802,
      "logps/chosen": -260.6955871582031,
      "logps/rejected": -326.9574279785156,
      "loss": 0.0708,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.864045143127441,
      "rewards/margins": 5.200525283813477,
      "rewards/rejected": -14.06457233428955,
      "step": 10240
    },
    {
      "epoch": 3.0510492632832267,
      "grad_norm": 7.8966193199157715,
      "learning_rate": 3.1485731450886155e-05,
      "logits/chosen": -0.44680318236351013,
      "logits/rejected": -0.5341857671737671,
      "logps/chosen": -261.2917785644531,
      "logps/rejected": -325.1286315917969,
      "loss": 0.1143,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.227361679077148,
      "rewards/margins": 4.518780708312988,
      "rewards/rejected": -14.74614143371582,
      "step": 10250
    },
    {
      "epoch": 3.05402589671082,
      "grad_norm": 12.56919002532959,
      "learning_rate": 3.143766896966056e-05,
      "logits/chosen": -0.34803247451782227,
      "logits/rejected": -0.41901469230651855,
      "logps/chosen": -264.93157958984375,
      "logps/rejected": -319.35394287109375,
      "loss": 0.1066,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.171026229858398,
      "rewards/margins": 4.675044059753418,
      "rewards/rejected": -13.8460693359375,
      "step": 10260
    },
    {
      "epoch": 3.0570025301384134,
      "grad_norm": 9.90678596496582,
      "learning_rate": 3.138960648843497e-05,
      "logits/chosen": -0.3250111937522888,
      "logits/rejected": -0.29116541147232056,
      "logps/chosen": -264.4964294433594,
      "logps/rejected": -322.2923889160156,
      "loss": 0.1382,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -9.701821327209473,
      "rewards/margins": 4.459721565246582,
      "rewards/rejected": -14.161541938781738,
      "step": 10270
    },
    {
      "epoch": 3.0599791635660067,
      "grad_norm": 8.081108093261719,
      "learning_rate": 3.1341544007209374e-05,
      "logits/chosen": -0.3095073699951172,
      "logits/rejected": -0.4329574704170227,
      "logps/chosen": -279.40533447265625,
      "logps/rejected": -352.6596984863281,
      "loss": 0.0777,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.687255859375,
      "rewards/margins": 5.134511947631836,
      "rewards/rejected": -15.821767807006836,
      "step": 10280
    },
    {
      "epoch": 3.0629557969936,
      "grad_norm": 1.3135404586791992,
      "learning_rate": 3.129348152598378e-05,
      "logits/chosen": -0.38734883069992065,
      "logits/rejected": -0.39782997965812683,
      "logps/chosen": -271.14813232421875,
      "logps/rejected": -338.9895935058594,
      "loss": 0.1038,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -9.508583068847656,
      "rewards/margins": 5.452515602111816,
      "rewards/rejected": -14.961099624633789,
      "step": 10290
    },
    {
      "epoch": 3.0659324304211935,
      "grad_norm": 6.565703392028809,
      "learning_rate": 3.1245419044758186e-05,
      "logits/chosen": -0.4139617085456848,
      "logits/rejected": -0.32041993737220764,
      "logps/chosen": -270.360595703125,
      "logps/rejected": -309.81439208984375,
      "loss": 0.1369,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.820889472961426,
      "rewards/margins": 4.362109184265137,
      "rewards/rejected": -14.182998657226562,
      "step": 10300
    },
    {
      "epoch": 3.068909063848787,
      "grad_norm": 2.939509630203247,
      "learning_rate": 3.119735656353259e-05,
      "logits/chosen": -0.5550576448440552,
      "logits/rejected": -0.731812596321106,
      "logps/chosen": -259.3557434082031,
      "logps/rejected": -327.1132507324219,
      "loss": 0.1756,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -9.02835750579834,
      "rewards/margins": 4.546071529388428,
      "rewards/rejected": -13.574430465698242,
      "step": 10310
    },
    {
      "epoch": 3.0718856972763806,
      "grad_norm": 12.462767601013184,
      "learning_rate": 3.1149294082307005e-05,
      "logits/chosen": -0.6179400086402893,
      "logits/rejected": -0.554656982421875,
      "logps/chosen": -260.69171142578125,
      "logps/rejected": -324.14495849609375,
      "loss": 0.1194,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.82765007019043,
      "rewards/margins": 5.36826753616333,
      "rewards/rejected": -14.195918083190918,
      "step": 10320
    },
    {
      "epoch": 3.074862330703974,
      "grad_norm": 8.37996768951416,
      "learning_rate": 3.110123160108141e-05,
      "logits/chosen": -0.577150285243988,
      "logits/rejected": -0.6177184581756592,
      "logps/chosen": -278.69610595703125,
      "logps/rejected": -341.28863525390625,
      "loss": 0.1353,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.173357009887695,
      "rewards/margins": 4.816866397857666,
      "rewards/rejected": -14.990221977233887,
      "step": 10330
    },
    {
      "epoch": 3.0778389641315673,
      "grad_norm": 17.187746047973633,
      "learning_rate": 3.105316911985582e-05,
      "logits/chosen": -0.680585503578186,
      "logits/rejected": -0.6026743650436401,
      "logps/chosen": -241.07504272460938,
      "logps/rejected": -298.25885009765625,
      "loss": 0.129,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.80757999420166,
      "rewards/margins": 4.866711139678955,
      "rewards/rejected": -12.674290657043457,
      "step": 10340
    },
    {
      "epoch": 3.0808155975591607,
      "grad_norm": 12.782675743103027,
      "learning_rate": 3.1005106638630223e-05,
      "logits/chosen": -0.6478832364082336,
      "logits/rejected": -0.6114169359207153,
      "logps/chosen": -240.20364379882812,
      "logps/rejected": -294.93365478515625,
      "loss": 0.1883,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -7.521641731262207,
      "rewards/margins": 4.445315837860107,
      "rewards/rejected": -11.966957092285156,
      "step": 10350
    },
    {
      "epoch": 3.083792230986754,
      "grad_norm": 3.467568874359131,
      "learning_rate": 3.095704415740463e-05,
      "logits/chosen": -0.540337324142456,
      "logits/rejected": -0.5151260495185852,
      "logps/chosen": -252.0541534423828,
      "logps/rejected": -303.37957763671875,
      "loss": 0.0858,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.573551177978516,
      "rewards/margins": 4.434503078460693,
      "rewards/rejected": -13.00805377960205,
      "step": 10360
    },
    {
      "epoch": 3.0867688644143474,
      "grad_norm": 4.3729729652404785,
      "learning_rate": 3.0908981676179036e-05,
      "logits/chosen": -0.5852247476577759,
      "logits/rejected": -0.5600296258926392,
      "logps/chosen": -270.16790771484375,
      "logps/rejected": -316.22308349609375,
      "loss": 0.1319,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -9.508105278015137,
      "rewards/margins": 4.594376564025879,
      "rewards/rejected": -14.102482795715332,
      "step": 10370
    },
    {
      "epoch": 3.0897454978419407,
      "grad_norm": 11.815850257873535,
      "learning_rate": 3.086091919495344e-05,
      "logits/chosen": -0.45815953612327576,
      "logits/rejected": -0.4512643814086914,
      "logps/chosen": -284.09039306640625,
      "logps/rejected": -333.80780029296875,
      "loss": 0.1528,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.083174705505371,
      "rewards/margins": 4.659537315368652,
      "rewards/rejected": -14.742712020874023,
      "step": 10380
    },
    {
      "epoch": 3.092722131269534,
      "grad_norm": 9.63447380065918,
      "learning_rate": 3.081285671372785e-05,
      "logits/chosen": -0.4545017182826996,
      "logits/rejected": -0.5697721838951111,
      "logps/chosen": -270.5917053222656,
      "logps/rejected": -352.29376220703125,
      "loss": 0.0585,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.074407577514648,
      "rewards/margins": 6.188027381896973,
      "rewards/rejected": -16.262435913085938,
      "step": 10390
    },
    {
      "epoch": 3.0956987646971275,
      "grad_norm": 3.5148303508758545,
      "learning_rate": 3.0764794232502254e-05,
      "logits/chosen": -0.4125432074069977,
      "logits/rejected": -0.4799446165561676,
      "logps/chosen": -247.6254119873047,
      "logps/rejected": -308.91949462890625,
      "loss": 0.1168,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.250760078430176,
      "rewards/margins": 4.745837688446045,
      "rewards/rejected": -13.996599197387695,
      "step": 10400
    },
    {
      "epoch": 3.098675398124721,
      "grad_norm": 13.330489158630371,
      "learning_rate": 3.071673175127666e-05,
      "logits/chosen": -0.422281414270401,
      "logits/rejected": -0.4022235870361328,
      "logps/chosen": -263.55242919921875,
      "logps/rejected": -335.74554443359375,
      "loss": 0.0639,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -9.72612190246582,
      "rewards/margins": 6.264303684234619,
      "rewards/rejected": -15.990423202514648,
      "step": 10410
    },
    {
      "epoch": 3.101652031552314,
      "grad_norm": 6.895145893096924,
      "learning_rate": 3.0668669270051066e-05,
      "logits/chosen": -0.3240657448768616,
      "logits/rejected": -0.2925623655319214,
      "logps/chosen": -271.3701171875,
      "logps/rejected": -335.8414611816406,
      "loss": 0.1104,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.657100677490234,
      "rewards/margins": 5.644475936889648,
      "rewards/rejected": -16.30157470703125,
      "step": 10420
    },
    {
      "epoch": 3.1046286649799075,
      "grad_norm": 7.150181770324707,
      "learning_rate": 3.062060678882547e-05,
      "logits/chosen": -0.3147770166397095,
      "logits/rejected": -0.43455925583839417,
      "logps/chosen": -279.26904296875,
      "logps/rejected": -353.91864013671875,
      "loss": 0.0809,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.965410232543945,
      "rewards/margins": 5.451814651489258,
      "rewards/rejected": -17.417224884033203,
      "step": 10430
    },
    {
      "epoch": 3.1076052984075013,
      "grad_norm": 2.7585818767547607,
      "learning_rate": 3.0572544307599886e-05,
      "logits/chosen": -0.37819841504096985,
      "logits/rejected": -0.3404802680015564,
      "logps/chosen": -288.71112060546875,
      "logps/rejected": -346.44921875,
      "loss": 0.2184,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.145830154418945,
      "rewards/margins": 5.37435245513916,
      "rewards/rejected": -16.520183563232422,
      "step": 10440
    },
    {
      "epoch": 3.1105819318350947,
      "grad_norm": 12.30270767211914,
      "learning_rate": 3.052448182637429e-05,
      "logits/chosen": -0.33642321825027466,
      "logits/rejected": -0.3982542157173157,
      "logps/chosen": -273.80645751953125,
      "logps/rejected": -331.20574951171875,
      "loss": 0.1625,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.427584648132324,
      "rewards/margins": 4.699342250823975,
      "rewards/rejected": -15.126927375793457,
      "step": 10450
    },
    {
      "epoch": 3.113558565262688,
      "grad_norm": 7.248732566833496,
      "learning_rate": 3.0476419345148698e-05,
      "logits/chosen": -0.41293057799339294,
      "logits/rejected": -0.3943886160850525,
      "logps/chosen": -285.1422424316406,
      "logps/rejected": -327.4322204589844,
      "loss": 0.1612,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.263997077941895,
      "rewards/margins": 4.5413689613342285,
      "rewards/rejected": -14.805364608764648,
      "step": 10460
    },
    {
      "epoch": 3.1165351986902814,
      "grad_norm": 5.51002836227417,
      "learning_rate": 3.04283568639231e-05,
      "logits/chosen": -0.3303522765636444,
      "logits/rejected": -0.28714242577552795,
      "logps/chosen": -269.54351806640625,
      "logps/rejected": -326.8858947753906,
      "loss": 0.0917,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.575910568237305,
      "rewards/margins": 5.323103427886963,
      "rewards/rejected": -14.899012565612793,
      "step": 10470
    },
    {
      "epoch": 3.1195118321178748,
      "grad_norm": 6.574610233306885,
      "learning_rate": 3.0380294382697507e-05,
      "logits/chosen": -0.16101959347724915,
      "logits/rejected": -0.2259882241487503,
      "logps/chosen": -271.22686767578125,
      "logps/rejected": -332.10565185546875,
      "loss": 0.1611,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.440549850463867,
      "rewards/margins": 4.955512046813965,
      "rewards/rejected": -15.396064758300781,
      "step": 10480
    },
    {
      "epoch": 3.122488465545468,
      "grad_norm": 4.735734939575195,
      "learning_rate": 3.0332231901471916e-05,
      "logits/chosen": -0.4530048370361328,
      "logits/rejected": -0.4066687524318695,
      "logps/chosen": -276.18731689453125,
      "logps/rejected": -323.77520751953125,
      "loss": 0.0819,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.861472129821777,
      "rewards/margins": 4.881075382232666,
      "rewards/rejected": -14.742547988891602,
      "step": 10490
    },
    {
      "epoch": 3.1254650989730615,
      "grad_norm": 1.5120409727096558,
      "learning_rate": 3.0284169420246322e-05,
      "logits/chosen": -0.3156910836696625,
      "logits/rejected": -0.5435842871665955,
      "logps/chosen": -249.1300506591797,
      "logps/rejected": -330.25555419921875,
      "loss": 0.0883,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.831789016723633,
      "rewards/margins": 5.121230125427246,
      "rewards/rejected": -13.953018188476562,
      "step": 10500
    },
    {
      "epoch": 3.128441732400655,
      "grad_norm": 3.845013380050659,
      "learning_rate": 3.024091318714329e-05,
      "logits/chosen": -0.3957676589488983,
      "logits/rejected": -0.45531755685806274,
      "logps/chosen": -266.5779113769531,
      "logps/rejected": -325.0047302246094,
      "loss": 0.2374,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.428253173828125,
      "rewards/margins": 4.7905378341674805,
      "rewards/rejected": -15.218790054321289,
      "step": 10510
    },
    {
      "epoch": 3.131418365828248,
      "grad_norm": 19.66368293762207,
      "learning_rate": 3.0192850705917695e-05,
      "logits/chosen": -0.31905531883239746,
      "logits/rejected": -0.33731481432914734,
      "logps/chosen": -262.88934326171875,
      "logps/rejected": -324.0552673339844,
      "loss": 0.1625,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.170583724975586,
      "rewards/margins": 5.042856216430664,
      "rewards/rejected": -14.21343994140625,
      "step": 10520
    },
    {
      "epoch": 3.1343949992558415,
      "grad_norm": 10.86194896697998,
      "learning_rate": 3.01447882246921e-05,
      "logits/chosen": -0.3802871108055115,
      "logits/rejected": -0.46678537130355835,
      "logps/chosen": -253.07315063476562,
      "logps/rejected": -311.9243469238281,
      "loss": 0.1122,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.079809188842773,
      "rewards/margins": 4.738421440124512,
      "rewards/rejected": -14.818229675292969,
      "step": 10530
    },
    {
      "epoch": 3.137371632683435,
      "grad_norm": 7.734447002410889,
      "learning_rate": 3.009672574346651e-05,
      "logits/chosen": -0.5418648719787598,
      "logits/rejected": -0.5636520981788635,
      "logps/chosen": -251.5408477783203,
      "logps/rejected": -295.86663818359375,
      "loss": 0.1534,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -8.4639253616333,
      "rewards/margins": 4.2481608390808105,
      "rewards/rejected": -12.71208667755127,
      "step": 10540
    },
    {
      "epoch": 3.1403482661110282,
      "grad_norm": 8.490208625793457,
      "learning_rate": 3.0048663262240914e-05,
      "logits/chosen": -0.39206889271736145,
      "logits/rejected": -0.4734192490577698,
      "logps/chosen": -250.3110809326172,
      "logps/rejected": -311.60308837890625,
      "loss": 0.2065,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -9.184455871582031,
      "rewards/margins": 4.272040367126465,
      "rewards/rejected": -13.45649528503418,
      "step": 10550
    },
    {
      "epoch": 3.143324899538622,
      "grad_norm": 0.5283945798873901,
      "learning_rate": 3.000060078101532e-05,
      "logits/chosen": -0.6022247672080994,
      "logits/rejected": -0.5167691707611084,
      "logps/chosen": -259.58197021484375,
      "logps/rejected": -297.3320007324219,
      "loss": 0.2114,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -7.3622283935546875,
      "rewards/margins": 4.431476593017578,
      "rewards/rejected": -11.793704986572266,
      "step": 10560
    },
    {
      "epoch": 3.1463015329662154,
      "grad_norm": 3.187389373779297,
      "learning_rate": 2.995253829978973e-05,
      "logits/chosen": -0.4594264030456543,
      "logits/rejected": -0.4473281502723694,
      "logps/chosen": -257.7787170410156,
      "logps/rejected": -308.66644287109375,
      "loss": 0.0663,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -7.972222805023193,
      "rewards/margins": 4.742952823638916,
      "rewards/rejected": -12.715176582336426,
      "step": 10570
    },
    {
      "epoch": 3.1492781663938088,
      "grad_norm": 5.02115535736084,
      "learning_rate": 2.9904475818564136e-05,
      "logits/chosen": -0.5496270656585693,
      "logits/rejected": -0.5667834281921387,
      "logps/chosen": -266.48187255859375,
      "logps/rejected": -326.6871032714844,
      "loss": 0.1825,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -8.860696792602539,
      "rewards/margins": 4.483495712280273,
      "rewards/rejected": -13.34419059753418,
      "step": 10580
    },
    {
      "epoch": 3.152254799821402,
      "grad_norm": 2.96610689163208,
      "learning_rate": 2.9856413337338542e-05,
      "logits/chosen": -0.5362941026687622,
      "logits/rejected": -0.5576446056365967,
      "logps/chosen": -269.19451904296875,
      "logps/rejected": -319.8114929199219,
      "loss": 0.0845,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.93785572052002,
      "rewards/margins": 4.744926929473877,
      "rewards/rejected": -13.682783126831055,
      "step": 10590
    },
    {
      "epoch": 3.1552314332489955,
      "grad_norm": 1.7396776676177979,
      "learning_rate": 2.980835085611295e-05,
      "logits/chosen": -0.5410717725753784,
      "logits/rejected": -0.5930522084236145,
      "logps/chosen": -281.582763671875,
      "logps/rejected": -337.3337097167969,
      "loss": 0.1606,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.164118766784668,
      "rewards/margins": 4.500818252563477,
      "rewards/rejected": -13.664937973022461,
      "step": 10600
    },
    {
      "epoch": 3.158208066676589,
      "grad_norm": 11.834432601928711,
      "learning_rate": 2.9760288374887354e-05,
      "logits/chosen": -0.2587360143661499,
      "logits/rejected": -0.4822753369808197,
      "logps/chosen": -265.480224609375,
      "logps/rejected": -342.36468505859375,
      "loss": 0.1282,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.938860893249512,
      "rewards/margins": 4.490030765533447,
      "rewards/rejected": -14.4288911819458,
      "step": 10610
    },
    {
      "epoch": 3.161184700104182,
      "grad_norm": 1.005699634552002,
      "learning_rate": 2.971222589366176e-05,
      "logits/chosen": -0.4036511480808258,
      "logits/rejected": -0.523072361946106,
      "logps/chosen": -279.16705322265625,
      "logps/rejected": -361.73809814453125,
      "loss": 0.0774,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.032336235046387,
      "rewards/margins": 5.500624656677246,
      "rewards/rejected": -15.53296184539795,
      "step": 10620
    },
    {
      "epoch": 3.1641613335317755,
      "grad_norm": 6.378949165344238,
      "learning_rate": 2.966416341243617e-05,
      "logits/chosen": -0.4377196431159973,
      "logits/rejected": -0.4590359628200531,
      "logps/chosen": -271.3847961425781,
      "logps/rejected": -332.27996826171875,
      "loss": 0.1188,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.229872703552246,
      "rewards/margins": 4.7063188552856445,
      "rewards/rejected": -14.936192512512207,
      "step": 10630
    },
    {
      "epoch": 3.167137966959369,
      "grad_norm": 6.560437202453613,
      "learning_rate": 2.9616100931210576e-05,
      "logits/chosen": -0.501244068145752,
      "logits/rejected": -0.3976787328720093,
      "logps/chosen": -278.72283935546875,
      "logps/rejected": -313.43585205078125,
      "loss": 0.2101,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.289488792419434,
      "rewards/margins": 4.667941093444824,
      "rewards/rejected": -13.957429885864258,
      "step": 10640
    },
    {
      "epoch": 3.1701146003869622,
      "grad_norm": 0.31859999895095825,
      "learning_rate": 2.9568038449984982e-05,
      "logits/chosen": -0.5413219332695007,
      "logits/rejected": -0.49005693197250366,
      "logps/chosen": -276.8550109863281,
      "logps/rejected": -328.689208984375,
      "loss": 0.0702,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -9.463651657104492,
      "rewards/margins": 5.05314826965332,
      "rewards/rejected": -14.51679801940918,
      "step": 10650
    },
    {
      "epoch": 3.1730912338145556,
      "grad_norm": 8.13619327545166,
      "learning_rate": 2.951997596875939e-05,
      "logits/chosen": -0.5212315320968628,
      "logits/rejected": -0.5344208478927612,
      "logps/chosen": -277.6150817871094,
      "logps/rejected": -331.32672119140625,
      "loss": 0.188,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -9.295389175415039,
      "rewards/margins": 4.636435031890869,
      "rewards/rejected": -13.931825637817383,
      "step": 10660
    },
    {
      "epoch": 3.176067867242149,
      "grad_norm": 3.1479251384735107,
      "learning_rate": 2.9471913487533794e-05,
      "logits/chosen": -0.465049684047699,
      "logits/rejected": -0.5734814405441284,
      "logps/chosen": -275.2971496582031,
      "logps/rejected": -340.8860168457031,
      "loss": 0.1071,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.22349739074707,
      "rewards/margins": 4.716858863830566,
      "rewards/rejected": -14.940356254577637,
      "step": 10670
    },
    {
      "epoch": 3.1790445006697423,
      "grad_norm": 12.33684253692627,
      "learning_rate": 2.94238510063082e-05,
      "logits/chosen": -0.34933167695999146,
      "logits/rejected": -0.507756233215332,
      "logps/chosen": -258.5343017578125,
      "logps/rejected": -354.1333923339844,
      "loss": 0.1013,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.088035583496094,
      "rewards/margins": 6.114036560058594,
      "rewards/rejected": -16.202072143554688,
      "step": 10680
    },
    {
      "epoch": 3.182021134097336,
      "grad_norm": 7.194088935852051,
      "learning_rate": 2.937578852508261e-05,
      "logits/chosen": -0.4802103042602539,
      "logits/rejected": -0.5920346975326538,
      "logps/chosen": -278.26202392578125,
      "logps/rejected": -345.646728515625,
      "loss": 0.1876,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.035104751586914,
      "rewards/margins": 4.794498443603516,
      "rewards/rejected": -14.82960319519043,
      "step": 10690
    },
    {
      "epoch": 3.1849977675249295,
      "grad_norm": 3.4549636840820312,
      "learning_rate": 2.9327726043857016e-05,
      "logits/chosen": -0.4315754473209381,
      "logits/rejected": -0.45359498262405396,
      "logps/chosen": -261.40924072265625,
      "logps/rejected": -342.8890075683594,
      "loss": 0.1172,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.341470718383789,
      "rewards/margins": 5.585259437561035,
      "rewards/rejected": -14.926729202270508,
      "step": 10700
    },
    {
      "epoch": 3.187974400952523,
      "grad_norm": 2.328439235687256,
      "learning_rate": 2.9279663562631422e-05,
      "logits/chosen": -0.3272485136985779,
      "logits/rejected": -0.48576074838638306,
      "logps/chosen": -259.6228942871094,
      "logps/rejected": -328.5782775878906,
      "loss": 0.1223,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.885403633117676,
      "rewards/margins": 4.487025737762451,
      "rewards/rejected": -14.372428894042969,
      "step": 10710
    },
    {
      "epoch": 3.190951034380116,
      "grad_norm": 3.0704538822174072,
      "learning_rate": 2.9231601081405832e-05,
      "logits/chosen": -0.36827850341796875,
      "logits/rejected": -0.36751192808151245,
      "logps/chosen": -261.1539001464844,
      "logps/rejected": -312.880126953125,
      "loss": 0.1139,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -8.99075984954834,
      "rewards/margins": 4.482131004333496,
      "rewards/rejected": -13.472890853881836,
      "step": 10720
    },
    {
      "epoch": 3.1939276678077095,
      "grad_norm": 6.652313232421875,
      "learning_rate": 2.9183538600180235e-05,
      "logits/chosen": -0.4894621968269348,
      "logits/rejected": -0.4770204424858093,
      "logps/chosen": -259.12286376953125,
      "logps/rejected": -305.8287658691406,
      "loss": 0.1917,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -8.846803665161133,
      "rewards/margins": 4.343400955200195,
      "rewards/rejected": -13.190205574035645,
      "step": 10730
    },
    {
      "epoch": 3.196904301235303,
      "grad_norm": 7.562119483947754,
      "learning_rate": 2.913547611895464e-05,
      "logits/chosen": -0.7040944695472717,
      "logits/rejected": -0.5418194532394409,
      "logps/chosen": -260.0777893066406,
      "logps/rejected": -281.25067138671875,
      "loss": 0.0734,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.0087890625,
      "rewards/margins": 4.251791477203369,
      "rewards/rejected": -11.260579109191895,
      "step": 10740
    },
    {
      "epoch": 3.1998809346628962,
      "grad_norm": 11.971736907958984,
      "learning_rate": 2.908741363772905e-05,
      "logits/chosen": -0.34314924478530884,
      "logits/rejected": -0.454336553812027,
      "logps/chosen": -290.97552490234375,
      "logps/rejected": -352.32110595703125,
      "loss": 0.1659,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -11.01860523223877,
      "rewards/margins": 4.532392978668213,
      "rewards/rejected": -15.550997734069824,
      "step": 10750
    },
    {
      "epoch": 3.2028575680904896,
      "grad_norm": 9.962479591369629,
      "learning_rate": 2.9039351156503456e-05,
      "logits/chosen": -0.3782366216182709,
      "logits/rejected": -0.4206937849521637,
      "logps/chosen": -255.115966796875,
      "logps/rejected": -323.7909240722656,
      "loss": 0.1153,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.398807525634766,
      "rewards/margins": 4.801210880279541,
      "rewards/rejected": -14.200017929077148,
      "step": 10760
    },
    {
      "epoch": 3.205834201518083,
      "grad_norm": 13.945859909057617,
      "learning_rate": 2.8991288675277866e-05,
      "logits/chosen": -0.3759040832519531,
      "logits/rejected": -0.4604470133781433,
      "logps/chosen": -260.30535888671875,
      "logps/rejected": -319.7790222167969,
      "loss": 0.226,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.946069717407227,
      "rewards/margins": 4.5455193519592285,
      "rewards/rejected": -14.491589546203613,
      "step": 10770
    },
    {
      "epoch": 3.2088108349456763,
      "grad_norm": 4.606744766235352,
      "learning_rate": 2.8943226194052272e-05,
      "logits/chosen": -0.5362377762794495,
      "logits/rejected": -0.46316179633140564,
      "logps/chosen": -258.9256286621094,
      "logps/rejected": -307.2167053222656,
      "loss": 0.1231,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -8.895120620727539,
      "rewards/margins": 4.406673431396484,
      "rewards/rejected": -13.301794052124023,
      "step": 10780
    },
    {
      "epoch": 3.2117874683732697,
      "grad_norm": 3.8449528217315674,
      "learning_rate": 2.8895163712826675e-05,
      "logits/chosen": -0.44530194997787476,
      "logits/rejected": -0.4213642179965973,
      "logps/chosen": -283.90325927734375,
      "logps/rejected": -333.934326171875,
      "loss": 0.0615,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -9.584867477416992,
      "rewards/margins": 4.958139896392822,
      "rewards/rejected": -14.543004989624023,
      "step": 10790
    },
    {
      "epoch": 3.214764101800863,
      "grad_norm": 6.822454452514648,
      "learning_rate": 2.884710123160108e-05,
      "logits/chosen": -0.27499374747276306,
      "logits/rejected": -0.36000627279281616,
      "logps/chosen": -269.845947265625,
      "logps/rejected": -345.32440185546875,
      "loss": 0.1087,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.051376342773438,
      "rewards/margins": 5.3202104568481445,
      "rewards/rejected": -15.371587753295898,
      "step": 10800
    },
    {
      "epoch": 3.217740735228457,
      "grad_norm": 10.375181198120117,
      "learning_rate": 2.879903875037549e-05,
      "logits/chosen": -0.44116440415382385,
      "logits/rejected": -0.4531422555446625,
      "logps/chosen": -271.73876953125,
      "logps/rejected": -323.47271728515625,
      "loss": 0.2144,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -9.767253875732422,
      "rewards/margins": 4.577423095703125,
      "rewards/rejected": -14.34467601776123,
      "step": 10810
    },
    {
      "epoch": 3.22071736865605,
      "grad_norm": 0.9661157131195068,
      "learning_rate": 2.8750976269149897e-05,
      "logits/chosen": -0.43006831407546997,
      "logits/rejected": -0.4199245572090149,
      "logps/chosen": -265.555419921875,
      "logps/rejected": -329.0098571777344,
      "loss": 0.0877,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.75966739654541,
      "rewards/margins": 5.469988822937012,
      "rewards/rejected": -14.229655265808105,
      "step": 10820
    },
    {
      "epoch": 3.2236940020836435,
      "grad_norm": 9.49179458618164,
      "learning_rate": 2.8702913787924306e-05,
      "logits/chosen": -0.35170477628707886,
      "logits/rejected": -0.27732154726982117,
      "logps/chosen": -291.9873046875,
      "logps/rejected": -341.17547607421875,
      "loss": 0.1837,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.318206787109375,
      "rewards/margins": 4.423093795776367,
      "rewards/rejected": -15.741299629211426,
      "step": 10830
    },
    {
      "epoch": 3.226670635511237,
      "grad_norm": 6.266351699829102,
      "learning_rate": 2.8654851306698712e-05,
      "logits/chosen": -0.33731961250305176,
      "logits/rejected": -0.3918328285217285,
      "logps/chosen": -291.70538330078125,
      "logps/rejected": -332.5499267578125,
      "loss": 0.1088,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.778258323669434,
      "rewards/margins": 4.4548869132995605,
      "rewards/rejected": -15.233144760131836,
      "step": 10840
    },
    {
      "epoch": 3.2296472689388303,
      "grad_norm": 6.5582170486450195,
      "learning_rate": 2.8606788825473115e-05,
      "logits/chosen": -0.37711232900619507,
      "logits/rejected": -0.4937850832939148,
      "logps/chosen": -270.3146057128906,
      "logps/rejected": -335.2734375,
      "loss": 0.1208,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.43779468536377,
      "rewards/margins": 5.05402946472168,
      "rewards/rejected": -14.49182415008545,
      "step": 10850
    },
    {
      "epoch": 3.2326239023664236,
      "grad_norm": 8.592074394226074,
      "learning_rate": 2.855872634424752e-05,
      "logits/chosen": -0.4501543939113617,
      "logits/rejected": -0.5331948399543762,
      "logps/chosen": -263.49224853515625,
      "logps/rejected": -329.14208984375,
      "loss": 0.0967,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.483447074890137,
      "rewards/margins": 4.990585803985596,
      "rewards/rejected": -14.474032402038574,
      "step": 10860
    },
    {
      "epoch": 3.235600535794017,
      "grad_norm": 4.554196357727051,
      "learning_rate": 2.851066386302193e-05,
      "logits/chosen": -0.41105833649635315,
      "logits/rejected": -0.4644584059715271,
      "logps/chosen": -276.354248046875,
      "logps/rejected": -331.6806640625,
      "loss": 0.2068,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -10.399163246154785,
      "rewards/margins": 4.831911563873291,
      "rewards/rejected": -15.23107624053955,
      "step": 10870
    },
    {
      "epoch": 3.2385771692216103,
      "grad_norm": 7.213534832000732,
      "learning_rate": 2.8462601381796337e-05,
      "logits/chosen": -0.3845997452735901,
      "logits/rejected": -0.4686715006828308,
      "logps/chosen": -265.86212158203125,
      "logps/rejected": -323.35394287109375,
      "loss": 0.1333,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.402685165405273,
      "rewards/margins": 4.479982852935791,
      "rewards/rejected": -13.882669448852539,
      "step": 10880
    },
    {
      "epoch": 3.2415538026492037,
      "grad_norm": 7.023529052734375,
      "learning_rate": 2.8414538900570747e-05,
      "logits/chosen": -0.4863623082637787,
      "logits/rejected": -0.35843199491500854,
      "logps/chosen": -249.21875,
      "logps/rejected": -304.9041748046875,
      "loss": 0.0786,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.561136245727539,
      "rewards/margins": 5.3598456382751465,
      "rewards/rejected": -13.920980453491211,
      "step": 10890
    },
    {
      "epoch": 3.244530436076797,
      "grad_norm": 6.744111061096191,
      "learning_rate": 2.8366476419345153e-05,
      "logits/chosen": -0.373460978269577,
      "logits/rejected": -0.38171201944351196,
      "logps/chosen": -278.029541015625,
      "logps/rejected": -343.60247802734375,
      "loss": 0.1772,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -11.091436386108398,
      "rewards/margins": 4.556948661804199,
      "rewards/rejected": -15.64838695526123,
      "step": 10900
    },
    {
      "epoch": 3.2475070695043904,
      "grad_norm": 7.410391330718994,
      "learning_rate": 2.8318413938119555e-05,
      "logits/chosen": -0.48456892371177673,
      "logits/rejected": -0.5036117434501648,
      "logps/chosen": -280.01763916015625,
      "logps/rejected": -337.66998291015625,
      "loss": 0.0926,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.298094749450684,
      "rewards/margins": 4.877249717712402,
      "rewards/rejected": -15.175341606140137,
      "step": 10910
    },
    {
      "epoch": 3.2504837029319837,
      "grad_norm": 1.681840419769287,
      "learning_rate": 2.827035145689396e-05,
      "logits/chosen": -0.4277365207672119,
      "logits/rejected": -0.4436482787132263,
      "logps/chosen": -281.7486572265625,
      "logps/rejected": -351.762451171875,
      "loss": 0.1087,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.691034317016602,
      "rewards/margins": 5.396805763244629,
      "rewards/rejected": -16.087841033935547,
      "step": 10920
    },
    {
      "epoch": 3.253460336359577,
      "grad_norm": 7.624762058258057,
      "learning_rate": 2.822228897566837e-05,
      "logits/chosen": -0.4222428798675537,
      "logits/rejected": -0.41316261887550354,
      "logps/chosen": -282.08514404296875,
      "logps/rejected": -330.6664123535156,
      "loss": 0.1666,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.106527328491211,
      "rewards/margins": 4.4944281578063965,
      "rewards/rejected": -15.60095500946045,
      "step": 10930
    },
    {
      "epoch": 3.256436969787171,
      "grad_norm": 2.779024839401245,
      "learning_rate": 2.8174226494442777e-05,
      "logits/chosen": -0.5215657949447632,
      "logits/rejected": -0.5578505396842957,
      "logps/chosen": -263.96392822265625,
      "logps/rejected": -331.95477294921875,
      "loss": 0.0888,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -9.114742279052734,
      "rewards/margins": 5.405095100402832,
      "rewards/rejected": -14.519838333129883,
      "step": 10940
    },
    {
      "epoch": 3.2594136032147643,
      "grad_norm": 4.960428714752197,
      "learning_rate": 2.8126164013217187e-05,
      "logits/chosen": -0.5165103077888489,
      "logits/rejected": -0.55817711353302,
      "logps/chosen": -260.16546630859375,
      "logps/rejected": -317.89239501953125,
      "loss": 0.1748,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.237716674804688,
      "rewards/margins": 4.498998165130615,
      "rewards/rejected": -13.736715316772461,
      "step": 10950
    },
    {
      "epoch": 3.2623902366423576,
      "grad_norm": 4.684145927429199,
      "learning_rate": 2.8078101531991593e-05,
      "logits/chosen": -0.41163721680641174,
      "logits/rejected": -0.38876527547836304,
      "logps/chosen": -289.2962951660156,
      "logps/rejected": -350.6790466308594,
      "loss": 0.1109,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.434623718261719,
      "rewards/margins": 5.316867828369141,
      "rewards/rejected": -15.751492500305176,
      "step": 10960
    },
    {
      "epoch": 3.265366870069951,
      "grad_norm": 2.09436297416687,
      "learning_rate": 2.8030039050766e-05,
      "logits/chosen": -0.518206000328064,
      "logits/rejected": -0.4080749452114105,
      "logps/chosen": -282.5565490722656,
      "logps/rejected": -325.5965576171875,
      "loss": 0.0614,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -9.825058937072754,
      "rewards/margins": 5.1013922691345215,
      "rewards/rejected": -14.9264497756958,
      "step": 10970
    },
    {
      "epoch": 3.2683435034975443,
      "grad_norm": 3.360649347305298,
      "learning_rate": 2.7981976569540402e-05,
      "logits/chosen": -0.1454125940799713,
      "logits/rejected": -0.11028468608856201,
      "logps/chosen": -256.76849365234375,
      "logps/rejected": -322.8580627441406,
      "loss": 0.0591,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -9.253461837768555,
      "rewards/margins": 5.4826555252075195,
      "rewards/rejected": -14.736117362976074,
      "step": 10980
    },
    {
      "epoch": 3.2713201369251377,
      "grad_norm": 4.467498302459717,
      "learning_rate": 2.793391408831481e-05,
      "logits/chosen": -0.2881804406642914,
      "logits/rejected": -0.1681881844997406,
      "logps/chosen": -297.2227783203125,
      "logps/rejected": -343.2669372558594,
      "loss": 0.155,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.096784591674805,
      "rewards/margins": 4.526529312133789,
      "rewards/rejected": -15.623313903808594,
      "step": 10990
    },
    {
      "epoch": 3.274296770352731,
      "grad_norm": 2.2659411430358887,
      "learning_rate": 2.7885851607089218e-05,
      "logits/chosen": -0.11092047393321991,
      "logits/rejected": -0.131841778755188,
      "logps/chosen": -275.4085998535156,
      "logps/rejected": -333.64935302734375,
      "loss": 0.0933,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.483548164367676,
      "rewards/margins": 5.276085376739502,
      "rewards/rejected": -15.75963306427002,
      "step": 11000
    },
    {
      "epoch": 3.2772734037803244,
      "grad_norm": 4.2983622550964355,
      "learning_rate": 2.7837789125863627e-05,
      "logits/chosen": -0.30877065658569336,
      "logits/rejected": -0.26085835695266724,
      "logps/chosen": -279.23040771484375,
      "logps/rejected": -340.6171875,
      "loss": 0.1351,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.460063934326172,
      "rewards/margins": 5.237697601318359,
      "rewards/rejected": -15.697763442993164,
      "step": 11010
    },
    {
      "epoch": 3.2802500372079177,
      "grad_norm": 8.644786834716797,
      "learning_rate": 2.7789726644638033e-05,
      "logits/chosen": -0.18004749715328217,
      "logits/rejected": -0.21666857600212097,
      "logps/chosen": -309.88873291015625,
      "logps/rejected": -367.4842834472656,
      "loss": 0.1294,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -12.689745903015137,
      "rewards/margins": 5.056944847106934,
      "rewards/rejected": -17.746688842773438,
      "step": 11020
    },
    {
      "epoch": 3.283226670635511,
      "grad_norm": 1.6423393487930298,
      "learning_rate": 2.774166416341244e-05,
      "logits/chosen": -0.1723661720752716,
      "logits/rejected": -0.23315644264221191,
      "logps/chosen": -264.916015625,
      "logps/rejected": -330.9446716308594,
      "loss": 0.1,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.875150680541992,
      "rewards/margins": 5.06751823425293,
      "rewards/rejected": -14.942667961120605,
      "step": 11030
    },
    {
      "epoch": 3.2862033040631045,
      "grad_norm": 3.4986681938171387,
      "learning_rate": 2.7693601682186842e-05,
      "logits/chosen": -0.18614885210990906,
      "logits/rejected": -0.19268539547920227,
      "logps/chosen": -273.79248046875,
      "logps/rejected": -333.93414306640625,
      "loss": 0.1479,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.461925506591797,
      "rewards/margins": 5.51247501373291,
      "rewards/rejected": -15.974401473999023,
      "step": 11040
    },
    {
      "epoch": 3.2891799374906983,
      "grad_norm": 1.237791657447815,
      "learning_rate": 2.764553920096125e-05,
      "logits/chosen": -0.2693638801574707,
      "logits/rejected": -0.36013084650039673,
      "logps/chosen": -259.5455017089844,
      "logps/rejected": -331.23675537109375,
      "loss": 0.1035,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.079093933105469,
      "rewards/margins": 5.248602390289307,
      "rewards/rejected": -15.3276948928833,
      "step": 11050
    },
    {
      "epoch": 3.2921565709182916,
      "grad_norm": 2.394012451171875,
      "learning_rate": 2.7597476719735658e-05,
      "logits/chosen": -0.36708348989486694,
      "logits/rejected": -0.37824031710624695,
      "logps/chosen": -278.50836181640625,
      "logps/rejected": -328.32928466796875,
      "loss": 0.1072,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.279245376586914,
      "rewards/margins": 4.9720916748046875,
      "rewards/rejected": -16.2513370513916,
      "step": 11060
    },
    {
      "epoch": 3.295133204345885,
      "grad_norm": 7.125432014465332,
      "learning_rate": 2.7549414238510067e-05,
      "logits/chosen": -0.5887221097946167,
      "logits/rejected": -0.5278922915458679,
      "logps/chosen": -280.2298889160156,
      "logps/rejected": -325.06109619140625,
      "loss": 0.0995,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.04395580291748,
      "rewards/margins": 4.71891450881958,
      "rewards/rejected": -15.762870788574219,
      "step": 11070
    },
    {
      "epoch": 3.2981098377734783,
      "grad_norm": 3.5730066299438477,
      "learning_rate": 2.7501351757284474e-05,
      "logits/chosen": -0.39117830991744995,
      "logits/rejected": -0.5038226842880249,
      "logps/chosen": -249.9337158203125,
      "logps/rejected": -330.77178955078125,
      "loss": 0.0923,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.339154243469238,
      "rewards/margins": 5.777834415435791,
      "rewards/rejected": -15.116986274719238,
      "step": 11080
    },
    {
      "epoch": 3.3010864712010717,
      "grad_norm": 6.580819129943848,
      "learning_rate": 2.745328927605888e-05,
      "logits/chosen": -0.42302411794662476,
      "logits/rejected": -0.4327008128166199,
      "logps/chosen": -281.7470397949219,
      "logps/rejected": -330.0074462890625,
      "loss": 0.1779,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.078630447387695,
      "rewards/margins": 4.542089939117432,
      "rewards/rejected": -14.620718002319336,
      "step": 11090
    },
    {
      "epoch": 3.304063104628665,
      "grad_norm": 7.856948375701904,
      "learning_rate": 2.7405226794833282e-05,
      "logits/chosen": -0.5201901197433472,
      "logits/rejected": -0.36234891414642334,
      "logps/chosen": -262.32818603515625,
      "logps/rejected": -300.8363952636719,
      "loss": 0.0975,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.079000473022461,
      "rewards/margins": 4.682692050933838,
      "rewards/rejected": -13.761691093444824,
      "step": 11100
    },
    {
      "epoch": 3.3070397380562584,
      "grad_norm": 14.395380973815918,
      "learning_rate": 2.7357164313607692e-05,
      "logits/chosen": -0.4119514524936676,
      "logits/rejected": -0.4804360270500183,
      "logps/chosen": -290.2046203613281,
      "logps/rejected": -341.99639892578125,
      "loss": 0.1704,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -10.86597728729248,
      "rewards/margins": 4.034306526184082,
      "rewards/rejected": -14.900283813476562,
      "step": 11110
    },
    {
      "epoch": 3.3100163714838517,
      "grad_norm": 8.497763633728027,
      "learning_rate": 2.7309101832382098e-05,
      "logits/chosen": -0.24168828129768372,
      "logits/rejected": -0.4097522795200348,
      "logps/chosen": -295.33612060546875,
      "logps/rejected": -371.02911376953125,
      "loss": 0.0763,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.242698669433594,
      "rewards/margins": 5.434144020080566,
      "rewards/rejected": -17.676841735839844,
      "step": 11120
    },
    {
      "epoch": 3.312993004911445,
      "grad_norm": 6.8278608322143555,
      "learning_rate": 2.7261039351156508e-05,
      "logits/chosen": -0.31862252950668335,
      "logits/rejected": -0.31460872292518616,
      "logps/chosen": -282.00469970703125,
      "logps/rejected": -336.40203857421875,
      "loss": 0.0969,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.838144302368164,
      "rewards/margins": 5.5033392906188965,
      "rewards/rejected": -16.341482162475586,
      "step": 11130
    },
    {
      "epoch": 3.3159696383390385,
      "grad_norm": 0.8347851037979126,
      "learning_rate": 2.7212976869930914e-05,
      "logits/chosen": -0.23713679611682892,
      "logits/rejected": -0.35100001096725464,
      "logps/chosen": -289.0357360839844,
      "logps/rejected": -366.72869873046875,
      "loss": 0.1562,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -11.314736366271973,
      "rewards/margins": 5.637720584869385,
      "rewards/rejected": -16.952457427978516,
      "step": 11140
    },
    {
      "epoch": 3.318946271766632,
      "grad_norm": 0.8317667245864868,
      "learning_rate": 2.716491438870532e-05,
      "logits/chosen": -0.2347169816493988,
      "logits/rejected": -0.1745612919330597,
      "logps/chosen": -274.5796203613281,
      "logps/rejected": -321.36865234375,
      "loss": 0.1681,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -11.268743515014648,
      "rewards/margins": 4.749725818634033,
      "rewards/rejected": -16.018468856811523,
      "step": 11150
    },
    {
      "epoch": 3.321922905194225,
      "grad_norm": 4.359466552734375,
      "learning_rate": 2.7116851907479723e-05,
      "logits/chosen": -0.1270022690296173,
      "logits/rejected": -0.15335595607757568,
      "logps/chosen": -311.548095703125,
      "logps/rejected": -387.8576965332031,
      "loss": 0.1055,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.488016128540039,
      "rewards/margins": 6.267772674560547,
      "rewards/rejected": -19.755788803100586,
      "step": 11160
    },
    {
      "epoch": 3.3248995386218185,
      "grad_norm": 15.498719215393066,
      "learning_rate": 2.7068789426254132e-05,
      "logits/chosen": -0.03744054585695267,
      "logits/rejected": -0.11094678938388824,
      "logps/chosen": -283.6498107910156,
      "logps/rejected": -354.45843505859375,
      "loss": 0.1195,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -12.576870918273926,
      "rewards/margins": 5.162683486938477,
      "rewards/rejected": -17.73955726623535,
      "step": 11170
    },
    {
      "epoch": 3.327876172049412,
      "grad_norm": 21.380462646484375,
      "learning_rate": 2.702072694502854e-05,
      "logits/chosen": 0.027243906632065773,
      "logits/rejected": -0.05284975841641426,
      "logps/chosen": -302.75018310546875,
      "logps/rejected": -359.57659912109375,
      "loss": 0.2722,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -13.840571403503418,
      "rewards/margins": 4.389713287353516,
      "rewards/rejected": -18.23028564453125,
      "step": 11180
    },
    {
      "epoch": 3.3308528054770057,
      "grad_norm": 5.607770919799805,
      "learning_rate": 2.6972664463802948e-05,
      "logits/chosen": -0.21390557289123535,
      "logits/rejected": -0.24430020153522491,
      "logps/chosen": -288.88079833984375,
      "logps/rejected": -350.8910217285156,
      "loss": 0.1161,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.008790969848633,
      "rewards/margins": 5.435059070587158,
      "rewards/rejected": -16.443849563598633,
      "step": 11190
    },
    {
      "epoch": 3.333829438904599,
      "grad_norm": 20.02532958984375,
      "learning_rate": 2.6924601982577354e-05,
      "logits/chosen": -0.10998505353927612,
      "logits/rejected": -0.038992494344711304,
      "logps/chosen": -280.6697692871094,
      "logps/rejected": -332.6543884277344,
      "loss": 0.1444,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.356188774108887,
      "rewards/margins": 4.700319290161133,
      "rewards/rejected": -16.056507110595703,
      "step": 11200
    },
    {
      "epoch": 3.3368060723321924,
      "grad_norm": 4.7976789474487305,
      "learning_rate": 2.687653950135176e-05,
      "logits/chosen": -0.2270083725452423,
      "logits/rejected": -0.18897253274917603,
      "logps/chosen": -285.0591735839844,
      "logps/rejected": -331.27032470703125,
      "loss": 0.1154,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.21241283416748,
      "rewards/margins": 4.697574615478516,
      "rewards/rejected": -15.90998649597168,
      "step": 11210
    },
    {
      "epoch": 3.3397827057597858,
      "grad_norm": 19.63951873779297,
      "learning_rate": 2.6828477020126163e-05,
      "logits/chosen": -0.2804953157901764,
      "logits/rejected": -0.317180335521698,
      "logps/chosen": -288.9377746582031,
      "logps/rejected": -354.39935302734375,
      "loss": 0.1367,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.480062484741211,
      "rewards/margins": 5.448296070098877,
      "rewards/rejected": -16.92835807800293,
      "step": 11220
    },
    {
      "epoch": 3.342759339187379,
      "grad_norm": 18.295339584350586,
      "learning_rate": 2.6780414538900572e-05,
      "logits/chosen": -0.2507651448249817,
      "logits/rejected": -0.2493809461593628,
      "logps/chosen": -302.8145446777344,
      "logps/rejected": -341.35687255859375,
      "loss": 0.2201,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -12.60679817199707,
      "rewards/margins": 3.81502103805542,
      "rewards/rejected": -16.42182159423828,
      "step": 11230
    },
    {
      "epoch": 3.3457359726149725,
      "grad_norm": 3.441755771636963,
      "learning_rate": 2.673235205767498e-05,
      "logits/chosen": -0.4191385805606842,
      "logits/rejected": -0.5053503513336182,
      "logps/chosen": -274.787841796875,
      "logps/rejected": -348.26220703125,
      "loss": 0.1228,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.32011890411377,
      "rewards/margins": 5.08333683013916,
      "rewards/rejected": -15.403454780578613,
      "step": 11240
    },
    {
      "epoch": 3.348712606042566,
      "grad_norm": 12.097614288330078,
      "learning_rate": 2.6684289576449388e-05,
      "logits/chosen": -0.2983218729496002,
      "logits/rejected": -0.36656874418258667,
      "logps/chosen": -284.7421875,
      "logps/rejected": -338.5362243652344,
      "loss": 0.1449,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.366610527038574,
      "rewards/margins": 4.916694164276123,
      "rewards/rejected": -15.283305168151855,
      "step": 11250
    },
    {
      "epoch": 3.351689239470159,
      "grad_norm": 15.699284553527832,
      "learning_rate": 2.6636227095223794e-05,
      "logits/chosen": -0.26222944259643555,
      "logits/rejected": -0.39297717809677124,
      "logps/chosen": -298.67718505859375,
      "logps/rejected": -375.2374572753906,
      "loss": 0.1263,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -12.181821823120117,
      "rewards/margins": 5.268336296081543,
      "rewards/rejected": -17.45015525817871,
      "step": 11260
    },
    {
      "epoch": 3.3546658728977525,
      "grad_norm": 1.2445423603057861,
      "learning_rate": 2.65881646139982e-05,
      "logits/chosen": -0.4729687571525574,
      "logits/rejected": -0.39189496636390686,
      "logps/chosen": -288.8484191894531,
      "logps/rejected": -337.11492919921875,
      "loss": 0.0864,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -9.84332275390625,
      "rewards/margins": 5.291201591491699,
      "rewards/rejected": -15.13452434539795,
      "step": 11270
    },
    {
      "epoch": 3.357642506325346,
      "grad_norm": 3.545305013656616,
      "learning_rate": 2.6540102132772607e-05,
      "logits/chosen": -0.3406825661659241,
      "logits/rejected": -0.3270057141780853,
      "logps/chosen": -264.031494140625,
      "logps/rejected": -322.0332946777344,
      "loss": 0.122,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.73475456237793,
      "rewards/margins": 5.17821741104126,
      "rewards/rejected": -14.912971496582031,
      "step": 11280
    },
    {
      "epoch": 3.3606191397529392,
      "grad_norm": 3.5937983989715576,
      "learning_rate": 2.6492039651547013e-05,
      "logits/chosen": -0.2296476662158966,
      "logits/rejected": -0.41474637389183044,
      "logps/chosen": -268.7120666503906,
      "logps/rejected": -331.9998779296875,
      "loss": 0.1572,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.871326446533203,
      "rewards/margins": 4.2109293937683105,
      "rewards/rejected": -15.082255363464355,
      "step": 11290
    },
    {
      "epoch": 3.363595773180533,
      "grad_norm": 6.830000400543213,
      "learning_rate": 2.644397717032142e-05,
      "logits/chosen": -0.17453642189502716,
      "logits/rejected": -0.21789351105690002,
      "logps/chosen": -277.27203369140625,
      "logps/rejected": -340.732177734375,
      "loss": 0.1325,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.06944751739502,
      "rewards/margins": 4.732668399810791,
      "rewards/rejected": -15.802114486694336,
      "step": 11300
    },
    {
      "epoch": 3.3665724066081264,
      "grad_norm": 4.465757369995117,
      "learning_rate": 2.639591468909583e-05,
      "logits/chosen": -0.34314751625061035,
      "logits/rejected": -0.35756832361221313,
      "logps/chosen": -290.966552734375,
      "logps/rejected": -339.16497802734375,
      "loss": 0.1627,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.649970054626465,
      "rewards/margins": 4.882497310638428,
      "rewards/rejected": -15.53246784210205,
      "step": 11310
    },
    {
      "epoch": 3.3695490400357198,
      "grad_norm": 2.968191385269165,
      "learning_rate": 2.6347852207870235e-05,
      "logits/chosen": -0.3561168611049652,
      "logits/rejected": -0.3958069682121277,
      "logps/chosen": -270.3858947753906,
      "logps/rejected": -319.8844299316406,
      "loss": 0.127,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.923043251037598,
      "rewards/margins": 4.470638275146484,
      "rewards/rejected": -14.393681526184082,
      "step": 11320
    },
    {
      "epoch": 3.372525673463313,
      "grad_norm": 14.851678848266602,
      "learning_rate": 2.629978972664464e-05,
      "logits/chosen": -0.4902305603027344,
      "logits/rejected": -0.500260591506958,
      "logps/chosen": -254.360107421875,
      "logps/rejected": -308.240234375,
      "loss": 0.2041,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -8.096223831176758,
      "rewards/margins": 4.211829662322998,
      "rewards/rejected": -12.308053970336914,
      "step": 11330
    },
    {
      "epoch": 3.3755023068909065,
      "grad_norm": 11.95688247680664,
      "learning_rate": 2.6251727245419047e-05,
      "logits/chosen": -0.2586917281150818,
      "logits/rejected": -0.4627991318702698,
      "logps/chosen": -276.05108642578125,
      "logps/rejected": -346.8208312988281,
      "loss": 0.1317,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.391357421875,
      "rewards/margins": 4.889952659606934,
      "rewards/rejected": -15.281309127807617,
      "step": 11340
    },
    {
      "epoch": 3.3784789403185,
      "grad_norm": 1.180943250656128,
      "learning_rate": 2.6203664764193453e-05,
      "logits/chosen": -0.3372727930545807,
      "logits/rejected": -0.4024704396724701,
      "logps/chosen": -264.90301513671875,
      "logps/rejected": -327.6280822753906,
      "loss": 0.1677,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.06965446472168,
      "rewards/margins": 5.035998344421387,
      "rewards/rejected": -15.105653762817383,
      "step": 11350
    },
    {
      "epoch": 3.381455573746093,
      "grad_norm": 1.2106726169586182,
      "learning_rate": 2.615560228296786e-05,
      "logits/chosen": -0.35323816537857056,
      "logits/rejected": -0.43655461072921753,
      "logps/chosen": -280.6618347167969,
      "logps/rejected": -339.2015075683594,
      "loss": 0.1418,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.10352897644043,
      "rewards/margins": 4.763382911682129,
      "rewards/rejected": -14.866912841796875,
      "step": 11360
    },
    {
      "epoch": 3.3844322071736865,
      "grad_norm": 11.84273624420166,
      "learning_rate": 2.610753980174227e-05,
      "logits/chosen": -0.3652827739715576,
      "logits/rejected": -0.4636192321777344,
      "logps/chosen": -255.6697540283203,
      "logps/rejected": -317.7137756347656,
      "loss": 0.1444,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -9.516014099121094,
      "rewards/margins": 5.207769393920898,
      "rewards/rejected": -14.723783493041992,
      "step": 11370
    },
    {
      "epoch": 3.38740884060128,
      "grad_norm": 13.237909317016602,
      "learning_rate": 2.6059477320516675e-05,
      "logits/chosen": -0.5349013209342957,
      "logits/rejected": -0.51712566614151,
      "logps/chosen": -285.48797607421875,
      "logps/rejected": -337.7085266113281,
      "loss": 0.1016,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.478666305541992,
      "rewards/margins": 4.911868095397949,
      "rewards/rejected": -14.390535354614258,
      "step": 11380
    },
    {
      "epoch": 3.3903854740288732,
      "grad_norm": 12.776443481445312,
      "learning_rate": 2.601141483929108e-05,
      "logits/chosen": -0.45546913146972656,
      "logits/rejected": -0.41291379928588867,
      "logps/chosen": -253.6603240966797,
      "logps/rejected": -301.8411560058594,
      "loss": 0.1092,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.405633926391602,
      "rewards/margins": 5.0079169273376465,
      "rewards/rejected": -13.413551330566406,
      "step": 11390
    },
    {
      "epoch": 3.3933621074564666,
      "grad_norm": 1.0693773031234741,
      "learning_rate": 2.5963352358065487e-05,
      "logits/chosen": -0.26504841446876526,
      "logits/rejected": -0.38080111145973206,
      "logps/chosen": -272.74078369140625,
      "logps/rejected": -342.5339050292969,
      "loss": 0.1306,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.2114839553833,
      "rewards/margins": 5.612574100494385,
      "rewards/rejected": -15.824058532714844,
      "step": 11400
    },
    {
      "epoch": 3.39633874088406,
      "grad_norm": 5.558544158935547,
      "learning_rate": 2.5915289876839893e-05,
      "logits/chosen": -0.2923150658607483,
      "logits/rejected": -0.18959546089172363,
      "logps/chosen": -266.27703857421875,
      "logps/rejected": -324.11651611328125,
      "loss": 0.0965,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.810314178466797,
      "rewards/margins": 5.433379173278809,
      "rewards/rejected": -15.243692398071289,
      "step": 11410
    },
    {
      "epoch": 3.3993153743116533,
      "grad_norm": 18.18741798400879,
      "learning_rate": 2.58672273956143e-05,
      "logits/chosen": -0.41235652565956116,
      "logits/rejected": -0.1611742079257965,
      "logps/chosen": -281.57171630859375,
      "logps/rejected": -316.05133056640625,
      "loss": 0.2164,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -9.916231155395508,
      "rewards/margins": 4.950095176696777,
      "rewards/rejected": -14.866325378417969,
      "step": 11420
    },
    {
      "epoch": 3.4022920077392467,
      "grad_norm": 9.615059852600098,
      "learning_rate": 2.581916491438871e-05,
      "logits/chosen": -0.35033637285232544,
      "logits/rejected": -0.3022240996360779,
      "logps/chosen": -281.602294921875,
      "logps/rejected": -327.4806213378906,
      "loss": 0.0952,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.015020370483398,
      "rewards/margins": 4.619522571563721,
      "rewards/rejected": -14.634542465209961,
      "step": 11430
    },
    {
      "epoch": 3.4052686411668405,
      "grad_norm": 5.927553653717041,
      "learning_rate": 2.5771102433163115e-05,
      "logits/chosen": -0.29843974113464355,
      "logits/rejected": -0.3489336669445038,
      "logps/chosen": -254.77749633789062,
      "logps/rejected": -317.28631591796875,
      "loss": 0.1574,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -9.690079689025879,
      "rewards/margins": 4.65671443939209,
      "rewards/rejected": -14.346794128417969,
      "step": 11440
    },
    {
      "epoch": 3.408245274594434,
      "grad_norm": 2.8234708309173584,
      "learning_rate": 2.572303995193752e-05,
      "logits/chosen": -0.3554747998714447,
      "logits/rejected": -0.38630563020706177,
      "logps/chosen": -294.6838073730469,
      "logps/rejected": -339.51788330078125,
      "loss": 0.1614,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.051989555358887,
      "rewards/margins": 4.740968227386475,
      "rewards/rejected": -14.79295825958252,
      "step": 11450
    },
    {
      "epoch": 3.411221908022027,
      "grad_norm": 0.9370613098144531,
      "learning_rate": 2.5674977470711927e-05,
      "logits/chosen": -0.4109986424446106,
      "logits/rejected": -0.35146066546440125,
      "logps/chosen": -264.8715515136719,
      "logps/rejected": -319.7948913574219,
      "loss": 0.1298,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.09796142578125,
      "rewards/margins": 5.058467864990234,
      "rewards/rejected": -14.1564302444458,
      "step": 11460
    },
    {
      "epoch": 3.4141985414496205,
      "grad_norm": 15.611342430114746,
      "learning_rate": 2.5626914989486334e-05,
      "logits/chosen": -0.32159656286239624,
      "logits/rejected": -0.33024564385414124,
      "logps/chosen": -255.49169921875,
      "logps/rejected": -303.51678466796875,
      "loss": 0.1543,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.46664810180664,
      "rewards/margins": 4.457512378692627,
      "rewards/rejected": -13.924160957336426,
      "step": 11470
    },
    {
      "epoch": 3.417175174877214,
      "grad_norm": 1.2904547452926636,
      "learning_rate": 2.557885250826074e-05,
      "logits/chosen": -0.3822646737098694,
      "logits/rejected": -0.3633352816104889,
      "logps/chosen": -261.90606689453125,
      "logps/rejected": -320.1928405761719,
      "loss": 0.0992,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.073713302612305,
      "rewards/margins": 5.279458522796631,
      "rewards/rejected": -14.353172302246094,
      "step": 11480
    },
    {
      "epoch": 3.4201518083048073,
      "grad_norm": 1.4369643926620483,
      "learning_rate": 2.553079002703515e-05,
      "logits/chosen": -0.1537075638771057,
      "logits/rejected": -0.32065561413764954,
      "logps/chosen": -268.511474609375,
      "logps/rejected": -350.1482849121094,
      "loss": 0.0868,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.792877197265625,
      "rewards/margins": 5.287778377532959,
      "rewards/rejected": -16.080656051635742,
      "step": 11490
    },
    {
      "epoch": 3.4231284417324006,
      "grad_norm": 16.638172149658203,
      "learning_rate": 2.5482727545809555e-05,
      "logits/chosen": -0.16754551231861115,
      "logits/rejected": -0.19494140148162842,
      "logps/chosen": -262.53143310546875,
      "logps/rejected": -320.02197265625,
      "loss": 0.155,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.576032638549805,
      "rewards/margins": 4.684356689453125,
      "rewards/rejected": -15.26038932800293,
      "step": 11500
    },
    {
      "epoch": 3.426105075159994,
      "grad_norm": 8.81686782836914,
      "learning_rate": 2.543466506458396e-05,
      "logits/chosen": -0.14506521821022034,
      "logits/rejected": -0.31969159841537476,
      "logps/chosen": -294.5172119140625,
      "logps/rejected": -377.9612121582031,
      "loss": 0.1633,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -12.192447662353516,
      "rewards/margins": 5.614127159118652,
      "rewards/rejected": -17.806575775146484,
      "step": 11510
    },
    {
      "epoch": 3.4290817085875873,
      "grad_norm": 3.001447916030884,
      "learning_rate": 2.5386602583358368e-05,
      "logits/chosen": -0.3263989984989166,
      "logits/rejected": -0.3993557095527649,
      "logps/chosen": -268.57403564453125,
      "logps/rejected": -325.8915100097656,
      "loss": 0.1461,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.460049629211426,
      "rewards/margins": 4.723124980926514,
      "rewards/rejected": -15.183176040649414,
      "step": 11520
    },
    {
      "epoch": 3.4320583420151807,
      "grad_norm": 3.197472333908081,
      "learning_rate": 2.5338540102132774e-05,
      "logits/chosen": -0.33890682458877563,
      "logits/rejected": -0.25283485651016235,
      "logps/chosen": -288.21075439453125,
      "logps/rejected": -334.78021240234375,
      "loss": 0.0969,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.348383903503418,
      "rewards/margins": 5.093579292297363,
      "rewards/rejected": -15.441965103149414,
      "step": 11530
    },
    {
      "epoch": 3.435034975442774,
      "grad_norm": 28.883026123046875,
      "learning_rate": 2.529047762090718e-05,
      "logits/chosen": -0.22065815329551697,
      "logits/rejected": -0.15937724709510803,
      "logps/chosen": -269.49957275390625,
      "logps/rejected": -298.7376403808594,
      "loss": 0.1788,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.954755783081055,
      "rewards/margins": 3.94317364692688,
      "rewards/rejected": -13.897929191589355,
      "step": 11540
    },
    {
      "epoch": 3.438011608870368,
      "grad_norm": 3.017259120941162,
      "learning_rate": 2.524241513968159e-05,
      "logits/chosen": -0.29547062516212463,
      "logits/rejected": -0.3096516728401184,
      "logps/chosen": -267.2903137207031,
      "logps/rejected": -316.4665222167969,
      "loss": 0.1291,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.344449043273926,
      "rewards/margins": 4.615522861480713,
      "rewards/rejected": -13.959973335266113,
      "step": 11550
    },
    {
      "epoch": 3.440988242297961,
      "grad_norm": 15.870802879333496,
      "learning_rate": 2.5194352658455996e-05,
      "logits/chosen": -0.40375643968582153,
      "logits/rejected": -0.21823588013648987,
      "logps/chosen": -277.78790283203125,
      "logps/rejected": -307.5337829589844,
      "loss": 0.1378,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.06496524810791,
      "rewards/margins": 3.854651927947998,
      "rewards/rejected": -13.91961669921875,
      "step": 11560
    },
    {
      "epoch": 3.4439648757255545,
      "grad_norm": 8.054030418395996,
      "learning_rate": 2.5146290177230405e-05,
      "logits/chosen": -0.34318238496780396,
      "logits/rejected": -0.3643049895763397,
      "logps/chosen": -269.5205078125,
      "logps/rejected": -319.72119140625,
      "loss": 0.1141,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.638697624206543,
      "rewards/margins": 4.491136074066162,
      "rewards/rejected": -14.129834175109863,
      "step": 11570
    },
    {
      "epoch": 3.446941509153148,
      "grad_norm": 1.180084228515625,
      "learning_rate": 2.5098227696004808e-05,
      "logits/chosen": -0.24174948036670685,
      "logits/rejected": -0.19354644417762756,
      "logps/chosen": -274.5017395019531,
      "logps/rejected": -329.5069274902344,
      "loss": 0.1052,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -9.775700569152832,
      "rewards/margins": 5.113098621368408,
      "rewards/rejected": -14.888798713684082,
      "step": 11580
    },
    {
      "epoch": 3.4499181425807413,
      "grad_norm": 2.949125051498413,
      "learning_rate": 2.5050165214779214e-05,
      "logits/chosen": -0.2809346318244934,
      "logits/rejected": -0.37883156538009644,
      "logps/chosen": -276.7692565917969,
      "logps/rejected": -336.36920166015625,
      "loss": 0.1261,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.949734687805176,
      "rewards/margins": 4.952792644500732,
      "rewards/rejected": -14.902524948120117,
      "step": 11590
    },
    {
      "epoch": 3.4528947760083346,
      "grad_norm": 5.017042636871338,
      "learning_rate": 2.500210273355362e-05,
      "logits/chosen": -0.3227144181728363,
      "logits/rejected": -0.27743807435035706,
      "logps/chosen": -282.78765869140625,
      "logps/rejected": -331.76824951171875,
      "loss": 0.1426,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.998727798461914,
      "rewards/margins": 4.773331642150879,
      "rewards/rejected": -14.772059440612793,
      "step": 11600
    },
    {
      "epoch": 3.455871409435928,
      "grad_norm": 5.662430763244629,
      "learning_rate": 2.495404025232803e-05,
      "logits/chosen": -0.2899455428123474,
      "logits/rejected": -0.28296536207199097,
      "logps/chosen": -274.73944091796875,
      "logps/rejected": -326.87060546875,
      "loss": 0.1401,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.438097953796387,
      "rewards/margins": 5.199799060821533,
      "rewards/rejected": -14.637898445129395,
      "step": 11610
    },
    {
      "epoch": 3.4588480428635213,
      "grad_norm": 5.087405681610107,
      "learning_rate": 2.4905977771102436e-05,
      "logits/chosen": -0.36965399980545044,
      "logits/rejected": -0.45200642943382263,
      "logps/chosen": -255.9808807373047,
      "logps/rejected": -315.7233581542969,
      "loss": 0.1537,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -9.39363956451416,
      "rewards/margins": 4.527800559997559,
      "rewards/rejected": -13.921438217163086,
      "step": 11620
    },
    {
      "epoch": 3.4618246762911147,
      "grad_norm": 5.941957473754883,
      "learning_rate": 2.4857915289876845e-05,
      "logits/chosen": -0.3936651349067688,
      "logits/rejected": -0.27159804105758667,
      "logps/chosen": -282.0767517089844,
      "logps/rejected": -337.17706298828125,
      "loss": 0.071,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.864737510681152,
      "rewards/margins": 5.809202671051025,
      "rewards/rejected": -15.673940658569336,
      "step": 11630
    },
    {
      "epoch": 3.464801309718708,
      "grad_norm": 1.8482847213745117,
      "learning_rate": 2.4809852808651248e-05,
      "logits/chosen": -0.2852763831615448,
      "logits/rejected": -0.34193500876426697,
      "logps/chosen": -283.99224853515625,
      "logps/rejected": -347.00396728515625,
      "loss": 0.2034,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -11.215655326843262,
      "rewards/margins": 5.322659492492676,
      "rewards/rejected": -16.538314819335938,
      "step": 11640
    },
    {
      "epoch": 3.4677779431463014,
      "grad_norm": 7.832004547119141,
      "learning_rate": 2.4761790327425654e-05,
      "logits/chosen": -0.1655213087797165,
      "logits/rejected": -0.3722147047519684,
      "logps/chosen": -263.73968505859375,
      "logps/rejected": -341.60888671875,
      "loss": 0.0958,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.971977233886719,
      "rewards/margins": 5.051540851593018,
      "rewards/rejected": -15.023516654968262,
      "step": 11650
    },
    {
      "epoch": 3.4707545765738947,
      "grad_norm": 1.0306204557418823,
      "learning_rate": 2.471372784620006e-05,
      "logits/chosen": -0.35004910826683044,
      "logits/rejected": -0.3743756413459778,
      "logps/chosen": -271.25311279296875,
      "logps/rejected": -339.1251220703125,
      "loss": 0.132,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.213225364685059,
      "rewards/margins": 5.1512346267700195,
      "rewards/rejected": -15.364460945129395,
      "step": 11660
    },
    {
      "epoch": 3.473731210001488,
      "grad_norm": 8.802118301391602,
      "learning_rate": 2.466566536497447e-05,
      "logits/chosen": -0.15603646636009216,
      "logits/rejected": -0.18428170680999756,
      "logps/chosen": -298.13970947265625,
      "logps/rejected": -350.2650146484375,
      "loss": 0.2028,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -12.094861030578613,
      "rewards/margins": 4.735468864440918,
      "rewards/rejected": -16.830333709716797,
      "step": 11670
    },
    {
      "epoch": 3.476707843429082,
      "grad_norm": 13.976459503173828,
      "learning_rate": 2.4617602883748876e-05,
      "logits/chosen": -0.16258104145526886,
      "logits/rejected": -0.32958558201789856,
      "logps/chosen": -253.5697021484375,
      "logps/rejected": -322.5364685058594,
      "loss": 0.1377,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.842192649841309,
      "rewards/margins": 4.746196746826172,
      "rewards/rejected": -14.588388442993164,
      "step": 11680
    },
    {
      "epoch": 3.4796844768566753,
      "grad_norm": 7.465741157531738,
      "learning_rate": 2.4569540402523286e-05,
      "logits/chosen": -0.36517027020454407,
      "logits/rejected": -0.2527540624141693,
      "logps/chosen": -297.2955627441406,
      "logps/rejected": -334.4279479980469,
      "loss": 0.137,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.539006233215332,
      "rewards/margins": 4.372441291809082,
      "rewards/rejected": -14.911447525024414,
      "step": 11690
    },
    {
      "epoch": 3.4826611102842686,
      "grad_norm": 19.02455711364746,
      "learning_rate": 2.452147792129769e-05,
      "logits/chosen": -0.10877661406993866,
      "logits/rejected": -0.1458016186952591,
      "logps/chosen": -295.64984130859375,
      "logps/rejected": -355.95294189453125,
      "loss": 0.0891,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.63335132598877,
      "rewards/margins": 5.305786609649658,
      "rewards/rejected": -16.939136505126953,
      "step": 11700
    },
    {
      "epoch": 3.485637743711862,
      "grad_norm": 3.1286487579345703,
      "learning_rate": 2.4473415440072095e-05,
      "logits/chosen": -0.16500063240528107,
      "logits/rejected": -0.35535088181495667,
      "logps/chosen": -289.5736083984375,
      "logps/rejected": -364.85748291015625,
      "loss": 0.1588,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -12.334510803222656,
      "rewards/margins": 4.919905185699463,
      "rewards/rejected": -17.25441551208496,
      "step": 11710
    },
    {
      "epoch": 3.4886143771394553,
      "grad_norm": 7.955048084259033,
      "learning_rate": 2.44253529588465e-05,
      "logits/chosen": -0.18768464028835297,
      "logits/rejected": -0.14817862212657928,
      "logps/chosen": -276.2109069824219,
      "logps/rejected": -327.24639892578125,
      "loss": 0.1146,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.569499015808105,
      "rewards/margins": 4.3721394538879395,
      "rewards/rejected": -14.94163990020752,
      "step": 11720
    },
    {
      "epoch": 3.4915910105670487,
      "grad_norm": 1.5415390729904175,
      "learning_rate": 2.437729047762091e-05,
      "logits/chosen": -0.20137491822242737,
      "logits/rejected": -0.11927972733974457,
      "logps/chosen": -273.742919921875,
      "logps/rejected": -335.27886962890625,
      "loss": 0.0677,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.132794380187988,
      "rewards/margins": 5.561026096343994,
      "rewards/rejected": -15.693819999694824,
      "step": 11730
    },
    {
      "epoch": 3.494567643994642,
      "grad_norm": 0.6772063970565796,
      "learning_rate": 2.4329227996395316e-05,
      "logits/chosen": -0.14722314476966858,
      "logits/rejected": -0.24485597014427185,
      "logps/chosen": -277.0122985839844,
      "logps/rejected": -367.9617919921875,
      "loss": 0.0801,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.289182662963867,
      "rewards/margins": 5.960452079772949,
      "rewards/rejected": -17.2496337890625,
      "step": 11740
    },
    {
      "epoch": 3.4975442774222354,
      "grad_norm": 10.864005088806152,
      "learning_rate": 2.4281165515169726e-05,
      "logits/chosen": -0.27213016152381897,
      "logits/rejected": -0.18458987772464752,
      "logps/chosen": -273.3509216308594,
      "logps/rejected": -335.0853576660156,
      "loss": 0.0953,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.146318435668945,
      "rewards/margins": 5.619591236114502,
      "rewards/rejected": -15.765910148620605,
      "step": 11750
    },
    {
      "epoch": 3.5005209108498287,
      "grad_norm": 7.699243545532227,
      "learning_rate": 2.423310303394413e-05,
      "logits/chosen": -0.3277067542076111,
      "logits/rejected": -0.5198855400085449,
      "logps/chosen": -279.8689270019531,
      "logps/rejected": -356.3337097167969,
      "loss": 0.1143,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.445798873901367,
      "rewards/margins": 4.871823787689209,
      "rewards/rejected": -15.31762409210205,
      "step": 11760
    },
    {
      "epoch": 3.503497544277422,
      "grad_norm": 14.116820335388184,
      "learning_rate": 2.4185040552718535e-05,
      "logits/chosen": -0.2054920494556427,
      "logits/rejected": -0.3442595601081848,
      "logps/chosen": -274.6158447265625,
      "logps/rejected": -340.35467529296875,
      "loss": 0.142,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.263567924499512,
      "rewards/margins": 5.216839790344238,
      "rewards/rejected": -16.480405807495117,
      "step": 11770
    },
    {
      "epoch": 3.506474177705016,
      "grad_norm": 5.166127681732178,
      "learning_rate": 2.413697807149294e-05,
      "logits/chosen": -0.38871413469314575,
      "logits/rejected": -0.37027156352996826,
      "logps/chosen": -274.98406982421875,
      "logps/rejected": -317.6028747558594,
      "loss": 0.1206,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.84782600402832,
      "rewards/margins": 4.813423156738281,
      "rewards/rejected": -14.661250114440918,
      "step": 11780
    },
    {
      "epoch": 3.5094508111326093,
      "grad_norm": 7.343161582946777,
      "learning_rate": 2.408891559026735e-05,
      "logits/chosen": -0.4584798216819763,
      "logits/rejected": -0.40360790491104126,
      "logps/chosen": -279.087646484375,
      "logps/rejected": -333.44677734375,
      "loss": 0.2207,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -10.033997535705566,
      "rewards/margins": 5.2161030769348145,
      "rewards/rejected": -15.250101089477539,
      "step": 11790
    },
    {
      "epoch": 3.5124274445602026,
      "grad_norm": 17.546836853027344,
      "learning_rate": 2.4040853109041757e-05,
      "logits/chosen": -0.2374405562877655,
      "logits/rejected": -0.246238112449646,
      "logps/chosen": -297.8878173828125,
      "logps/rejected": -341.8493957519531,
      "loss": 0.1558,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -11.44240951538086,
      "rewards/margins": 4.4540324211120605,
      "rewards/rejected": -15.896441459655762,
      "step": 11800
    },
    {
      "epoch": 3.515404077987796,
      "grad_norm": 2.210540533065796,
      "learning_rate": 2.3992790627816166e-05,
      "logits/chosen": -0.5172356367111206,
      "logits/rejected": -0.4884610176086426,
      "logps/chosen": -264.84124755859375,
      "logps/rejected": -317.88671875,
      "loss": 0.1232,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.378546714782715,
      "rewards/margins": 4.865699768066406,
      "rewards/rejected": -14.244247436523438,
      "step": 11810
    },
    {
      "epoch": 3.5183807114153893,
      "grad_norm": 6.406558513641357,
      "learning_rate": 2.394472814659057e-05,
      "logits/chosen": -0.43160152435302734,
      "logits/rejected": -0.40539899468421936,
      "logps/chosen": -261.9906311035156,
      "logps/rejected": -311.23883056640625,
      "loss": 0.1493,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -9.370692253112793,
      "rewards/margins": 4.6636199951171875,
      "rewards/rejected": -14.03431224822998,
      "step": 11820
    },
    {
      "epoch": 3.5213573448429827,
      "grad_norm": 6.9386467933654785,
      "learning_rate": 2.3896665665364975e-05,
      "logits/chosen": -0.46484479308128357,
      "logits/rejected": -0.5545981526374817,
      "logps/chosen": -245.4463348388672,
      "logps/rejected": -317.1294860839844,
      "loss": 0.1096,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.279478073120117,
      "rewards/margins": 4.433574199676514,
      "rewards/rejected": -12.713052749633789,
      "step": 11830
    },
    {
      "epoch": 3.524333978270576,
      "grad_norm": 2.41831636428833,
      "learning_rate": 2.384860318413938e-05,
      "logits/chosen": -0.47019582986831665,
      "logits/rejected": -0.2999230623245239,
      "logps/chosen": -247.82815551757812,
      "logps/rejected": -289.16571044921875,
      "loss": 0.1123,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.108449935913086,
      "rewards/margins": 4.948824882507324,
      "rewards/rejected": -13.057275772094727,
      "step": 11840
    },
    {
      "epoch": 3.5273106116981694,
      "grad_norm": 4.143951892852783,
      "learning_rate": 2.380054070291379e-05,
      "logits/chosen": -0.4276130795478821,
      "logits/rejected": -0.4615665376186371,
      "logps/chosen": -262.07330322265625,
      "logps/rejected": -316.70257568359375,
      "loss": 0.1125,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -9.432807922363281,
      "rewards/margins": 4.600300312042236,
      "rewards/rejected": -14.033108711242676,
      "step": 11850
    },
    {
      "epoch": 3.5302872451257628,
      "grad_norm": 1.8570910692214966,
      "learning_rate": 2.3752478221688197e-05,
      "logits/chosen": -0.3969166874885559,
      "logits/rejected": -0.3568965494632721,
      "logps/chosen": -274.7334289550781,
      "logps/rejected": -330.5202941894531,
      "loss": 0.1579,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.411324501037598,
      "rewards/margins": 4.702362060546875,
      "rewards/rejected": -15.113687515258789,
      "step": 11860
    },
    {
      "epoch": 3.533263878553356,
      "grad_norm": 7.455212116241455,
      "learning_rate": 2.3704415740462607e-05,
      "logits/chosen": -0.20447690784931183,
      "logits/rejected": -0.27646464109420776,
      "logps/chosen": -274.1688537597656,
      "logps/rejected": -338.07818603515625,
      "loss": 0.1264,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.293030738830566,
      "rewards/margins": 5.188148021697998,
      "rewards/rejected": -15.481178283691406,
      "step": 11870
    },
    {
      "epoch": 3.5362405119809495,
      "grad_norm": 4.13401460647583,
      "learning_rate": 2.365635325923701e-05,
      "logits/chosen": -0.13327594101428986,
      "logits/rejected": -0.077650286257267,
      "logps/chosen": -272.77008056640625,
      "logps/rejected": -332.7648010253906,
      "loss": 0.1033,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.193705558776855,
      "rewards/margins": 5.45787239074707,
      "rewards/rejected": -16.65157699584961,
      "step": 11880
    },
    {
      "epoch": 3.539217145408543,
      "grad_norm": 2.0796515941619873,
      "learning_rate": 2.3608290778011415e-05,
      "logits/chosen": -0.22139105200767517,
      "logits/rejected": -0.15206822752952576,
      "logps/chosen": -297.23284912109375,
      "logps/rejected": -342.3411560058594,
      "loss": 0.1555,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -12.242128372192383,
      "rewards/margins": 4.80573844909668,
      "rewards/rejected": -17.047866821289062,
      "step": 11890
    },
    {
      "epoch": 3.542193778836136,
      "grad_norm": 7.30399751663208,
      "learning_rate": 2.356022829678582e-05,
      "logits/chosen": -0.16047415137290955,
      "logits/rejected": -0.20101282000541687,
      "logps/chosen": -281.96209716796875,
      "logps/rejected": -335.1277770996094,
      "loss": 0.2103,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.9675931930542,
      "rewards/margins": 5.03815221786499,
      "rewards/rejected": -16.00574493408203,
      "step": 11900
    },
    {
      "epoch": 3.5451704122637295,
      "grad_norm": 6.559205055236816,
      "learning_rate": 2.351216581556023e-05,
      "logits/chosen": -0.18405483663082123,
      "logits/rejected": -0.26348844170570374,
      "logps/chosen": -263.04010009765625,
      "logps/rejected": -316.77008056640625,
      "loss": 0.1034,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.22801399230957,
      "rewards/margins": 4.527016639709473,
      "rewards/rejected": -14.755030632019043,
      "step": 11910
    },
    {
      "epoch": 3.548147045691323,
      "grad_norm": 4.026980876922607,
      "learning_rate": 2.3464103334334637e-05,
      "logits/chosen": -0.2497740238904953,
      "logits/rejected": -0.20842471718788147,
      "logps/chosen": -271.11187744140625,
      "logps/rejected": -324.85089111328125,
      "loss": 0.0749,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.351515769958496,
      "rewards/margins": 5.058197498321533,
      "rewards/rejected": -15.409713745117188,
      "step": 11920
    },
    {
      "epoch": 3.5511236791189162,
      "grad_norm": 5.935850620269775,
      "learning_rate": 2.3416040853109047e-05,
      "logits/chosen": 0.013939142227172852,
      "logits/rejected": -0.1162637248635292,
      "logps/chosen": -283.6661071777344,
      "logps/rejected": -343.21014404296875,
      "loss": 0.1619,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.734471321105957,
      "rewards/margins": 4.421652793884277,
      "rewards/rejected": -16.156124114990234,
      "step": 11930
    },
    {
      "epoch": 3.55410031254651,
      "grad_norm": 9.620502471923828,
      "learning_rate": 2.336797837188345e-05,
      "logits/chosen": -0.1380743682384491,
      "logits/rejected": -0.21959920227527618,
      "logps/chosen": -297.02581787109375,
      "logps/rejected": -350.5169372558594,
      "loss": 0.1648,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -12.353798866271973,
      "rewards/margins": 4.339341163635254,
      "rewards/rejected": -16.693140029907227,
      "step": 11940
    },
    {
      "epoch": 3.5570769459741034,
      "grad_norm": 2.6896252632141113,
      "learning_rate": 2.3319915890657856e-05,
      "logits/chosen": -0.09201683104038239,
      "logits/rejected": -0.0647476464509964,
      "logps/chosen": -266.2200927734375,
      "logps/rejected": -318.2149963378906,
      "loss": 0.1317,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.943700790405273,
      "rewards/margins": 4.498805999755859,
      "rewards/rejected": -15.44250774383545,
      "step": 11950
    },
    {
      "epoch": 3.5600535794016968,
      "grad_norm": 0.9913008809089661,
      "learning_rate": 2.3271853409432262e-05,
      "logits/chosen": 0.13586130738258362,
      "logits/rejected": -0.14238207042217255,
      "logps/chosen": -273.7008361816406,
      "logps/rejected": -358.19940185546875,
      "loss": 0.1031,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.752798080444336,
      "rewards/margins": 5.348635673522949,
      "rewards/rejected": -17.1014347076416,
      "step": 11960
    },
    {
      "epoch": 3.56303021282929,
      "grad_norm": 3.1111671924591064,
      "learning_rate": 2.322379092820667e-05,
      "logits/chosen": -0.20722274482250214,
      "logits/rejected": -0.16015586256980896,
      "logps/chosen": -291.89007568359375,
      "logps/rejected": -346.1412048339844,
      "loss": 0.1638,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -11.735837936401367,
      "rewards/margins": 4.582751274108887,
      "rewards/rejected": -16.31859016418457,
      "step": 11970
    },
    {
      "epoch": 3.5660068462568835,
      "grad_norm": 3.073568105697632,
      "learning_rate": 2.3175728446981078e-05,
      "logits/chosen": -0.07418917119503021,
      "logits/rejected": -0.24857845902442932,
      "logps/chosen": -285.1302795410156,
      "logps/rejected": -367.92572021484375,
      "loss": 0.0592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -11.04460334777832,
      "rewards/margins": 5.677643775939941,
      "rewards/rejected": -16.722248077392578,
      "step": 11980
    },
    {
      "epoch": 3.568983479684477,
      "grad_norm": 2.057025671005249,
      "learning_rate": 2.3127665965755487e-05,
      "logits/chosen": -0.11116846650838852,
      "logits/rejected": -0.14731857180595398,
      "logps/chosen": -298.8615417480469,
      "logps/rejected": -374.61419677734375,
      "loss": 0.0978,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -12.13784408569336,
      "rewards/margins": 5.606139183044434,
      "rewards/rejected": -17.74398422241211,
      "step": 11990
    },
    {
      "epoch": 3.57196011311207,
      "grad_norm": 5.8234734535217285,
      "learning_rate": 2.307960348452989e-05,
      "logits/chosen": -0.22725915908813477,
      "logits/rejected": -0.09800676256418228,
      "logps/chosen": -269.060302734375,
      "logps/rejected": -319.7122497558594,
      "loss": 0.1242,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.439652442932129,
      "rewards/margins": 5.527449131011963,
      "rewards/rejected": -14.967100143432617,
      "step": 12000
    },
    {
      "epoch": 3.5749367465396635,
      "grad_norm": 6.441647052764893,
      "learning_rate": 2.3031541003304296e-05,
      "logits/chosen": -0.2789762616157532,
      "logits/rejected": -0.1413639485836029,
      "logps/chosen": -292.5922546386719,
      "logps/rejected": -323.63116455078125,
      "loss": 0.1382,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.78515625,
      "rewards/margins": 4.305581092834473,
      "rewards/rejected": -15.090738296508789,
      "step": 12010
    },
    {
      "epoch": 3.577913379967257,
      "grad_norm": 2.6971776485443115,
      "learning_rate": 2.2983478522078702e-05,
      "logits/chosen": -0.1926496922969818,
      "logits/rejected": -0.2819444239139557,
      "logps/chosen": -297.5921936035156,
      "logps/rejected": -369.17352294921875,
      "loss": 0.1765,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.408281326293945,
      "rewards/margins": 5.6847944259643555,
      "rewards/rejected": -17.093074798583984,
      "step": 12020
    },
    {
      "epoch": 3.5808900133948507,
      "grad_norm": 6.7957000732421875,
      "learning_rate": 2.293541604085311e-05,
      "logits/chosen": -0.27648061513900757,
      "logits/rejected": -0.3982151448726654,
      "logps/chosen": -281.55047607421875,
      "logps/rejected": -352.2635498046875,
      "loss": 0.1944,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -11.152162551879883,
      "rewards/margins": 5.288376808166504,
      "rewards/rejected": -16.440540313720703,
      "step": 12030
    },
    {
      "epoch": 3.583866646822444,
      "grad_norm": 2.818222999572754,
      "learning_rate": 2.2887353559627518e-05,
      "logits/chosen": -0.21152186393737793,
      "logits/rejected": -0.2060718834400177,
      "logps/chosen": -272.3221130371094,
      "logps/rejected": -332.42889404296875,
      "loss": 0.1047,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.275644302368164,
      "rewards/margins": 5.699117183685303,
      "rewards/rejected": -15.974761962890625,
      "step": 12040
    },
    {
      "epoch": 3.5868432802500374,
      "grad_norm": 20.332096099853516,
      "learning_rate": 2.2839291078401927e-05,
      "logits/chosen": -0.10097205638885498,
      "logits/rejected": -0.17446549236774445,
      "logps/chosen": -301.07415771484375,
      "logps/rejected": -377.6773986816406,
      "loss": 0.1229,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.682768821716309,
      "rewards/margins": 5.679837226867676,
      "rewards/rejected": -17.362606048583984,
      "step": 12050
    },
    {
      "epoch": 3.5898199136776308,
      "grad_norm": 0.3604864776134491,
      "learning_rate": 2.279122859717633e-05,
      "logits/chosen": -0.21435825526714325,
      "logits/rejected": -0.212269589304924,
      "logps/chosen": -270.3297119140625,
      "logps/rejected": -332.93463134765625,
      "loss": 0.128,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.857038497924805,
      "rewards/margins": 5.330479621887207,
      "rewards/rejected": -15.187517166137695,
      "step": 12060
    },
    {
      "epoch": 3.592796547105224,
      "grad_norm": 3.674919605255127,
      "learning_rate": 2.2743166115950736e-05,
      "logits/chosen": -0.299324631690979,
      "logits/rejected": -0.19713082909584045,
      "logps/chosen": -284.6796569824219,
      "logps/rejected": -351.027587890625,
      "loss": 0.0612,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.303443908691406,
      "rewards/margins": 5.903680324554443,
      "rewards/rejected": -16.207124710083008,
      "step": 12070
    },
    {
      "epoch": 3.5957731805328175,
      "grad_norm": 5.932102203369141,
      "learning_rate": 2.2695103634725146e-05,
      "logits/chosen": -0.2441025972366333,
      "logits/rejected": -0.23975367844104767,
      "logps/chosen": -291.46197509765625,
      "logps/rejected": -355.7497863769531,
      "loss": 0.1265,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.098787307739258,
      "rewards/margins": 5.880263328552246,
      "rewards/rejected": -16.97905158996582,
      "step": 12080
    },
    {
      "epoch": 3.598749813960411,
      "grad_norm": 0.6085813045501709,
      "learning_rate": 2.2647041153499552e-05,
      "logits/chosen": -0.15125401318073273,
      "logits/rejected": -0.18186691403388977,
      "logps/chosen": -274.0357360839844,
      "logps/rejected": -328.033447265625,
      "loss": 0.1064,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.387773513793945,
      "rewards/margins": 4.947550296783447,
      "rewards/rejected": -15.335322380065918,
      "step": 12090
    },
    {
      "epoch": 3.601726447388004,
      "grad_norm": 10.950566291809082,
      "learning_rate": 2.2598978672273958e-05,
      "logits/chosen": -0.0032555670477449894,
      "logits/rejected": -0.2108067274093628,
      "logps/chosen": -279.0096740722656,
      "logps/rejected": -368.71258544921875,
      "loss": 0.1091,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.034429550170898,
      "rewards/margins": 5.724212169647217,
      "rewards/rejected": -17.758642196655273,
      "step": 12100
    },
    {
      "epoch": 3.6047030808155975,
      "grad_norm": 2.6797432899475098,
      "learning_rate": 2.2550916191048368e-05,
      "logits/chosen": 0.09711909294128418,
      "logits/rejected": -0.10120675712823868,
      "logps/chosen": -278.4767150878906,
      "logps/rejected": -360.0436096191406,
      "loss": 0.1136,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.52787971496582,
      "rewards/margins": 5.910973072052002,
      "rewards/rejected": -17.438854217529297,
      "step": 12110
    },
    {
      "epoch": 3.607679714243191,
      "grad_norm": 4.447271823883057,
      "learning_rate": 2.250285370982277e-05,
      "logits/chosen": -0.17976802587509155,
      "logits/rejected": -0.1348683089017868,
      "logps/chosen": -290.60394287109375,
      "logps/rejected": -337.48114013671875,
      "loss": 0.1592,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.423805236816406,
      "rewards/margins": 5.161895751953125,
      "rewards/rejected": -16.5856990814209,
      "step": 12120
    },
    {
      "epoch": 3.6106563476707842,
      "grad_norm": 2.156184673309326,
      "learning_rate": 2.2454791228597177e-05,
      "logits/chosen": -0.17178331315517426,
      "logits/rejected": -0.1868758350610733,
      "logps/chosen": -290.8645935058594,
      "logps/rejected": -359.573486328125,
      "loss": 0.1105,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.705246925354004,
      "rewards/margins": 5.9519877433776855,
      "rewards/rejected": -17.657236099243164,
      "step": 12130
    },
    {
      "epoch": 3.6136329810983776,
      "grad_norm": 0.2600594460964203,
      "learning_rate": 2.2406728747371586e-05,
      "logits/chosen": -0.08653700351715088,
      "logits/rejected": -0.1039588674902916,
      "logps/chosen": -273.7076110839844,
      "logps/rejected": -344.31610107421875,
      "loss": 0.0954,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.331818580627441,
      "rewards/margins": 5.967316627502441,
      "rewards/rejected": -17.299137115478516,
      "step": 12140
    },
    {
      "epoch": 3.616609614525971,
      "grad_norm": 0.9996023178100586,
      "learning_rate": 2.2358666266145992e-05,
      "logits/chosen": -0.08305483311414719,
      "logits/rejected": -0.26356014609336853,
      "logps/chosen": -292.3388366699219,
      "logps/rejected": -375.51470947265625,
      "loss": 0.1552,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -12.183797836303711,
      "rewards/margins": 5.844053268432617,
      "rewards/rejected": -18.027851104736328,
      "step": 12150
    },
    {
      "epoch": 3.6195862479535643,
      "grad_norm": 4.698025226593018,
      "learning_rate": 2.23106037849204e-05,
      "logits/chosen": -0.34274089336395264,
      "logits/rejected": -0.24196366965770721,
      "logps/chosen": -282.9724426269531,
      "logps/rejected": -329.82501220703125,
      "loss": 0.1834,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -10.880691528320312,
      "rewards/margins": 5.170367240905762,
      "rewards/rejected": -16.05105972290039,
      "step": 12160
    },
    {
      "epoch": 3.6225628813811577,
      "grad_norm": 1.6240290403366089,
      "learning_rate": 2.2262541303694808e-05,
      "logits/chosen": -0.22693531215190887,
      "logits/rejected": -0.25647133588790894,
      "logps/chosen": -273.27215576171875,
      "logps/rejected": -351.14154052734375,
      "loss": 0.1075,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.417478561401367,
      "rewards/margins": 6.046141624450684,
      "rewards/rejected": -16.463621139526367,
      "step": 12170
    },
    {
      "epoch": 3.625539514808751,
      "grad_norm": 5.912861347198486,
      "learning_rate": 2.221447882246921e-05,
      "logits/chosen": -0.1494339406490326,
      "logits/rejected": -0.25214916467666626,
      "logps/chosen": -266.0310363769531,
      "logps/rejected": -326.67889404296875,
      "loss": 0.1587,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.213517189025879,
      "rewards/margins": 4.688246726989746,
      "rewards/rejected": -14.901763916015625,
      "step": 12180
    },
    {
      "epoch": 3.628516148236345,
      "grad_norm": 0.4607204496860504,
      "learning_rate": 2.2166416341243617e-05,
      "logits/chosen": -0.3250376880168915,
      "logits/rejected": -0.12368295341730118,
      "logps/chosen": -288.3824768066406,
      "logps/rejected": -326.35504150390625,
      "loss": 0.0875,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.189386367797852,
      "rewards/margins": 4.887275218963623,
      "rewards/rejected": -15.076662063598633,
      "step": 12190
    },
    {
      "epoch": 3.631492781663938,
      "grad_norm": 12.955901145935059,
      "learning_rate": 2.2118353860018026e-05,
      "logits/chosen": -0.1977066695690155,
      "logits/rejected": -0.1572306603193283,
      "logps/chosen": -279.4930114746094,
      "logps/rejected": -343.50860595703125,
      "loss": 0.1177,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.34516716003418,
      "rewards/margins": 5.419510841369629,
      "rewards/rejected": -15.764677047729492,
      "step": 12200
    },
    {
      "epoch": 3.6344694150915315,
      "grad_norm": 5.619563102722168,
      "learning_rate": 2.2070291378792432e-05,
      "logits/chosen": -0.2501685619354248,
      "logits/rejected": -0.36431917548179626,
      "logps/chosen": -277.7597961425781,
      "logps/rejected": -350.7186584472656,
      "loss": 0.1219,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.975065231323242,
      "rewards/margins": 5.0920186042785645,
      "rewards/rejected": -16.067081451416016,
      "step": 12210
    },
    {
      "epoch": 3.637446048519125,
      "grad_norm": 5.3678388595581055,
      "learning_rate": 2.202222889756684e-05,
      "logits/chosen": -0.3379662334918976,
      "logits/rejected": -0.3077704906463623,
      "logps/chosen": -275.44061279296875,
      "logps/rejected": -347.0943908691406,
      "loss": 0.1086,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.154200553894043,
      "rewards/margins": 5.36443567276001,
      "rewards/rejected": -15.518636703491211,
      "step": 12220
    },
    {
      "epoch": 3.6404226819467183,
      "grad_norm": 2.2365152835845947,
      "learning_rate": 2.1974166416341248e-05,
      "logits/chosen": -0.2767491340637207,
      "logits/rejected": -0.3176765441894531,
      "logps/chosen": -279.9425354003906,
      "logps/rejected": -340.4295349121094,
      "loss": 0.1386,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.334615707397461,
      "rewards/margins": 5.373314380645752,
      "rewards/rejected": -16.707929611206055,
      "step": 12230
    },
    {
      "epoch": 3.6433993153743116,
      "grad_norm": 2.2395482063293457,
      "learning_rate": 2.192610393511565e-05,
      "logits/chosen": -0.24563005566596985,
      "logits/rejected": -0.21713793277740479,
      "logps/chosen": -269.3737487792969,
      "logps/rejected": -319.5242614746094,
      "loss": 0.1776,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.224040985107422,
      "rewards/margins": 4.881766319274902,
      "rewards/rejected": -15.105804443359375,
      "step": 12240
    },
    {
      "epoch": 3.646375948801905,
      "grad_norm": 2.191908359527588,
      "learning_rate": 2.1878041453890057e-05,
      "logits/chosen": -0.427503764629364,
      "logits/rejected": -0.39628666639328003,
      "logps/chosen": -293.70721435546875,
      "logps/rejected": -336.30084228515625,
      "loss": 0.1528,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.186771392822266,
      "rewards/margins": 4.526358604431152,
      "rewards/rejected": -14.713129997253418,
      "step": 12250
    },
    {
      "epoch": 3.6493525822294983,
      "grad_norm": 4.609481334686279,
      "learning_rate": 2.1829978972664467e-05,
      "logits/chosen": -0.307547390460968,
      "logits/rejected": -0.2897360622882843,
      "logps/chosen": -276.1286926269531,
      "logps/rejected": -334.7425231933594,
      "loss": 0.1017,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.579858779907227,
      "rewards/margins": 5.562839508056641,
      "rewards/rejected": -15.1427001953125,
      "step": 12260
    },
    {
      "epoch": 3.6523292156570917,
      "grad_norm": 3.9700562953948975,
      "learning_rate": 2.1781916491438873e-05,
      "logits/chosen": -0.2430892288684845,
      "logits/rejected": -0.28380364179611206,
      "logps/chosen": -281.55206298828125,
      "logps/rejected": -356.949951171875,
      "loss": 0.1728,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.538125991821289,
      "rewards/margins": 5.338408470153809,
      "rewards/rejected": -15.876531600952148,
      "step": 12270
    },
    {
      "epoch": 3.6553058490846855,
      "grad_norm": 8.648880958557129,
      "learning_rate": 2.173385401021328e-05,
      "logits/chosen": -0.2510024905204773,
      "logits/rejected": -0.23949894309043884,
      "logps/chosen": -263.55023193359375,
      "logps/rejected": -313.7266540527344,
      "loss": 0.0672,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.042928695678711,
      "rewards/margins": 4.754474639892578,
      "rewards/rejected": -13.797403335571289,
      "step": 12280
    },
    {
      "epoch": 3.658282482512279,
      "grad_norm": 1.922758936882019,
      "learning_rate": 2.168579152898769e-05,
      "logits/chosen": -0.11717615276575089,
      "logits/rejected": -0.23203349113464355,
      "logps/chosen": -271.30377197265625,
      "logps/rejected": -349.67279052734375,
      "loss": 0.1155,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.730822563171387,
      "rewards/margins": 5.744754791259766,
      "rewards/rejected": -16.475576400756836,
      "step": 12290
    },
    {
      "epoch": 3.661259115939872,
      "grad_norm": 9.07068920135498,
      "learning_rate": 2.163772904776209e-05,
      "logits/chosen": -0.20039084553718567,
      "logits/rejected": -0.16101384162902832,
      "logps/chosen": -281.96917724609375,
      "logps/rejected": -329.5494079589844,
      "loss": 0.1474,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.596084594726562,
      "rewards/margins": 4.589824199676514,
      "rewards/rejected": -15.185907363891602,
      "step": 12300
    },
    {
      "epoch": 3.6642357493674655,
      "grad_norm": 20.578739166259766,
      "learning_rate": 2.1589666566536497e-05,
      "logits/chosen": -0.09967372566461563,
      "logits/rejected": -0.06454719603061676,
      "logps/chosen": -294.6985778808594,
      "logps/rejected": -342.9775085449219,
      "loss": 0.1542,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.801698684692383,
      "rewards/margins": 4.427910804748535,
      "rewards/rejected": -16.2296085357666,
      "step": 12310
    },
    {
      "epoch": 3.667212382795059,
      "grad_norm": 5.785316467285156,
      "learning_rate": 2.1541604085310907e-05,
      "logits/chosen": -0.07759643346071243,
      "logits/rejected": -0.024419667199254036,
      "logps/chosen": -294.9243469238281,
      "logps/rejected": -356.1536560058594,
      "loss": 0.0635,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.63813304901123,
      "rewards/margins": 5.025738716125488,
      "rewards/rejected": -17.66387176513672,
      "step": 12320
    },
    {
      "epoch": 3.6701890162226523,
      "grad_norm": 2.6543471813201904,
      "learning_rate": 2.1493541604085313e-05,
      "logits/chosen": -0.10825403034687042,
      "logits/rejected": -0.21812479197978973,
      "logps/chosen": -288.74041748046875,
      "logps/rejected": -370.44000244140625,
      "loss": 0.1709,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -10.837860107421875,
      "rewards/margins": 6.227139949798584,
      "rewards/rejected": -17.064998626708984,
      "step": 12330
    },
    {
      "epoch": 3.6731656496502456,
      "grad_norm": 4.963797569274902,
      "learning_rate": 2.144547912285972e-05,
      "logits/chosen": -0.0783543512225151,
      "logits/rejected": -0.2546692490577698,
      "logps/chosen": -290.6510009765625,
      "logps/rejected": -361.8329772949219,
      "loss": 0.1305,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.100081443786621,
      "rewards/margins": 4.691497802734375,
      "rewards/rejected": -16.791576385498047,
      "step": 12340
    },
    {
      "epoch": 3.676142283077839,
      "grad_norm": 14.36071491241455,
      "learning_rate": 2.139741664163413e-05,
      "logits/chosen": -0.17688524723052979,
      "logits/rejected": -0.2841394543647766,
      "logps/chosen": -298.8415832519531,
      "logps/rejected": -379.36114501953125,
      "loss": 0.166,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -12.02768325805664,
      "rewards/margins": 5.852331638336182,
      "rewards/rejected": -17.880014419555664,
      "step": 12350
    },
    {
      "epoch": 3.6791189165054323,
      "grad_norm": 12.02843952178955,
      "learning_rate": 2.134935416040853e-05,
      "logits/chosen": -0.2926334738731384,
      "logits/rejected": -0.36228689551353455,
      "logps/chosen": -277.9496154785156,
      "logps/rejected": -346.1302185058594,
      "loss": 0.177,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.777009010314941,
      "rewards/margins": 4.8647003173828125,
      "rewards/rejected": -15.641708374023438,
      "step": 12360
    },
    {
      "epoch": 3.6820955499330257,
      "grad_norm": 11.463549613952637,
      "learning_rate": 2.1301291679182938e-05,
      "logits/chosen": -0.3268962502479553,
      "logits/rejected": -0.33332183957099915,
      "logps/chosen": -280.2235412597656,
      "logps/rejected": -327.3154602050781,
      "loss": 0.1206,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.466856956481934,
      "rewards/margins": 4.628315448760986,
      "rewards/rejected": -14.095171928405762,
      "step": 12370
    },
    {
      "epoch": 3.685072183360619,
      "grad_norm": 5.365075588226318,
      "learning_rate": 2.1253229197957347e-05,
      "logits/chosen": -0.1921788901090622,
      "logits/rejected": -0.1914301961660385,
      "logps/chosen": -285.64312744140625,
      "logps/rejected": -334.1799011230469,
      "loss": 0.103,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.172772407531738,
      "rewards/margins": 4.505755424499512,
      "rewards/rejected": -15.67852783203125,
      "step": 12380
    },
    {
      "epoch": 3.6880488167882124,
      "grad_norm": 4.144796848297119,
      "learning_rate": 2.1205166716731753e-05,
      "logits/chosen": -0.14945752918720245,
      "logits/rejected": -0.1187349408864975,
      "logps/chosen": -298.74212646484375,
      "logps/rejected": -357.30206298828125,
      "loss": 0.1294,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -12.091758728027344,
      "rewards/margins": 5.171477317810059,
      "rewards/rejected": -17.26323699951172,
      "step": 12390
    },
    {
      "epoch": 3.6910254502158057,
      "grad_norm": 6.597752571105957,
      "learning_rate": 2.115710423550616e-05,
      "logits/chosen": -0.045669518411159515,
      "logits/rejected": -0.15339365601539612,
      "logps/chosen": -295.91741943359375,
      "logps/rejected": -369.77642822265625,
      "loss": 0.1199,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.015828132629395,
      "rewards/margins": 5.579859256744385,
      "rewards/rejected": -17.595687866210938,
      "step": 12400
    },
    {
      "epoch": 3.694002083643399,
      "grad_norm": 11.321330070495605,
      "learning_rate": 2.110904175428057e-05,
      "logits/chosen": -0.08397816121578217,
      "logits/rejected": -0.31442397832870483,
      "logps/chosen": -281.4794921875,
      "logps/rejected": -366.7243347167969,
      "loss": 0.1251,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.937385559082031,
      "rewards/margins": 5.577115058898926,
      "rewards/rejected": -16.51449966430664,
      "step": 12410
    },
    {
      "epoch": 3.6969787170709925,
      "grad_norm": 17.373001098632812,
      "learning_rate": 2.1060979273054972e-05,
      "logits/chosen": -0.19791118800640106,
      "logits/rejected": -0.2753519117832184,
      "logps/chosen": -282.93670654296875,
      "logps/rejected": -334.3510437011719,
      "loss": 0.2552,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -11.43017578125,
      "rewards/margins": 3.862210512161255,
      "rewards/rejected": -15.292384147644043,
      "step": 12420
    },
    {
      "epoch": 3.6999553504985863,
      "grad_norm": 4.854043960571289,
      "learning_rate": 2.1012916791829378e-05,
      "logits/chosen": -0.2034159153699875,
      "logits/rejected": -0.09650453180074692,
      "logps/chosen": -269.72760009765625,
      "logps/rejected": -318.78582763671875,
      "loss": 0.1012,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.46785831451416,
      "rewards/margins": 5.3356828689575195,
      "rewards/rejected": -15.803540229797363,
      "step": 12430
    },
    {
      "epoch": 3.7029319839261796,
      "grad_norm": 3.7630698680877686,
      "learning_rate": 2.0964854310603787e-05,
      "logits/chosen": -0.12376512587070465,
      "logits/rejected": -0.310870498418808,
      "logps/chosen": -264.60601806640625,
      "logps/rejected": -328.4028015136719,
      "loss": 0.0679,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.674382209777832,
      "rewards/margins": 4.794703483581543,
      "rewards/rejected": -15.469085693359375,
      "step": 12440
    },
    {
      "epoch": 3.705908617353773,
      "grad_norm": 0.5248737931251526,
      "learning_rate": 2.0916791829378194e-05,
      "logits/chosen": -0.2692264914512634,
      "logits/rejected": -0.3596413731575012,
      "logps/chosen": -297.869384765625,
      "logps/rejected": -378.401611328125,
      "loss": 0.0796,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.228809356689453,
      "rewards/margins": 6.07623815536499,
      "rewards/rejected": -18.3050479888916,
      "step": 12450
    },
    {
      "epoch": 3.7088852507813663,
      "grad_norm": 4.518884181976318,
      "learning_rate": 2.08687293481526e-05,
      "logits/chosen": -0.1489080786705017,
      "logits/rejected": -0.12872275710105896,
      "logps/chosen": -276.24444580078125,
      "logps/rejected": -337.43560791015625,
      "loss": 0.1304,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -11.02354621887207,
      "rewards/margins": 5.592546463012695,
      "rewards/rejected": -16.616092681884766,
      "step": 12460
    },
    {
      "epoch": 3.7118618842089597,
      "grad_norm": 7.666529178619385,
      "learning_rate": 2.082066686692701e-05,
      "logits/chosen": -0.24719390273094177,
      "logits/rejected": -0.22695240378379822,
      "logps/chosen": -288.5994873046875,
      "logps/rejected": -351.22296142578125,
      "loss": 0.086,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.143967628479004,
      "rewards/margins": 5.689196586608887,
      "rewards/rejected": -16.83316421508789,
      "step": 12470
    },
    {
      "epoch": 3.714838517636553,
      "grad_norm": 1.3277286291122437,
      "learning_rate": 2.0772604385701412e-05,
      "logits/chosen": -0.15842707455158234,
      "logits/rejected": -0.19518299400806427,
      "logps/chosen": -285.04449462890625,
      "logps/rejected": -358.23211669921875,
      "loss": 0.1131,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.138412475585938,
      "rewards/margins": 5.812320232391357,
      "rewards/rejected": -16.950733184814453,
      "step": 12480
    },
    {
      "epoch": 3.7178151510641464,
      "grad_norm": 1.607377052307129,
      "learning_rate": 2.0724541904475818e-05,
      "logits/chosen": -0.2125297337770462,
      "logits/rejected": -0.3511059582233429,
      "logps/chosen": -281.7194519042969,
      "logps/rejected": -357.27880859375,
      "loss": 0.1073,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.74719524383545,
      "rewards/margins": 5.654536247253418,
      "rewards/rejected": -17.401729583740234,
      "step": 12490
    },
    {
      "epoch": 3.7207917844917398,
      "grad_norm": 21.19643783569336,
      "learning_rate": 2.0676479423250228e-05,
      "logits/chosen": -0.14586715400218964,
      "logits/rejected": -0.3083896338939667,
      "logps/chosen": -289.8128356933594,
      "logps/rejected": -367.440673828125,
      "loss": 0.1262,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.973783493041992,
      "rewards/margins": 5.3472700119018555,
      "rewards/rejected": -17.321054458618164,
      "step": 12500
    },
    {
      "epoch": 3.723768417919333,
      "grad_norm": 4.003468990325928,
      "learning_rate": 2.0628416942024634e-05,
      "logits/chosen": -0.11758460104465485,
      "logits/rejected": -0.33730849623680115,
      "logps/chosen": -298.55133056640625,
      "logps/rejected": -392.8784484863281,
      "loss": 0.0705,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.876913070678711,
      "rewards/margins": 6.4693732261657715,
      "rewards/rejected": -18.34628677368164,
      "step": 12510
    },
    {
      "epoch": 3.7267450513469265,
      "grad_norm": 11.031200408935547,
      "learning_rate": 2.058035446079904e-05,
      "logits/chosen": -0.37043872475624084,
      "logits/rejected": -0.12707041203975677,
      "logps/chosen": -297.4029846191406,
      "logps/rejected": -334.47943115234375,
      "loss": 0.1119,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.169622421264648,
      "rewards/margins": 5.5816144943237305,
      "rewards/rejected": -15.751235961914062,
      "step": 12520
    },
    {
      "epoch": 3.7297216847745203,
      "grad_norm": 1.2650622129440308,
      "learning_rate": 2.053229197957345e-05,
      "logits/chosen": -0.37365883588790894,
      "logits/rejected": -0.25359708070755005,
      "logps/chosen": -276.2410888671875,
      "logps/rejected": -313.02789306640625,
      "loss": 0.1234,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -8.571768760681152,
      "rewards/margins": 5.167181968688965,
      "rewards/rejected": -13.738950729370117,
      "step": 12530
    },
    {
      "epoch": 3.7326983182021136,
      "grad_norm": 6.650180339813232,
      "learning_rate": 2.0484229498347852e-05,
      "logits/chosen": -0.29106563329696655,
      "logits/rejected": -0.1921030580997467,
      "logps/chosen": -290.4085388183594,
      "logps/rejected": -343.1824951171875,
      "loss": 0.0903,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.09710693359375,
      "rewards/margins": 4.998631000518799,
      "rewards/rejected": -16.095735549926758,
      "step": 12540
    },
    {
      "epoch": 3.735674951629707,
      "grad_norm": 3.036844253540039,
      "learning_rate": 2.043616701712226e-05,
      "logits/chosen": -0.27177292108535767,
      "logits/rejected": -0.2495773583650589,
      "logps/chosen": -274.93414306640625,
      "logps/rejected": -339.35125732421875,
      "loss": 0.091,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.753120422363281,
      "rewards/margins": 4.96248722076416,
      "rewards/rejected": -15.715609550476074,
      "step": 12550
    },
    {
      "epoch": 3.7386515850573003,
      "grad_norm": 1.5005583763122559,
      "learning_rate": 2.0388104535896668e-05,
      "logits/chosen": -0.16349737346172333,
      "logits/rejected": -0.30460625886917114,
      "logps/chosen": -276.36285400390625,
      "logps/rejected": -337.24053955078125,
      "loss": 0.1691,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.932889938354492,
      "rewards/margins": 4.816812515258789,
      "rewards/rejected": -15.749702453613281,
      "step": 12560
    },
    {
      "epoch": 3.7416282184848937,
      "grad_norm": 6.002533912658691,
      "learning_rate": 2.0340042054671074e-05,
      "logits/chosen": 0.029586344957351685,
      "logits/rejected": -0.10097034275531769,
      "logps/chosen": -290.9139099121094,
      "logps/rejected": -361.0074157714844,
      "loss": 0.1135,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.976902961730957,
      "rewards/margins": 5.463184833526611,
      "rewards/rejected": -17.440088272094727,
      "step": 12570
    },
    {
      "epoch": 3.744604851912487,
      "grad_norm": 16.632577896118164,
      "learning_rate": 2.029197957344548e-05,
      "logits/chosen": -0.18808215856552124,
      "logits/rejected": -0.20706982910633087,
      "logps/chosen": -307.72760009765625,
      "logps/rejected": -368.57281494140625,
      "loss": 0.1783,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -12.169393539428711,
      "rewards/margins": 5.561187744140625,
      "rewards/rejected": -17.730579376220703,
      "step": 12580
    },
    {
      "epoch": 3.7475814853400804,
      "grad_norm": 8.45357608795166,
      "learning_rate": 2.024391709221989e-05,
      "logits/chosen": -0.19602873921394348,
      "logits/rejected": -0.052424997091293335,
      "logps/chosen": -274.4476013183594,
      "logps/rejected": -317.76165771484375,
      "loss": 0.1518,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.790454864501953,
      "rewards/margins": 4.741070747375488,
      "rewards/rejected": -15.531526565551758,
      "step": 12590
    },
    {
      "epoch": 3.7505581187676738,
      "grad_norm": 2.779681444168091,
      "learning_rate": 2.0195854610994293e-05,
      "logits/chosen": -0.17380373179912567,
      "logits/rejected": -0.1299785077571869,
      "logps/chosen": -298.0980224609375,
      "logps/rejected": -346.91412353515625,
      "loss": 0.0931,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.615601539611816,
      "rewards/margins": 5.427304267883301,
      "rewards/rejected": -17.042903900146484,
      "step": 12600
    },
    {
      "epoch": 3.753534752195267,
      "grad_norm": 7.647292613983154,
      "learning_rate": 2.01477921297687e-05,
      "logits/chosen": -0.08173041045665741,
      "logits/rejected": 0.02029174380004406,
      "logps/chosen": -304.781494140625,
      "logps/rejected": -362.31671142578125,
      "loss": 0.1068,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -12.010459899902344,
      "rewards/margins": 5.500279426574707,
      "rewards/rejected": -17.510738372802734,
      "step": 12610
    },
    {
      "epoch": 3.7565113856228605,
      "grad_norm": 17.40541648864746,
      "learning_rate": 2.0099729648543108e-05,
      "logits/chosen": -0.05923237279057503,
      "logits/rejected": -0.09935446083545685,
      "logps/chosen": -297.5428466796875,
      "logps/rejected": -372.419921875,
      "loss": 0.111,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -12.340447425842285,
      "rewards/margins": 5.49533748626709,
      "rewards/rejected": -17.835784912109375,
      "step": 12620
    },
    {
      "epoch": 3.759488019050454,
      "grad_norm": 8.1536865234375,
      "learning_rate": 2.0051667167317514e-05,
      "logits/chosen": -0.13457521796226501,
      "logits/rejected": -0.08628455549478531,
      "logps/chosen": -293.5015563964844,
      "logps/rejected": -350.25958251953125,
      "loss": 0.1801,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.890706062316895,
      "rewards/margins": 5.179696083068848,
      "rewards/rejected": -17.07040023803711,
      "step": 12630
    },
    {
      "epoch": 3.762464652478047,
      "grad_norm": 3.7371058464050293,
      "learning_rate": 2.000360468609192e-05,
      "logits/chosen": -0.176947221159935,
      "logits/rejected": -0.18188679218292236,
      "logps/chosen": -286.4673767089844,
      "logps/rejected": -355.1689453125,
      "loss": 0.1394,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.01391887664795,
      "rewards/margins": 5.472002983093262,
      "rewards/rejected": -16.48592185974121,
      "step": 12640
    },
    {
      "epoch": 3.7654412859056405,
      "grad_norm": 12.380799293518066,
      "learning_rate": 1.9955542204866327e-05,
      "logits/chosen": -0.26051202416419983,
      "logits/rejected": -0.163801908493042,
      "logps/chosen": -293.6034851074219,
      "logps/rejected": -348.1741943359375,
      "loss": 0.0914,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.3306303024292,
      "rewards/margins": 5.555377960205078,
      "rewards/rejected": -16.886009216308594,
      "step": 12650
    },
    {
      "epoch": 3.768417919333234,
      "grad_norm": 20.762006759643555,
      "learning_rate": 1.9907479723640736e-05,
      "logits/chosen": -0.33606916666030884,
      "logits/rejected": -0.34879904985427856,
      "logps/chosen": -270.7305603027344,
      "logps/rejected": -331.1860656738281,
      "loss": 0.1324,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.209847450256348,
      "rewards/margins": 5.249787330627441,
      "rewards/rejected": -15.459634780883789,
      "step": 12660
    },
    {
      "epoch": 3.7713945527608272,
      "grad_norm": 34.416786193847656,
      "learning_rate": 1.9859417242415142e-05,
      "logits/chosen": -0.3015105128288269,
      "logits/rejected": -0.3924800157546997,
      "logps/chosen": -271.13116455078125,
      "logps/rejected": -346.728271484375,
      "loss": 0.1502,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.917438507080078,
      "rewards/margins": 5.5578131675720215,
      "rewards/rejected": -15.475252151489258,
      "step": 12670
    },
    {
      "epoch": 3.774371186188421,
      "grad_norm": 4.874875068664551,
      "learning_rate": 1.981135476118955e-05,
      "logits/chosen": -0.42895832657814026,
      "logits/rejected": -0.41021212935447693,
      "logps/chosen": -268.03765869140625,
      "logps/rejected": -331.8888244628906,
      "loss": 0.1005,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.575139999389648,
      "rewards/margins": 5.197985649108887,
      "rewards/rejected": -14.773127555847168,
      "step": 12680
    },
    {
      "epoch": 3.7773478196160144,
      "grad_norm": 8.511955261230469,
      "learning_rate": 1.9763292279963955e-05,
      "logits/chosen": -0.27070000767707825,
      "logits/rejected": -0.3404995799064636,
      "logps/chosen": -275.955322265625,
      "logps/rejected": -347.3021240234375,
      "loss": 0.0687,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -10.686258316040039,
      "rewards/margins": 5.576637268066406,
      "rewards/rejected": -16.262897491455078,
      "step": 12690
    },
    {
      "epoch": 3.7803244530436078,
      "grad_norm": 19.865020751953125,
      "learning_rate": 1.971522979873836e-05,
      "logits/chosen": -0.3171350061893463,
      "logits/rejected": -0.1986093521118164,
      "logps/chosen": -304.057861328125,
      "logps/rejected": -346.7191162109375,
      "loss": 0.1673,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -12.412276268005371,
      "rewards/margins": 4.885976314544678,
      "rewards/rejected": -17.29825210571289,
      "step": 12700
    },
    {
      "epoch": 3.783301086471201,
      "grad_norm": 4.137208461761475,
      "learning_rate": 1.9667167317512767e-05,
      "logits/chosen": -0.24953386187553406,
      "logits/rejected": -0.13471832871437073,
      "logps/chosen": -287.71112060546875,
      "logps/rejected": -351.6275634765625,
      "loss": 0.0824,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -12.01076889038086,
      "rewards/margins": 6.200523376464844,
      "rewards/rejected": -18.211292266845703,
      "step": 12710
    },
    {
      "epoch": 3.7862777198987945,
      "grad_norm": 8.762202262878418,
      "learning_rate": 1.9619104836287176e-05,
      "logits/chosen": -0.16374550759792328,
      "logits/rejected": -0.23052096366882324,
      "logps/chosen": -299.7974548339844,
      "logps/rejected": -384.6773986816406,
      "loss": 0.1538,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -12.599942207336426,
      "rewards/margins": 6.018429756164551,
      "rewards/rejected": -18.618371963500977,
      "step": 12720
    },
    {
      "epoch": 3.789254353326388,
      "grad_norm": 8.785402297973633,
      "learning_rate": 1.9571042355061583e-05,
      "logits/chosen": -0.2582174837589264,
      "logits/rejected": -0.23024773597717285,
      "logps/chosen": -285.6094665527344,
      "logps/rejected": -345.8565979003906,
      "loss": 0.1259,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.024795532226562,
      "rewards/margins": 5.340673923492432,
      "rewards/rejected": -16.36547088623047,
      "step": 12730
    },
    {
      "epoch": 3.792230986753981,
      "grad_norm": 9.5352144241333,
      "learning_rate": 1.952297987383599e-05,
      "logits/chosen": -0.3482765257358551,
      "logits/rejected": -0.3697367310523987,
      "logps/chosen": -298.59637451171875,
      "logps/rejected": -357.44891357421875,
      "loss": 0.253,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -11.9912691116333,
      "rewards/margins": 4.493448734283447,
      "rewards/rejected": -16.484716415405273,
      "step": 12740
    },
    {
      "epoch": 3.7952076201815745,
      "grad_norm": 9.459319114685059,
      "learning_rate": 1.9474917392610395e-05,
      "logits/chosen": -0.3614364266395569,
      "logits/rejected": -0.48391789197921753,
      "logps/chosen": -282.19342041015625,
      "logps/rejected": -355.18499755859375,
      "loss": 0.1143,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.806476593017578,
      "rewards/margins": 5.540255546569824,
      "rewards/rejected": -17.346731185913086,
      "step": 12750
    },
    {
      "epoch": 3.798184253609168,
      "grad_norm": 2.749607801437378,
      "learning_rate": 1.94268549113848e-05,
      "logits/chosen": -0.18819639086723328,
      "logits/rejected": -0.3249451816082001,
      "logps/chosen": -274.3514099121094,
      "logps/rejected": -368.4951171875,
      "loss": 0.0948,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.750777244567871,
      "rewards/margins": 6.615830898284912,
      "rewards/rejected": -18.366607666015625,
      "step": 12760
    },
    {
      "epoch": 3.8011608870367617,
      "grad_norm": 7.684932231903076,
      "learning_rate": 1.9378792430159207e-05,
      "logits/chosen": -0.28262972831726074,
      "logits/rejected": -0.394130140542984,
      "logps/chosen": -302.28887939453125,
      "logps/rejected": -371.6407165527344,
      "loss": 0.142,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.866777420043945,
      "rewards/margins": 5.8934736251831055,
      "rewards/rejected": -18.760250091552734,
      "step": 12770
    },
    {
      "epoch": 3.804137520464355,
      "grad_norm": 8.064760208129883,
      "learning_rate": 1.9330729948933617e-05,
      "logits/chosen": -0.3515121340751648,
      "logits/rejected": -0.280831515789032,
      "logps/chosen": -275.47418212890625,
      "logps/rejected": -322.57794189453125,
      "loss": 0.134,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.182016372680664,
      "rewards/margins": 4.812992572784424,
      "rewards/rejected": -15.99500846862793,
      "step": 12780
    },
    {
      "epoch": 3.8071141538919484,
      "grad_norm": 13.680832862854004,
      "learning_rate": 1.9282667467708023e-05,
      "logits/chosen": -0.38960856199264526,
      "logits/rejected": -0.2907930910587311,
      "logps/chosen": -281.5882873535156,
      "logps/rejected": -354.14605712890625,
      "loss": 0.096,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.920869827270508,
      "rewards/margins": 6.066141605377197,
      "rewards/rejected": -16.987010955810547,
      "step": 12790
    },
    {
      "epoch": 3.8100907873195418,
      "grad_norm": 8.761336326599121,
      "learning_rate": 1.923460498648243e-05,
      "logits/chosen": -0.31682130694389343,
      "logits/rejected": -0.1510801613330841,
      "logps/chosen": -318.91461181640625,
      "logps/rejected": -367.6263122558594,
      "loss": 0.1148,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -12.244327545166016,
      "rewards/margins": 5.2884087562561035,
      "rewards/rejected": -17.53273582458496,
      "step": 12800
    },
    {
      "epoch": 3.813067420747135,
      "grad_norm": 2.6910085678100586,
      "learning_rate": 1.9186542505256835e-05,
      "logits/chosen": -0.44498521089553833,
      "logits/rejected": -0.42283859848976135,
      "logps/chosen": -258.7718200683594,
      "logps/rejected": -316.83367919921875,
      "loss": 0.1644,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -9.553007125854492,
      "rewards/margins": 4.8835978507995605,
      "rewards/rejected": -14.436602592468262,
      "step": 12810
    },
    {
      "epoch": 3.8160440541747285,
      "grad_norm": 2.5527355670928955,
      "learning_rate": 1.913848002403124e-05,
      "logits/chosen": -0.2558421194553375,
      "logits/rejected": -0.43252652883529663,
      "logps/chosen": -267.29180908203125,
      "logps/rejected": -349.4607238769531,
      "loss": 0.0926,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.918769836425781,
      "rewards/margins": 5.406668186187744,
      "rewards/rejected": -16.325437545776367,
      "step": 12820
    },
    {
      "epoch": 3.819020687602322,
      "grad_norm": 10.098738670349121,
      "learning_rate": 1.9090417542805647e-05,
      "logits/chosen": -0.40039190649986267,
      "logits/rejected": -0.3109726011753082,
      "logps/chosen": -275.7222900390625,
      "logps/rejected": -334.13922119140625,
      "loss": 0.0546,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.463330268859863,
      "rewards/margins": 5.911205291748047,
      "rewards/rejected": -16.374534606933594,
      "step": 12830
    },
    {
      "epoch": 3.821997321029915,
      "grad_norm": 12.427311897277832,
      "learning_rate": 1.9042355061580057e-05,
      "logits/chosen": -0.2946407198905945,
      "logits/rejected": -0.29658108949661255,
      "logps/chosen": -261.56378173828125,
      "logps/rejected": -317.27374267578125,
      "loss": 0.2264,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -9.975417137145996,
      "rewards/margins": 5.105672836303711,
      "rewards/rejected": -15.081089973449707,
      "step": 12840
    },
    {
      "epoch": 3.8249739544575085,
      "grad_norm": 16.231916427612305,
      "learning_rate": 1.8994292580354463e-05,
      "logits/chosen": -0.27895429730415344,
      "logits/rejected": -0.33811911940574646,
      "logps/chosen": -283.358154296875,
      "logps/rejected": -345.66455078125,
      "loss": 0.1905,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -11.987466812133789,
      "rewards/margins": 4.628663063049316,
      "rewards/rejected": -16.616130828857422,
      "step": 12850
    },
    {
      "epoch": 3.827950587885102,
      "grad_norm": 2.059262752532959,
      "learning_rate": 1.894623009912887e-05,
      "logits/chosen": -0.34076443314552307,
      "logits/rejected": -0.32823920249938965,
      "logps/chosen": -280.47381591796875,
      "logps/rejected": -350.72198486328125,
      "loss": 0.0874,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.182255744934082,
      "rewards/margins": 5.565553665161133,
      "rewards/rejected": -16.747806549072266,
      "step": 12860
    },
    {
      "epoch": 3.8309272213126953,
      "grad_norm": 10.313234329223633,
      "learning_rate": 1.8898167617903275e-05,
      "logits/chosen": -0.2972901463508606,
      "logits/rejected": -0.3458173871040344,
      "logps/chosen": -310.229248046875,
      "logps/rejected": -385.8416442871094,
      "loss": 0.1013,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -13.20671272277832,
      "rewards/margins": 6.573189735412598,
      "rewards/rejected": -19.77989959716797,
      "step": 12870
    },
    {
      "epoch": 3.8339038547402886,
      "grad_norm": 13.078292846679688,
      "learning_rate": 1.8850105136677685e-05,
      "logits/chosen": -0.07974731922149658,
      "logits/rejected": -0.18238602578639984,
      "logps/chosen": -311.71807861328125,
      "logps/rejected": -397.24212646484375,
      "loss": 0.1343,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -14.05854606628418,
      "rewards/margins": 6.325940132141113,
      "rewards/rejected": -20.38448715209961,
      "step": 12880
    },
    {
      "epoch": 3.836880488167882,
      "grad_norm": 4.006040573120117,
      "learning_rate": 1.8802042655452088e-05,
      "logits/chosen": -0.295468807220459,
      "logits/rejected": -0.12792745232582092,
      "logps/chosen": -284.9950866699219,
      "logps/rejected": -338.5768737792969,
      "loss": 0.1448,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.330123901367188,
      "rewards/margins": 5.780869483947754,
      "rewards/rejected": -17.110992431640625,
      "step": 12890
    },
    {
      "epoch": 3.8398571215954753,
      "grad_norm": 3.3543217182159424,
      "learning_rate": 1.8753980174226497e-05,
      "logits/chosen": -0.22954018414020538,
      "logits/rejected": -0.26622113585472107,
      "logps/chosen": -295.0567932128906,
      "logps/rejected": -368.7243347167969,
      "loss": 0.141,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -12.197257995605469,
      "rewards/margins": 6.07420015335083,
      "rewards/rejected": -18.27145767211914,
      "step": 12900
    },
    {
      "epoch": 3.8428337550230687,
      "grad_norm": 5.740220546722412,
      "learning_rate": 1.8705917693000903e-05,
      "logits/chosen": -0.1971018761396408,
      "logits/rejected": -0.2371772974729538,
      "logps/chosen": -303.1443176269531,
      "logps/rejected": -372.45831298828125,
      "loss": 0.1927,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -11.809168815612793,
      "rewards/margins": 6.107270240783691,
      "rewards/rejected": -17.916439056396484,
      "step": 12910
    },
    {
      "epoch": 3.845810388450662,
      "grad_norm": 2.9348347187042236,
      "learning_rate": 1.865785521177531e-05,
      "logits/chosen": -0.1637088507413864,
      "logits/rejected": -0.33974704146385193,
      "logps/chosen": -267.8590087890625,
      "logps/rejected": -345.577880859375,
      "loss": 0.1225,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.586991310119629,
      "rewards/margins": 4.901086330413818,
      "rewards/rejected": -15.488078117370605,
      "step": 12920
    },
    {
      "epoch": 3.848787021878256,
      "grad_norm": 6.3364973068237305,
      "learning_rate": 1.8609792730549716e-05,
      "logits/chosen": -0.22114598751068115,
      "logits/rejected": -0.3252255320549011,
      "logps/chosen": -273.5756530761719,
      "logps/rejected": -347.34033203125,
      "loss": 0.1314,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.667049407958984,
      "rewards/margins": 5.173357963562012,
      "rewards/rejected": -15.840408325195312,
      "step": 12930
    },
    {
      "epoch": 3.851763655305849,
      "grad_norm": 5.307745933532715,
      "learning_rate": 1.8561730249324125e-05,
      "logits/chosen": -0.2818676233291626,
      "logits/rejected": -0.30387839674949646,
      "logps/chosen": -281.14239501953125,
      "logps/rejected": -341.4402160644531,
      "loss": 0.1544,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.536125183105469,
      "rewards/margins": 4.926515102386475,
      "rewards/rejected": -16.46263885498047,
      "step": 12940
    },
    {
      "epoch": 3.8547402887334425,
      "grad_norm": 3.844270944595337,
      "learning_rate": 1.8513667768098528e-05,
      "logits/chosen": -0.2853194773197174,
      "logits/rejected": -0.2944040894508362,
      "logps/chosen": -282.678466796875,
      "logps/rejected": -347.51666259765625,
      "loss": 0.0781,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.313405990600586,
      "rewards/margins": 5.0797600746154785,
      "rewards/rejected": -16.393165588378906,
      "step": 12950
    },
    {
      "epoch": 3.857716922161036,
      "grad_norm": 6.561033725738525,
      "learning_rate": 1.8465605286872938e-05,
      "logits/chosen": -0.2155660092830658,
      "logits/rejected": -0.22102120518684387,
      "logps/chosen": -290.9830627441406,
      "logps/rejected": -354.2218017578125,
      "loss": 0.0966,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -12.128979682922363,
      "rewards/margins": 5.464536190032959,
      "rewards/rejected": -17.593515396118164,
      "step": 12960
    },
    {
      "epoch": 3.8606935555886293,
      "grad_norm": 13.106939315795898,
      "learning_rate": 1.8417542805647344e-05,
      "logits/chosen": -0.1196938306093216,
      "logits/rejected": -0.2024669647216797,
      "logps/chosen": -277.89251708984375,
      "logps/rejected": -345.17059326171875,
      "loss": 0.1256,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.722268104553223,
      "rewards/margins": 5.308882236480713,
      "rewards/rejected": -17.03114891052246,
      "step": 12970
    },
    {
      "epoch": 3.8636701890162226,
      "grad_norm": 14.844727516174316,
      "learning_rate": 1.836948032442175e-05,
      "logits/chosen": -0.18087340891361237,
      "logits/rejected": -0.07137824594974518,
      "logps/chosen": -271.10174560546875,
      "logps/rejected": -321.75042724609375,
      "loss": 0.136,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -11.626386642456055,
      "rewards/margins": 5.475070953369141,
      "rewards/rejected": -17.101455688476562,
      "step": 12980
    },
    {
      "epoch": 3.866646822443816,
      "grad_norm": 5.14820671081543,
      "learning_rate": 1.8321417843196156e-05,
      "logits/chosen": -0.23444664478302002,
      "logits/rejected": -0.2036781758069992,
      "logps/chosen": -311.059326171875,
      "logps/rejected": -374.9887390136719,
      "loss": 0.1539,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -12.377148628234863,
      "rewards/margins": 6.0550432205200195,
      "rewards/rejected": -18.432193756103516,
      "step": 12990
    },
    {
      "epoch": 3.8696234558714093,
      "grad_norm": 2.916609764099121,
      "learning_rate": 1.8273355361970565e-05,
      "logits/chosen": -0.19091354310512543,
      "logits/rejected": -0.22677700221538544,
      "logps/chosen": -282.8034973144531,
      "logps/rejected": -344.6039123535156,
      "loss": 0.1537,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -12.14545726776123,
      "rewards/margins": 5.761136531829834,
      "rewards/rejected": -17.906593322753906,
      "step": 13000
    },
    {
      "epoch": 3.8726000892990027,
      "grad_norm": 5.923845291137695,
      "learning_rate": 1.8225292880744968e-05,
      "logits/chosen": -0.06128184124827385,
      "logits/rejected": 0.020350193604826927,
      "logps/chosen": -291.46490478515625,
      "logps/rejected": -347.1809997558594,
      "loss": 0.1662,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -12.361692428588867,
      "rewards/margins": 5.361968040466309,
      "rewards/rejected": -17.72365951538086,
      "step": 13010
    },
    {
      "epoch": 3.8755767227265965,
      "grad_norm": 10.039198875427246,
      "learning_rate": 1.8177230399519378e-05,
      "logits/chosen": -0.32571926712989807,
      "logits/rejected": -0.29829809069633484,
      "logps/chosen": -278.5748291015625,
      "logps/rejected": -326.05419921875,
      "loss": 0.1406,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.032248497009277,
      "rewards/margins": 4.675398349761963,
      "rewards/rejected": -15.707647323608398,
      "step": 13020
    },
    {
      "epoch": 3.87855335615419,
      "grad_norm": 10.693360328674316,
      "learning_rate": 1.8129167918293784e-05,
      "logits/chosen": -0.009086942300200462,
      "logits/rejected": -0.19220177829265594,
      "logps/chosen": -287.40045166015625,
      "logps/rejected": -363.7809753417969,
      "loss": 0.1249,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -12.648309707641602,
      "rewards/margins": 5.639643669128418,
      "rewards/rejected": -18.28795623779297,
      "step": 13030
    },
    {
      "epoch": 3.881529989581783,
      "grad_norm": 4.409448146820068,
      "learning_rate": 1.808110543706819e-05,
      "logits/chosen": -0.11086070537567139,
      "logits/rejected": -0.1737534999847412,
      "logps/chosen": -308.6759338378906,
      "logps/rejected": -385.42498779296875,
      "loss": 0.1028,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -12.754545211791992,
      "rewards/margins": 5.835122108459473,
      "rewards/rejected": -18.58966827392578,
      "step": 13040
    },
    {
      "epoch": 3.8845066230093765,
      "grad_norm": 4.360292434692383,
      "learning_rate": 1.8033042955842596e-05,
      "logits/chosen": -0.18130189180374146,
      "logits/rejected": -0.23539213836193085,
      "logps/chosen": -294.4930725097656,
      "logps/rejected": -368.97735595703125,
      "loss": 0.1226,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.742058753967285,
      "rewards/margins": 5.62283992767334,
      "rewards/rejected": -18.364898681640625,
      "step": 13050
    },
    {
      "epoch": 3.88748325643697,
      "grad_norm": 3.848970651626587,
      "learning_rate": 1.7984980474617006e-05,
      "logits/chosen": -0.2846245765686035,
      "logits/rejected": -0.25909367203712463,
      "logps/chosen": -289.1370544433594,
      "logps/rejected": -352.5686950683594,
      "loss": 0.0603,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.610422134399414,
      "rewards/margins": 5.861883163452148,
      "rewards/rejected": -17.47230339050293,
      "step": 13060
    },
    {
      "epoch": 3.8904598898645633,
      "grad_norm": 6.990538597106934,
      "learning_rate": 1.793691799339141e-05,
      "logits/chosen": -0.24112172424793243,
      "logits/rejected": -0.02217312715947628,
      "logps/chosen": -288.40386962890625,
      "logps/rejected": -317.4620056152344,
      "loss": 0.1435,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.019768714904785,
      "rewards/margins": 4.862431049346924,
      "rewards/rejected": -15.882200241088867,
      "step": 13070
    },
    {
      "epoch": 3.8934365232921566,
      "grad_norm": 12.3737211227417,
      "learning_rate": 1.7888855512165818e-05,
      "logits/chosen": -0.22111757099628448,
      "logits/rejected": -0.32877594232559204,
      "logps/chosen": -268.52264404296875,
      "logps/rejected": -332.7304992675781,
      "loss": 0.1515,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -11.2926664352417,
      "rewards/margins": 5.179656028747559,
      "rewards/rejected": -16.472320556640625,
      "step": 13080
    },
    {
      "epoch": 3.89641315671975,
      "grad_norm": 4.600978851318359,
      "learning_rate": 1.7840793030940224e-05,
      "logits/chosen": -0.30689364671707153,
      "logits/rejected": -0.3285229802131653,
      "logps/chosen": -286.74481201171875,
      "logps/rejected": -358.5604553222656,
      "loss": 0.0881,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.008430480957031,
      "rewards/margins": 6.057735919952393,
      "rewards/rejected": -17.066165924072266,
      "step": 13090
    },
    {
      "epoch": 3.8993897901473433,
      "grad_norm": 2.699897289276123,
      "learning_rate": 1.779273054971463e-05,
      "logits/chosen": -0.2947268486022949,
      "logits/rejected": -0.211075097322464,
      "logps/chosen": -293.7330017089844,
      "logps/rejected": -345.7731018066406,
      "loss": 0.1134,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.071290969848633,
      "rewards/margins": 5.594553470611572,
      "rewards/rejected": -16.665843963623047,
      "step": 13100
    },
    {
      "epoch": 3.9023664235749367,
      "grad_norm": 3.5059847831726074,
      "learning_rate": 1.7744668068489036e-05,
      "logits/chosen": -0.43167534470558167,
      "logits/rejected": -0.25991159677505493,
      "logps/chosen": -274.2132568359375,
      "logps/rejected": -322.4024963378906,
      "loss": 0.2301,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -9.262533187866211,
      "rewards/margins": 5.175965309143066,
      "rewards/rejected": -14.438499450683594,
      "step": 13110
    },
    {
      "epoch": 3.90534305700253,
      "grad_norm": 5.876224040985107,
      "learning_rate": 1.7696605587263446e-05,
      "logits/chosen": -0.3947067856788635,
      "logits/rejected": -0.3243297040462494,
      "logps/chosen": -277.1755676269531,
      "logps/rejected": -322.7135009765625,
      "loss": 0.1518,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.284720420837402,
      "rewards/margins": 4.37031888961792,
      "rewards/rejected": -14.655038833618164,
      "step": 13120
    },
    {
      "epoch": 3.9083196904301234,
      "grad_norm": 16.343027114868164,
      "learning_rate": 1.764854310603785e-05,
      "logits/chosen": -0.1953987330198288,
      "logits/rejected": -0.2394733726978302,
      "logps/chosen": -281.46856689453125,
      "logps/rejected": -325.3466491699219,
      "loss": 0.1953,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -11.037036895751953,
      "rewards/margins": 4.486117362976074,
      "rewards/rejected": -15.523152351379395,
      "step": 13130
    },
    {
      "epoch": 3.9112963238577168,
      "grad_norm": 9.723916053771973,
      "learning_rate": 1.760048062481226e-05,
      "logits/chosen": -0.2942632734775543,
      "logits/rejected": -0.15816061198711395,
      "logps/chosen": -289.4561767578125,
      "logps/rejected": -348.8240966796875,
      "loss": 0.1299,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.758559226989746,
      "rewards/margins": 5.434501647949219,
      "rewards/rejected": -16.19305992126465,
      "step": 13140
    },
    {
      "epoch": 3.91427295728531,
      "grad_norm": 0.9592617154121399,
      "learning_rate": 1.7552418143586664e-05,
      "logits/chosen": -0.25680363178253174,
      "logits/rejected": -0.18953414261341095,
      "logps/chosen": -273.3829650878906,
      "logps/rejected": -331.12677001953125,
      "loss": 0.1693,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.997849464416504,
      "rewards/margins": 5.475033283233643,
      "rewards/rejected": -16.472881317138672,
      "step": 13150
    },
    {
      "epoch": 3.9172495907129035,
      "grad_norm": 7.455223560333252,
      "learning_rate": 1.750435566236107e-05,
      "logits/chosen": -0.2323170006275177,
      "logits/rejected": -0.17570650577545166,
      "logps/chosen": -288.8304138183594,
      "logps/rejected": -342.3534240722656,
      "loss": 0.1988,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -12.195964813232422,
      "rewards/margins": 5.0916852951049805,
      "rewards/rejected": -17.28765106201172,
      "step": 13160
    },
    {
      "epoch": 3.9202262241404973,
      "grad_norm": 7.36057186126709,
      "learning_rate": 1.7456293181135477e-05,
      "logits/chosen": -0.20374512672424316,
      "logits/rejected": -0.16213993728160858,
      "logps/chosen": -295.4999084472656,
      "logps/rejected": -349.3294677734375,
      "loss": 0.0925,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.076574325561523,
      "rewards/margins": 5.38803768157959,
      "rewards/rejected": -17.464611053466797,
      "step": 13170
    },
    {
      "epoch": 3.9232028575680906,
      "grad_norm": 3.0775468349456787,
      "learning_rate": 1.7408230699909886e-05,
      "logits/chosen": -0.30527108907699585,
      "logits/rejected": -0.24171264469623566,
      "logps/chosen": -278.99444580078125,
      "logps/rejected": -332.1943664550781,
      "loss": 0.1479,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.64020824432373,
      "rewards/margins": 5.1144232749938965,
      "rewards/rejected": -15.754631042480469,
      "step": 13180
    },
    {
      "epoch": 3.926179490995684,
      "grad_norm": 6.6761474609375,
      "learning_rate": 1.736016821868429e-05,
      "logits/chosen": -0.42481327056884766,
      "logits/rejected": -0.2680414021015167,
      "logps/chosen": -296.15142822265625,
      "logps/rejected": -333.8583984375,
      "loss": 0.1254,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.402942657470703,
      "rewards/margins": 5.057470798492432,
      "rewards/rejected": -15.460415840148926,
      "step": 13190
    },
    {
      "epoch": 3.9291561244232773,
      "grad_norm": 19.7720890045166,
      "learning_rate": 1.73121057374587e-05,
      "logits/chosen": -0.3215220272541046,
      "logits/rejected": -0.19740232825279236,
      "logps/chosen": -261.03729248046875,
      "logps/rejected": -311.6561584472656,
      "loss": 0.0831,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -9.735949516296387,
      "rewards/margins": 5.315793037414551,
      "rewards/rejected": -15.051742553710938,
      "step": 13200
    },
    {
      "epoch": 3.9321327578508707,
      "grad_norm": 5.568587779998779,
      "learning_rate": 1.7264043256233105e-05,
      "logits/chosen": -0.3690839111804962,
      "logits/rejected": -0.3513348698616028,
      "logps/chosen": -265.4442443847656,
      "logps/rejected": -328.642822265625,
      "loss": 0.1429,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -9.44122314453125,
      "rewards/margins": 5.4200239181518555,
      "rewards/rejected": -14.861247062683105,
      "step": 13210
    },
    {
      "epoch": 3.935109391278464,
      "grad_norm": 0.6456167697906494,
      "learning_rate": 1.721598077500751e-05,
      "logits/chosen": -0.2426155060529709,
      "logits/rejected": -0.4615197777748108,
      "logps/chosen": -264.99420166015625,
      "logps/rejected": -343.3972473144531,
      "loss": 0.128,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -11.182795524597168,
      "rewards/margins": 5.068475723266602,
      "rewards/rejected": -16.251270294189453,
      "step": 13220
    },
    {
      "epoch": 3.9380860247060574,
      "grad_norm": 9.650761604309082,
      "learning_rate": 1.7167918293781917e-05,
      "logits/chosen": -0.08491826057434082,
      "logits/rejected": -0.16669416427612305,
      "logps/chosen": -284.13214111328125,
      "logps/rejected": -343.6591796875,
      "loss": 0.1377,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.60516357421875,
      "rewards/margins": 5.230534076690674,
      "rewards/rejected": -16.835697174072266,
      "step": 13230
    },
    {
      "epoch": 3.9410626581336508,
      "grad_norm": 14.697391510009766,
      "learning_rate": 1.7119855812556327e-05,
      "logits/chosen": -0.2542917728424072,
      "logits/rejected": -0.28890353441238403,
      "logps/chosen": -275.5459899902344,
      "logps/rejected": -340.3116149902344,
      "loss": 0.2437,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.465398788452148,
      "rewards/margins": 5.2941694259643555,
      "rewards/rejected": -15.75956916809082,
      "step": 13240
    },
    {
      "epoch": 3.944039291561244,
      "grad_norm": 5.2861247062683105,
      "learning_rate": 1.707179333133073e-05,
      "logits/chosen": -0.27080997824668884,
      "logits/rejected": -0.23509952425956726,
      "logps/chosen": -279.689697265625,
      "logps/rejected": -344.15289306640625,
      "loss": 0.148,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.36038589477539,
      "rewards/margins": 5.284527778625488,
      "rewards/rejected": -15.644915580749512,
      "step": 13250
    },
    {
      "epoch": 3.9470159249888375,
      "grad_norm": 12.360882759094238,
      "learning_rate": 1.702373085010514e-05,
      "logits/chosen": -0.32263892889022827,
      "logits/rejected": -0.35334134101867676,
      "logps/chosen": -300.49151611328125,
      "logps/rejected": -348.6321716308594,
      "loss": 0.1625,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.24267292022705,
      "rewards/margins": 4.8506574630737305,
      "rewards/rejected": -16.093332290649414,
      "step": 13260
    },
    {
      "epoch": 3.9499925584164313,
      "grad_norm": 2.013169050216675,
      "learning_rate": 1.6975668368879545e-05,
      "logits/chosen": -0.20797176659107208,
      "logits/rejected": -0.3367982506752014,
      "logps/chosen": -280.95001220703125,
      "logps/rejected": -360.05487060546875,
      "loss": 0.0646,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.185694694519043,
      "rewards/margins": 5.862557888031006,
      "rewards/rejected": -17.04825210571289,
      "step": 13270
    },
    {
      "epoch": 3.9529691918440246,
      "grad_norm": 6.5786871910095215,
      "learning_rate": 1.692760588765395e-05,
      "logits/chosen": -0.26313483715057373,
      "logits/rejected": -0.22510822117328644,
      "logps/chosen": -290.55120849609375,
      "logps/rejected": -338.3763732910156,
      "loss": 0.1506,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -11.476238250732422,
      "rewards/margins": 5.1706156730651855,
      "rewards/rejected": -16.646854400634766,
      "step": 13280
    },
    {
      "epoch": 3.955945825271618,
      "grad_norm": 4.011466979980469,
      "learning_rate": 1.6879543406428357e-05,
      "logits/chosen": -0.2282927930355072,
      "logits/rejected": -0.3801965117454529,
      "logps/chosen": -266.16400146484375,
      "logps/rejected": -348.1343078613281,
      "loss": 0.1106,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.460606575012207,
      "rewards/margins": 5.955479621887207,
      "rewards/rejected": -16.416086196899414,
      "step": 13290
    },
    {
      "epoch": 3.9589224586992113,
      "grad_norm": 14.563257217407227,
      "learning_rate": 1.6831480925202767e-05,
      "logits/chosen": -0.3142940104007721,
      "logits/rejected": -0.3303237557411194,
      "logps/chosen": -279.12261962890625,
      "logps/rejected": -340.5314025878906,
      "loss": 0.1075,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.538808822631836,
      "rewards/margins": 5.420257568359375,
      "rewards/rejected": -15.959066390991211,
      "step": 13300
    },
    {
      "epoch": 3.9618990921268047,
      "grad_norm": 0.5360752940177917,
      "learning_rate": 1.678341844397717e-05,
      "logits/chosen": -0.3071672320365906,
      "logits/rejected": -0.4452418386936188,
      "logps/chosen": -282.81890869140625,
      "logps/rejected": -351.9652099609375,
      "loss": 0.2059,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.988360404968262,
      "rewards/margins": 4.860118389129639,
      "rewards/rejected": -15.848480224609375,
      "step": 13310
    },
    {
      "epoch": 3.964875725554398,
      "grad_norm": 7.864865303039551,
      "learning_rate": 1.6740162210874136e-05,
      "logits/chosen": -0.35061585903167725,
      "logits/rejected": -0.31573858857154846,
      "logps/chosen": -286.94891357421875,
      "logps/rejected": -332.98480224609375,
      "loss": 0.1866,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -11.607317924499512,
      "rewards/margins": 4.83513069152832,
      "rewards/rejected": -16.44244956970215,
      "step": 13320
    },
    {
      "epoch": 3.9678523589819914,
      "grad_norm": 7.255005836486816,
      "learning_rate": 1.6692099729648546e-05,
      "logits/chosen": -0.29582518339157104,
      "logits/rejected": -0.4588819146156311,
      "logps/chosen": -286.14788818359375,
      "logps/rejected": -372.514892578125,
      "loss": 0.0718,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.042436599731445,
      "rewards/margins": 5.836656093597412,
      "rewards/rejected": -16.87908935546875,
      "step": 13330
    },
    {
      "epoch": 3.9708289924095848,
      "grad_norm": 2.1602606773376465,
      "learning_rate": 1.6644037248422952e-05,
      "logits/chosen": -0.3830709755420685,
      "logits/rejected": -0.4923439919948578,
      "logps/chosen": -271.1380310058594,
      "logps/rejected": -344.51458740234375,
      "loss": 0.2017,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -10.580395698547363,
      "rewards/margins": 5.610462188720703,
      "rewards/rejected": -16.190858840942383,
      "step": 13340
    },
    {
      "epoch": 3.973805625837178,
      "grad_norm": 10.230942726135254,
      "learning_rate": 1.659597476719736e-05,
      "logits/chosen": -0.3955148756504059,
      "logits/rejected": -0.5777240991592407,
      "logps/chosen": -277.397705078125,
      "logps/rejected": -362.584716796875,
      "loss": 0.1108,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.310758590698242,
      "rewards/margins": 6.106735706329346,
      "rewards/rejected": -17.41749382019043,
      "step": 13350
    },
    {
      "epoch": 3.9767822592647715,
      "grad_norm": 7.260427951812744,
      "learning_rate": 1.6547912285971764e-05,
      "logits/chosen": -0.22681203484535217,
      "logits/rejected": -0.275253027677536,
      "logps/chosen": -280.5765686035156,
      "logps/rejected": -349.61126708984375,
      "loss": 0.1585,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -10.503427505493164,
      "rewards/margins": 6.0031585693359375,
      "rewards/rejected": -16.5065860748291,
      "step": 13360
    },
    {
      "epoch": 3.979758892692365,
      "grad_norm": 9.582204818725586,
      "learning_rate": 1.649984980474617e-05,
      "logits/chosen": -0.2019670307636261,
      "logits/rejected": -0.3903563320636749,
      "logps/chosen": -282.36383056640625,
      "logps/rejected": -371.6644592285156,
      "loss": 0.0938,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.630030632019043,
      "rewards/margins": 5.717068195343018,
      "rewards/rejected": -17.34709930419922,
      "step": 13370
    },
    {
      "epoch": 3.982735526119958,
      "grad_norm": 6.099182605743408,
      "learning_rate": 1.6451787323520577e-05,
      "logits/chosen": -0.2930513620376587,
      "logits/rejected": -0.13060082495212555,
      "logps/chosen": -259.0501403808594,
      "logps/rejected": -304.1745910644531,
      "loss": 0.0896,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.058979034423828,
      "rewards/margins": 5.437037467956543,
      "rewards/rejected": -14.496015548706055,
      "step": 13380
    },
    {
      "epoch": 3.9857121595475515,
      "grad_norm": 5.597383975982666,
      "learning_rate": 1.6403724842294986e-05,
      "logits/chosen": -0.33007049560546875,
      "logits/rejected": -0.3669622540473938,
      "logps/chosen": -256.1831359863281,
      "logps/rejected": -326.858154296875,
      "loss": 0.1681,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.914896011352539,
      "rewards/margins": 5.560693740844727,
      "rewards/rejected": -14.47558879852295,
      "step": 13390
    },
    {
      "epoch": 3.988688792975145,
      "grad_norm": 6.72525691986084,
      "learning_rate": 1.6355662361069392e-05,
      "logits/chosen": -0.2726123034954071,
      "logits/rejected": -0.4486878514289856,
      "logps/chosen": -292.63299560546875,
      "logps/rejected": -357.5541687011719,
      "loss": 0.1165,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.562970161437988,
      "rewards/margins": 4.895758152008057,
      "rewards/rejected": -16.458728790283203,
      "step": 13400
    },
    {
      "epoch": 3.9916654264027382,
      "grad_norm": 2.273859977722168,
      "learning_rate": 1.63075998798438e-05,
      "logits/chosen": -0.2266072928905487,
      "logits/rejected": -0.26691025495529175,
      "logps/chosen": -280.28582763671875,
      "logps/rejected": -343.913818359375,
      "loss": 0.1547,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -10.574779510498047,
      "rewards/margins": 5.16178035736084,
      "rewards/rejected": -15.736559867858887,
      "step": 13410
    },
    {
      "epoch": 3.994642059830332,
      "grad_norm": 2.2096445560455322,
      "learning_rate": 1.6259537398618205e-05,
      "logits/chosen": -0.19099362194538116,
      "logits/rejected": -0.2316860407590866,
      "logps/chosen": -268.4615478515625,
      "logps/rejected": -340.23748779296875,
      "loss": 0.0772,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.795219421386719,
      "rewards/margins": 5.905118465423584,
      "rewards/rejected": -15.700335502624512,
      "step": 13420
    },
    {
      "epoch": 3.9976186932579254,
      "grad_norm": 7.998254299163818,
      "learning_rate": 1.621147491739261e-05,
      "logits/chosen": -0.2731870412826538,
      "logits/rejected": -0.30580297112464905,
      "logps/chosen": -274.992919921875,
      "logps/rejected": -331.4501037597656,
      "loss": 0.1429,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.735215187072754,
      "rewards/margins": 4.710017204284668,
      "rewards/rejected": -15.445231437683105,
      "step": 13430
    },
    {
      "epoch": 4.000595326685518,
      "grad_norm": 0.6590014696121216,
      "learning_rate": 1.6163412436167017e-05,
      "logits/chosen": -0.3531246781349182,
      "logits/rejected": -0.3206407427787781,
      "logps/chosen": -297.43359375,
      "logps/rejected": -341.56622314453125,
      "loss": 0.1692,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -10.822439193725586,
      "rewards/margins": 4.914914131164551,
      "rewards/rejected": -15.737353324890137,
      "step": 13440
    },
    {
      "epoch": 4.003571960113112,
      "grad_norm": 5.175838470458984,
      "learning_rate": 1.6115349954941427e-05,
      "logits/chosen": -0.21003541350364685,
      "logits/rejected": -0.2620159387588501,
      "logps/chosen": -292.85406494140625,
      "logps/rejected": -363.46331787109375,
      "loss": 0.0877,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -11.34324836730957,
      "rewards/margins": 6.0523223876953125,
      "rewards/rejected": -17.395570755004883,
      "step": 13450
    },
    {
      "epoch": 4.006548593540705,
      "grad_norm": 4.550721645355225,
      "learning_rate": 1.6067287473715833e-05,
      "logits/chosen": -0.22119978070259094,
      "logits/rejected": -0.24340805411338806,
      "logps/chosen": -268.97210693359375,
      "logps/rejected": -328.70965576171875,
      "loss": 0.0683,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.68994426727295,
      "rewards/margins": 5.305096626281738,
      "rewards/rejected": -15.995040893554688,
      "step": 13460
    },
    {
      "epoch": 4.009525226968299,
      "grad_norm": 1.7385950088500977,
      "learning_rate": 1.601922499249024e-05,
      "logits/chosen": -0.2531232237815857,
      "logits/rejected": -0.24822518229484558,
      "logps/chosen": -300.53997802734375,
      "logps/rejected": -370.467529296875,
      "loss": 0.0404,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -11.905643463134766,
      "rewards/margins": 6.649308204650879,
      "rewards/rejected": -18.554950714111328,
      "step": 13470
    },
    {
      "epoch": 4.012501860395893,
      "grad_norm": 4.729836463928223,
      "learning_rate": 1.5971162511264645e-05,
      "logits/chosen": -0.17916986346244812,
      "logits/rejected": -0.23865287005901337,
      "logps/chosen": -294.2605285644531,
      "logps/rejected": -378.2278137207031,
      "loss": 0.051,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.913294792175293,
      "rewards/margins": 6.560264587402344,
      "rewards/rejected": -19.473560333251953,
      "step": 13480
    },
    {
      "epoch": 4.015478493823486,
      "grad_norm": 2.358285665512085,
      "learning_rate": 1.592310003003905e-05,
      "logits/chosen": -0.21196746826171875,
      "logits/rejected": -0.22635796666145325,
      "logps/chosen": -281.3841552734375,
      "logps/rejected": -355.24871826171875,
      "loss": 0.0297,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -10.618980407714844,
      "rewards/margins": 6.35535192489624,
      "rewards/rejected": -16.974334716796875,
      "step": 13490
    },
    {
      "epoch": 4.018455127251079,
      "grad_norm": 3.620553731918335,
      "learning_rate": 1.5875037548813457e-05,
      "logits/chosen": -0.11041686683893204,
      "logits/rejected": -0.1476757526397705,
      "logps/chosen": -309.37158203125,
      "logps/rejected": -370.43536376953125,
      "loss": 0.0462,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.31908130645752,
      "rewards/margins": 5.771014213562012,
      "rewards/rejected": -19.09009552001953,
      "step": 13500
    },
    {
      "epoch": 4.021431760678673,
      "grad_norm": 1.3585044145584106,
      "learning_rate": 1.5826975067587867e-05,
      "logits/chosen": -0.1803242266178131,
      "logits/rejected": -0.09797577559947968,
      "logps/chosen": -290.48333740234375,
      "logps/rejected": -358.29144287109375,
      "loss": 0.0383,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.696255683898926,
      "rewards/margins": 6.576679229736328,
      "rewards/rejected": -19.272937774658203,
      "step": 13510
    },
    {
      "epoch": 4.024408394106266,
      "grad_norm": 6.367133140563965,
      "learning_rate": 1.5778912586362273e-05,
      "logits/chosen": 0.08897615969181061,
      "logits/rejected": -0.024042213335633278,
      "logps/chosen": -291.0760192871094,
      "logps/rejected": -375.56341552734375,
      "loss": 0.0368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.94372272491455,
      "rewards/margins": 6.4166693687438965,
      "rewards/rejected": -19.360393524169922,
      "step": 13520
    },
    {
      "epoch": 4.027385027533859,
      "grad_norm": 11.807267189025879,
      "learning_rate": 1.573085010513668e-05,
      "logits/chosen": -0.04021991044282913,
      "logits/rejected": -0.1050787940621376,
      "logps/chosen": -317.2679748535156,
      "logps/rejected": -405.5362548828125,
      "loss": 0.0517,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.477890014648438,
      "rewards/margins": 6.590952396392822,
      "rewards/rejected": -21.068843841552734,
      "step": 13530
    },
    {
      "epoch": 4.030361660961453,
      "grad_norm": 0.9894324541091919,
      "learning_rate": 1.5682787623911085e-05,
      "logits/chosen": -0.17774370312690735,
      "logits/rejected": -0.1974179446697235,
      "logps/chosen": -308.16119384765625,
      "logps/rejected": -379.32073974609375,
      "loss": 0.0263,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.489742279052734,
      "rewards/margins": 6.841338157653809,
      "rewards/rejected": -19.33108139038086,
      "step": 13540
    },
    {
      "epoch": 4.033338294389046,
      "grad_norm": 1.1513605117797852,
      "learning_rate": 1.563472514268549e-05,
      "logits/chosen": -0.26655763387680054,
      "logits/rejected": -0.17308944463729858,
      "logps/chosen": -288.1973571777344,
      "logps/rejected": -361.12884521484375,
      "loss": 0.04,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.113908767700195,
      "rewards/margins": 7.099376678466797,
      "rewards/rejected": -18.21328353881836,
      "step": 13550
    },
    {
      "epoch": 4.0363149278166395,
      "grad_norm": 0.8915055990219116,
      "learning_rate": 1.55866626614599e-05,
      "logits/chosen": -0.13077393174171448,
      "logits/rejected": -0.2435365617275238,
      "logps/chosen": -307.18572998046875,
      "logps/rejected": -391.35638427734375,
      "loss": 0.0451,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.342571258544922,
      "rewards/margins": 6.5336174964904785,
      "rewards/rejected": -18.876190185546875,
      "step": 13560
    },
    {
      "epoch": 4.039291561244233,
      "grad_norm": 4.258880615234375,
      "learning_rate": 1.5538600180234307e-05,
      "logits/chosen": -0.2210485190153122,
      "logits/rejected": -0.21757790446281433,
      "logps/chosen": -278.376953125,
      "logps/rejected": -346.23486328125,
      "loss": 0.0244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -11.498367309570312,
      "rewards/margins": 6.421440124511719,
      "rewards/rejected": -17.9198055267334,
      "step": 13570
    },
    {
      "epoch": 4.042268194671826,
      "grad_norm": 6.971085548400879,
      "learning_rate": 1.5490537699008713e-05,
      "logits/chosen": -0.3309575617313385,
      "logits/rejected": -0.4125073552131653,
      "logps/chosen": -306.2227478027344,
      "logps/rejected": -379.4727478027344,
      "loss": 0.0623,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.498706817626953,
      "rewards/margins": 6.207376956939697,
      "rewards/rejected": -18.706083297729492,
      "step": 13580
    },
    {
      "epoch": 4.0452448280994195,
      "grad_norm": 0.4552272856235504,
      "learning_rate": 1.544247521778312e-05,
      "logits/chosen": -0.27054908871650696,
      "logits/rejected": -0.2305591106414795,
      "logps/chosen": -302.1151428222656,
      "logps/rejected": -366.51678466796875,
      "loss": 0.0714,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -12.08635139465332,
      "rewards/margins": 5.73657751083374,
      "rewards/rejected": -17.822927474975586,
      "step": 13590
    },
    {
      "epoch": 4.048221461527013,
      "grad_norm": 4.84072208404541,
      "learning_rate": 1.5394412736557526e-05,
      "logits/chosen": -0.16719341278076172,
      "logits/rejected": -0.18832749128341675,
      "logps/chosen": -300.1230773925781,
      "logps/rejected": -388.19921875,
      "loss": 0.0249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -11.840429306030273,
      "rewards/margins": 7.6586761474609375,
      "rewards/rejected": -19.49910545349121,
      "step": 13600
    },
    {
      "epoch": 4.051198094954606,
      "grad_norm": 5.663027763366699,
      "learning_rate": 1.534635025533193e-05,
      "logits/chosen": -0.2447478324174881,
      "logits/rejected": -0.1936262845993042,
      "logps/chosen": -310.5324401855469,
      "logps/rejected": -373.43316650390625,
      "loss": 0.045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.66698932647705,
      "rewards/margins": 6.228962421417236,
      "rewards/rejected": -19.895950317382812,
      "step": 13610
    },
    {
      "epoch": 4.0541747283822,
      "grad_norm": 1.1947733163833618,
      "learning_rate": 1.529828777410634e-05,
      "logits/chosen": -0.15627917647361755,
      "logits/rejected": -0.10332592576742172,
      "logps/chosen": -280.6927795410156,
      "logps/rejected": -341.24664306640625,
      "loss": 0.0345,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.073429107666016,
      "rewards/margins": 6.192419528961182,
      "rewards/rejected": -18.265850067138672,
      "step": 13620
    },
    {
      "epoch": 4.057151361809793,
      "grad_norm": 1.6536855697631836,
      "learning_rate": 1.5250225292880747e-05,
      "logits/chosen": -0.11761447042226791,
      "logits/rejected": -0.092507503926754,
      "logps/chosen": -296.31256103515625,
      "logps/rejected": -371.3296813964844,
      "loss": 0.0702,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -13.201065063476562,
      "rewards/margins": 6.621391296386719,
      "rewards/rejected": -19.82245445251465,
      "step": 13630
    },
    {
      "epoch": 4.060127995237386,
      "grad_norm": 4.714250087738037,
      "learning_rate": 1.5202162811655152e-05,
      "logits/chosen": -0.13938936591148376,
      "logits/rejected": -0.2017604410648346,
      "logps/chosen": -311.58056640625,
      "logps/rejected": -384.1370849609375,
      "loss": 0.0643,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.17585563659668,
      "rewards/margins": 6.250687599182129,
      "rewards/rejected": -20.426544189453125,
      "step": 13640
    },
    {
      "epoch": 4.06310462866498,
      "grad_norm": 4.09597110748291,
      "learning_rate": 1.515410033042956e-05,
      "logits/chosen": -0.15752439200878143,
      "logits/rejected": -0.13370990753173828,
      "logps/chosen": -292.50115966796875,
      "logps/rejected": -362.2479553222656,
      "loss": 0.0912,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -12.808690071105957,
      "rewards/margins": 6.522511959075928,
      "rewards/rejected": -19.331201553344727,
      "step": 13650
    },
    {
      "epoch": 4.066081262092573,
      "grad_norm": 14.311110496520996,
      "learning_rate": 1.5106037849203967e-05,
      "logits/chosen": -0.19878293573856354,
      "logits/rejected": -0.19876834750175476,
      "logps/chosen": -319.0097351074219,
      "logps/rejected": -379.88494873046875,
      "loss": 0.0521,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.397705078125,
      "rewards/margins": 5.981740951538086,
      "rewards/rejected": -19.379446029663086,
      "step": 13660
    },
    {
      "epoch": 4.069057895520166,
      "grad_norm": 5.05406379699707,
      "learning_rate": 1.5057975367978372e-05,
      "logits/chosen": -0.020919520407915115,
      "logits/rejected": -0.11232699453830719,
      "logps/chosen": -311.2275390625,
      "logps/rejected": -404.9787292480469,
      "loss": 0.0597,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.303790092468262,
      "rewards/margins": 7.55438756942749,
      "rewards/rejected": -20.858179092407227,
      "step": 13670
    },
    {
      "epoch": 4.07203452894776,
      "grad_norm": 4.156872272491455,
      "learning_rate": 1.500991288675278e-05,
      "logits/chosen": -0.1757279634475708,
      "logits/rejected": -0.03726477175951004,
      "logps/chosen": -310.52239990234375,
      "logps/rejected": -384.7991638183594,
      "loss": 0.0476,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.901545524597168,
      "rewards/margins": 6.373802185058594,
      "rewards/rejected": -19.275348663330078,
      "step": 13680
    },
    {
      "epoch": 4.075011162375353,
      "grad_norm": 1.0330394506454468,
      "learning_rate": 1.4961850405527188e-05,
      "logits/chosen": -0.12782041728496552,
      "logits/rejected": -0.09387660026550293,
      "logps/chosen": -284.8959045410156,
      "logps/rejected": -364.78387451171875,
      "loss": 0.0257,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -11.22782039642334,
      "rewards/margins": 7.067518711090088,
      "rewards/rejected": -18.295339584350586,
      "step": 13690
    },
    {
      "epoch": 4.0779877958029465,
      "grad_norm": 0.21498911082744598,
      "learning_rate": 1.4913787924301592e-05,
      "logits/chosen": -0.23727445304393768,
      "logits/rejected": -0.09488923102617264,
      "logps/chosen": -310.00738525390625,
      "logps/rejected": -376.04168701171875,
      "loss": 0.0308,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.984228134155273,
      "rewards/margins": 7.03634786605835,
      "rewards/rejected": -20.02057647705078,
      "step": 13700
    },
    {
      "epoch": 4.080964429230541,
      "grad_norm": 1.457716941833496,
      "learning_rate": 1.4865725443076e-05,
      "logits/chosen": -0.11940499395132065,
      "logits/rejected": -0.1299709975719452,
      "logps/chosen": -316.76080322265625,
      "logps/rejected": -390.287841796875,
      "loss": 0.0522,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.982007026672363,
      "rewards/margins": 6.607645511627197,
      "rewards/rejected": -20.589651107788086,
      "step": 13710
    },
    {
      "epoch": 4.083941062658134,
      "grad_norm": 5.351062774658203,
      "learning_rate": 1.4817662961850408e-05,
      "logits/chosen": -0.05203434079885483,
      "logits/rejected": -0.06647729128599167,
      "logps/chosen": -297.22576904296875,
      "logps/rejected": -375.86651611328125,
      "loss": 0.0271,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.667068481445312,
      "rewards/margins": 6.950626373291016,
      "rewards/rejected": -19.617694854736328,
      "step": 13720
    },
    {
      "epoch": 4.086917696085727,
      "grad_norm": 1.1473006010055542,
      "learning_rate": 1.4769600480624812e-05,
      "logits/chosen": -0.07340051978826523,
      "logits/rejected": -0.025584910064935684,
      "logps/chosen": -316.56622314453125,
      "logps/rejected": -380.6648864746094,
      "loss": 0.0236,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.302212715148926,
      "rewards/margins": 7.063279628753662,
      "rewards/rejected": -20.365493774414062,
      "step": 13730
    },
    {
      "epoch": 4.089894329513321,
      "grad_norm": 0.8583046793937683,
      "learning_rate": 1.472153799939922e-05,
      "logits/chosen": -0.09363577514886856,
      "logits/rejected": -0.11105626821517944,
      "logps/chosen": -280.2017517089844,
      "logps/rejected": -355.13433837890625,
      "loss": 0.0379,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.431615829467773,
      "rewards/margins": 6.608992576599121,
      "rewards/rejected": -19.040607452392578,
      "step": 13740
    },
    {
      "epoch": 4.092870962940914,
      "grad_norm": 1.996751308441162,
      "learning_rate": 1.4673475518173628e-05,
      "logits/chosen": 0.031867511570453644,
      "logits/rejected": -0.12667573988437653,
      "logps/chosen": -318.53521728515625,
      "logps/rejected": -411.20166015625,
      "loss": 0.054,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.041723251342773,
      "rewards/margins": 7.490229606628418,
      "rewards/rejected": -21.53195571899414,
      "step": 13750
    },
    {
      "epoch": 4.0958475963685075,
      "grad_norm": 4.226419448852539,
      "learning_rate": 1.4625413036948032e-05,
      "logits/chosen": 0.16548819839954376,
      "logits/rejected": -0.04157399386167526,
      "logps/chosen": -303.4787292480469,
      "logps/rejected": -402.8090515136719,
      "loss": 0.0303,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.155085563659668,
      "rewards/margins": 7.117168426513672,
      "rewards/rejected": -21.272254943847656,
      "step": 13760
    },
    {
      "epoch": 4.098824229796101,
      "grad_norm": 2.1159827709198,
      "learning_rate": 1.457735055572244e-05,
      "logits/chosen": -0.02653944492340088,
      "logits/rejected": 0.08737124502658844,
      "logps/chosen": -302.69439697265625,
      "logps/rejected": -373.43463134765625,
      "loss": 0.1124,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -13.542329788208008,
      "rewards/margins": 6.435230255126953,
      "rewards/rejected": -19.97756004333496,
      "step": 13770
    },
    {
      "epoch": 4.101800863223694,
      "grad_norm": 0.911490797996521,
      "learning_rate": 1.4529288074496848e-05,
      "logits/chosen": -0.023551886901259422,
      "logits/rejected": -0.10272480547428131,
      "logps/chosen": -348.24749755859375,
      "logps/rejected": -432.1700744628906,
      "loss": 0.0422,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.281964302062988,
      "rewards/margins": 6.679182529449463,
      "rewards/rejected": -21.96114730834961,
      "step": 13780
    },
    {
      "epoch": 4.1047774966512875,
      "grad_norm": 32.566993713378906,
      "learning_rate": 1.4481225593271252e-05,
      "logits/chosen": -0.08347778022289276,
      "logits/rejected": -0.21377725899219513,
      "logps/chosen": -327.80029296875,
      "logps/rejected": -412.8660583496094,
      "loss": 0.0596,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.976827621459961,
      "rewards/margins": 6.853798866271973,
      "rewards/rejected": -20.83062744140625,
      "step": 13790
    },
    {
      "epoch": 4.107754130078881,
      "grad_norm": 4.920100688934326,
      "learning_rate": 1.443316311204566e-05,
      "logits/chosen": -0.03392023220658302,
      "logits/rejected": -0.008810603059828281,
      "logps/chosen": -298.54107666015625,
      "logps/rejected": -357.88922119140625,
      "loss": 0.0367,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.63401985168457,
      "rewards/margins": 5.9346923828125,
      "rewards/rejected": -19.568710327148438,
      "step": 13800
    },
    {
      "epoch": 4.110730763506474,
      "grad_norm": 1.1441659927368164,
      "learning_rate": 1.4385100630820068e-05,
      "logits/chosen": -0.22758197784423828,
      "logits/rejected": 0.010648720897734165,
      "logps/chosen": -330.38519287109375,
      "logps/rejected": -390.1710205078125,
      "loss": 0.0564,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.428634643554688,
      "rewards/margins": 6.623448371887207,
      "rewards/rejected": -20.052082061767578,
      "step": 13810
    },
    {
      "epoch": 4.113707396934068,
      "grad_norm": 12.349174499511719,
      "learning_rate": 1.4337038149594473e-05,
      "logits/chosen": -0.03761560469865799,
      "logits/rejected": -0.006168860010802746,
      "logps/chosen": -319.0418395996094,
      "logps/rejected": -385.7283630371094,
      "loss": 0.0509,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.541906356811523,
      "rewards/margins": 6.461202144622803,
      "rewards/rejected": -20.003108978271484,
      "step": 13820
    },
    {
      "epoch": 4.116684030361661,
      "grad_norm": 4.111758232116699,
      "learning_rate": 1.428897566836888e-05,
      "logits/chosen": -0.13330066204071045,
      "logits/rejected": -0.013422220945358276,
      "logps/chosen": -311.84283447265625,
      "logps/rejected": -393.5068359375,
      "loss": 0.0467,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.894340515136719,
      "rewards/margins": 7.4613356590271,
      "rewards/rejected": -20.355676651000977,
      "step": 13830
    },
    {
      "epoch": 4.119660663789254,
      "grad_norm": 0.8743393421173096,
      "learning_rate": 1.4240913187143288e-05,
      "logits/chosen": -0.1355922669172287,
      "logits/rejected": -0.11096219718456268,
      "logps/chosen": -304.0143127441406,
      "logps/rejected": -381.4697265625,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.216288566589355,
      "rewards/margins": 7.217374324798584,
      "rewards/rejected": -20.433666229248047,
      "step": 13840
    },
    {
      "epoch": 4.122637297216848,
      "grad_norm": 4.925431251525879,
      "learning_rate": 1.4192850705917693e-05,
      "logits/chosen": -0.057608962059020996,
      "logits/rejected": -0.05233393982052803,
      "logps/chosen": -306.14453125,
      "logps/rejected": -386.3471374511719,
      "loss": 0.0301,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.9378662109375,
      "rewards/margins": 7.266571998596191,
      "rewards/rejected": -20.20444107055664,
      "step": 13850
    },
    {
      "epoch": 4.125613930644441,
      "grad_norm": 3.19134783744812,
      "learning_rate": 1.41447882246921e-05,
      "logits/chosen": -0.019880032166838646,
      "logits/rejected": 0.05849485844373703,
      "logps/chosen": -290.7205505371094,
      "logps/rejected": -372.9596252441406,
      "loss": 0.0751,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.57917308807373,
      "rewards/margins": 6.954270362854004,
      "rewards/rejected": -19.533443450927734,
      "step": 13860
    },
    {
      "epoch": 4.128590564072034,
      "grad_norm": 3.1302576065063477,
      "learning_rate": 1.4096725743466508e-05,
      "logits/chosen": -0.23290801048278809,
      "logits/rejected": -0.09280408918857574,
      "logps/chosen": -296.9755859375,
      "logps/rejected": -361.5337219238281,
      "loss": 0.0384,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.322078704833984,
      "rewards/margins": 6.847802639007568,
      "rewards/rejected": -19.169879913330078,
      "step": 13870
    },
    {
      "epoch": 4.131567197499628,
      "grad_norm": 1.7711187601089478,
      "learning_rate": 1.4048663262240913e-05,
      "logits/chosen": -0.13197581470012665,
      "logits/rejected": -0.06723067909479141,
      "logps/chosen": -295.59454345703125,
      "logps/rejected": -368.57080078125,
      "loss": 0.1058,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.251121520996094,
      "rewards/margins": 6.346502304077148,
      "rewards/rejected": -18.597623825073242,
      "step": 13880
    },
    {
      "epoch": 4.134543830927221,
      "grad_norm": 1.106224536895752,
      "learning_rate": 1.400060078101532e-05,
      "logits/chosen": 0.1277811974287033,
      "logits/rejected": 0.026927435770630836,
      "logps/chosen": -301.5334167480469,
      "logps/rejected": -392.67633056640625,
      "loss": 0.0378,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.044710159301758,
      "rewards/margins": 7.2612152099609375,
      "rewards/rejected": -21.305923461914062,
      "step": 13890
    },
    {
      "epoch": 4.1375204643548145,
      "grad_norm": 1.4902890920639038,
      "learning_rate": 1.3952538299789729e-05,
      "logits/chosen": -0.10014526546001434,
      "logits/rejected": 0.06883611530065536,
      "logps/chosen": -300.5314025878906,
      "logps/rejected": -358.55718994140625,
      "loss": 0.0418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.927286148071289,
      "rewards/margins": 6.286347389221191,
      "rewards/rejected": -19.21363067626953,
      "step": 13900
    },
    {
      "epoch": 4.140497097782408,
      "grad_norm": 11.823901176452637,
      "learning_rate": 1.3904475818564133e-05,
      "logits/chosen": 0.018756184726953506,
      "logits/rejected": 0.06068775802850723,
      "logps/chosen": -294.70538330078125,
      "logps/rejected": -361.4740905761719,
      "loss": 0.1316,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -13.108558654785156,
      "rewards/margins": 6.0758562088012695,
      "rewards/rejected": -19.184412002563477,
      "step": 13910
    },
    {
      "epoch": 4.143473731210001,
      "grad_norm": 2.524021625518799,
      "learning_rate": 1.3856413337338541e-05,
      "logits/chosen": 0.057228315621614456,
      "logits/rejected": 0.09273351728916168,
      "logps/chosen": -299.0747375488281,
      "logps/rejected": -371.9501953125,
      "loss": 0.112,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.525017738342285,
      "rewards/margins": 6.691828727722168,
      "rewards/rejected": -19.21684455871582,
      "step": 13920
    },
    {
      "epoch": 4.1464503646375945,
      "grad_norm": 0.7383536100387573,
      "learning_rate": 1.3808350856112949e-05,
      "logits/chosen": 0.17039650678634644,
      "logits/rejected": -0.09605540335178375,
      "logps/chosen": -316.3777770996094,
      "logps/rejected": -424.84375,
      "loss": 0.0536,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.602773666381836,
      "rewards/margins": 7.9386887550354,
      "rewards/rejected": -22.541461944580078,
      "step": 13930
    },
    {
      "epoch": 4.149426998065188,
      "grad_norm": 5.033971786499023,
      "learning_rate": 1.3760288374887353e-05,
      "logits/chosen": -0.044526614248752594,
      "logits/rejected": 0.0022358112037181854,
      "logps/chosen": -325.5381774902344,
      "logps/rejected": -395.759765625,
      "loss": 0.0967,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -14.95411205291748,
      "rewards/margins": 6.419493198394775,
      "rewards/rejected": -21.373605728149414,
      "step": 13940
    },
    {
      "epoch": 4.152403631492781,
      "grad_norm": 3.005343198776245,
      "learning_rate": 1.3712225893661761e-05,
      "logits/chosen": 0.034266967326402664,
      "logits/rejected": -0.06278263032436371,
      "logps/chosen": -312.45526123046875,
      "logps/rejected": -400.4820861816406,
      "loss": 0.0539,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.839714050292969,
      "rewards/margins": 7.6354217529296875,
      "rewards/rejected": -20.47513771057129,
      "step": 13950
    },
    {
      "epoch": 4.155380264920375,
      "grad_norm": 17.240753173828125,
      "learning_rate": 1.3664163412436169e-05,
      "logits/chosen": 0.090825155377388,
      "logits/rejected": -0.07190041989088058,
      "logps/chosen": -292.24505615234375,
      "logps/rejected": -394.6705017089844,
      "loss": 0.0719,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.105941772460938,
      "rewards/margins": 7.3850998878479,
      "rewards/rejected": -21.491039276123047,
      "step": 13960
    },
    {
      "epoch": 4.158356898347969,
      "grad_norm": 0.916292130947113,
      "learning_rate": 1.3616100931210573e-05,
      "logits/chosen": 0.01915564574301243,
      "logits/rejected": -0.029841382056474686,
      "logps/chosen": -297.64727783203125,
      "logps/rejected": -374.3826599121094,
      "loss": 0.0544,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.744030952453613,
      "rewards/margins": 6.695220947265625,
      "rewards/rejected": -20.439250946044922,
      "step": 13970
    },
    {
      "epoch": 4.161333531775562,
      "grad_norm": 1.4579147100448608,
      "learning_rate": 1.3568038449984981e-05,
      "logits/chosen": -0.05218355730175972,
      "logits/rejected": -0.06147902086377144,
      "logps/chosen": -308.4771423339844,
      "logps/rejected": -379.53875732421875,
      "loss": 0.0263,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.447216987609863,
      "rewards/margins": 6.690694332122803,
      "rewards/rejected": -20.13791275024414,
      "step": 13980
    },
    {
      "epoch": 4.164310165203156,
      "grad_norm": 1.0400512218475342,
      "learning_rate": 1.3519975968759389e-05,
      "logits/chosen": 0.03379286825656891,
      "logits/rejected": 0.06962670385837555,
      "logps/chosen": -313.9329528808594,
      "logps/rejected": -372.76116943359375,
      "loss": 0.0941,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.569368362426758,
      "rewards/margins": 5.801417350769043,
      "rewards/rejected": -19.370784759521484,
      "step": 13990
    },
    {
      "epoch": 4.167286798630749,
      "grad_norm": 4.938882350921631,
      "learning_rate": 1.3471913487533793e-05,
      "logits/chosen": -0.22548000514507294,
      "logits/rejected": -0.16244900226593018,
      "logps/chosen": -325.927001953125,
      "logps/rejected": -384.5846862792969,
      "loss": 0.0561,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.93407917022705,
      "rewards/margins": 6.005709171295166,
      "rewards/rejected": -19.939788818359375,
      "step": 14000
    },
    {
      "epoch": 4.170263432058342,
      "grad_norm": 2.9827511310577393,
      "learning_rate": 1.3423851006308201e-05,
      "logits/chosen": 0.09793145954608917,
      "logits/rejected": -0.13670632243156433,
      "logps/chosen": -269.1822509765625,
      "logps/rejected": -362.1527404785156,
      "loss": 0.0586,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.311471939086914,
      "rewards/margins": 6.941496849060059,
      "rewards/rejected": -18.25296974182129,
      "step": 14010
    },
    {
      "epoch": 4.173240065485936,
      "grad_norm": 0.9971430897712708,
      "learning_rate": 1.3375788525082609e-05,
      "logits/chosen": 0.06201130151748657,
      "logits/rejected": -0.14770308136940002,
      "logps/chosen": -322.3221130371094,
      "logps/rejected": -420.39862060546875,
      "loss": 0.031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.143778800964355,
      "rewards/margins": 7.634545803070068,
      "rewards/rejected": -22.7783260345459,
      "step": 14020
    },
    {
      "epoch": 4.176216698913529,
      "grad_norm": 0.9848248362541199,
      "learning_rate": 1.3327726043857014e-05,
      "logits/chosen": -0.0540638342499733,
      "logits/rejected": 0.02369077131152153,
      "logps/chosen": -318.70269775390625,
      "logps/rejected": -382.4354553222656,
      "loss": 0.0936,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -14.182218551635742,
      "rewards/margins": 6.460640907287598,
      "rewards/rejected": -20.64286231994629,
      "step": 14030
    },
    {
      "epoch": 4.179193332341122,
      "grad_norm": 1.911437749862671,
      "learning_rate": 1.3279663562631421e-05,
      "logits/chosen": -0.033644065260887146,
      "logits/rejected": 0.0017640948062762618,
      "logps/chosen": -316.0871887207031,
      "logps/rejected": -413.98846435546875,
      "loss": 0.0299,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.529963493347168,
      "rewards/margins": 8.204914093017578,
      "rewards/rejected": -21.734874725341797,
      "step": 14040
    },
    {
      "epoch": 4.182169965768716,
      "grad_norm": 3.453495502471924,
      "learning_rate": 1.323160108140583e-05,
      "logits/chosen": 0.1212773472070694,
      "logits/rejected": -0.08575980365276337,
      "logps/chosen": -312.9964599609375,
      "logps/rejected": -410.0162048339844,
      "loss": 0.045,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.103736877441406,
      "rewards/margins": 7.838587760925293,
      "rewards/rejected": -22.942325592041016,
      "step": 14050
    },
    {
      "epoch": 4.185146599196309,
      "grad_norm": 4.0768656730651855,
      "learning_rate": 1.3183538600180235e-05,
      "logits/chosen": -0.04074528068304062,
      "logits/rejected": 0.0763426274061203,
      "logps/chosen": -319.36468505859375,
      "logps/rejected": -395.5074768066406,
      "loss": 0.0441,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.042859077453613,
      "rewards/margins": 7.573599338531494,
      "rewards/rejected": -21.6164608001709,
      "step": 14060
    },
    {
      "epoch": 4.188123232623902,
      "grad_norm": 28.37804412841797,
      "learning_rate": 1.3135476118954642e-05,
      "logits/chosen": -0.10145661979913712,
      "logits/rejected": -0.21887381374835968,
      "logps/chosen": -308.9278564453125,
      "logps/rejected": -391.77838134765625,
      "loss": 0.072,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.343374252319336,
      "rewards/margins": 7.167423248291016,
      "rewards/rejected": -21.51079559326172,
      "step": 14070
    },
    {
      "epoch": 4.191099866051496,
      "grad_norm": 4.1340651512146,
      "learning_rate": 1.308741363772905e-05,
      "logits/chosen": -0.11111096292734146,
      "logits/rejected": -0.09471599757671356,
      "logps/chosen": -310.0494689941406,
      "logps/rejected": -391.1292724609375,
      "loss": 0.0553,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.865946769714355,
      "rewards/margins": 6.939852714538574,
      "rewards/rejected": -20.805797576904297,
      "step": 14080
    },
    {
      "epoch": 4.194076499479089,
      "grad_norm": 5.086530685424805,
      "learning_rate": 1.3039351156503456e-05,
      "logits/chosen": -0.025233402848243713,
      "logits/rejected": -0.07941596210002899,
      "logps/chosen": -303.268310546875,
      "logps/rejected": -403.7364196777344,
      "loss": 0.0467,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.860305786132812,
      "rewards/margins": 7.956507682800293,
      "rewards/rejected": -20.81681251525879,
      "step": 14090
    },
    {
      "epoch": 4.1970531329066825,
      "grad_norm": 10.98253345489502,
      "learning_rate": 1.2991288675277862e-05,
      "logits/chosen": -0.006646967027336359,
      "logits/rejected": -0.04043726250529289,
      "logps/chosen": -316.64691162109375,
      "logps/rejected": -386.1500549316406,
      "loss": 0.0451,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.849365234375,
      "rewards/margins": 6.566669464111328,
      "rewards/rejected": -20.416034698486328,
      "step": 14100
    },
    {
      "epoch": 4.200029766334276,
      "grad_norm": 0.1875975877046585,
      "learning_rate": 1.294322619405227e-05,
      "logits/chosen": 0.009783243760466576,
      "logits/rejected": 0.014727341942489147,
      "logps/chosen": -294.9210510253906,
      "logps/rejected": -399.99365234375,
      "loss": 0.0268,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.863980293273926,
      "rewards/margins": 8.264126777648926,
      "rewards/rejected": -21.12810707092285,
      "step": 14110
    },
    {
      "epoch": 4.203006399761869,
      "grad_norm": 1.5223500728607178,
      "learning_rate": 1.2895163712826676e-05,
      "logits/chosen": 0.019743971526622772,
      "logits/rejected": 0.0184873528778553,
      "logps/chosen": -309.7269287109375,
      "logps/rejected": -391.5612487792969,
      "loss": 0.0191,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.674057006835938,
      "rewards/margins": 7.469328880310059,
      "rewards/rejected": -21.143386840820312,
      "step": 14120
    },
    {
      "epoch": 4.2059830331894625,
      "grad_norm": 2.9043664932250977,
      "learning_rate": 1.2847101231601082e-05,
      "logits/chosen": -0.07939838618040085,
      "logits/rejected": -0.05074552446603775,
      "logps/chosen": -330.1337890625,
      "logps/rejected": -395.2339782714844,
      "loss": 0.0841,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -13.582727432250977,
      "rewards/margins": 6.90948486328125,
      "rewards/rejected": -20.49221420288086,
      "step": 14130
    },
    {
      "epoch": 4.208959666617056,
      "grad_norm": 0.8536844253540039,
      "learning_rate": 1.279903875037549e-05,
      "logits/chosen": -0.18044763803482056,
      "logits/rejected": -0.10235979408025742,
      "logps/chosen": -307.5518798828125,
      "logps/rejected": -388.8211364746094,
      "loss": 0.0319,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.088113784790039,
      "rewards/margins": 7.161744594573975,
      "rewards/rejected": -20.24985694885254,
      "step": 14140
    },
    {
      "epoch": 4.211936300044649,
      "grad_norm": 0.3927637040615082,
      "learning_rate": 1.2750976269149896e-05,
      "logits/chosen": -0.06272263824939728,
      "logits/rejected": -0.11652656644582748,
      "logps/chosen": -290.86651611328125,
      "logps/rejected": -373.3982238769531,
      "loss": 0.0618,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.230401992797852,
      "rewards/margins": 7.1993303298950195,
      "rewards/rejected": -19.429733276367188,
      "step": 14150
    },
    {
      "epoch": 4.214912933472243,
      "grad_norm": 4.338694095611572,
      "learning_rate": 1.2702913787924302e-05,
      "logits/chosen": 0.05775367468595505,
      "logits/rejected": 0.006668011657893658,
      "logps/chosen": -301.554443359375,
      "logps/rejected": -384.0516662597656,
      "loss": 0.0318,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.34943675994873,
      "rewards/margins": 7.502309322357178,
      "rewards/rejected": -20.851747512817383,
      "step": 14160
    },
    {
      "epoch": 4.217889566899836,
      "grad_norm": 5.953186511993408,
      "learning_rate": 1.265485130669871e-05,
      "logits/chosen": -0.013900304213166237,
      "logits/rejected": -0.07029023766517639,
      "logps/chosen": -336.513916015625,
      "logps/rejected": -418.4081115722656,
      "loss": 0.0398,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -16.15034294128418,
      "rewards/margins": 7.049007415771484,
      "rewards/rejected": -23.199350357055664,
      "step": 14170
    },
    {
      "epoch": 4.220866200327429,
      "grad_norm": 12.627067565917969,
      "learning_rate": 1.2606788825473116e-05,
      "logits/chosen": 0.1568179577589035,
      "logits/rejected": -0.07554486393928528,
      "logps/chosen": -317.6330871582031,
      "logps/rejected": -408.76513671875,
      "loss": 0.0519,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.448541641235352,
      "rewards/margins": 7.3352508544921875,
      "rewards/rejected": -22.78379249572754,
      "step": 14180
    },
    {
      "epoch": 4.223842833755023,
      "grad_norm": 3.937126398086548,
      "learning_rate": 1.2558726344247522e-05,
      "logits/chosen": -0.022811269387602806,
      "logits/rejected": -0.029354434460401535,
      "logps/chosen": -340.06707763671875,
      "logps/rejected": -440.98028564453125,
      "loss": 0.0859,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.771310806274414,
      "rewards/margins": 8.189784049987793,
      "rewards/rejected": -23.961095809936523,
      "step": 14190
    },
    {
      "epoch": 4.226819467182617,
      "grad_norm": 11.035943031311035,
      "learning_rate": 1.251066386302193e-05,
      "logits/chosen": -0.06412016600370407,
      "logits/rejected": -0.047980885952711105,
      "logps/chosen": -319.4652099609375,
      "logps/rejected": -393.2301330566406,
      "loss": 0.0766,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.099812507629395,
      "rewards/margins": 6.6439666748046875,
      "rewards/rejected": -20.743778228759766,
      "step": 14200
    },
    {
      "epoch": 4.22979610061021,
      "grad_norm": 0.3345082104206085,
      "learning_rate": 1.2462601381796336e-05,
      "logits/chosen": 0.02039453014731407,
      "logits/rejected": -0.1397835910320282,
      "logps/chosen": -296.48211669921875,
      "logps/rejected": -395.04217529296875,
      "loss": 0.0753,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.156285285949707,
      "rewards/margins": 7.493121147155762,
      "rewards/rejected": -21.649402618408203,
      "step": 14210
    },
    {
      "epoch": 4.232772734037804,
      "grad_norm": 3.419935464859009,
      "learning_rate": 1.2414538900570742e-05,
      "logits/chosen": -0.08520912379026413,
      "logits/rejected": 0.012950107455253601,
      "logps/chosen": -290.76446533203125,
      "logps/rejected": -366.6282958984375,
      "loss": 0.0441,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.88195514678955,
      "rewards/margins": 7.158435821533203,
      "rewards/rejected": -20.040393829345703,
      "step": 14220
    },
    {
      "epoch": 4.235749367465397,
      "grad_norm": 10.981124877929688,
      "learning_rate": 1.236647641934515e-05,
      "logits/chosen": -0.14498555660247803,
      "logits/rejected": -0.07915887981653214,
      "logps/chosen": -295.68646240234375,
      "logps/rejected": -378.17047119140625,
      "loss": 0.0533,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.434806823730469,
      "rewards/margins": 7.858743190765381,
      "rewards/rejected": -20.29355239868164,
      "step": 14230
    },
    {
      "epoch": 4.23872600089299,
      "grad_norm": 3.815361499786377,
      "learning_rate": 1.2318413938119556e-05,
      "logits/chosen": -0.009393391199409962,
      "logits/rejected": -0.08477889001369476,
      "logps/chosen": -311.72430419921875,
      "logps/rejected": -392.9374084472656,
      "loss": 0.0329,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.910151481628418,
      "rewards/margins": 7.272931098937988,
      "rewards/rejected": -21.18308448791504,
      "step": 14240
    },
    {
      "epoch": 4.241702634320584,
      "grad_norm": 9.090457916259766,
      "learning_rate": 1.2270351456893962e-05,
      "logits/chosen": 0.09294724464416504,
      "logits/rejected": -0.014115862548351288,
      "logps/chosen": -287.80853271484375,
      "logps/rejected": -388.9488220214844,
      "loss": 0.024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.63115119934082,
      "rewards/margins": 7.946516513824463,
      "rewards/rejected": -20.577665328979492,
      "step": 14250
    },
    {
      "epoch": 4.244679267748177,
      "grad_norm": 4.788072109222412,
      "learning_rate": 1.222228897566837e-05,
      "logits/chosen": -0.00634451350197196,
      "logits/rejected": 0.02231450006365776,
      "logps/chosen": -335.7844543457031,
      "logps/rejected": -418.854736328125,
      "loss": 0.0712,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -16.048568725585938,
      "rewards/margins": 7.135122776031494,
      "rewards/rejected": -23.183691024780273,
      "step": 14260
    },
    {
      "epoch": 4.24765590117577,
      "grad_norm": 1.0471298694610596,
      "learning_rate": 1.2174226494442776e-05,
      "logits/chosen": -0.017209652811288834,
      "logits/rejected": -0.03393562510609627,
      "logps/chosen": -321.74072265625,
      "logps/rejected": -414.4791564941406,
      "loss": 0.0226,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.774606704711914,
      "rewards/margins": 7.753953456878662,
      "rewards/rejected": -23.528560638427734,
      "step": 14270
    },
    {
      "epoch": 4.250632534603364,
      "grad_norm": 6.919139862060547,
      "learning_rate": 1.2126164013217182e-05,
      "logits/chosen": -0.05081282928586006,
      "logits/rejected": 0.15140242874622345,
      "logps/chosen": -314.2289733886719,
      "logps/rejected": -376.0711975097656,
      "loss": 0.0324,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.362855911254883,
      "rewards/margins": 7.15737771987915,
      "rewards/rejected": -20.520233154296875,
      "step": 14280
    },
    {
      "epoch": 4.253609168030957,
      "grad_norm": 0.557080090045929,
      "learning_rate": 1.207810153199159e-05,
      "logits/chosen": -0.034057971090078354,
      "logits/rejected": -0.06435085088014603,
      "logps/chosen": -292.4027404785156,
      "logps/rejected": -376.73883056640625,
      "loss": 0.0412,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.251154899597168,
      "rewards/margins": 6.963708400726318,
      "rewards/rejected": -19.214862823486328,
      "step": 14290
    },
    {
      "epoch": 4.2565858014585505,
      "grad_norm": 2.321808338165283,
      "learning_rate": 1.2030039050765996e-05,
      "logits/chosen": 0.06020306423306465,
      "logits/rejected": 0.12963974475860596,
      "logps/chosen": -291.3372497558594,
      "logps/rejected": -371.38519287109375,
      "loss": 0.0298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.392423629760742,
      "rewards/margins": 7.203919887542725,
      "rewards/rejected": -20.596345901489258,
      "step": 14300
    },
    {
      "epoch": 4.259562434886144,
      "grad_norm": 3.877450704574585,
      "learning_rate": 1.1981976569540403e-05,
      "logits/chosen": -0.005441020242869854,
      "logits/rejected": -0.03106072172522545,
      "logps/chosen": -312.61083984375,
      "logps/rejected": -401.74542236328125,
      "loss": 0.0416,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.160440444946289,
      "rewards/margins": 7.770558834075928,
      "rewards/rejected": -20.930997848510742,
      "step": 14310
    },
    {
      "epoch": 4.262539068313737,
      "grad_norm": 0.6439612507820129,
      "learning_rate": 1.193391408831481e-05,
      "logits/chosen": -0.018881864845752716,
      "logits/rejected": -0.016215775161981583,
      "logps/chosen": -349.10784912109375,
      "logps/rejected": -439.77032470703125,
      "loss": 0.0309,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -17.04117202758789,
      "rewards/margins": 8.158672332763672,
      "rewards/rejected": -25.199846267700195,
      "step": 14320
    },
    {
      "epoch": 4.2655157017413305,
      "grad_norm": 15.072416305541992,
      "learning_rate": 1.1885851607089217e-05,
      "logits/chosen": 0.2864764928817749,
      "logits/rejected": 0.05111626908183098,
      "logps/chosen": -326.39715576171875,
      "logps/rejected": -419.13714599609375,
      "loss": 0.0463,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.992609024047852,
      "rewards/margins": 7.235201358795166,
      "rewards/rejected": -23.22780990600586,
      "step": 14330
    },
    {
      "epoch": 4.268492335168924,
      "grad_norm": 0.6489050388336182,
      "learning_rate": 1.1837789125863623e-05,
      "logits/chosen": 0.2089693546295166,
      "logits/rejected": 0.15748873353004456,
      "logps/chosen": -336.63671875,
      "logps/rejected": -411.6964416503906,
      "loss": 0.0547,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -17.050861358642578,
      "rewards/margins": 6.9002861976623535,
      "rewards/rejected": -23.95114517211914,
      "step": 14340
    },
    {
      "epoch": 4.271468968596517,
      "grad_norm": 6.0541863441467285,
      "learning_rate": 1.178972664463803e-05,
      "logits/chosen": 0.17876215279102325,
      "logits/rejected": 0.11978421360254288,
      "logps/chosen": -331.458740234375,
      "logps/rejected": -407.1478576660156,
      "loss": 0.0395,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -16.2325496673584,
      "rewards/margins": 6.859544277191162,
      "rewards/rejected": -23.09209442138672,
      "step": 14350
    },
    {
      "epoch": 4.274445602024111,
      "grad_norm": 21.600210189819336,
      "learning_rate": 1.1741664163412437e-05,
      "logits/chosen": 0.17357802391052246,
      "logits/rejected": 0.08473712205886841,
      "logps/chosen": -310.88336181640625,
      "logps/rejected": -404.04901123046875,
      "loss": 0.0867,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -15.072392463684082,
      "rewards/margins": 7.588539123535156,
      "rewards/rejected": -22.660932540893555,
      "step": 14360
    },
    {
      "epoch": 4.277422235451704,
      "grad_norm": 6.507168769836426,
      "learning_rate": 1.1693601682186843e-05,
      "logits/chosen": -0.06708265841007233,
      "logits/rejected": -0.05038747191429138,
      "logps/chosen": -317.79803466796875,
      "logps/rejected": -407.79193115234375,
      "loss": 0.0492,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.609606742858887,
      "rewards/margins": 7.383481025695801,
      "rewards/rejected": -21.993087768554688,
      "step": 14370
    },
    {
      "epoch": 4.280398868879297,
      "grad_norm": 1.7420915365219116,
      "learning_rate": 1.164553920096125e-05,
      "logits/chosen": -0.06435136497020721,
      "logits/rejected": 0.05550485849380493,
      "logps/chosen": -339.5796203613281,
      "logps/rejected": -402.3083190917969,
      "loss": 0.0258,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.808853149414062,
      "rewards/margins": 7.645088195800781,
      "rewards/rejected": -22.45393943786621,
      "step": 14380
    },
    {
      "epoch": 4.283375502306891,
      "grad_norm": 0.7361541986465454,
      "learning_rate": 1.1597476719735657e-05,
      "logits/chosen": 0.07414649426937103,
      "logits/rejected": 0.02192586287856102,
      "logps/chosen": -311.1214904785156,
      "logps/rejected": -410.087646484375,
      "loss": 0.046,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.822491645812988,
      "rewards/margins": 8.264857292175293,
      "rewards/rejected": -23.08734703063965,
      "step": 14390
    },
    {
      "epoch": 4.286352135734484,
      "grad_norm": 17.895963668823242,
      "learning_rate": 1.1549414238510063e-05,
      "logits/chosen": 0.09178633987903595,
      "logits/rejected": 0.13458581268787384,
      "logps/chosen": -326.0909118652344,
      "logps/rejected": -401.99053955078125,
      "loss": 0.1085,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -15.732275009155273,
      "rewards/margins": 7.166363716125488,
      "rewards/rejected": -22.898639678955078,
      "step": 14400
    },
    {
      "epoch": 4.289328769162077,
      "grad_norm": 4.148769855499268,
      "learning_rate": 1.1501351757284471e-05,
      "logits/chosen": 0.21978648006916046,
      "logits/rejected": 0.12312088906764984,
      "logps/chosen": -312.4478454589844,
      "logps/rejected": -409.19207763671875,
      "loss": 0.0648,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.637725830078125,
      "rewards/margins": 7.139849662780762,
      "rewards/rejected": -22.777576446533203,
      "step": 14410
    },
    {
      "epoch": 4.292305402589671,
      "grad_norm": 7.134589672088623,
      "learning_rate": 1.1453289276058877e-05,
      "logits/chosen": 0.03337222337722778,
      "logits/rejected": -0.0034124315716326237,
      "logps/chosen": -348.9120178222656,
      "logps/rejected": -451.65191650390625,
      "loss": 0.0487,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -17.028438568115234,
      "rewards/margins": 8.10395336151123,
      "rewards/rejected": -25.13239288330078,
      "step": 14420
    },
    {
      "epoch": 4.295282036017264,
      "grad_norm": 18.80016326904297,
      "learning_rate": 1.1405226794833283e-05,
      "logits/chosen": 0.019482538104057312,
      "logits/rejected": 0.04394485801458359,
      "logps/chosen": -319.59033203125,
      "logps/rejected": -404.3717956542969,
      "loss": 0.0854,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -16.158836364746094,
      "rewards/margins": 7.309729099273682,
      "rewards/rejected": -23.468563079833984,
      "step": 14430
    },
    {
      "epoch": 4.2982586694448575,
      "grad_norm": 3.1445844173431396,
      "learning_rate": 1.1357164313607691e-05,
      "logits/chosen": -0.10197998583316803,
      "logits/rejected": 0.022137928754091263,
      "logps/chosen": -324.7605285644531,
      "logps/rejected": -398.0123596191406,
      "loss": 0.0312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.981033325195312,
      "rewards/margins": 7.346010684967041,
      "rewards/rejected": -22.327045440673828,
      "step": 14440
    },
    {
      "epoch": 4.301235302872451,
      "grad_norm": 2.834157943725586,
      "learning_rate": 1.1309101832382097e-05,
      "logits/chosen": -0.04379582777619362,
      "logits/rejected": 0.08259981125593185,
      "logps/chosen": -313.9544677734375,
      "logps/rejected": -388.7857971191406,
      "loss": 0.0392,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.20531177520752,
      "rewards/margins": 7.036216735839844,
      "rewards/rejected": -21.24152946472168,
      "step": 14450
    },
    {
      "epoch": 4.304211936300045,
      "grad_norm": 12.442970275878906,
      "learning_rate": 1.1261039351156505e-05,
      "logits/chosen": -0.03845871612429619,
      "logits/rejected": 0.11074433475732803,
      "logps/chosen": -317.6485290527344,
      "logps/rejected": -398.070556640625,
      "loss": 0.039,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.658723831176758,
      "rewards/margins": 7.704401969909668,
      "rewards/rejected": -21.36312484741211,
      "step": 14460
    },
    {
      "epoch": 4.307188569727638,
      "grad_norm": 4.766997337341309,
      "learning_rate": 1.1212976869930911e-05,
      "logits/chosen": 0.07705942541360855,
      "logits/rejected": 0.06769071519374847,
      "logps/chosen": -318.28436279296875,
      "logps/rejected": -398.4765930175781,
      "loss": 0.0323,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.51496410369873,
      "rewards/margins": 7.524204254150391,
      "rewards/rejected": -22.039165496826172,
      "step": 14470
    },
    {
      "epoch": 4.310165203155232,
      "grad_norm": 25.547746658325195,
      "learning_rate": 1.1164914388705317e-05,
      "logits/chosen": -0.02494898810982704,
      "logits/rejected": 0.035320669412612915,
      "logps/chosen": -334.79254150390625,
      "logps/rejected": -432.50323486328125,
      "loss": 0.0716,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -16.495403289794922,
      "rewards/margins": 7.935244560241699,
      "rewards/rejected": -24.430648803710938,
      "step": 14480
    },
    {
      "epoch": 4.313141836582825,
      "grad_norm": 0.7632997035980225,
      "learning_rate": 1.1116851907479725e-05,
      "logits/chosen": 0.0565299391746521,
      "logits/rejected": 0.02576022408902645,
      "logps/chosen": -324.2492370605469,
      "logps/rejected": -404.16778564453125,
      "loss": 0.0528,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.155462265014648,
      "rewards/margins": 7.451234340667725,
      "rewards/rejected": -21.6066951751709,
      "step": 14490
    },
    {
      "epoch": 4.3161184700104185,
      "grad_norm": 0.2927529513835907,
      "learning_rate": 1.1068789426254131e-05,
      "logits/chosen": 0.06528078019618988,
      "logits/rejected": -0.11521333456039429,
      "logps/chosen": -320.8961486816406,
      "logps/rejected": -419.6534118652344,
      "loss": 0.0736,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.037188529968262,
      "rewards/margins": 7.570883750915527,
      "rewards/rejected": -22.608074188232422,
      "step": 14500
    },
    {
      "epoch": 4.319095103438012,
      "grad_norm": 4.498998641967773,
      "learning_rate": 1.1020726945028537e-05,
      "logits/chosen": -0.13763412833213806,
      "logits/rejected": -0.12961316108703613,
      "logps/chosen": -337.4984130859375,
      "logps/rejected": -435.3926696777344,
      "loss": 0.031,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.370559692382812,
      "rewards/margins": 8.42341423034668,
      "rewards/rejected": -22.793973922729492,
      "step": 14510
    },
    {
      "epoch": 4.322071736865605,
      "grad_norm": 2.7363643646240234,
      "learning_rate": 1.0972664463802945e-05,
      "logits/chosen": -0.1319950968027115,
      "logits/rejected": 0.026136908680200577,
      "logps/chosen": -316.90087890625,
      "logps/rejected": -381.99407958984375,
      "loss": 0.0241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.155179977416992,
      "rewards/margins": 7.095845699310303,
      "rewards/rejected": -21.251028060913086,
      "step": 14520
    },
    {
      "epoch": 4.3250483702931986,
      "grad_norm": 0.7996686100959778,
      "learning_rate": 1.0924601982577351e-05,
      "logits/chosen": -0.032176125794649124,
      "logits/rejected": 0.022417714819312096,
      "logps/chosen": -330.5054931640625,
      "logps/rejected": -402.50982666015625,
      "loss": 0.0485,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.509969711303711,
      "rewards/margins": 7.420007228851318,
      "rewards/rejected": -21.929977416992188,
      "step": 14530
    },
    {
      "epoch": 4.328025003720792,
      "grad_norm": 12.336894035339355,
      "learning_rate": 1.0876539501351758e-05,
      "logits/chosen": 0.0947272926568985,
      "logits/rejected": 0.020353233441710472,
      "logps/chosen": -321.263427734375,
      "logps/rejected": -409.4587097167969,
      "loss": 0.0431,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -16.07311248779297,
      "rewards/margins": 7.590705871582031,
      "rewards/rejected": -23.663816452026367,
      "step": 14540
    },
    {
      "epoch": 4.331001637148385,
      "grad_norm": 2.792076826095581,
      "learning_rate": 1.0828477020126165e-05,
      "logits/chosen": -0.08007237315177917,
      "logits/rejected": -0.08317215740680695,
      "logps/chosen": -331.8755798339844,
      "logps/rejected": -426.3311462402344,
      "loss": 0.0278,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.438014030456543,
      "rewards/margins": 8.034296035766602,
      "rewards/rejected": -22.47231101989746,
      "step": 14550
    },
    {
      "epoch": 4.333978270575979,
      "grad_norm": 3.315859317779541,
      "learning_rate": 1.0780414538900572e-05,
      "logits/chosen": -0.03797844052314758,
      "logits/rejected": -0.16510355472564697,
      "logps/chosen": -330.00360107421875,
      "logps/rejected": -428.7607421875,
      "loss": 0.0655,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -15.855318069458008,
      "rewards/margins": 6.886984348297119,
      "rewards/rejected": -22.7423038482666,
      "step": 14560
    },
    {
      "epoch": 4.336954904003572,
      "grad_norm": 2.88071608543396,
      "learning_rate": 1.0732352057674978e-05,
      "logits/chosen": -0.2590371072292328,
      "logits/rejected": -0.08248431980609894,
      "logps/chosen": -295.98577880859375,
      "logps/rejected": -368.92462158203125,
      "loss": 0.0411,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.071779251098633,
      "rewards/margins": 6.877976894378662,
      "rewards/rejected": -18.949756622314453,
      "step": 14570
    },
    {
      "epoch": 4.339931537431165,
      "grad_norm": 5.152494430541992,
      "learning_rate": 1.0684289576449386e-05,
      "logits/chosen": -0.18446946144104004,
      "logits/rejected": -0.2171630561351776,
      "logps/chosen": -317.47576904296875,
      "logps/rejected": -390.963134765625,
      "loss": 0.0448,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.210718154907227,
      "rewards/margins": 6.91922664642334,
      "rewards/rejected": -21.12994384765625,
      "step": 14580
    },
    {
      "epoch": 4.342908170858759,
      "grad_norm": 23.9457950592041,
      "learning_rate": 1.0636227095223792e-05,
      "logits/chosen": -0.15199697017669678,
      "logits/rejected": -0.12039986997842789,
      "logps/chosen": -309.63958740234375,
      "logps/rejected": -376.6270446777344,
      "loss": 0.0792,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.392033576965332,
      "rewards/margins": 6.7399001121521,
      "rewards/rejected": -21.13193130493164,
      "step": 14590
    },
    {
      "epoch": 4.345884804286352,
      "grad_norm": 1.9315533638000488,
      "learning_rate": 1.0588164613998198e-05,
      "logits/chosen": -0.00037420092849060893,
      "logits/rejected": -0.13792705535888672,
      "logps/chosen": -311.3768310546875,
      "logps/rejected": -406.69097900390625,
      "loss": 0.0347,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.67924690246582,
      "rewards/margins": 7.615908145904541,
      "rewards/rejected": -22.29515266418457,
      "step": 14600
    },
    {
      "epoch": 4.348861437713945,
      "grad_norm": 0.44146499037742615,
      "learning_rate": 1.0540102132772606e-05,
      "logits/chosen": -0.11877932399511337,
      "logits/rejected": -0.08553443104028702,
      "logps/chosen": -323.7688293457031,
      "logps/rejected": -407.16986083984375,
      "loss": 0.0143,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.09301471710205,
      "rewards/margins": 7.972052097320557,
      "rewards/rejected": -23.065067291259766,
      "step": 14610
    },
    {
      "epoch": 4.351838071141539,
      "grad_norm": 5.3754658699035645,
      "learning_rate": 1.0492039651547012e-05,
      "logits/chosen": -0.04551312327384949,
      "logits/rejected": 0.1440681517124176,
      "logps/chosen": -317.80950927734375,
      "logps/rejected": -381.82489013671875,
      "loss": 0.0639,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.438130378723145,
      "rewards/margins": 7.073912143707275,
      "rewards/rejected": -21.512042999267578,
      "step": 14620
    },
    {
      "epoch": 4.354814704569132,
      "grad_norm": 0.6310390830039978,
      "learning_rate": 1.0443977170321418e-05,
      "logits/chosen": -0.1713857352733612,
      "logits/rejected": -0.07435698807239532,
      "logps/chosen": -312.42926025390625,
      "logps/rejected": -380.1828308105469,
      "loss": 0.1965,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -13.916131973266602,
      "rewards/margins": 6.8875603675842285,
      "rewards/rejected": -20.803691864013672,
      "step": 14630
    },
    {
      "epoch": 4.3577913379967255,
      "grad_norm": 7.5252203941345215,
      "learning_rate": 1.0395914689095826e-05,
      "logits/chosen": -0.10526403039693832,
      "logits/rejected": -0.15875408053398132,
      "logps/chosen": -291.90020751953125,
      "logps/rejected": -390.2002868652344,
      "loss": 0.0176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.55285358428955,
      "rewards/margins": 8.095240592956543,
      "rewards/rejected": -20.648096084594727,
      "step": 14640
    },
    {
      "epoch": 4.360767971424319,
      "grad_norm": 0.22744427621364594,
      "learning_rate": 1.0347852207870232e-05,
      "logits/chosen": 0.05386839061975479,
      "logits/rejected": -0.0430745966732502,
      "logps/chosen": -309.6336364746094,
      "logps/rejected": -384.49102783203125,
      "loss": 0.0536,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.389653205871582,
      "rewards/margins": 6.809770107269287,
      "rewards/rejected": -21.199426651000977,
      "step": 14650
    },
    {
      "epoch": 4.363744604851912,
      "grad_norm": 5.613674163818359,
      "learning_rate": 1.0299789726644638e-05,
      "logits/chosen": -0.1061156764626503,
      "logits/rejected": -0.14415526390075684,
      "logps/chosen": -314.65191650390625,
      "logps/rejected": -386.38922119140625,
      "loss": 0.049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.784527778625488,
      "rewards/margins": 6.177420616149902,
      "rewards/rejected": -20.96194839477539,
      "step": 14660
    },
    {
      "epoch": 4.3667212382795055,
      "grad_norm": 1.7814738750457764,
      "learning_rate": 1.0251727245419046e-05,
      "logits/chosen": -0.02408858947455883,
      "logits/rejected": -0.21746547520160675,
      "logps/chosen": -310.9947814941406,
      "logps/rejected": -422.2220153808594,
      "loss": 0.0474,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.162808418273926,
      "rewards/margins": 7.587411403656006,
      "rewards/rejected": -21.750219345092773,
      "step": 14670
    },
    {
      "epoch": 4.369697871707099,
      "grad_norm": 0.3995250463485718,
      "learning_rate": 1.0203664764193452e-05,
      "logits/chosen": -0.07512646168470383,
      "logits/rejected": -0.04175148159265518,
      "logps/chosen": -299.84796142578125,
      "logps/rejected": -386.1331787109375,
      "loss": 0.0714,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.893010139465332,
      "rewards/margins": 7.735793113708496,
      "rewards/rejected": -21.628801345825195,
      "step": 14680
    },
    {
      "epoch": 4.372674505134692,
      "grad_norm": 1.411297082901001,
      "learning_rate": 1.0155602282967858e-05,
      "logits/chosen": -0.1231861487030983,
      "logits/rejected": -0.19127744436264038,
      "logps/chosen": -330.941162109375,
      "logps/rejected": -414.3148498535156,
      "loss": 0.1072,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.12980842590332,
      "rewards/margins": 7.347788333892822,
      "rewards/rejected": -22.477596282958984,
      "step": 14690
    },
    {
      "epoch": 4.3756511385622865,
      "grad_norm": 1.0709221363067627,
      "learning_rate": 1.0107539801742266e-05,
      "logits/chosen": 0.042951662093400955,
      "logits/rejected": -0.07499320805072784,
      "logps/chosen": -302.71527099609375,
      "logps/rejected": -396.38360595703125,
      "loss": 0.0327,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.581550598144531,
      "rewards/margins": 8.094897270202637,
      "rewards/rejected": -21.676448822021484,
      "step": 14700
    },
    {
      "epoch": 4.37862777198988,
      "grad_norm": 1.555583119392395,
      "learning_rate": 1.0059477320516672e-05,
      "logits/chosen": 0.04843846708536148,
      "logits/rejected": -0.012551039457321167,
      "logps/chosen": -317.3291931152344,
      "logps/rejected": -393.8180236816406,
      "loss": 0.0832,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -14.460199356079102,
      "rewards/margins": 6.953392028808594,
      "rewards/rejected": -21.413589477539062,
      "step": 14710
    },
    {
      "epoch": 4.381604405417473,
      "grad_norm": 9.410045623779297,
      "learning_rate": 1.0011414839291078e-05,
      "logits/chosen": -0.14578115940093994,
      "logits/rejected": -0.09704269468784332,
      "logps/chosen": -306.7359313964844,
      "logps/rejected": -385.6329040527344,
      "loss": 0.0428,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.610735893249512,
      "rewards/margins": 7.241526126861572,
      "rewards/rejected": -20.85226058959961,
      "step": 14720
    },
    {
      "epoch": 4.384581038845067,
      "grad_norm": 4.70364236831665,
      "learning_rate": 9.963352358065486e-06,
      "logits/chosen": -0.07382277399301529,
      "logits/rejected": -0.011282898485660553,
      "logps/chosen": -269.99761962890625,
      "logps/rejected": -356.31683349609375,
      "loss": 0.0362,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -11.5618896484375,
      "rewards/margins": 7.1013946533203125,
      "rewards/rejected": -18.663286209106445,
      "step": 14730
    },
    {
      "epoch": 4.38755767227266,
      "grad_norm": 3.3508410453796387,
      "learning_rate": 9.915289876839892e-06,
      "logits/chosen": -0.22009940445423126,
      "logits/rejected": -0.12135963141918182,
      "logps/chosen": -315.2729797363281,
      "logps/rejected": -390.24237060546875,
      "loss": 0.0542,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.934698104858398,
      "rewards/margins": 7.256396293640137,
      "rewards/rejected": -21.19109535217285,
      "step": 14740
    },
    {
      "epoch": 4.390534305700253,
      "grad_norm": 3.6356658935546875,
      "learning_rate": 9.8672273956143e-06,
      "logits/chosen": -0.10219462215900421,
      "logits/rejected": -0.24897341430187225,
      "logps/chosen": -300.0135498046875,
      "logps/rejected": -381.1020812988281,
      "loss": 0.1234,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.672743797302246,
      "rewards/margins": 6.858506679534912,
      "rewards/rejected": -19.53125,
      "step": 14750
    },
    {
      "epoch": 4.393510939127847,
      "grad_norm": 9.009610176086426,
      "learning_rate": 9.819164914388706e-06,
      "logits/chosen": -0.1308150738477707,
      "logits/rejected": -0.1486281007528305,
      "logps/chosen": -315.35052490234375,
      "logps/rejected": -406.98431396484375,
      "loss": 0.0553,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.813117980957031,
      "rewards/margins": 7.9704790115356445,
      "rewards/rejected": -21.783594131469727,
      "step": 14760
    },
    {
      "epoch": 4.39648757255544,
      "grad_norm": 2.5540473461151123,
      "learning_rate": 9.771102433163112e-06,
      "logits/chosen": -0.02683860994875431,
      "logits/rejected": -0.08180222660303116,
      "logps/chosen": -319.7275695800781,
      "logps/rejected": -413.2919006347656,
      "loss": 0.036,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.640957832336426,
      "rewards/margins": 7.981403350830078,
      "rewards/rejected": -23.62236213684082,
      "step": 14770
    },
    {
      "epoch": 4.399464205983033,
      "grad_norm": 2.276712656021118,
      "learning_rate": 9.72303995193752e-06,
      "logits/chosen": -0.044537849724292755,
      "logits/rejected": -0.18782472610473633,
      "logps/chosen": -310.90740966796875,
      "logps/rejected": -397.16143798828125,
      "loss": 0.1456,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.356493949890137,
      "rewards/margins": 7.14923620223999,
      "rewards/rejected": -21.5057315826416,
      "step": 14780
    },
    {
      "epoch": 4.402440839410627,
      "grad_norm": 12.43993091583252,
      "learning_rate": 9.674977470711926e-06,
      "logits/chosen": -0.05626703053712845,
      "logits/rejected": -0.06739144027233124,
      "logps/chosen": -324.17340087890625,
      "logps/rejected": -405.69940185546875,
      "loss": 0.0394,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.838976860046387,
      "rewards/margins": 7.178593635559082,
      "rewards/rejected": -22.01757049560547,
      "step": 14790
    },
    {
      "epoch": 4.40541747283822,
      "grad_norm": 1.9360105991363525,
      "learning_rate": 9.626914989486333e-06,
      "logits/chosen": -0.16985270380973816,
      "logits/rejected": -0.05531694367527962,
      "logps/chosen": -298.57958984375,
      "logps/rejected": -391.47076416015625,
      "loss": 0.0471,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.712697982788086,
      "rewards/margins": 8.47767448425293,
      "rewards/rejected": -21.19037437438965,
      "step": 14800
    },
    {
      "epoch": 4.408394106265813,
      "grad_norm": 1.312328577041626,
      "learning_rate": 9.57885250826074e-06,
      "logits/chosen": 0.019229020923376083,
      "logits/rejected": -0.09854540973901749,
      "logps/chosen": -334.5881652832031,
      "logps/rejected": -431.958740234375,
      "loss": 0.0215,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.770009994506836,
      "rewards/margins": 8.352557182312012,
      "rewards/rejected": -24.12256622314453,
      "step": 14810
    },
    {
      "epoch": 4.411370739693407,
      "grad_norm": 1.5299559831619263,
      "learning_rate": 9.530790027035147e-06,
      "logits/chosen": -0.024922218173742294,
      "logits/rejected": 0.04918528348207474,
      "logps/chosen": -314.4278869628906,
      "logps/rejected": -393.7703552246094,
      "loss": 0.0645,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.15869426727295,
      "rewards/margins": 7.266242027282715,
      "rewards/rejected": -22.424936294555664,
      "step": 14820
    },
    {
      "epoch": 4.414347373121,
      "grad_norm": 13.121115684509277,
      "learning_rate": 9.482727545809553e-06,
      "logits/chosen": -0.17204847931861877,
      "logits/rejected": -0.058805935084819794,
      "logps/chosen": -319.0626525878906,
      "logps/rejected": -394.4820556640625,
      "loss": 0.0383,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.854814529418945,
      "rewards/margins": 7.611808776855469,
      "rewards/rejected": -22.466623306274414,
      "step": 14830
    },
    {
      "epoch": 4.4173240065485935,
      "grad_norm": 0.23867282271385193,
      "learning_rate": 9.43466506458396e-06,
      "logits/chosen": 0.07640168815851212,
      "logits/rejected": -0.07229633629322052,
      "logps/chosen": -328.8840026855469,
      "logps/rejected": -414.4075622558594,
      "loss": 0.1356,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -16.20465660095215,
      "rewards/margins": 6.833010673522949,
      "rewards/rejected": -23.037668228149414,
      "step": 14840
    },
    {
      "epoch": 4.420300639976187,
      "grad_norm": 9.522229194641113,
      "learning_rate": 9.386602583358367e-06,
      "logits/chosen": 0.032526981085538864,
      "logits/rejected": -0.039993517100811005,
      "logps/chosen": -312.71807861328125,
      "logps/rejected": -409.78790283203125,
      "loss": 0.0346,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.027112007141113,
      "rewards/margins": 7.6161956787109375,
      "rewards/rejected": -22.643308639526367,
      "step": 14850
    },
    {
      "epoch": 4.42327727340378,
      "grad_norm": 6.411500930786133,
      "learning_rate": 9.338540102132775e-06,
      "logits/chosen": -0.09457068890333176,
      "logits/rejected": 0.005325221922248602,
      "logps/chosen": -313.02203369140625,
      "logps/rejected": -388.42236328125,
      "loss": 0.0384,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.132074356079102,
      "rewards/margins": 7.547501564025879,
      "rewards/rejected": -21.67957305908203,
      "step": 14860
    },
    {
      "epoch": 4.4262539068313735,
      "grad_norm": 1.7851439714431763,
      "learning_rate": 9.29047762090718e-06,
      "logits/chosen": -0.4049568772315979,
      "logits/rejected": -0.28744474053382874,
      "logps/chosen": -305.1517639160156,
      "logps/rejected": -369.82501220703125,
      "loss": 0.0237,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.527238845825195,
      "rewards/margins": 6.82354211807251,
      "rewards/rejected": -19.350780487060547,
      "step": 14870
    },
    {
      "epoch": 4.429230540258967,
      "grad_norm": 2.13568115234375,
      "learning_rate": 9.242415139681587e-06,
      "logits/chosen": 0.011168072000145912,
      "logits/rejected": -0.044179972261190414,
      "logps/chosen": -301.73223876953125,
      "logps/rejected": -380.4783630371094,
      "loss": 0.0686,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.492507934570312,
      "rewards/margins": 6.732395172119141,
      "rewards/rejected": -20.224903106689453,
      "step": 14880
    },
    {
      "epoch": 4.43220717368656,
      "grad_norm": 0.9751837253570557,
      "learning_rate": 9.194352658455995e-06,
      "logits/chosen": -0.04586218670010567,
      "logits/rejected": -0.13525739312171936,
      "logps/chosen": -305.2554016113281,
      "logps/rejected": -386.9845275878906,
      "loss": 0.0167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.643720626831055,
      "rewards/margins": 7.825894832611084,
      "rewards/rejected": -21.469615936279297,
      "step": 14890
    },
    {
      "epoch": 4.435183807114154,
      "grad_norm": 17.333786010742188,
      "learning_rate": 9.1462901772304e-06,
      "logits/chosen": -0.11499346792697906,
      "logits/rejected": 0.01931067183613777,
      "logps/chosen": -306.9247131347656,
      "logps/rejected": -377.7212219238281,
      "loss": 0.079,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.672150611877441,
      "rewards/margins": 7.150973320007324,
      "rewards/rejected": -19.8231258392334,
      "step": 14900
    },
    {
      "epoch": 4.438160440541747,
      "grad_norm": 2.835932493209839,
      "learning_rate": 9.098227696004807e-06,
      "logits/chosen": -0.07112325727939606,
      "logits/rejected": -0.2188471555709839,
      "logps/chosen": -296.904296875,
      "logps/rejected": -383.2823181152344,
      "loss": 0.0799,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.32043743133545,
      "rewards/margins": 7.167552947998047,
      "rewards/rejected": -20.487987518310547,
      "step": 14910
    },
    {
      "epoch": 4.44113707396934,
      "grad_norm": 3.2048330307006836,
      "learning_rate": 9.050165214779215e-06,
      "logits/chosen": -0.040467001497745514,
      "logits/rejected": -0.1047203540802002,
      "logps/chosen": -329.54119873046875,
      "logps/rejected": -439.24005126953125,
      "loss": 0.0223,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.53471565246582,
      "rewards/margins": 9.456633567810059,
      "rewards/rejected": -23.991350173950195,
      "step": 14920
    },
    {
      "epoch": 4.444113707396934,
      "grad_norm": 0.296957790851593,
      "learning_rate": 9.002102733553621e-06,
      "logits/chosen": -0.23449096083641052,
      "logits/rejected": -0.16718704998493195,
      "logps/chosen": -305.0307922363281,
      "logps/rejected": -384.2018737792969,
      "loss": 0.0614,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -13.211931228637695,
      "rewards/margins": 7.0976715087890625,
      "rewards/rejected": -20.309600830078125,
      "step": 14930
    },
    {
      "epoch": 4.447090340824527,
      "grad_norm": 0.4484941065311432,
      "learning_rate": 8.954040252328027e-06,
      "logits/chosen": -0.0924840196967125,
      "logits/rejected": -0.0794234499335289,
      "logps/chosen": -300.5138244628906,
      "logps/rejected": -369.62481689453125,
      "loss": 0.075,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -13.515400886535645,
      "rewards/margins": 6.128405570983887,
      "rewards/rejected": -19.643808364868164,
      "step": 14940
    },
    {
      "epoch": 4.45006697425212,
      "grad_norm": 0.7991517186164856,
      "learning_rate": 8.905977771102435e-06,
      "logits/chosen": 0.032275013625621796,
      "logits/rejected": -0.05796214938163757,
      "logps/chosen": -322.1551818847656,
      "logps/rejected": -395.5710754394531,
      "loss": 0.1176,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.320752143859863,
      "rewards/margins": 6.749194145202637,
      "rewards/rejected": -22.0699462890625,
      "step": 14950
    },
    {
      "epoch": 4.453043607679715,
      "grad_norm": 0.7099012136459351,
      "learning_rate": 8.857915289876841e-06,
      "logits/chosen": -0.09695224463939667,
      "logits/rejected": -0.08576998859643936,
      "logps/chosen": -321.274658203125,
      "logps/rejected": -411.75244140625,
      "loss": 0.0755,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.403923034667969,
      "rewards/margins": 8.278629302978516,
      "rewards/rejected": -22.682552337646484,
      "step": 14960
    },
    {
      "epoch": 4.456020241107308,
      "grad_norm": 6.896656513214111,
      "learning_rate": 8.809852808651247e-06,
      "logits/chosen": 0.035221170634031296,
      "logits/rejected": -0.07917213439941406,
      "logps/chosen": -313.9273986816406,
      "logps/rejected": -404.56591796875,
      "loss": 0.0246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.53583812713623,
      "rewards/margins": 7.799205780029297,
      "rewards/rejected": -22.335044860839844,
      "step": 14970
    },
    {
      "epoch": 4.458996874534901,
      "grad_norm": 8.878471374511719,
      "learning_rate": 8.761790327425655e-06,
      "logits/chosen": -0.1695970594882965,
      "logits/rejected": 0.023554839193820953,
      "logps/chosen": -315.60406494140625,
      "logps/rejected": -392.92926025390625,
      "loss": 0.1018,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -13.861351013183594,
      "rewards/margins": 7.845513820648193,
      "rewards/rejected": -21.706863403320312,
      "step": 14980
    },
    {
      "epoch": 4.461973507962495,
      "grad_norm": 0.26325640082359314,
      "learning_rate": 8.713727846200061e-06,
      "logits/chosen": 0.03205827623605728,
      "logits/rejected": -0.005350255873054266,
      "logps/chosen": -294.1886291503906,
      "logps/rejected": -371.9220886230469,
      "loss": 0.0391,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.111268997192383,
      "rewards/margins": 7.220536708831787,
      "rewards/rejected": -20.331804275512695,
      "step": 14990
    },
    {
      "epoch": 4.464950141390088,
      "grad_norm": 1.3031914234161377,
      "learning_rate": 8.665665364974467e-06,
      "logits/chosen": 0.03590866178274155,
      "logits/rejected": -0.02069568634033203,
      "logps/chosen": -300.7066955566406,
      "logps/rejected": -403.9918518066406,
      "loss": 0.0531,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.215721130371094,
      "rewards/margins": 8.109519958496094,
      "rewards/rejected": -22.32524299621582,
      "step": 15000
    },
    {
      "epoch": 4.467926774817681,
      "grad_norm": 0.6391630172729492,
      "learning_rate": 8.617602883748875e-06,
      "logits/chosen": -0.003300689160823822,
      "logits/rejected": 0.04486153647303581,
      "logps/chosen": -317.6682434082031,
      "logps/rejected": -393.540771484375,
      "loss": 0.1156,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.437910079956055,
      "rewards/margins": 6.914848327636719,
      "rewards/rejected": -21.35276222229004,
      "step": 15010
    },
    {
      "epoch": 4.470903408245275,
      "grad_norm": 1.4319297075271606,
      "learning_rate": 8.569540402523281e-06,
      "logits/chosen": -0.028973538428544998,
      "logits/rejected": -0.18725916743278503,
      "logps/chosen": -323.34466552734375,
      "logps/rejected": -410.4708557128906,
      "loss": 0.0489,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.609636306762695,
      "rewards/margins": 6.938736915588379,
      "rewards/rejected": -21.54837417602539,
      "step": 15020
    },
    {
      "epoch": 4.473880041672868,
      "grad_norm": 38.270545959472656,
      "learning_rate": 8.521477921297688e-06,
      "logits/chosen": -0.07612196356058121,
      "logits/rejected": -0.16737060248851776,
      "logps/chosen": -305.172119140625,
      "logps/rejected": -380.53509521484375,
      "loss": 0.0672,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.472569465637207,
      "rewards/margins": 6.909586429595947,
      "rewards/rejected": -20.38215446472168,
      "step": 15030
    },
    {
      "epoch": 4.4768566751004615,
      "grad_norm": 0.1820201277732849,
      "learning_rate": 8.473415440072095e-06,
      "logits/chosen": -0.13309749960899353,
      "logits/rejected": -0.09549710899591446,
      "logps/chosen": -287.4644470214844,
      "logps/rejected": -368.66680908203125,
      "loss": 0.0446,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.894014358520508,
      "rewards/margins": 7.417515754699707,
      "rewards/rejected": -19.31153106689453,
      "step": 15040
    },
    {
      "epoch": 4.479833308528055,
      "grad_norm": 0.3520403802394867,
      "learning_rate": 8.425352958846502e-06,
      "logits/chosen": -0.04035649821162224,
      "logits/rejected": -0.023787496611475945,
      "logps/chosen": -306.7478942871094,
      "logps/rejected": -384.30804443359375,
      "loss": 0.0504,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.872385025024414,
      "rewards/margins": 7.4064531326293945,
      "rewards/rejected": -21.278837203979492,
      "step": 15050
    },
    {
      "epoch": 4.482809941955648,
      "grad_norm": 11.767663955688477,
      "learning_rate": 8.377290477620908e-06,
      "logits/chosen": -0.13397268950939178,
      "logits/rejected": -0.01808829978108406,
      "logps/chosen": -325.44329833984375,
      "logps/rejected": -390.33880615234375,
      "loss": 0.0408,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.108163833618164,
      "rewards/margins": 7.4318952560424805,
      "rewards/rejected": -21.540058135986328,
      "step": 15060
    },
    {
      "epoch": 4.4857865753832415,
      "grad_norm": 9.572033882141113,
      "learning_rate": 8.329227996395316e-06,
      "logits/chosen": -0.20786356925964355,
      "logits/rejected": -0.030082162469625473,
      "logps/chosen": -328.1344299316406,
      "logps/rejected": -374.35223388671875,
      "loss": 0.0582,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.3788423538208,
      "rewards/margins": 6.6943159103393555,
      "rewards/rejected": -20.073158264160156,
      "step": 15070
    },
    {
      "epoch": 4.488763208810835,
      "grad_norm": 1.7203720808029175,
      "learning_rate": 8.281165515169722e-06,
      "logits/chosen": -0.26398640871047974,
      "logits/rejected": -0.12068724632263184,
      "logps/chosen": -324.78515625,
      "logps/rejected": -402.5641174316406,
      "loss": 0.0447,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.285733222961426,
      "rewards/margins": 7.308680057525635,
      "rewards/rejected": -21.59441566467285,
      "step": 15080
    },
    {
      "epoch": 4.491739842238428,
      "grad_norm": 9.738035202026367,
      "learning_rate": 8.233103033944128e-06,
      "logits/chosen": -0.054626792669296265,
      "logits/rejected": -0.069856658577919,
      "logps/chosen": -322.4873046875,
      "logps/rejected": -412.94158935546875,
      "loss": 0.0698,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.83647346496582,
      "rewards/margins": 7.777104377746582,
      "rewards/rejected": -22.613576889038086,
      "step": 15090
    },
    {
      "epoch": 4.494716475666022,
      "grad_norm": 0.6785499453544617,
      "learning_rate": 8.185040552718536e-06,
      "logits/chosen": -0.12585750222206116,
      "logits/rejected": -0.22809863090515137,
      "logps/chosen": -331.5284729003906,
      "logps/rejected": -399.2815246582031,
      "loss": 0.0514,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.47288990020752,
      "rewards/margins": 6.270891189575195,
      "rewards/rejected": -21.7437801361084,
      "step": 15100
    },
    {
      "epoch": 4.497693109093615,
      "grad_norm": 0.28913557529449463,
      "learning_rate": 8.136978071492942e-06,
      "logits/chosen": -0.1509358137845993,
      "logits/rejected": -0.04565753787755966,
      "logps/chosen": -318.15228271484375,
      "logps/rejected": -383.69537353515625,
      "loss": 0.0598,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.3703031539917,
      "rewards/margins": 6.602755069732666,
      "rewards/rejected": -20.97305679321289,
      "step": 15110
    },
    {
      "epoch": 4.500669742521208,
      "grad_norm": 1.6225931644439697,
      "learning_rate": 8.088915590267348e-06,
      "logits/chosen": -0.07027573883533478,
      "logits/rejected": 0.10706102848052979,
      "logps/chosen": -288.35302734375,
      "logps/rejected": -359.3031311035156,
      "loss": 0.0393,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.5133056640625,
      "rewards/margins": 7.186968803405762,
      "rewards/rejected": -19.700275421142578,
      "step": 15120
    },
    {
      "epoch": 4.503646375948802,
      "grad_norm": 3.8280510902404785,
      "learning_rate": 8.040853109041756e-06,
      "logits/chosen": -0.04496952146291733,
      "logits/rejected": 0.02819501981139183,
      "logps/chosen": -329.0525817871094,
      "logps/rejected": -401.9598693847656,
      "loss": 0.1379,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -14.838129043579102,
      "rewards/margins": 6.881065368652344,
      "rewards/rejected": -21.719196319580078,
      "step": 15130
    },
    {
      "epoch": 4.506623009376395,
      "grad_norm": 7.21602201461792,
      "learning_rate": 7.992790627816162e-06,
      "logits/chosen": 0.10613157600164413,
      "logits/rejected": 0.07071749866008759,
      "logps/chosen": -316.8213806152344,
      "logps/rejected": -404.31304931640625,
      "loss": 0.0355,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.312774658203125,
      "rewards/margins": 7.264962673187256,
      "rewards/rejected": -22.57773780822754,
      "step": 15140
    },
    {
      "epoch": 4.509599642803988,
      "grad_norm": 5.496248245239258,
      "learning_rate": 7.944728146590568e-06,
      "logits/chosen": -0.026491478085517883,
      "logits/rejected": 0.17917069792747498,
      "logps/chosen": -308.47119140625,
      "logps/rejected": -379.7694396972656,
      "loss": 0.0488,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.499259948730469,
      "rewards/margins": 7.284173488616943,
      "rewards/rejected": -20.78343391418457,
      "step": 15150
    },
    {
      "epoch": 4.512576276231582,
      "grad_norm": 10.657976150512695,
      "learning_rate": 7.896665665364976e-06,
      "logits/chosen": -0.07899106293916702,
      "logits/rejected": 0.0691709965467453,
      "logps/chosen": -299.3150939941406,
      "logps/rejected": -368.50848388671875,
      "loss": 0.0327,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.012901306152344,
      "rewards/margins": 6.9295654296875,
      "rewards/rejected": -19.942466735839844,
      "step": 15160
    },
    {
      "epoch": 4.515552909659175,
      "grad_norm": 7.269739151000977,
      "learning_rate": 7.848603184139382e-06,
      "logits/chosen": -0.06745810806751251,
      "logits/rejected": -0.19980403780937195,
      "logps/chosen": -324.3359069824219,
      "logps/rejected": -412.32366943359375,
      "loss": 0.0995,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.190381050109863,
      "rewards/margins": 7.56960916519165,
      "rewards/rejected": -21.759990692138672,
      "step": 15170
    },
    {
      "epoch": 4.518529543086769,
      "grad_norm": 0.9852597713470459,
      "learning_rate": 7.800540702913788e-06,
      "logits/chosen": 0.09734421223402023,
      "logits/rejected": 0.1915593147277832,
      "logps/chosen": -319.43463134765625,
      "logps/rejected": -390.1156921386719,
      "loss": 0.0683,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -14.083788871765137,
      "rewards/margins": 7.332723140716553,
      "rewards/rejected": -21.41651153564453,
      "step": 15180
    },
    {
      "epoch": 4.521506176514363,
      "grad_norm": 13.218377113342285,
      "learning_rate": 7.752478221688196e-06,
      "logits/chosen": 0.12331481277942657,
      "logits/rejected": -9.277164645027369e-05,
      "logps/chosen": -340.13275146484375,
      "logps/rejected": -423.01666259765625,
      "loss": 0.1071,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -15.751261711120605,
      "rewards/margins": 7.166747093200684,
      "rewards/rejected": -22.918006896972656,
      "step": 15190
    },
    {
      "epoch": 4.524482809941956,
      "grad_norm": 8.920612335205078,
      "learning_rate": 7.704415740462602e-06,
      "logits/chosen": 0.04485728219151497,
      "logits/rejected": 0.013277098536491394,
      "logps/chosen": -329.3814697265625,
      "logps/rejected": -413.0975036621094,
      "loss": 0.0758,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.485334396362305,
      "rewards/margins": 6.928365230560303,
      "rewards/rejected": -22.413700103759766,
      "step": 15200
    },
    {
      "epoch": 4.527459443369549,
      "grad_norm": 0.9185543060302734,
      "learning_rate": 7.656353259237008e-06,
      "logits/chosen": -0.04153502732515335,
      "logits/rejected": -0.050137173384428024,
      "logps/chosen": -316.00689697265625,
      "logps/rejected": -400.05584716796875,
      "loss": 0.1176,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -14.621830940246582,
      "rewards/margins": 7.072731018066406,
      "rewards/rejected": -21.694561004638672,
      "step": 15210
    },
    {
      "epoch": 4.530436076797143,
      "grad_norm": 11.80682373046875,
      "learning_rate": 7.608290778011415e-06,
      "logits/chosen": -0.044571779668331146,
      "logits/rejected": 0.02739517018198967,
      "logps/chosen": -284.772705078125,
      "logps/rejected": -352.6110534667969,
      "loss": 0.057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.082330703735352,
      "rewards/margins": 6.309073448181152,
      "rewards/rejected": -18.391403198242188,
      "step": 15220
    },
    {
      "epoch": 4.533412710224736,
      "grad_norm": 11.396662712097168,
      "learning_rate": 7.560228296785822e-06,
      "logits/chosen": -0.13869993388652802,
      "logits/rejected": -0.06948326528072357,
      "logps/chosen": -286.9961853027344,
      "logps/rejected": -354.66058349609375,
      "loss": 0.1236,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -12.227668762207031,
      "rewards/margins": 6.822070121765137,
      "rewards/rejected": -19.04973793029785,
      "step": 15230
    },
    {
      "epoch": 4.5363893436523295,
      "grad_norm": 1.4958000183105469,
      "learning_rate": 7.5121658155602285e-06,
      "logits/chosen": -0.1768791675567627,
      "logits/rejected": -0.1819627285003662,
      "logps/chosen": -320.76104736328125,
      "logps/rejected": -403.55340576171875,
      "loss": 0.0319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.220919609069824,
      "rewards/margins": 7.823065757751465,
      "rewards/rejected": -21.04398536682129,
      "step": 15240
    },
    {
      "epoch": 4.539365977079923,
      "grad_norm": 3.3290414810180664,
      "learning_rate": 7.4641033343346355e-06,
      "logits/chosen": -0.09539216011762619,
      "logits/rejected": -0.09877710044384003,
      "logps/chosen": -295.17425537109375,
      "logps/rejected": -365.05523681640625,
      "loss": 0.0473,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.283172607421875,
      "rewards/margins": 7.018914222717285,
      "rewards/rejected": -19.302085876464844,
      "step": 15250
    },
    {
      "epoch": 4.542342610507516,
      "grad_norm": 3.3001489639282227,
      "learning_rate": 7.4160408531090425e-06,
      "logits/chosen": -0.17809461057186127,
      "logits/rejected": -0.14412912726402283,
      "logps/chosen": -279.3216247558594,
      "logps/rejected": -356.6000671386719,
      "loss": 0.0642,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -11.51823902130127,
      "rewards/margins": 7.169491767883301,
      "rewards/rejected": -18.68773078918457,
      "step": 15260
    },
    {
      "epoch": 4.5453192439351096,
      "grad_norm": 0.7253117561340332,
      "learning_rate": 7.367978371883449e-06,
      "logits/chosen": -0.04124560207128525,
      "logits/rejected": -0.007679869420826435,
      "logps/chosen": -296.7055969238281,
      "logps/rejected": -370.23394775390625,
      "loss": 0.0602,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.759953498840332,
      "rewards/margins": 7.401422023773193,
      "rewards/rejected": -20.161373138427734,
      "step": 15270
    },
    {
      "epoch": 4.548295877362703,
      "grad_norm": 5.88752555847168,
      "learning_rate": 7.319915890657856e-06,
      "logits/chosen": 0.035624910145998,
      "logits/rejected": -0.04823562502861023,
      "logps/chosen": -306.16241455078125,
      "logps/rejected": -397.25811767578125,
      "loss": 0.0645,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.847539901733398,
      "rewards/margins": 7.565598964691162,
      "rewards/rejected": -21.41314125061035,
      "step": 15280
    },
    {
      "epoch": 4.551272510790296,
      "grad_norm": 11.383545875549316,
      "learning_rate": 7.271853409432263e-06,
      "logits/chosen": 0.09219950437545776,
      "logits/rejected": -0.07308326661586761,
      "logps/chosen": -313.42694091796875,
      "logps/rejected": -409.1557922363281,
      "loss": 0.0497,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.819040298461914,
      "rewards/margins": 6.8756818771362305,
      "rewards/rejected": -21.69472312927246,
      "step": 15290
    },
    {
      "epoch": 4.55424914421789,
      "grad_norm": 0.9172811508178711,
      "learning_rate": 7.223790928206669e-06,
      "logits/chosen": -0.09798810631036758,
      "logits/rejected": 0.03722792863845825,
      "logps/chosen": -294.2157287597656,
      "logps/rejected": -362.660888671875,
      "loss": 0.0189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.155621528625488,
      "rewards/margins": 7.617203712463379,
      "rewards/rejected": -19.772823333740234,
      "step": 15300
    },
    {
      "epoch": 4.557225777645483,
      "grad_norm": 1.0319997072219849,
      "learning_rate": 7.1757284469810766e-06,
      "logits/chosen": -0.12285039573907852,
      "logits/rejected": -0.10149961709976196,
      "logps/chosen": -341.24237060546875,
      "logps/rejected": -432.55645751953125,
      "loss": 0.0289,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.37725830078125,
      "rewards/margins": 7.955370903015137,
      "rewards/rejected": -23.33262825012207,
      "step": 15310
    },
    {
      "epoch": 4.560202411073076,
      "grad_norm": 14.7587251663208,
      "learning_rate": 7.127665965755483e-06,
      "logits/chosen": -0.05930628255009651,
      "logits/rejected": -0.06069841980934143,
      "logps/chosen": -325.5518493652344,
      "logps/rejected": -390.9736022949219,
      "loss": 0.0311,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.21961498260498,
      "rewards/margins": 6.971475124359131,
      "rewards/rejected": -22.191089630126953,
      "step": 15320
    },
    {
      "epoch": 4.56317904450067,
      "grad_norm": 4.209749221801758,
      "learning_rate": 7.079603484529889e-06,
      "logits/chosen": 0.03388486057519913,
      "logits/rejected": 0.033585648983716965,
      "logps/chosen": -332.08966064453125,
      "logps/rejected": -408.14581298828125,
      "loss": 0.0856,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.866930961608887,
      "rewards/margins": 6.791085720062256,
      "rewards/rejected": -22.65801429748535,
      "step": 15330
    },
    {
      "epoch": 4.566155677928263,
      "grad_norm": 2.599357843399048,
      "learning_rate": 7.031541003304297e-06,
      "logits/chosen": -0.020795291289687157,
      "logits/rejected": -0.037648189812898636,
      "logps/chosen": -316.81719970703125,
      "logps/rejected": -396.2840270996094,
      "loss": 0.0422,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.864416122436523,
      "rewards/margins": 6.983027458190918,
      "rewards/rejected": -21.84744644165039,
      "step": 15340
    },
    {
      "epoch": 4.569132311355856,
      "grad_norm": 11.899301528930664,
      "learning_rate": 6.983478522078703e-06,
      "logits/chosen": -0.05751851946115494,
      "logits/rejected": 0.06588645279407501,
      "logps/chosen": -313.72381591796875,
      "logps/rejected": -400.3185119628906,
      "loss": 0.0351,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.7098388671875,
      "rewards/margins": 8.057968139648438,
      "rewards/rejected": -21.76780891418457,
      "step": 15350
    },
    {
      "epoch": 4.57210894478345,
      "grad_norm": 0.391294926404953,
      "learning_rate": 6.93541604085311e-06,
      "logits/chosen": -0.09477706998586655,
      "logits/rejected": -0.026177415624260902,
      "logps/chosen": -308.7904052734375,
      "logps/rejected": -399.6434326171875,
      "loss": 0.0714,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.1387939453125,
      "rewards/margins": 7.862684726715088,
      "rewards/rejected": -21.00147819519043,
      "step": 15360
    },
    {
      "epoch": 4.575085578211043,
      "grad_norm": 2.5490224361419678,
      "learning_rate": 6.887353559627517e-06,
      "logits/chosen": -0.0191040076315403,
      "logits/rejected": 0.012852603569626808,
      "logps/chosen": -296.5705871582031,
      "logps/rejected": -366.31756591796875,
      "loss": 0.0752,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.542098999023438,
      "rewards/margins": 6.980834007263184,
      "rewards/rejected": -19.522932052612305,
      "step": 15370
    },
    {
      "epoch": 4.5780622116386365,
      "grad_norm": 1.3981850147247314,
      "learning_rate": 6.839291078401923e-06,
      "logits/chosen": -0.036816488951444626,
      "logits/rejected": -0.018346652388572693,
      "logps/chosen": -315.46380615234375,
      "logps/rejected": -397.60858154296875,
      "loss": 0.0193,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.112650871276855,
      "rewards/margins": 7.304268836975098,
      "rewards/rejected": -21.416919708251953,
      "step": 15380
    },
    {
      "epoch": 4.58103884506623,
      "grad_norm": 1.0250951051712036,
      "learning_rate": 6.79122859717633e-06,
      "logits/chosen": -0.04654962196946144,
      "logits/rejected": 0.06583955138921738,
      "logps/chosen": -298.17254638671875,
      "logps/rejected": -371.9879455566406,
      "loss": 0.0524,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.929247856140137,
      "rewards/margins": 7.706768989562988,
      "rewards/rejected": -20.636014938354492,
      "step": 15390
    },
    {
      "epoch": 4.584015478493823,
      "grad_norm": 1.8640069961547852,
      "learning_rate": 6.743166115950737e-06,
      "logits/chosen": -0.06494253873825073,
      "logits/rejected": -0.0016793400282040238,
      "logps/chosen": -329.5306701660156,
      "logps/rejected": -413.48699951171875,
      "loss": 0.0178,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.096728324890137,
      "rewards/margins": 7.280362606048584,
      "rewards/rejected": -22.377092361450195,
      "step": 15400
    },
    {
      "epoch": 4.5869921119214165,
      "grad_norm": 11.648693084716797,
      "learning_rate": 6.695103634725143e-06,
      "logits/chosen": -0.03439193218946457,
      "logits/rejected": 0.03587508946657181,
      "logps/chosen": -345.5439758300781,
      "logps/rejected": -418.88134765625,
      "loss": 0.0322,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -16.44479751586914,
      "rewards/margins": 7.484330177307129,
      "rewards/rejected": -23.929126739501953,
      "step": 15410
    },
    {
      "epoch": 4.58996874534901,
      "grad_norm": 2.9621191024780273,
      "learning_rate": 6.64704115349955e-06,
      "logits/chosen": 0.017937010154128075,
      "logits/rejected": 0.09883071482181549,
      "logps/chosen": -285.65155029296875,
      "logps/rejected": -363.88262939453125,
      "loss": 0.042,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.943796157836914,
      "rewards/margins": 7.5641374588012695,
      "rewards/rejected": -20.507930755615234,
      "step": 15420
    },
    {
      "epoch": 4.592945378776603,
      "grad_norm": 0.9169937372207642,
      "learning_rate": 6.598978672273957e-06,
      "logits/chosen": 0.05325769633054733,
      "logits/rejected": 0.23000574111938477,
      "logps/chosen": -311.49188232421875,
      "logps/rejected": -390.8944091796875,
      "loss": 0.0381,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.977361679077148,
      "rewards/margins": 7.849381923675537,
      "rewards/rejected": -21.82674217224121,
      "step": 15430
    },
    {
      "epoch": 4.595922012204197,
      "grad_norm": 8.423467636108398,
      "learning_rate": 6.550916191048363e-06,
      "logits/chosen": 0.007698565721511841,
      "logits/rejected": 0.11565674841403961,
      "logps/chosen": -319.6899108886719,
      "logps/rejected": -396.3060607910156,
      "loss": 0.0509,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.316659927368164,
      "rewards/margins": 7.954218864440918,
      "rewards/rejected": -22.2708797454834,
      "step": 15440
    },
    {
      "epoch": 4.59889864563179,
      "grad_norm": 5.187467098236084,
      "learning_rate": 6.50285370982277e-06,
      "logits/chosen": -0.09566664695739746,
      "logits/rejected": -0.04782489687204361,
      "logps/chosen": -297.43060302734375,
      "logps/rejected": -373.32867431640625,
      "loss": 0.0971,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.595820426940918,
      "rewards/margins": 6.929685115814209,
      "rewards/rejected": -19.525503158569336,
      "step": 15450
    },
    {
      "epoch": 4.601875279059384,
      "grad_norm": 4.770342826843262,
      "learning_rate": 6.454791228597177e-06,
      "logits/chosen": -0.018523475155234337,
      "logits/rejected": -0.08903871476650238,
      "logps/chosen": -316.1969299316406,
      "logps/rejected": -406.1296691894531,
      "loss": 0.0772,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.73895263671875,
      "rewards/margins": 7.495558738708496,
      "rewards/rejected": -21.23451042175293,
      "step": 15460
    },
    {
      "epoch": 4.604851912486978,
      "grad_norm": 1.4344173669815063,
      "learning_rate": 6.406728747371583e-06,
      "logits/chosen": -0.08652476966381073,
      "logits/rejected": 0.03531733900308609,
      "logps/chosen": -314.4412841796875,
      "logps/rejected": -380.0509338378906,
      "loss": 0.059,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.234418869018555,
      "rewards/margins": 7.100325584411621,
      "rewards/rejected": -21.33474349975586,
      "step": 15470
    },
    {
      "epoch": 4.607828545914571,
      "grad_norm": 2.351139783859253,
      "learning_rate": 6.35866626614599e-06,
      "logits/chosen": -0.1004229336977005,
      "logits/rejected": 0.03635140880942345,
      "logps/chosen": -289.6540832519531,
      "logps/rejected": -348.8892822265625,
      "loss": 0.0516,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.35239028930664,
      "rewards/margins": 6.813785552978516,
      "rewards/rejected": -18.166175842285156,
      "step": 15480
    },
    {
      "epoch": 4.610805179342164,
      "grad_norm": 10.54891586303711,
      "learning_rate": 6.310603784920397e-06,
      "logits/chosen": -0.06610723584890366,
      "logits/rejected": -5.531460192287341e-05,
      "logps/chosen": -308.04327392578125,
      "logps/rejected": -383.0061950683594,
      "loss": 0.0712,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.73823070526123,
      "rewards/margins": 6.941241264343262,
      "rewards/rejected": -19.679471969604492,
      "step": 15490
    },
    {
      "epoch": 4.613781812769758,
      "grad_norm": 1.6004433631896973,
      "learning_rate": 6.2625413036948035e-06,
      "logits/chosen": -0.20687739551067352,
      "logits/rejected": -0.053483832627534866,
      "logps/chosen": -311.7685241699219,
      "logps/rejected": -381.86236572265625,
      "loss": 0.0641,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.634289741516113,
      "rewards/margins": 7.4405198097229,
      "rewards/rejected": -21.074810028076172,
      "step": 15500
    },
    {
      "epoch": 4.616758446197351,
      "grad_norm": 0.6296374201774597,
      "learning_rate": 6.214478822469211e-06,
      "logits/chosen": -0.04162638634443283,
      "logits/rejected": -0.03921734541654587,
      "logps/chosen": -291.65576171875,
      "logps/rejected": -365.4248046875,
      "loss": 0.0792,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.198341369628906,
      "rewards/margins": 6.604942321777344,
      "rewards/rejected": -18.803281784057617,
      "step": 15510
    },
    {
      "epoch": 4.619735079624944,
      "grad_norm": 4.205372333526611,
      "learning_rate": 6.1664163412436175e-06,
      "logits/chosen": -0.0434480644762516,
      "logits/rejected": -0.12673595547676086,
      "logps/chosen": -301.0860900878906,
      "logps/rejected": -399.87591552734375,
      "loss": 0.0208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.273831367492676,
      "rewards/margins": 7.869889259338379,
      "rewards/rejected": -22.143718719482422,
      "step": 15520
    },
    {
      "epoch": 4.622711713052538,
      "grad_norm": 9.76474666595459,
      "learning_rate": 6.118353860018024e-06,
      "logits/chosen": 0.0047995550557971,
      "logits/rejected": -0.06406955420970917,
      "logps/chosen": -311.0871887207031,
      "logps/rejected": -419.8973693847656,
      "loss": 0.0267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.039590835571289,
      "rewards/margins": 8.030563354492188,
      "rewards/rejected": -22.070154190063477,
      "step": 15530
    },
    {
      "epoch": 4.625688346480131,
      "grad_norm": 0.8680943250656128,
      "learning_rate": 6.0702913787924315e-06,
      "logits/chosen": -0.06339863687753677,
      "logits/rejected": -0.05826106667518616,
      "logps/chosen": -310.81689453125,
      "logps/rejected": -402.1268615722656,
      "loss": 0.018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.19329833984375,
      "rewards/margins": 8.169454574584961,
      "rewards/rejected": -22.362754821777344,
      "step": 15540
    },
    {
      "epoch": 4.628664979907724,
      "grad_norm": 20.32703971862793,
      "learning_rate": 6.022228897566838e-06,
      "logits/chosen": 0.022195689380168915,
      "logits/rejected": -0.005696418695151806,
      "logps/chosen": -306.0704650878906,
      "logps/rejected": -393.0492248535156,
      "loss": 0.0841,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.812724113464355,
      "rewards/margins": 7.834512233734131,
      "rewards/rejected": -21.64723777770996,
      "step": 15550
    },
    {
      "epoch": 4.631641613335318,
      "grad_norm": 3.3937923908233643,
      "learning_rate": 5.974166416341244e-06,
      "logits/chosen": 0.00761451106518507,
      "logits/rejected": 0.03462103009223938,
      "logps/chosen": -346.5082092285156,
      "logps/rejected": -421.4098205566406,
      "loss": 0.0321,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -16.311351776123047,
      "rewards/margins": 7.5179901123046875,
      "rewards/rejected": -23.829341888427734,
      "step": 15560
    },
    {
      "epoch": 4.634618246762911,
      "grad_norm": 0.9797900319099426,
      "learning_rate": 5.926103935115652e-06,
      "logits/chosen": 0.04864409938454628,
      "logits/rejected": 0.1723291575908661,
      "logps/chosen": -318.33551025390625,
      "logps/rejected": -389.8270568847656,
      "loss": 0.0408,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.950820922851562,
      "rewards/margins": 7.372228145599365,
      "rewards/rejected": -22.32305145263672,
      "step": 15570
    },
    {
      "epoch": 4.6375948801905045,
      "grad_norm": 15.894360542297363,
      "learning_rate": 5.878041453890058e-06,
      "logits/chosen": -0.02977040410041809,
      "logits/rejected": 0.030028510838747025,
      "logps/chosen": -306.392822265625,
      "logps/rejected": -392.2657165527344,
      "loss": 0.0301,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.84442138671875,
      "rewards/margins": 7.917993068695068,
      "rewards/rejected": -21.76241683959961,
      "step": 15580
    },
    {
      "epoch": 4.640571513618098,
      "grad_norm": 9.804685592651367,
      "learning_rate": 5.829978972664464e-06,
      "logits/chosen": 0.13661721348762512,
      "logits/rejected": -0.04734591022133827,
      "logps/chosen": -319.02386474609375,
      "logps/rejected": -406.5022277832031,
      "loss": 0.1812,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -14.94860553741455,
      "rewards/margins": 7.102034568786621,
      "rewards/rejected": -22.050640106201172,
      "step": 15590
    },
    {
      "epoch": 4.643548147045691,
      "grad_norm": 2.084458589553833,
      "learning_rate": 5.781916491438872e-06,
      "logits/chosen": -0.06217042729258537,
      "logits/rejected": -0.07199680060148239,
      "logps/chosen": -300.09759521484375,
      "logps/rejected": -398.29327392578125,
      "loss": 0.0278,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.032989501953125,
      "rewards/margins": 8.48203182220459,
      "rewards/rejected": -21.51502227783203,
      "step": 15600
    },
    {
      "epoch": 4.6465247804732845,
      "grad_norm": 0.28673940896987915,
      "learning_rate": 5.733854010213278e-06,
      "logits/chosen": -0.11997531354427338,
      "logits/rejected": -0.17758820950984955,
      "logps/chosen": -336.434326171875,
      "logps/rejected": -412.63238525390625,
      "loss": 0.0338,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -16.187591552734375,
      "rewards/margins": 7.4120774269104,
      "rewards/rejected": -23.599668502807617,
      "step": 15610
    },
    {
      "epoch": 4.649501413900878,
      "grad_norm": 2.9775631427764893,
      "learning_rate": 5.685791528987684e-06,
      "logits/chosen": -0.045801952481269836,
      "logits/rejected": -0.2720382809638977,
      "logps/chosen": -313.17486572265625,
      "logps/rejected": -411.29827880859375,
      "loss": 0.0608,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.716870307922363,
      "rewards/margins": 7.529850959777832,
      "rewards/rejected": -22.246719360351562,
      "step": 15620
    },
    {
      "epoch": 4.652478047328471,
      "grad_norm": 18.70435905456543,
      "learning_rate": 5.637729047762092e-06,
      "logits/chosen": -0.134243905544281,
      "logits/rejected": 0.1802922785282135,
      "logps/chosen": -312.3299255371094,
      "logps/rejected": -367.5887145996094,
      "loss": 0.1275,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -14.804489135742188,
      "rewards/margins": 6.533499240875244,
      "rewards/rejected": -21.337987899780273,
      "step": 15630
    },
    {
      "epoch": 4.655454680756065,
      "grad_norm": 0.6616200804710388,
      "learning_rate": 5.589666566536498e-06,
      "logits/chosen": -0.22912995517253876,
      "logits/rejected": -0.19857044517993927,
      "logps/chosen": -293.1838684082031,
      "logps/rejected": -367.5800476074219,
      "loss": 0.0525,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.98155689239502,
      "rewards/margins": 7.131159782409668,
      "rewards/rejected": -20.112716674804688,
      "step": 15640
    },
    {
      "epoch": 4.658431314183658,
      "grad_norm": 0.3324153423309326,
      "learning_rate": 5.541604085310904e-06,
      "logits/chosen": -0.142248272895813,
      "logits/rejected": -0.17509882152080536,
      "logps/chosen": -305.14288330078125,
      "logps/rejected": -387.96246337890625,
      "loss": 0.0448,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.247856140136719,
      "rewards/margins": 7.5804338455200195,
      "rewards/rejected": -20.828289031982422,
      "step": 15650
    },
    {
      "epoch": 4.661407947611251,
      "grad_norm": 8.090843200683594,
      "learning_rate": 5.493541604085312e-06,
      "logits/chosen": 0.013543516397476196,
      "logits/rejected": -0.19538268446922302,
      "logps/chosen": -320.66644287109375,
      "logps/rejected": -434.21356201171875,
      "loss": 0.0473,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.235666275024414,
      "rewards/margins": 8.058113098144531,
      "rewards/rejected": -23.293781280517578,
      "step": 15660
    },
    {
      "epoch": 4.664384581038845,
      "grad_norm": 9.855420112609863,
      "learning_rate": 5.445479122859718e-06,
      "logits/chosen": -0.04203697293996811,
      "logits/rejected": 0.010525023564696312,
      "logps/chosen": -311.20281982421875,
      "logps/rejected": -376.46405029296875,
      "loss": 0.0842,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -13.654393196105957,
      "rewards/margins": 7.019379615783691,
      "rewards/rejected": -20.67377281188965,
      "step": 15670
    },
    {
      "epoch": 4.667361214466439,
      "grad_norm": 3.136648178100586,
      "learning_rate": 5.397416641634124e-06,
      "logits/chosen": 0.08535335958003998,
      "logits/rejected": 0.051544737070798874,
      "logps/chosen": -319.29302978515625,
      "logps/rejected": -406.8199768066406,
      "loss": 0.0532,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.213777542114258,
      "rewards/margins": 7.77475118637085,
      "rewards/rejected": -22.988529205322266,
      "step": 15680
    },
    {
      "epoch": 4.670337847894032,
      "grad_norm": 3.5454533100128174,
      "learning_rate": 5.349354160408532e-06,
      "logits/chosen": -0.22607269883155823,
      "logits/rejected": -0.040207039564847946,
      "logps/chosen": -306.86187744140625,
      "logps/rejected": -366.7102966308594,
      "loss": 0.0429,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.534141540527344,
      "rewards/margins": 7.160378456115723,
      "rewards/rejected": -19.694520950317383,
      "step": 15690
    },
    {
      "epoch": 4.673314481321626,
      "grad_norm": 17.580724716186523,
      "learning_rate": 5.301291679182938e-06,
      "logits/chosen": 0.011652475222945213,
      "logits/rejected": 0.05259127542376518,
      "logps/chosen": -308.1585998535156,
      "logps/rejected": -373.08306884765625,
      "loss": 0.0494,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.151107788085938,
      "rewards/margins": 6.554847717285156,
      "rewards/rejected": -20.70595359802246,
      "step": 15700
    },
    {
      "epoch": 4.676291114749219,
      "grad_norm": 3.729402780532837,
      "learning_rate": 5.2532291979573445e-06,
      "logits/chosen": 0.05619857460260391,
      "logits/rejected": -0.06071633845567703,
      "logps/chosen": -305.6808166503906,
      "logps/rejected": -415.4894104003906,
      "loss": 0.0254,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.428503036499023,
      "rewards/margins": 8.179241180419922,
      "rewards/rejected": -21.607742309570312,
      "step": 15710
    },
    {
      "epoch": 4.679267748176812,
      "grad_norm": 0.44859960675239563,
      "learning_rate": 5.205166716731752e-06,
      "logits/chosen": -0.04690171033143997,
      "logits/rejected": -0.03788089007139206,
      "logps/chosen": -309.44366455078125,
      "logps/rejected": -380.6087951660156,
      "loss": 0.0636,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.493069648742676,
      "rewards/margins": 6.445962429046631,
      "rewards/rejected": -20.93903160095215,
      "step": 15720
    },
    {
      "epoch": 4.682244381604406,
      "grad_norm": 0.9419508576393127,
      "learning_rate": 5.1571042355061585e-06,
      "logits/chosen": 0.005779549479484558,
      "logits/rejected": -0.09602348506450653,
      "logps/chosen": -309.44146728515625,
      "logps/rejected": -400.0005187988281,
      "loss": 0.0534,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.169795036315918,
      "rewards/margins": 7.459101676940918,
      "rewards/rejected": -22.628896713256836,
      "step": 15730
    },
    {
      "epoch": 4.685221015031999,
      "grad_norm": 4.457457542419434,
      "learning_rate": 5.109041754280565e-06,
      "logits/chosen": 0.1248491033911705,
      "logits/rejected": 0.20453119277954102,
      "logps/chosen": -310.3612060546875,
      "logps/rejected": -385.917724609375,
      "loss": 0.0503,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.686983108520508,
      "rewards/margins": 7.15261697769165,
      "rewards/rejected": -21.839597702026367,
      "step": 15740
    },
    {
      "epoch": 4.688197648459592,
      "grad_norm": 1.971119999885559,
      "learning_rate": 5.0609792730549724e-06,
      "logits/chosen": -0.045766446739435196,
      "logits/rejected": 0.03907404839992523,
      "logps/chosen": -298.10516357421875,
      "logps/rejected": -377.20294189453125,
      "loss": 0.0462,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.891656875610352,
      "rewards/margins": 7.180387020111084,
      "rewards/rejected": -20.07204246520996,
      "step": 15750
    },
    {
      "epoch": 4.691174281887186,
      "grad_norm": 1.7408922910690308,
      "learning_rate": 5.012916791829379e-06,
      "logits/chosen": -0.07114215195178986,
      "logits/rejected": -0.13399404287338257,
      "logps/chosen": -307.99359130859375,
      "logps/rejected": -388.48614501953125,
      "loss": 0.0608,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.899343490600586,
      "rewards/margins": 6.760606288909912,
      "rewards/rejected": -20.659950256347656,
      "step": 15760
    },
    {
      "epoch": 4.694150915314779,
      "grad_norm": 1.3423515558242798,
      "learning_rate": 4.964854310603786e-06,
      "logits/chosen": -0.164793461561203,
      "logits/rejected": -0.14244090020656586,
      "logps/chosen": -307.47357177734375,
      "logps/rejected": -378.7698059082031,
      "loss": 0.0615,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.41722583770752,
      "rewards/margins": 6.880484104156494,
      "rewards/rejected": -20.297710418701172,
      "step": 15770
    },
    {
      "epoch": 4.6971275487423725,
      "grad_norm": 1.1190379858016968,
      "learning_rate": 4.916791829378192e-06,
      "logits/chosen": -0.0004690185305662453,
      "logits/rejected": -0.09743935614824295,
      "logps/chosen": -324.47357177734375,
      "logps/rejected": -435.94744873046875,
      "loss": 0.0567,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.501388549804688,
      "rewards/margins": 8.316242218017578,
      "rewards/rejected": -23.8176326751709,
      "step": 15780
    },
    {
      "epoch": 4.700104182169966,
      "grad_norm": 12.08851432800293,
      "learning_rate": 4.868729348152599e-06,
      "logits/chosen": 0.07838976383209229,
      "logits/rejected": -0.14400938153266907,
      "logps/chosen": -304.334716796875,
      "logps/rejected": -403.05859375,
      "loss": 0.0473,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.498886108398438,
      "rewards/margins": 6.92385196685791,
      "rewards/rejected": -21.4227352142334,
      "step": 15790
    },
    {
      "epoch": 4.703080815597559,
      "grad_norm": 2.298800230026245,
      "learning_rate": 4.820666866927006e-06,
      "logits/chosen": -0.05780811235308647,
      "logits/rejected": 0.05980177968740463,
      "logps/chosen": -326.0521545410156,
      "logps/rejected": -393.4283752441406,
      "loss": 0.0634,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.84071159362793,
      "rewards/margins": 6.206686973571777,
      "rewards/rejected": -21.04739761352539,
      "step": 15800
    },
    {
      "epoch": 4.7060574490251526,
      "grad_norm": 0.9950459003448486,
      "learning_rate": 4.772604385701412e-06,
      "logits/chosen": 0.0381162166595459,
      "logits/rejected": 0.029657816514372826,
      "logps/chosen": -308.13714599609375,
      "logps/rejected": -393.2347717285156,
      "loss": 0.0413,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.035802841186523,
      "rewards/margins": 7.6695427894592285,
      "rewards/rejected": -21.705347061157227,
      "step": 15810
    },
    {
      "epoch": 4.709034082452746,
      "grad_norm": 1.365168809890747,
      "learning_rate": 4.724541904475819e-06,
      "logits/chosen": -0.07064060866832733,
      "logits/rejected": -0.08542373031377792,
      "logps/chosen": -310.57501220703125,
      "logps/rejected": -393.52825927734375,
      "loss": 0.1319,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -14.22973918914795,
      "rewards/margins": 7.512165069580078,
      "rewards/rejected": -21.74190330505371,
      "step": 15820
    },
    {
      "epoch": 4.712010715880339,
      "grad_norm": 1.386722445487976,
      "learning_rate": 4.676479423250226e-06,
      "logits/chosen": -0.23434226214885712,
      "logits/rejected": -0.14094915986061096,
      "logps/chosen": -331.3321228027344,
      "logps/rejected": -394.81622314453125,
      "loss": 0.0672,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.73994255065918,
      "rewards/margins": 6.757443904876709,
      "rewards/rejected": -21.497386932373047,
      "step": 15830
    },
    {
      "epoch": 4.714987349307933,
      "grad_norm": 17.132843017578125,
      "learning_rate": 4.628416942024632e-06,
      "logits/chosen": -0.05483759194612503,
      "logits/rejected": -0.06483365595340729,
      "logps/chosen": -311.727294921875,
      "logps/rejected": -392.8912353515625,
      "loss": 0.073,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.328265190124512,
      "rewards/margins": 7.408883571624756,
      "rewards/rejected": -21.737150192260742,
      "step": 15840
    },
    {
      "epoch": 4.717963982735526,
      "grad_norm": 2.222296714782715,
      "learning_rate": 4.580354460799039e-06,
      "logits/chosen": -0.14233505725860596,
      "logits/rejected": -0.16616888344287872,
      "logps/chosen": -310.4366149902344,
      "logps/rejected": -387.8576965332031,
      "loss": 0.0581,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.54858112335205,
      "rewards/margins": 7.230508327484131,
      "rewards/rejected": -20.779088973999023,
      "step": 15850
    },
    {
      "epoch": 4.720940616163119,
      "grad_norm": 4.399165630340576,
      "learning_rate": 4.532291979573446e-06,
      "logits/chosen": -0.11872853338718414,
      "logits/rejected": -0.09275640547275543,
      "logps/chosen": -304.08636474609375,
      "logps/rejected": -386.57586669921875,
      "loss": 0.0324,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.413922309875488,
      "rewards/margins": 7.401998996734619,
      "rewards/rejected": -20.815921783447266,
      "step": 15860
    },
    {
      "epoch": 4.723917249590713,
      "grad_norm": 7.370315074920654,
      "learning_rate": 4.484229498347852e-06,
      "logits/chosen": 0.008922022767364979,
      "logits/rejected": -0.05730311945080757,
      "logps/chosen": -304.53021240234375,
      "logps/rejected": -387.76068115234375,
      "loss": 0.0437,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.583654403686523,
      "rewards/margins": 7.43842077255249,
      "rewards/rejected": -21.02207374572754,
      "step": 15870
    },
    {
      "epoch": 4.726893883018306,
      "grad_norm": 9.7395601272583,
      "learning_rate": 4.436167017122259e-06,
      "logits/chosen": -0.0030446425080299377,
      "logits/rejected": -0.1532190442085266,
      "logps/chosen": -296.3570861816406,
      "logps/rejected": -400.5631103515625,
      "loss": 0.0532,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.496434211730957,
      "rewards/margins": 7.6316962242126465,
      "rewards/rejected": -21.128131866455078,
      "step": 15880
    },
    {
      "epoch": 4.729870516445899,
      "grad_norm": 2.185699462890625,
      "learning_rate": 4.388104535896666e-06,
      "logits/chosen": -0.06742166727781296,
      "logits/rejected": -0.0845729261636734,
      "logps/chosen": -332.6623840332031,
      "logps/rejected": -416.75872802734375,
      "loss": 0.0363,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.223057746887207,
      "rewards/margins": 8.316827774047852,
      "rewards/rejected": -22.539884567260742,
      "step": 15890
    },
    {
      "epoch": 4.732847149873493,
      "grad_norm": 4.592174053192139,
      "learning_rate": 4.340042054671072e-06,
      "logits/chosen": -0.18266913294792175,
      "logits/rejected": -0.13821041584014893,
      "logps/chosen": -311.3586730957031,
      "logps/rejected": -387.23162841796875,
      "loss": 0.071,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -13.529966354370117,
      "rewards/margins": 6.854556083679199,
      "rewards/rejected": -20.384523391723633,
      "step": 15900
    },
    {
      "epoch": 4.735823783301086,
      "grad_norm": 1.8413207530975342,
      "learning_rate": 4.291979573445479e-06,
      "logits/chosen": -0.17854824662208557,
      "logits/rejected": -0.00039057136746123433,
      "logps/chosen": -326.21270751953125,
      "logps/rejected": -391.5397033691406,
      "loss": 0.0528,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.711359024047852,
      "rewards/margins": 7.446755886077881,
      "rewards/rejected": -21.15811538696289,
      "step": 15910
    },
    {
      "epoch": 4.7388004167286795,
      "grad_norm": 0.5512670278549194,
      "learning_rate": 4.243917092219886e-06,
      "logits/chosen": -0.007396602537482977,
      "logits/rejected": -0.031167665496468544,
      "logps/chosen": -341.55767822265625,
      "logps/rejected": -431.36932373046875,
      "loss": 0.0386,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.442827224731445,
      "rewards/margins": 8.187276840209961,
      "rewards/rejected": -23.630102157592773,
      "step": 15920
    },
    {
      "epoch": 4.741777050156273,
      "grad_norm": 0.27484408020973206,
      "learning_rate": 4.195854610994292e-06,
      "logits/chosen": 0.0779615119099617,
      "logits/rejected": -0.11672370135784149,
      "logps/chosen": -318.3264465332031,
      "logps/rejected": -410.39605712890625,
      "loss": 0.0924,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -14.910100936889648,
      "rewards/margins": 7.726330757141113,
      "rewards/rejected": -22.636432647705078,
      "step": 15930
    },
    {
      "epoch": 4.744753683583866,
      "grad_norm": 22.306001663208008,
      "learning_rate": 4.147792129768699e-06,
      "logits/chosen": 0.1987047642469406,
      "logits/rejected": -0.08848525583744049,
      "logps/chosen": -314.30450439453125,
      "logps/rejected": -418.90545654296875,
      "loss": 0.058,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.526555061340332,
      "rewards/margins": 7.1514387130737305,
      "rewards/rejected": -22.67799186706543,
      "step": 15940
    },
    {
      "epoch": 4.74773031701146,
      "grad_norm": 1.9997276067733765,
      "learning_rate": 4.099729648543106e-06,
      "logits/chosen": 0.1075359359383583,
      "logits/rejected": 0.053831569850444794,
      "logps/chosen": -313.05218505859375,
      "logps/rejected": -415.81964111328125,
      "loss": 0.0287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.205894470214844,
      "rewards/margins": 7.995530128479004,
      "rewards/rejected": -23.201425552368164,
      "step": 15950
    },
    {
      "epoch": 4.750706950439054,
      "grad_norm": 0.6150095462799072,
      "learning_rate": 4.0516671673175125e-06,
      "logits/chosen": 0.0311381034553051,
      "logits/rejected": -0.042796630412340164,
      "logps/chosen": -340.7671813964844,
      "logps/rejected": -444.6986389160156,
      "loss": 0.04,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.487159729003906,
      "rewards/margins": 8.789806365966797,
      "rewards/rejected": -24.276966094970703,
      "step": 15960
    },
    {
      "epoch": 4.753683583866647,
      "grad_norm": 0.7029114961624146,
      "learning_rate": 4.0036046860919195e-06,
      "logits/chosen": 0.19758805632591248,
      "logits/rejected": 0.1330084353685379,
      "logps/chosen": -336.9969177246094,
      "logps/rejected": -420.39501953125,
      "loss": 0.0535,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -16.41619110107422,
      "rewards/margins": 7.087477207183838,
      "rewards/rejected": -23.5036678314209,
      "step": 15970
    },
    {
      "epoch": 4.7566602172942405,
      "grad_norm": 2.9970107078552246,
      "learning_rate": 3.9555422048663265e-06,
      "logits/chosen": 0.14878462255001068,
      "logits/rejected": -0.03231441602110863,
      "logps/chosen": -301.43145751953125,
      "logps/rejected": -393.01397705078125,
      "loss": 0.072,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.587385177612305,
      "rewards/margins": 6.980443477630615,
      "rewards/rejected": -21.567829132080078,
      "step": 15980
    },
    {
      "epoch": 4.759636850721834,
      "grad_norm": 6.443550109863281,
      "learning_rate": 3.907479723640733e-06,
      "logits/chosen": 0.11926420778036118,
      "logits/rejected": -0.086720310151577,
      "logps/chosen": -337.20953369140625,
      "logps/rejected": -443.7040100097656,
      "loss": 0.1402,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -16.47457504272461,
      "rewards/margins": 8.054190635681152,
      "rewards/rejected": -24.528766632080078,
      "step": 15990
    },
    {
      "epoch": 4.762613484149427,
      "grad_norm": 7.705634593963623,
      "learning_rate": 3.85941724241514e-06,
      "logits/chosen": 0.034649163484573364,
      "logits/rejected": -0.03822990506887436,
      "logps/chosen": -327.28802490234375,
      "logps/rejected": -399.0033264160156,
      "loss": 0.0399,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.665136337280273,
      "rewards/margins": 6.972515106201172,
      "rewards/rejected": -21.637651443481445,
      "step": 16000
    },
    {
      "epoch": 4.765590117577021,
      "grad_norm": 1.7906090021133423,
      "learning_rate": 3.8113547611895467e-06,
      "logits/chosen": -0.019765596836805344,
      "logits/rejected": 0.00429545110091567,
      "logps/chosen": -328.8077087402344,
      "logps/rejected": -413.5875549316406,
      "loss": 0.0581,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.067230224609375,
      "rewards/margins": 7.316030979156494,
      "rewards/rejected": -22.38326072692871,
      "step": 16010
    },
    {
      "epoch": 4.768566751004614,
      "grad_norm": 3.4045798778533936,
      "learning_rate": 3.7632922799639532e-06,
      "logits/chosen": -0.012888508848845959,
      "logits/rejected": -0.17937198281288147,
      "logps/chosen": -321.97943115234375,
      "logps/rejected": -421.8836975097656,
      "loss": 0.0164,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.081390380859375,
      "rewards/margins": 8.278006553649902,
      "rewards/rejected": -23.35939598083496,
      "step": 16020
    },
    {
      "epoch": 4.771543384432207,
      "grad_norm": 2.4128406047821045,
      "learning_rate": 3.7152297987383602e-06,
      "logits/chosen": -0.018948376178741455,
      "logits/rejected": -0.04645254462957382,
      "logps/chosen": -334.45611572265625,
      "logps/rejected": -411.90960693359375,
      "loss": 0.0368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.630929946899414,
      "rewards/margins": 8.025927543640137,
      "rewards/rejected": -22.656858444213867,
      "step": 16030
    },
    {
      "epoch": 4.774520017859801,
      "grad_norm": 1.6931908130645752,
      "learning_rate": 3.667167317512767e-06,
      "logits/chosen": 0.08008681237697601,
      "logits/rejected": -0.007914933376014233,
      "logps/chosen": -317.24658203125,
      "logps/rejected": -408.36456298828125,
      "loss": 0.0452,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.956515312194824,
      "rewards/margins": 7.6886305809021,
      "rewards/rejected": -22.645145416259766,
      "step": 16040
    },
    {
      "epoch": 4.777496651287394,
      "grad_norm": 1.4911843538284302,
      "learning_rate": 3.6191048362871734e-06,
      "logits/chosen": 0.028560996055603027,
      "logits/rejected": 0.03811336308717728,
      "logps/chosen": -313.8207092285156,
      "logps/rejected": -407.87347412109375,
      "loss": 0.0531,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.09752368927002,
      "rewards/margins": 8.012174606323242,
      "rewards/rejected": -22.109699249267578,
      "step": 16050
    },
    {
      "epoch": 4.780473284714987,
      "grad_norm": 0.08511263877153397,
      "learning_rate": 3.5710423550615804e-06,
      "logits/chosen": -0.14466239511966705,
      "logits/rejected": -0.0022429197560995817,
      "logps/chosen": -333.34295654296875,
      "logps/rejected": -398.64520263671875,
      "loss": 0.0952,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -15.233131408691406,
      "rewards/margins": 6.78766393661499,
      "rewards/rejected": -22.020797729492188,
      "step": 16060
    },
    {
      "epoch": 4.783449918142581,
      "grad_norm": 5.598965167999268,
      "learning_rate": 3.5229798738359873e-06,
      "logits/chosen": -0.058617688715457916,
      "logits/rejected": -0.05363898351788521,
      "logps/chosen": -317.04156494140625,
      "logps/rejected": -402.46087646484375,
      "loss": 0.0557,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.182835578918457,
      "rewards/margins": 8.022331237792969,
      "rewards/rejected": -22.205169677734375,
      "step": 16070
    },
    {
      "epoch": 4.786426551570174,
      "grad_norm": 15.090847969055176,
      "learning_rate": 3.474917392610394e-06,
      "logits/chosen": -0.04311298578977585,
      "logits/rejected": -0.10195569694042206,
      "logps/chosen": -335.1462097167969,
      "logps/rejected": -423.95135498046875,
      "loss": 0.028,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.899836540222168,
      "rewards/margins": 8.125658988952637,
      "rewards/rejected": -23.025493621826172,
      "step": 16080
    },
    {
      "epoch": 4.789403184997767,
      "grad_norm": 2.911416530609131,
      "learning_rate": 3.4268549113848005e-06,
      "logits/chosen": 0.020815065130591393,
      "logits/rejected": -0.03424476832151413,
      "logps/chosen": -332.4830627441406,
      "logps/rejected": -422.2915954589844,
      "loss": 0.0338,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.829730033874512,
      "rewards/margins": 7.7519683837890625,
      "rewards/rejected": -22.581701278686523,
      "step": 16090
    },
    {
      "epoch": 4.792379818425361,
      "grad_norm": 3.805795192718506,
      "learning_rate": 3.3787924301592075e-06,
      "logits/chosen": 0.20781977474689484,
      "logits/rejected": 0.012513095512986183,
      "logps/chosen": -322.03131103515625,
      "logps/rejected": -441.6463317871094,
      "loss": 0.0407,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.420366287231445,
      "rewards/margins": 8.362760543823242,
      "rewards/rejected": -23.783124923706055,
      "step": 16100
    },
    {
      "epoch": 4.795356451852954,
      "grad_norm": 1.8723523616790771,
      "learning_rate": 3.330729948933614e-06,
      "logits/chosen": 0.21376915276050568,
      "logits/rejected": 0.05740322917699814,
      "logps/chosen": -321.5673522949219,
      "logps/rejected": -412.59210205078125,
      "loss": 0.0402,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -16.152881622314453,
      "rewards/margins": 7.285626411437988,
      "rewards/rejected": -23.438508987426758,
      "step": 16110
    },
    {
      "epoch": 4.7983330852805475,
      "grad_norm": 4.6201276779174805,
      "learning_rate": 3.2826674677080206e-06,
      "logits/chosen": 0.04905131459236145,
      "logits/rejected": -0.12094281613826752,
      "logps/chosen": -333.3467712402344,
      "logps/rejected": -433.64678955078125,
      "loss": 0.0295,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.859254837036133,
      "rewards/margins": 8.219499588012695,
      "rewards/rejected": -24.078754425048828,
      "step": 16120
    },
    {
      "epoch": 4.801309718708141,
      "grad_norm": 0.9557433128356934,
      "learning_rate": 3.2346049864824276e-06,
      "logits/chosen": 0.06577977538108826,
      "logits/rejected": 0.11752237379550934,
      "logps/chosen": -322.49432373046875,
      "logps/rejected": -402.03826904296875,
      "loss": 0.0954,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -15.52900505065918,
      "rewards/margins": 7.76379919052124,
      "rewards/rejected": -23.292800903320312,
      "step": 16130
    },
    {
      "epoch": 4.804286352135734,
      "grad_norm": 0.4163621962070465,
      "learning_rate": 3.186542505256834e-06,
      "logits/chosen": -0.054427631199359894,
      "logits/rejected": -0.011952303349971771,
      "logps/chosen": -322.5087585449219,
      "logps/rejected": -403.6532287597656,
      "loss": 0.0538,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.167913436889648,
      "rewards/margins": 7.576475620269775,
      "rewards/rejected": -22.7443904876709,
      "step": 16140
    },
    {
      "epoch": 4.8072629855633275,
      "grad_norm": 4.176705360412598,
      "learning_rate": 3.1384800240312408e-06,
      "logits/chosen": 0.06625103950500488,
      "logits/rejected": 0.14086690545082092,
      "logps/chosen": -312.9124450683594,
      "logps/rejected": -386.78564453125,
      "loss": 0.0382,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.398483276367188,
      "rewards/margins": 7.090353488922119,
      "rewards/rejected": -21.48883628845215,
      "step": 16150
    },
    {
      "epoch": 4.810239618990921,
      "grad_norm": 40.677513122558594,
      "learning_rate": 3.0904175428056478e-06,
      "logits/chosen": -0.2038300335407257,
      "logits/rejected": 0.009649890474975109,
      "logps/chosen": -328.88641357421875,
      "logps/rejected": -397.5127868652344,
      "loss": 0.0822,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.412185668945312,
      "rewards/margins": 7.500741004943848,
      "rewards/rejected": -21.912927627563477,
      "step": 16160
    },
    {
      "epoch": 4.813216252418515,
      "grad_norm": 4.5073933601379395,
      "learning_rate": 3.0423550615800547e-06,
      "logits/chosen": 0.0910169929265976,
      "logits/rejected": 0.10820670425891876,
      "logps/chosen": -315.1302185058594,
      "logps/rejected": -403.4317932128906,
      "loss": 0.033,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.285341262817383,
      "rewards/margins": 8.114014625549316,
      "rewards/rejected": -22.399354934692383,
      "step": 16170
    },
    {
      "epoch": 4.8161928858461085,
      "grad_norm": 2.88598370552063,
      "learning_rate": 2.994292580354461e-06,
      "logits/chosen": -0.032253067940473557,
      "logits/rejected": -0.0765054002404213,
      "logps/chosen": -326.62493896484375,
      "logps/rejected": -417.39794921875,
      "loss": 0.1005,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.267474174499512,
      "rewards/margins": 7.485674858093262,
      "rewards/rejected": -22.75314712524414,
      "step": 16180
    },
    {
      "epoch": 4.819169519273702,
      "grad_norm": 9.009703636169434,
      "learning_rate": 2.946230099128868e-06,
      "logits/chosen": 0.0701710507273674,
      "logits/rejected": 0.11199663579463959,
      "logps/chosen": -303.75115966796875,
      "logps/rejected": -400.25213623046875,
      "loss": 0.0215,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.872093200683594,
      "rewards/margins": 8.508448600769043,
      "rewards/rejected": -22.380544662475586,
      "step": 16190
    },
    {
      "epoch": 4.822146152701295,
      "grad_norm": 1.6540637016296387,
      "learning_rate": 2.898167617903275e-06,
      "logits/chosen": 0.11789469420909882,
      "logits/rejected": -0.01804773509502411,
      "logps/chosen": -317.10845947265625,
      "logps/rejected": -410.70941162109375,
      "loss": 0.0159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.525911331176758,
      "rewards/margins": 7.791295051574707,
      "rewards/rejected": -23.31720733642578,
      "step": 16200
    },
    {
      "epoch": 4.825122786128889,
      "grad_norm": 5.56670618057251,
      "learning_rate": 2.850105136677681e-06,
      "logits/chosen": -0.1327458620071411,
      "logits/rejected": 0.07378729432821274,
      "logps/chosen": -299.27337646484375,
      "logps/rejected": -371.3917541503906,
      "loss": 0.0515,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.979464530944824,
      "rewards/margins": 7.104636192321777,
      "rewards/rejected": -20.084102630615234,
      "step": 16210
    },
    {
      "epoch": 4.828099419556482,
      "grad_norm": 11.624752044677734,
      "learning_rate": 2.802042655452088e-06,
      "logits/chosen": 0.06685642898082733,
      "logits/rejected": -0.0019484009826555848,
      "logps/chosen": -330.97503662109375,
      "logps/rejected": -429.2478942871094,
      "loss": 0.0284,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.635887145996094,
      "rewards/margins": 8.542377471923828,
      "rewards/rejected": -24.178264617919922,
      "step": 16220
    },
    {
      "epoch": 4.831076052984075,
      "grad_norm": 7.518089294433594,
      "learning_rate": 2.753980174226495e-06,
      "logits/chosen": -0.16287106275558472,
      "logits/rejected": 0.03242627531290054,
      "logps/chosen": -345.41888427734375,
      "logps/rejected": -411.66796875,
      "loss": 0.0421,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.341214179992676,
      "rewards/margins": 7.619879722595215,
      "rewards/rejected": -22.96109390258789,
      "step": 16230
    },
    {
      "epoch": 4.834052686411669,
      "grad_norm": 1.7267143726348877,
      "learning_rate": 2.705917693000901e-06,
      "logits/chosen": 0.14684376120567322,
      "logits/rejected": 0.15389743447303772,
      "logps/chosen": -345.3709716796875,
      "logps/rejected": -419.831298828125,
      "loss": 0.0753,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -17.123714447021484,
      "rewards/margins": 6.561883449554443,
      "rewards/rejected": -23.685596466064453,
      "step": 16240
    },
    {
      "epoch": 4.837029319839262,
      "grad_norm": 5.674466609954834,
      "learning_rate": 2.657855211775308e-06,
      "logits/chosen": 0.06938230246305466,
      "logits/rejected": -0.10742497444152832,
      "logps/chosen": -331.68731689453125,
      "logps/rejected": -426.76824951171875,
      "loss": 0.0706,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -16.121944427490234,
      "rewards/margins": 7.592012882232666,
      "rewards/rejected": -23.71395492553711,
      "step": 16250
    },
    {
      "epoch": 4.840005953266855,
      "grad_norm": 11.753965377807617,
      "learning_rate": 2.609792730549715e-06,
      "logits/chosen": 0.21720173954963684,
      "logits/rejected": -0.008694789372384548,
      "logps/chosen": -312.501220703125,
      "logps/rejected": -414.6022033691406,
      "loss": 0.0355,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.293757438659668,
      "rewards/margins": 7.631545066833496,
      "rewards/rejected": -22.92530059814453,
      "step": 16260
    },
    {
      "epoch": 4.842982586694449,
      "grad_norm": 4.047159194946289,
      "learning_rate": 2.5617302493241213e-06,
      "logits/chosen": 0.108890101313591,
      "logits/rejected": -0.02230464480817318,
      "logps/chosen": -338.8684997558594,
      "logps/rejected": -430.89422607421875,
      "loss": 0.0401,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.75404167175293,
      "rewards/margins": 7.561800956726074,
      "rewards/rejected": -23.315841674804688,
      "step": 16270
    },
    {
      "epoch": 4.845959220122042,
      "grad_norm": 1.6729177236557007,
      "learning_rate": 2.5136677680985283e-06,
      "logits/chosen": 0.07028679549694061,
      "logits/rejected": 0.005904114339500666,
      "logps/chosen": -317.649658203125,
      "logps/rejected": -412.5679626464844,
      "loss": 0.0466,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.173985481262207,
      "rewards/margins": 8.163124084472656,
      "rewards/rejected": -22.337108612060547,
      "step": 16280
    },
    {
      "epoch": 4.848935853549635,
      "grad_norm": 8.749448776245117,
      "learning_rate": 2.465605286872935e-06,
      "logits/chosen": 0.028138279914855957,
      "logits/rejected": 0.12619231641292572,
      "logps/chosen": -328.41009521484375,
      "logps/rejected": -408.3593444824219,
      "loss": 0.0789,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -15.417322158813477,
      "rewards/margins": 7.819699764251709,
      "rewards/rejected": -23.23702049255371,
      "step": 16290
    },
    {
      "epoch": 4.851912486977229,
      "grad_norm": 5.644593238830566,
      "learning_rate": 2.417542805647342e-06,
      "logits/chosen": 0.10482170432806015,
      "logits/rejected": 0.10911495983600616,
      "logps/chosen": -324.96514892578125,
      "logps/rejected": -397.6590270996094,
      "loss": 0.0397,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.783833503723145,
      "rewards/margins": 6.893063545227051,
      "rewards/rejected": -21.676898956298828,
      "step": 16300
    },
    {
      "epoch": 4.854889120404822,
      "grad_norm": 22.064254760742188,
      "learning_rate": 2.3694803244217484e-06,
      "logits/chosen": 0.24621662497520447,
      "logits/rejected": -0.044615719467401505,
      "logps/chosen": -301.884765625,
      "logps/rejected": -411.05108642578125,
      "loss": 0.0742,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.545400619506836,
      "rewards/margins": 7.8454999923706055,
      "rewards/rejected": -22.390899658203125,
      "step": 16310
    },
    {
      "epoch": 4.8578657538324155,
      "grad_norm": 27.434741973876953,
      "learning_rate": 2.321417843196155e-06,
      "logits/chosen": -0.13337218761444092,
      "logits/rejected": 0.10672984272241592,
      "logps/chosen": -317.5893249511719,
      "logps/rejected": -369.9342346191406,
      "loss": 0.0541,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.621438980102539,
      "rewards/margins": 6.595719337463379,
      "rewards/rejected": -21.217159271240234,
      "step": 16320
    },
    {
      "epoch": 4.860842387260009,
      "grad_norm": 38.533538818359375,
      "learning_rate": 2.273355361970562e-06,
      "logits/chosen": 0.1502009481191635,
      "logits/rejected": 0.05564800649881363,
      "logps/chosen": -330.51861572265625,
      "logps/rejected": -418.7801818847656,
      "loss": 0.0584,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.36059856414795,
      "rewards/margins": 7.881396293640137,
      "rewards/rejected": -23.24199867248535,
      "step": 16330
    },
    {
      "epoch": 4.863819020687602,
      "grad_norm": 6.8196187019348145,
      "learning_rate": 2.2252928807449686e-06,
      "logits/chosen": 0.17540358006954193,
      "logits/rejected": 0.04317304491996765,
      "logps/chosen": -309.41448974609375,
      "logps/rejected": -406.21539306640625,
      "loss": 0.0683,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.16309928894043,
      "rewards/margins": 7.096522331237793,
      "rewards/rejected": -22.259624481201172,
      "step": 16340
    },
    {
      "epoch": 4.8667956541151955,
      "grad_norm": 17.822181701660156,
      "learning_rate": 2.177230399519375e-06,
      "logits/chosen": 0.044747062027454376,
      "logits/rejected": -0.04233172535896301,
      "logps/chosen": -306.57000732421875,
      "logps/rejected": -389.74969482421875,
      "loss": 0.056,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.850339889526367,
      "rewards/margins": 7.120233058929443,
      "rewards/rejected": -21.97057342529297,
      "step": 16350
    },
    {
      "epoch": 4.869772287542789,
      "grad_norm": 1.3025364875793457,
      "learning_rate": 2.129167918293782e-06,
      "logits/chosen": 0.02510962449014187,
      "logits/rejected": 0.05837329104542732,
      "logps/chosen": -315.1625061035156,
      "logps/rejected": -409.5639343261719,
      "loss": 0.0285,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.028254508972168,
      "rewards/margins": 8.448526382446289,
      "rewards/rejected": -22.476781845092773,
      "step": 16360
    },
    {
      "epoch": 4.872748920970382,
      "grad_norm": 4.6155686378479,
      "learning_rate": 2.0811054370681887e-06,
      "logits/chosen": 0.033971451222896576,
      "logits/rejected": -0.050669729709625244,
      "logps/chosen": -357.6737060546875,
      "logps/rejected": -453.454345703125,
      "loss": 0.0536,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -16.75835418701172,
      "rewards/margins": 7.989466190338135,
      "rewards/rejected": -24.747817993164062,
      "step": 16370
    },
    {
      "epoch": 4.875725554397976,
      "grad_norm": 3.2120015621185303,
      "learning_rate": 2.0330429558425953e-06,
      "logits/chosen": 0.14718253910541534,
      "logits/rejected": 0.17704185843467712,
      "logps/chosen": -324.874267578125,
      "logps/rejected": -414.51153564453125,
      "loss": 0.0657,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.159695625305176,
      "rewards/margins": 8.429061889648438,
      "rewards/rejected": -23.588756561279297,
      "step": 16380
    },
    {
      "epoch": 4.878702187825569,
      "grad_norm": 20.39179039001465,
      "learning_rate": 1.9849804746170023e-06,
      "logits/chosen": 0.02999575436115265,
      "logits/rejected": 0.060411740094423294,
      "logps/chosen": -313.9876403808594,
      "logps/rejected": -402.081298828125,
      "loss": 0.081,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -13.879971504211426,
      "rewards/margins": 7.23336935043335,
      "rewards/rejected": -21.113338470458984,
      "step": 16390
    },
    {
      "epoch": 4.881678821253162,
      "grad_norm": 1.7727669477462769,
      "learning_rate": 1.936917993391409e-06,
      "logits/chosen": 0.20968791842460632,
      "logits/rejected": 0.153187096118927,
      "logps/chosen": -336.9364929199219,
      "logps/rejected": -412.4878845214844,
      "loss": 0.0431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -16.801355361938477,
      "rewards/margins": 6.826666355133057,
      "rewards/rejected": -23.628021240234375,
      "step": 16400
    },
    {
      "epoch": 4.884655454680756,
      "grad_norm": 9.566977500915527,
      "learning_rate": 1.8888555121658156e-06,
      "logits/chosen": 0.04844968020915985,
      "logits/rejected": 0.07643772661685944,
      "logps/chosen": -302.5833435058594,
      "logps/rejected": -371.2668762207031,
      "loss": 0.0801,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.213725090026855,
      "rewards/margins": 7.006529808044434,
      "rewards/rejected": -20.22025489807129,
      "step": 16410
    },
    {
      "epoch": 4.887632088108349,
      "grad_norm": 5.817923069000244,
      "learning_rate": 1.8407930309402224e-06,
      "logits/chosen": -0.05854666233062744,
      "logits/rejected": -0.058524239808321,
      "logps/chosen": -324.0551452636719,
      "logps/rejected": -404.2085876464844,
      "loss": 0.0413,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.724087715148926,
      "rewards/margins": 7.509329319000244,
      "rewards/rejected": -22.23341178894043,
      "step": 16420
    },
    {
      "epoch": 4.890608721535942,
      "grad_norm": 0.6713635921478271,
      "learning_rate": 1.7927305497146292e-06,
      "logits/chosen": 0.09936787188053131,
      "logits/rejected": -0.0028057664167135954,
      "logps/chosen": -333.881591796875,
      "logps/rejected": -427.44940185546875,
      "loss": 0.0425,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -16.280059814453125,
      "rewards/margins": 7.4542107582092285,
      "rewards/rejected": -23.734272003173828,
      "step": 16430
    },
    {
      "epoch": 4.893585354963536,
      "grad_norm": 7.221268653869629,
      "learning_rate": 1.744668068489036e-06,
      "logits/chosen": 0.19694456458091736,
      "logits/rejected": 0.18459250032901764,
      "logps/chosen": -311.92169189453125,
      "logps/rejected": -382.32177734375,
      "loss": 0.0762,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -14.421510696411133,
      "rewards/margins": 7.037282466888428,
      "rewards/rejected": -21.45879364013672,
      "step": 16440
    },
    {
      "epoch": 4.89656198839113,
      "grad_norm": 6.3286051750183105,
      "learning_rate": 1.6966055872634427e-06,
      "logits/chosen": 0.03521374613046646,
      "logits/rejected": -0.0709221139550209,
      "logps/chosen": -321.177490234375,
      "logps/rejected": -404.17913818359375,
      "loss": 0.0343,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.33397388458252,
      "rewards/margins": 7.329693794250488,
      "rewards/rejected": -21.66366958618164,
      "step": 16450
    },
    {
      "epoch": 4.899538621818723,
      "grad_norm": 2.8051679134368896,
      "learning_rate": 1.6485431060378493e-06,
      "logits/chosen": 0.032601065933704376,
      "logits/rejected": -0.026254970580339432,
      "logps/chosen": -302.79974365234375,
      "logps/rejected": -396.43170166015625,
      "loss": 0.0304,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.146886825561523,
      "rewards/margins": 7.880336761474609,
      "rewards/rejected": -22.027223587036133,
      "step": 16460
    },
    {
      "epoch": 4.902515255246317,
      "grad_norm": 3.927172899246216,
      "learning_rate": 1.600480624812256e-06,
      "logits/chosen": 0.01643732562661171,
      "logits/rejected": -0.0030351101886481047,
      "logps/chosen": -294.83551025390625,
      "logps/rejected": -381.4899597167969,
      "loss": 0.0524,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.992279052734375,
      "rewards/margins": 7.892533779144287,
      "rewards/rejected": -20.884811401367188,
      "step": 16470
    },
    {
      "epoch": 4.90549188867391,
      "grad_norm": 10.980367660522461,
      "learning_rate": 1.5524181435866629e-06,
      "logits/chosen": 0.24227690696716309,
      "logits/rejected": -0.01108615379780531,
      "logps/chosen": -307.28289794921875,
      "logps/rejected": -414.34393310546875,
      "loss": 0.0546,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.103912353515625,
      "rewards/margins": 7.599368095397949,
      "rewards/rejected": -22.70328140258789,
      "step": 16480
    },
    {
      "epoch": 4.908468522101503,
      "grad_norm": 2.6252787113189697,
      "learning_rate": 1.5043556623610694e-06,
      "logits/chosen": -0.09839364886283875,
      "logits/rejected": -0.09407428652048111,
      "logps/chosen": -348.098388671875,
      "logps/rejected": -427.09136962890625,
      "loss": 0.05,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.839052200317383,
      "rewards/margins": 7.826784610748291,
      "rewards/rejected": -22.66583824157715,
      "step": 16490
    },
    {
      "epoch": 4.911445155529097,
      "grad_norm": 0.7294626235961914,
      "learning_rate": 1.4562931811354764e-06,
      "logits/chosen": 0.18621332943439484,
      "logits/rejected": 0.03339291363954544,
      "logps/chosen": -320.60052490234375,
      "logps/rejected": -427.86602783203125,
      "loss": 0.019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.720146179199219,
      "rewards/margins": 8.603955268859863,
      "rewards/rejected": -24.324100494384766,
      "step": 16500
    },
    {
      "epoch": 4.91442178895669,
      "grad_norm": 6.5545196533203125,
      "learning_rate": 1.408230699909883e-06,
      "logits/chosen": 0.18193040788173676,
      "logits/rejected": -0.012815356254577637,
      "logps/chosen": -305.4330749511719,
      "logps/rejected": -412.22845458984375,
      "loss": 0.0304,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -14.699211120605469,
      "rewards/margins": 7.8391008377075195,
      "rewards/rejected": -22.538311004638672,
      "step": 16510
    },
    {
      "epoch": 4.9173984223842835,
      "grad_norm": 2.9680919647216797,
      "learning_rate": 1.3601682186842896e-06,
      "logits/chosen": 0.10360288619995117,
      "logits/rejected": 0.04708169773221016,
      "logps/chosen": -328.7913818359375,
      "logps/rejected": -421.28369140625,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.712641716003418,
      "rewards/margins": 7.359253883361816,
      "rewards/rejected": -23.0718936920166,
      "step": 16520
    },
    {
      "epoch": 4.920375055811877,
      "grad_norm": 1.3085941076278687,
      "learning_rate": 1.3121057374586966e-06,
      "logits/chosen": 0.03179943561553955,
      "logits/rejected": -0.01844165101647377,
      "logps/chosen": -321.02984619140625,
      "logps/rejected": -409.5945739746094,
      "loss": 0.0656,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -14.873146057128906,
      "rewards/margins": 7.415116786956787,
      "rewards/rejected": -22.28826332092285,
      "step": 16530
    },
    {
      "epoch": 4.92335168923947,
      "grad_norm": 1.745329737663269,
      "learning_rate": 1.2640432562331031e-06,
      "logits/chosen": -0.051932454109191895,
      "logits/rejected": -0.10929348319768906,
      "logps/chosen": -341.79571533203125,
      "logps/rejected": -431.3662109375,
      "loss": 0.0484,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -16.013099670410156,
      "rewards/margins": 7.663094520568848,
      "rewards/rejected": -23.67619514465332,
      "step": 16540
    },
    {
      "epoch": 4.9263283226670636,
      "grad_norm": 14.157937049865723,
      "learning_rate": 1.21598077500751e-06,
      "logits/chosen": -0.054951030761003494,
      "logits/rejected": -0.3197260797023773,
      "logps/chosen": -332.26544189453125,
      "logps/rejected": -441.01531982421875,
      "loss": 0.0398,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -16.17660903930664,
      "rewards/margins": 8.084297180175781,
      "rewards/rejected": -24.260906219482422,
      "step": 16550
    },
    {
      "epoch": 4.929304956094657,
      "grad_norm": 2.0989677906036377,
      "learning_rate": 1.1679182937819165e-06,
      "logits/chosen": 0.21970942616462708,
      "logits/rejected": 0.09788388013839722,
      "logps/chosen": -323.8443298339844,
      "logps/rejected": -412.6317443847656,
      "loss": 0.0921,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -15.490313529968262,
      "rewards/margins": 7.8622331619262695,
      "rewards/rejected": -23.352548599243164,
      "step": 16560
    },
    {
      "epoch": 4.93228158952225,
      "grad_norm": 0.8672546148300171,
      "learning_rate": 1.1198558125563233e-06,
      "logits/chosen": 0.10249584913253784,
      "logits/rejected": -0.02634267881512642,
      "logps/chosen": -326.91583251953125,
      "logps/rejected": -420.0924377441406,
      "loss": 0.0263,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -16.11397361755371,
      "rewards/margins": 7.946942329406738,
      "rewards/rejected": -24.060916900634766,
      "step": 16570
    },
    {
      "epoch": 4.935258222949844,
      "grad_norm": 1.359262228012085,
      "learning_rate": 1.07179333133073e-06,
      "logits/chosen": -0.024938177317380905,
      "logits/rejected": -0.053644001483917236,
      "logps/chosen": -329.87432861328125,
      "logps/rejected": -420.58074951171875,
      "loss": 0.0455,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.2422513961792,
      "rewards/margins": 7.9389824867248535,
      "rewards/rejected": -23.181232452392578,
      "step": 16580
    },
    {
      "epoch": 4.938234856377437,
      "grad_norm": 5.514378070831299,
      "learning_rate": 1.0237308501051366e-06,
      "logits/chosen": -0.035427045077085495,
      "logits/rejected": -0.11682077497243881,
      "logps/chosen": -328.50006103515625,
      "logps/rejected": -413.5162048339844,
      "loss": 0.0494,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.031471252441406,
      "rewards/margins": 6.937451362609863,
      "rewards/rejected": -21.968923568725586,
      "step": 16590
    },
    {
      "epoch": 4.94121148980503,
      "grad_norm": 1.8473563194274902,
      "learning_rate": 9.756683688795434e-07,
      "logits/chosen": 0.14134560525417328,
      "logits/rejected": 0.025665421038866043,
      "logps/chosen": -291.0975036621094,
      "logps/rejected": -380.7895812988281,
      "loss": 0.0375,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.088086128234863,
      "rewards/margins": 6.713870048522949,
      "rewards/rejected": -20.80195426940918,
      "step": 16600
    },
    {
      "epoch": 4.944188123232624,
      "grad_norm": 5.444241046905518,
      "learning_rate": 9.276058876539502e-07,
      "logits/chosen": 0.10262951999902725,
      "logits/rejected": 0.14819961786270142,
      "logps/chosen": -308.83441162109375,
      "logps/rejected": -398.9292297363281,
      "loss": 0.0304,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.037422180175781,
      "rewards/margins": 8.124837875366211,
      "rewards/rejected": -22.162256240844727,
      "step": 16610
    },
    {
      "epoch": 4.947164756660217,
      "grad_norm": 3.9835236072540283,
      "learning_rate": 8.79543406428357e-07,
      "logits/chosen": 0.034422338008880615,
      "logits/rejected": 0.10354050248861313,
      "logps/chosen": -321.53656005859375,
      "logps/rejected": -402.49212646484375,
      "loss": 0.0461,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.914545059204102,
      "rewards/margins": 7.790425777435303,
      "rewards/rejected": -22.70496940612793,
      "step": 16620
    },
    {
      "epoch": 4.95014139008781,
      "grad_norm": 1.8435910940170288,
      "learning_rate": 8.314809252027636e-07,
      "logits/chosen": 0.07919733226299286,
      "logits/rejected": -0.03932108357548714,
      "logps/chosen": -338.6748046875,
      "logps/rejected": -457.0205993652344,
      "loss": 0.0526,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -16.8140811920166,
      "rewards/margins": 8.789398193359375,
      "rewards/rejected": -25.603479385375977,
      "step": 16630
    },
    {
      "epoch": 4.953118023515404,
      "grad_norm": 0.7122912406921387,
      "learning_rate": 7.834184439771704e-07,
      "logits/chosen": 0.17310740053653717,
      "logits/rejected": 0.28214672207832336,
      "logps/chosen": -305.17987060546875,
      "logps/rejected": -383.888916015625,
      "loss": 0.0633,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.699407577514648,
      "rewards/margins": 7.12502908706665,
      "rewards/rejected": -21.824438095092773,
      "step": 16640
    },
    {
      "epoch": 4.956094656942997,
      "grad_norm": 0.5558840036392212,
      "learning_rate": 7.353559627515772e-07,
      "logits/chosen": 0.021536987274885178,
      "logits/rejected": 0.0068448795937001705,
      "logps/chosen": -300.33233642578125,
      "logps/rejected": -380.09710693359375,
      "loss": 0.0812,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.468480110168457,
      "rewards/margins": 7.3907318115234375,
      "rewards/rejected": -20.85921287536621,
      "step": 16650
    },
    {
      "epoch": 4.959071290370591,
      "grad_norm": 1.7604035139083862,
      "learning_rate": 6.872934815259838e-07,
      "logits/chosen": 0.06540994346141815,
      "logits/rejected": 0.10772041976451874,
      "logps/chosen": -359.1473083496094,
      "logps/rejected": -435.46844482421875,
      "loss": 0.0549,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -17.176990509033203,
      "rewards/margins": 7.1687421798706055,
      "rewards/rejected": -24.345733642578125,
      "step": 16660
    },
    {
      "epoch": 4.962047923798185,
      "grad_norm": 3.4153671264648438,
      "learning_rate": 6.392310003003906e-07,
      "logits/chosen": 0.10465151071548462,
      "logits/rejected": 0.04281419515609741,
      "logps/chosen": -299.05914306640625,
      "logps/rejected": -378.89752197265625,
      "loss": 0.049,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.436216354370117,
      "rewards/margins": 7.288930416107178,
      "rewards/rejected": -21.725149154663086,
      "step": 16670
    },
    {
      "epoch": 4.965024557225778,
      "grad_norm": 3.0324416160583496,
      "learning_rate": 5.911685190747972e-07,
      "logits/chosen": -0.08520772308111191,
      "logits/rejected": 0.07583822309970856,
      "logps/chosen": -337.63116455078125,
      "logps/rejected": -417.8916931152344,
      "loss": 0.0462,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.52880859375,
      "rewards/margins": 7.745789527893066,
      "rewards/rejected": -23.274599075317383,
      "step": 16680
    },
    {
      "epoch": 4.968001190653371,
      "grad_norm": 0.1760161817073822,
      "learning_rate": 5.43106037849204e-07,
      "logits/chosen": 0.019362544640898705,
      "logits/rejected": -0.030938681215047836,
      "logps/chosen": -327.04541015625,
      "logps/rejected": -420.9244689941406,
      "loss": 0.0355,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -16.04758071899414,
      "rewards/margins": 7.595091342926025,
      "rewards/rejected": -23.64267349243164,
      "step": 16690
    },
    {
      "epoch": 4.970977824080965,
      "grad_norm": 2.3935766220092773,
      "learning_rate": 4.950435566236107e-07,
      "logits/chosen": 0.24067990481853485,
      "logits/rejected": -0.11874588578939438,
      "logps/chosen": -329.53717041015625,
      "logps/rejected": -455.1190490722656,
      "loss": 0.0189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -16.749738693237305,
      "rewards/margins": 8.37537956237793,
      "rewards/rejected": -25.125118255615234,
      "step": 16700
    },
    {
      "epoch": 4.973954457508558,
      "grad_norm": 2.9000158309936523,
      "learning_rate": 4.469810753980174e-07,
      "logits/chosen": -0.07796572148799896,
      "logits/rejected": 0.054942917078733444,
      "logps/chosen": -331.2364196777344,
      "logps/rejected": -408.23162841796875,
      "loss": 0.0567,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -15.183491706848145,
      "rewards/margins": 7.850583076477051,
      "rewards/rejected": -23.034076690673828,
      "step": 16710
    },
    {
      "epoch": 4.9769310909361515,
      "grad_norm": 0.9648988246917725,
      "learning_rate": 3.989185941724242e-07,
      "logits/chosen": 0.21955761313438416,
      "logits/rejected": 0.051001884043216705,
      "logps/chosen": -329.7876281738281,
      "logps/rejected": -442.1558532714844,
      "loss": 0.0594,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -16.89134979248047,
      "rewards/margins": 7.791162014007568,
      "rewards/rejected": -24.682514190673828,
      "step": 16720
    },
    {
      "epoch": 4.979907724363745,
      "grad_norm": 4.367990016937256,
      "learning_rate": 3.508561129468309e-07,
      "logits/chosen": 0.07339731603860855,
      "logits/rejected": 0.18548494577407837,
      "logps/chosen": -301.3920593261719,
      "logps/rejected": -371.5559387207031,
      "loss": 0.0564,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -13.34649658203125,
      "rewards/margins": 6.51729679107666,
      "rewards/rejected": -19.863794326782227,
      "step": 16730
    },
    {
      "epoch": 4.982884357791338,
      "grad_norm": 3.0639426708221436,
      "learning_rate": 3.027936317212376e-07,
      "logits/chosen": -0.02511361613869667,
      "logits/rejected": -0.044034458696842194,
      "logps/chosen": -323.41693115234375,
      "logps/rejected": -399.33331298828125,
      "loss": 0.0604,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.991735458374023,
      "rewards/margins": 7.588999271392822,
      "rewards/rejected": -22.580734252929688,
      "step": 16740
    },
    {
      "epoch": 4.985860991218932,
      "grad_norm": 0.2277916967868805,
      "learning_rate": 2.5473115049564434e-07,
      "logits/chosen": 0.058975040912628174,
      "logits/rejected": -0.02738809585571289,
      "logps/chosen": -314.8311462402344,
      "logps/rejected": -400.5791015625,
      "loss": 0.0765,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.597318649291992,
      "rewards/margins": 6.916300296783447,
      "rewards/rejected": -21.51361846923828,
      "step": 16750
    },
    {
      "epoch": 4.988837624646525,
      "grad_norm": 14.606693267822266,
      "learning_rate": 2.066686692700511e-07,
      "logits/chosen": -0.03514984995126724,
      "logits/rejected": 0.050484128296375275,
      "logps/chosen": -328.3027038574219,
      "logps/rejected": -407.8944091796875,
      "loss": 0.0336,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -15.250930786132812,
      "rewards/margins": 7.332544803619385,
      "rewards/rejected": -22.583477020263672,
      "step": 16760
    },
    {
      "epoch": 4.991814258074118,
      "grad_norm": 0.9452378153800964,
      "learning_rate": 1.5860618804445783e-07,
      "logits/chosen": 0.13154974579811096,
      "logits/rejected": -0.005752342753112316,
      "logps/chosen": -302.1006164550781,
      "logps/rejected": -389.13568115234375,
      "loss": 0.0618,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.570574760437012,
      "rewards/margins": 6.90341329574585,
      "rewards/rejected": -20.473987579345703,
      "step": 16770
    },
    {
      "epoch": 4.994790891501712,
      "grad_norm": 1.0085115432739258,
      "learning_rate": 1.1054370681886454e-07,
      "logits/chosen": 0.006734614260494709,
      "logits/rejected": -0.03950675204396248,
      "logps/chosen": -335.1709289550781,
      "logps/rejected": -423.7314453125,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -15.749258041381836,
      "rewards/margins": 7.464423179626465,
      "rewards/rejected": -23.213680267333984,
      "step": 16780
    },
    {
      "epoch": 4.997767524929305,
      "grad_norm": 5.399809837341309,
      "learning_rate": 6.248122559327126e-08,
      "logits/chosen": -0.0029809861443936825,
      "logits/rejected": 0.10368941724300385,
      "logps/chosen": -307.86334228515625,
      "logps/rejected": -394.9649353027344,
      "loss": 0.0398,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -14.815852165222168,
      "rewards/margins": 7.738120079040527,
      "rewards/rejected": -22.553974151611328,
      "step": 16790
    }
  ],
  "logging_steps": 10,
  "max_steps": 16795,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
