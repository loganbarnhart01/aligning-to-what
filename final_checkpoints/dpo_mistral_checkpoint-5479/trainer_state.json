{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9999087507984306,
  "eval_steps": 500.0,
  "global_step": 5479,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00018249840313897252,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "logits/chosen": -2.4092752933502197,
      "logits/rejected": -2.317518472671509,
      "logps/chosen": -123.6567611694336,
      "logps/rejected": -88.57423400878906,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.0018249840313897254,
      "grad_norm": 8.175853729248047,
      "learning_rate": 4.266666666666668e-06,
      "logits/chosen": -2.5828781127929688,
      "logits/rejected": -2.617816686630249,
      "logps/chosen": -103.63066101074219,
      "logps/rejected": -112.27155303955078,
      "loss": 0.6928,
      "rewards/accuracies": 0.3611111044883728,
      "rewards/chosen": -0.0005522437277249992,
      "rewards/margins": 0.0006882641464471817,
      "rewards/rejected": -0.0012405076995491982,
      "step": 10
    },
    {
      "epoch": 0.003649968062779451,
      "grad_norm": 3.666804790496826,
      "learning_rate": 9.600000000000001e-06,
      "logits/chosen": -2.653010129928589,
      "logits/rejected": -2.586711883544922,
      "logps/chosen": -113.43757629394531,
      "logps/rejected": -104.9506607055664,
      "loss": 0.6955,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.00019616140343714505,
      "rewards/margins": -0.004117190837860107,
      "rewards/rejected": 0.0043133520521223545,
      "step": 20
    },
    {
      "epoch": 0.005474952094169176,
      "grad_norm": 4.212480068206787,
      "learning_rate": 1.4933333333333335e-05,
      "logits/chosen": -2.758718729019165,
      "logits/rejected": -2.666560173034668,
      "logps/chosen": -148.66293334960938,
      "logps/rejected": -121.6388168334961,
      "loss": 0.694,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": -0.005557110533118248,
      "rewards/margins": -0.0004352731630206108,
      "rewards/rejected": -0.00512183690443635,
      "step": 30
    },
    {
      "epoch": 0.007299936125558902,
      "grad_norm": 3.4575278759002686,
      "learning_rate": 1.9733333333333336e-05,
      "logits/chosen": -2.6433653831481934,
      "logits/rejected": -2.6287972927093506,
      "logps/chosen": -125.00502014160156,
      "logps/rejected": -122.26686096191406,
      "loss": 0.6923,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.013761691749095917,
      "rewards/margins": 0.002209798898547888,
      "rewards/rejected": 0.011551893316209316,
      "step": 40
    },
    {
      "epoch": 0.009124920156948626,
      "grad_norm": 3.6210267543792725,
      "learning_rate": 2.5066666666666672e-05,
      "logits/chosen": -2.6851580142974854,
      "logits/rejected": -2.6241626739501953,
      "logps/chosen": -129.9113311767578,
      "logps/rejected": -102.13633728027344,
      "loss": 0.6837,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.01769421622157097,
      "rewards/margins": 0.024005722254514694,
      "rewards/rejected": -0.0063115074299275875,
      "step": 50
    },
    {
      "epoch": 0.010949904188338352,
      "grad_norm": 3.7692935466766357,
      "learning_rate": 3.0400000000000004e-05,
      "logits/chosen": -2.662832260131836,
      "logits/rejected": -2.5535776615142822,
      "logps/chosen": -139.91873168945312,
      "logps/rejected": -104.26212310791016,
      "loss": 0.6855,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.09677836298942566,
      "rewards/margins": 0.023587018251419067,
      "rewards/rejected": 0.07319134473800659,
      "step": 60
    },
    {
      "epoch": 0.012774888219728078,
      "grad_norm": 3.502406358718872,
      "learning_rate": 3.573333333333333e-05,
      "logits/chosen": -2.6791369915008545,
      "logits/rejected": -2.6054816246032715,
      "logps/chosen": -123.4290771484375,
      "logps/rejected": -109.3270263671875,
      "loss": 0.6621,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.1908625215291977,
      "rewards/margins": 0.07777716219425201,
      "rewards/rejected": 0.11308535188436508,
      "step": 70
    },
    {
      "epoch": 0.014599872251117803,
      "grad_norm": 3.519925832748413,
      "learning_rate": 4.106666666666667e-05,
      "logits/chosen": -2.6593308448791504,
      "logits/rejected": -2.547121524810791,
      "logps/chosen": -126.9876480102539,
      "logps/rejected": -96.2612533569336,
      "loss": 0.6656,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.25534144043922424,
      "rewards/margins": 0.07924098521471024,
      "rewards/rejected": 0.17610043287277222,
      "step": 80
    },
    {
      "epoch": 0.01642485628250753,
      "grad_norm": 4.990277290344238,
      "learning_rate": 4.64e-05,
      "logits/chosen": -2.6531190872192383,
      "logits/rejected": -2.5636801719665527,
      "logps/chosen": -128.20663452148438,
      "logps/rejected": -102.7027587890625,
      "loss": 0.633,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.37039434909820557,
      "rewards/margins": 0.18507368862628937,
      "rewards/rejected": 0.1853206604719162,
      "step": 90
    },
    {
      "epoch": 0.018249840313897252,
      "grad_norm": 4.913554668426514,
      "learning_rate": 5.1733333333333335e-05,
      "logits/chosen": -2.670083999633789,
      "logits/rejected": -2.554006338119507,
      "logps/chosen": -137.1621856689453,
      "logps/rejected": -113.8561782836914,
      "loss": 0.6297,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.5048809051513672,
      "rewards/margins": 0.1976844221353531,
      "rewards/rejected": 0.3071964383125305,
      "step": 100
    },
    {
      "epoch": 0.020074824345286978,
      "grad_norm": 4.689681529998779,
      "learning_rate": 5.7066666666666674e-05,
      "logits/chosen": -2.7278130054473877,
      "logits/rejected": -2.601201295852661,
      "logps/chosen": -147.5699005126953,
      "logps/rejected": -101.57984161376953,
      "loss": 0.5982,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.3581223487854004,
      "rewards/margins": 0.2898571491241455,
      "rewards/rejected": 0.06826517730951309,
      "step": 110
    },
    {
      "epoch": 0.021899808376676703,
      "grad_norm": 5.491913795471191,
      "learning_rate": 6.186666666666668e-05,
      "logits/chosen": -2.6634232997894287,
      "logits/rejected": -2.5803816318511963,
      "logps/chosen": -120.1042709350586,
      "logps/rejected": -107.60984802246094,
      "loss": 0.6095,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.17997394502162933,
      "rewards/margins": 0.26092609763145447,
      "rewards/rejected": -0.08095212280750275,
      "step": 120
    },
    {
      "epoch": 0.02372479240806643,
      "grad_norm": 3.8959906101226807,
      "learning_rate": 6.720000000000001e-05,
      "logits/chosen": -2.6189186573028564,
      "logits/rejected": -2.5108096599578857,
      "logps/chosen": -139.83346557617188,
      "logps/rejected": -122.78926086425781,
      "loss": 0.6474,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.23542778193950653,
      "rewards/margins": 0.253742516040802,
      "rewards/rejected": -0.018314724788069725,
      "step": 130
    },
    {
      "epoch": 0.025549776439456155,
      "grad_norm": 4.996853351593018,
      "learning_rate": 7.253333333333334e-05,
      "logits/chosen": -2.6536502838134766,
      "logits/rejected": -2.569732189178467,
      "logps/chosen": -130.91058349609375,
      "logps/rejected": -108.55094146728516,
      "loss": 0.6108,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.27393612265586853,
      "rewards/margins": 0.2712773084640503,
      "rewards/rejected": 0.002658836543560028,
      "step": 140
    },
    {
      "epoch": 0.02737476047084588,
      "grad_norm": 6.3048319816589355,
      "learning_rate": 7.786666666666667e-05,
      "logits/chosen": -2.6485884189605713,
      "logits/rejected": -2.5752506256103516,
      "logps/chosen": -117.93284606933594,
      "logps/rejected": -110.1736068725586,
      "loss": 0.6107,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.37231093645095825,
      "rewards/margins": 0.3725668787956238,
      "rewards/rejected": -0.0002559334097895771,
      "step": 150
    },
    {
      "epoch": 0.029199744502235607,
      "grad_norm": 6.40491247177124,
      "learning_rate": 7.990992681553763e-05,
      "logits/chosen": -2.6642050743103027,
      "logits/rejected": -2.5407469272613525,
      "logps/chosen": -126.81025695800781,
      "logps/rejected": -103.26997375488281,
      "loss": 0.4867,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 0.541077733039856,
      "rewards/margins": 0.7362024188041687,
      "rewards/rejected": -0.19512470066547394,
      "step": 160
    },
    {
      "epoch": 0.03102472853362533,
      "grad_norm": 7.450811862945557,
      "learning_rate": 7.975980484143367e-05,
      "logits/chosen": -2.3872761726379395,
      "logits/rejected": -2.2748050689697266,
      "logps/chosen": -133.53750610351562,
      "logps/rejected": -114.01750183105469,
      "loss": 0.5639,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.023122048005461693,
      "rewards/margins": 0.6285382509231567,
      "rewards/rejected": -0.6516603231430054,
      "step": 170
    },
    {
      "epoch": 0.03284971256501506,
      "grad_norm": 8.688027381896973,
      "learning_rate": 7.960968286732972e-05,
      "logits/chosen": -2.5250797271728516,
      "logits/rejected": -2.4634876251220703,
      "logps/chosen": -115.45748138427734,
      "logps/rejected": -114.4288101196289,
      "loss": 0.5807,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.23027530312538147,
      "rewards/margins": 0.594229519367218,
      "rewards/rejected": -0.8245047330856323,
      "step": 180
    },
    {
      "epoch": 0.034674696596404785,
      "grad_norm": 7.48948860168457,
      "learning_rate": 7.945956089322576e-05,
      "logits/chosen": -2.5553627014160156,
      "logits/rejected": -2.5045783519744873,
      "logps/chosen": -114.0888900756836,
      "logps/rejected": -106.08845520019531,
      "loss": 0.576,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.025537734851241112,
      "rewards/margins": 0.6072281002998352,
      "rewards/rejected": -0.5816903114318848,
      "step": 190
    },
    {
      "epoch": 0.036499680627794504,
      "grad_norm": 5.697614669799805,
      "learning_rate": 7.93094389191218e-05,
      "logits/chosen": -2.4260776042938232,
      "logits/rejected": -2.3854830265045166,
      "logps/chosen": -121.80241394042969,
      "logps/rejected": -107.9430160522461,
      "loss": 0.6519,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.06923185288906097,
      "rewards/margins": 0.4379841387271881,
      "rewards/rejected": -0.5072159767150879,
      "step": 200
    },
    {
      "epoch": 0.03832466465918423,
      "grad_norm": 4.888853073120117,
      "learning_rate": 7.915931694501783e-05,
      "logits/chosen": -2.505974769592285,
      "logits/rejected": -2.418767213821411,
      "logps/chosen": -123.67769622802734,
      "logps/rejected": -117.357666015625,
      "loss": 0.625,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.23268601298332214,
      "rewards/margins": 0.5228343605995178,
      "rewards/rejected": -0.2901483476161957,
      "step": 210
    },
    {
      "epoch": 0.040149648690573955,
      "grad_norm": 5.245663166046143,
      "learning_rate": 7.900919497091387e-05,
      "logits/chosen": -2.6931910514831543,
      "logits/rejected": -2.562570095062256,
      "logps/chosen": -124.37532043457031,
      "logps/rejected": -103.99766540527344,
      "loss": 0.6124,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.5262085795402527,
      "rewards/margins": 0.3625832498073578,
      "rewards/rejected": 0.16362540423870087,
      "step": 220
    },
    {
      "epoch": 0.04197463272196368,
      "grad_norm": 5.955623626708984,
      "learning_rate": 7.885907299680992e-05,
      "logits/chosen": -2.4523720741271973,
      "logits/rejected": -2.3812966346740723,
      "logps/chosen": -125.86103820800781,
      "logps/rejected": -111.79264831542969,
      "loss": 0.7054,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.4640182852745056,
      "rewards/margins": 0.16158244013786316,
      "rewards/rejected": 0.30243590474128723,
      "step": 230
    },
    {
      "epoch": 0.04379961675335341,
      "grad_norm": 3.9158802032470703,
      "learning_rate": 7.870895102270596e-05,
      "logits/chosen": -2.5578091144561768,
      "logits/rejected": -2.472928285598755,
      "logps/chosen": -119.68556213378906,
      "logps/rejected": -105.36366271972656,
      "loss": 0.626,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.24068133533000946,
      "rewards/margins": 0.3422147333621979,
      "rewards/rejected": -0.10153336822986603,
      "step": 240
    },
    {
      "epoch": 0.04562460078474313,
      "grad_norm": 6.7330827713012695,
      "learning_rate": 7.855882904860199e-05,
      "logits/chosen": -2.5562305450439453,
      "logits/rejected": -2.4932563304901123,
      "logps/chosen": -117.92494201660156,
      "logps/rejected": -107.61181640625,
      "loss": 0.5988,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.5784105062484741,
      "rewards/margins": 0.44231900572776794,
      "rewards/rejected": 0.13609154522418976,
      "step": 250
    },
    {
      "epoch": 0.04744958481613286,
      "grad_norm": 8.486922264099121,
      "learning_rate": 7.840870707449803e-05,
      "logits/chosen": -2.559088706970215,
      "logits/rejected": -2.4989519119262695,
      "logps/chosen": -132.70004272460938,
      "logps/rejected": -119.8644027709961,
      "loss": 0.6508,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.3836745023727417,
      "rewards/margins": 0.2552299499511719,
      "rewards/rejected": 0.12844456732273102,
      "step": 260
    },
    {
      "epoch": 0.049274568847522585,
      "grad_norm": 5.048450469970703,
      "learning_rate": 7.825858510039407e-05,
      "logits/chosen": -2.580059766769409,
      "logits/rejected": -2.4195034503936768,
      "logps/chosen": -145.9488525390625,
      "logps/rejected": -116.5447769165039,
      "loss": 0.6646,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.3724321126937866,
      "rewards/margins": 0.24027800559997559,
      "rewards/rejected": 0.13215407729148865,
      "step": 270
    },
    {
      "epoch": 0.05109955287891231,
      "grad_norm": 8.518242835998535,
      "learning_rate": 7.810846312629012e-05,
      "logits/chosen": -2.6266233921051025,
      "logits/rejected": -2.5200648307800293,
      "logps/chosen": -117.1067123413086,
      "logps/rejected": -98.4225845336914,
      "loss": 0.6532,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.32460516691207886,
      "rewards/margins": 0.2732795178890228,
      "rewards/rejected": 0.05132564902305603,
      "step": 280
    },
    {
      "epoch": 0.052924536910302036,
      "grad_norm": 9.466962814331055,
      "learning_rate": 7.795834115218616e-05,
      "logits/chosen": -2.6937294006347656,
      "logits/rejected": -2.59062123298645,
      "logps/chosen": -132.79559326171875,
      "logps/rejected": -116.63346862792969,
      "loss": 0.5141,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.3578139841556549,
      "rewards/margins": 0.7378063797950745,
      "rewards/rejected": -0.37999245524406433,
      "step": 290
    },
    {
      "epoch": 0.05474952094169176,
      "grad_norm": 7.302637100219727,
      "learning_rate": 7.78082191780822e-05,
      "logits/chosen": -2.5231716632843018,
      "logits/rejected": -2.477207660675049,
      "logps/chosen": -133.65811157226562,
      "logps/rejected": -126.2979965209961,
      "loss": 0.5502,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.10371465981006622,
      "rewards/margins": 0.5920694470405579,
      "rewards/rejected": -0.6957839727401733,
      "step": 300
    },
    {
      "epoch": 0.05657450497308149,
      "grad_norm": 5.90393590927124,
      "learning_rate": 7.765809720397823e-05,
      "logits/chosen": -2.5731053352355957,
      "logits/rejected": -2.474872589111328,
      "logps/chosen": -150.6895751953125,
      "logps/rejected": -127.07850646972656,
      "loss": 0.5777,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.12210042774677277,
      "rewards/margins": 0.6037915945053101,
      "rewards/rejected": -0.7258920073509216,
      "step": 310
    },
    {
      "epoch": 0.058399489004471214,
      "grad_norm": 5.811565399169922,
      "learning_rate": 7.750797522987427e-05,
      "logits/chosen": -2.5881049633026123,
      "logits/rejected": -2.511040449142456,
      "logps/chosen": -119.97859954833984,
      "logps/rejected": -103.8304672241211,
      "loss": 0.7009,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.18063516914844513,
      "rewards/margins": 0.26188308000564575,
      "rewards/rejected": -0.08124794811010361,
      "step": 320
    },
    {
      "epoch": 0.06022447303586093,
      "grad_norm": 3.9594874382019043,
      "learning_rate": 7.735785325577032e-05,
      "logits/chosen": -2.5748023986816406,
      "logits/rejected": -2.483177661895752,
      "logps/chosen": -142.94833374023438,
      "logps/rejected": -119.52693939208984,
      "loss": 0.5398,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.15826644003391266,
      "rewards/margins": 0.5957100987434387,
      "rewards/rejected": -0.43744367361068726,
      "step": 330
    },
    {
      "epoch": 0.06204945706725066,
      "grad_norm": 10.124235153198242,
      "learning_rate": 7.720773128166636e-05,
      "logits/chosen": -2.507725238800049,
      "logits/rejected": -2.4399094581604004,
      "logps/chosen": -130.85073852539062,
      "logps/rejected": -124.004150390625,
      "loss": 0.5326,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.18115024268627167,
      "rewards/margins": 0.874841034412384,
      "rewards/rejected": -1.0559911727905273,
      "step": 340
    },
    {
      "epoch": 0.06387444109864039,
      "grad_norm": 5.244548320770264,
      "learning_rate": 7.70576093075624e-05,
      "logits/chosen": -2.594780445098877,
      "logits/rejected": -2.508054256439209,
      "logps/chosen": -134.6678009033203,
      "logps/rejected": -124.85604095458984,
      "loss": 0.5629,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.3665763735771179,
      "rewards/margins": 0.8336493372917175,
      "rewards/rejected": -1.200225830078125,
      "step": 350
    },
    {
      "epoch": 0.06569942513003012,
      "grad_norm": 5.8409528732299805,
      "learning_rate": 7.690748733345845e-05,
      "logits/chosen": -2.519547700881958,
      "logits/rejected": -2.502254009246826,
      "logps/chosen": -132.9026336669922,
      "logps/rejected": -130.12937927246094,
      "loss": 0.6052,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.31753009557724,
      "rewards/margins": 0.6409378051757812,
      "rewards/rejected": -0.9584678411483765,
      "step": 360
    },
    {
      "epoch": 0.06752440916141984,
      "grad_norm": 5.525332927703857,
      "learning_rate": 7.675736535935449e-05,
      "logits/chosen": -2.619123935699463,
      "logits/rejected": -2.512883186340332,
      "logps/chosen": -122.65934753417969,
      "logps/rejected": -105.93223571777344,
      "loss": 0.5809,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.13216693699359894,
      "rewards/margins": 0.6279956102371216,
      "rewards/rejected": -0.4958287179470062,
      "step": 370
    },
    {
      "epoch": 0.06934939319280957,
      "grad_norm": 4.9429240226745605,
      "learning_rate": 7.660724338525052e-05,
      "logits/chosen": -2.6649975776672363,
      "logits/rejected": -2.563743829727173,
      "logps/chosen": -127.0440444946289,
      "logps/rejected": -103.78269958496094,
      "loss": 0.6389,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.34175071120262146,
      "rewards/margins": 0.4518852233886719,
      "rewards/rejected": -0.11013450473546982,
      "step": 380
    },
    {
      "epoch": 0.0711743772241993,
      "grad_norm": 5.6162824630737305,
      "learning_rate": 7.645712141114656e-05,
      "logits/chosen": -2.62556529045105,
      "logits/rejected": -2.5931642055511475,
      "logps/chosen": -138.8408966064453,
      "logps/rejected": -120.26715087890625,
      "loss": 0.6258,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.1599275916814804,
      "rewards/margins": 0.41555914282798767,
      "rewards/rejected": -0.25563153624534607,
      "step": 390
    },
    {
      "epoch": 0.07299936125558901,
      "grad_norm": 3.8303189277648926,
      "learning_rate": 7.63069994370426e-05,
      "logits/chosen": -2.742013454437256,
      "logits/rejected": -2.649503707885742,
      "logps/chosen": -130.9425048828125,
      "logps/rejected": -102.8482437133789,
      "loss": 0.6222,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.14122065901756287,
      "rewards/margins": 0.3685302138328552,
      "rewards/rejected": -0.5097509622573853,
      "step": 400
    },
    {
      "epoch": 0.07482434528697873,
      "grad_norm": 4.011654853820801,
      "learning_rate": 7.615687746293865e-05,
      "logits/chosen": -2.7300593852996826,
      "logits/rejected": -2.6627511978149414,
      "logps/chosen": -129.0786895751953,
      "logps/rejected": -120.67808532714844,
      "loss": 0.5295,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.40596461296081543,
      "rewards/margins": 0.7177220582962036,
      "rewards/rejected": -0.31175747513771057,
      "step": 410
    },
    {
      "epoch": 0.07664932931836846,
      "grad_norm": 6.7605390548706055,
      "learning_rate": 7.600675548883468e-05,
      "logits/chosen": -2.67803955078125,
      "logits/rejected": -2.6121666431427,
      "logps/chosen": -125.4455795288086,
      "logps/rejected": -115.39424133300781,
      "loss": 0.5977,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.1576298028230667,
      "rewards/margins": 0.582163393497467,
      "rewards/rejected": -0.7397931814193726,
      "step": 420
    },
    {
      "epoch": 0.07847431334975818,
      "grad_norm": 5.218918800354004,
      "learning_rate": 7.585663351473073e-05,
      "logits/chosen": -2.626023054122925,
      "logits/rejected": -2.549999475479126,
      "logps/chosen": -121.9181900024414,
      "logps/rejected": -109.33283996582031,
      "loss": 0.6422,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.2513018250465393,
      "rewards/margins": 0.33574801683425903,
      "rewards/rejected": -0.08444613963365555,
      "step": 430
    },
    {
      "epoch": 0.08029929738114791,
      "grad_norm": 4.131470203399658,
      "learning_rate": 7.570651154062676e-05,
      "logits/chosen": -2.5806143283843994,
      "logits/rejected": -2.5145561695098877,
      "logps/chosen": -123.83030700683594,
      "logps/rejected": -116.69466400146484,
      "loss": 0.5657,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.2654868960380554,
      "rewards/margins": 0.6025069952011108,
      "rewards/rejected": -0.3370201587677002,
      "step": 440
    },
    {
      "epoch": 0.08212428141253764,
      "grad_norm": 5.978945255279541,
      "learning_rate": 7.55563895665228e-05,
      "logits/chosen": -2.557781219482422,
      "logits/rejected": -2.5713109970092773,
      "logps/chosen": -126.95957946777344,
      "logps/rejected": -118.6000747680664,
      "loss": 0.6257,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.026292767375707626,
      "rewards/margins": 0.4477049708366394,
      "rewards/rejected": -0.42141228914260864,
      "step": 450
    },
    {
      "epoch": 0.08394926544392736,
      "grad_norm": 5.738992691040039,
      "learning_rate": 7.540626759241885e-05,
      "logits/chosen": -2.6588683128356934,
      "logits/rejected": -2.552781581878662,
      "logps/chosen": -130.19845581054688,
      "logps/rejected": -106.9281005859375,
      "loss": 0.5912,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.28140977025032043,
      "rewards/margins": 0.5394867062568665,
      "rewards/rejected": -0.2580769956111908,
      "step": 460
    },
    {
      "epoch": 0.08577424947531709,
      "grad_norm": 4.658355236053467,
      "learning_rate": 7.525614561831489e-05,
      "logits/chosen": -2.6880850791931152,
      "logits/rejected": -2.646151065826416,
      "logps/chosen": -115.628173828125,
      "logps/rejected": -112.38771057128906,
      "loss": 0.5708,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.1564420759677887,
      "rewards/margins": 0.6854078769683838,
      "rewards/rejected": -0.8418499827384949,
      "step": 470
    },
    {
      "epoch": 0.08759923350670681,
      "grad_norm": 4.781117916107178,
      "learning_rate": 7.510602364421092e-05,
      "logits/chosen": -2.6935341358184814,
      "logits/rejected": -2.670687437057495,
      "logps/chosen": -127.08296203613281,
      "logps/rejected": -124.52561950683594,
      "loss": 0.6673,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.7136963605880737,
      "rewards/margins": 0.24407267570495605,
      "rewards/rejected": -0.9577690362930298,
      "step": 480
    },
    {
      "epoch": 0.08942421753809654,
      "grad_norm": 5.896699905395508,
      "learning_rate": 7.495590167010696e-05,
      "logits/chosen": -2.583914041519165,
      "logits/rejected": -2.412356376647949,
      "logps/chosen": -141.41464233398438,
      "logps/rejected": -110.3458023071289,
      "loss": 0.5155,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.09933874756097794,
      "rewards/margins": 0.7341279983520508,
      "rewards/rejected": -0.8334667086601257,
      "step": 490
    },
    {
      "epoch": 0.09124920156948627,
      "grad_norm": 5.184852123260498,
      "learning_rate": 7.4805779696003e-05,
      "logits/chosen": -2.742464065551758,
      "logits/rejected": -2.705132484436035,
      "logps/chosen": -126.2884521484375,
      "logps/rejected": -122.38545989990234,
      "loss": 0.6144,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.005247050430625677,
      "rewards/margins": 0.5165914297103882,
      "rewards/rejected": -0.511344313621521,
      "step": 500
    },
    {
      "epoch": 0.09307418560087599,
      "grad_norm": 6.949149131774902,
      "learning_rate": 7.465565772189905e-05,
      "logits/chosen": -2.5286946296691895,
      "logits/rejected": -2.5338852405548096,
      "logps/chosen": -136.06211853027344,
      "logps/rejected": -138.07601928710938,
      "loss": 0.596,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.10876383632421494,
      "rewards/margins": 0.5701471567153931,
      "rewards/rejected": -0.4613833427429199,
      "step": 510
    },
    {
      "epoch": 0.09489916963226572,
      "grad_norm": 6.766363620758057,
      "learning_rate": 7.450553574779509e-05,
      "logits/chosen": -2.5907325744628906,
      "logits/rejected": -2.469339370727539,
      "logps/chosen": -131.03048706054688,
      "logps/rejected": -114.92388916015625,
      "loss": 0.504,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.0014572322834283113,
      "rewards/margins": 0.8601886630058289,
      "rewards/rejected": -0.8616459965705872,
      "step": 520
    },
    {
      "epoch": 0.09672415366365544,
      "grad_norm": 7.552542209625244,
      "learning_rate": 7.435541377369113e-05,
      "logits/chosen": -2.5932719707489014,
      "logits/rejected": -2.481029510498047,
      "logps/chosen": -127.78035736083984,
      "logps/rejected": -104.634765625,
      "loss": 0.5561,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.015424849465489388,
      "rewards/margins": 0.7027866840362549,
      "rewards/rejected": -0.7182114720344543,
      "step": 530
    },
    {
      "epoch": 0.09854913769504517,
      "grad_norm": 7.081697463989258,
      "learning_rate": 7.420529179958718e-05,
      "logits/chosen": -2.4101829528808594,
      "logits/rejected": -2.381258726119995,
      "logps/chosen": -125.46781921386719,
      "logps/rejected": -117.5398941040039,
      "loss": 0.6497,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.08212568610906601,
      "rewards/margins": 0.32766222953796387,
      "rewards/rejected": -0.40978795289993286,
      "step": 540
    },
    {
      "epoch": 0.1003741217264349,
      "grad_norm": 4.3826704025268555,
      "learning_rate": 7.40551698254832e-05,
      "logits/chosen": -2.6334338188171387,
      "logits/rejected": -2.5257208347320557,
      "logps/chosen": -147.78945922851562,
      "logps/rejected": -130.20460510253906,
      "loss": 0.4954,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.029406066983938217,
      "rewards/margins": 0.8409723043441772,
      "rewards/rejected": -0.8115663528442383,
      "step": 550
    },
    {
      "epoch": 0.10219910575782462,
      "grad_norm": 6.361285209655762,
      "learning_rate": 7.390504785137925e-05,
      "logits/chosen": -2.5079047679901123,
      "logits/rejected": -2.4888176918029785,
      "logps/chosen": -129.61053466796875,
      "logps/rejected": -122.26799011230469,
      "loss": 0.6448,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.39324718713760376,
      "rewards/margins": 0.5893646478652954,
      "rewards/rejected": -0.9826118350028992,
      "step": 560
    },
    {
      "epoch": 0.10402408978921435,
      "grad_norm": 6.809459686279297,
      "learning_rate": 7.375492587727529e-05,
      "logits/chosen": -2.5478739738464355,
      "logits/rejected": -2.5057766437530518,
      "logps/chosen": -117.72648620605469,
      "logps/rejected": -120.2489013671875,
      "loss": 0.6247,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.25634393095970154,
      "rewards/margins": 0.42162132263183594,
      "rewards/rejected": -0.6779652833938599,
      "step": 570
    },
    {
      "epoch": 0.10584907382060407,
      "grad_norm": 3.763997793197632,
      "learning_rate": 7.360480390317134e-05,
      "logits/chosen": -2.538367509841919,
      "logits/rejected": -2.515641689300537,
      "logps/chosen": -134.01498413085938,
      "logps/rejected": -126.98728942871094,
      "loss": 0.6296,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.47191914916038513,
      "rewards/margins": 0.4867115914821625,
      "rewards/rejected": -0.9586307406425476,
      "step": 580
    },
    {
      "epoch": 0.1076740578519938,
      "grad_norm": 6.670726776123047,
      "learning_rate": 7.345468192906738e-05,
      "logits/chosen": -2.4321091175079346,
      "logits/rejected": -2.255439043045044,
      "logps/chosen": -132.9988250732422,
      "logps/rejected": -95.72122955322266,
      "loss": 0.6085,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.06383226811885834,
      "rewards/margins": 0.49843111634254456,
      "rewards/rejected": -0.5622633695602417,
      "step": 590
    },
    {
      "epoch": 0.10949904188338352,
      "grad_norm": 6.743649482727051,
      "learning_rate": 7.330455995496342e-05,
      "logits/chosen": -2.524258613586426,
      "logits/rejected": -2.425873041152954,
      "logps/chosen": -141.1539306640625,
      "logps/rejected": -122.58866119384766,
      "loss": 0.538,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.3072824478149414,
      "rewards/margins": 0.6136423349380493,
      "rewards/rejected": -0.9209247827529907,
      "step": 600
    },
    {
      "epoch": 0.11132402591477325,
      "grad_norm": 2.351278305053711,
      "learning_rate": 7.315443798085945e-05,
      "logits/chosen": -2.403547525405884,
      "logits/rejected": -2.2781898975372314,
      "logps/chosen": -129.04078674316406,
      "logps/rejected": -119.66252136230469,
      "loss": 0.5928,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.2942622900009155,
      "rewards/margins": 0.6187402606010437,
      "rewards/rejected": -0.3244779109954834,
      "step": 610
    },
    {
      "epoch": 0.11314900994616298,
      "grad_norm": 5.968111515045166,
      "learning_rate": 7.300431600675549e-05,
      "logits/chosen": -2.4770917892456055,
      "logits/rejected": -2.3768279552459717,
      "logps/chosen": -120.24871826171875,
      "logps/rejected": -115.40522766113281,
      "loss": 0.6082,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.37622880935668945,
      "rewards/margins": 0.5056843757629395,
      "rewards/rejected": -0.8819131851196289,
      "step": 620
    },
    {
      "epoch": 0.1149739939775527,
      "grad_norm": 5.77686882019043,
      "learning_rate": 7.285419403265154e-05,
      "logits/chosen": -2.326409101486206,
      "logits/rejected": -2.194523334503174,
      "logps/chosen": -130.678466796875,
      "logps/rejected": -110.91800689697266,
      "loss": 0.5195,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.23800714313983917,
      "rewards/margins": 0.8487952947616577,
      "rewards/rejected": -1.086802363395691,
      "step": 630
    },
    {
      "epoch": 0.11679897800894243,
      "grad_norm": 3.692206859588623,
      "learning_rate": 7.270407205854758e-05,
      "logits/chosen": -2.273200273513794,
      "logits/rejected": -2.164742946624756,
      "logps/chosen": -146.91244506835938,
      "logps/rejected": -119.65030670166016,
      "loss": 0.6249,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.5095165967941284,
      "rewards/margins": 0.541599452495575,
      "rewards/rejected": -1.0511161088943481,
      "step": 640
    },
    {
      "epoch": 0.11862396204033215,
      "grad_norm": 5.193602561950684,
      "learning_rate": 7.255395008444361e-05,
      "logits/chosen": -2.2914652824401855,
      "logits/rejected": -2.1128618717193604,
      "logps/chosen": -151.57261657714844,
      "logps/rejected": -127.3588638305664,
      "loss": 0.4988,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.26039212942123413,
      "rewards/margins": 0.9234476089477539,
      "rewards/rejected": -1.1838397979736328,
      "step": 650
    },
    {
      "epoch": 0.12044894607172187,
      "grad_norm": 5.823806285858154,
      "learning_rate": 7.240382811033965e-05,
      "logits/chosen": -2.270064115524292,
      "logits/rejected": -2.011850595474243,
      "logps/chosen": -145.9517822265625,
      "logps/rejected": -112.30525207519531,
      "loss": 0.4959,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.05774650722742081,
      "rewards/margins": 0.8850286602973938,
      "rewards/rejected": -0.9427751302719116,
      "step": 660
    },
    {
      "epoch": 0.12227393010311159,
      "grad_norm": 6.302151679992676,
      "learning_rate": 7.225370613623571e-05,
      "logits/chosen": -2.3586490154266357,
      "logits/rejected": -2.2045884132385254,
      "logps/chosen": -135.44009399414062,
      "logps/rejected": -120.08485412597656,
      "loss": 0.6055,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.2018243372440338,
      "rewards/margins": 0.6951358914375305,
      "rewards/rejected": -0.4933115541934967,
      "step": 670
    },
    {
      "epoch": 0.12409891413450132,
      "grad_norm": 5.334803104400635,
      "learning_rate": 7.210358416213174e-05,
      "logits/chosen": -2.2527031898498535,
      "logits/rejected": -2.1408021450042725,
      "logps/chosen": -113.21577453613281,
      "logps/rejected": -104.32170104980469,
      "loss": 0.5679,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.03384014964103699,
      "rewards/margins": 0.7510592937469482,
      "rewards/rejected": -0.7848995327949524,
      "step": 680
    },
    {
      "epoch": 0.12592389816589106,
      "grad_norm": 6.354593753814697,
      "learning_rate": 7.195346218802778e-05,
      "logits/chosen": -2.359356164932251,
      "logits/rejected": -2.171511173248291,
      "logps/chosen": -134.26951599121094,
      "logps/rejected": -125.64710998535156,
      "loss": 0.5464,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.3692227900028229,
      "rewards/margins": 0.6993604898452759,
      "rewards/rejected": -0.3301376700401306,
      "step": 690
    },
    {
      "epoch": 0.12774888219728078,
      "grad_norm": 4.249727725982666,
      "learning_rate": 7.180334021392382e-05,
      "logits/chosen": -2.3720650672912598,
      "logits/rejected": -2.121351480484009,
      "logps/chosen": -152.93502807617188,
      "logps/rejected": -117.6482162475586,
      "loss": 0.5648,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.029986146837472916,
      "rewards/margins": 0.6694357395172119,
      "rewards/rejected": -0.6394495368003845,
      "step": 700
    },
    {
      "epoch": 0.1295738662286705,
      "grad_norm": 5.313299179077148,
      "learning_rate": 7.165321823981987e-05,
      "logits/chosen": -2.268944501876831,
      "logits/rejected": -2.154700756072998,
      "logps/chosen": -127.96134948730469,
      "logps/rejected": -106.9772720336914,
      "loss": 0.6146,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.4030340313911438,
      "rewards/margins": 0.675213098526001,
      "rewards/rejected": -1.0782470703125,
      "step": 710
    },
    {
      "epoch": 0.13139885026006023,
      "grad_norm": 5.201636791229248,
      "learning_rate": 7.15030962657159e-05,
      "logits/chosen": -2.2315661907196045,
      "logits/rejected": -2.0668959617614746,
      "logps/chosen": -137.91249084472656,
      "logps/rejected": -119.85139465332031,
      "loss": 0.5993,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.19744831323623657,
      "rewards/margins": 0.4911559522151947,
      "rewards/rejected": -0.2937076687812805,
      "step": 720
    },
    {
      "epoch": 0.13322383429144996,
      "grad_norm": 4.83179235458374,
      "learning_rate": 7.135297429161194e-05,
      "logits/chosen": -2.284498453140259,
      "logits/rejected": -2.134402275085449,
      "logps/chosen": -130.14895629882812,
      "logps/rejected": -116.96610260009766,
      "loss": 0.5772,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.06327281147241592,
      "rewards/margins": 0.6195738911628723,
      "rewards/rejected": -0.6828466653823853,
      "step": 730
    },
    {
      "epoch": 0.1350488183228397,
      "grad_norm": 4.7251763343811035,
      "learning_rate": 7.120285231750798e-05,
      "logits/chosen": -2.423295497894287,
      "logits/rejected": -2.2911691665649414,
      "logps/chosen": -122.83480072021484,
      "logps/rejected": -111.5543441772461,
      "loss": 0.6113,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.2129041850566864,
      "rewards/margins": 0.5485730171203613,
      "rewards/rejected": -0.7614772319793701,
      "step": 740
    },
    {
      "epoch": 0.1368738023542294,
      "grad_norm": 6.2697367668151855,
      "learning_rate": 7.105273034340402e-05,
      "logits/chosen": -2.4703900814056396,
      "logits/rejected": -2.3008005619049072,
      "logps/chosen": -124.46675872802734,
      "logps/rejected": -114.17628479003906,
      "loss": 0.4836,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.2585311830043793,
      "rewards/margins": 1.0688350200653076,
      "rewards/rejected": -1.3273664712905884,
      "step": 750
    },
    {
      "epoch": 0.13869878638561914,
      "grad_norm": 4.5650506019592285,
      "learning_rate": 7.090260836930007e-05,
      "logits/chosen": -2.368557929992676,
      "logits/rejected": -2.2271108627319336,
      "logps/chosen": -129.56881713867188,
      "logps/rejected": -113.86917877197266,
      "loss": 0.6025,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.17974944412708282,
      "rewards/margins": 0.6690826416015625,
      "rewards/rejected": -0.8488321304321289,
      "step": 760
    },
    {
      "epoch": 0.14052377041700886,
      "grad_norm": 3.7191967964172363,
      "learning_rate": 7.075248639519611e-05,
      "logits/chosen": -2.420424699783325,
      "logits/rejected": -2.2223916053771973,
      "logps/chosen": -139.68984985351562,
      "logps/rejected": -104.4108657836914,
      "loss": 0.6023,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.18475957214832306,
      "rewards/margins": 0.5241340398788452,
      "rewards/rejected": -0.7088936567306519,
      "step": 770
    },
    {
      "epoch": 0.1423487544483986,
      "grad_norm": 6.867656230926514,
      "learning_rate": 7.060236442109214e-05,
      "logits/chosen": -2.425081253051758,
      "logits/rejected": -2.422138214111328,
      "logps/chosen": -126.7109146118164,
      "logps/rejected": -137.1927490234375,
      "loss": 0.6431,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.4722270965576172,
      "rewards/margins": 0.43136778473854065,
      "rewards/rejected": -0.9035948514938354,
      "step": 780
    },
    {
      "epoch": 0.1441737384797883,
      "grad_norm": 3.062455415725708,
      "learning_rate": 7.045224244698818e-05,
      "logits/chosen": -2.456149101257324,
      "logits/rejected": -2.3690333366394043,
      "logps/chosen": -125.92921447753906,
      "logps/rejected": -117.0735855102539,
      "loss": 0.5021,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6042095422744751,
      "rewards/margins": 0.7039594650268555,
      "rewards/rejected": -1.308168888092041,
      "step": 790
    },
    {
      "epoch": 0.14599872251117801,
      "grad_norm": 6.813319206237793,
      "learning_rate": 7.030212047288422e-05,
      "logits/chosen": -2.3868536949157715,
      "logits/rejected": -2.300809621810913,
      "logps/chosen": -135.36862182617188,
      "logps/rejected": -119.01078796386719,
      "loss": 0.5901,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.897312343120575,
      "rewards/margins": 0.6886463165283203,
      "rewards/rejected": -1.5859586000442505,
      "step": 800
    },
    {
      "epoch": 0.14782370654256774,
      "grad_norm": 5.027698516845703,
      "learning_rate": 7.015199849878027e-05,
      "logits/chosen": -2.4423699378967285,
      "logits/rejected": -2.3396732807159424,
      "logps/chosen": -130.99752807617188,
      "logps/rejected": -118.73158264160156,
      "loss": 0.5306,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.40793076157569885,
      "rewards/margins": 0.8042293787002563,
      "rewards/rejected": -1.2121601104736328,
      "step": 810
    },
    {
      "epoch": 0.14964869057395747,
      "grad_norm": 4.407551288604736,
      "learning_rate": 7.00018765246763e-05,
      "logits/chosen": -2.4779868125915527,
      "logits/rejected": -2.3624095916748047,
      "logps/chosen": -134.3787078857422,
      "logps/rejected": -120.15606689453125,
      "loss": 0.5837,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.3815816342830658,
      "rewards/margins": 0.6236292123794556,
      "rewards/rejected": -1.0052108764648438,
      "step": 820
    },
    {
      "epoch": 0.1514736746053472,
      "grad_norm": 4.537209510803223,
      "learning_rate": 6.985175455057234e-05,
      "logits/chosen": -2.4696946144104004,
      "logits/rejected": -2.3498520851135254,
      "logps/chosen": -133.44277954101562,
      "logps/rejected": -123.7242660522461,
      "loss": 0.6052,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.2471567690372467,
      "rewards/margins": 0.5462091565132141,
      "rewards/rejected": -0.793366014957428,
      "step": 830
    },
    {
      "epoch": 0.15329865863673692,
      "grad_norm": 3.5452582836151123,
      "learning_rate": 6.97016325764684e-05,
      "logits/chosen": -2.4201321601867676,
      "logits/rejected": -2.3098537921905518,
      "logps/chosen": -128.57669067382812,
      "logps/rejected": -115.36895751953125,
      "loss": 0.5322,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.12609337270259857,
      "rewards/margins": 0.7072848677635193,
      "rewards/rejected": -0.8333781957626343,
      "step": 840
    },
    {
      "epoch": 0.15512364266812664,
      "grad_norm": 4.5515828132629395,
      "learning_rate": 6.955151060236442e-05,
      "logits/chosen": -2.3178954124450684,
      "logits/rejected": -2.2341091632843018,
      "logps/chosen": -127.1375503540039,
      "logps/rejected": -117.59881591796875,
      "loss": 0.5391,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.27029579877853394,
      "rewards/margins": 0.881003201007843,
      "rewards/rejected": -1.1512988805770874,
      "step": 850
    },
    {
      "epoch": 0.15694862669951637,
      "grad_norm": 4.500773906707764,
      "learning_rate": 6.940138862826047e-05,
      "logits/chosen": -2.4026572704315186,
      "logits/rejected": -2.2819314002990723,
      "logps/chosen": -137.82608032226562,
      "logps/rejected": -127.93418884277344,
      "loss": 0.5521,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.19488771259784698,
      "rewards/margins": 0.7989031076431274,
      "rewards/rejected": -0.9937908053398132,
      "step": 860
    },
    {
      "epoch": 0.1587736107309061,
      "grad_norm": 5.860198020935059,
      "learning_rate": 6.925126665415651e-05,
      "logits/chosen": -2.5292282104492188,
      "logits/rejected": -2.385125160217285,
      "logps/chosen": -147.71401977539062,
      "logps/rejected": -133.5926513671875,
      "loss": 0.5137,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.48812705278396606,
      "rewards/margins": 1.0082249641418457,
      "rewards/rejected": -1.496351957321167,
      "step": 870
    },
    {
      "epoch": 0.16059859476229582,
      "grad_norm": 6.454724311828613,
      "learning_rate": 6.910114468005255e-05,
      "logits/chosen": -2.5165629386901855,
      "logits/rejected": -2.4022879600524902,
      "logps/chosen": -148.0371856689453,
      "logps/rejected": -147.17056274414062,
      "loss": 0.5454,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6941507458686829,
      "rewards/margins": 0.9011728167533875,
      "rewards/rejected": -1.5953234434127808,
      "step": 880
    },
    {
      "epoch": 0.16242357879368555,
      "grad_norm": 6.465231418609619,
      "learning_rate": 6.895102270594858e-05,
      "logits/chosen": -2.3132951259613037,
      "logits/rejected": -2.129194736480713,
      "logps/chosen": -156.94302368164062,
      "logps/rejected": -131.30967712402344,
      "loss": 0.6548,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.6330863833427429,
      "rewards/margins": 0.6548758149147034,
      "rewards/rejected": -1.2879621982574463,
      "step": 890
    },
    {
      "epoch": 0.16424856282507527,
      "grad_norm": 7.518553256988525,
      "learning_rate": 6.880090073184463e-05,
      "logits/chosen": -2.4045073986053467,
      "logits/rejected": -2.3353004455566406,
      "logps/chosen": -120.90834045410156,
      "logps/rejected": -122.2747573852539,
      "loss": 0.6169,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.36298704147338867,
      "rewards/margins": 0.5238158702850342,
      "rewards/rejected": -0.8868028521537781,
      "step": 900
    },
    {
      "epoch": 0.166073546856465,
      "grad_norm": 5.443199634552002,
      "learning_rate": 6.865077875774067e-05,
      "logits/chosen": -2.366541862487793,
      "logits/rejected": -2.2710070610046387,
      "logps/chosen": -127.6979751586914,
      "logps/rejected": -124.40291595458984,
      "loss": 0.5645,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.20076778531074524,
      "rewards/margins": 0.6593181490898132,
      "rewards/rejected": -0.8600858449935913,
      "step": 910
    },
    {
      "epoch": 0.16789853088785472,
      "grad_norm": 3.9979658126831055,
      "learning_rate": 6.850065678363671e-05,
      "logits/chosen": -2.404282331466675,
      "logits/rejected": -2.269378900527954,
      "logps/chosen": -132.6209716796875,
      "logps/rejected": -124.2505874633789,
      "loss": 0.5522,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.2921580374240875,
      "rewards/margins": 0.7119413018226624,
      "rewards/rejected": -1.0040992498397827,
      "step": 920
    },
    {
      "epoch": 0.16972351491924445,
      "grad_norm": 6.273191928863525,
      "learning_rate": 6.835053480953275e-05,
      "logits/chosen": -2.499884843826294,
      "logits/rejected": -2.3457553386688232,
      "logps/chosen": -139.37437438964844,
      "logps/rejected": -126.6839599609375,
      "loss": 0.5862,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9563049077987671,
      "rewards/margins": 0.7186662554740906,
      "rewards/rejected": -1.6749712228775024,
      "step": 930
    },
    {
      "epoch": 0.17154849895063418,
      "grad_norm": 5.999586582183838,
      "learning_rate": 6.82004128354288e-05,
      "logits/chosen": -2.448413848876953,
      "logits/rejected": -2.33870530128479,
      "logps/chosen": -134.9854736328125,
      "logps/rejected": -122.66090393066406,
      "loss": 0.5661,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.241676688194275,
      "rewards/margins": 0.7504304647445679,
      "rewards/rejected": -1.9921071529388428,
      "step": 940
    },
    {
      "epoch": 0.1733734829820239,
      "grad_norm": 11.04850959777832,
      "learning_rate": 6.805029086132483e-05,
      "logits/chosen": -2.481904983520508,
      "logits/rejected": -2.344914436340332,
      "logps/chosen": -139.21348571777344,
      "logps/rejected": -114.75898742675781,
      "loss": 0.5533,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8395435214042664,
      "rewards/margins": 0.8010191917419434,
      "rewards/rejected": -1.6405627727508545,
      "step": 950
    },
    {
      "epoch": 0.17519846701341363,
      "grad_norm": 5.105612754821777,
      "learning_rate": 6.790016888722087e-05,
      "logits/chosen": -2.544034481048584,
      "logits/rejected": -2.419166088104248,
      "logps/chosen": -150.27598571777344,
      "logps/rejected": -133.57876586914062,
      "loss": 0.5329,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4681715965270996,
      "rewards/margins": 0.8365251421928406,
      "rewards/rejected": -2.304696559906006,
      "step": 960
    },
    {
      "epoch": 0.17702345104480335,
      "grad_norm": 7.1640119552612305,
      "learning_rate": 6.775004691311691e-05,
      "logits/chosen": -2.394923686981201,
      "logits/rejected": -2.295867443084717,
      "logps/chosen": -138.51473999023438,
      "logps/rejected": -136.36927795410156,
      "loss": 0.6263,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.3491779565811157,
      "rewards/margins": 0.8803084492683411,
      "rewards/rejected": -2.2294862270355225,
      "step": 970
    },
    {
      "epoch": 0.17884843507619308,
      "grad_norm": 6.398427963256836,
      "learning_rate": 6.759992493901295e-05,
      "logits/chosen": -2.4076859951019287,
      "logits/rejected": -2.3931145668029785,
      "logps/chosen": -130.76473999023438,
      "logps/rejected": -128.24227905273438,
      "loss": 0.5797,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.1455062627792358,
      "rewards/margins": 0.6054573655128479,
      "rewards/rejected": -1.750963568687439,
      "step": 980
    },
    {
      "epoch": 0.1806734191075828,
      "grad_norm": 6.774322986602783,
      "learning_rate": 6.744980296490898e-05,
      "logits/chosen": -2.5532631874084473,
      "logits/rejected": -2.391590118408203,
      "logps/chosen": -135.75241088867188,
      "logps/rejected": -114.87972259521484,
      "loss": 0.6633,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.3175690174102783,
      "rewards/margins": 0.5457120537757874,
      "rewards/rejected": -1.863281011581421,
      "step": 990
    },
    {
      "epoch": 0.18249840313897253,
      "grad_norm": 6.526928424835205,
      "learning_rate": 6.729968099080504e-05,
      "logits/chosen": -2.510079860687256,
      "logits/rejected": -2.3843324184417725,
      "logps/chosen": -153.59127807617188,
      "logps/rejected": -135.2144775390625,
      "loss": 0.5151,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.875012993812561,
      "rewards/margins": 0.8980299234390259,
      "rewards/rejected": -1.7730426788330078,
      "step": 1000
    },
    {
      "epoch": 0.18432338717036226,
      "grad_norm": 6.293522834777832,
      "learning_rate": 6.714955901670108e-05,
      "logits/chosen": -2.427852153778076,
      "logits/rejected": -2.2644827365875244,
      "logps/chosen": -137.5253143310547,
      "logps/rejected": -118.59608459472656,
      "loss": 0.5669,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0853010416030884,
      "rewards/margins": 0.8168166875839233,
      "rewards/rejected": -1.9021174907684326,
      "step": 1010
    },
    {
      "epoch": 0.18614837120175198,
      "grad_norm": 5.481391429901123,
      "learning_rate": 6.699943704259711e-05,
      "logits/chosen": -2.389798641204834,
      "logits/rejected": -2.3187057971954346,
      "logps/chosen": -127.0828628540039,
      "logps/rejected": -131.07522583007812,
      "loss": 0.6053,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.749494194984436,
      "rewards/margins": 0.6310063600540161,
      "rewards/rejected": -1.3805005550384521,
      "step": 1020
    },
    {
      "epoch": 0.1879733552331417,
      "grad_norm": 5.0605950355529785,
      "learning_rate": 6.684931506849316e-05,
      "logits/chosen": -2.43554949760437,
      "logits/rejected": -2.307060956954956,
      "logps/chosen": -131.4115753173828,
      "logps/rejected": -124.50384521484375,
      "loss": 0.5047,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.815169632434845,
      "rewards/margins": 0.932111918926239,
      "rewards/rejected": -1.7472814321517944,
      "step": 1030
    },
    {
      "epoch": 0.18979833926453143,
      "grad_norm": 4.8618083000183105,
      "learning_rate": 6.66991930943892e-05,
      "logits/chosen": -2.4839491844177246,
      "logits/rejected": -2.3556137084960938,
      "logps/chosen": -142.83792114257812,
      "logps/rejected": -123.80489349365234,
      "loss": 0.5836,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.4870050847530365,
      "rewards/margins": 0.7459557056427002,
      "rewards/rejected": -1.2329607009887695,
      "step": 1040
    },
    {
      "epoch": 0.19162332329592116,
      "grad_norm": 3.6622776985168457,
      "learning_rate": 6.654907112028524e-05,
      "logits/chosen": -2.531322717666626,
      "logits/rejected": -2.440359115600586,
      "logps/chosen": -115.60020446777344,
      "logps/rejected": -111.0457534790039,
      "loss": 0.5232,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.45894449949264526,
      "rewards/margins": 0.8091202974319458,
      "rewards/rejected": -1.2680647373199463,
      "step": 1050
    },
    {
      "epoch": 0.1934483073273109,
      "grad_norm": 7.836673259735107,
      "learning_rate": 6.639894914618127e-05,
      "logits/chosen": -2.49802303314209,
      "logits/rejected": -2.440685987472534,
      "logps/chosen": -130.7918701171875,
      "logps/rejected": -126.92253112792969,
      "loss": 0.4686,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.381725013256073,
      "rewards/margins": 0.9662340879440308,
      "rewards/rejected": -1.3479589223861694,
      "step": 1060
    },
    {
      "epoch": 0.1952732913587006,
      "grad_norm": 5.573409557342529,
      "learning_rate": 6.624882717207731e-05,
      "logits/chosen": -2.524630308151245,
      "logits/rejected": -2.3812053203582764,
      "logps/chosen": -154.6499786376953,
      "logps/rejected": -139.73898315429688,
      "loss": 0.5902,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8214042782783508,
      "rewards/margins": 0.8618475794792175,
      "rewards/rejected": -1.6832520961761475,
      "step": 1070
    },
    {
      "epoch": 0.19709827539009034,
      "grad_norm": 6.035401344299316,
      "learning_rate": 6.609870519797336e-05,
      "logits/chosen": -2.5854105949401855,
      "logits/rejected": -2.514192819595337,
      "logps/chosen": -134.67471313476562,
      "logps/rejected": -143.81130981445312,
      "loss": 0.4418,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.7997631430625916,
      "rewards/margins": 1.2404272556304932,
      "rewards/rejected": -2.0401902198791504,
      "step": 1080
    },
    {
      "epoch": 0.19892325942148006,
      "grad_norm": 5.953843116760254,
      "learning_rate": 6.59485832238694e-05,
      "logits/chosen": -2.33463716506958,
      "logits/rejected": -2.188509702682495,
      "logps/chosen": -150.18972778320312,
      "logps/rejected": -132.79995727539062,
      "loss": 0.6007,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.9621580243110657,
      "rewards/margins": 0.8307898640632629,
      "rewards/rejected": -1.792947769165039,
      "step": 1090
    },
    {
      "epoch": 0.2007482434528698,
      "grad_norm": 4.943575382232666,
      "learning_rate": 6.579846124976544e-05,
      "logits/chosen": -2.391397714614868,
      "logits/rejected": -2.2935791015625,
      "logps/chosen": -125.4947509765625,
      "logps/rejected": -124.06864929199219,
      "loss": 0.6114,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7522364854812622,
      "rewards/margins": 1.0034363269805908,
      "rewards/rejected": -1.7556726932525635,
      "step": 1100
    },
    {
      "epoch": 0.20257322748425952,
      "grad_norm": 6.450965881347656,
      "learning_rate": 6.564833927566149e-05,
      "logits/chosen": -2.4050636291503906,
      "logits/rejected": -2.4067282676696777,
      "logps/chosen": -132.52896118164062,
      "logps/rejected": -142.35919189453125,
      "loss": 0.6478,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0614303350448608,
      "rewards/margins": 0.49867886304855347,
      "rewards/rejected": -1.560109257698059,
      "step": 1110
    },
    {
      "epoch": 0.20439821151564924,
      "grad_norm": 3.131413459777832,
      "learning_rate": 6.549821730155751e-05,
      "logits/chosen": -2.4209225177764893,
      "logits/rejected": -2.3500735759735107,
      "logps/chosen": -140.531982421875,
      "logps/rejected": -126.39424133300781,
      "loss": 0.5963,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0854474306106567,
      "rewards/margins": 0.7593299150466919,
      "rewards/rejected": -1.8447773456573486,
      "step": 1120
    },
    {
      "epoch": 0.20622319554703897,
      "grad_norm": 4.549625396728516,
      "learning_rate": 6.534809532745356e-05,
      "logits/chosen": -2.414698600769043,
      "logits/rejected": -2.256965160369873,
      "logps/chosen": -128.01502990722656,
      "logps/rejected": -108.08036041259766,
      "loss": 0.5586,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8318570852279663,
      "rewards/margins": 0.782321572303772,
      "rewards/rejected": -1.6141786575317383,
      "step": 1130
    },
    {
      "epoch": 0.2080481795784287,
      "grad_norm": 5.082957744598389,
      "learning_rate": 6.51979733533496e-05,
      "logits/chosen": -2.389068126678467,
      "logits/rejected": -2.343829870223999,
      "logps/chosen": -128.438720703125,
      "logps/rejected": -130.6393280029297,
      "loss": 0.6267,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.2190165519714355,
      "rewards/margins": 0.48549890518188477,
      "rewards/rejected": -1.7045156955718994,
      "step": 1140
    },
    {
      "epoch": 0.20987316360981842,
      "grad_norm": 4.995397567749023,
      "learning_rate": 6.504785137924564e-05,
      "logits/chosen": -2.427371025085449,
      "logits/rejected": -2.327606678009033,
      "logps/chosen": -135.20333862304688,
      "logps/rejected": -127.95650482177734,
      "loss": 0.4964,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0586885213851929,
      "rewards/margins": 0.8407958745956421,
      "rewards/rejected": -1.899484395980835,
      "step": 1150
    },
    {
      "epoch": 0.21169814764120815,
      "grad_norm": 5.50068473815918,
      "learning_rate": 6.489772940514169e-05,
      "logits/chosen": -2.362161159515381,
      "logits/rejected": -2.2477846145629883,
      "logps/chosen": -141.8004913330078,
      "logps/rejected": -138.76034545898438,
      "loss": 0.4737,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6230512857437134,
      "rewards/margins": 1.082279086112976,
      "rewards/rejected": -2.7053303718566895,
      "step": 1160
    },
    {
      "epoch": 0.21352313167259787,
      "grad_norm": 5.506470203399658,
      "learning_rate": 6.474760743103773e-05,
      "logits/chosen": -2.5355844497680664,
      "logits/rejected": -2.3945956230163574,
      "logps/chosen": -138.45620727539062,
      "logps/rejected": -119.66615295410156,
      "loss": 0.5288,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.039268970489502,
      "rewards/margins": 0.882726788520813,
      "rewards/rejected": -2.9219958782196045,
      "step": 1170
    },
    {
      "epoch": 0.2153481157039876,
      "grad_norm": 4.613704681396484,
      "learning_rate": 6.459748545693377e-05,
      "logits/chosen": -2.500521421432495,
      "logits/rejected": -2.365741014480591,
      "logps/chosen": -146.05018615722656,
      "logps/rejected": -135.2683868408203,
      "loss": 0.5557,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.9299094676971436,
      "rewards/margins": 0.9450410604476929,
      "rewards/rejected": -2.874950408935547,
      "step": 1180
    },
    {
      "epoch": 0.21717309973537732,
      "grad_norm": 6.401017665863037,
      "learning_rate": 6.44473634828298e-05,
      "logits/chosen": -2.4197421073913574,
      "logits/rejected": -2.34808349609375,
      "logps/chosen": -133.9452667236328,
      "logps/rejected": -127.93965148925781,
      "loss": 0.4766,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3447695970535278,
      "rewards/margins": 1.094456672668457,
      "rewards/rejected": -2.4392263889312744,
      "step": 1190
    },
    {
      "epoch": 0.21899808376676705,
      "grad_norm": 4.368514537811279,
      "learning_rate": 6.429724150872584e-05,
      "logits/chosen": -2.362884521484375,
      "logits/rejected": -2.3503148555755615,
      "logps/chosen": -137.03402709960938,
      "logps/rejected": -134.60804748535156,
      "loss": 0.6039,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.9652663469314575,
      "rewards/margins": 0.6017603278160095,
      "rewards/rejected": -1.5670266151428223,
      "step": 1200
    },
    {
      "epoch": 0.22082306779815677,
      "grad_norm": 7.608809947967529,
      "learning_rate": 6.414711953462189e-05,
      "logits/chosen": -2.622056245803833,
      "logits/rejected": -2.4871668815612793,
      "logps/chosen": -143.38377380371094,
      "logps/rejected": -123.92106628417969,
      "loss": 0.644,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.6028165221214294,
      "rewards/margins": 0.6768338680267334,
      "rewards/rejected": -1.279650330543518,
      "step": 1210
    },
    {
      "epoch": 0.2226480518295465,
      "grad_norm": 3.892611026763916,
      "learning_rate": 6.399699756051793e-05,
      "logits/chosen": -2.4629173278808594,
      "logits/rejected": -2.388688802719116,
      "logps/chosen": -124.7882308959961,
      "logps/rejected": -111.50335693359375,
      "loss": 0.5548,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.6693869829177856,
      "rewards/margins": 0.674685001373291,
      "rewards/rejected": -1.3440719842910767,
      "step": 1220
    },
    {
      "epoch": 0.22447303586093623,
      "grad_norm": 3.369145393371582,
      "learning_rate": 6.384687558641396e-05,
      "logits/chosen": -2.4583137035369873,
      "logits/rejected": -2.3792366981506348,
      "logps/chosen": -127.06974792480469,
      "logps/rejected": -122.7020263671875,
      "loss": 0.5648,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5540033578872681,
      "rewards/margins": 0.712666392326355,
      "rewards/rejected": -1.266669750213623,
      "step": 1230
    },
    {
      "epoch": 0.22629801989232595,
      "grad_norm": 4.4783244132995605,
      "learning_rate": 6.369675361231e-05,
      "logits/chosen": -2.716966152191162,
      "logits/rejected": -2.582900047302246,
      "logps/chosen": -152.9979248046875,
      "logps/rejected": -122.182373046875,
      "loss": 0.5055,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.39739760756492615,
      "rewards/margins": 0.8267094492912292,
      "rewards/rejected": -1.2241071462631226,
      "step": 1240
    },
    {
      "epoch": 0.22812300392371568,
      "grad_norm": 7.28573751449585,
      "learning_rate": 6.354663163820604e-05,
      "logits/chosen": -2.4918770790100098,
      "logits/rejected": -2.4206128120422363,
      "logps/chosen": -138.80685424804688,
      "logps/rejected": -130.43716430664062,
      "loss": 0.6189,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.7851712107658386,
      "rewards/margins": 0.6844509840011597,
      "rewards/rejected": -1.4696221351623535,
      "step": 1250
    },
    {
      "epoch": 0.2299479879551054,
      "grad_norm": 5.310054302215576,
      "learning_rate": 6.339650966410209e-05,
      "logits/chosen": -2.4555270671844482,
      "logits/rejected": -2.405569076538086,
      "logps/chosen": -137.32252502441406,
      "logps/rejected": -132.55300903320312,
      "loss": 0.5646,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.5725687742233276,
      "rewards/margins": 0.850002646446228,
      "rewards/rejected": -1.4225714206695557,
      "step": 1260
    },
    {
      "epoch": 0.23177297198649513,
      "grad_norm": 3.544157028198242,
      "learning_rate": 6.324638768999813e-05,
      "logits/chosen": -2.6487698554992676,
      "logits/rejected": -2.4644100666046143,
      "logps/chosen": -156.18663024902344,
      "logps/rejected": -126.03395080566406,
      "loss": 0.5633,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.6773918867111206,
      "rewards/margins": 0.7195534706115723,
      "rewards/rejected": -1.3969454765319824,
      "step": 1270
    },
    {
      "epoch": 0.23359795601788486,
      "grad_norm": 9.233736991882324,
      "learning_rate": 6.309626571589417e-05,
      "logits/chosen": -2.5898778438568115,
      "logits/rejected": -2.504512310028076,
      "logps/chosen": -139.61532592773438,
      "logps/rejected": -130.39382934570312,
      "loss": 0.4992,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.783972442150116,
      "rewards/margins": 0.979466438293457,
      "rewards/rejected": -1.7634388208389282,
      "step": 1280
    },
    {
      "epoch": 0.23542294004927458,
      "grad_norm": 5.080788612365723,
      "learning_rate": 6.29461437417902e-05,
      "logits/chosen": -2.4655723571777344,
      "logits/rejected": -2.3902859687805176,
      "logps/chosen": -124.42559814453125,
      "logps/rejected": -124.17878723144531,
      "loss": 0.5384,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.49612846970558167,
      "rewards/margins": 1.044729471206665,
      "rewards/rejected": -1.5408579111099243,
      "step": 1290
    },
    {
      "epoch": 0.2372479240806643,
      "grad_norm": 7.533785343170166,
      "learning_rate": 6.279602176768625e-05,
      "logits/chosen": -2.5087859630584717,
      "logits/rejected": -2.4531617164611816,
      "logps/chosen": -135.37232971191406,
      "logps/rejected": -127.3398208618164,
      "loss": 0.5262,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7644544243812561,
      "rewards/margins": 0.8927713632583618,
      "rewards/rejected": -1.6572258472442627,
      "step": 1300
    },
    {
      "epoch": 0.23907290811205403,
      "grad_norm": 3.2818033695220947,
      "learning_rate": 6.264589979358229e-05,
      "logits/chosen": -2.449801206588745,
      "logits/rejected": -2.381657600402832,
      "logps/chosen": -141.64906311035156,
      "logps/rejected": -129.57772827148438,
      "loss": 0.6283,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.1463983058929443,
      "rewards/margins": 0.7383068799972534,
      "rewards/rejected": -1.8847051858901978,
      "step": 1310
    },
    {
      "epoch": 0.24089789214344373,
      "grad_norm": 4.745299339294434,
      "learning_rate": 6.249577781947833e-05,
      "logits/chosen": -2.5794246196746826,
      "logits/rejected": -2.5045647621154785,
      "logps/chosen": -127.26114654541016,
      "logps/rejected": -112.7254638671875,
      "loss": 0.522,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.5043220520019531,
      "rewards/margins": 0.8100326657295227,
      "rewards/rejected": -1.314354658126831,
      "step": 1320
    },
    {
      "epoch": 0.24272287617483346,
      "grad_norm": 4.502133369445801,
      "learning_rate": 6.234565584537437e-05,
      "logits/chosen": -2.4728822708129883,
      "logits/rejected": -2.3633182048797607,
      "logps/chosen": -140.64419555664062,
      "logps/rejected": -119.71266174316406,
      "loss": 0.591,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.775110125541687,
      "rewards/margins": 0.6506502032279968,
      "rewards/rejected": -1.4257603883743286,
      "step": 1330
    },
    {
      "epoch": 0.24454786020622318,
      "grad_norm": 3.2724244594573975,
      "learning_rate": 6.219553387127042e-05,
      "logits/chosen": -2.5672426223754883,
      "logits/rejected": -2.57957124710083,
      "logps/chosen": -117.42118835449219,
      "logps/rejected": -126.359130859375,
      "loss": 0.515,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.7201003432273865,
      "rewards/margins": 0.8466984033584595,
      "rewards/rejected": -1.5667986869812012,
      "step": 1340
    },
    {
      "epoch": 0.2463728442376129,
      "grad_norm": 4.71242094039917,
      "learning_rate": 6.204541189716646e-05,
      "logits/chosen": -2.4360573291778564,
      "logits/rejected": -2.4248745441436768,
      "logps/chosen": -122.0933837890625,
      "logps/rejected": -141.76351928710938,
      "loss": 0.5093,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9739343523979187,
      "rewards/margins": 1.0476558208465576,
      "rewards/rejected": -2.021590232849121,
      "step": 1350
    },
    {
      "epoch": 0.24819782826900263,
      "grad_norm": 4.176822185516357,
      "learning_rate": 6.189528992306249e-05,
      "logits/chosen": -2.5131185054779053,
      "logits/rejected": -2.4348227977752686,
      "logps/chosen": -149.7661590576172,
      "logps/rejected": -135.16824340820312,
      "loss": 0.4794,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6509965658187866,
      "rewards/margins": 1.1965477466583252,
      "rewards/rejected": -1.8475440740585327,
      "step": 1360
    },
    {
      "epoch": 0.25002281230039236,
      "grad_norm": 3.655198574066162,
      "learning_rate": 6.174516794895853e-05,
      "logits/chosen": -2.5369884967803955,
      "logits/rejected": -2.5370657444000244,
      "logps/chosen": -125.81111907958984,
      "logps/rejected": -129.30715942382812,
      "loss": 0.5742,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.2178618609905243,
      "rewards/margins": 0.8801935315132141,
      "rewards/rejected": -1.0980554819107056,
      "step": 1370
    },
    {
      "epoch": 0.2518477963317821,
      "grad_norm": 6.030019283294678,
      "learning_rate": 6.159504597485457e-05,
      "logits/chosen": -2.555729389190674,
      "logits/rejected": -2.5088086128234863,
      "logps/chosen": -137.03298950195312,
      "logps/rejected": -136.8401336669922,
      "loss": 0.5144,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6225496530532837,
      "rewards/margins": 0.9992852210998535,
      "rewards/rejected": -1.6218351125717163,
      "step": 1380
    },
    {
      "epoch": 0.2536727803631718,
      "grad_norm": 6.311168670654297,
      "learning_rate": 6.144492400075062e-05,
      "logits/chosen": -2.648054599761963,
      "logits/rejected": -2.5089738368988037,
      "logps/chosen": -146.63900756835938,
      "logps/rejected": -127.59820556640625,
      "loss": 0.5173,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.656701922416687,
      "rewards/margins": 1.0368833541870117,
      "rewards/rejected": -1.6935853958129883,
      "step": 1390
    },
    {
      "epoch": 0.25549776439456157,
      "grad_norm": 6.413686275482178,
      "learning_rate": 6.129480202664665e-05,
      "logits/chosen": -2.665895462036133,
      "logits/rejected": -2.5575289726257324,
      "logps/chosen": -145.99087524414062,
      "logps/rejected": -122.67350769042969,
      "loss": 0.5076,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.25955280661582947,
      "rewards/margins": 1.1264281272888184,
      "rewards/rejected": -1.3859809637069702,
      "step": 1400
    },
    {
      "epoch": 0.25732274842595126,
      "grad_norm": 4.998263359069824,
      "learning_rate": 6.11446800525427e-05,
      "logits/chosen": -2.672637462615967,
      "logits/rejected": -2.522700071334839,
      "logps/chosen": -158.81011962890625,
      "logps/rejected": -129.4644775390625,
      "loss": 0.5428,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.4914552569389343,
      "rewards/margins": 1.3166775703430176,
      "rewards/rejected": -1.8081328868865967,
      "step": 1410
    },
    {
      "epoch": 0.259147732457341,
      "grad_norm": 6.1712117195129395,
      "learning_rate": 6.099455807843874e-05,
      "logits/chosen": -2.5878167152404785,
      "logits/rejected": -2.5219154357910156,
      "logps/chosen": -130.44119262695312,
      "logps/rejected": -129.9792938232422,
      "loss": 0.5534,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.6564422845840454,
      "rewards/margins": 1.1822619438171387,
      "rewards/rejected": -1.8387043476104736,
      "step": 1420
    },
    {
      "epoch": 0.2609727164887307,
      "grad_norm": 4.262754440307617,
      "learning_rate": 6.0844436104334776e-05,
      "logits/chosen": -2.5357327461242676,
      "logits/rejected": -2.4763569831848145,
      "logps/chosen": -120.86991882324219,
      "logps/rejected": -112.57060241699219,
      "loss": 0.5982,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.36312198638916016,
      "rewards/margins": 0.8215511441230774,
      "rewards/rejected": -1.1846731901168823,
      "step": 1430
    },
    {
      "epoch": 0.26279770052012047,
      "grad_norm": 5.5492472648620605,
      "learning_rate": 6.069431413023082e-05,
      "logits/chosen": -2.7115018367767334,
      "logits/rejected": -2.523409128189087,
      "logps/chosen": -140.5504913330078,
      "logps/rejected": -113.27256774902344,
      "loss": 0.5483,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.31776130199432373,
      "rewards/margins": 1.0727494955062866,
      "rewards/rejected": -1.3905109167099,
      "step": 1440
    },
    {
      "epoch": 0.26462268455151017,
      "grad_norm": 3.6189074516296387,
      "learning_rate": 6.0544192156126855e-05,
      "logits/chosen": -2.6004137992858887,
      "logits/rejected": -2.578737258911133,
      "logps/chosen": -118.08768463134766,
      "logps/rejected": -124.51849365234375,
      "loss": 0.5433,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.6206476092338562,
      "rewards/margins": 0.8523738980293274,
      "rewards/rejected": -1.473021388053894,
      "step": 1450
    },
    {
      "epoch": 0.2664476685828999,
      "grad_norm": 4.586349010467529,
      "learning_rate": 6.03940701820229e-05,
      "logits/chosen": -2.637589454650879,
      "logits/rejected": -2.5651254653930664,
      "logps/chosen": -126.26082611083984,
      "logps/rejected": -112.00584411621094,
      "loss": 0.5431,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.31443649530410767,
      "rewards/margins": 1.066267490386963,
      "rewards/rejected": -1.3807039260864258,
      "step": 1460
    },
    {
      "epoch": 0.2682726526142896,
      "grad_norm": 4.114231586456299,
      "learning_rate": 6.0243948207918934e-05,
      "logits/chosen": -2.643871307373047,
      "logits/rejected": -2.550901412963867,
      "logps/chosen": -137.64761352539062,
      "logps/rejected": -125.4258041381836,
      "loss": 0.5504,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7146825194358826,
      "rewards/margins": 0.9765836596488953,
      "rewards/rejected": -1.6912662982940674,
      "step": 1470
    },
    {
      "epoch": 0.2700976366456794,
      "grad_norm": 5.699412822723389,
      "learning_rate": 6.0093826233814976e-05,
      "logits/chosen": -2.6155717372894287,
      "logits/rejected": -2.46549391746521,
      "logps/chosen": -150.16549682617188,
      "logps/rejected": -116.07618713378906,
      "loss": 0.5082,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.7631981372833252,
      "rewards/margins": 0.9064409136772156,
      "rewards/rejected": -1.6696388721466064,
      "step": 1480
    },
    {
      "epoch": 0.27192262067706907,
      "grad_norm": 4.755728244781494,
      "learning_rate": 5.9943704259711026e-05,
      "logits/chosen": -2.5610716342926025,
      "logits/rejected": -2.5546910762786865,
      "logps/chosen": -129.5367431640625,
      "logps/rejected": -132.46670532226562,
      "loss": 0.672,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.0090649127960205,
      "rewards/margins": 0.5891266465187073,
      "rewards/rejected": -1.598191499710083,
      "step": 1490
    },
    {
      "epoch": 0.2737476047084588,
      "grad_norm": 7.563808441162109,
      "learning_rate": 5.979358228560706e-05,
      "logits/chosen": -2.5746099948883057,
      "logits/rejected": -2.524282455444336,
      "logps/chosen": -128.17271423339844,
      "logps/rejected": -127.67669677734375,
      "loss": 0.5488,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.946679413318634,
      "rewards/margins": 0.8180945515632629,
      "rewards/rejected": -1.764773964881897,
      "step": 1500
    },
    {
      "epoch": 0.2755725887398485,
      "grad_norm": 6.659735202789307,
      "learning_rate": 5.9643460311503105e-05,
      "logits/chosen": -2.6429378986358643,
      "logits/rejected": -2.532576084136963,
      "logps/chosen": -138.4251251220703,
      "logps/rejected": -132.03392028808594,
      "loss": 0.5596,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7356349229812622,
      "rewards/margins": 1.0103121995925903,
      "rewards/rejected": -1.7459471225738525,
      "step": 1510
    },
    {
      "epoch": 0.2773975727712383,
      "grad_norm": 4.116048812866211,
      "learning_rate": 5.949333833739914e-05,
      "logits/chosen": -2.6520895957946777,
      "logits/rejected": -2.543929100036621,
      "logps/chosen": -134.47854614257812,
      "logps/rejected": -119.66165924072266,
      "loss": 0.5978,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7603394985198975,
      "rewards/margins": 0.7181136608123779,
      "rewards/rejected": -1.4784530401229858,
      "step": 1520
    },
    {
      "epoch": 0.279222556802628,
      "grad_norm": 4.477151870727539,
      "learning_rate": 5.9343216363295184e-05,
      "logits/chosen": -2.61680269241333,
      "logits/rejected": -2.4860689640045166,
      "logps/chosen": -150.2395477294922,
      "logps/rejected": -120.27143859863281,
      "loss": 0.5324,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8705994486808777,
      "rewards/margins": 0.926526665687561,
      "rewards/rejected": -1.797126054763794,
      "step": 1530
    },
    {
      "epoch": 0.28104754083401773,
      "grad_norm": 3.99692440032959,
      "learning_rate": 5.919309438919122e-05,
      "logits/chosen": -2.5524916648864746,
      "logits/rejected": -2.500636577606201,
      "logps/chosen": -122.39432525634766,
      "logps/rejected": -119.22271728515625,
      "loss": 0.6253,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0314662456512451,
      "rewards/margins": 0.6440907120704651,
      "rewards/rejected": -1.6755568981170654,
      "step": 1540
    },
    {
      "epoch": 0.2828725248654074,
      "grad_norm": 1.972058892250061,
      "learning_rate": 5.904297241508726e-05,
      "logits/chosen": -2.6382362842559814,
      "logits/rejected": -2.4950668811798096,
      "logps/chosen": -156.8558349609375,
      "logps/rejected": -130.36929321289062,
      "loss": 0.4964,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0548789501190186,
      "rewards/margins": 1.0538809299468994,
      "rewards/rejected": -2.108760118484497,
      "step": 1550
    },
    {
      "epoch": 0.2846975088967972,
      "grad_norm": 4.246242523193359,
      "learning_rate": 5.88928504409833e-05,
      "logits/chosen": -2.5277607440948486,
      "logits/rejected": -2.392331600189209,
      "logps/chosen": -147.9029083251953,
      "logps/rejected": -128.92214965820312,
      "loss": 0.4885,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9581437110900879,
      "rewards/margins": 1.062846064567566,
      "rewards/rejected": -2.0209898948669434,
      "step": 1560
    },
    {
      "epoch": 0.2865224929281869,
      "grad_norm": 4.989009857177734,
      "learning_rate": 5.874272846687935e-05,
      "logits/chosen": -2.559098482131958,
      "logits/rejected": -2.5017499923706055,
      "logps/chosen": -149.11599731445312,
      "logps/rejected": -139.28170776367188,
      "loss": 0.4561,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8845437169075012,
      "rewards/margins": 1.1573288440704346,
      "rewards/rejected": -2.041872501373291,
      "step": 1570
    },
    {
      "epoch": 0.2883474769595766,
      "grad_norm": 10.155505180358887,
      "learning_rate": 5.8592606492775385e-05,
      "logits/chosen": -2.5189788341522217,
      "logits/rejected": -2.5334763526916504,
      "logps/chosen": -142.52511596679688,
      "logps/rejected": -143.8020782470703,
      "loss": 0.5689,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.5315115451812744,
      "rewards/margins": 0.8819044828414917,
      "rewards/rejected": -2.4134161472320557,
      "step": 1580
    },
    {
      "epoch": 0.29017246099096633,
      "grad_norm": 7.184571266174316,
      "learning_rate": 5.844248451867143e-05,
      "logits/chosen": -2.5665783882141113,
      "logits/rejected": -2.5512454509735107,
      "logps/chosen": -139.13665771484375,
      "logps/rejected": -138.63198852539062,
      "loss": 0.6137,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.022099256515503,
      "rewards/margins": 0.7407720685005188,
      "rewards/rejected": -1.7628713846206665,
      "step": 1590
    },
    {
      "epoch": 0.29199744502235603,
      "grad_norm": 4.172760963439941,
      "learning_rate": 5.8292362544567464e-05,
      "logits/chosen": -2.5084939002990723,
      "logits/rejected": -2.4649300575256348,
      "logps/chosen": -132.1163787841797,
      "logps/rejected": -138.17620849609375,
      "loss": 0.637,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1824003458023071,
      "rewards/margins": 0.7547959089279175,
      "rewards/rejected": -1.9371963739395142,
      "step": 1600
    },
    {
      "epoch": 0.2938224290537458,
      "grad_norm": 6.167251110076904,
      "learning_rate": 5.8142240570463507e-05,
      "logits/chosen": -2.5551066398620605,
      "logits/rejected": -2.439828634262085,
      "logps/chosen": -142.34854125976562,
      "logps/rejected": -124.15714263916016,
      "loss": 0.6454,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.1022529602050781,
      "rewards/margins": 0.596183180809021,
      "rewards/rejected": -1.6984363794326782,
      "step": 1610
    },
    {
      "epoch": 0.2956474130851355,
      "grad_norm": 3.323558807373047,
      "learning_rate": 5.799211859635954e-05,
      "logits/chosen": -2.4915835857391357,
      "logits/rejected": -2.391319513320923,
      "logps/chosen": -138.5183563232422,
      "logps/rejected": -124.273681640625,
      "loss": 0.5352,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.01802659034729,
      "rewards/margins": 0.8344483375549316,
      "rewards/rejected": -1.852474570274353,
      "step": 1620
    },
    {
      "epoch": 0.29747239711652523,
      "grad_norm": 2.8022451400756836,
      "learning_rate": 5.7841996622255586e-05,
      "logits/chosen": -2.518479108810425,
      "logits/rejected": -2.4278082847595215,
      "logps/chosen": -128.32040405273438,
      "logps/rejected": -125.49710845947266,
      "loss": 0.5314,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.928296685218811,
      "rewards/margins": 1.0793884992599487,
      "rewards/rejected": -2.0076851844787598,
      "step": 1630
    },
    {
      "epoch": 0.29929738114791493,
      "grad_norm": 7.578444004058838,
      "learning_rate": 5.769187464815162e-05,
      "logits/chosen": -2.6281485557556152,
      "logits/rejected": -2.5587828159332275,
      "logps/chosen": -135.4694061279297,
      "logps/rejected": -131.10183715820312,
      "loss": 0.5393,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.6405086517333984,
      "rewards/margins": 1.122282862663269,
      "rewards/rejected": -2.762791395187378,
      "step": 1640
    },
    {
      "epoch": 0.3011223651793047,
      "grad_norm": 4.846171855926514,
      "learning_rate": 5.754175267404767e-05,
      "logits/chosen": -2.66998553276062,
      "logits/rejected": -2.574552536010742,
      "logps/chosen": -138.0370330810547,
      "logps/rejected": -133.84799194335938,
      "loss": 0.6783,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.3082292079925537,
      "rewards/margins": 0.5717079639434814,
      "rewards/rejected": -1.879936933517456,
      "step": 1650
    },
    {
      "epoch": 0.3029473492106944,
      "grad_norm": 4.294241428375244,
      "learning_rate": 5.7391630699943714e-05,
      "logits/chosen": -2.517667055130005,
      "logits/rejected": -2.389068126678467,
      "logps/chosen": -137.67672729492188,
      "logps/rejected": -134.3751220703125,
      "loss": 0.5434,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.110388994216919,
      "rewards/margins": 0.7921687364578247,
      "rewards/rejected": -1.9025577306747437,
      "step": 1660
    },
    {
      "epoch": 0.30477233324208414,
      "grad_norm": 3.9807050228118896,
      "learning_rate": 5.724150872583975e-05,
      "logits/chosen": -2.58787202835083,
      "logits/rejected": -2.507267475128174,
      "logps/chosen": -151.4918975830078,
      "logps/rejected": -136.25576782226562,
      "loss": 0.6095,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8594902157783508,
      "rewards/margins": 0.5694223642349243,
      "rewards/rejected": -1.4289125204086304,
      "step": 1670
    },
    {
      "epoch": 0.30659731727347384,
      "grad_norm": 6.229872226715088,
      "learning_rate": 5.709138675173579e-05,
      "logits/chosen": -2.508000373840332,
      "logits/rejected": -2.427189350128174,
      "logps/chosen": -142.82118225097656,
      "logps/rejected": -136.53955078125,
      "loss": 0.5252,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.959730327129364,
      "rewards/margins": 0.9081211090087891,
      "rewards/rejected": -1.8678514957427979,
      "step": 1680
    },
    {
      "epoch": 0.3084223013048636,
      "grad_norm": 4.115452766418457,
      "learning_rate": 5.694126477763183e-05,
      "logits/chosen": -2.343857765197754,
      "logits/rejected": -2.4710030555725098,
      "logps/chosen": -104.17424011230469,
      "logps/rejected": -153.1817626953125,
      "loss": 0.7514,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.8631795048713684,
      "rewards/margins": 0.2136397808790207,
      "rewards/rejected": -1.0768193006515503,
      "step": 1690
    },
    {
      "epoch": 0.3102472853362533,
      "grad_norm": 6.866363048553467,
      "learning_rate": 5.679114280352787e-05,
      "logits/chosen": -2.5295417308807373,
      "logits/rejected": -2.519808769226074,
      "logps/chosen": -124.2186508178711,
      "logps/rejected": -134.04664611816406,
      "loss": 0.535,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6825559735298157,
      "rewards/margins": 0.7633446455001831,
      "rewards/rejected": -1.4459006786346436,
      "step": 1700
    },
    {
      "epoch": 0.31207226936764304,
      "grad_norm": 5.519438743591309,
      "learning_rate": 5.664102082942391e-05,
      "logits/chosen": -2.5243217945098877,
      "logits/rejected": -2.4630441665649414,
      "logps/chosen": -137.16860961914062,
      "logps/rejected": -120.88548278808594,
      "loss": 0.5211,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8985223770141602,
      "rewards/margins": 0.8968520164489746,
      "rewards/rejected": -1.7953742742538452,
      "step": 1710
    },
    {
      "epoch": 0.31389725339903274,
      "grad_norm": 5.801994323730469,
      "learning_rate": 5.649089885531995e-05,
      "logits/chosen": -2.4881138801574707,
      "logits/rejected": -2.413158655166626,
      "logps/chosen": -132.92501831054688,
      "logps/rejected": -133.34176635742188,
      "loss": 0.5423,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.5527594089508057,
      "rewards/margins": 0.9707633256912231,
      "rewards/rejected": -1.5235226154327393,
      "step": 1720
    },
    {
      "epoch": 0.3157222374304225,
      "grad_norm": 3.5126848220825195,
      "learning_rate": 5.634077688121599e-05,
      "logits/chosen": -2.512768268585205,
      "logits/rejected": -2.4303412437438965,
      "logps/chosen": -142.42459106445312,
      "logps/rejected": -123.1050796508789,
      "loss": 0.582,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.4008517861366272,
      "rewards/margins": 0.8269799947738647,
      "rewards/rejected": -1.2278318405151367,
      "step": 1730
    },
    {
      "epoch": 0.3175472214618122,
      "grad_norm": 4.980856418609619,
      "learning_rate": 5.619065490711204e-05,
      "logits/chosen": -2.459728956222534,
      "logits/rejected": -2.4187874794006348,
      "logps/chosen": -130.3194122314453,
      "logps/rejected": -125.86639404296875,
      "loss": 0.5619,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.49913185834884644,
      "rewards/margins": 0.8031128644943237,
      "rewards/rejected": -1.302244782447815,
      "step": 1740
    },
    {
      "epoch": 0.31937220549320194,
      "grad_norm": 4.07568883895874,
      "learning_rate": 5.604053293300807e-05,
      "logits/chosen": -2.6196420192718506,
      "logits/rejected": -2.534411907196045,
      "logps/chosen": -110.96517181396484,
      "logps/rejected": -105.59468078613281,
      "loss": 0.4876,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.543867290019989,
      "rewards/margins": 1.133590579032898,
      "rewards/rejected": -1.6774580478668213,
      "step": 1750
    },
    {
      "epoch": 0.32119718952459164,
      "grad_norm": 6.3064985275268555,
      "learning_rate": 5.5890410958904116e-05,
      "logits/chosen": -2.5154500007629395,
      "logits/rejected": -2.4487602710723877,
      "logps/chosen": -144.16468811035156,
      "logps/rejected": -141.7770233154297,
      "loss": 0.5999,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7842182517051697,
      "rewards/margins": 1.0111627578735352,
      "rewards/rejected": -1.7953811883926392,
      "step": 1760
    },
    {
      "epoch": 0.3230221735559814,
      "grad_norm": 6.200943470001221,
      "learning_rate": 5.574028898480015e-05,
      "logits/chosen": -2.4648892879486084,
      "logits/rejected": -2.4505057334899902,
      "logps/chosen": -128.85806274414062,
      "logps/rejected": -132.37075805664062,
      "loss": 0.5957,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.7839749455451965,
      "rewards/margins": 0.78119957447052,
      "rewards/rejected": -1.5651745796203613,
      "step": 1770
    },
    {
      "epoch": 0.3248471575873711,
      "grad_norm": 8.290140151977539,
      "learning_rate": 5.5590167010696195e-05,
      "logits/chosen": -2.499882936477661,
      "logits/rejected": -2.4312093257904053,
      "logps/chosen": -121.20933532714844,
      "logps/rejected": -110.014892578125,
      "loss": 0.6719,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.686062216758728,
      "rewards/margins": 0.5662750601768494,
      "rewards/rejected": -1.2523372173309326,
      "step": 1780
    },
    {
      "epoch": 0.32667214161876085,
      "grad_norm": 3.9735307693481445,
      "learning_rate": 5.544004503659223e-05,
      "logits/chosen": -2.5298469066619873,
      "logits/rejected": -2.3835208415985107,
      "logps/chosen": -145.26837158203125,
      "logps/rejected": -120.87152099609375,
      "loss": 0.4378,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.5245501399040222,
      "rewards/margins": 1.0905810594558716,
      "rewards/rejected": -1.6151313781738281,
      "step": 1790
    },
    {
      "epoch": 0.32849712565015055,
      "grad_norm": 5.262851238250732,
      "learning_rate": 5.5289923062488274e-05,
      "logits/chosen": -2.5428080558776855,
      "logits/rejected": -2.473386764526367,
      "logps/chosen": -130.81378173828125,
      "logps/rejected": -119.12635803222656,
      "loss": 0.4866,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.425367534160614,
      "rewards/margins": 1.0204105377197266,
      "rewards/rejected": -1.4457778930664062,
      "step": 1800
    },
    {
      "epoch": 0.3303221096815403,
      "grad_norm": 8.12792682647705,
      "learning_rate": 5.513980108838431e-05,
      "logits/chosen": -2.4345436096191406,
      "logits/rejected": -2.2995901107788086,
      "logps/chosen": -134.3529052734375,
      "logps/rejected": -121.15370178222656,
      "loss": 0.5269,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.2838788628578186,
      "rewards/margins": 1.211326241493225,
      "rewards/rejected": -1.4952051639556885,
      "step": 1810
    },
    {
      "epoch": 0.33214709371293,
      "grad_norm": 4.975539207458496,
      "learning_rate": 5.498967911428036e-05,
      "logits/chosen": -2.4689159393310547,
      "logits/rejected": -2.2768914699554443,
      "logps/chosen": -135.55313110351562,
      "logps/rejected": -101.19529724121094,
      "loss": 0.5497,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.39058560132980347,
      "rewards/margins": 0.8940967321395874,
      "rewards/rejected": -1.2846823930740356,
      "step": 1820
    },
    {
      "epoch": 0.33397207774431975,
      "grad_norm": 6.877305030822754,
      "learning_rate": 5.48395571401764e-05,
      "logits/chosen": -2.5283379554748535,
      "logits/rejected": -2.3784892559051514,
      "logps/chosen": -145.10891723632812,
      "logps/rejected": -133.54306030273438,
      "loss": 0.4597,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.19244877994060516,
      "rewards/margins": 1.1290494203567505,
      "rewards/rejected": -1.321498155593872,
      "step": 1830
    },
    {
      "epoch": 0.33579706177570945,
      "grad_norm": 4.585037708282471,
      "learning_rate": 5.468943516607244e-05,
      "logits/chosen": -2.5387940406799316,
      "logits/rejected": -2.4595024585723877,
      "logps/chosen": -138.968017578125,
      "logps/rejected": -132.31790161132812,
      "loss": 0.5257,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.4422670006752014,
      "rewards/margins": 1.0245416164398193,
      "rewards/rejected": -1.466808557510376,
      "step": 1840
    },
    {
      "epoch": 0.3376220458070992,
      "grad_norm": 6.948405742645264,
      "learning_rate": 5.453931319196848e-05,
      "logits/chosen": -2.4862968921661377,
      "logits/rejected": -2.3637266159057617,
      "logps/chosen": -145.8249969482422,
      "logps/rejected": -135.05056762695312,
      "loss": 0.5701,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.6355441808700562,
      "rewards/margins": 0.9617268443107605,
      "rewards/rejected": -1.597271203994751,
      "step": 1850
    },
    {
      "epoch": 0.3394470298384889,
      "grad_norm": 7.31657600402832,
      "learning_rate": 5.438919121786452e-05,
      "logits/chosen": -2.5359549522399902,
      "logits/rejected": -2.447112560272217,
      "logps/chosen": -127.82612609863281,
      "logps/rejected": -115.1983871459961,
      "loss": 0.5406,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.47790318727493286,
      "rewards/margins": 0.8000386357307434,
      "rewards/rejected": -1.2779419422149658,
      "step": 1860
    },
    {
      "epoch": 0.34127201386987865,
      "grad_norm": 2.835589647293091,
      "learning_rate": 5.423906924376056e-05,
      "logits/chosen": -2.4504337310791016,
      "logits/rejected": -2.3263936042785645,
      "logps/chosen": -135.6923828125,
      "logps/rejected": -118.00532531738281,
      "loss": 0.5099,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.4229675829410553,
      "rewards/margins": 1.0988349914550781,
      "rewards/rejected": -1.5218026638031006,
      "step": 1870
    },
    {
      "epoch": 0.34309699790126835,
      "grad_norm": 7.020561218261719,
      "learning_rate": 5.4088947269656596e-05,
      "logits/chosen": -2.5037407875061035,
      "logits/rejected": -2.4311280250549316,
      "logps/chosen": -123.8533935546875,
      "logps/rejected": -120.67671966552734,
      "loss": 0.6149,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.4813920557498932,
      "rewards/margins": 0.6636765003204346,
      "rewards/rejected": -1.1450685262680054,
      "step": 1880
    },
    {
      "epoch": 0.3449219819326581,
      "grad_norm": 5.976438522338867,
      "learning_rate": 5.393882529555264e-05,
      "logits/chosen": -2.472670793533325,
      "logits/rejected": -2.4302265644073486,
      "logps/chosen": -129.21693420410156,
      "logps/rejected": -133.35572814941406,
      "loss": 0.6766,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -0.5721836686134338,
      "rewards/margins": 0.4497540593147278,
      "rewards/rejected": -1.021937608718872,
      "step": 1890
    },
    {
      "epoch": 0.3467469659640478,
      "grad_norm": 4.08913516998291,
      "learning_rate": 5.378870332144868e-05,
      "logits/chosen": -2.471984624862671,
      "logits/rejected": -2.4277048110961914,
      "logps/chosen": -127.05147552490234,
      "logps/rejected": -133.43394470214844,
      "loss": 0.5194,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.4178708493709564,
      "rewards/margins": 0.9901508092880249,
      "rewards/rejected": -1.4080216884613037,
      "step": 1900
    },
    {
      "epoch": 0.34857194999543756,
      "grad_norm": 7.158084869384766,
      "learning_rate": 5.3638581347344725e-05,
      "logits/chosen": -2.506301164627075,
      "logits/rejected": -2.3513591289520264,
      "logps/chosen": -143.4857635498047,
      "logps/rejected": -119.07125091552734,
      "loss": 0.6487,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.2815517783164978,
      "rewards/margins": 0.6787508726119995,
      "rewards/rejected": -0.9603026509284973,
      "step": 1910
    },
    {
      "epoch": 0.35039693402682726,
      "grad_norm": 5.503444194793701,
      "learning_rate": 5.348845937324076e-05,
      "logits/chosen": -2.4135403633117676,
      "logits/rejected": -2.328829050064087,
      "logps/chosen": -129.0507049560547,
      "logps/rejected": -124.27418518066406,
      "loss": 0.5994,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5124702453613281,
      "rewards/margins": 0.5762871503829956,
      "rewards/rejected": -1.0887572765350342,
      "step": 1920
    },
    {
      "epoch": 0.352221918058217,
      "grad_norm": 3.7077457904815674,
      "learning_rate": 5.3338337399136804e-05,
      "logits/chosen": -2.486708641052246,
      "logits/rejected": -2.3005776405334473,
      "logps/chosen": -143.68911743164062,
      "logps/rejected": -113.65492248535156,
      "loss": 0.5721,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.4300374984741211,
      "rewards/margins": 0.7763863205909729,
      "rewards/rejected": -1.2064238786697388,
      "step": 1930
    },
    {
      "epoch": 0.3540469020896067,
      "grad_norm": 4.134433746337891,
      "learning_rate": 5.318821542503284e-05,
      "logits/chosen": -2.4977848529815674,
      "logits/rejected": -2.4527249336242676,
      "logps/chosen": -121.550537109375,
      "logps/rejected": -115.50071716308594,
      "loss": 0.6126,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.27216479182243347,
      "rewards/margins": 0.5408036112785339,
      "rewards/rejected": -0.8129684329032898,
      "step": 1940
    },
    {
      "epoch": 0.35587188612099646,
      "grad_norm": 3.836544990539551,
      "learning_rate": 5.303809345092888e-05,
      "logits/chosen": -2.5537233352661133,
      "logits/rejected": -2.365349769592285,
      "logps/chosen": -135.4188690185547,
      "logps/rejected": -116.59822082519531,
      "loss": 0.5146,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.021339815109968185,
      "rewards/margins": 0.9522697329521179,
      "rewards/rejected": -0.9309300184249878,
      "step": 1950
    },
    {
      "epoch": 0.35769687015238616,
      "grad_norm": 5.223825931549072,
      "learning_rate": 5.288797147682492e-05,
      "logits/chosen": -2.507869243621826,
      "logits/rejected": -2.3631091117858887,
      "logps/chosen": -127.69708251953125,
      "logps/rejected": -119.5732421875,
      "loss": 0.5057,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.19410355389118195,
      "rewards/margins": 1.0264132022857666,
      "rewards/rejected": -1.2205169200897217,
      "step": 1960
    },
    {
      "epoch": 0.3595218541837759,
      "grad_norm": 4.9951863288879395,
      "learning_rate": 5.273784950272096e-05,
      "logits/chosen": -2.5219435691833496,
      "logits/rejected": -2.4241256713867188,
      "logps/chosen": -126.60137939453125,
      "logps/rejected": -131.02230834960938,
      "loss": 0.5515,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.7098764777183533,
      "rewards/margins": 0.9081953763961792,
      "rewards/rejected": -1.6180717945098877,
      "step": 1970
    },
    {
      "epoch": 0.3613468382151656,
      "grad_norm": 8.028104782104492,
      "learning_rate": 5.258772752861701e-05,
      "logits/chosen": -2.3954641819000244,
      "logits/rejected": -2.308074951171875,
      "logps/chosen": -137.95310974121094,
      "logps/rejected": -134.2935028076172,
      "loss": 0.5583,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.5883597135543823,
      "rewards/margins": 1.0254993438720703,
      "rewards/rejected": -1.613858938217163,
      "step": 1980
    },
    {
      "epoch": 0.36317182224655536,
      "grad_norm": 1.7249618768692017,
      "learning_rate": 5.243760555451305e-05,
      "logits/chosen": -2.551121473312378,
      "logits/rejected": -2.4245753288269043,
      "logps/chosen": -136.66552734375,
      "logps/rejected": -131.26998901367188,
      "loss": 0.3819,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.0518176555633545,
      "rewards/margins": 1.6238889694213867,
      "rewards/rejected": -2.675706386566162,
      "step": 1990
    },
    {
      "epoch": 0.36499680627794506,
      "grad_norm": 7.276607990264893,
      "learning_rate": 5.228748358040909e-05,
      "logits/chosen": -2.397355079650879,
      "logits/rejected": -2.190059185028076,
      "logps/chosen": -167.0581817626953,
      "logps/rejected": -136.00282287597656,
      "loss": 0.6171,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.232913613319397,
      "rewards/margins": 1.1599140167236328,
      "rewards/rejected": -2.3928275108337402,
      "step": 2000
    },
    {
      "epoch": 0.3668217903093348,
      "grad_norm": 4.405358791351318,
      "learning_rate": 5.2137361606305126e-05,
      "logits/chosen": -2.5378384590148926,
      "logits/rejected": -2.3952198028564453,
      "logps/chosen": -131.3154754638672,
      "logps/rejected": -112.88409423828125,
      "loss": 0.5504,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6601747274398804,
      "rewards/margins": 0.9767755270004272,
      "rewards/rejected": -1.6369502544403076,
      "step": 2010
    },
    {
      "epoch": 0.3686467743407245,
      "grad_norm": 4.428316116333008,
      "learning_rate": 5.198723963220117e-05,
      "logits/chosen": -2.4820199012756348,
      "logits/rejected": -2.3997395038604736,
      "logps/chosen": -121.69737243652344,
      "logps/rejected": -118.85050201416016,
      "loss": 0.5384,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6167760491371155,
      "rewards/margins": 1.0557410717010498,
      "rewards/rejected": -1.67251718044281,
      "step": 2020
    },
    {
      "epoch": 0.37047175837211427,
      "grad_norm": 4.5366668701171875,
      "learning_rate": 5.1837117658097205e-05,
      "logits/chosen": -2.4788849353790283,
      "logits/rejected": -2.37837290763855,
      "logps/chosen": -121.61314392089844,
      "logps/rejected": -115.1313247680664,
      "loss": 0.5664,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0706570148468018,
      "rewards/margins": 0.8209676742553711,
      "rewards/rejected": -1.8916246891021729,
      "step": 2030
    },
    {
      "epoch": 0.37229674240350397,
      "grad_norm": 6.535577774047852,
      "learning_rate": 5.168699568399325e-05,
      "logits/chosen": -2.471473217010498,
      "logits/rejected": -2.365900993347168,
      "logps/chosen": -149.62777709960938,
      "logps/rejected": -145.70352172851562,
      "loss": 0.5688,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0674997568130493,
      "rewards/margins": 0.7627546191215515,
      "rewards/rejected": -1.830254316329956,
      "step": 2040
    },
    {
      "epoch": 0.3741217264348937,
      "grad_norm": 6.856731414794922,
      "learning_rate": 5.1536873709889284e-05,
      "logits/chosen": -2.5099093914031982,
      "logits/rejected": -2.3617587089538574,
      "logps/chosen": -157.55886840820312,
      "logps/rejected": -133.5872344970703,
      "loss": 0.669,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.1681677103042603,
      "rewards/margins": 0.7597752809524536,
      "rewards/rejected": -1.927943229675293,
      "step": 2050
    },
    {
      "epoch": 0.3759467104662834,
      "grad_norm": 4.500516891479492,
      "learning_rate": 5.1386751735785334e-05,
      "logits/chosen": -2.5072648525238037,
      "logits/rejected": -2.45125150680542,
      "logps/chosen": -135.52102661132812,
      "logps/rejected": -143.97451782226562,
      "loss": 0.569,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8239790201187134,
      "rewards/margins": 0.6496572494506836,
      "rewards/rejected": -1.4736363887786865,
      "step": 2060
    },
    {
      "epoch": 0.37777169449767317,
      "grad_norm": 5.656288146972656,
      "learning_rate": 5.123662976168137e-05,
      "logits/chosen": -2.5113043785095215,
      "logits/rejected": -2.4291179180145264,
      "logps/chosen": -126.81382751464844,
      "logps/rejected": -116.52669525146484,
      "loss": 0.5373,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.49345874786376953,
      "rewards/margins": 0.7396858334541321,
      "rewards/rejected": -1.2331446409225464,
      "step": 2070
    },
    {
      "epoch": 0.37959667852906287,
      "grad_norm": 2.707754373550415,
      "learning_rate": 5.108650778757741e-05,
      "logits/chosen": -2.60066556930542,
      "logits/rejected": -2.4826748371124268,
      "logps/chosen": -123.86983489990234,
      "logps/rejected": -116.0867691040039,
      "loss": 0.6138,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.4249144196510315,
      "rewards/margins": 0.5388549566268921,
      "rewards/rejected": -0.963769257068634,
      "step": 2080
    },
    {
      "epoch": 0.3814216625604526,
      "grad_norm": 6.281579971313477,
      "learning_rate": 5.093638581347345e-05,
      "logits/chosen": -2.4897513389587402,
      "logits/rejected": -2.3303604125976562,
      "logps/chosen": -149.03688049316406,
      "logps/rejected": -144.01963806152344,
      "loss": 0.4599,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.3794599175453186,
      "rewards/margins": 1.2579419612884521,
      "rewards/rejected": -1.637401819229126,
      "step": 2090
    },
    {
      "epoch": 0.3832466465918423,
      "grad_norm": 25.772167205810547,
      "learning_rate": 5.078626383936949e-05,
      "logits/chosen": -2.4421849250793457,
      "logits/rejected": -2.293196678161621,
      "logps/chosen": -153.68019104003906,
      "logps/rejected": -133.3516082763672,
      "loss": 0.5622,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.618230402469635,
      "rewards/margins": 0.8562528491020203,
      "rewards/rejected": -1.4744832515716553,
      "step": 2100
    },
    {
      "epoch": 0.385071630623232,
      "grad_norm": 2.688460111618042,
      "learning_rate": 5.063614186526553e-05,
      "logits/chosen": -2.6174232959747314,
      "logits/rejected": -2.4352545738220215,
      "logps/chosen": -141.49014282226562,
      "logps/rejected": -122.79390716552734,
      "loss": 0.5881,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5773910284042358,
      "rewards/margins": 0.6308870315551758,
      "rewards/rejected": -1.208277940750122,
      "step": 2110
    },
    {
      "epoch": 0.3868966146546218,
      "grad_norm": 4.614914417266846,
      "learning_rate": 5.048601989116157e-05,
      "logits/chosen": -2.5312530994415283,
      "logits/rejected": -2.419154405593872,
      "logps/chosen": -147.35690307617188,
      "logps/rejected": -132.2052764892578,
      "loss": 0.6234,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.4991821348667145,
      "rewards/margins": 0.673241138458252,
      "rewards/rejected": -1.1724231243133545,
      "step": 2120
    },
    {
      "epoch": 0.38872159868601147,
      "grad_norm": 3.1475815773010254,
      "learning_rate": 5.033589791705761e-05,
      "logits/chosen": -2.5474228858947754,
      "logits/rejected": -2.38799786567688,
      "logps/chosen": -141.47506713867188,
      "logps/rejected": -133.25009155273438,
      "loss": 0.4759,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.5954216718673706,
      "rewards/margins": 1.193485975265503,
      "rewards/rejected": -1.7889076471328735,
      "step": 2130
    },
    {
      "epoch": 0.3905465827174012,
      "grad_norm": 5.824889183044434,
      "learning_rate": 5.018577594295365e-05,
      "logits/chosen": -2.414368152618408,
      "logits/rejected": -2.3857178688049316,
      "logps/chosen": -129.95541381835938,
      "logps/rejected": -134.15182495117188,
      "loss": 0.5149,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.8239105939865112,
      "rewards/margins": 0.9189049601554871,
      "rewards/rejected": -1.742815375328064,
      "step": 2140
    },
    {
      "epoch": 0.3923715667487909,
      "grad_norm": 3.6689841747283936,
      "learning_rate": 5.00356539688497e-05,
      "logits/chosen": -2.4679861068725586,
      "logits/rejected": -2.4355294704437256,
      "logps/chosen": -135.2594757080078,
      "logps/rejected": -138.83151245117188,
      "loss": 0.6458,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.4578755795955658,
      "rewards/margins": 0.713943362236023,
      "rewards/rejected": -1.1718189716339111,
      "step": 2150
    },
    {
      "epoch": 0.3941965507801807,
      "grad_norm": 6.453490734100342,
      "learning_rate": 4.9885531994745736e-05,
      "logits/chosen": -2.5149085521698,
      "logits/rejected": -2.4360134601593018,
      "logps/chosen": -123.83549499511719,
      "logps/rejected": -114.1139907836914,
      "loss": 0.5936,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5770431756973267,
      "rewards/margins": 0.6780223846435547,
      "rewards/rejected": -1.2550654411315918,
      "step": 2160
    },
    {
      "epoch": 0.3960215348115704,
      "grad_norm": 4.912491798400879,
      "learning_rate": 4.973541002064178e-05,
      "logits/chosen": -2.5578150749206543,
      "logits/rejected": -2.406447649002075,
      "logps/chosen": -128.12408447265625,
      "logps/rejected": -104.49696350097656,
      "loss": 0.5909,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.34668415784835815,
      "rewards/margins": 0.6286967396736145,
      "rewards/rejected": -0.9753808975219727,
      "step": 2170
    },
    {
      "epoch": 0.39784651884296013,
      "grad_norm": 7.534056663513184,
      "learning_rate": 4.9585288046537815e-05,
      "logits/chosen": -2.5230929851531982,
      "logits/rejected": -2.414796829223633,
      "logps/chosen": -137.6764373779297,
      "logps/rejected": -127.07547760009766,
      "loss": 0.5787,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.3463422358036041,
      "rewards/margins": 0.8255637884140015,
      "rewards/rejected": -1.1719058752059937,
      "step": 2180
    },
    {
      "epoch": 0.3996715028743498,
      "grad_norm": 3.3247463703155518,
      "learning_rate": 4.943516607243386e-05,
      "logits/chosen": -2.616834878921509,
      "logits/rejected": -2.488255739212036,
      "logps/chosen": -126.76214599609375,
      "logps/rejected": -115.6500015258789,
      "loss": 0.4981,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.16439031064510345,
      "rewards/margins": 1.0346932411193848,
      "rewards/rejected": -1.1990835666656494,
      "step": 2190
    },
    {
      "epoch": 0.4014964869057396,
      "grad_norm": 5.896086692810059,
      "learning_rate": 4.9285044098329894e-05,
      "logits/chosen": -2.539755344390869,
      "logits/rejected": -2.4544315338134766,
      "logps/chosen": -113.86656188964844,
      "logps/rejected": -119.88480377197266,
      "loss": 0.6124,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.471169650554657,
      "rewards/margins": 0.6648319959640503,
      "rewards/rejected": -1.136001706123352,
      "step": 2200
    },
    {
      "epoch": 0.4033214709371293,
      "grad_norm": 5.6183857917785645,
      "learning_rate": 4.9134922124225936e-05,
      "logits/chosen": -2.6130518913269043,
      "logits/rejected": -2.433241844177246,
      "logps/chosen": -149.63180541992188,
      "logps/rejected": -126.1301498413086,
      "loss": 0.5099,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.309513658285141,
      "rewards/margins": 0.9485148191452026,
      "rewards/rejected": -1.2580286264419556,
      "step": 2210
    },
    {
      "epoch": 0.40514645496851903,
      "grad_norm": 5.683692932128906,
      "learning_rate": 4.898480015012197e-05,
      "logits/chosen": -2.5678651332855225,
      "logits/rejected": -2.4581246376037598,
      "logps/chosen": -139.7548065185547,
      "logps/rejected": -122.0179214477539,
      "loss": 0.5109,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.5395236015319824,
      "rewards/margins": 1.1211647987365723,
      "rewards/rejected": -1.6606881618499756,
      "step": 2220
    },
    {
      "epoch": 0.40697143899990873,
      "grad_norm": 6.429083824157715,
      "learning_rate": 4.883467817601802e-05,
      "logits/chosen": -2.570125102996826,
      "logits/rejected": -2.4107487201690674,
      "logps/chosen": -132.01150512695312,
      "logps/rejected": -114.86959075927734,
      "loss": 0.6672,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.2980699837207794,
      "rewards/margins": 0.6288211941719055,
      "rewards/rejected": -0.9268911480903625,
      "step": 2230
    },
    {
      "epoch": 0.4087964230312985,
      "grad_norm": 8.325922012329102,
      "learning_rate": 4.8684556201914065e-05,
      "logits/chosen": -2.6549153327941895,
      "logits/rejected": -2.5898327827453613,
      "logps/chosen": -122.00691986083984,
      "logps/rejected": -115.3258285522461,
      "loss": 0.6005,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.20581789314746857,
      "rewards/margins": 0.8483767509460449,
      "rewards/rejected": -1.054194688796997,
      "step": 2240
    },
    {
      "epoch": 0.4106214070626882,
      "grad_norm": 5.0428924560546875,
      "learning_rate": 4.85344342278101e-05,
      "logits/chosen": -2.6117775440216064,
      "logits/rejected": -2.4084312915802,
      "logps/chosen": -135.4069061279297,
      "logps/rejected": -112.8040771484375,
      "loss": 0.5453,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.41668248176574707,
      "rewards/margins": 0.8240248560905457,
      "rewards/rejected": -1.2407073974609375,
      "step": 2250
    },
    {
      "epoch": 0.41244639109407794,
      "grad_norm": 6.476723670959473,
      "learning_rate": 4.838431225370614e-05,
      "logits/chosen": -2.6158111095428467,
      "logits/rejected": -2.5093939304351807,
      "logps/chosen": -133.59559631347656,
      "logps/rejected": -139.71385192871094,
      "loss": 0.5633,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.3182067573070526,
      "rewards/margins": 0.9333285093307495,
      "rewards/rejected": -1.251535177230835,
      "step": 2260
    },
    {
      "epoch": 0.41427137512546763,
      "grad_norm": 4.764502048492432,
      "learning_rate": 4.823419027960218e-05,
      "logits/chosen": -2.744158983230591,
      "logits/rejected": -2.5236363410949707,
      "logps/chosen": -134.5015106201172,
      "logps/rejected": -112.6318130493164,
      "loss": 0.6064,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7860792875289917,
      "rewards/margins": 0.6208987236022949,
      "rewards/rejected": -1.406977891921997,
      "step": 2270
    },
    {
      "epoch": 0.4160963591568574,
      "grad_norm": 4.106575012207031,
      "learning_rate": 4.8084068305498216e-05,
      "logits/chosen": -2.731482744216919,
      "logits/rejected": -2.598956823348999,
      "logps/chosen": -116.04974365234375,
      "logps/rejected": -105.5695571899414,
      "loss": 0.5795,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.46837249398231506,
      "rewards/margins": 0.827294647693634,
      "rewards/rejected": -1.2956669330596924,
      "step": 2280
    },
    {
      "epoch": 0.4179213431882471,
      "grad_norm": 7.851390838623047,
      "learning_rate": 4.793394633139426e-05,
      "logits/chosen": -2.693708896636963,
      "logits/rejected": -2.499866008758545,
      "logps/chosen": -147.76724243164062,
      "logps/rejected": -129.7613525390625,
      "loss": 0.5163,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8866987228393555,
      "rewards/margins": 0.9480382800102234,
      "rewards/rejected": -1.8347371816635132,
      "step": 2290
    },
    {
      "epoch": 0.41974632721963684,
      "grad_norm": 4.270461082458496,
      "learning_rate": 4.7783824357290295e-05,
      "logits/chosen": -2.6543068885803223,
      "logits/rejected": -2.566542387008667,
      "logps/chosen": -131.74026489257812,
      "logps/rejected": -131.78762817382812,
      "loss": 0.5592,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.0427799224853516,
      "rewards/margins": 0.7964124083518982,
      "rewards/rejected": -1.8391921520233154,
      "step": 2300
    },
    {
      "epoch": 0.42157131125102654,
      "grad_norm": 5.370818138122559,
      "learning_rate": 4.7633702383186345e-05,
      "logits/chosen": -2.64730167388916,
      "logits/rejected": -2.53432297706604,
      "logps/chosen": -133.09890747070312,
      "logps/rejected": -117.22901916503906,
      "loss": 0.6494,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8142138719558716,
      "rewards/margins": 0.6168844699859619,
      "rewards/rejected": -1.431098461151123,
      "step": 2310
    },
    {
      "epoch": 0.4233962952824163,
      "grad_norm": 5.65261173248291,
      "learning_rate": 4.748358040908239e-05,
      "logits/chosen": -2.655683755874634,
      "logits/rejected": -2.5915563106536865,
      "logps/chosen": -126.73542785644531,
      "logps/rejected": -119.14656066894531,
      "loss": 0.5992,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6970565319061279,
      "rewards/margins": 0.620063304901123,
      "rewards/rejected": -1.317119836807251,
      "step": 2320
    },
    {
      "epoch": 0.425221279313806,
      "grad_norm": 4.154386520385742,
      "learning_rate": 4.7333458434978424e-05,
      "logits/chosen": -2.680823802947998,
      "logits/rejected": -2.5810539722442627,
      "logps/chosen": -126.50264739990234,
      "logps/rejected": -108.4411392211914,
      "loss": 0.6249,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.5911508798599243,
      "rewards/margins": 0.5263170599937439,
      "rewards/rejected": -1.117467999458313,
      "step": 2330
    },
    {
      "epoch": 0.42704626334519574,
      "grad_norm": 3.7509872913360596,
      "learning_rate": 4.7183336460874467e-05,
      "logits/chosen": -2.6247715950012207,
      "logits/rejected": -2.5781826972961426,
      "logps/chosen": -127.8074722290039,
      "logps/rejected": -136.8563232421875,
      "loss": 0.4744,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.43676573038101196,
      "rewards/margins": 1.1516170501708984,
      "rewards/rejected": -1.5883828401565552,
      "step": 2340
    },
    {
      "epoch": 0.42887124737658544,
      "grad_norm": 5.087589263916016,
      "learning_rate": 4.70482266841809e-05,
      "logits/chosen": -2.609431743621826,
      "logits/rejected": -2.4792160987854004,
      "logps/chosen": -138.82077026367188,
      "logps/rejected": -131.67453002929688,
      "loss": 0.546,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8216501474380493,
      "rewards/margins": 0.9664870500564575,
      "rewards/rejected": -1.7881370782852173,
      "step": 2350
    },
    {
      "epoch": 0.4306962314079752,
      "grad_norm": 2.9311001300811768,
      "learning_rate": 4.6898104710076944e-05,
      "logits/chosen": -2.598724842071533,
      "logits/rejected": -2.4958815574645996,
      "logps/chosen": -125.45027160644531,
      "logps/rejected": -127.9290542602539,
      "loss": 0.4795,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8643888235092163,
      "rewards/margins": 1.2864677906036377,
      "rewards/rejected": -2.1508564949035645,
      "step": 2360
    },
    {
      "epoch": 0.4325212154393649,
      "grad_norm": 6.151259422302246,
      "learning_rate": 4.674798273597298e-05,
      "logits/chosen": -2.6039881706237793,
      "logits/rejected": -2.4364516735076904,
      "logps/chosen": -130.85452270507812,
      "logps/rejected": -112.20170593261719,
      "loss": 0.4754,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.6434215903282166,
      "rewards/margins": 1.2723972797393799,
      "rewards/rejected": -1.9158189296722412,
      "step": 2370
    },
    {
      "epoch": 0.43434619947075465,
      "grad_norm": 10.202103614807129,
      "learning_rate": 4.659786076186902e-05,
      "logits/chosen": -2.667743444442749,
      "logits/rejected": -2.566438674926758,
      "logps/chosen": -138.26339721679688,
      "logps/rejected": -118.40278625488281,
      "loss": 0.579,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8267780542373657,
      "rewards/margins": 0.8119373321533203,
      "rewards/rejected": -1.638715386390686,
      "step": 2380
    },
    {
      "epoch": 0.43617118350214434,
      "grad_norm": 4.615761756896973,
      "learning_rate": 4.644773878776506e-05,
      "logits/chosen": -2.787731170654297,
      "logits/rejected": -2.58101224899292,
      "logps/chosen": -152.35183715820312,
      "logps/rejected": -110.70145416259766,
      "loss": 0.5133,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.37025436758995056,
      "rewards/margins": 1.1403292417526245,
      "rewards/rejected": -1.510583519935608,
      "step": 2390
    },
    {
      "epoch": 0.4379961675335341,
      "grad_norm": 10.569215774536133,
      "learning_rate": 4.62976168136611e-05,
      "logits/chosen": -2.6276490688323975,
      "logits/rejected": -2.6013357639312744,
      "logps/chosen": -127.15681457519531,
      "logps/rejected": -126.79949951171875,
      "loss": 0.6066,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.5959048271179199,
      "rewards/margins": 0.7884529829025269,
      "rewards/rejected": -1.3843578100204468,
      "step": 2400
    },
    {
      "epoch": 0.4398211515649238,
      "grad_norm": 6.916880130767822,
      "learning_rate": 4.6147494839557145e-05,
      "logits/chosen": -2.736349105834961,
      "logits/rejected": -2.6220879554748535,
      "logps/chosen": -136.85678100585938,
      "logps/rejected": -121.02888488769531,
      "loss": 0.5511,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.6642802357673645,
      "rewards/margins": 0.8917310833930969,
      "rewards/rejected": -1.5560111999511719,
      "step": 2410
    },
    {
      "epoch": 0.44164613559631355,
      "grad_norm": 4.461422443389893,
      "learning_rate": 4.599737286545319e-05,
      "logits/chosen": -2.5765583515167236,
      "logits/rejected": -2.4823896884918213,
      "logps/chosen": -120.7160873413086,
      "logps/rejected": -120.4998779296875,
      "loss": 0.4704,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.8636832237243652,
      "rewards/margins": 1.3450630903244019,
      "rewards/rejected": -2.2087461948394775,
      "step": 2420
    },
    {
      "epoch": 0.44347111962770325,
      "grad_norm": 4.287565231323242,
      "learning_rate": 4.5847250891349224e-05,
      "logits/chosen": -2.6580405235290527,
      "logits/rejected": -2.6532206535339355,
      "logps/chosen": -138.3712158203125,
      "logps/rejected": -148.5576171875,
      "loss": 0.4662,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9672715067863464,
      "rewards/margins": 1.224899172782898,
      "rewards/rejected": -2.1921706199645996,
      "step": 2430
    },
    {
      "epoch": 0.445296103659093,
      "grad_norm": 4.561032295227051,
      "learning_rate": 4.5697128917245267e-05,
      "logits/chosen": -2.6539647579193115,
      "logits/rejected": -2.583791732788086,
      "logps/chosen": -130.8960418701172,
      "logps/rejected": -130.28408813476562,
      "loss": 0.5275,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.5602923631668091,
      "rewards/margins": 1.085990309715271,
      "rewards/rejected": -1.6462825536727905,
      "step": 2440
    },
    {
      "epoch": 0.4471210876904827,
      "grad_norm": 7.843081951141357,
      "learning_rate": 4.55620191405517e-05,
      "logits/chosen": -2.665163040161133,
      "logits/rejected": -2.6228952407836914,
      "logps/chosen": -123.07426452636719,
      "logps/rejected": -123.70050048828125,
      "loss": 0.6069,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6174814105033875,
      "rewards/margins": 0.8444105386734009,
      "rewards/rejected": -1.4618918895721436,
      "step": 2450
    },
    {
      "epoch": 0.44894607172187245,
      "grad_norm": 6.32977819442749,
      "learning_rate": 4.5411897166447744e-05,
      "logits/chosen": -2.7669944763183594,
      "logits/rejected": -2.596893310546875,
      "logps/chosen": -151.46542358398438,
      "logps/rejected": -126.04792785644531,
      "loss": 0.6738,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.650765061378479,
      "rewards/margins": 0.5924800038337708,
      "rewards/rejected": -1.2432448863983154,
      "step": 2460
    },
    {
      "epoch": 0.45077105575326215,
      "grad_norm": 5.508012294769287,
      "learning_rate": 4.526177519234378e-05,
      "logits/chosen": -2.6273245811462402,
      "logits/rejected": -2.488431453704834,
      "logps/chosen": -145.03811645507812,
      "logps/rejected": -122.7486343383789,
      "loss": 0.5428,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.666633129119873,
      "rewards/margins": 1.0635337829589844,
      "rewards/rejected": -1.7301671504974365,
      "step": 2470
    },
    {
      "epoch": 0.4525960397846519,
      "grad_norm": 8.123263359069824,
      "learning_rate": 4.511165321823982e-05,
      "logits/chosen": -2.60709810256958,
      "logits/rejected": -2.504840850830078,
      "logps/chosen": -136.2899932861328,
      "logps/rejected": -136.64088439941406,
      "loss": 0.6075,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.0165483951568604,
      "rewards/margins": 0.8776386380195618,
      "rewards/rejected": -1.8941867351531982,
      "step": 2480
    },
    {
      "epoch": 0.4544210238160416,
      "grad_norm": 5.112154006958008,
      "learning_rate": 4.496153124413586e-05,
      "logits/chosen": -2.51511812210083,
      "logits/rejected": -2.4212937355041504,
      "logps/chosen": -132.63906860351562,
      "logps/rejected": -133.59786987304688,
      "loss": 0.4811,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0393890142440796,
      "rewards/margins": 1.2665575742721558,
      "rewards/rejected": -2.3059465885162354,
      "step": 2490
    },
    {
      "epoch": 0.45624600784743136,
      "grad_norm": 4.35161018371582,
      "learning_rate": 4.48114092700319e-05,
      "logits/chosen": -2.6239402294158936,
      "logits/rejected": -2.476871967315674,
      "logps/chosen": -130.14700317382812,
      "logps/rejected": -108.5963134765625,
      "loss": 0.5377,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.936225414276123,
      "rewards/margins": 0.9397726058959961,
      "rewards/rejected": -1.8759979009628296,
      "step": 2500
    },
    {
      "epoch": 0.45807099187882105,
      "grad_norm": 7.644682884216309,
      "learning_rate": 4.466128729592795e-05,
      "logits/chosen": -2.579453706741333,
      "logits/rejected": -2.3499398231506348,
      "logps/chosen": -157.75062561035156,
      "logps/rejected": -124.33439636230469,
      "loss": 0.5553,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7847273349761963,
      "rewards/margins": 1.1464791297912598,
      "rewards/rejected": -1.9312063455581665,
      "step": 2510
    },
    {
      "epoch": 0.4598959759102108,
      "grad_norm": 6.250443935394287,
      "learning_rate": 4.451116532182399e-05,
      "logits/chosen": -2.56829571723938,
      "logits/rejected": -2.3882453441619873,
      "logps/chosen": -156.15762329101562,
      "logps/rejected": -129.27671813964844,
      "loss": 0.5432,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.49070167541503906,
      "rewards/margins": 0.9554640650749207,
      "rewards/rejected": -1.4461658000946045,
      "step": 2520
    },
    {
      "epoch": 0.4617209599416005,
      "grad_norm": 6.298057556152344,
      "learning_rate": 4.436104334772003e-05,
      "logits/chosen": -2.640608549118042,
      "logits/rejected": -2.536302089691162,
      "logps/chosen": -143.01026916503906,
      "logps/rejected": -132.45376586914062,
      "loss": 0.6166,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5756314396858215,
      "rewards/margins": 0.8119403123855591,
      "rewards/rejected": -1.3875716924667358,
      "step": 2530
    },
    {
      "epoch": 0.46354594397299026,
      "grad_norm": 2.329181671142578,
      "learning_rate": 4.4210921373616067e-05,
      "logits/chosen": -2.464395046234131,
      "logits/rejected": -2.371758222579956,
      "logps/chosen": -132.58419799804688,
      "logps/rejected": -120.7157211303711,
      "loss": 0.5644,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.47889503836631775,
      "rewards/margins": 0.794263482093811,
      "rewards/rejected": -1.2731585502624512,
      "step": 2540
    },
    {
      "epoch": 0.46537092800437996,
      "grad_norm": 6.716659069061279,
      "learning_rate": 4.406079939951211e-05,
      "logits/chosen": -2.5697197914123535,
      "logits/rejected": -2.447882652282715,
      "logps/chosen": -115.60050964355469,
      "logps/rejected": -109.58045959472656,
      "loss": 0.461,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.23988625407218933,
      "rewards/margins": 1.0429697036743164,
      "rewards/rejected": -1.2828561067581177,
      "step": 2550
    },
    {
      "epoch": 0.4671959120357697,
      "grad_norm": 4.969099521636963,
      "learning_rate": 4.3910677425408146e-05,
      "logits/chosen": -2.5120208263397217,
      "logits/rejected": -2.3605599403381348,
      "logps/chosen": -122.1008071899414,
      "logps/rejected": -109.39388275146484,
      "loss": 0.528,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.5206863284111023,
      "rewards/margins": 1.1049835681915283,
      "rewards/rejected": -1.6256698369979858,
      "step": 2560
    },
    {
      "epoch": 0.4690208960671594,
      "grad_norm": 3.356326103210449,
      "learning_rate": 4.376055545130419e-05,
      "logits/chosen": -2.4313786029815674,
      "logits/rejected": -2.435703992843628,
      "logps/chosen": -126.40486907958984,
      "logps/rejected": -138.64077758789062,
      "loss": 0.7153,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.5532614588737488,
      "rewards/margins": 0.5726485848426819,
      "rewards/rejected": -1.1259100437164307,
      "step": 2570
    },
    {
      "epoch": 0.47084588009854916,
      "grad_norm": 2.5340325832366943,
      "learning_rate": 4.3610433477200224e-05,
      "logits/chosen": -2.5777106285095215,
      "logits/rejected": -2.4205915927886963,
      "logps/chosen": -123.9983901977539,
      "logps/rejected": -113.6518783569336,
      "loss": 0.5259,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.34847986698150635,
      "rewards/margins": 0.8375908732414246,
      "rewards/rejected": -1.1860707998275757,
      "step": 2580
    },
    {
      "epoch": 0.47267086412993886,
      "grad_norm": 3.8287301063537598,
      "learning_rate": 4.3460311503096274e-05,
      "logits/chosen": -2.5114712715148926,
      "logits/rejected": -2.420409679412842,
      "logps/chosen": -124.2292251586914,
      "logps/rejected": -116.01566314697266,
      "loss": 0.5113,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.7396264672279358,
      "rewards/margins": 0.8730729818344116,
      "rewards/rejected": -1.6126995086669922,
      "step": 2590
    },
    {
      "epoch": 0.4744958481613286,
      "grad_norm": 4.117801189422607,
      "learning_rate": 4.331018952899231e-05,
      "logits/chosen": -2.537019729614258,
      "logits/rejected": -2.472212553024292,
      "logps/chosen": -128.6697540283203,
      "logps/rejected": -123.8684310913086,
      "loss": 0.5911,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.6880923509597778,
      "rewards/margins": 0.7063658833503723,
      "rewards/rejected": -1.3944581747055054,
      "step": 2600
    },
    {
      "epoch": 0.4763208321927183,
      "grad_norm": 3.183304786682129,
      "learning_rate": 4.316006755488835e-05,
      "logits/chosen": -2.6826891899108887,
      "logits/rejected": -2.5545406341552734,
      "logps/chosen": -134.5196990966797,
      "logps/rejected": -128.43414306640625,
      "loss": 0.5098,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.28920912742614746,
      "rewards/margins": 1.052330732345581,
      "rewards/rejected": -1.3415398597717285,
      "step": 2610
    },
    {
      "epoch": 0.47814581622410807,
      "grad_norm": 4.182354927062988,
      "learning_rate": 4.300994558078439e-05,
      "logits/chosen": -2.6000046730041504,
      "logits/rejected": -2.4595205783843994,
      "logps/chosen": -140.76043701171875,
      "logps/rejected": -120.4977035522461,
      "loss": 0.5276,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.41995853185653687,
      "rewards/margins": 1.104863166809082,
      "rewards/rejected": -1.5248216390609741,
      "step": 2620
    },
    {
      "epoch": 0.47997080025549776,
      "grad_norm": 6.452111721038818,
      "learning_rate": 4.285982360668043e-05,
      "logits/chosen": -2.5766024589538574,
      "logits/rejected": -2.4740986824035645,
      "logps/chosen": -143.12185668945312,
      "logps/rejected": -132.5729217529297,
      "loss": 0.6357,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.8387101888656616,
      "rewards/margins": 0.7616825103759766,
      "rewards/rejected": -1.6003925800323486,
      "step": 2630
    },
    {
      "epoch": 0.48179578428688746,
      "grad_norm": 3.643341302871704,
      "learning_rate": 4.270970163257647e-05,
      "logits/chosen": -2.7049882411956787,
      "logits/rejected": -2.501072406768799,
      "logps/chosen": -146.34957885742188,
      "logps/rejected": -123.53105163574219,
      "loss": 0.5178,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.3699370324611664,
      "rewards/margins": 0.9920594096183777,
      "rewards/rejected": -1.3619964122772217,
      "step": 2640
    },
    {
      "epoch": 0.4836207683182772,
      "grad_norm": 3.6895151138305664,
      "learning_rate": 4.255957965847251e-05,
      "logits/chosen": -2.6066830158233643,
      "logits/rejected": -2.486147880554199,
      "logps/chosen": -149.60174560546875,
      "logps/rejected": -135.45523071289062,
      "loss": 0.5077,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.3102189600467682,
      "rewards/margins": 0.8846108317375183,
      "rewards/rejected": -1.1948298215866089,
      "step": 2650
    },
    {
      "epoch": 0.4854457523496669,
      "grad_norm": 6.331787109375,
      "learning_rate": 4.240945768436855e-05,
      "logits/chosen": -2.4574310779571533,
      "logits/rejected": -2.4090065956115723,
      "logps/chosen": -128.8203125,
      "logps/rejected": -134.14259338378906,
      "loss": 0.6018,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6959742307662964,
      "rewards/margins": 0.8194279670715332,
      "rewards/rejected": -1.5154021978378296,
      "step": 2660
    },
    {
      "epoch": 0.48727073638105667,
      "grad_norm": 4.562155723571777,
      "learning_rate": 4.22593357102646e-05,
      "logits/chosen": -2.572178602218628,
      "logits/rejected": -2.5248990058898926,
      "logps/chosen": -144.39794921875,
      "logps/rejected": -144.48440551757812,
      "loss": 0.5743,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.4784092307090759,
      "rewards/margins": 0.8613583445549011,
      "rewards/rejected": -1.339767575263977,
      "step": 2670
    },
    {
      "epoch": 0.48909572041244637,
      "grad_norm": 6.914539813995361,
      "learning_rate": 4.210921373616064e-05,
      "logits/chosen": -2.584902286529541,
      "logits/rejected": -2.4137535095214844,
      "logps/chosen": -129.85438537597656,
      "logps/rejected": -106.677978515625,
      "loss": 0.5359,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.43599939346313477,
      "rewards/margins": 0.755778431892395,
      "rewards/rejected": -1.1917778253555298,
      "step": 2680
    },
    {
      "epoch": 0.4909207044438361,
      "grad_norm": 4.312023162841797,
      "learning_rate": 4.1959091762056676e-05,
      "logits/chosen": -2.6661343574523926,
      "logits/rejected": -2.450528860092163,
      "logps/chosen": -156.89801025390625,
      "logps/rejected": -128.18431091308594,
      "loss": 0.4731,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.405008465051651,
      "rewards/margins": 1.064508318901062,
      "rewards/rejected": -1.4695167541503906,
      "step": 2690
    },
    {
      "epoch": 0.4927456884752258,
      "grad_norm": 4.686208724975586,
      "learning_rate": 4.180896978795272e-05,
      "logits/chosen": -2.5813655853271484,
      "logits/rejected": -2.436509370803833,
      "logps/chosen": -150.67300415039062,
      "logps/rejected": -133.43426513671875,
      "loss": 0.5234,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.589307963848114,
      "rewards/margins": 1.1238588094711304,
      "rewards/rejected": -1.7131668329238892,
      "step": 2700
    },
    {
      "epoch": 0.49457067250661557,
      "grad_norm": 8.022482872009277,
      "learning_rate": 4.1658847813848755e-05,
      "logits/chosen": -2.4957096576690674,
      "logits/rejected": -2.443246603012085,
      "logps/chosen": -135.25546264648438,
      "logps/rejected": -144.50949096679688,
      "loss": 0.6027,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.009233832359314,
      "rewards/margins": 0.857361912727356,
      "rewards/rejected": -1.8665956258773804,
      "step": 2710
    },
    {
      "epoch": 0.49639565653800527,
      "grad_norm": 6.452142238616943,
      "learning_rate": 4.15087258397448e-05,
      "logits/chosen": -2.4138271808624268,
      "logits/rejected": -2.3362948894500732,
      "logps/chosen": -147.09194946289062,
      "logps/rejected": -144.61260986328125,
      "loss": 0.6343,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.197352647781372,
      "rewards/margins": 0.8424696922302246,
      "rewards/rejected": -2.0398223400115967,
      "step": 2720
    },
    {
      "epoch": 0.498220640569395,
      "grad_norm": 3.327296733856201,
      "learning_rate": 4.1358603865640834e-05,
      "logits/chosen": -2.570176124572754,
      "logits/rejected": -2.4351751804351807,
      "logps/chosen": -115.4731216430664,
      "logps/rejected": -104.36749267578125,
      "loss": 0.4822,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.4739643633365631,
      "rewards/margins": 1.1190592050552368,
      "rewards/rejected": -1.5930237770080566,
      "step": 2730
    },
    {
      "epoch": 0.5000456246007847,
      "grad_norm": 5.715978622436523,
      "learning_rate": 4.1208481891536876e-05,
      "logits/chosen": -2.539097547531128,
      "logits/rejected": -2.368769407272339,
      "logps/chosen": -157.78807067871094,
      "logps/rejected": -131.0543670654297,
      "loss": 0.5739,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.5439707040786743,
      "rewards/margins": 0.8937085866928101,
      "rewards/rejected": -1.4376792907714844,
      "step": 2740
    },
    {
      "epoch": 0.5018706086321745,
      "grad_norm": 4.833406925201416,
      "learning_rate": 4.105835991743292e-05,
      "logits/chosen": -2.4627633094787598,
      "logits/rejected": -2.4301772117614746,
      "logps/chosen": -129.26754760742188,
      "logps/rejected": -130.7792205810547,
      "loss": 0.5696,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.3718103766441345,
      "rewards/margins": 0.7772188186645508,
      "rewards/rejected": -1.1490291357040405,
      "step": 2750
    },
    {
      "epoch": 0.5036955926635642,
      "grad_norm": 5.145395278930664,
      "learning_rate": 4.090823794332896e-05,
      "logits/chosen": -2.514030933380127,
      "logits/rejected": -2.4964256286621094,
      "logps/chosen": -136.1942138671875,
      "logps/rejected": -137.08392333984375,
      "loss": 0.6073,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.4209655225276947,
      "rewards/margins": 0.6564900875091553,
      "rewards/rejected": -1.0774556398391724,
      "step": 2760
    },
    {
      "epoch": 0.5055205766949539,
      "grad_norm": 3.9361605644226074,
      "learning_rate": 4.0758115969225e-05,
      "logits/chosen": -2.5684075355529785,
      "logits/rejected": -2.506129503250122,
      "logps/chosen": -111.19864654541016,
      "logps/rejected": -127.5184326171875,
      "loss": 0.3723,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.10993547737598419,
      "rewards/margins": 1.5384904146194458,
      "rewards/rejected": -1.6484256982803345,
      "step": 2770
    },
    {
      "epoch": 0.5073455607263436,
      "grad_norm": 4.70595121383667,
      "learning_rate": 4.060799399512104e-05,
      "logits/chosen": -2.564131736755371,
      "logits/rejected": -2.3319263458251953,
      "logps/chosen": -151.15628051757812,
      "logps/rejected": -117.71517181396484,
      "loss": 0.4677,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.168771505355835,
      "rewards/margins": 1.3877217769622803,
      "rewards/rejected": -2.5564932823181152,
      "step": 2780
    },
    {
      "epoch": 0.5091705447577334,
      "grad_norm": 5.160515308380127,
      "learning_rate": 4.045787202101708e-05,
      "logits/chosen": -2.4125618934631348,
      "logits/rejected": -2.3095271587371826,
      "logps/chosen": -151.3241729736328,
      "logps/rejected": -147.1299285888672,
      "loss": 0.5847,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.4102901220321655,
      "rewards/margins": 1.0931119918823242,
      "rewards/rejected": -2.5034022331237793,
      "step": 2790
    },
    {
      "epoch": 0.5109955287891231,
      "grad_norm": 12.72346305847168,
      "learning_rate": 4.030775004691312e-05,
      "logits/chosen": -2.3850085735321045,
      "logits/rejected": -2.1916351318359375,
      "logps/chosen": -142.32040405273438,
      "logps/rejected": -127.96635437011719,
      "loss": 0.4511,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.407201886177063,
      "rewards/margins": 1.4598437547683716,
      "rewards/rejected": -2.8670458793640137,
      "step": 2800
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 5.2147345542907715,
      "learning_rate": 4.0157628072809156e-05,
      "logits/chosen": -2.555438995361328,
      "logits/rejected": -2.414700508117676,
      "logps/chosen": -140.70840454101562,
      "logps/rejected": -127.25590515136719,
      "loss": 0.5608,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7403686046600342,
      "rewards/margins": 1.0420809984207153,
      "rewards/rejected": -2.782449722290039,
      "step": 2810
    },
    {
      "epoch": 0.5146454968519025,
      "grad_norm": 4.288267135620117,
      "learning_rate": 4.00075060987052e-05,
      "logits/chosen": -2.5823311805725098,
      "logits/rejected": -2.495894193649292,
      "logps/chosen": -138.221923828125,
      "logps/rejected": -130.4685821533203,
      "loss": 0.4867,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8160262107849121,
      "rewards/margins": 1.0703232288360596,
      "rewards/rejected": -1.8863496780395508,
      "step": 2820
    },
    {
      "epoch": 0.5164704808832923,
      "grad_norm": 6.5487751960754395,
      "learning_rate": 3.985738412460124e-05,
      "logits/chosen": -2.601900100708008,
      "logits/rejected": -2.43351674079895,
      "logps/chosen": -142.62820434570312,
      "logps/rejected": -130.6158905029297,
      "loss": 0.5128,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1920673847198486,
      "rewards/margins": 1.272852897644043,
      "rewards/rejected": -2.4649200439453125,
      "step": 2830
    },
    {
      "epoch": 0.518295464914682,
      "grad_norm": 5.549468517303467,
      "learning_rate": 3.970726215049728e-05,
      "logits/chosen": -2.4973254203796387,
      "logits/rejected": -2.413642168045044,
      "logps/chosen": -128.49932861328125,
      "logps/rejected": -138.04046630859375,
      "loss": 0.4553,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0876498222351074,
      "rewards/margins": 1.3856745958328247,
      "rewards/rejected": -2.4733242988586426,
      "step": 2840
    },
    {
      "epoch": 0.5201204489460717,
      "grad_norm": 3.764655113220215,
      "learning_rate": 3.955714017639333e-05,
      "logits/chosen": -2.484393358230591,
      "logits/rejected": -2.4525649547576904,
      "logps/chosen": -136.57345581054688,
      "logps/rejected": -144.7801055908203,
      "loss": 0.4529,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9682022929191589,
      "rewards/margins": 1.4835498332977295,
      "rewards/rejected": -2.451752185821533,
      "step": 2850
    },
    {
      "epoch": 0.5219454329774614,
      "grad_norm": 8.747374534606934,
      "learning_rate": 3.9407018202289364e-05,
      "logits/chosen": -2.5171303749084473,
      "logits/rejected": -2.405717372894287,
      "logps/chosen": -136.64695739746094,
      "logps/rejected": -134.76535034179688,
      "loss": 0.4772,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3025248050689697,
      "rewards/margins": 1.3854358196258545,
      "rewards/rejected": -2.687960624694824,
      "step": 2860
    },
    {
      "epoch": 0.5237704170088512,
      "grad_norm": 5.050955772399902,
      "learning_rate": 3.925689622818541e-05,
      "logits/chosen": -2.5780177116394043,
      "logits/rejected": -2.425241708755493,
      "logps/chosen": -140.87881469726562,
      "logps/rejected": -129.14637756347656,
      "loss": 0.5184,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2447744607925415,
      "rewards/margins": 1.3546380996704102,
      "rewards/rejected": -2.599412441253662,
      "step": 2870
    },
    {
      "epoch": 0.5255954010402409,
      "grad_norm": 4.114623546600342,
      "learning_rate": 3.910677425408144e-05,
      "logits/chosen": -2.595503568649292,
      "logits/rejected": -2.3776581287384033,
      "logps/chosen": -151.63168334960938,
      "logps/rejected": -126.85264587402344,
      "loss": 0.4822,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.193847417831421,
      "rewards/margins": 1.3192020654678345,
      "rewards/rejected": -2.513049602508545,
      "step": 2880
    },
    {
      "epoch": 0.5274203850716306,
      "grad_norm": 7.429598331451416,
      "learning_rate": 3.8956652279977486e-05,
      "logits/chosen": -2.620403528213501,
      "logits/rejected": -2.499680995941162,
      "logps/chosen": -146.71685791015625,
      "logps/rejected": -132.33535766601562,
      "loss": 0.4528,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.0202362537384033,
      "rewards/margins": 1.455197811126709,
      "rewards/rejected": -2.475433826446533,
      "step": 2890
    },
    {
      "epoch": 0.5292453691030203,
      "grad_norm": 5.2643303871154785,
      "learning_rate": 3.880653030587353e-05,
      "logits/chosen": -2.5599207878112793,
      "logits/rejected": -2.4489970207214355,
      "logps/chosen": -122.38016510009766,
      "logps/rejected": -130.4197540283203,
      "loss": 0.4648,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.108449101448059,
      "rewards/margins": 1.5871249437332153,
      "rewards/rejected": -2.6955740451812744,
      "step": 2900
    },
    {
      "epoch": 0.5310703531344101,
      "grad_norm": 4.579492568969727,
      "learning_rate": 3.8656408331769565e-05,
      "logits/chosen": -2.602680206298828,
      "logits/rejected": -2.5263113975524902,
      "logps/chosen": -143.854248046875,
      "logps/rejected": -131.72012329101562,
      "loss": 0.6333,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.282069206237793,
      "rewards/margins": 0.7376190423965454,
      "rewards/rejected": -2.019688129425049,
      "step": 2910
    },
    {
      "epoch": 0.5328953371657998,
      "grad_norm": 6.161257266998291,
      "learning_rate": 3.850628635766561e-05,
      "logits/chosen": -2.5964722633361816,
      "logits/rejected": -2.3775534629821777,
      "logps/chosen": -144.14723205566406,
      "logps/rejected": -111.08119201660156,
      "loss": 0.487,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.7129071950912476,
      "rewards/margins": 1.3573358058929443,
      "rewards/rejected": -2.0702431201934814,
      "step": 2920
    },
    {
      "epoch": 0.5347203211971895,
      "grad_norm": 7.0402116775512695,
      "learning_rate": 3.8356164383561644e-05,
      "logits/chosen": -2.5847558975219727,
      "logits/rejected": -2.523747444152832,
      "logps/chosen": -122.56694030761719,
      "logps/rejected": -118.0162124633789,
      "loss": 0.625,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.4419991970062256,
      "rewards/margins": 0.8592002987861633,
      "rewards/rejected": -2.301199436187744,
      "step": 2930
    },
    {
      "epoch": 0.5365453052285792,
      "grad_norm": 3.225634813308716,
      "learning_rate": 3.8206042409457686e-05,
      "logits/chosen": -2.5909156799316406,
      "logits/rejected": -2.4542109966278076,
      "logps/chosen": -148.58639526367188,
      "logps/rejected": -136.38961791992188,
      "loss": 0.5112,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.212975263595581,
      "rewards/margins": 1.2326953411102295,
      "rewards/rejected": -2.4456706047058105,
      "step": 2940
    },
    {
      "epoch": 0.538370289259969,
      "grad_norm": 4.602450847625732,
      "learning_rate": 3.805592043535373e-05,
      "logits/chosen": -2.511340618133545,
      "logits/rejected": -2.5101640224456787,
      "logps/chosen": -121.67695617675781,
      "logps/rejected": -133.52296447753906,
      "loss": 0.6478,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.7117210626602173,
      "rewards/margins": 0.8663078546524048,
      "rewards/rejected": -2.578029155731201,
      "step": 2950
    },
    {
      "epoch": 0.5401952732913587,
      "grad_norm": 9.723780632019043,
      "learning_rate": 3.7905798461249765e-05,
      "logits/chosen": -2.6594319343566895,
      "logits/rejected": -2.5083365440368652,
      "logps/chosen": -146.98434448242188,
      "logps/rejected": -124.7300796508789,
      "loss": 0.5866,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0967376232147217,
      "rewards/margins": 0.8831688761711121,
      "rewards/rejected": -1.979906678199768,
      "step": 2960
    },
    {
      "epoch": 0.5420202573227484,
      "grad_norm": 4.141384124755859,
      "learning_rate": 3.775567648714581e-05,
      "logits/chosen": -2.7469210624694824,
      "logits/rejected": -2.65739369392395,
      "logps/chosen": -136.2699432373047,
      "logps/rejected": -133.3512725830078,
      "loss": 0.5963,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.9911632537841797,
      "rewards/margins": 0.771894097328186,
      "rewards/rejected": -1.7630573511123657,
      "step": 2970
    },
    {
      "epoch": 0.5438452413541381,
      "grad_norm": 5.6623992919921875,
      "learning_rate": 3.760555451304185e-05,
      "logits/chosen": -2.6499783992767334,
      "logits/rejected": -2.584756374359131,
      "logps/chosen": -137.65493774414062,
      "logps/rejected": -133.35165405273438,
      "loss": 0.6452,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -1.1632596254348755,
      "rewards/margins": 0.703620970249176,
      "rewards/rejected": -1.8668807744979858,
      "step": 2980
    },
    {
      "epoch": 0.5456702253855279,
      "grad_norm": 3.0300097465515137,
      "learning_rate": 3.745543253893789e-05,
      "logits/chosen": -2.574402093887329,
      "logits/rejected": -2.438971519470215,
      "logps/chosen": -139.71755981445312,
      "logps/rejected": -122.8198013305664,
      "loss": 0.4349,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.7555192708969116,
      "rewards/margins": 1.0739467144012451,
      "rewards/rejected": -1.8294661045074463,
      "step": 2990
    },
    {
      "epoch": 0.5474952094169176,
      "grad_norm": 2.9288482666015625,
      "learning_rate": 3.730531056483393e-05,
      "logits/chosen": -2.6531407833099365,
      "logits/rejected": -2.4991517066955566,
      "logps/chosen": -130.16339111328125,
      "logps/rejected": -116.48100280761719,
      "loss": 0.4586,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7783580422401428,
      "rewards/margins": 1.1102951765060425,
      "rewards/rejected": -1.8886533975601196,
      "step": 3000
    },
    {
      "epoch": 0.5493201934483073,
      "grad_norm": 5.353767395019531,
      "learning_rate": 3.7155188590729966e-05,
      "logits/chosen": -2.5403409004211426,
      "logits/rejected": -2.433986186981201,
      "logps/chosen": -131.8846893310547,
      "logps/rejected": -122.0605697631836,
      "loss": 0.5718,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.123816728591919,
      "rewards/margins": 0.8456963300704956,
      "rewards/rejected": -1.969512939453125,
      "step": 3010
    },
    {
      "epoch": 0.551145177479697,
      "grad_norm": 2.2145652770996094,
      "learning_rate": 3.7005066616626016e-05,
      "logits/chosen": -2.616088390350342,
      "logits/rejected": -2.4805843830108643,
      "logps/chosen": -148.19296264648438,
      "logps/rejected": -136.81634521484375,
      "loss": 0.574,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.258069396018982,
      "rewards/margins": 0.9005132913589478,
      "rewards/rejected": -2.1585826873779297,
      "step": 3020
    },
    {
      "epoch": 0.5529701615110868,
      "grad_norm": 12.158803939819336,
      "learning_rate": 3.685494464252205e-05,
      "logits/chosen": -2.547178030014038,
      "logits/rejected": -2.4091689586639404,
      "logps/chosen": -146.59951782226562,
      "logps/rejected": -131.32693481445312,
      "loss": 0.5226,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2210267782211304,
      "rewards/margins": 0.9770906567573547,
      "rewards/rejected": -2.198117256164551,
      "step": 3030
    },
    {
      "epoch": 0.5547951455424766,
      "grad_norm": 6.669105529785156,
      "learning_rate": 3.6704822668418095e-05,
      "logits/chosen": -2.7516980171203613,
      "logits/rejected": -2.6989810466766357,
      "logps/chosen": -126.6004638671875,
      "logps/rejected": -127.26114654541016,
      "loss": 0.6029,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.157785177230835,
      "rewards/margins": 0.6863996386528015,
      "rewards/rejected": -1.8441848754882812,
      "step": 3040
    },
    {
      "epoch": 0.5566201295738662,
      "grad_norm": 4.285030841827393,
      "learning_rate": 3.655470069431413e-05,
      "logits/chosen": -2.526125907897949,
      "logits/rejected": -2.4657225608825684,
      "logps/chosen": -107.91535949707031,
      "logps/rejected": -113.0749740600586,
      "loss": 0.5515,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.4765563011169434,
      "rewards/margins": 0.9149880409240723,
      "rewards/rejected": -2.3915441036224365,
      "step": 3050
    },
    {
      "epoch": 0.558445113605256,
      "grad_norm": 4.865703105926514,
      "learning_rate": 3.6404578720210174e-05,
      "logits/chosen": -2.6088380813598633,
      "logits/rejected": -2.4727249145507812,
      "logps/chosen": -147.88311767578125,
      "logps/rejected": -141.5452117919922,
      "loss": 0.4597,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1308077573776245,
      "rewards/margins": 1.1695241928100586,
      "rewards/rejected": -2.3003320693969727,
      "step": 3060
    },
    {
      "epoch": 0.5602700976366457,
      "grad_norm": 2.7603273391723633,
      "learning_rate": 3.6254456746106217e-05,
      "logits/chosen": -2.6263935565948486,
      "logits/rejected": -2.582253932952881,
      "logps/chosen": -129.9552459716797,
      "logps/rejected": -142.676025390625,
      "loss": 0.5474,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.280417561531067,
      "rewards/margins": 1.0346038341522217,
      "rewards/rejected": -2.315021514892578,
      "step": 3070
    },
    {
      "epoch": 0.5620950816680355,
      "grad_norm": 3.68327260017395,
      "learning_rate": 3.610433477200225e-05,
      "logits/chosen": -2.531961679458618,
      "logits/rejected": -2.425229549407959,
      "logps/chosen": -133.52462768554688,
      "logps/rejected": -133.10897827148438,
      "loss": 0.5831,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.1725915670394897,
      "rewards/margins": 0.9990827441215515,
      "rewards/rejected": -2.1716742515563965,
      "step": 3080
    },
    {
      "epoch": 0.5639200656994251,
      "grad_norm": 3.243354320526123,
      "learning_rate": 3.5954212797898296e-05,
      "logits/chosen": -2.613394021987915,
      "logits/rejected": -2.471299648284912,
      "logps/chosen": -144.71495056152344,
      "logps/rejected": -127.0926742553711,
      "loss": 0.5368,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.9567787051200867,
      "rewards/margins": 0.9839474558830261,
      "rewards/rejected": -1.9407260417938232,
      "step": 3090
    },
    {
      "epoch": 0.5657450497308149,
      "grad_norm": 6.387897491455078,
      "learning_rate": 3.580409082379434e-05,
      "logits/chosen": -2.538464069366455,
      "logits/rejected": -2.499512195587158,
      "logps/chosen": -122.97142028808594,
      "logps/rejected": -141.4268341064453,
      "loss": 0.5619,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8157294988632202,
      "rewards/margins": 1.4371073246002197,
      "rewards/rejected": -2.2528369426727295,
      "step": 3100
    },
    {
      "epoch": 0.5675700337622046,
      "grad_norm": 3.95090389251709,
      "learning_rate": 3.5653968849690375e-05,
      "logits/chosen": -2.4958982467651367,
      "logits/rejected": -2.396601676940918,
      "logps/chosen": -149.5994415283203,
      "logps/rejected": -136.0130615234375,
      "loss": 0.4942,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9962199926376343,
      "rewards/margins": 1.179701805114746,
      "rewards/rejected": -2.17592191696167,
      "step": 3110
    },
    {
      "epoch": 0.5693950177935944,
      "grad_norm": 8.150829315185547,
      "learning_rate": 3.550384687558642e-05,
      "logits/chosen": -2.433973789215088,
      "logits/rejected": -2.3535683155059814,
      "logps/chosen": -142.3497772216797,
      "logps/rejected": -148.0263214111328,
      "loss": 0.5639,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.687083899974823,
      "rewards/margins": 1.2195651531219482,
      "rewards/rejected": -1.9066489934921265,
      "step": 3120
    },
    {
      "epoch": 0.571220001824984,
      "grad_norm": 6.170750617980957,
      "learning_rate": 3.5353724901482453e-05,
      "logits/chosen": -2.684917688369751,
      "logits/rejected": -2.519134283065796,
      "logps/chosen": -130.31040954589844,
      "logps/rejected": -112.65861511230469,
      "loss": 0.4684,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.49306195974349976,
      "rewards/margins": 1.2794238328933716,
      "rewards/rejected": -1.7724857330322266,
      "step": 3130
    },
    {
      "epoch": 0.5730449858563738,
      "grad_norm": 7.436776638031006,
      "learning_rate": 3.5203602927378496e-05,
      "logits/chosen": -2.522634983062744,
      "logits/rejected": -2.531341075897217,
      "logps/chosen": -141.2534942626953,
      "logps/rejected": -151.381103515625,
      "loss": 0.5533,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7642966508865356,
      "rewards/margins": 0.905899703502655,
      "rewards/rejected": -1.670196533203125,
      "step": 3140
    },
    {
      "epoch": 0.5748699698877635,
      "grad_norm": 5.73862886428833,
      "learning_rate": 3.505348095327454e-05,
      "logits/chosen": -2.581167697906494,
      "logits/rejected": -2.526801586151123,
      "logps/chosen": -123.70210266113281,
      "logps/rejected": -115.79872131347656,
      "loss": 0.584,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.6469415426254272,
      "rewards/margins": 0.7977264523506165,
      "rewards/rejected": -1.4446680545806885,
      "step": 3150
    },
    {
      "epoch": 0.5766949539191532,
      "grad_norm": 5.2228193283081055,
      "learning_rate": 3.4903358979170575e-05,
      "logits/chosen": -2.59747576713562,
      "logits/rejected": -2.4389660358428955,
      "logps/chosen": -125.42110443115234,
      "logps/rejected": -112.66609954833984,
      "loss": 0.496,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.4282570779323578,
      "rewards/margins": 1.2032983303070068,
      "rewards/rejected": -1.6315555572509766,
      "step": 3160
    },
    {
      "epoch": 0.5785199379505429,
      "grad_norm": 6.672463417053223,
      "learning_rate": 3.475323700506662e-05,
      "logits/chosen": -2.620664119720459,
      "logits/rejected": -2.4969005584716797,
      "logps/chosen": -129.5053253173828,
      "logps/rejected": -113.35587310791016,
      "loss": 0.5435,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.4429005980491638,
      "rewards/margins": 0.9539434313774109,
      "rewards/rejected": -1.3968440294265747,
      "step": 3170
    },
    {
      "epoch": 0.5803449219819327,
      "grad_norm": 4.651492118835449,
      "learning_rate": 3.460311503096266e-05,
      "logits/chosen": -2.6408424377441406,
      "logits/rejected": -2.561087131500244,
      "logps/chosen": -135.94918823242188,
      "logps/rejected": -132.45143127441406,
      "loss": 0.6068,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.7238314151763916,
      "rewards/margins": 0.6683397889137268,
      "rewards/rejected": -1.3921711444854736,
      "step": 3180
    },
    {
      "epoch": 0.5821699060133224,
      "grad_norm": 3.6889147758483887,
      "learning_rate": 3.4452993056858704e-05,
      "logits/chosen": -2.5303072929382324,
      "logits/rejected": -2.3961143493652344,
      "logps/chosen": -132.87460327148438,
      "logps/rejected": -117.64088439941406,
      "loss": 0.5632,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7540003657341003,
      "rewards/margins": 0.8852033615112305,
      "rewards/rejected": -1.639203667640686,
      "step": 3190
    },
    {
      "epoch": 0.5839948900447121,
      "grad_norm": 5.950997829437256,
      "learning_rate": 3.430287108275474e-05,
      "logits/chosen": -2.4947216510772705,
      "logits/rejected": -2.3961257934570312,
      "logps/chosen": -135.98338317871094,
      "logps/rejected": -126.06307220458984,
      "loss": 0.4857,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9122980237007141,
      "rewards/margins": 1.0968832969665527,
      "rewards/rejected": -2.009181261062622,
      "step": 3200
    },
    {
      "epoch": 0.5858198740761018,
      "grad_norm": 2.8159122467041016,
      "learning_rate": 3.415274910865078e-05,
      "logits/chosen": -2.6887078285217285,
      "logits/rejected": -2.521193742752075,
      "logps/chosen": -152.7974395751953,
      "logps/rejected": -127.133544921875,
      "loss": 0.474,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.72057044506073,
      "rewards/margins": 1.2492071390151978,
      "rewards/rejected": -1.9697774648666382,
      "step": 3210
    },
    {
      "epoch": 0.5876448581074916,
      "grad_norm": 4.6359429359436035,
      "learning_rate": 3.4002627134546826e-05,
      "logits/chosen": -2.554640293121338,
      "logits/rejected": -2.450812578201294,
      "logps/chosen": -147.0388641357422,
      "logps/rejected": -135.60330200195312,
      "loss": 0.6547,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.9662356376647949,
      "rewards/margins": 0.8664528131484985,
      "rewards/rejected": -1.832688331604004,
      "step": 3220
    },
    {
      "epoch": 0.5894698421388813,
      "grad_norm": 6.56107234954834,
      "learning_rate": 3.385250516044286e-05,
      "logits/chosen": -2.4977622032165527,
      "logits/rejected": -2.4220080375671387,
      "logps/chosen": -133.76571655273438,
      "logps/rejected": -129.9354248046875,
      "loss": 0.507,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.7029874920845032,
      "rewards/margins": 1.065735101699829,
      "rewards/rejected": -1.7687225341796875,
      "step": 3230
    },
    {
      "epoch": 0.591294826170271,
      "grad_norm": 6.343636512756348,
      "learning_rate": 3.3702383186338905e-05,
      "logits/chosen": -2.4532010555267334,
      "logits/rejected": -2.3207483291625977,
      "logps/chosen": -134.30934143066406,
      "logps/rejected": -127.56111145019531,
      "loss": 0.4406,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.7894213795661926,
      "rewards/margins": 1.3552818298339844,
      "rewards/rejected": -2.144702911376953,
      "step": 3240
    },
    {
      "epoch": 0.5931198102016607,
      "grad_norm": 4.543653964996338,
      "learning_rate": 3.355226121223494e-05,
      "logits/chosen": -2.5129153728485107,
      "logits/rejected": -2.3994343280792236,
      "logps/chosen": -134.92196655273438,
      "logps/rejected": -124.2807846069336,
      "loss": 0.5035,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8639401197433472,
      "rewards/margins": 1.0225356817245483,
      "rewards/rejected": -1.886475920677185,
      "step": 3250
    },
    {
      "epoch": 0.5949447942330505,
      "grad_norm": 5.258756637573242,
      "learning_rate": 3.3402139238130984e-05,
      "logits/chosen": -2.5088863372802734,
      "logits/rejected": -2.4122166633605957,
      "logps/chosen": -146.55746459960938,
      "logps/rejected": -134.3494873046875,
      "loss": 0.5375,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6770111322402954,
      "rewards/margins": 0.9257867932319641,
      "rewards/rejected": -1.6027978658676147,
      "step": 3260
    },
    {
      "epoch": 0.5967697782644402,
      "grad_norm": 4.417481422424316,
      "learning_rate": 3.3252017264027027e-05,
      "logits/chosen": -2.4808106422424316,
      "logits/rejected": -2.4718992710113525,
      "logps/chosen": -124.9833755493164,
      "logps/rejected": -132.73745727539062,
      "loss": 0.5302,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0004152059555054,
      "rewards/margins": 0.912389874458313,
      "rewards/rejected": -1.912805199623108,
      "step": 3270
    },
    {
      "epoch": 0.5985947622958299,
      "grad_norm": 4.467449188232422,
      "learning_rate": 3.310189528992306e-05,
      "logits/chosen": -2.6274991035461426,
      "logits/rejected": -2.4844279289245605,
      "logps/chosen": -139.33346557617188,
      "logps/rejected": -124.98509216308594,
      "loss": 0.4915,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8045613169670105,
      "rewards/margins": 1.2010389566421509,
      "rewards/rejected": -2.0056004524230957,
      "step": 3280
    },
    {
      "epoch": 0.6004197463272196,
      "grad_norm": 3.835421323776245,
      "learning_rate": 3.2951773315819105e-05,
      "logits/chosen": -2.539077043533325,
      "logits/rejected": -2.4088666439056396,
      "logps/chosen": -138.4291534423828,
      "logps/rejected": -132.46304321289062,
      "loss": 0.5876,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1735332012176514,
      "rewards/margins": 0.7820956110954285,
      "rewards/rejected": -1.9556289911270142,
      "step": 3290
    },
    {
      "epoch": 0.6022447303586094,
      "grad_norm": 6.073951244354248,
      "learning_rate": 3.280165134171515e-05,
      "logits/chosen": -2.666138172149658,
      "logits/rejected": -2.5066258907318115,
      "logps/chosen": -140.9739990234375,
      "logps/rejected": -127.7179183959961,
      "loss": 0.4438,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9804307818412781,
      "rewards/margins": 1.096766710281372,
      "rewards/rejected": -2.077197551727295,
      "step": 3300
    },
    {
      "epoch": 0.6040697143899991,
      "grad_norm": 7.227461338043213,
      "learning_rate": 3.2651529367611184e-05,
      "logits/chosen": -2.5748484134674072,
      "logits/rejected": -2.4161694049835205,
      "logps/chosen": -155.29013061523438,
      "logps/rejected": -130.69435119628906,
      "loss": 0.5706,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.067554235458374,
      "rewards/margins": 0.9051898121833801,
      "rewards/rejected": -1.9727439880371094,
      "step": 3310
    },
    {
      "epoch": 0.6058946984213888,
      "grad_norm": 5.143510341644287,
      "learning_rate": 3.250140739350723e-05,
      "logits/chosen": -2.5142455101013184,
      "logits/rejected": -2.4390783309936523,
      "logps/chosen": -129.73068237304688,
      "logps/rejected": -134.71688842773438,
      "loss": 0.5396,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8759433031082153,
      "rewards/margins": 0.9606763124465942,
      "rewards/rejected": -1.8366193771362305,
      "step": 3320
    },
    {
      "epoch": 0.6077196824527785,
      "grad_norm": 8.233708381652832,
      "learning_rate": 3.2351285419403263e-05,
      "logits/chosen": -2.523953437805176,
      "logits/rejected": -2.4269165992736816,
      "logps/chosen": -126.70179748535156,
      "logps/rejected": -122.89200592041016,
      "loss": 0.5345,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.6836581826210022,
      "rewards/margins": 0.9461644887924194,
      "rewards/rejected": -1.6298224925994873,
      "step": 3330
    },
    {
      "epoch": 0.6095446664841683,
      "grad_norm": 6.943474769592285,
      "learning_rate": 3.220116344529931e-05,
      "logits/chosen": -2.60457181930542,
      "logits/rejected": -2.3907952308654785,
      "logps/chosen": -158.21234130859375,
      "logps/rejected": -126.1541519165039,
      "loss": 0.4889,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6042725443840027,
      "rewards/margins": 1.0902540683746338,
      "rewards/rejected": -1.6945266723632812,
      "step": 3340
    },
    {
      "epoch": 0.611369650515558,
      "grad_norm": 5.87856912612915,
      "learning_rate": 3.205104147119535e-05,
      "logits/chosen": -2.5868325233459473,
      "logits/rejected": -2.5359578132629395,
      "logps/chosen": -142.55465698242188,
      "logps/rejected": -149.01321411132812,
      "loss": 0.5199,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8761926889419556,
      "rewards/margins": 1.1145621538162231,
      "rewards/rejected": -1.9907548427581787,
      "step": 3350
    },
    {
      "epoch": 0.6131946345469477,
      "grad_norm": 6.15061092376709,
      "learning_rate": 3.190091949709139e-05,
      "logits/chosen": -2.4919662475585938,
      "logits/rejected": -2.4539973735809326,
      "logps/chosen": -139.76327514648438,
      "logps/rejected": -144.04922485351562,
      "loss": 0.4877,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0894980430603027,
      "rewards/margins": 1.1193610429763794,
      "rewards/rejected": -2.2088589668273926,
      "step": 3360
    },
    {
      "epoch": 0.6150196185783374,
      "grad_norm": 8.340354919433594,
      "learning_rate": 3.175079752298743e-05,
      "logits/chosen": -2.4878413677215576,
      "logits/rejected": -2.41810941696167,
      "logps/chosen": -137.67245483398438,
      "logps/rejected": -134.83966064453125,
      "loss": 0.6461,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.7003908157348633,
      "rewards/margins": 1.0566127300262451,
      "rewards/rejected": -1.7570034265518188,
      "step": 3370
    },
    {
      "epoch": 0.6168446026097272,
      "grad_norm": 4.2196197509765625,
      "learning_rate": 3.160067554888347e-05,
      "logits/chosen": -2.537590503692627,
      "logits/rejected": -2.4193403720855713,
      "logps/chosen": -133.023193359375,
      "logps/rejected": -123.28199768066406,
      "loss": 0.5543,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.9553146362304688,
      "rewards/margins": 0.9296685457229614,
      "rewards/rejected": -1.8849830627441406,
      "step": 3380
    },
    {
      "epoch": 0.6186695866411169,
      "grad_norm": 2.4456238746643066,
      "learning_rate": 3.1450553574779514e-05,
      "logits/chosen": -2.5210227966308594,
      "logits/rejected": -2.453827381134033,
      "logps/chosen": -124.23860931396484,
      "logps/rejected": -129.35702514648438,
      "loss": 0.4958,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6256037950515747,
      "rewards/margins": 1.0185811519622803,
      "rewards/rejected": -1.6441848278045654,
      "step": 3390
    },
    {
      "epoch": 0.6204945706725066,
      "grad_norm": 4.0221171379089355,
      "learning_rate": 3.130043160067555e-05,
      "logits/chosen": -2.42730975151062,
      "logits/rejected": -2.364025831222534,
      "logps/chosen": -138.46925354003906,
      "logps/rejected": -134.70315551757812,
      "loss": 0.5791,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.8559101223945618,
      "rewards/margins": 0.8621340990066528,
      "rewards/rejected": -1.7180440425872803,
      "step": 3400
    },
    {
      "epoch": 0.6223195547038963,
      "grad_norm": 7.844204425811768,
      "learning_rate": 3.115030962657159e-05,
      "logits/chosen": -2.472104549407959,
      "logits/rejected": -2.345458507537842,
      "logps/chosen": -139.90008544921875,
      "logps/rejected": -129.14321899414062,
      "loss": 0.5442,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.9306102991104126,
      "rewards/margins": 0.9929698705673218,
      "rewards/rejected": -1.9235801696777344,
      "step": 3410
    },
    {
      "epoch": 0.6241445387352861,
      "grad_norm": 2.8686769008636475,
      "learning_rate": 3.100018765246763e-05,
      "logits/chosen": -2.4601378440856934,
      "logits/rejected": -2.325763702392578,
      "logps/chosen": -152.97467041015625,
      "logps/rejected": -130.7819061279297,
      "loss": 0.6368,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.6828551292419434,
      "rewards/margins": 0.8736481666564941,
      "rewards/rejected": -1.5565030574798584,
      "step": 3420
    },
    {
      "epoch": 0.6259695227666758,
      "grad_norm": 4.261242866516113,
      "learning_rate": 3.085006567836367e-05,
      "logits/chosen": -2.546168804168701,
      "logits/rejected": -2.3828470706939697,
      "logps/chosen": -142.3179473876953,
      "logps/rejected": -124.5071792602539,
      "loss": 0.4791,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.4151690900325775,
      "rewards/margins": 1.0943094491958618,
      "rewards/rejected": -1.5094784498214722,
      "step": 3430
    },
    {
      "epoch": 0.6277945067980655,
      "grad_norm": 4.169073104858398,
      "learning_rate": 3.0699943704259715e-05,
      "logits/chosen": -2.4535515308380127,
      "logits/rejected": -2.3387413024902344,
      "logps/chosen": -126.1058578491211,
      "logps/rejected": -111.23576354980469,
      "loss": 0.6292,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6722275614738464,
      "rewards/margins": 0.7066588997840881,
      "rewards/rejected": -1.3788865804672241,
      "step": 3440
    },
    {
      "epoch": 0.6296194908294552,
      "grad_norm": 5.697286605834961,
      "learning_rate": 3.054982173015575e-05,
      "logits/chosen": -2.5474579334259033,
      "logits/rejected": -2.479462146759033,
      "logps/chosen": -125.64530944824219,
      "logps/rejected": -123.20875549316406,
      "loss": 0.6194,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.8614696264266968,
      "rewards/margins": 0.7470174431800842,
      "rewards/rejected": -1.6084871292114258,
      "step": 3450
    },
    {
      "epoch": 0.631444474860845,
      "grad_norm": 3.941948652267456,
      "learning_rate": 3.0399699756051794e-05,
      "logits/chosen": -2.4603829383850098,
      "logits/rejected": -2.375124454498291,
      "logps/chosen": -137.0384979248047,
      "logps/rejected": -135.19151306152344,
      "loss": 0.5176,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.5943067073822021,
      "rewards/margins": 1.0293505191802979,
      "rewards/rejected": -1.6236572265625,
      "step": 3460
    },
    {
      "epoch": 0.6332694588922347,
      "grad_norm": 4.831931114196777,
      "learning_rate": 3.0249577781947836e-05,
      "logits/chosen": -2.383150815963745,
      "logits/rejected": -2.3211073875427246,
      "logps/chosen": -133.13027954101562,
      "logps/rejected": -125.40806579589844,
      "loss": 0.5786,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.6077407598495483,
      "rewards/margins": 0.9800847172737122,
      "rewards/rejected": -1.5878251791000366,
      "step": 3470
    },
    {
      "epoch": 0.6350944429236244,
      "grad_norm": 5.273384094238281,
      "learning_rate": 3.0099455807843876e-05,
      "logits/chosen": -2.6694161891937256,
      "logits/rejected": -2.5111217498779297,
      "logps/chosen": -141.70159912109375,
      "logps/rejected": -116.1089859008789,
      "loss": 0.5908,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6219640970230103,
      "rewards/margins": 0.7294095158576965,
      "rewards/rejected": -1.3513734340667725,
      "step": 3480
    },
    {
      "epoch": 0.6369194269550141,
      "grad_norm": 9.951310157775879,
      "learning_rate": 2.9949333833739915e-05,
      "logits/chosen": -2.567762851715088,
      "logits/rejected": -2.3204941749572754,
      "logps/chosen": -138.28054809570312,
      "logps/rejected": -117.5205078125,
      "loss": 0.5246,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.46281567215919495,
      "rewards/margins": 1.0905897617340088,
      "rewards/rejected": -1.5534052848815918,
      "step": 3490
    },
    {
      "epoch": 0.6387444109864039,
      "grad_norm": 4.81205940246582,
      "learning_rate": 2.9799211859635955e-05,
      "logits/chosen": -2.560687780380249,
      "logits/rejected": -2.3741297721862793,
      "logps/chosen": -139.89022827148438,
      "logps/rejected": -123.6832046508789,
      "loss": 0.4384,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.60556960105896,
      "rewards/margins": 1.1206700801849365,
      "rewards/rejected": -1.726239562034607,
      "step": 3500
    },
    {
      "epoch": 0.6405693950177936,
      "grad_norm": 4.500985145568848,
      "learning_rate": 2.9649089885531998e-05,
      "logits/chosen": -2.540808916091919,
      "logits/rejected": -2.4796886444091797,
      "logps/chosen": -118.72237396240234,
      "logps/rejected": -121.46406555175781,
      "loss": 0.547,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7873358726501465,
      "rewards/margins": 1.094890832901001,
      "rewards/rejected": -1.8822267055511475,
      "step": 3510
    },
    {
      "epoch": 0.6423943790491833,
      "grad_norm": 4.103571891784668,
      "learning_rate": 2.9498967911428037e-05,
      "logits/chosen": -2.491868019104004,
      "logits/rejected": -2.437262773513794,
      "logps/chosen": -122.48912048339844,
      "logps/rejected": -120.7386703491211,
      "loss": 0.5241,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.9207668304443359,
      "rewards/margins": 0.9609954953193665,
      "rewards/rejected": -1.881762146949768,
      "step": 3520
    },
    {
      "epoch": 0.644219363080573,
      "grad_norm": 4.694395065307617,
      "learning_rate": 2.9348845937324077e-05,
      "logits/chosen": -2.617043972015381,
      "logits/rejected": -2.540579319000244,
      "logps/chosen": -146.44705200195312,
      "logps/rejected": -134.9929962158203,
      "loss": 0.6296,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0729835033416748,
      "rewards/margins": 0.8438533544540405,
      "rewards/rejected": -1.9168369770050049,
      "step": 3530
    },
    {
      "epoch": 0.6460443471119628,
      "grad_norm": 4.73476505279541,
      "learning_rate": 2.9198723963220116e-05,
      "logits/chosen": -2.558736562728882,
      "logits/rejected": -2.390491485595703,
      "logps/chosen": -148.95245361328125,
      "logps/rejected": -124.75175476074219,
      "loss": 0.5034,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.141154408454895,
      "rewards/margins": 1.1229026317596436,
      "rewards/rejected": -2.264056921005249,
      "step": 3540
    },
    {
      "epoch": 0.6478693311433525,
      "grad_norm": 8.675764083862305,
      "learning_rate": 2.9048601989116162e-05,
      "logits/chosen": -2.5652518272399902,
      "logits/rejected": -2.5451388359069824,
      "logps/chosen": -117.59016418457031,
      "logps/rejected": -132.08673095703125,
      "loss": 0.7559,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.1055656671524048,
      "rewards/margins": 0.4232669472694397,
      "rewards/rejected": -1.5288324356079102,
      "step": 3550
    },
    {
      "epoch": 0.6496943151747422,
      "grad_norm": 5.571259021759033,
      "learning_rate": 2.8898480015012202e-05,
      "logits/chosen": -2.4872212409973145,
      "logits/rejected": -2.3724021911621094,
      "logps/chosen": -151.18228149414062,
      "logps/rejected": -133.08682250976562,
      "loss": 0.5599,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9643954038619995,
      "rewards/margins": 0.9230481386184692,
      "rewards/rejected": -1.8874435424804688,
      "step": 3560
    },
    {
      "epoch": 0.6515192992061319,
      "grad_norm": 3.2469899654388428,
      "learning_rate": 2.8748358040908238e-05,
      "logits/chosen": -2.546081066131592,
      "logits/rejected": -2.3894131183624268,
      "logps/chosen": -139.29278564453125,
      "logps/rejected": -126.7083969116211,
      "loss": 0.5116,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8720492124557495,
      "rewards/margins": 1.1475412845611572,
      "rewards/rejected": -2.0195908546447754,
      "step": 3570
    },
    {
      "epoch": 0.6533442832375217,
      "grad_norm": 5.351781368255615,
      "learning_rate": 2.8598236066804277e-05,
      "logits/chosen": -2.5648627281188965,
      "logits/rejected": -2.4091696739196777,
      "logps/chosen": -142.94757080078125,
      "logps/rejected": -131.00558471679688,
      "loss": 0.4864,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8107439875602722,
      "rewards/margins": 1.0165945291519165,
      "rewards/rejected": -1.8273385763168335,
      "step": 3580
    },
    {
      "epoch": 0.6551692672689114,
      "grad_norm": 5.687622547149658,
      "learning_rate": 2.8448114092700324e-05,
      "logits/chosen": -2.561669111251831,
      "logits/rejected": -2.5039525032043457,
      "logps/chosen": -117.4845962524414,
      "logps/rejected": -117.79708099365234,
      "loss": 0.6339,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1701884269714355,
      "rewards/margins": 0.6966153383255005,
      "rewards/rejected": -1.8668038845062256,
      "step": 3590
    },
    {
      "epoch": 0.6569942513003011,
      "grad_norm": 5.686426162719727,
      "learning_rate": 2.8297992118596363e-05,
      "logits/chosen": -2.5432305335998535,
      "logits/rejected": -2.4474334716796875,
      "logps/chosen": -124.48631286621094,
      "logps/rejected": -124.52952575683594,
      "loss": 0.4962,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9431833028793335,
      "rewards/margins": 1.1365091800689697,
      "rewards/rejected": -2.0796923637390137,
      "step": 3600
    },
    {
      "epoch": 0.6588192353316908,
      "grad_norm": 3.9601852893829346,
      "learning_rate": 2.8147870144492403e-05,
      "logits/chosen": -2.562143087387085,
      "logits/rejected": -2.542534351348877,
      "logps/chosen": -124.65614318847656,
      "logps/rejected": -125.8714828491211,
      "loss": 0.6728,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -1.1016216278076172,
      "rewards/margins": 0.5018078088760376,
      "rewards/rejected": -1.6034294366836548,
      "step": 3610
    },
    {
      "epoch": 0.6606442193630806,
      "grad_norm": 3.652176856994629,
      "learning_rate": 2.7997748170388442e-05,
      "logits/chosen": -2.379333972930908,
      "logits/rejected": -2.2498555183410645,
      "logps/chosen": -141.08692932128906,
      "logps/rejected": -126.72831726074219,
      "loss": 0.5068,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9283572435379028,
      "rewards/margins": 1.1202495098114014,
      "rewards/rejected": -2.0486066341400146,
      "step": 3620
    },
    {
      "epoch": 0.6624692033944704,
      "grad_norm": 3.3636016845703125,
      "learning_rate": 2.7847626196284485e-05,
      "logits/chosen": -2.464658260345459,
      "logits/rejected": -2.396258592605591,
      "logps/chosen": -147.2225341796875,
      "logps/rejected": -149.12600708007812,
      "loss": 0.5093,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.8070749044418335,
      "rewards/margins": 0.98637855052948,
      "rewards/rejected": -1.793453574180603,
      "step": 3630
    },
    {
      "epoch": 0.66429418742586,
      "grad_norm": 6.386331558227539,
      "learning_rate": 2.7697504222180525e-05,
      "logits/chosen": -2.562288761138916,
      "logits/rejected": -2.410653829574585,
      "logps/chosen": -131.70004272460938,
      "logps/rejected": -120.70204162597656,
      "loss": 0.5014,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1354937553405762,
      "rewards/margins": 1.2534137964248657,
      "rewards/rejected": -2.3889071941375732,
      "step": 3640
    },
    {
      "epoch": 0.6661191714572497,
      "grad_norm": 3.3826417922973633,
      "learning_rate": 2.7547382248076564e-05,
      "logits/chosen": -2.6870431900024414,
      "logits/rejected": -2.5681254863739014,
      "logps/chosen": -136.7792510986328,
      "logps/rejected": -129.29193115234375,
      "loss": 0.5854,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.0080612897872925,
      "rewards/margins": 0.7724336385726929,
      "rewards/rejected": -1.7804949283599854,
      "step": 3650
    },
    {
      "epoch": 0.6679441554886395,
      "grad_norm": 6.795756816864014,
      "learning_rate": 2.7397260273972603e-05,
      "logits/chosen": -2.512479782104492,
      "logits/rejected": -2.3426761627197266,
      "logps/chosen": -138.09100341796875,
      "logps/rejected": -126.5081787109375,
      "loss": 0.5288,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.9987122416496277,
      "rewards/margins": 1.0058999061584473,
      "rewards/rejected": -2.004612445831299,
      "step": 3660
    },
    {
      "epoch": 0.6697691395200293,
      "grad_norm": 5.996919631958008,
      "learning_rate": 2.7247138299868646e-05,
      "logits/chosen": -2.51503324508667,
      "logits/rejected": -2.455247163772583,
      "logps/chosen": -138.50698852539062,
      "logps/rejected": -140.05270385742188,
      "loss": 0.5328,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.294323205947876,
      "rewards/margins": 0.9792982339859009,
      "rewards/rejected": -2.2736213207244873,
      "step": 3670
    },
    {
      "epoch": 0.6715941235514189,
      "grad_norm": 5.394887447357178,
      "learning_rate": 2.7097016325764686e-05,
      "logits/chosen": -2.6125504970550537,
      "logits/rejected": -2.3972995281219482,
      "logps/chosen": -140.21067810058594,
      "logps/rejected": -115.68537902832031,
      "loss": 0.5043,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.3748573064804077,
      "rewards/margins": 0.9828672409057617,
      "rewards/rejected": -2.357724666595459,
      "step": 3680
    },
    {
      "epoch": 0.6734191075828087,
      "grad_norm": 4.5735554695129395,
      "learning_rate": 2.6946894351660725e-05,
      "logits/chosen": -2.5813727378845215,
      "logits/rejected": -2.4524085521698,
      "logps/chosen": -135.0352020263672,
      "logps/rejected": -118.08943939208984,
      "loss": 0.5678,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.4442102909088135,
      "rewards/margins": 0.9362266659736633,
      "rewards/rejected": -2.380436897277832,
      "step": 3690
    },
    {
      "epoch": 0.6752440916141984,
      "grad_norm": 2.460890293121338,
      "learning_rate": 2.6796772377556765e-05,
      "logits/chosen": -2.5499510765075684,
      "logits/rejected": -2.401516914367676,
      "logps/chosen": -132.7089080810547,
      "logps/rejected": -136.2897186279297,
      "loss": 0.4268,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.22018301486969,
      "rewards/margins": 1.307852029800415,
      "rewards/rejected": -2.5280351638793945,
      "step": 3700
    },
    {
      "epoch": 0.677069075645588,
      "grad_norm": 5.336580276489258,
      "learning_rate": 2.664665040345281e-05,
      "logits/chosen": -2.554845094680786,
      "logits/rejected": -2.5215001106262207,
      "logps/chosen": -134.46414184570312,
      "logps/rejected": -147.76266479492188,
      "loss": 0.6366,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.6229890584945679,
      "rewards/margins": 0.7738783955574036,
      "rewards/rejected": -2.396867513656616,
      "step": 3710
    },
    {
      "epoch": 0.6788940596769778,
      "grad_norm": 4.9487152099609375,
      "learning_rate": 2.649652842934885e-05,
      "logits/chosen": -2.475497007369995,
      "logits/rejected": -2.336097240447998,
      "logps/chosen": -146.07748413085938,
      "logps/rejected": -137.77310180664062,
      "loss": 0.5741,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.715691328048706,
      "rewards/margins": 0.9732627868652344,
      "rewards/rejected": -2.6889543533325195,
      "step": 3720
    },
    {
      "epoch": 0.6807190437083676,
      "grad_norm": 4.456233501434326,
      "learning_rate": 2.634640645524489e-05,
      "logits/chosen": -2.5577011108398438,
      "logits/rejected": -2.4468586444854736,
      "logps/chosen": -144.38148498535156,
      "logps/rejected": -132.8509063720703,
      "loss": 0.5592,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.0636162757873535,
      "rewards/margins": 0.8170388340950012,
      "rewards/rejected": -2.88065505027771,
      "step": 3730
    },
    {
      "epoch": 0.6825440277397573,
      "grad_norm": 4.171649932861328,
      "learning_rate": 2.619628448114093e-05,
      "logits/chosen": -2.5155701637268066,
      "logits/rejected": -2.28833270072937,
      "logps/chosen": -151.1986846923828,
      "logps/rejected": -117.87953186035156,
      "loss": 0.469,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8930002450942993,
      "rewards/margins": 1.299202799797058,
      "rewards/rejected": -3.1922028064727783,
      "step": 3740
    },
    {
      "epoch": 0.684369011771147,
      "grad_norm": 4.563533306121826,
      "learning_rate": 2.6046162507036972e-05,
      "logits/chosen": -2.530594825744629,
      "logits/rejected": -2.456268548965454,
      "logps/chosen": -147.0224151611328,
      "logps/rejected": -148.85638427734375,
      "loss": 0.4671,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3458073139190674,
      "rewards/margins": 1.1494476795196533,
      "rewards/rejected": -2.4952549934387207,
      "step": 3750
    },
    {
      "epoch": 0.6861939958025367,
      "grad_norm": 7.67488431930542,
      "learning_rate": 2.5896040532933012e-05,
      "logits/chosen": -2.5882279872894287,
      "logits/rejected": -2.5187318325042725,
      "logps/chosen": -147.52981567382812,
      "logps/rejected": -151.9724578857422,
      "loss": 0.5701,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.3883004188537598,
      "rewards/margins": 0.8945873975753784,
      "rewards/rejected": -2.2828879356384277,
      "step": 3760
    },
    {
      "epoch": 0.6880189798339265,
      "grad_norm": 5.656114101409912,
      "learning_rate": 2.574591855882905e-05,
      "logits/chosen": -2.505025863647461,
      "logits/rejected": -2.360617160797119,
      "logps/chosen": -151.79702758789062,
      "logps/rejected": -128.60154724121094,
      "loss": 0.5056,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.091920256614685,
      "rewards/margins": 1.24288809299469,
      "rewards/rejected": -2.334808349609375,
      "step": 3770
    },
    {
      "epoch": 0.6898439638653162,
      "grad_norm": 4.322807312011719,
      "learning_rate": 2.559579658472509e-05,
      "logits/chosen": -2.587580442428589,
      "logits/rejected": -2.4191086292266846,
      "logps/chosen": -147.19134521484375,
      "logps/rejected": -123.85433197021484,
      "loss": 0.5451,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.7084150314331055,
      "rewards/margins": 1.0786539316177368,
      "rewards/rejected": -1.7870690822601318,
      "step": 3780
    },
    {
      "epoch": 0.6916689478967059,
      "grad_norm": 2.4474222660064697,
      "learning_rate": 2.5445674610621134e-05,
      "logits/chosen": -2.6549196243286133,
      "logits/rejected": -2.4798576831817627,
      "logps/chosen": -137.16123962402344,
      "logps/rejected": -122.99018859863281,
      "loss": 0.5469,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1958534717559814,
      "rewards/margins": 0.9228569865226746,
      "rewards/rejected": -2.1187102794647217,
      "step": 3790
    },
    {
      "epoch": 0.6934939319280956,
      "grad_norm": 5.1646504402160645,
      "learning_rate": 2.5295552636517173e-05,
      "logits/chosen": -2.4392952919006348,
      "logits/rejected": -2.3214480876922607,
      "logps/chosen": -134.748046875,
      "logps/rejected": -132.7917938232422,
      "loss": 0.6057,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.2557098865509033,
      "rewards/margins": 0.8040388822555542,
      "rewards/rejected": -2.059748888015747,
      "step": 3800
    },
    {
      "epoch": 0.6953189159594854,
      "grad_norm": 3.728984832763672,
      "learning_rate": 2.5145430662413213e-05,
      "logits/chosen": -2.476412773132324,
      "logits/rejected": -2.3490498065948486,
      "logps/chosen": -138.0062255859375,
      "logps/rejected": -128.25021362304688,
      "loss": 0.4875,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2760820388793945,
      "rewards/margins": 1.095315933227539,
      "rewards/rejected": -2.3713977336883545,
      "step": 3810
    },
    {
      "epoch": 0.6971438999908751,
      "grad_norm": 5.416796684265137,
      "learning_rate": 2.4995308688309252e-05,
      "logits/chosen": -2.5876004695892334,
      "logits/rejected": -2.447373628616333,
      "logps/chosen": -142.14633178710938,
      "logps/rejected": -127.31398010253906,
      "loss": 0.495,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8553757667541504,
      "rewards/margins": 1.1778481006622314,
      "rewards/rejected": -2.0332236289978027,
      "step": 3820
    },
    {
      "epoch": 0.6989688840222648,
      "grad_norm": 5.017892360687256,
      "learning_rate": 2.4845186714205295e-05,
      "logits/chosen": -2.563368082046509,
      "logits/rejected": -2.3872199058532715,
      "logps/chosen": -162.35433959960938,
      "logps/rejected": -123.54327392578125,
      "loss": 0.4758,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.391719937324524,
      "rewards/margins": 1.181862473487854,
      "rewards/rejected": -2.573582172393799,
      "step": 3830
    },
    {
      "epoch": 0.7007938680536545,
      "grad_norm": 5.781111717224121,
      "learning_rate": 2.4695064740101334e-05,
      "logits/chosen": -2.616971492767334,
      "logits/rejected": -2.4587464332580566,
      "logps/chosen": -141.74871826171875,
      "logps/rejected": -125.09465026855469,
      "loss": 0.618,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.1876685619354248,
      "rewards/margins": 0.9032012224197388,
      "rewards/rejected": -2.090869426727295,
      "step": 3840
    },
    {
      "epoch": 0.7026188520850443,
      "grad_norm": 8.62502384185791,
      "learning_rate": 2.4544942765997374e-05,
      "logits/chosen": -2.566495418548584,
      "logits/rejected": -2.5001630783081055,
      "logps/chosen": -132.12838745117188,
      "logps/rejected": -132.04881286621094,
      "loss": 0.5453,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.184138298034668,
      "rewards/margins": 1.0663349628448486,
      "rewards/rejected": -2.2504732608795166,
      "step": 3850
    },
    {
      "epoch": 0.704443836116434,
      "grad_norm": 5.696164608001709,
      "learning_rate": 2.4394820791893413e-05,
      "logits/chosen": -2.5763700008392334,
      "logits/rejected": -2.4055023193359375,
      "logps/chosen": -147.29464721679688,
      "logps/rejected": -128.92222595214844,
      "loss": 0.542,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7304250001907349,
      "rewards/margins": 1.2263720035552979,
      "rewards/rejected": -1.9567972421646118,
      "step": 3860
    },
    {
      "epoch": 0.7062688201478237,
      "grad_norm": 5.198910236358643,
      "learning_rate": 2.4244698817789453e-05,
      "logits/chosen": -2.5634469985961914,
      "logits/rejected": -2.511587142944336,
      "logps/chosen": -127.68162536621094,
      "logps/rejected": -128.66014099121094,
      "loss": 0.516,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.7906179428100586,
      "rewards/margins": 0.9935073852539062,
      "rewards/rejected": -1.7841253280639648,
      "step": 3870
    },
    {
      "epoch": 0.7080938041792134,
      "grad_norm": 6.417693138122559,
      "learning_rate": 2.40945768436855e-05,
      "logits/chosen": -2.6100618839263916,
      "logits/rejected": -2.4591760635375977,
      "logps/chosen": -143.4188995361328,
      "logps/rejected": -138.49728393554688,
      "loss": 0.6131,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.8593364953994751,
      "rewards/margins": 0.8374401926994324,
      "rewards/rejected": -1.6967767477035522,
      "step": 3880
    },
    {
      "epoch": 0.7099187882106032,
      "grad_norm": 6.532637119293213,
      "learning_rate": 2.394445486958154e-05,
      "logits/chosen": -2.5841429233551025,
      "logits/rejected": -2.563274383544922,
      "logps/chosen": -137.2495880126953,
      "logps/rejected": -138.76425170898438,
      "loss": 0.6952,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.9618843793869019,
      "rewards/margins": 0.5539848208427429,
      "rewards/rejected": -1.5158692598342896,
      "step": 3890
    },
    {
      "epoch": 0.7117437722419929,
      "grad_norm": 4.178299427032471,
      "learning_rate": 2.3794332895477578e-05,
      "logits/chosen": -2.650207996368408,
      "logits/rejected": -2.57236909866333,
      "logps/chosen": -139.34339904785156,
      "logps/rejected": -130.8326416015625,
      "loss": 0.6862,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.7037888765335083,
      "rewards/margins": 0.5988333821296692,
      "rewards/rejected": -1.3026223182678223,
      "step": 3900
    },
    {
      "epoch": 0.7135687562733826,
      "grad_norm": 4.37467098236084,
      "learning_rate": 2.3644210921373618e-05,
      "logits/chosen": -2.5723047256469727,
      "logits/rejected": -2.452176570892334,
      "logps/chosen": -131.8476104736328,
      "logps/rejected": -124.6981201171875,
      "loss": 0.4899,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6993955373764038,
      "rewards/margins": 0.8427358865737915,
      "rewards/rejected": -1.5421315431594849,
      "step": 3910
    },
    {
      "epoch": 0.7153937403047723,
      "grad_norm": 3.8508551120758057,
      "learning_rate": 2.349408894726966e-05,
      "logits/chosen": -2.615898847579956,
      "logits/rejected": -2.4818127155303955,
      "logps/chosen": -143.40597534179688,
      "logps/rejected": -129.81381225585938,
      "loss": 0.5754,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.834453284740448,
      "rewards/margins": 0.8454939723014832,
      "rewards/rejected": -1.6799472570419312,
      "step": 3920
    },
    {
      "epoch": 0.7172187243361621,
      "grad_norm": 4.497443199157715,
      "learning_rate": 2.33439669731657e-05,
      "logits/chosen": -2.5569915771484375,
      "logits/rejected": -2.4342880249023438,
      "logps/chosen": -124.55049133300781,
      "logps/rejected": -134.0072479248047,
      "loss": 0.6805,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.0402284860610962,
      "rewards/margins": 0.7580111622810364,
      "rewards/rejected": -1.7982397079467773,
      "step": 3930
    },
    {
      "epoch": 0.7190437083675518,
      "grad_norm": 3.629112720489502,
      "learning_rate": 2.319384499906174e-05,
      "logits/chosen": -2.681955099105835,
      "logits/rejected": -2.608011245727539,
      "logps/chosen": -116.20951843261719,
      "logps/rejected": -118.55726623535156,
      "loss": 0.6109,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.6835896968841553,
      "rewards/margins": 0.5277150273323059,
      "rewards/rejected": -1.211304783821106,
      "step": 3940
    },
    {
      "epoch": 0.7208686923989415,
      "grad_norm": 3.178678035736084,
      "learning_rate": 2.304372302495778e-05,
      "logits/chosen": -2.663651943206787,
      "logits/rejected": -2.4591214656829834,
      "logps/chosen": -149.90200805664062,
      "logps/rejected": -126.55720520019531,
      "loss": 0.4313,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.619404137134552,
      "rewards/margins": 1.0735982656478882,
      "rewards/rejected": -1.6930023431777954,
      "step": 3950
    },
    {
      "epoch": 0.7226936764303312,
      "grad_norm": 8.643986701965332,
      "learning_rate": 2.2893601050853822e-05,
      "logits/chosen": -2.6465065479278564,
      "logits/rejected": -2.5643205642700195,
      "logps/chosen": -140.83428955078125,
      "logps/rejected": -130.86428833007812,
      "loss": 0.5666,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.7011741995811462,
      "rewards/margins": 0.7538214921951294,
      "rewards/rejected": -1.4549956321716309,
      "step": 3960
    },
    {
      "epoch": 0.724518660461721,
      "grad_norm": 2.844062089920044,
      "learning_rate": 2.274347907674986e-05,
      "logits/chosen": -2.5524535179138184,
      "logits/rejected": -2.4708194732666016,
      "logps/chosen": -121.9993667602539,
      "logps/rejected": -124.44535827636719,
      "loss": 0.4776,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7355964183807373,
      "rewards/margins": 1.2368972301483154,
      "rewards/rejected": -1.9724934101104736,
      "step": 3970
    },
    {
      "epoch": 0.7263436444931107,
      "grad_norm": 2.573127269744873,
      "learning_rate": 2.25933571026459e-05,
      "logits/chosen": -2.5847835540771484,
      "logits/rejected": -2.4508564472198486,
      "logps/chosen": -139.0526580810547,
      "logps/rejected": -119.50772857666016,
      "loss": 0.5246,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1889147758483887,
      "rewards/margins": 1.0162627696990967,
      "rewards/rejected": -2.2051775455474854,
      "step": 3980
    },
    {
      "epoch": 0.7281686285245004,
      "grad_norm": 3.242601156234741,
      "learning_rate": 2.244323512854194e-05,
      "logits/chosen": -2.6589696407318115,
      "logits/rejected": -2.4394962787628174,
      "logps/chosen": -160.1846923828125,
      "logps/rejected": -133.1903533935547,
      "loss": 0.4492,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9126862287521362,
      "rewards/margins": 1.405378818511963,
      "rewards/rejected": -2.3180649280548096,
      "step": 3990
    },
    {
      "epoch": 0.7299936125558901,
      "grad_norm": 5.695135593414307,
      "learning_rate": 2.2293113154437983e-05,
      "logits/chosen": -2.66656494140625,
      "logits/rejected": -2.49094820022583,
      "logps/chosen": -144.29335021972656,
      "logps/rejected": -128.70797729492188,
      "loss": 0.5591,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1879370212554932,
      "rewards/margins": 1.048954963684082,
      "rewards/rejected": -2.2368922233581543,
      "step": 4000
    },
    {
      "epoch": 0.7318185965872799,
      "grad_norm": 4.9909892082214355,
      "learning_rate": 2.2142991180334023e-05,
      "logits/chosen": -2.5499215126037598,
      "logits/rejected": -2.3947763442993164,
      "logps/chosen": -133.463623046875,
      "logps/rejected": -118.7997817993164,
      "loss": 0.5289,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1175930500030518,
      "rewards/margins": 1.118696689605713,
      "rewards/rejected": -2.2362897396087646,
      "step": 4010
    },
    {
      "epoch": 0.7336435806186696,
      "grad_norm": 2.533064842224121,
      "learning_rate": 2.1992869206230062e-05,
      "logits/chosen": -2.5741424560546875,
      "logits/rejected": -2.4214999675750732,
      "logps/chosen": -140.79736328125,
      "logps/rejected": -132.90953063964844,
      "loss": 0.4585,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4392706155776978,
      "rewards/margins": 1.278688907623291,
      "rewards/rejected": -2.717959403991699,
      "step": 4020
    },
    {
      "epoch": 0.7354685646500593,
      "grad_norm": 3.645601272583008,
      "learning_rate": 2.18427472321261e-05,
      "logits/chosen": -2.57950496673584,
      "logits/rejected": -2.4665069580078125,
      "logps/chosen": -145.71002197265625,
      "logps/rejected": -142.26434326171875,
      "loss": 0.5302,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9437605738639832,
      "rewards/margins": 1.1962560415267944,
      "rewards/rejected": -2.140017032623291,
      "step": 4030
    },
    {
      "epoch": 0.737293548681449,
      "grad_norm": 3.0622379779815674,
      "learning_rate": 2.1692625258022148e-05,
      "logits/chosen": -2.63032603263855,
      "logits/rejected": -2.29721736907959,
      "logps/chosen": -161.23931884765625,
      "logps/rejected": -120.97935485839844,
      "loss": 0.3599,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.9483312368392944,
      "rewards/margins": 1.7112274169921875,
      "rewards/rejected": -2.6595587730407715,
      "step": 4040
    },
    {
      "epoch": 0.7391185327128388,
      "grad_norm": 5.0863776206970215,
      "learning_rate": 2.1542503283918187e-05,
      "logits/chosen": -2.4654552936553955,
      "logits/rejected": -2.358950138092041,
      "logps/chosen": -141.77529907226562,
      "logps/rejected": -126.95765686035156,
      "loss": 0.5509,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.112545132637024,
      "rewards/margins": 1.4440250396728516,
      "rewards/rejected": -2.556570053100586,
      "step": 4050
    },
    {
      "epoch": 0.7409435167442285,
      "grad_norm": 6.205599308013916,
      "learning_rate": 2.1392381309814227e-05,
      "logits/chosen": -2.6355791091918945,
      "logits/rejected": -2.581258535385132,
      "logps/chosen": -134.92857360839844,
      "logps/rejected": -138.891845703125,
      "loss": 0.6095,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0891212224960327,
      "rewards/margins": 1.0660440921783447,
      "rewards/rejected": -2.155165433883667,
      "step": 4060
    },
    {
      "epoch": 0.7427685007756182,
      "grad_norm": 4.710812091827393,
      "learning_rate": 2.1242259335710266e-05,
      "logits/chosen": -2.5711941719055176,
      "logits/rejected": -2.5282492637634277,
      "logps/chosen": -135.49942016601562,
      "logps/rejected": -133.55075073242188,
      "loss": 0.6254,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.1131058931350708,
      "rewards/margins": 1.1278960704803467,
      "rewards/rejected": -2.241001844406128,
      "step": 4070
    },
    {
      "epoch": 0.7445934848070079,
      "grad_norm": 7.513300895690918,
      "learning_rate": 2.109213736160631e-05,
      "logits/chosen": -2.5865275859832764,
      "logits/rejected": -2.511052370071411,
      "logps/chosen": -141.7535858154297,
      "logps/rejected": -133.1395263671875,
      "loss": 0.4958,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.06405508518219,
      "rewards/margins": 1.282743215560913,
      "rewards/rejected": -2.3467981815338135,
      "step": 4080
    },
    {
      "epoch": 0.7464184688383977,
      "grad_norm": 7.579240798950195,
      "learning_rate": 2.094201538750235e-05,
      "logits/chosen": -2.4757046699523926,
      "logits/rejected": -2.417184591293335,
      "logps/chosen": -145.7719268798828,
      "logps/rejected": -145.97286987304688,
      "loss": 0.6236,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.457506775856018,
      "rewards/margins": 0.8247496485710144,
      "rewards/rejected": -2.2822563648223877,
      "step": 4090
    },
    {
      "epoch": 0.7482434528697874,
      "grad_norm": 3.2677698135375977,
      "learning_rate": 2.0791893413398388e-05,
      "logits/chosen": -2.721437692642212,
      "logits/rejected": -2.5886168479919434,
      "logps/chosen": -135.94554138183594,
      "logps/rejected": -132.45310974121094,
      "loss": 0.5671,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.1011979579925537,
      "rewards/margins": 1.1815286874771118,
      "rewards/rejected": -2.282726764678955,
      "step": 4100
    },
    {
      "epoch": 0.7500684369011771,
      "grad_norm": 5.800891399383545,
      "learning_rate": 2.0641771439294428e-05,
      "logits/chosen": -2.551231622695923,
      "logits/rejected": -2.4613916873931885,
      "logps/chosen": -122.47331237792969,
      "logps/rejected": -127.2016372680664,
      "loss": 0.5843,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2201414108276367,
      "rewards/margins": 0.7222474813461304,
      "rewards/rejected": -1.942388892173767,
      "step": 4110
    },
    {
      "epoch": 0.7518934209325668,
      "grad_norm": 5.094048023223877,
      "learning_rate": 2.049164946519047e-05,
      "logits/chosen": -2.6071293354034424,
      "logits/rejected": -2.4084742069244385,
      "logps/chosen": -157.11683654785156,
      "logps/rejected": -130.37794494628906,
      "loss": 0.4761,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9534735679626465,
      "rewards/margins": 1.320249080657959,
      "rewards/rejected": -2.2737224102020264,
      "step": 4120
    },
    {
      "epoch": 0.7537184049639566,
      "grad_norm": 4.696273326873779,
      "learning_rate": 2.034152749108651e-05,
      "logits/chosen": -2.616518020629883,
      "logits/rejected": -2.5346267223358154,
      "logps/chosen": -143.62351989746094,
      "logps/rejected": -139.75857543945312,
      "loss": 0.6411,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.8084133267402649,
      "rewards/margins": 0.7971683740615845,
      "rewards/rejected": -1.6055816411972046,
      "step": 4130
    },
    {
      "epoch": 0.7555433889953463,
      "grad_norm": 4.204150199890137,
      "learning_rate": 2.019140551698255e-05,
      "logits/chosen": -2.3668293952941895,
      "logits/rejected": -2.258528232574463,
      "logps/chosen": -147.61581420898438,
      "logps/rejected": -120.86235046386719,
      "loss": 0.5992,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.110848069190979,
      "rewards/margins": 0.9713259935379028,
      "rewards/rejected": -2.0821738243103027,
      "step": 4140
    },
    {
      "epoch": 0.757368373026736,
      "grad_norm": 4.263387203216553,
      "learning_rate": 2.004128354287859e-05,
      "logits/chosen": -2.527700901031494,
      "logits/rejected": -2.466172218322754,
      "logps/chosen": -121.9908218383789,
      "logps/rejected": -121.2601089477539,
      "loss": 0.556,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.8891972303390503,
      "rewards/margins": 0.7520764470100403,
      "rewards/rejected": -1.6412737369537354,
      "step": 4150
    },
    {
      "epoch": 0.7591933570581257,
      "grad_norm": 4.657529354095459,
      "learning_rate": 1.9891161568774632e-05,
      "logits/chosen": -2.5788321495056152,
      "logits/rejected": -2.5104026794433594,
      "logps/chosen": -135.10499572753906,
      "logps/rejected": -137.5055694580078,
      "loss": 0.6059,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.7945681214332581,
      "rewards/margins": 0.8929333686828613,
      "rewards/rejected": -1.6875016689300537,
      "step": 4160
    },
    {
      "epoch": 0.7610183410895155,
      "grad_norm": 3.8825020790100098,
      "learning_rate": 1.974103959467067e-05,
      "logits/chosen": -2.5464041233062744,
      "logits/rejected": -2.3988089561462402,
      "logps/chosen": -147.86376953125,
      "logps/rejected": -126.7596664428711,
      "loss": 0.6192,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.7639504671096802,
      "rewards/margins": 0.807045578956604,
      "rewards/rejected": -1.5709959268569946,
      "step": 4170
    },
    {
      "epoch": 0.7628433251209052,
      "grad_norm": 4.612525939941406,
      "learning_rate": 1.959091762056671e-05,
      "logits/chosen": -2.6158287525177,
      "logits/rejected": -2.5365707874298096,
      "logps/chosen": -134.7832794189453,
      "logps/rejected": -132.4285888671875,
      "loss": 0.4705,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.7127453088760376,
      "rewards/margins": 1.0696628093719482,
      "rewards/rejected": -1.7824081182479858,
      "step": 4180
    },
    {
      "epoch": 0.7646683091522949,
      "grad_norm": 3.917694330215454,
      "learning_rate": 1.9440795646462754e-05,
      "logits/chosen": -2.491307258605957,
      "logits/rejected": -2.4172770977020264,
      "logps/chosen": -139.59619140625,
      "logps/rejected": -140.17239379882812,
      "loss": 0.629,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.9639360308647156,
      "rewards/margins": 0.6499789953231812,
      "rewards/rejected": -1.6139148473739624,
      "step": 4190
    },
    {
      "epoch": 0.7664932931836846,
      "grad_norm": 31.93751335144043,
      "learning_rate": 1.9290673672358793e-05,
      "logits/chosen": -2.548229217529297,
      "logits/rejected": -2.3999438285827637,
      "logps/chosen": -133.4697265625,
      "logps/rejected": -130.35360717773438,
      "loss": 0.542,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.43299707770347595,
      "rewards/margins": 1.099267840385437,
      "rewards/rejected": -1.5322649478912354,
      "step": 4200
    },
    {
      "epoch": 0.7683182772150744,
      "grad_norm": 7.417355537414551,
      "learning_rate": 1.9140551698254836e-05,
      "logits/chosen": -2.630070924758911,
      "logits/rejected": -2.555903911590576,
      "logps/chosen": -127.85096740722656,
      "logps/rejected": -117.9269027709961,
      "loss": 0.6365,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.8318708539009094,
      "rewards/margins": 0.7349172830581665,
      "rewards/rejected": -1.5667880773544312,
      "step": 4210
    },
    {
      "epoch": 0.770143261246464,
      "grad_norm": 4.5373406410217285,
      "learning_rate": 1.8990429724150875e-05,
      "logits/chosen": -2.61830472946167,
      "logits/rejected": -2.4162638187408447,
      "logps/chosen": -139.970947265625,
      "logps/rejected": -117.76237487792969,
      "loss": 0.5403,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6431517601013184,
      "rewards/margins": 1.0158270597457886,
      "rewards/rejected": -1.658978819847107,
      "step": 4220
    },
    {
      "epoch": 0.7719682452778538,
      "grad_norm": 4.347890853881836,
      "learning_rate": 1.8840307750046915e-05,
      "logits/chosen": -2.5468497276306152,
      "logits/rejected": -2.4536170959472656,
      "logps/chosen": -130.05799865722656,
      "logps/rejected": -127.2353744506836,
      "loss": 0.552,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.9641860127449036,
      "rewards/margins": 0.8924468159675598,
      "rewards/rejected": -1.8566325902938843,
      "step": 4230
    },
    {
      "epoch": 0.7737932293092435,
      "grad_norm": 6.150737285614014,
      "learning_rate": 1.8690185775942954e-05,
      "logits/chosen": -2.5715420246124268,
      "logits/rejected": -2.4493720531463623,
      "logps/chosen": -144.2794189453125,
      "logps/rejected": -132.77536010742188,
      "loss": 0.5015,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9554667472839355,
      "rewards/margins": 1.098581075668335,
      "rewards/rejected": -2.0540475845336914,
      "step": 4240
    },
    {
      "epoch": 0.7756182133406333,
      "grad_norm": 4.311827659606934,
      "learning_rate": 1.8540063801838997e-05,
      "logits/chosen": -2.573970317840576,
      "logits/rejected": -2.5067636966705322,
      "logps/chosen": -135.5526580810547,
      "logps/rejected": -131.01622009277344,
      "loss": 0.5576,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.9494048357009888,
      "rewards/margins": 1.018259882926941,
      "rewards/rejected": -1.9676649570465088,
      "step": 4250
    },
    {
      "epoch": 0.7774431973720229,
      "grad_norm": 5.190637588500977,
      "learning_rate": 1.8389941827735037e-05,
      "logits/chosen": -2.5145273208618164,
      "logits/rejected": -2.4181928634643555,
      "logps/chosen": -127.94450378417969,
      "logps/rejected": -131.79586791992188,
      "loss": 0.5034,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.7223103046417236,
      "rewards/margins": 1.0900498628616333,
      "rewards/rejected": -1.812360167503357,
      "step": 4260
    },
    {
      "epoch": 0.7792681814034127,
      "grad_norm": 3.021538734436035,
      "learning_rate": 1.8239819853631076e-05,
      "logits/chosen": -2.5633111000061035,
      "logits/rejected": -2.4628958702087402,
      "logps/chosen": -140.19906616210938,
      "logps/rejected": -133.02809143066406,
      "loss": 0.5349,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7637661695480347,
      "rewards/margins": 0.9570969343185425,
      "rewards/rejected": -1.7208629846572876,
      "step": 4270
    },
    {
      "epoch": 0.7810931654348024,
      "grad_norm": 3.3512096405029297,
      "learning_rate": 1.8089697879527116e-05,
      "logits/chosen": -2.5247886180877686,
      "logits/rejected": -2.420436382293701,
      "logps/chosen": -125.41432189941406,
      "logps/rejected": -122.18342590332031,
      "loss": 0.5998,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0881593227386475,
      "rewards/margins": 0.9428322911262512,
      "rewards/rejected": -2.030991792678833,
      "step": 4280
    },
    {
      "epoch": 0.7829181494661922,
      "grad_norm": 5.565601348876953,
      "learning_rate": 1.793957590542316e-05,
      "logits/chosen": -2.4957313537597656,
      "logits/rejected": -2.356196165084839,
      "logps/chosen": -142.51243591308594,
      "logps/rejected": -129.06634521484375,
      "loss": 0.5977,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.7413848042488098,
      "rewards/margins": 0.8069046139717102,
      "rewards/rejected": -1.5482892990112305,
      "step": 4290
    },
    {
      "epoch": 0.7847431334975818,
      "grad_norm": 4.744284152984619,
      "learning_rate": 1.7789453931319198e-05,
      "logits/chosen": -2.5664615631103516,
      "logits/rejected": -2.4502437114715576,
      "logps/chosen": -129.88327026367188,
      "logps/rejected": -121.160400390625,
      "loss": 0.5855,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.8592756986618042,
      "rewards/margins": 0.8524110913276672,
      "rewards/rejected": -1.7116868495941162,
      "step": 4300
    },
    {
      "epoch": 0.7865681175289716,
      "grad_norm": 4.087545394897461,
      "learning_rate": 1.7639331957215237e-05,
      "logits/chosen": -2.6639630794525146,
      "logits/rejected": -2.481904983520508,
      "logps/chosen": -131.24441528320312,
      "logps/rejected": -126.15824127197266,
      "loss": 0.4424,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.5663541555404663,
      "rewards/margins": 1.3571875095367432,
      "rewards/rejected": -1.9235414266586304,
      "step": 4310
    },
    {
      "epoch": 0.7883931015603614,
      "grad_norm": 4.898564338684082,
      "learning_rate": 1.748920998311128e-05,
      "logits/chosen": -2.5757689476013184,
      "logits/rejected": -2.396000862121582,
      "logps/chosen": -147.24595642089844,
      "logps/rejected": -125.66035461425781,
      "loss": 0.4818,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6959190964698792,
      "rewards/margins": 1.0883711576461792,
      "rewards/rejected": -1.7842903137207031,
      "step": 4320
    },
    {
      "epoch": 0.7902180855917511,
      "grad_norm": 5.593438148498535,
      "learning_rate": 1.733908800900732e-05,
      "logits/chosen": -2.630880832672119,
      "logits/rejected": -2.543462038040161,
      "logps/chosen": -131.59521484375,
      "logps/rejected": -121.68087005615234,
      "loss": 0.5412,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.988128662109375,
      "rewards/margins": 0.9456683397293091,
      "rewards/rejected": -1.9337971210479736,
      "step": 4330
    },
    {
      "epoch": 0.7920430696231407,
      "grad_norm": 4.2800092697143555,
      "learning_rate": 1.718896603490336e-05,
      "logits/chosen": -2.6270692348480225,
      "logits/rejected": -2.5359737873077393,
      "logps/chosen": -134.74832153320312,
      "logps/rejected": -119.31205749511719,
      "loss": 0.5135,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.0205528736114502,
      "rewards/margins": 1.1313724517822266,
      "rewards/rejected": -2.1519253253936768,
      "step": 4340
    },
    {
      "epoch": 0.7938680536545305,
      "grad_norm": 3.7517833709716797,
      "learning_rate": 1.70388440607994e-05,
      "logits/chosen": -2.6781017780303955,
      "logits/rejected": -2.452059507369995,
      "logps/chosen": -169.77406311035156,
      "logps/rejected": -128.14810180664062,
      "loss": 0.5144,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.0125614404678345,
      "rewards/margins": 1.1191953420639038,
      "rewards/rejected": -2.131756544113159,
      "step": 4350
    },
    {
      "epoch": 0.7956930376859203,
      "grad_norm": 4.392749786376953,
      "learning_rate": 1.688872208669544e-05,
      "logits/chosen": -2.707035779953003,
      "logits/rejected": -2.5450804233551025,
      "logps/chosen": -159.45254516601562,
      "logps/rejected": -145.70347595214844,
      "loss": 0.488,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.65638667345047,
      "rewards/margins": 1.2098057270050049,
      "rewards/rejected": -1.8661922216415405,
      "step": 4360
    },
    {
      "epoch": 0.79751802171731,
      "grad_norm": 5.689526557922363,
      "learning_rate": 1.675361231000188e-05,
      "logits/chosen": -2.736873149871826,
      "logits/rejected": -2.502531051635742,
      "logps/chosen": -145.1500244140625,
      "logps/rejected": -116.75142669677734,
      "loss": 0.4901,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8490885496139526,
      "rewards/margins": 1.2404606342315674,
      "rewards/rejected": -2.0895488262176514,
      "step": 4370
    },
    {
      "epoch": 0.7993430057486997,
      "grad_norm": 3.6003103256225586,
      "learning_rate": 1.660349033589792e-05,
      "logits/chosen": -2.6473636627197266,
      "logits/rejected": -2.40067982673645,
      "logps/chosen": -145.43878173828125,
      "logps/rejected": -119.15657043457031,
      "loss": 0.3629,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.8086656332015991,
      "rewards/margins": 1.6801761388778687,
      "rewards/rejected": -2.488842010498047,
      "step": 4380
    },
    {
      "epoch": 0.8011679897800894,
      "grad_norm": 4.147243499755859,
      "learning_rate": 1.645336836179396e-05,
      "logits/chosen": -2.727867841720581,
      "logits/rejected": -2.566368579864502,
      "logps/chosen": -138.1863250732422,
      "logps/rejected": -132.859375,
      "loss": 0.5793,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0340226888656616,
      "rewards/margins": 1.1704671382904053,
      "rewards/rejected": -2.2044897079467773,
      "step": 4390
    },
    {
      "epoch": 0.8029929738114792,
      "grad_norm": 6.208108901977539,
      "learning_rate": 1.6303246387689998e-05,
      "logits/chosen": -2.6401526927948,
      "logits/rejected": -2.4778313636779785,
      "logps/chosen": -144.44198608398438,
      "logps/rejected": -138.0843048095703,
      "loss": 0.3952,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.7762380838394165,
      "rewards/margins": 1.6385173797607422,
      "rewards/rejected": -2.414755344390869,
      "step": 4400
    },
    {
      "epoch": 0.8048179578428689,
      "grad_norm": 3.5763018131256104,
      "learning_rate": 1.615312441358604e-05,
      "logits/chosen": -2.621309518814087,
      "logits/rejected": -2.554971933364868,
      "logps/chosen": -147.99465942382812,
      "logps/rejected": -136.62393188476562,
      "loss": 0.6683,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.0044609308242798,
      "rewards/margins": 0.9657575488090515,
      "rewards/rejected": -1.9702184200286865,
      "step": 4410
    },
    {
      "epoch": 0.8066429418742586,
      "grad_norm": 2.511894702911377,
      "learning_rate": 1.600300243948208e-05,
      "logits/chosen": -2.671643018722534,
      "logits/rejected": -2.6099085807800293,
      "logps/chosen": -124.25728607177734,
      "logps/rejected": -126.8459243774414,
      "loss": 0.5149,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.6704643368721008,
      "rewards/margins": 1.3214949369430542,
      "rewards/rejected": -1.9919589757919312,
      "step": 4420
    },
    {
      "epoch": 0.8084679259056483,
      "grad_norm": 5.83834981918335,
      "learning_rate": 1.5852880465378123e-05,
      "logits/chosen": -2.681774854660034,
      "logits/rejected": -2.5245070457458496,
      "logps/chosen": -146.25901794433594,
      "logps/rejected": -139.94346618652344,
      "loss": 0.4564,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8509647250175476,
      "rewards/margins": 1.4326798915863037,
      "rewards/rejected": -2.283644676208496,
      "step": 4430
    },
    {
      "epoch": 0.8102929099370381,
      "grad_norm": 5.7122297286987305,
      "learning_rate": 1.5702758491274163e-05,
      "logits/chosen": -2.645357608795166,
      "logits/rejected": -2.5406973361968994,
      "logps/chosen": -141.37716674804688,
      "logps/rejected": -134.4551544189453,
      "loss": 0.4657,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8669732809066772,
      "rewards/margins": 1.1801921129226685,
      "rewards/rejected": -2.0471653938293457,
      "step": 4440
    },
    {
      "epoch": 0.8121178939684278,
      "grad_norm": 3.6511471271514893,
      "learning_rate": 1.5552636517170202e-05,
      "logits/chosen": -2.5998692512512207,
      "logits/rejected": -2.4250497817993164,
      "logps/chosen": -147.0718231201172,
      "logps/rejected": -139.9832305908203,
      "loss": 0.5524,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.7730551362037659,
      "rewards/margins": 1.2709314823150635,
      "rewards/rejected": -2.0439863204956055,
      "step": 4450
    },
    {
      "epoch": 0.8139428779998175,
      "grad_norm": 4.51198148727417,
      "learning_rate": 1.540251454306624e-05,
      "logits/chosen": -2.567600965499878,
      "logits/rejected": -2.547504186630249,
      "logps/chosen": -134.4320526123047,
      "logps/rejected": -151.72781372070312,
      "loss": 0.6213,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.928483784198761,
      "rewards/margins": 0.9741033315658569,
      "rewards/rejected": -1.9025871753692627,
      "step": 4460
    },
    {
      "epoch": 0.8157678620312072,
      "grad_norm": 6.964414119720459,
      "learning_rate": 1.5252392568962283e-05,
      "logits/chosen": -2.5656423568725586,
      "logits/rejected": -2.480013132095337,
      "logps/chosen": -137.3496551513672,
      "logps/rejected": -130.91136169433594,
      "loss": 0.5585,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.9890225529670715,
      "rewards/margins": 1.0255959033966064,
      "rewards/rejected": -2.0146186351776123,
      "step": 4470
    },
    {
      "epoch": 0.817592846062597,
      "grad_norm": 4.6240949630737305,
      "learning_rate": 1.5102270594858324e-05,
      "logits/chosen": -2.6652731895446777,
      "logits/rejected": -2.6181890964508057,
      "logps/chosen": -128.96661376953125,
      "logps/rejected": -137.38613891601562,
      "loss": 0.557,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8149639368057251,
      "rewards/margins": 1.135066270828247,
      "rewards/rejected": -1.9500305652618408,
      "step": 4480
    },
    {
      "epoch": 0.8194178300939867,
      "grad_norm": 7.027332305908203,
      "learning_rate": 1.4952148620754363e-05,
      "logits/chosen": -2.631955623626709,
      "logits/rejected": -2.4792299270629883,
      "logps/chosen": -124.8575439453125,
      "logps/rejected": -124.2325210571289,
      "loss": 0.4745,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.6894478797912598,
      "rewards/margins": 1.2146084308624268,
      "rewards/rejected": -1.9040563106536865,
      "step": 4490
    },
    {
      "epoch": 0.8212428141253764,
      "grad_norm": 6.061670780181885,
      "learning_rate": 1.4802026646650405e-05,
      "logits/chosen": -2.751041889190674,
      "logits/rejected": -2.592223882675171,
      "logps/chosen": -155.5038604736328,
      "logps/rejected": -140.69654846191406,
      "loss": 0.4782,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0125133991241455,
      "rewards/margins": 1.556882619857788,
      "rewards/rejected": -2.5693957805633545,
      "step": 4500
    },
    {
      "epoch": 0.8230677981567661,
      "grad_norm": 6.637200832366943,
      "learning_rate": 1.4651904672546444e-05,
      "logits/chosen": -2.6043620109558105,
      "logits/rejected": -2.591679334640503,
      "logps/chosen": -131.7303924560547,
      "logps/rejected": -139.7667694091797,
      "loss": 0.5576,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.006635308265686,
      "rewards/margins": 1.070211410522461,
      "rewards/rejected": -2.0768465995788574,
      "step": 4510
    },
    {
      "epoch": 0.8248927821881559,
      "grad_norm": 4.860266208648682,
      "learning_rate": 1.4501782698442485e-05,
      "logits/chosen": -2.584101676940918,
      "logits/rejected": -2.4424521923065186,
      "logps/chosen": -131.1997528076172,
      "logps/rejected": -124.32582092285156,
      "loss": 0.3813,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8664388656616211,
      "rewards/margins": 1.7106142044067383,
      "rewards/rejected": -2.5770530700683594,
      "step": 4520
    },
    {
      "epoch": 0.8267177662195456,
      "grad_norm": 6.529538631439209,
      "learning_rate": 1.4351660724338525e-05,
      "logits/chosen": -2.4827821254730225,
      "logits/rejected": -2.486466884613037,
      "logps/chosen": -127.0303726196289,
      "logps/rejected": -148.64564514160156,
      "loss": 0.5063,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2406634092330933,
      "rewards/margins": 1.2288014888763428,
      "rewards/rejected": -2.4694650173187256,
      "step": 4530
    },
    {
      "epoch": 0.8285427502509353,
      "grad_norm": 7.731001377105713,
      "learning_rate": 1.4201538750234568e-05,
      "logits/chosen": -2.52168345451355,
      "logits/rejected": -2.4387118816375732,
      "logps/chosen": -126.10871887207031,
      "logps/rejected": -120.8735122680664,
      "loss": 0.5816,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.435049057006836,
      "rewards/margins": 0.8028289079666138,
      "rewards/rejected": -2.237877607345581,
      "step": 4540
    },
    {
      "epoch": 0.830367734282325,
      "grad_norm": 2.4371631145477295,
      "learning_rate": 1.4051416776130607e-05,
      "logits/chosen": -2.539170503616333,
      "logits/rejected": -2.3915412425994873,
      "logps/chosen": -124.74952697753906,
      "logps/rejected": -112.44270324707031,
      "loss": 0.4925,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1135811805725098,
      "rewards/margins": 1.4494191408157349,
      "rewards/rejected": -2.562999963760376,
      "step": 4550
    },
    {
      "epoch": 0.8321927183137148,
      "grad_norm": 7.350841522216797,
      "learning_rate": 1.3901294802026648e-05,
      "logits/chosen": -2.6227524280548096,
      "logits/rejected": -2.4063732624053955,
      "logps/chosen": -148.82630920410156,
      "logps/rejected": -124.71409606933594,
      "loss": 0.3814,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8677014112472534,
      "rewards/margins": 1.452867031097412,
      "rewards/rejected": -2.320568323135376,
      "step": 4560
    },
    {
      "epoch": 0.8340177023451045,
      "grad_norm": 4.430558681488037,
      "learning_rate": 1.3751172827922688e-05,
      "logits/chosen": -2.6190474033355713,
      "logits/rejected": -2.4187843799591064,
      "logps/chosen": -143.93797302246094,
      "logps/rejected": -131.2327423095703,
      "loss": 0.5112,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1473195552825928,
      "rewards/margins": 1.1864051818847656,
      "rewards/rejected": -2.3337249755859375,
      "step": 4570
    },
    {
      "epoch": 0.8358426863764942,
      "grad_norm": 3.7518482208251953,
      "learning_rate": 1.3601050853818729e-05,
      "logits/chosen": -2.7194507122039795,
      "logits/rejected": -2.5643532276153564,
      "logps/chosen": -152.2590789794922,
      "logps/rejected": -141.29507446289062,
      "loss": 0.5588,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.015903353691101,
      "rewards/margins": 1.0253350734710693,
      "rewards/rejected": -2.04123854637146,
      "step": 4580
    },
    {
      "epoch": 0.8376676704078839,
      "grad_norm": 4.620767593383789,
      "learning_rate": 1.3450928879714768e-05,
      "logits/chosen": -2.5155210494995117,
      "logits/rejected": -2.507302761077881,
      "logps/chosen": -125.01890563964844,
      "logps/rejected": -133.11773681640625,
      "loss": 0.5583,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0685614347457886,
      "rewards/margins": 1.176729440689087,
      "rewards/rejected": -2.245290756225586,
      "step": 4590
    },
    {
      "epoch": 0.8394926544392737,
      "grad_norm": 8.087509155273438,
      "learning_rate": 1.330080690561081e-05,
      "logits/chosen": -2.608937978744507,
      "logits/rejected": -2.423621416091919,
      "logps/chosen": -142.28964233398438,
      "logps/rejected": -132.1903839111328,
      "loss": 0.4911,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2916162014007568,
      "rewards/margins": 1.172029733657837,
      "rewards/rejected": -2.463646411895752,
      "step": 4600
    },
    {
      "epoch": 0.8413176384706634,
      "grad_norm": 8.170966148376465,
      "learning_rate": 1.3150684931506849e-05,
      "logits/chosen": -2.6610045433044434,
      "logits/rejected": -2.43630313873291,
      "logps/chosen": -150.4405517578125,
      "logps/rejected": -111.57115173339844,
      "loss": 0.6613,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.372929334640503,
      "rewards/margins": 0.9460976719856262,
      "rewards/rejected": -2.3190271854400635,
      "step": 4610
    },
    {
      "epoch": 0.8431426225020531,
      "grad_norm": 3.7346200942993164,
      "learning_rate": 1.3000562957402892e-05,
      "logits/chosen": -2.580687999725342,
      "logits/rejected": -2.4236092567443848,
      "logps/chosen": -123.71485900878906,
      "logps/rejected": -115.19698333740234,
      "loss": 0.4775,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.3417991399765015,
      "rewards/margins": 1.157593011856079,
      "rewards/rejected": -2.499392032623291,
      "step": 4620
    },
    {
      "epoch": 0.8449676065334428,
      "grad_norm": 3.2388226985931396,
      "learning_rate": 1.2850440983298931e-05,
      "logits/chosen": -2.6134819984436035,
      "logits/rejected": -2.5285563468933105,
      "logps/chosen": -127.7432861328125,
      "logps/rejected": -125.25181579589844,
      "loss": 0.5016,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0746190547943115,
      "rewards/margins": 1.428572654724121,
      "rewards/rejected": -2.5031917095184326,
      "step": 4630
    },
    {
      "epoch": 0.8467925905648326,
      "grad_norm": 6.1014485359191895,
      "learning_rate": 1.2700319009194973e-05,
      "logits/chosen": -2.6350815296173096,
      "logits/rejected": -2.5669498443603516,
      "logps/chosen": -136.29739379882812,
      "logps/rejected": -136.6406707763672,
      "loss": 0.5033,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1206414699554443,
      "rewards/margins": 1.1637287139892578,
      "rewards/rejected": -2.284370183944702,
      "step": 4640
    },
    {
      "epoch": 0.8486175745962223,
      "grad_norm": 5.328658103942871,
      "learning_rate": 1.2550197035091012e-05,
      "logits/chosen": -2.691270589828491,
      "logits/rejected": -2.558957099914551,
      "logps/chosen": -149.0586395263672,
      "logps/rejected": -142.4573516845703,
      "loss": 0.5415,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.9399611353874207,
      "rewards/margins": 1.1704589128494263,
      "rewards/rejected": -2.110419988632202,
      "step": 4650
    },
    {
      "epoch": 0.850442558627612,
      "grad_norm": 2.942394733428955,
      "learning_rate": 1.2400075060987053e-05,
      "logits/chosen": -2.7128570079803467,
      "logits/rejected": -2.6595346927642822,
      "logps/chosen": -148.818603515625,
      "logps/rejected": -151.12777709960938,
      "loss": 0.4371,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.821910560131073,
      "rewards/margins": 1.153132438659668,
      "rewards/rejected": -1.9750430583953857,
      "step": 4660
    },
    {
      "epoch": 0.8522675426590017,
      "grad_norm": 6.871669292449951,
      "learning_rate": 1.2249953086883093e-05,
      "logits/chosen": -2.689591884613037,
      "logits/rejected": -2.55169677734375,
      "logps/chosen": -124.20039367675781,
      "logps/rejected": -124.70542907714844,
      "loss": 0.396,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0451289415359497,
      "rewards/margins": 1.6498401165008545,
      "rewards/rejected": -2.6949691772460938,
      "step": 4670
    },
    {
      "epoch": 0.8540925266903915,
      "grad_norm": 4.701475143432617,
      "learning_rate": 1.2099831112779134e-05,
      "logits/chosen": -2.533360719680786,
      "logits/rejected": -2.5158402919769287,
      "logps/chosen": -126.46358489990234,
      "logps/rejected": -142.0872802734375,
      "loss": 0.7152,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -1.258375883102417,
      "rewards/margins": 0.9125324487686157,
      "rewards/rejected": -2.1709084510803223,
      "step": 4680
    },
    {
      "epoch": 0.8559175107217812,
      "grad_norm": 8.743557929992676,
      "learning_rate": 1.1949709138675173e-05,
      "logits/chosen": -2.637845039367676,
      "logits/rejected": -2.572540521621704,
      "logps/chosen": -132.65402221679688,
      "logps/rejected": -144.52587890625,
      "loss": 0.6255,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.4335508346557617,
      "rewards/margins": 0.751557469367981,
      "rewards/rejected": -2.1851084232330322,
      "step": 4690
    },
    {
      "epoch": 0.8577424947531709,
      "grad_norm": 3.9495019912719727,
      "learning_rate": 1.1799587164571216e-05,
      "logits/chosen": -2.6273984909057617,
      "logits/rejected": -2.449730396270752,
      "logps/chosen": -131.6776885986328,
      "logps/rejected": -126.08094787597656,
      "loss": 0.4398,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.889575183391571,
      "rewards/margins": 1.5227640867233276,
      "rewards/rejected": -2.412339448928833,
      "step": 4700
    },
    {
      "epoch": 0.8595674787845606,
      "grad_norm": 3.831259250640869,
      "learning_rate": 1.1649465190467256e-05,
      "logits/chosen": -2.5117104053497314,
      "logits/rejected": -2.413013219833374,
      "logps/chosen": -126.0168228149414,
      "logps/rejected": -119.9179916381836,
      "loss": 0.4825,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9978426098823547,
      "rewards/margins": 1.3422966003417969,
      "rewards/rejected": -2.340139150619507,
      "step": 4710
    },
    {
      "epoch": 0.8613924628159504,
      "grad_norm": 7.806338787078857,
      "learning_rate": 1.1499343216363297e-05,
      "logits/chosen": -2.648317337036133,
      "logits/rejected": -2.5115246772766113,
      "logps/chosen": -128.67579650878906,
      "logps/rejected": -120.37535095214844,
      "loss": 0.4554,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.17902410030365,
      "rewards/margins": 1.4460644721984863,
      "rewards/rejected": -2.6250882148742676,
      "step": 4720
    },
    {
      "epoch": 0.86321744684734,
      "grad_norm": 4.109682083129883,
      "learning_rate": 1.1349221242259336e-05,
      "logits/chosen": -2.6173815727233887,
      "logits/rejected": -2.5331053733825684,
      "logps/chosen": -118.09449768066406,
      "logps/rejected": -123.1769027709961,
      "loss": 0.6018,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.015875220298767,
      "rewards/margins": 0.8854528665542603,
      "rewards/rejected": -1.9013280868530273,
      "step": 4730
    },
    {
      "epoch": 0.8650424308787298,
      "grad_norm": 5.621465682983398,
      "learning_rate": 1.1199099268155378e-05,
      "logits/chosen": -2.6958165168762207,
      "logits/rejected": -2.489983081817627,
      "logps/chosen": -168.22401428222656,
      "logps/rejected": -132.9518280029297,
      "loss": 0.608,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8648964166641235,
      "rewards/margins": 1.079700231552124,
      "rewards/rejected": -1.9445966482162476,
      "step": 4740
    },
    {
      "epoch": 0.8668674149101195,
      "grad_norm": 4.384995937347412,
      "learning_rate": 1.1048977294051417e-05,
      "logits/chosen": -2.64860463142395,
      "logits/rejected": -2.6009726524353027,
      "logps/chosen": -133.79086303710938,
      "logps/rejected": -141.770263671875,
      "loss": 0.5665,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0927737951278687,
      "rewards/margins": 1.1475725173950195,
      "rewards/rejected": -2.2403464317321777,
      "step": 4750
    },
    {
      "epoch": 0.8686923989415093,
      "grad_norm": 4.352636337280273,
      "learning_rate": 1.0898855319947458e-05,
      "logits/chosen": -2.475721836090088,
      "logits/rejected": -2.5488369464874268,
      "logps/chosen": -118.93101501464844,
      "logps/rejected": -157.9466094970703,
      "loss": 0.5616,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2373783588409424,
      "rewards/margins": 1.1595405340194702,
      "rewards/rejected": -2.396918773651123,
      "step": 4760
    },
    {
      "epoch": 0.8705173829728989,
      "grad_norm": 5.465213298797607,
      "learning_rate": 1.0748733345843498e-05,
      "logits/chosen": -2.628671884536743,
      "logits/rejected": -2.5157999992370605,
      "logps/chosen": -131.4976806640625,
      "logps/rejected": -136.67996215820312,
      "loss": 0.4935,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2312605381011963,
      "rewards/margins": 1.3604423999786377,
      "rewards/rejected": -2.591702938079834,
      "step": 4770
    },
    {
      "epoch": 0.8723423670042887,
      "grad_norm": 6.658505439758301,
      "learning_rate": 1.059861137173954e-05,
      "logits/chosen": -2.683846950531006,
      "logits/rejected": -2.63141131401062,
      "logps/chosen": -148.4324493408203,
      "logps/rejected": -148.429443359375,
      "loss": 0.5432,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.1737136840820312,
      "rewards/margins": 1.0744222402572632,
      "rewards/rejected": -2.248136043548584,
      "step": 4780
    },
    {
      "epoch": 0.8741673510356784,
      "grad_norm": 5.225896835327148,
      "learning_rate": 1.044848939763558e-05,
      "logits/chosen": -2.58030366897583,
      "logits/rejected": -2.5343987941741943,
      "logps/chosen": -127.9443588256836,
      "logps/rejected": -118.6398696899414,
      "loss": 0.5275,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.107508659362793,
      "rewards/margins": 1.2157552242279053,
      "rewards/rejected": -2.323263645172119,
      "step": 4790
    },
    {
      "epoch": 0.8759923350670682,
      "grad_norm": 7.104804039001465,
      "learning_rate": 1.0298367423531621e-05,
      "logits/chosen": -2.558607578277588,
      "logits/rejected": -2.512033224105835,
      "logps/chosen": -133.7987060546875,
      "logps/rejected": -140.90658569335938,
      "loss": 0.6465,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.1826382875442505,
      "rewards/margins": 0.8325251340866089,
      "rewards/rejected": -2.0151636600494385,
      "step": 4800
    },
    {
      "epoch": 0.8778173190984578,
      "grad_norm": 5.1860737800598145,
      "learning_rate": 1.014824544942766e-05,
      "logits/chosen": -2.643455982208252,
      "logits/rejected": -2.5569541454315186,
      "logps/chosen": -133.62289428710938,
      "logps/rejected": -134.93678283691406,
      "loss": 0.4465,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1993155479431152,
      "rewards/margins": 1.2335669994354248,
      "rewards/rejected": -2.43288254737854,
      "step": 4810
    },
    {
      "epoch": 0.8796423031298476,
      "grad_norm": 11.034368515014648,
      "learning_rate": 9.998123475323702e-06,
      "logits/chosen": -2.670032501220703,
      "logits/rejected": -2.582519054412842,
      "logps/chosen": -137.31259155273438,
      "logps/rejected": -139.06358337402344,
      "loss": 0.502,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9679095149040222,
      "rewards/margins": 1.207148551940918,
      "rewards/rejected": -2.175057888031006,
      "step": 4820
    },
    {
      "epoch": 0.8814672871612373,
      "grad_norm": 5.42802619934082,
      "learning_rate": 9.848001501219741e-06,
      "logits/chosen": -2.5114221572875977,
      "logits/rejected": -2.3607184886932373,
      "logps/chosen": -155.67149353027344,
      "logps/rejected": -134.0083770751953,
      "loss": 0.5963,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9118584394454956,
      "rewards/margins": 1.2419545650482178,
      "rewards/rejected": -2.153813123703003,
      "step": 4830
    },
    {
      "epoch": 0.8832922711926271,
      "grad_norm": 6.007030963897705,
      "learning_rate": 9.697879527115783e-06,
      "logits/chosen": -2.655590057373047,
      "logits/rejected": -2.503279447555542,
      "logps/chosen": -138.38455200195312,
      "logps/rejected": -115.50688171386719,
      "loss": 0.5737,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1625630855560303,
      "rewards/margins": 0.9327972531318665,
      "rewards/rejected": -2.095360517501831,
      "step": 4840
    },
    {
      "epoch": 0.8851172552240167,
      "grad_norm": 7.429067134857178,
      "learning_rate": 9.547757553011822e-06,
      "logits/chosen": -2.5823440551757812,
      "logits/rejected": -2.497797727584839,
      "logps/chosen": -148.80459594726562,
      "logps/rejected": -148.83509826660156,
      "loss": 0.6005,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.0832221508026123,
      "rewards/margins": 0.8529642820358276,
      "rewards/rejected": -1.9361861944198608,
      "step": 4850
    },
    {
      "epoch": 0.8869422392554065,
      "grad_norm": 4.359014987945557,
      "learning_rate": 9.397635578907863e-06,
      "logits/chosen": -2.6178855895996094,
      "logits/rejected": -2.3794217109680176,
      "logps/chosen": -150.2004852294922,
      "logps/rejected": -110.74113464355469,
      "loss": 0.563,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9573365449905396,
      "rewards/margins": 0.9173489809036255,
      "rewards/rejected": -1.8746856451034546,
      "step": 4860
    },
    {
      "epoch": 0.8887672232867962,
      "grad_norm": 4.022671222686768,
      "learning_rate": 9.247513604803904e-06,
      "logits/chosen": -2.5642495155334473,
      "logits/rejected": -2.4935100078582764,
      "logps/chosen": -123.88444519042969,
      "logps/rejected": -122.9025650024414,
      "loss": 0.5333,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7820272445678711,
      "rewards/margins": 0.9333568811416626,
      "rewards/rejected": -1.7153841257095337,
      "step": 4870
    },
    {
      "epoch": 0.890592207318186,
      "grad_norm": 6.311031818389893,
      "learning_rate": 9.097391630699944e-06,
      "logits/chosen": -2.6403958797454834,
      "logits/rejected": -2.546623945236206,
      "logps/chosen": -136.09840393066406,
      "logps/rejected": -128.97181701660156,
      "loss": 0.5554,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.8784992098808289,
      "rewards/margins": 0.738358199596405,
      "rewards/rejected": -1.6168575286865234,
      "step": 4880
    },
    {
      "epoch": 0.8924171913495756,
      "grad_norm": 6.380713939666748,
      "learning_rate": 8.947269656595985e-06,
      "logits/chosen": -2.5341954231262207,
      "logits/rejected": -2.484166145324707,
      "logps/chosen": -116.62864685058594,
      "logps/rejected": -124.06028747558594,
      "loss": 0.5494,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.1105310916900635,
      "rewards/margins": 0.916172981262207,
      "rewards/rejected": -2.0267038345336914,
      "step": 4890
    },
    {
      "epoch": 0.8942421753809654,
      "grad_norm": 2.8113038539886475,
      "learning_rate": 8.797147682492026e-06,
      "logits/chosen": -2.601161241531372,
      "logits/rejected": -2.5955028533935547,
      "logps/chosen": -142.38478088378906,
      "logps/rejected": -160.6363983154297,
      "loss": 0.5277,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9858749508857727,
      "rewards/margins": 0.9743081331253052,
      "rewards/rejected": -1.9601831436157227,
      "step": 4900
    },
    {
      "epoch": 0.8960671594123552,
      "grad_norm": 5.2035231590271,
      "learning_rate": 8.647025708388066e-06,
      "logits/chosen": -2.6550707817077637,
      "logits/rejected": -2.467101573944092,
      "logps/chosen": -127.960693359375,
      "logps/rejected": -115.1823959350586,
      "loss": 0.4592,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7467267513275146,
      "rewards/margins": 1.211366057395935,
      "rewards/rejected": -1.9580929279327393,
      "step": 4910
    },
    {
      "epoch": 0.8978921434437449,
      "grad_norm": 4.222314357757568,
      "learning_rate": 8.496903734284107e-06,
      "logits/chosen": -2.68733549118042,
      "logits/rejected": -2.6108086109161377,
      "logps/chosen": -146.46798706054688,
      "logps/rejected": -130.84664916992188,
      "loss": 0.5082,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7731224894523621,
      "rewards/margins": 1.0393468141555786,
      "rewards/rejected": -1.812469244003296,
      "step": 4920
    },
    {
      "epoch": 0.8997171274751345,
      "grad_norm": 5.418064117431641,
      "learning_rate": 8.346781760180146e-06,
      "logits/chosen": -2.5782618522644043,
      "logits/rejected": -2.453275203704834,
      "logps/chosen": -143.30206298828125,
      "logps/rejected": -136.1195068359375,
      "loss": 0.5391,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.775731086730957,
      "rewards/margins": 1.034284234046936,
      "rewards/rejected": -1.810015320777893,
      "step": 4930
    },
    {
      "epoch": 0.9015421115065243,
      "grad_norm": 4.904159069061279,
      "learning_rate": 8.196659786076187e-06,
      "logits/chosen": -2.6080315113067627,
      "logits/rejected": -2.521777391433716,
      "logps/chosen": -128.76199340820312,
      "logps/rejected": -117.28887939453125,
      "loss": 0.5157,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.9322229623794556,
      "rewards/margins": 1.014449119567871,
      "rewards/rejected": -1.9466718435287476,
      "step": 4940
    },
    {
      "epoch": 0.903367095537914,
      "grad_norm": 4.817139148712158,
      "learning_rate": 8.046537811972229e-06,
      "logits/chosen": -2.465949535369873,
      "logits/rejected": -2.453737258911133,
      "logps/chosen": -112.52862548828125,
      "logps/rejected": -119.37776184082031,
      "loss": 0.5203,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0133874416351318,
      "rewards/margins": 0.9338682293891907,
      "rewards/rejected": -1.9472554922103882,
      "step": 4950
    },
    {
      "epoch": 0.9051920795693038,
      "grad_norm": 5.852043628692627,
      "learning_rate": 7.896415837868268e-06,
      "logits/chosen": -2.681414842605591,
      "logits/rejected": -2.516573429107666,
      "logps/chosen": -143.4747314453125,
      "logps/rejected": -120.2377700805664,
      "loss": 0.5112,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8763588666915894,
      "rewards/margins": 1.1563153266906738,
      "rewards/rejected": -2.0326743125915527,
      "step": 4960
    },
    {
      "epoch": 0.9070170636006935,
      "grad_norm": 4.971339702606201,
      "learning_rate": 7.74629386376431e-06,
      "logits/chosen": -2.6674256324768066,
      "logits/rejected": -2.5954372882843018,
      "logps/chosen": -142.30520629882812,
      "logps/rejected": -146.01092529296875,
      "loss": 0.4317,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9624913930892944,
      "rewards/margins": 1.1377050876617432,
      "rewards/rejected": -2.100196361541748,
      "step": 4970
    },
    {
      "epoch": 0.9088420476320832,
      "grad_norm": 4.297473430633545,
      "learning_rate": 7.59617188966035e-06,
      "logits/chosen": -2.6305606365203857,
      "logits/rejected": -2.501452684402466,
      "logps/chosen": -129.14572143554688,
      "logps/rejected": -126.5699234008789,
      "loss": 0.5588,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.9731548428535461,
      "rewards/margins": 0.9796401858329773,
      "rewards/rejected": -1.9527950286865234,
      "step": 4980
    },
    {
      "epoch": 0.910667031663473,
      "grad_norm": 6.737730503082275,
      "learning_rate": 7.44604991555639e-06,
      "logits/chosen": -2.668921947479248,
      "logits/rejected": -2.3988122940063477,
      "logps/chosen": -156.7523193359375,
      "logps/rejected": -129.8453826904297,
      "loss": 0.5127,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.3413112163543701,
      "rewards/margins": 1.2313544750213623,
      "rewards/rejected": -2.5726656913757324,
      "step": 4990
    },
    {
      "epoch": 0.9124920156948627,
      "grad_norm": 6.073237895965576,
      "learning_rate": 7.295927941452431e-06,
      "logits/chosen": -2.5778491497039795,
      "logits/rejected": -2.418600559234619,
      "logps/chosen": -145.23660278320312,
      "logps/rejected": -131.08157348632812,
      "loss": 0.5266,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.0774190425872803,
      "rewards/margins": 1.1933234930038452,
      "rewards/rejected": -2.270742416381836,
      "step": 5000
    },
    {
      "epoch": 0.9143169997262524,
      "grad_norm": 4.895395755767822,
      "learning_rate": 7.1458059673484715e-06,
      "logits/chosen": -2.639725923538208,
      "logits/rejected": -2.459900379180908,
      "logps/chosen": -156.2251434326172,
      "logps/rejected": -130.0203857421875,
      "loss": 0.4395,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0136877298355103,
      "rewards/margins": 1.4365990161895752,
      "rewards/rejected": -2.450286626815796,
      "step": 5010
    },
    {
      "epoch": 0.9161419837576421,
      "grad_norm": 9.00960922241211,
      "learning_rate": 6.995683993244512e-06,
      "logits/chosen": -2.6543357372283936,
      "logits/rejected": -2.50727915763855,
      "logps/chosen": -124.43830871582031,
      "logps/rejected": -122.45267486572266,
      "loss": 0.5782,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.2932878732681274,
      "rewards/margins": 1.2483487129211426,
      "rewards/rejected": -2.5416364669799805,
      "step": 5020
    },
    {
      "epoch": 0.9179669677890319,
      "grad_norm": 10.902544975280762,
      "learning_rate": 6.845562019140552e-06,
      "logits/chosen": -2.5892016887664795,
      "logits/rejected": -2.444209575653076,
      "logps/chosen": -151.55804443359375,
      "logps/rejected": -147.83609008789062,
      "loss": 0.5344,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1387073993682861,
      "rewards/margins": 1.112653136253357,
      "rewards/rejected": -2.2513606548309326,
      "step": 5030
    },
    {
      "epoch": 0.9197919518204216,
      "grad_norm": 7.394289016723633,
      "learning_rate": 6.695440045036593e-06,
      "logits/chosen": -2.619784116744995,
      "logits/rejected": -2.4997739791870117,
      "logps/chosen": -151.4549102783203,
      "logps/rejected": -137.44528198242188,
      "loss": 0.6191,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.1742334365844727,
      "rewards/margins": 0.8722003698348999,
      "rewards/rejected": -2.046433687210083,
      "step": 5040
    },
    {
      "epoch": 0.9216169358518113,
      "grad_norm": 5.077610969543457,
      "learning_rate": 6.545318070932634e-06,
      "logits/chosen": -2.5279812812805176,
      "logits/rejected": -2.4243171215057373,
      "logps/chosen": -122.89775085449219,
      "logps/rejected": -126.70294189453125,
      "loss": 0.4606,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9599002599716187,
      "rewards/margins": 1.479706048965454,
      "rewards/rejected": -2.439606189727783,
      "step": 5050
    },
    {
      "epoch": 0.923441919883201,
      "grad_norm": 23.10643196105957,
      "learning_rate": 6.395196096828674e-06,
      "logits/chosen": -2.5610108375549316,
      "logits/rejected": -2.364375591278076,
      "logps/chosen": -152.44284057617188,
      "logps/rejected": -115.1534652709961,
      "loss": 0.626,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.1505444049835205,
      "rewards/margins": 1.0875526666641235,
      "rewards/rejected": -2.2380969524383545,
      "step": 5060
    },
    {
      "epoch": 0.9252669039145908,
      "grad_norm": 3.875401496887207,
      "learning_rate": 6.245074122724715e-06,
      "logits/chosen": -2.7072665691375732,
      "logits/rejected": -2.639756679534912,
      "logps/chosen": -134.06919860839844,
      "logps/rejected": -141.68304443359375,
      "loss": 0.4598,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.0490847826004028,
      "rewards/margins": 1.2599108219146729,
      "rewards/rejected": -2.308995485305786,
      "step": 5070
    },
    {
      "epoch": 0.9270918879459805,
      "grad_norm": 4.772804260253906,
      "learning_rate": 6.0949521486207554e-06,
      "logits/chosen": -2.738595962524414,
      "logits/rejected": -2.6010191440582275,
      "logps/chosen": -127.16536712646484,
      "logps/rejected": -131.9310760498047,
      "loss": 0.4891,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0551878213882446,
      "rewards/margins": 1.3182703256607056,
      "rewards/rejected": -2.37345814704895,
      "step": 5080
    },
    {
      "epoch": 0.9289168719773702,
      "grad_norm": 6.985811710357666,
      "learning_rate": 5.944830174516796e-06,
      "logits/chosen": -2.58134388923645,
      "logits/rejected": -2.5611464977264404,
      "logps/chosen": -129.54917907714844,
      "logps/rejected": -137.7565460205078,
      "loss": 0.5849,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.960946261882782,
      "rewards/margins": 1.0619533061981201,
      "rewards/rejected": -2.022899627685547,
      "step": 5090
    },
    {
      "epoch": 0.9307418560087599,
      "grad_norm": 6.802789688110352,
      "learning_rate": 5.794708200412836e-06,
      "logits/chosen": -2.6185288429260254,
      "logits/rejected": -2.5453128814697266,
      "logps/chosen": -147.38259887695312,
      "logps/rejected": -141.66075134277344,
      "loss": 0.6878,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.2484735250473022,
      "rewards/margins": 0.7291097640991211,
      "rewards/rejected": -1.9775832891464233,
      "step": 5100
    },
    {
      "epoch": 0.9325668400401497,
      "grad_norm": 5.421417713165283,
      "learning_rate": 5.644586226308877e-06,
      "logits/chosen": -2.683032989501953,
      "logits/rejected": -2.4030261039733887,
      "logps/chosen": -138.97158813476562,
      "logps/rejected": -114.3052978515625,
      "loss": 0.5241,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7754751443862915,
      "rewards/margins": 1.314928412437439,
      "rewards/rejected": -2.0904037952423096,
      "step": 5110
    },
    {
      "epoch": 0.9343918240715394,
      "grad_norm": 3.5512421131134033,
      "learning_rate": 5.494464252204918e-06,
      "logits/chosen": -2.668977975845337,
      "logits/rejected": -2.5960750579833984,
      "logps/chosen": -124.33158874511719,
      "logps/rejected": -116.8194580078125,
      "loss": 0.6362,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.3862143754959106,
      "rewards/margins": 0.9490643739700317,
      "rewards/rejected": -2.3352785110473633,
      "step": 5120
    },
    {
      "epoch": 0.9362168081029291,
      "grad_norm": 5.155153274536133,
      "learning_rate": 5.344342278100958e-06,
      "logits/chosen": -2.7194879055023193,
      "logits/rejected": -2.5494940280914307,
      "logps/chosen": -154.55194091796875,
      "logps/rejected": -135.15830993652344,
      "loss": 0.5272,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0411792993545532,
      "rewards/margins": 1.1081581115722656,
      "rewards/rejected": -2.1493372917175293,
      "step": 5130
    },
    {
      "epoch": 0.9380417921343188,
      "grad_norm": 5.884458541870117,
      "learning_rate": 5.194220303996998e-06,
      "logits/chosen": -2.665024757385254,
      "logits/rejected": -2.5946319103240967,
      "logps/chosen": -141.30772399902344,
      "logps/rejected": -126.44889831542969,
      "loss": 0.5575,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0728721618652344,
      "rewards/margins": 0.9515096545219421,
      "rewards/rejected": -2.024381637573242,
      "step": 5140
    },
    {
      "epoch": 0.9398667761657086,
      "grad_norm": 7.156614303588867,
      "learning_rate": 5.0440983298930394e-06,
      "logits/chosen": -2.657552480697632,
      "logits/rejected": -2.5510268211364746,
      "logps/chosen": -139.89956665039062,
      "logps/rejected": -122.6423110961914,
      "loss": 0.616,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.0097594261169434,
      "rewards/margins": 1.0925527811050415,
      "rewards/rejected": -2.1023120880126953,
      "step": 5150
    },
    {
      "epoch": 0.9416917601970983,
      "grad_norm": 5.590129852294922,
      "learning_rate": 4.893976355789079e-06,
      "logits/chosen": -2.57621431350708,
      "logits/rejected": -2.5213735103607178,
      "logps/chosen": -137.39515686035156,
      "logps/rejected": -144.19422912597656,
      "loss": 0.4974,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.2675471305847168,
      "rewards/margins": 0.9308677911758423,
      "rewards/rejected": -2.1984148025512695,
      "step": 5160
    },
    {
      "epoch": 0.943516744228488,
      "grad_norm": 6.245999813079834,
      "learning_rate": 4.743854381685119e-06,
      "logits/chosen": -2.6913862228393555,
      "logits/rejected": -2.5725040435791016,
      "logps/chosen": -134.56234741210938,
      "logps/rejected": -114.0805435180664,
      "loss": 0.5539,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0180680751800537,
      "rewards/margins": 0.9158011674880981,
      "rewards/rejected": -1.9338691234588623,
      "step": 5170
    },
    {
      "epoch": 0.9453417282598777,
      "grad_norm": 4.299062728881836,
      "learning_rate": 4.59373240758116e-06,
      "logits/chosen": -2.5940306186676025,
      "logits/rejected": -2.415503978729248,
      "logps/chosen": -145.01773071289062,
      "logps/rejected": -120.42110443115234,
      "loss": 0.4357,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.1189755201339722,
      "rewards/margins": 1.1671335697174072,
      "rewards/rejected": -2.2861084938049316,
      "step": 5180
    },
    {
      "epoch": 0.9471667122912675,
      "grad_norm": 4.912108898162842,
      "learning_rate": 4.443610433477201e-06,
      "logits/chosen": -2.561091184616089,
      "logits/rejected": -2.4922804832458496,
      "logps/chosen": -141.07296752929688,
      "logps/rejected": -140.66043090820312,
      "loss": 0.4547,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2736985683441162,
      "rewards/margins": 1.1630475521087646,
      "rewards/rejected": -2.436746120452881,
      "step": 5190
    },
    {
      "epoch": 0.9489916963226572,
      "grad_norm": 4.501620292663574,
      "learning_rate": 4.293488459373241e-06,
      "logits/chosen": -2.7400927543640137,
      "logits/rejected": -2.5188326835632324,
      "logps/chosen": -143.51315307617188,
      "logps/rejected": -130.05116271972656,
      "loss": 0.4093,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7609957456588745,
      "rewards/margins": 1.388185739517212,
      "rewards/rejected": -2.149181604385376,
      "step": 5200
    },
    {
      "epoch": 0.9508166803540469,
      "grad_norm": 3.4062235355377197,
      "learning_rate": 4.143366485269281e-06,
      "logits/chosen": -2.6120498180389404,
      "logits/rejected": -2.459895372390747,
      "logps/chosen": -141.05796813964844,
      "logps/rejected": -125.58499908447266,
      "loss": 0.6767,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.2248008251190186,
      "rewards/margins": 0.823525607585907,
      "rewards/rejected": -2.0483267307281494,
      "step": 5210
    },
    {
      "epoch": 0.9526416643854366,
      "grad_norm": 4.206314563751221,
      "learning_rate": 3.9932445111653226e-06,
      "logits/chosen": -2.6206884384155273,
      "logits/rejected": -2.540295362472534,
      "logps/chosen": -133.2779998779297,
      "logps/rejected": -128.05990600585938,
      "loss": 0.5001,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.0604060888290405,
      "rewards/margins": 1.2093838453292847,
      "rewards/rejected": -2.269789934158325,
      "step": 5220
    },
    {
      "epoch": 0.9544666484168264,
      "grad_norm": 6.027927398681641,
      "learning_rate": 3.843122537061363e-06,
      "logits/chosen": -2.748523235321045,
      "logits/rejected": -2.5014052391052246,
      "logps/chosen": -156.22886657714844,
      "logps/rejected": -126.748291015625,
      "loss": 0.5635,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.2396358251571655,
      "rewards/margins": 1.1677613258361816,
      "rewards/rejected": -2.407397508621216,
      "step": 5230
    },
    {
      "epoch": 0.9562916324482161,
      "grad_norm": 8.012752532958984,
      "learning_rate": 3.6930005629574032e-06,
      "logits/chosen": -2.6624059677124023,
      "logits/rejected": -2.5331270694732666,
      "logps/chosen": -141.62716674804688,
      "logps/rejected": -134.0032196044922,
      "loss": 0.6286,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.3739702701568604,
      "rewards/margins": 0.814238429069519,
      "rewards/rejected": -2.188208818435669,
      "step": 5240
    },
    {
      "epoch": 0.9581166164796058,
      "grad_norm": 6.576486587524414,
      "learning_rate": 3.542878588853444e-06,
      "logits/chosen": -2.5570547580718994,
      "logits/rejected": -2.4711191654205322,
      "logps/chosen": -135.33963012695312,
      "logps/rejected": -148.4684600830078,
      "loss": 0.5747,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.2237409353256226,
      "rewards/margins": 0.9547117948532104,
      "rewards/rejected": -2.178452730178833,
      "step": 5250
    },
    {
      "epoch": 0.9599416005109955,
      "grad_norm": 4.704826354980469,
      "learning_rate": 3.3927566147494843e-06,
      "logits/chosen": -2.556372880935669,
      "logits/rejected": -2.483738422393799,
      "logps/chosen": -135.26034545898438,
      "logps/rejected": -126.82563781738281,
      "loss": 0.619,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.4579277038574219,
      "rewards/margins": 0.7442724704742432,
      "rewards/rejected": -2.202200174331665,
      "step": 5260
    },
    {
      "epoch": 0.9617665845423853,
      "grad_norm": 6.455029487609863,
      "learning_rate": 3.242634640645525e-06,
      "logits/chosen": -2.667832851409912,
      "logits/rejected": -2.5511887073516846,
      "logps/chosen": -135.6425018310547,
      "logps/rejected": -131.5713348388672,
      "loss": 0.5625,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0791970491409302,
      "rewards/margins": 1.025200605392456,
      "rewards/rejected": -2.104397773742676,
      "step": 5270
    },
    {
      "epoch": 0.9635915685737749,
      "grad_norm": 5.854624271392822,
      "learning_rate": 3.092512666541565e-06,
      "logits/chosen": -2.6280863285064697,
      "logits/rejected": -2.492922306060791,
      "logps/chosen": -137.35247802734375,
      "logps/rejected": -132.6622772216797,
      "loss": 0.4658,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1939016580581665,
      "rewards/margins": 1.4250266551971436,
      "rewards/rejected": -2.6189284324645996,
      "step": 5280
    },
    {
      "epoch": 0.9654165526051647,
      "grad_norm": 3.2349607944488525,
      "learning_rate": 2.9423906924376057e-06,
      "logits/chosen": -2.5931620597839355,
      "logits/rejected": -2.5512478351593018,
      "logps/chosen": -146.56973266601562,
      "logps/rejected": -140.06651306152344,
      "loss": 0.5555,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.2473070621490479,
      "rewards/margins": 1.0691375732421875,
      "rewards/rejected": -2.3164443969726562,
      "step": 5290
    },
    {
      "epoch": 0.9672415366365544,
      "grad_norm": 5.183230876922607,
      "learning_rate": 2.792268718333646e-06,
      "logits/chosen": -2.594872236251831,
      "logits/rejected": -2.431334972381592,
      "logps/chosen": -148.92881774902344,
      "logps/rejected": -118.92878723144531,
      "loss": 0.5803,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.2014074325561523,
      "rewards/margins": 0.7939847707748413,
      "rewards/rejected": -1.9953922033309937,
      "step": 5300
    },
    {
      "epoch": 0.9690665206679442,
      "grad_norm": 6.805576324462891,
      "learning_rate": 2.6421467442296868e-06,
      "logits/chosen": -2.6514666080474854,
      "logits/rejected": -2.5960493087768555,
      "logps/chosen": -143.09043884277344,
      "logps/rejected": -145.7832489013672,
      "loss": 0.7185,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.5768938064575195,
      "rewards/margins": 0.6689296364784241,
      "rewards/rejected": -2.245823383331299,
      "step": 5310
    },
    {
      "epoch": 0.9708915046993338,
      "grad_norm": 6.049954891204834,
      "learning_rate": 2.4920247701257275e-06,
      "logits/chosen": -2.7531728744506836,
      "logits/rejected": -2.5648159980773926,
      "logps/chosen": -148.1363983154297,
      "logps/rejected": -122.64208984375,
      "loss": 0.4344,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0594079494476318,
      "rewards/margins": 1.331979513168335,
      "rewards/rejected": -2.391387462615967,
      "step": 5320
    },
    {
      "epoch": 0.9727164887307236,
      "grad_norm": 3.5710818767547607,
      "learning_rate": 2.341902796021768e-06,
      "logits/chosen": -2.628929615020752,
      "logits/rejected": -2.51423716545105,
      "logps/chosen": -143.82260131835938,
      "logps/rejected": -135.59048461914062,
      "loss": 0.4778,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0429461002349854,
      "rewards/margins": 1.097476601600647,
      "rewards/rejected": -2.1404225826263428,
      "step": 5330
    },
    {
      "epoch": 0.9745414727621133,
      "grad_norm": 6.450779914855957,
      "learning_rate": 2.191780821917808e-06,
      "logits/chosen": -2.5778262615203857,
      "logits/rejected": -2.5125784873962402,
      "logps/chosen": -133.1647186279297,
      "logps/rejected": -128.79922485351562,
      "loss": 0.6096,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.332908034324646,
      "rewards/margins": 0.8543310165405273,
      "rewards/rejected": -2.187239170074463,
      "step": 5340
    },
    {
      "epoch": 0.9763664567935031,
      "grad_norm": 9.467707633972168,
      "learning_rate": 2.041658847813849e-06,
      "logits/chosen": -2.689483642578125,
      "logits/rejected": -2.64534330368042,
      "logps/chosen": -153.0635528564453,
      "logps/rejected": -139.9286651611328,
      "loss": 0.6498,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.5635225772857666,
      "rewards/margins": 0.6941515207290649,
      "rewards/rejected": -2.257673978805542,
      "step": 5350
    },
    {
      "epoch": 0.9781914408248927,
      "grad_norm": 7.806236267089844,
      "learning_rate": 1.8915368737098895e-06,
      "logits/chosen": -2.525430202484131,
      "logits/rejected": -2.4864203929901123,
      "logps/chosen": -143.40081787109375,
      "logps/rejected": -130.55699157714844,
      "loss": 0.7789,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -1.6584545373916626,
      "rewards/margins": 0.5181323289871216,
      "rewards/rejected": -2.176586627960205,
      "step": 5360
    },
    {
      "epoch": 0.9800164248562825,
      "grad_norm": 6.127879619598389,
      "learning_rate": 1.74141489960593e-06,
      "logits/chosen": -2.7478349208831787,
      "logits/rejected": -2.6486289501190186,
      "logps/chosen": -136.22848510742188,
      "logps/rejected": -133.2983856201172,
      "loss": 0.4735,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.236745834350586,
      "rewards/margins": 1.0260897874832153,
      "rewards/rejected": -2.262835741043091,
      "step": 5370
    },
    {
      "epoch": 0.9818414088876722,
      "grad_norm": 4.396317481994629,
      "learning_rate": 1.5912929255019705e-06,
      "logits/chosen": -2.5660529136657715,
      "logits/rejected": -2.566023349761963,
      "logps/chosen": -127.07011413574219,
      "logps/rejected": -126.8545150756836,
      "loss": 0.6015,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.293502926826477,
      "rewards/margins": 0.8420907258987427,
      "rewards/rejected": -2.135593891143799,
      "step": 5380
    },
    {
      "epoch": 0.983666392919062,
      "grad_norm": 4.03972053527832,
      "learning_rate": 1.441170951398011e-06,
      "logits/chosen": -2.5538156032562256,
      "logits/rejected": -2.5636956691741943,
      "logps/chosen": -119.048828125,
      "logps/rejected": -134.69863891601562,
      "loss": 0.5789,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.4173511266708374,
      "rewards/margins": 0.8613840937614441,
      "rewards/rejected": -2.278735399246216,
      "step": 5390
    },
    {
      "epoch": 0.9854913769504516,
      "grad_norm": 10.4498929977417,
      "learning_rate": 1.2910489772940516e-06,
      "logits/chosen": -2.608372449874878,
      "logits/rejected": -2.499382495880127,
      "logps/chosen": -149.90090942382812,
      "logps/rejected": -143.39718627929688,
      "loss": 0.5213,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2894072532653809,
      "rewards/margins": 1.1224257946014404,
      "rewards/rejected": -2.4118330478668213,
      "step": 5400
    },
    {
      "epoch": 0.9873163609818414,
      "grad_norm": 4.7770209312438965,
      "learning_rate": 1.1409270031900922e-06,
      "logits/chosen": -2.6202926635742188,
      "logits/rejected": -2.6065261363983154,
      "logps/chosen": -124.31622314453125,
      "logps/rejected": -137.25234985351562,
      "loss": 0.4519,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.1448637247085571,
      "rewards/margins": 1.2229368686676025,
      "rewards/rejected": -2.36780047416687,
      "step": 5410
    },
    {
      "epoch": 0.9891413450132311,
      "grad_norm": 3.17768931388855,
      "learning_rate": 9.908050290861327e-07,
      "logits/chosen": -2.5854907035827637,
      "logits/rejected": -2.42053484916687,
      "logps/chosen": -154.5315399169922,
      "logps/rejected": -139.26080322265625,
      "loss": 0.4269,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0812855958938599,
      "rewards/margins": 1.147510290145874,
      "rewards/rejected": -2.2287955284118652,
      "step": 5420
    },
    {
      "epoch": 0.9909663290446209,
      "grad_norm": 4.927701950073242,
      "learning_rate": 8.40683054982173e-07,
      "logits/chosen": -2.6138458251953125,
      "logits/rejected": -2.574979305267334,
      "logps/chosen": -146.65145874023438,
      "logps/rejected": -151.2632293701172,
      "loss": 0.4395,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.0107662677764893,
      "rewards/margins": 1.3035297393798828,
      "rewards/rejected": -2.314296245574951,
      "step": 5430
    },
    {
      "epoch": 0.9927913130760105,
      "grad_norm": 3.031869411468506,
      "learning_rate": 6.905610808782136e-07,
      "logits/chosen": -2.6452643871307373,
      "logits/rejected": -2.481574535369873,
      "logps/chosen": -155.51744079589844,
      "logps/rejected": -125.78691101074219,
      "loss": 0.4814,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.106610894203186,
      "rewards/margins": 1.2182481288909912,
      "rewards/rejected": -2.3248589038848877,
      "step": 5440
    },
    {
      "epoch": 0.9946162971074003,
      "grad_norm": 4.965636253356934,
      "learning_rate": 5.404391067742541e-07,
      "logits/chosen": -2.6841213703155518,
      "logits/rejected": -2.567760944366455,
      "logps/chosen": -127.10904693603516,
      "logps/rejected": -134.2977752685547,
      "loss": 0.3832,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.081321120262146,
      "rewards/margins": 1.4525560140609741,
      "rewards/rejected": -2.533876895904541,
      "step": 5450
    },
    {
      "epoch": 0.99644128113879,
      "grad_norm": 4.126001834869385,
      "learning_rate": 3.903171326702947e-07,
      "logits/chosen": -2.600142240524292,
      "logits/rejected": -2.5669894218444824,
      "logps/chosen": -134.84268188476562,
      "logps/rejected": -136.0788116455078,
      "loss": 0.5274,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0273422002792358,
      "rewards/margins": 0.9695913195610046,
      "rewards/rejected": -1.9969335794448853,
      "step": 5460
    },
    {
      "epoch": 0.9982662651701798,
      "grad_norm": 3.5677671432495117,
      "learning_rate": 2.401951585663352e-07,
      "logits/chosen": -2.705389976501465,
      "logits/rejected": -2.582361936569214,
      "logps/chosen": -150.9313507080078,
      "logps/rejected": -138.55859375,
      "loss": 0.5824,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.3854666948318481,
      "rewards/margins": 0.9952986836433411,
      "rewards/rejected": -2.380765438079834,
      "step": 5470
    }
  ],
  "logging_steps": 10,
  "max_steps": 5479,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
